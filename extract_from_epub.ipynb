{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# By ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ebooklib import epub, ITEM_DOCUMENT  # 수정된 부분\n",
    "from bs4 import BeautifulSoup\n",
    "import html2text\n",
    "\n",
    "def epub_to_markdown(epub_path, output_md_path):\n",
    "    # EPUB 파일 읽기\n",
    "    book = epub.read_epub(epub_path)\n",
    "    \n",
    "    # 변환기 설정\n",
    "    converter = html2text.HTML2Text()\n",
    "    converter.ignore_links = False  # 링크 유지\n",
    "    converter.ignore_images = False  # 이미지 유지\n",
    "    converter.ignore_tables = False  # 표 유지\n",
    "    \n",
    "    md_content = \"\"\n",
    "\n",
    "    # EPUB 파일에서 본문 추출\n",
    "    for item in book.get_items():\n",
    "        if item.get_type() == ITEM_DOCUMENT:  # 수정된 부분\n",
    "            # HTML 파싱\n",
    "            soup = BeautifulSoup(item.content, \"html.parser\")\n",
    "            \n",
    "            # 제목 추출 (h1~h6 태그 변환)\n",
    "            for header in soup.find_all([\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"]):\n",
    "                header.string = \"#\" * int(header.name[1]) + \" \" + (header.get_text() or \"\")\n",
    "                \n",
    "            # HTML -> Markdown 변환\n",
    "            md_content += converter.handle(str(soup)) + \"\\n\\n\"\n",
    "    \n",
    "    # 결과 저장\n",
    "    with open(output_md_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(md_content)\n",
    "    \n",
    "    print(f\"Markdown 파일이 생성되었습니다: {output_md_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/skcho/miniconda3/envs/translation/lib/python3.11/site-packages/ebooklib/epub.py:1395: UserWarning: In the future version we will turn default option ignore_ncx to True.\n",
      "  warnings.warn('In the future version we will turn default option ignore_ncx to True.')\n",
      "/Users/skcho/miniconda3/envs/translation/lib/python3.11/site-packages/ebooklib/epub.py:1423: FutureWarning: This search incorrectly ignores the root element, and will be fixed in a future version.  If you rely on the current behaviour, change it to './/xmlns:rootfile[@media-type]'\n",
      "  for root_file in tree.findall('//xmlns:rootfile[@media-type]', namespaces={'xmlns': NAMESPACES['CONTAINERNS']}):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markdown 파일이 생성되었습니다: The Collected Works of Spinoza.qmd\n"
     ]
    }
   ],
   "source": [
    "# 사용 예시\n",
    "book_file = \"documents/The Collected Works of Spinoza.epub\"\n",
    "epub_to_markdown(book_file, \"The Collected Works of Spinoza.qmd\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# By DeepSeek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ebooklib import epub\n",
    "import ebooklib\n",
    "from bs4 import BeautifulSoup\n",
    "import html2text\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "def epub_to_markdown_ds(epub_path, output_file = None):\n",
    "    # EPUB 파일 읽기\n",
    "    book = epub.read_epub(epub_path)\n",
    "    \n",
    "    # HTML to Markdown 변환기 설정\n",
    "    h = html2text.HTML2Text()\n",
    "    h.ignore_links = False\n",
    "    h.body_width = 0  # 줄 바꿈 비활성화\n",
    "    \n",
    "    markdown_content = []\n",
    "    \n",
    "    # 스파인 순서대로 아이템 처리\n",
    "    items = {item.id: item for item in book.get_items()}\n",
    "    \n",
    "    for item_id, _ in book.spine:\n",
    "        item = items.get(item_id)\n",
    "        if item and item.get_type() == ebooklib.ITEM_DOCUMENT:\n",
    "            # HTML 내용 파싱\n",
    "            soup = BeautifulSoup(item.get_content(), 'html.parser')\n",
    "            \n",
    "            # 본문 내용 추출\n",
    "            body = soup.find('body')\n",
    "            if body:\n",
    "                # HTML을 Markdown으로 변환\n",
    "                text = h.handle(str(body))\n",
    "                markdown_content.append(text)\n",
    "    \n",
    "    # output_file 지정하지 않을 경우, epub_path의 이름을 사용하고 현재 날짜와 시간을 추가하여 저장\n",
    "    if not output_file:\n",
    "        base_name = os.path.basename(epub_path)\n",
    "        name, _ = os.path.splitext(base_name)\n",
    "        current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        output_file = f\"{name}_{current_time}.md\"\n",
    "\n",
    "    # Markdown 파일 저장\n",
    "    with open(output_file, 'w', encoding='utf-8') as md_file:\n",
    "        md_file.write('\\n\\n'.join(markdown_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markdown 파일 생성 완료\n"
     ]
    }
   ],
   "source": [
    "input_epub = \"Counterfactuals/Counterfactuals and Causal Inference.epub\"\n",
    "\n",
    "# output_md = \"output_by_deepseek.md\"\n",
    "epub_to_markdown_ds(input_epub)\n",
    "print(f\"Markdown 파일 생성 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/skcho/miniconda3/envs/translation/lib/python3.11/site-packages/ebooklib/epub.py:1395: UserWarning: In the future version we will turn default option ignore_ncx to True.\n",
      "  warnings.warn('In the future version we will turn default option ignore_ncx to True.')\n",
      "/Users/skcho/miniconda3/envs/translation/lib/python3.11/site-packages/ebooklib/epub.py:1423: FutureWarning: This search incorrectly ignores the root element, and will be fixed in a future version.  If you rely on the current behaviour, change it to './/xmlns:rootfile[@media-type]'\n",
      "  for root_file in tree.findall('//xmlns:rootfile[@media-type]', namespaces={'xmlns': NAMESPACES['CONTAINERNS']}):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markdown 파일 생성 완료: output_by_deepseek2.md\n"
     ]
    }
   ],
   "source": [
    "input_epub = \"The Compassionate Mind/Paul_Gilbert_The_Compassionate_Mind.epub\"\n",
    "output_md = \"output_by_deepseek2.md\"\n",
    "epub_to_markdown_ds(input_epub, output_md)\n",
    "print(f\"Markdown 파일 생성 완료: {output_md}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# By Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ebooklib import epub\n",
    "import html2text\n",
    "import os\n",
    "\n",
    "def extract_epub_to_markdown(epub_path, output_dir):\n",
    "    \"\"\"\n",
    "    EPUB 파일을 구조를 유지하며 Markdown으로 변환하는 함수\n",
    "    \"\"\"\n",
    "    # EPUB 파일 로드\n",
    "    book = epub.read_epub(epub_path)\n",
    "    \n",
    "    # Markdown 변환기 설정\n",
    "    h = html2text.HTML2Text()\n",
    "    h.body_width = 0  # 줄바꿈 비활성화\n",
    "    h.emphasis_mark = '*'\n",
    "    h.strong_mark = '**'\n",
    "    h.ignore_images = False\n",
    "    h.ignore_links = False\n",
    "    h.ignore_tables = False\n",
    "    \n",
    "    # 출력 디렉토리 생성\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 메타데이터 추출 및 저장\n",
    "    metadata_md = \"# 도서 정보\\n\\n\"\n",
    "    \n",
    "    # 제목 처리\n",
    "    titles = book.get_metadata('DC', 'title')\n",
    "    if titles:\n",
    "        metadata_md += f\"- **제목**: {titles[0][0]}\\n\"\n",
    "    \n",
    "    # 작성자 처리\n",
    "    creators = book.get_metadata('DC', 'creator')\n",
    "    if creators:\n",
    "        metadata_md += f\"- **작성자**: {creators[0][0]}\\n\"\n",
    "    \n",
    "    # 언어 처리\n",
    "    languages = book.get_metadata('DC', 'language')\n",
    "    if languages:\n",
    "        metadata_md += f\"- **언어**: {languages[0][0]}\\n\"\n",
    "    \n",
    "    # 식별자 처리\n",
    "    identifiers = book.get_metadata('DC', 'identifier')\n",
    "    if identifiers:\n",
    "        metadata_md += f\"- **식별자**: {identifiers[0][0]}\\n\"\n",
    "    \n",
    "    # 출판사 처리\n",
    "    publishers = book.get_metadata('DC', 'publisher')\n",
    "    if publishers:\n",
    "        metadata_md += f\"- **출판사**: {publishers[0][0]}\\n\"\n",
    "    \n",
    "    with open(os.path.join(output_dir, \"000_metadata.md\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(metadata_md)\n",
    "    \n",
    "    # 목차 정보 추출\n",
    "    toc = book.toc\n",
    "    def process_toc(toc_items, level=1):\n",
    "        toc_md = \"\"\n",
    "        for item in toc_items:\n",
    "            if isinstance(item, tuple):\n",
    "                # 섹션 제목과 링크\n",
    "                section, href = item\n",
    "                toc_md += f\"{'  ' * (level-1)}- [{section}]({href})\\n\"\n",
    "            elif isinstance(item, list):\n",
    "                # 하위 목차 처리\n",
    "                toc_md += process_toc(item, level+1)\n",
    "        return toc_md\n",
    "    \n",
    "    toc_md = \"# 목차\\n\\n\" + process_toc(toc)\n",
    "    with open(os.path.join(output_dir, \"001_toc.md\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(toc_md)\n",
    "    \n",
    "    # 컨텐츠 추출 및 변환\n",
    "    for i, item in enumerate(book.get_items(), 2):\n",
    "        # 문서 타입 확인 방법 변경\n",
    "        if isinstance(item, epub.EpubHtml):  # XHTML 문서인지 확인\n",
    "            # 파일명 생성\n",
    "            filename = f\"{i:03d}_{item.get_name().replace('.html', '.md')}\"\n",
    "            \n",
    "            # HTML 컨텐츠를 Markdown으로 변환\n",
    "            html_content = item.get_content().decode('utf-8')\n",
    "            md_content = h.handle(html_content)\n",
    "            \n",
    "            # Markdown 파일 저장\n",
    "            with open(os.path.join(output_dir, filename), \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(md_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변환이 완료되었습니다. 결과물이 book_markdown 디렉토리에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 사용 예시\n",
    "epub_file = \"Counterfactuals/Counterfactuals and Causal Inference.epub\"\n",
    "output_directory = \"book_markdown\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # epub_file = \"book.epub\"\n",
    "    # output_directory = \"book_markdown\"\n",
    "    \n",
    "    try:\n",
    "        extract_epub_to_markdown(epub_file, output_directory)\n",
    "        print(f\"변환이 완료되었습니다. 결과물이 {output_directory} 디렉토리에 저장되었습니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"오류가 발생했습니다: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "translation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
