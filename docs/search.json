[
  {
    "objectID": "extracted/nun_study.html",
    "href": "extracted/nun_study.html",
    "title": "Positive Emotions in Early Life and Longevity - Findings from the Nun Study",
    "section": "",
    "text": "Deborah D. Danner, David A. Snowdon, Wallace V. Friesen\nDeborah D. Danner and David A. Snowdon, Department of Preventive Medicine and Sanders-Brown Center on Aging, College of Medicine, University of Kentucky; Wallace V. Friesen, Sanders-Brown Center on Aging, College of Medicine, University of Kentucky.\nDavid A. Snowdon is now at the Department of Neurology and the Sanders-Brown Center on Aging, College of Medicine, University of Kentucky.\nThe study was funded by National Institute on Aging Grants R01AG09862, K04AG00553, and 5P50AG05144, and by a grant from the Kleberg Foundation.\nThis study would not have been possible without the spirited support of the members, leaders, and health care providers of the School Sisters of Notre Dame religious congregation. Archivists at each of the main con- vents were instrumental in the study. We also wish to recognize the help of Lydia Greiner in the conception of the study and Mark Desrosiers for his valuable scientific and programming assistance. Other staff members of the Nun Study who provided invaluable assistance on this project include Danice Creager, Gari-Anne Patzwald, Jeanne Ray, and Mary Roycraft.\nMore information on the Nun Study may be obtained at http://www.\nnunstudy.org.\nCorrespondence concerning this article should be addressed to Deborah D. Danner, Sanders-Brown Center on Aging, University of Kentucky, 800 South Limestone, Lexington, Kentucky 40536-0230. Electronic mail may be sent to dddann00@uky.edu.\nJournal of Personality and Social Psyc Copyright 2001 by the American Psychological Association",
    "crumbs": [
      "Data Science",
      "Positive Emotions in Early Life and Longevity - Findings from the Nun Study"
    ]
  },
  {
    "objectID": "extracted/nun_study.html#abstract",
    "href": "extracted/nun_study.html#abstract",
    "title": "Positive Emotions in Early Life and Longevity - Findings from the Nun Study",
    "section": "Abstract",
    "text": "Abstract\nHandwritten autobiographies from 180 Catholic nuns, composed when participants were a mean age of 22 years, were scored for emotional content and related to survival during ages 75 to 95. A strong inverse association was found between positive emotional content in these writings and risk of mortality in late life (p &lt; .001). As the quartile ranking of positive emotion in early life increased, there was a stepwise decrease in risk of mortality resulting in a 2.5-fold difference between the lowest and highest quartiles. Positive emotional content in early-life autobiographies was strongly associated with longev- ity 6 decades later. Underlying mechanisms of balanced emotional states are discussed.\nLongevity may be related to a variety of factors including heredity, gender, socioeconomic status, nutrition, social support, medical care, and personality and behavioral characteristics (Rob- ine, Vaupel, Jeune, & Allard, 1997). These factors might operate throughout life or at particular life stages. Recent findings from the Nun Study, a longitudinal study of older Catholic sisters, indicated that linguistic ability in early life is associated with survival in late life (Snowdon, Greiner, Kemper, Nanayakkara, & Mortimer, 1999). In that study, the idea density (proposition, information, and content) of autobiographies written at a mean age of 22 years was strongly related to survival and longevity 6 decades later. Because the autobiographies appeared to contain emotional content that might be associated with idea density (Snowdon et al., 1996), we investigated the relationship between emotional content in these early life writings and survival in late life.\nA growing body of literature has shown positive and negative emotion-related attitudes and states to be associated with physical health, mental health, and longevity. For example, in a longitudinal study of Harvard graduates, Peterson (Peterson, Seligman, & Vail- lant, 1988) found the ways in which young men explained bad events predicted health outcome decades later. Such studies appear to be based on assumptions that emotion-based constructs reflect patterns of coping with negative life events and stresses that can be harmful or beneficial to health. The assumptions of the current longitudinal investigation of emotions and longevity are very similar and evolved from what is known about the underlying relationships among emotion, temperament, and physiology that might influence longevity. This study builds on the knowledge that there are universal, patterned emotional responses that affect phys- iology in ways that are potentially damaging or beneficial.\nOver the past 30 years, emotion researchers have identified basic emotions such as happiness, sadness, anger, fear, and disgust (Ekman & Friesen, 1969). More recently, these basic emotions have been associated with differentially patterned autonomic nervous system (ANS) responses (Ekman, Levenson, & Friesen, 1983; Levenson, Carstensen, Friesen, & Ekman, 1991; Levenson, Ekman, & Friesen, 1990; Levenson, Ekman, Heider, & Friesen, 1992). The functional characteristics of the associated patterns of emotion and ANS activation (Levenson, in press) strongly suggest the potential for a lifelong pattern of emotional arousal affecting health and longevity. Furthermore, numerous studies have shown that complex emotional states, such as anxiety, produce elements of ANS patterns associated with specific negative emotions (Laza- rus, 1991). These same elements of elevated galvanic skin re- sponse, heart rate, and blood pressure are found in the patterned ology, 2001, Vol. 80, No. 5, 804-813 c. 0022-35I4/01/$5.00 DO): 10.1037//0022-3514.80.5.804 ANS responses to the arousal of basic emotions and potentially could affect health and longevity.\nLaboratory research also has found that the suppression of emotional states can exacerbate ANS responses (Gross & Leven- son, 1997). A lifelong pattern of suppressing the expression of emotion has the potential for adverse effects on essential body systems. Although no ANS pattern has been found to be associated with positive emotion that differentiates it from baseline (Leven- son et al., 1990), studies have demonstrated the potential muting effects of positive emotion on the bodily responses to negative emotion (Fredrickson & Levenson, 1998). This healing effect of positive emotion may have the potential to reduce stress on the cardiovascular system even in the face of inevitable negative life events. In other words, constructs such as optimism and positive attitude may imply the following sequence: Events arousing neg- ative affect are approached with confidence that the future holds something positive and better, thus internally generating a positive emotional state that mutes the adverse effects of the prolonged arousal of a negative emotion.\nThe basic research of Fredrickson, Gross, and Levenson cited above has laid the groundwork for the study of how sustained and repetitious patterns of emotional arousal might relate to physical health and survival and, more specifically, how the emotion sys- tem is intimately tied to the ANS, which activates cardiovascular responses that could have cumulative adverse or salutary effects on health (Krantz & Manuck, 1984). What is needed is an explanation for why a particular pattern of emotional and ANS responses would be repeated with sufficient frequency to produce such cumulative effects. As part of this explanation, it is necessary to examine the relationship among patterns of emotional responsive- ness, temperament, and the development of personality.\nTemperament, the biologically based propensity for individuals to respond to events in particular ways, is considered by some theorists to contribute to the development of personality (Izard, Libero, Putnam, & Haynes, 1993; Malatesta & Wilson, 1988).\nMoreover, temperament is proposed to reflect the degree to which emotions are generally expressed, as well as the differing frequen- cies with which specific emotions or patterns of emotions are displayed or suppressed (Izard et al., 1993). Early and continuing styles of emotional expression are proposed to constitute some characteristics of personality (Izard et al., 1993; Malatesta & Wilson, 1988). Supporting this line of reasoning, work by Headey (Headey & Wearing, 1992) suggests that individuals maintain levels of positive or negative affect that are determined by their personalities and that after emotional arousal or stress these levels return to individual baselines (Diener, 2000). When an individual’s response pattern is frequent or sustained negative emotional arousal with slow return to a tranquil baseline, the autonomic response could prompt cardiovascular activity that accelerates disease mechanisms such as atherosclerosis. In contrast, a pattern of relatively infrequent negative emotional arousal or one that rapidly returns to a calm baseline following negative arousal could have beneficial effects on health.\nSuch a balance of emotional states, either by avoiding suppres- sion of the expression of aroused emotion or by readily resolving negative arousal, is compatible with Vaillant’s proposal that ma- ture defenses work to promote a positive psychology that enhances the ability to work, love, and play (Vaillant, 2000). Vaillant provided evidence that earlier life manifestations of mature ego defenses that balance and attenuate multiple sources of conflict predict enhanced physical and mental health 20 years later and suggests that mature ego defenses may reflect inborn traits. If so, Vaillant’s proposition may offer yet another pathway for how potentially beneficial or harmful patterns of emotional responses may be expressed and balanced and may be mediated through patterns of problem solving throughout a lifetime, thereby influ- encing longevity.\nA pattern of emotional arousal and temperament may be dis- closed, in part, by the written expression of language. Research by Pennebaker and his colleagues has used written language as a means of understanding how emotion influences both physical and psychological health (Hughes, Uhlmann, & Pennebaker, 1994; Pennebaker, 1993; Pennebaker & King, 1999). The early-life au- tobiographies in our study afford another opportunity to examine emotional content in written language and its relationship to health. If the use of emotional content in these writings reflects reactions to inevitable stressful life events, then these writings may reveal characteristic responses to intense or sustained arousal that produces allostatic load—indicators of physiological response to stress (McEwen, 1998; Singer & Ryff, 1999; Sterling & Eyer, 1988). Furthermore, if the use of positive and negative emotional content in writing reflects a general readiness to express emotion, then these writings may indicate a pattern that avoids the adverse effects of suppressing the expression of emotions. On the other hand, if the use of positive emotional content in writing reflects a readiness to resolve negative arousal, then writings may be reveal- ing a pattern of balance in emotional response indicating allostasis, adaption to change while maintaining physiological systems within a normal range (Singer & Ryff, 1999; Sterling & Eyer, 1988; McEwen, 1998). Both the avoidance of suppression and the positive resolution of life’s stresses could have beneficial effects on health and longevity.\nSeligman emphasizes that an insightful, positive attitude in dealing with life events, an optimistic explanatory style in contrast to a pessimistic one, can lead to greater feelings of well-being and perhaps even to longer life (Seligman, 2000). In support, a recent study found optimism, as measured by a new optimism-pessimism scale of the Minnesota Multiphasic Personality Inventory (Swen- son, Pearson, & Osborne, 1973), was associated with a lower risk of death in 839 Mayo Clinic patients observed over a 30-year period (Maruta, Colligan, Malinchoc, & Offord, 2000). However, in another long-term study of more than a thousand bright Cali- fornia school children, cheerfulness (i.e., parental judgments of optimism and a sense of humor) had an inverse relationship with longevity during middle and old age (Friedman, 1999). In the latter study, the cheerful participants also were found to be more likely to engage in activities known to be risk factors for mortality. On the other hand, in another analysis of the California data, Peterson and colleagues used the Content Analysis of Verbatim Explana- tions technique (Peterson, Seligman, Yurko, Martin, & Friedman, 1) to code questionnaires completed by the participants in early adulthood and found evidence of a negative relationship between pessimism and longevity.\nThe early-life autobiographies and mortality data available for participants in the Nun Study offer a unique opportunity to inves- tigate the possible association of written emotional expression to longevity. Participants in our study had the same reproductive and marital histories, had similar social activities and support, did not smoke or drink excessive amounts of alcohol, had similar occu- pations and socioeconomic status, and had comparable access to medical care. Therefore, even though it may be difficult to gener- alize from this unique population of Catholic sisters, many factors that confound most studies of longevity have been minimized or eliminated.",
    "crumbs": [
      "Data Science",
      "Positive Emotions in Early Life and Longevity - Findings from the Nun Study"
    ]
  },
  {
    "objectID": "extracted/nun_study.html#method",
    "href": "extracted/nun_study.html#method",
    "title": "Positive Emotions in Early Life and Longevity - Findings from the Nun Study",
    "section": "Method",
    "text": "Method\n\nStudy Population\nThe Nun Study is a longitudinal study of aging and Alzheimer’s disease (Snowdon, 1997; Snowdon et al., 1996, 1999). Participants were members of the School Sisters of Notre Dame religious congregation who, before their retirement, lived and taught in the schools of cities and towns in the midwestern, eastern, and southern United States. In 1991 through 1993, all American School Sisters of Notre Dame born before 1917 were asked to join the Nun Study. Six hundred seventy-eight women agreed to participate in all phases of the study and gave informed written consent to allow access to their archived and active records, participate in annual assessments of cognitive and physical function, and donate their brains at death. At the first annual exam, the 678 participants were 75 to 102 years old (M = 83).\nA search of the convents’ archives revealed that the Mother Superior of the North American sisters, who resided in Milwaukee, Wisconsin, had sent a letter on September 22, 1930, requesting that each sister write an autobiography. A mix of handwritten and typed autobiographies for many of the 678 sisters in the study was found and these autobiographies became an invaluable research source. Criteria used to select autobiographies for intensive study were that the writers were born and raised in the United States and thus had the opportunity to master the English language and that the autobiographies were handwritten and therefore could be authenticated as unaltered by clerical staff.\nWe found that the number of available handwritten autobiographies was related to the convent in which the sister lived and the year she wrote her life story. A large number of autobiographies meeting criteria were found for participants from the Milwaukee, Wisconsin, and the Baltimore, Mary- land, convents who took their religious vows and formally joined the religious congregation during 1931 to 1943 (Snowdon et al., 1999). Of the 678 sisters in the Nun Study, 218 took their vows in these two convents during that time period and handwritten autobiographies were found for 180 (83%) of these participants; that is, 101 participants from the Milwau- kee, Wisconsin, convent and 79 from the Baltimore, Maryland, convent.\nThese 180 autobiographies were written some time between the ages of 18 and 32 (M = 22) depending on the age at which the sister joined the congregation. At the time of writing the autobiographies, 82% of the sisters had earned a high school diploma. By the beginning of the mortality follow-up period in 1991, 91% had earned at least a bachelors degree.\nDuring the mortality follow-up period of November 13, 1991, to Septem- ber 1, 2000, the participants ranged in age from 75 to 95 years and 76 I had died (Milwaukee sample = 43%, Baltimore sample = 42%).\n\n\nAutobiographies\nBeginning in 1930, each sister who took her final vows was asked to write a short sketch of [her] life. This account should not contain more than two to three hundred words and should be written on a single sheet of paper . . . include place of birth, parentage, interesting and edifying events of childhood, schools attended, influences that led to the convent, religious life, and outstanding events.\nClearly, the instructions were not intended to influence the manner in which these life events were described nor were they intended for the study of emotional content, coping styles, or patterns of reasoning. Rather, we suspect that the autobiographies may have been used in part by the convent leaders to gather information that might help to determine future educa- tional and occupational paths, as well as to provide information useful for creating obituaries.\nDespite uniformity in the events that were described, the manner in which the life facts were told in the autobiographies reflected individual style and ranged from simply stating that these life events happened and when they occurred to elaborations of the simple facts that included the emotions experienced by the writer or others involved in the life event. The following sentences, from the beginning and ending of two autobiogra- phies, demonstrate differences in emotional content: Sister 1 (low positive emotion): I was born on September 26, 1909, the eldest of seven children, five girls and two boys …. My candidate year was spent in the Motherhouse, teaching Chemistry and Second Year Latin at Notre Dame Institute. With God’s grace, I intend to do my best for our Order, for the spread of religion and for my personal sanctification.\nSister 2 (high positive emotion): God started my life off well by bestowing upon me a grace of inestimable value… . The past year which I have spent as a candidate studying at Notre Dame College has been a very happy one. Now I look forward with eager joy to receiving the Holy Habit of Our Lady and to a life of union with Love Divine.\n\n\nCoding the Autobiographies and Generating Scores\nThe coding system used in classifying the written autobiographies was designed specifically for this study (Danner, Friesen, & Snowdon, 2000).\nAll coding and review of the autobiographies were done without knowl- edge of the health or functional status of the study participants. Two coders identified all words in thel80 autobiographies that reflected an emotional experience and classified them as positive, negative, or neutral. Later, a third coder verified each coded word for accuracy and determined the specific type of emotional experience or state referenced by each word.\nCoders were instructed on the distinctions between descriptions of possible elicitors of emotion (e.g., death of a family member), the emotion that was experienced (e.g., sadness), subsequent behaviors (e.g., crying), and attempts to control the overt expression of the emotion. They were instructed not to code descriptions of possible elicitors, but to code only words that in context described the emotion that was experienced and behaviors subsequent to emotional arousal. Further, they were instructed not to code words such as good and bad that have positive or negative connotations or might imply an emotional reaction but do not directly describe an emotional experience.\nThe coders were provided with examples of words related to the expe- rience of the positive emotions of accomplishment, amusement, content- ment, gratitude, happiness, hope, interest, love, and relief; the negative emotions of anger, contempt, disgust, disinterest, fear, sadness, and shame; and the neutral emotion of surprise. The two coders, one with a background in psychology and the other with training in education, then independently read the autobiographies. They marked words that conveyed emotion as experienced by the writer or others and classified the valence of the emotional content as positive, negative, or neutral. When necessary for comprehension, the coders were instructed to identify and code phrases rather than single words.\nTwo procedures were used to generate scores for the primary analysis on the basis of the positive, negative, and neutral scoring. The first procedure simply used the raw count of positive, negative, and neutral emotion words for each autobiography. The second procedure used these coded emotion words to classify each sentence as containing one or more positive, negative, or neutral words or as containing no emotion words. The first two columns of Table 1 show the number of positive, negative, and neutral emotional words and sentences as determined by each individual coder.\nThe table shows that the two coders identified very similar numbers of positive, negative, and neutral emotional words.\nTable 1 Reliability of the Emotion Coding as Indicated b Scored by Two Coders for Autobiographies Writ by 180 Participants in the Nun Study Count Unit of analysis and emotion Coder A Coder B Words Positive 1,243 1,242 Negative 206 192 Neutral 16 17 Sentences Positive 1,006 1,017 Negative 196 179 Neutral 16 17 Note. For all correlations, p &lt; .0001.\na 95% confidence intervals appear in parentheses.\nIn the verification phase of the coding, the words scored by the two coders were extracted from the autobiographies and a nonredundant list of words was reviewed by a third person (Wallace V. Friesen) for accuracy.\nThis review was done without knowledge of whether one or both coders had scored the word or how frequently the word was scored. Words that did not meet the original criteria for an emotional experience were removed from the list. The 1,598 words retained in the final scoring constituted 1.8% of the total words in the autobiographies and 95% of the words scored by one or both coders. Of these emotional words, 84% were classified as positive, 14% as negative, and 1% as neutral. As described above for the single coders, the verified coding of emotion words was used to determine the number of sentences with one or more positive, negative, and neutral emotion words.\nAs a part of the verification process, each unique emotion word was classified as referring to a specific type of positive or negative emotions (only one emotion, surprise, was scored in the neutral category). Initially, the purpose of the categorization was to aid in the verification of the positive, negative, and neutral scoring of Coders A and B. If a word could not be categorized, its validity as an emotion word was questionable. We carefully reviewed this categorization of the emotion words and disagree- ments were discussed and arbitrated. The final list of subcategories and the number and percentage of sentences containing one or more words in each category is presented in Table 2.\n\n\nIntercoder Reliability\nTwo types of intercoder reliability were assessed: the overall agreement in selecting and classifying the valence of emotional words and the degree to which the coders’ scoring and the verified scoring of the autobiographies were correlated. Kappa coefficients were used to assess overall agreement between the two coders on the selection and classification of emotion words. The coefficient values were .83 and .84, .85, and .79 for all emotion, positive, negative, and neutral words respectively, indicating a satisfactory level of intercoder reliability both overall and for the individual types of emotion words. Additional analyses indicated that most differences be- tween the two coders were due to one coder identifying a word that the other failed to detect and that this occurred with similar frequencies for the two coders. Examination of these disagreements indicated that the coder who failed to code apparently simply did not see the word because the same word was identified and classified identically by the errant coder in different places in the autobiographies. In other words, had the errant coder the Number of Emotion Words and Sentences en in Early Life Correlation of counts Final coding andeach codera Coders A and Ba Coder A Coder B 96 (.95, .97) .99 (.98, .99) .98 (.98, .99) 89 (.85, .94) .97 (.94, .99) .94 (.91, .97) 78 (.64, .93) .97 (.90, 1.00) .82 (.69, .95) 97 (.96, .98) .99 (.98, .99) .99 (.98, .99) 90 (.85, .95) .97 (.96, .99) .94 (.91, .97) 78 (.64, .93) .97 (.90, 1.00) .82 (.69, .95) noticed the word when reading the autobiography, it almost certainly would have been scored in agreement with the accurate coder.\nIn addition to the kappa coefficients of agreement, each coder’s scoring and the verified scoring were used to generate positive, negative, and neutral counts for both words and sentences for each autobiography.\nCorrelations were used to test the comparability of the three sets of coding.\nThe resulting correlations are shown in the three columns on the right of Table I. It can be seen here that the correlations between Coders A and B and verified counts of the numbers of emotional words and sentences were very high, indicating that virtually identical results would have been obtained in subsequent survival analysis had either Coder A’s or Coder B’s scoring been used in place of the final verified scores.\n\n\nLinguistic Measures\nRecent findings from studies of the same 180 autobiographies indicated that linguistic ability in early life was associated with survival in late life (Snowdon et al., 1999). In that study, the idea density (proposition, infor- mation, and content) of these autobiographies was associated with survival and longevity 6 decades later. Idea density of the early-life autobiographies also had a strong inverse association with Alzheimer’s disease (Snowdon et al., 1996; Snowdon, Greiner, & Markesbery, 2000). Because idea-dense sentences of the autobiographies were observed to contain emotional words (Snowdon et al., 1996), idea density and grammatical complexity were used as control variables in one of the analyses in the current study. The following is a brief description of how idea density and grammatical complexity were measured.\nWithout the linguistic coders’ knowledge of the age or cognitive func- tion of each sister during late life, each autobiography was scored for two indicators of linguistic ability: idea density (Kintsch & Keenan, 1973; Turner & Greene, 1977) and grammatical complexity (Cheung & Kemper, 1992). Mean idea-density and grammatical-complexity scores were com- puted from the last ten sentences of each autobiography. Idea density was defined as the average number of ideas expressed per ten words. Ideas corresponded to elementary propositions, typically a verb, adjective, ad- verb, or prepositional phrase. Complex propositions that stated or inferred causal, temporal, or other relationships between ideas also were counted.\nGrammatical complexity was computed using the Developmental Level metric originally developed by Rosenberg and Abbeduto (Rosenberg & Abbeduto, 1987) and modified by Cheung and Kemper (1992). The De- velopmental Level metric classifies sentences according to eight levels of Table 2 Distribution of the Different Types of Emotion Sentences in the Autobiographies Written in Early Life by 180 Participants in the Nun Study No. (and %) of sentences Milwaukee Baltimore Both Type of emotion convent convent convents Positive Happiness 109(6.10) 341 (12.51) 450 (9.97) Interest 160(8.95) 281 (10.31) 441 (9.77) Love 36(2.01) 131 (4.81) 167(3.70) Hope 21 (1.17) 30(1.10) 51(1.13) Gratefulness 6 (0.34) 41 (1.50) 47(1.04) Contentment 19(1.06) 21 (0.77) 40 (0.89) Unspecified 11(0.62) 14(0.51) 25 (0.55) Accomplishment 7 (0.39) 15(0.55) 22 (0.49) Relief 2(0.11) 4(0.15) 6(0.13) Amusement 0 (0.00) 1 (0.04) 1 (0.02) Negative Unspecified 19(1.06) 36(1.32) 55 (1.22) Sadness 8 (0.45) 46(1.69) 54(1.20) Afraid 4 (0.22) 18(0.66) 22 (0.49) Disinterest 7 (0.39) 13 (0.48) 20 (0.44) Confused 5 (0.28) 13 (0.48) 18(0.40) Anxiety 1 (0.06) 16(0.59) 17 (0.38) Suffering 8 (0.45) 9 (0.33) 17 (0.38) Shame 4 (0.22) 6 (0.22) 10 (0.22) Hopelessness 2(0.11) 2 (0.07) 4 (0.09) Frustration 1 (0.06) 1 (0.04) 2 (0.04) Disgust 1 (0.06) 1 (0.04) 2 (0.04) Anger 0 (0.00) 2 (0.07) 2 (0.04) Contempt 0 (0.00) 1 (0.04) 1 (0.02) Neutral Surprise 3(0.17) 14(0.51) 17 (0.38) Note. A small percentage of sentences contained more than one type of emotion word. Nonspecific positive and negative emotion words were classified as unspecified (e.g., words such as liked and filled with emotion).\nThese are words that definitely refer to an emotional experience but might refer to several different basic or complex emotional states.\ngrammatical complexity, ranging from 0 (simple one-clause sentences) to 7 (complex sentences with multiple forms of embedding and subordination).\n\n\nData Analysis\nThe dependent variables in the analyses were simple measures of all- cause mortality such as the percent who died by the end of an approxi- mately 9-year follow-up period and the mortality rate (i.e., deaths per person-years of observation) for that same period of time. The primary multivariate method used to investigate mortality was Cox proportional hazards regression (Allison, 1995). This regression yielded the relative risk of death, which refers to the ratio of mortality rates (or, more exactly, to the ratio of hazard functions). Age was adjusted in these analyses by using age as the time scale for the regression (Allison, 1995). Educational level at the time the autobiographies were written in early life was adjusted by includ- ing it as an ordinal variable in the regression. Age- and education-adjusted survival curves (the probability of a 75-year-old surviving to different advanced ages) were created using the baseline feature of the Cox regres- sion procedure in the SAS statistical program (Allison, 1995).\nIn the regression analyses, ordinal variables were used to characterize the percentile ranking of each type of emotional expression; that is, the number of positive emotional words. Binary variables were used in the regression to characterize the quartile rankings of each type of emotional expression. These percentile and quartile rankings of emotional-word us- age were derived using the distribution within each of the two convents.\nThis was done to obtain comparable scales of emotional expression across convents because the distribution of emotion-word usage differed between convents (see Table 2). The primary analyses used three measures of emotion word usage: (a) the percentile or quartile rankings derived from the number of sentences containing one or more positive or negative emotion words or no emotion words; (b) percentile and quartile ranks derived from the simple counts of positive emotion words; and (c) percen- tile and quartile ranks of a diversity score generated by counting the number of different positive emotion categories (see Table 2) scored in each autobiography.",
    "crumbs": [
      "Data Science",
      "Positive Emotions in Early Life and Longevity - Findings from the Nun Study"
    ]
  },
  {
    "objectID": "extracted/nun_study.html#results",
    "href": "extracted/nun_study.html#results",
    "title": "Positive Emotions in Early Life and Longevity - Findings from the Nun Study",
    "section": "Results",
    "text": "Results\nThe current study included 180 participants from the Milwau- kee, Wisconsin, and Baltimore, Maryland, convents of the School Sisters of Notre Dame. Handwritten autobiographies composed when the sisters were a mean age of 22 years were scored for positive, negative, and neutral emotional content. When these autobiographies were written in early life, 82% of the participants had earned a high school diploma. At the beginning of the Nun Study in 1991, approximately 58 years later, 91% of them had earned at least a bachelors degree. During the 9-year mortality surveillance period, the 180 participants ranged in age from 75 to 95 years and 76 (42%) of them had died (Milwaukee sample = 43%, Baltimore sample = 42%).\nCompared with the Baltimore participants, the Milwaukee par- ticipants had a lower mean number of positive emotion sentences (Milwaukee = 3.2, Baltimore = 9.7; p &lt; .001), negative emotion sentences (Milwaukee = 0.6, Baltimore = 2.0; p &lt; .001), and nonemotion sentences (Milwaukee = 14.1, Baltimore = 23.5;/? &lt; .001). (Given the very low frequency of neutral emotions, shown in Tables 1 and 2, their possible relationship to mortality was not examined.) Although the exact reasons for the differences between convents in written emotional expression is not known, the differ- ences in lengths of the autobiographies could simply reflect more time allowed for the Baltimore sisters to complete the task. Be- cause of differences in the distribution of these measures between convents, all analyses were based on percentile and quartile rank- ings within each convent.\nFour basic types of analyses were conducted and all were age and education adjusted. The first examined the relationship be- tween risk of mortality and the percentile ranking of the number of positive emotion sentences, negative emotion sentences, and non- emotion sentences in the autobiographies from early life. The second examined the relationships between the risk of mortality and the quartile ranking of the number of positive emotion sen- tences, positive emotion words, and different types of positive emotion words (i.e., categories). The third analysis examined the age-adjusted survival curves (length of life) as a function of the quartile rankings of positive-emotion sentences, positive-emotion words, and different categories of positive emotion words. A fourth analysis examined the relationships between positive emo- tion usage and survival after controlling for linguistic ability demonstrated in the early-life autobiographies, the level of educa- tion attained at the time the autobiographies were written, and the lifetime occupation of the participants.\nThe first Cox regression model we used to investigate mortality used the percentile ranking of positive emotion sentences, negative emotion sentences, or no emotion sentences and was adjusted for age and education. The results of these analyses are presented in Table 3 (Model I). Statistically significant inverse associations were found between the percentile ranking of the number of positive sentences in the early-life autobiographies and the risk of mortality in late-life within each of the convents and in both convents combined. For example, for every 1.0% increase in the number of positive-emotion sentences there was a 1.4% decrease in the mortality rate (i.e., the hazard function from the Cox regression model). In contrast, there were no statistically signifi- cant associations between the risk of mortality and the percentile rankings of the number of negative emotion sentences or the number of nonemotion sentences.\nIn another regression model that included age, education, and the percentile rankings of all three types of sentences (Model II; see Table 3), the strength of the associations with mortality were statistically unchanged from those above (Model I). Overall, the findings from these regressions suggest that positive and negative content reflected different aspects of written emotional expression.\nBecause of these findings, the remaining analyses focused on positive emotions.\nWe further explored the association between positive emotion content and survival using quartile rankings of positive emotion sentences. Both the percent who had died and the mortality rate had inverse associations with the quartile rankings of the number of positive-emotion sentences (see Table 4). Findings from age- and education-adjusted Cox regression analyses also indicated that the relative risk of death increased in a stepwise fashion as the quartile ranking of positive emotion sentences decreased, with a 2.5-fold difference in mortality between the lowest and highest quartiles of positive emotional expression. Two other methods of characterizing positive-emotion content, the number of positive- emotion words and the number of different positive emotions, also had strong inverse associations with mortality (see Table 4).\nCox regression also was used to create age- and education- adjusted survival curves, that is, probabilities of a 75-year-old surviving to different advanced ages. Figure 1 shows a strong association between the quartile rankings of the number of positive emotion sentences and survival: The median age at death was 86.6 years for those in the lowest quartile for the number of positive emotion sentences, 86.8 for the second quartile, 90.0 for the third Table 3 Percent Change in the All-Cause Mortality Rate in the Ranking of the Number of Sentences Mode Sentence type Milwaukee convent Baltimore c Positive emotion -1.4 (-2.5,-0.2)* -1.4 (-2.7,- Negative emotion -0.7 (-1.9, 0.6) -0.7 (-1.9, Noemotion 0.5 (-0.6, 1.6) -0.6 (-1.9, Note. 95% confidence intervals appear in parenthese Cox regression. Both Models I and II were adjusted for level of education achieved at the time in early life ordinal variable in both Model I and II regressions.\nincluded only one sentence-type variable, as well as a that is, it included each of the three sentence-type vari p£.05. p&lt;.01. /?&lt;. 001.\nquartile, and 93.5 for those in the highest quartile, that is, a difference of 6.9 years between the highest and lowest quartiles of positive emotion sentences. Survival curves for the other two measures of positive emotion content (not shown) indicated even stronger associations with survival; in other words, the difference in the median age at death between the highest and lowest quartiles was 9.4 years for the number of positive emotion words and 10.7 years for the number of different positive emotions.\nOther analyses indicated that there were no material changes in the association between positive emotion content and survival after controlling for measures of linguistic ability as demonstrated in the autobiographies; that is, the 2.5-fold difference in risk of mortality between the lowest and highest positive emotion sentence quartiles in Table 4 was a 2.2-fold difference in risk when adjusted for idea density. Furthermore, the relationship between positive-emotion content and survival was still apparent after limiting the analyses to 162 college-educated, lifetime teachers.",
    "crumbs": [
      "Data Science",
      "Positive Emotions in Early Life and Longevity - Findings from the Nun Study"
    ]
  },
  {
    "objectID": "extracted/nun_study.html#discussion",
    "href": "extracted/nun_study.html#discussion",
    "title": "Positive Emotions in Early Life and Longevity - Findings from the Nun Study",
    "section": "Discussion",
    "text": "Discussion\nThis study found a very strong association between positive emotional content in autobiographies written in early adulthood and longevity 6 decades later. Such a finding is congruent with other studies by investigators that have found relationships be- tween longevity and emotion-related concepts. Features of the current study differ from other studies that have investigated relationships between emotion-relevant behaviors and longevity or mortality and may account for the strength of the relationship observed in the current study: the population sample and the technique used to measure emotion.\nOur findings are compatible with recent longitudinal studies that suggest that optimism is associated with longer life (Maruta et al., 2000; Peterson et al., 1998), but incompatible with another study indicating that cheerfulness measured in early life was not asso- ciated with longer survival (Friedman, 1999). In the latter study, the investigators reported that there were behaviors related to risk and substance abuse in late-life activities of the more cheerful participants that may account for their findings (Friedman, 1999).\nThese types of behaviors should be less of an issue in our study of Catholic sisters given the relative homogeneity of their adult lifestyles and environments.\nPer Single Percentile Change I Model II, both nvent Both convents convents 0.1)* -1.4 (-2.3,-0.6)*** -1.4 (-2.3,-0.5)** .6) -0.7 (-1.5, 0.2) -0.2 (-1.2, 0.8) .7) -0.1 (-0.9,0.7) 0.3 (-0.6, 1.2) . The mortality rate refers to the hazard function from age by using age as the time scale in the regression. The hen the autobiography was written was included as an hree regressions were used for Model I, that is, each e and education. One regression was used in Model II, bles, as well as age and education.\nTable 4 Positive Emotion Expression in Autobiographies Written in Early in Late Life for 180 Participants in the Nun Study No. of participants Categories and quartiles Age at follow-up Dead At-risk Positive emotion sentences I (low) 80.1 25 46 II 81.1 23 40 III 80.1 18 52 IV (high) 79.4 10 42 Positive emotion words I (low) 79.9 23 42 II 81.1 30 51 III 79.7 13 40 IV (high) 79.9 10 47 Different positive emotions I (low) 81.3 11 17 II 80.4 26 58 III 80.2 29 65 IV (high) 79.4 10 40 Note. CI = confidence interval. The relative risks were adjusted for age regression analyses, and the level of education achieved at the time in early in regressions). The quartiles are not equal size groups because of the distrib sentences, and different positive emotions refer to up to 10 different types ” In person-years. b Deaths per 100 person-years.\n*/7&lt;.05. **/&gt;&lt;.01.\nThere were, however, other important differences between the studies of Maruta et al. (2000), Peterson et al. (1988), and Fried- man (1999) and the current study in addition to the sample pop- ulations. Maruta used items from the first Minnesota Multiphasic Personality Inventory to develop a scale of optimism. Peterson measured globality of explanatory style (a tendency to ascribe a single cause across negative life events) in samples of writing.\nFriedman, studying the same population as Peterson, used parental reports of children’s degree of cheerfulness as a measure of pos- itive affect. Thus, there were notable differences in the sources of information and the constructs that were measured as predictor variables in previous research. The current study used a different source of data and an emotion-specific measurement technique.\nGiven the unique lifestyle and culture of our study population of Catholic sisters and the fact that the autobiographies were written 6 decades ago, we created a coding system appropriate for this sample of writings. It has face validity and good reliability. Based on knowledge of emotion research and theory, it was designed to identify positive and negative emotional content in writings and requires little or no inference to apply. However, such coding does not attempt to measure more complex reactions to life events such as long-term positive or negative attitudes, forward thinking, types of explanatory style, mature ego defenses, pessimism, or opti- mism. Further research is required to discover how the use of emotion words in written text is related to other constructs that have been found to be related to better health and longevity.\nAlthough the scoring tool used in this study was designed to measure both positive and negative emotion, the emotional content of the writings describing the early lives of the participants in our study was overwhelmingly positive. This finding does not differ substantially from what other research studies using similar mea- ife and the Risk of All-Cause Mortality Relative risk of mortality Survival” % died Mortality rateb (and 95% CI) 253.3 54 10 2.5(1.2,5.3)** 221.8 58 10 2.4(1.1,5.2)* 333.4 35 5 1.4(0.6,3.0) 296.9 24 3 1.0 233.0 55 10 3.2(1.5,6.8) 279.5 59 11 3.1 (1.5,6.4) 255.6 33 5 1.6(0.7,3.7) 337.3 21 3 1.0 91.0 65 12 4.3(1.7, 10.4)** 331.0 45 8 2.3(1.1,4.7) 388.0 45 7 2.2(1.1,4.6) 295.5 25 3 1.0 d education (i.e., age was adjusted by using it as the time scale in the Cox life when the autobiography was written was included as an ordinal variable tion of the variables. Positive emotion sentences refer to the number of such f positive emotions.\nsurement tools have found (Pennebaker & Francis, 1999). More- over, an examination of cross-cultural and developmental data for 13 cultures by Boucher and Osgood (1969) found a universal tendency to learn positive words earlier than negative words in the acquisition of language, to more readily retain positive words in tests of memory, and to use more positive than negative words when communicating.\nContextual factors also may have influenced the use of positive emotion words in this set of writings. For example, the Catholic sisters in our study may have been aware, or at least believed, that the content of the autobiographies would be used by their superiors to determine their careers in the religious congregation, and there- fore they may have been cautious about revealing memories of negative emotion. Even more likely to have influenced the tone of these autobiographies was that they were written during a period of time when the sisters would be expected to feel happy and positive about the future; namely, when they were about to leave the convent and begin working (mainly teaching) in the community.\nHaving completed years of study and preparation for entry into the religious order, the sisters wrote these autobiographies just prior to taking their final vows. A goal toward which they had worked was being realized. Yet, despite the forces that may have resulted in predominantly positive content that was relatively constant for all of the authors of the autobiographies, there were individual dif- ferences in the use of positive emotion words that predicted longevity.\nBecause there was relatively little negative emotional content in the autobiographies, it was not possible to address directly ques- tions related to the underlying mechanisms responsible for the current findings. Whether a generalized suppression of emotional expressiveness presented a risk factor for longevity (Gross & 1.0 0.9 0.8 m 0.7 iivrjytilibbor 0.6 0) “5 0.5 0.4 n Quartile 1 0.3 Quartile 2 a.\nQuartile 3 0.2 Quartile 4 0.1 0.0 75 80 Figure 1. Quartile rankings of the number of positive and the probability of survival in late life for 180 parti for Quartiles 1 and 2 are virtually overlaid on each ot Levenson, 1997), or, conversely, whether those persons using more positive emotion words were in fact more expressive of all emotions and thereby reduced allostatic load by avoiding the detrimental effects of suppression could not be tested. Although negative life events were sometimes mentioned in the autobiogra- phies, the participants had not been instructed to include such events or to elaborate on their resolution. The absence of negative emotion words in relating negative incidents did not allow a direct test of whether positive emotion might have been a factor in muting the adverse effects of negative emotional arousal (Fredrickson & Levenson, 1998). Finally, the relative absence of negative emotional content limited the statistical power to detect associations with mortality. However, the analysis that we could perform indicated that in this context written negative emotional content is not the opposite of positive emotional content but, rather, is a reflection of something different. This finding that positive emotion may be a different phenomenon from negative emotion (depression) also was reported by Ostir and colleagues (Ostir, Markides, Black, & Goodwin, 2000).\nOur investigation raises questions about why the positive emo- tional content in early-life writings might have such a powerful relationship to longevity. Unfortunately we had no independent measures of temperament, personality, or emotional tendencies for participants, and we can only speculate that individual differences in emotional content in the autobiographies reflect life-long pat- terns of emotional response to life events.\nA pattern of emotional expression that accentuates positive affect undoubtedly has behavioral correlates that could enhance or disrupt the positive effects on physiology and health. One behav- ioral pathway is suggested by the study by Friedman (1999) in 85 90 95 ge motion sentences in autobiographies written in early life ipants in the Nun Study. (Note that the survival curves er.) which cheerful participants were more likely to engage in behav- iors that are health risks such as excessive drinking and smoking.\nSuch a pathway would be expected to disrupt the potential phys- iological benefits of a pervading pattern of positive emotional responsiveness. In contrast, all participants in the current study had lived a lifestyle in which such health-risk behaviors were improb- able and therefore the physiological impact of a positive emotional style was almost certainly enhanced. Because many alternative paths that might be the consequence of a positive style were not a part of this study, generalization of the current findings is limited.\nMany of the limitations of our study also could be considered strengths. As mentioned earlier, participants in our study were all female, had the same reproductive and marital histories, had sim- ilar social activities and support, did not smoke or drink excessive amounts of alcohol, had virtually the same occupation and socio- economic status, and had comparable access to medical care.\nFurthermore, the 180 participants had successfully completed a lifetime within their careers and living situations and many had lived beyond average life expectancy for their generation by the time they were enrolled in this study. Although it may be difficult to generalize from this unique population of Catholic sisters, the findings of the study should not be minimized. Despite factors in these sisters’ lives that are known to extend life and that might have overwhelmed any contribution of the mechanisms underlying our findings, the phenomenon represented by the use of positive emotion words in early-life writings effectively added to longevity.\nIt could be argued that the results of this study may not apply to a sample of participants less than 75 years of age. We are in the process of searching the convent archives for the autobiographies of sisters who died prior to the beginning of the study and in particular those who died before age 75. This information will allow us to examine the possibility that what was found in this study was the late stages of a relationship between the use of positive emotion words and longevity that was evident years earlier. Furthermore, increasing the sample size will increase the statistical power of future analyses and allow the investigation of relationships between survival and different types of positive emo- tional words, such as interest, love, and hope. Finally, our contin- ued follow-up of the population will allow us to determine whether this association continues beyond age 95.\nFinding such a strong association of written positive emotional expression to longevity indicates a need for research that sheds light on the underlying mechanisms and mediators responsible for and associated with this relationship. Within the context of the Nun Study, evidence that the expressive patterns observed in the early- life autobiographies were stable over time would help substantiate a relationship between emotional expression and temperament and personality. In future research, we will study late-life writings and spoken speech samples from the sisters for consistency of the expressive patterns found in early life.\nArchived records of medical history and career path will be examined for evidence of social and health-related patterns asso- ciated with what has been observed in the autobiographical writ- ings and that might suggest pathways taken by participants differ- ing in their use of positive emotional words that might have contributed to their longevity or mortality. Considering the poten- tial impact of positive expressiveness on relationships, we feel that research is needed to examine possible differences in social and professional behaviors that may have amplified the effects of a positive style on longevity.\nGiven that there have been annual examinations of cognitive and physical functioning, it will be possible to study relationships between the emotional content of the early-life writings and late- life capacities. Also, the results of neurological examinations will allow study of relationships with neurological functioning and related disease and disability. Finally, because there will be brain autopsies on all participants, it will be possible to study relation- ships between written emotional expressions and neuropathology and brain structure. These future studies hold promise for identi- fying underlying mechanisms and mediators that may account for the findings of the current study.\nReferences Allison, P. D. (1995). Survival analysis using the SAS system: A practical guide. Cary, NC: SAS Institute.\nBoucher, J., & Osgood, C. E. (1969). The Pollyanna Hypothesis. Journal of Verbal Learning and Verbal Behavior, 8, 1-8.\nCheung, H., & Kemper, S. (1992). Competing complexity metrics and adults’ production of complex sentences. Applied Psycholinguistics, 13, 53-76.\nDanner, D. D., Friesen, W. V., & Snowdon, D. A. (2000). Written emotion expression code. Unpublished manuscript, University of Kentucky, Lex- ington.\nDiener, E. (2000). Subjective well-being: The science of happiness and a proposal for a national index. American Psychologist, 55, 34-43.\nEkman, P., & Friesen, W. V. (1969). The repertoire of nonverbal behavior: Cite%OTO4, CK%,, \\4Age,, ra& eoAmg. Semiotica, ], 49-9%.\nEkman, P., Levenson, R. W., & Friesen, W. V. (1983). Autonomic nervous system activity distinguishes among emotions. Science, 221, 1208- 1210.\nFredrickson, B. L., & Levenson, R. W. (1998). Positive emotions speed recovery from the cardiovascular sequelae of negative emotions. Cog- nition and Emotion, 12, 191-220.\nFriedman, H. S. (1999). Personality and longevity: Paradoxes. In J. -M.\nRobine, B. Forette, C. Franceschi, & M. Allard (Eds.), The paradoxes of longevity (pp. 115-122). Berlin, Germany: Springer-Verlag.\nGross, J. J., & Levenson, R. W. (1997). Hiding feelings: The acute effects of inhibiting negative and positive emotion. Journal of Abnormal Psy- chology, 106, 95-103.\nHeadey, B., & Wearing, A. J. (1992). Understanding happiness: A theory of subjective well-being. Melbourne, Australia: Longman Cheshire.\nHughes, C. F., Uhlmann, C, & Pennebaker, J. W. (1994). The body’s response to processing emotional trauma: Linking verbal text with autonomic activity. Journal of Personality, 62, 565-585.\nIzard, C. E., Libero, D. Z., Putnam, P., & Haynes, O. M. (1993). Stability of emotion experiences and their relations to traits of personality. Jour- nal of Personality and Social Psychology, 64, 847- 860.\nKintsch, W., & Keenan, J. (1973). Reading rate and retention as a function of the number of propositions in the base structure of sentences. Cog- nitive Psychology, 5, 257-274.\nKrantz, D. S., & Manuck, S. B. (1984). Acute psychophysiologic reactivity and risk of cardiovascular disease: A review and methodologic critique.\nPsychological Bulletin, 96, 435-464.\nLazarus, R. S. (1991). Emotion and adaptation. New York: Oxford Uni- versity Press.\nLevenson, R. W. (in press). Autonomic specificity and emotion. In R. J.\nDavidson, K. Scherer, & H. H. Goldsmith (Eds.), Handbook of affective sciences. New York: Oxford University Press.\nLevenson, R. W., Carstensen, L. L., Friesen, W. V., & Ekman, P. (1991).\nEmotion, physiology, and expression in old age. Psychology and Aging, 6, 28-35.\nLevenson, R. W., Ekman, P., & Friesen, W. V. (1990). Voluntary facial action generates emotion-specific autonomic nervous system activity.\nPsychophysiology, 27, 363-384.\nLevenson, R. W., Ekman, P., Heider, K., & Friesen, W. V. (1992). Emotion and autonomic nervous system activity in the Minangkabau of West Sumatra. Journal of Personality and Social Psychology, 62, 972-988.\nMalatesta, C. Z., & Wilson, A. (1988). Emotion cognition interaction in personality development: A discrete emotions, functionalist analysis.\nBritish Journal of Social Psychology, 27, 91-112.\nMaruta, T., Colligan, R. C, Malinchoc, M., & Offord, K. P. (2000).\nOptimists vs pessimists: Survival rate among medical patients over a 30-year period. Mayo Clinic Proceedings, 75, 140-143.\nMcEwen, B. S. (1998). Stress, adaptation, and disease: Allostasis and allostatic load. Annals of the New York Academy of Sciences, 840, 33-44.\nOstir, G. V., Markides, K. S., Black, S. A., & Goodwin, J. S. (2000).\nEmotional well-being predicts subsequent functional independence and survival. Journal of the American Geriatrics Society, 48, 473-478.\nPennebaker, J. W. (1993). Putting stress into words: Health, linguistic and therapeutic implications. Behaviour Research and Therapy, 31, 539- 548.\nPennebaker, J. W., & Francis, M. E. (1999). Linguistic Inquiry and Word Count (LIWC). Mahwah, NJ: LEA Software and Alternative Media/ Erlbaum.\nPennebaker, J. W., & King, L. A. (1999). Linguistic styles: Language use as an individual difference. Journal of Personality and Social Psychol- ogy, 77, 1296-1312.\nPeterson, C, Seligman, M. E. P., & Vaillant, G. E. (1988). Pessimistic e*psty« a risk factor fox pYi^sVcaX fflness-. A ftnrty-fwe year longitudinal study. Journal of Personality and Social Psychology, 55, 23-27.\nPeterson, C, Seligman, M. E. P., Yurko, K. H., Martin, L. R., & Friedman, H. S. (1998). Catastrophizing and untimely death. Psychological Sci- ence, 9, 127-130.\nRobine, J. -M, Vaupel, J. W., Jeune, B., & Allard, M. (1997). Longevity: To the limits and beyond. Berlin, Germany: Springer-Verlag.\nRosenberg, S., & Abbeduto, L. (1987). Indicators of linguistic competence in the peer group conversational behavior of mildly retarded adults.\nApplied Psycholinguistics, 8, 19-32.\nSeligman, M. E. P. (2000). Optimism, pessimism, and mortality. Mayo Clinic Proceedings, 75, 133-134.\nSinger, B., & Ryff, C. D. (1999). Hierarchies of life histories and associ- ated health risks. Annals of the New York Academy of Sciences, 896, 96-115.\nSnowdon, D. A. (1997). Aging and Alzheimer’s disease: Lessons from the Nun Study. Gerontologist, 37, 150-156.\nSnowdon, D. A., Greiner, L. H., Kemper, S. J., Nanayakkara, N., & Mortimer, J. A. (1999). Linguistic ability in early life and longevity: Findings from the Nun Study. In J. -M. Robine, B. Forette, C. Franches- chi, & M. Allard (Eds.), The paradoxes of longevity (pp. 103-113).\nBerlin, Germany: Springer-Verlag.\nSnowdon, D. A., Greiner, L. H., & Markesbery, W. R. (2000). Linguistic ability in early life and the neuropathology of Alzheimer’s disease and ## Low Publication Prices for\nKeeping you up-to-date. All APA Fello\nreceive—as part of their annual dues—sub APA Monitor. High School Teacher and In the APA Monitor, and they may subscribe t reduced rate. In addition, all Members and to 60% (plus a journal credit) on all other A subscriptions from cooperating societies and Counseling and Development, Academic Pr Essential resources. APA members and APA books, including the Publication Manu and on dozens of new topical books each y Other benefits Of membership. Mem competitive insurance plans, continuing edu and specialty divisions.\nMore information. Write to American Psy 750 First Street, NE, Washington, DC 2000 cerebrovascular disease: Findings from the Nun Study. Annals of the New York Academy of Sciences, 903, 34-38.\nSnowdon, D. A., Kemper, S. J., Mortimer, J. A., Greiner, L. H., Wekstein, D. R., & Markesbery, W. R. (1996). Linguistic ability in early life and cognitive function and Alzheimer’s disease in late life: Findings from the Nun Study. Journal of the American Medical Association, 275, 528-532.\nSterling, P., & Eyer, J. (1988). Allostasis: A new paradigm to explain arousal pathology. In S. Fisher & J. Reason (Eds.), Handbook of life stress, cognition, and health (pp. 629-649). New York: Wiley.\nSwenson, W. M., Pearson, J. S., & Osborne, D. (1973). An MMPI source book: Basic item, scale, and pattern data on 50,000 medical patients.\nMinneapolis: University of Minnesota Press.\nTurner, A., & Greene, E. (1977). The construction and use of a proposi- tional text base. Boulder: Institute for the Study of Intellectual Behavior, University of Colorado.\nVaillant, G. E. (2000). Adaptive mental mechanisms: Their role in a positive psychology. American Psychologist, 55, 89-98.\nReceived October 6, 2000 Accepted October 30, 2000 • ## PA Members and Affiliates\ns, Members, Associates, and Student Affiliates\ncriptions to the American Psychologist and ernational Affiliates receive subscriptions to the American Psychologist at a significantly tudent Affiliates are eligible for savings of up A journals, as well as significant discounts on publishers (e.g., the American Association for ss, and Human Sciences Press).\nffiliates receive special rates for purchases of l of the American Psychological Association, ar.\nership in APA also provides eligibility for ation programs, reduced APA convention fees, hological Association, Membership Services, -4242.",
    "crumbs": [
      "Data Science",
      "Positive Emotions in Early Life and Longevity - Findings from the Nun Study"
    ]
  },
  {
    "objectID": "extracted/The Book of Why - Judea Pearl.html",
    "href": "extracted/The Book of Why - Judea Pearl.html",
    "title": "The book of why",
    "section": "",
    "text": "Copyright Copyright © 2018 by Judea Pearl and Dana Mackenzie Hachette Book Group supports the right to free expression and the value of copyright. The purpose of copyright is to encourage writers and artists to produce the creative works that enrich our culture.\nThe scanning, uploading, and distribution of this book without permission is a theft of the author’s intellectual property. If you would like permission to use material from the book (other than for review purposes), please contact permissions@hbgusa.com. Thank you for your support of the author’s rights.\nBasic Books Hachette Book Group 1290 Avenue of the Americas, New York, NY 10104 www.basicbooks.com First Edition: May 2018 Published by Basic Books, an imprint of Perseus Books, LLC, a subsidiary of Hachette Book Group, Inc. The Basic Books name and logo is a trademark of the Hachette Book Group.\nThe Hachette Speakers Bureau provides a wide range of authors for speaking events. To find out more, go to www.hachettespeakersbureau.com or call (866) 376-6591.\nThe publisher is not responsible for websites (or their content) that are not owned by the publisher.\nLibrary of Congress Cataloging-in-Publication Data Names: Pearl, Judea, author. | Mackenzie, Dana, author.\nTitle: The book of why : the new science of cause and effect / Judea Pearl and Dana Mackenzie.\nDescription: New York : Basic Books, [2018] | Includes bibliographical references and index.\nIdentifiers: LCCN 2017056458 (print) | LCCN 2018005510 (ebook) | ISBN 9780465097616 (ebook) | ISBN 9780465097609 (hardcover) | ISBN 046509760X (hardcover) | ISBN 0465097618 (ebook) Subjects: LCSH: Causation. | Inference.\nClassification: LCC Q175.32.C38 (ebook) | LCC Q175.32.C38 P43 2018 (print) | DDC 501—dc23 LC record available at https://lccn.loc.gov/2017056458 ISBNs: 978-0-465-09760-9 (hardcover); 978-0-465-09761-6 (ebook) E3-20180417-JV-PC ## CONTENTS\nCover\nTitle Page Copyright Dedication Preface INTRODUCTION Mind over Data CHAPTER 1 The Ladder of Causation CHAPTER 2 From Buccaneers to Guinea Pigs: The Genesis of Causal Inference CHAPTER 3 From Evidence to Causes: Reverend Bayes Meets Mr. Holmes CHAPTER 4 Confounding and Deconfounding: Or, Slaying the Lurking Variable CHAPTER 5 The Smoke-Filled Debate: Clearing the Air CHAPTER 6 Paradoxes Galore! CHAPTER 7 Beyond Adjustment: The Conquest of Mount Intervention CHAPTER 8 Counterfactuals: Mining Worlds That Could Have Been CHAPTER 9 Mediation: The Search for a Mechanism CHAPTER 10 Big Data, Artificial Intelligence, and the Big Questions Acknowledgments About the Authors Also by Judea Pearl Notes Bibliography Index To Ruth PREFACE A LMOST two decades ago, when I wrote the preface to my book Causality (2000), I made a rather daring remark that friends advised me to tone down.\n“Causality has undergone a major transformation,” I wrote, “from a concept shrouded in mystery into a mathematical object with well-defined semantics and well-founded logic. Paradoxes and controversies have been resolved, slippery concepts have been explicated, and practical problems relying on causal information that long were regarded as either metaphysical or unmanageable can now be solved using elementary mathematics. Put simply, causality has been mathematized.” Reading this passage today, I feel I was somewhat shortsighted. What I described as a “transformation” turned out to be a “revolution” that has changed the thinking in many of the sciences. Many now call it “the Causal Revolution,” and the excitement that it has generated in research circles is spilling over to education and applications. I believe the time is ripe to share it with a broader audience.\nThis book strives to fulfill a three-pronged mission: first, to lay before you in nonmathematical language the intellectual content of the Causal Revolution and how it is affecting our lives as well as our future; second, to share with you some of the heroic journeys, both successful and failed, that scientists have embarked on when confronted by critical cause-effect questions.\nFinally, returning the Causal Revolution to its womb in artificial intelligence, I aim to describe to you how robots can be constructed that learn to communicate in our mother tongue—the language of cause and effect. This new generation of robots should explain to us why things happened, why they responded the way they did, and why nature operates one way and not another. More ambitiously, they should also teach us about ourselves: why our mind clicks the way it does and what it means to think rationally about cause and effect, credit and regret, intent and responsibility.\nWhen I write equations, I have a very clear idea of who my readers are.\nNot so when I write for the general public—an entirely new adventure for me.\nStrange, but this new experience has been one of the most rewarding educational trips of my life. The need to shape ideas in your language, to guess your background, your questions, and your reactions, did more to sharpen my understanding of causality than all the equations I have written prior to writing this book.\nFor this I will forever be grateful to you. I hope you are as excited as I am to see the results.\nJudea Pearl Los Angeles, October 2017 INTRODUCTION: MIND OVER DATA Every science that has thriven has thriven upon its own symbols.\n—AUGUSTUS DE MORGAN (1864) T HIS book tells the story of a science that has changed the way we distinguish facts from fiction and yet has remained under the radar of the general public. The consequences of the new science are already impacting crucial facets of our lives and have the potential to affect more, from the development of new drugs to the control of economic policies, from education and robotics to gun control and global warming. Remarkably, despite the diversity and apparent incommensurability of these problem areas, the new science embraces them all under a unified framework that was practically nonexistent two decades ago.\nThe new science does not have a fancy name: I call it simply “causal inference,” as do many of my colleagues. Nor is it particularly high-tech. The ideal technology that causal inference strives to emulate resides within our own minds. Some tens of thousands of years ago, humans began to realize that certain things cause other things and that tinkering with the former can change the latter. No other species grasps this, certainly not to the extent that we do. From this discovery came organized societies, then towns and cities, and eventually the science- and technology-based civilization we enjoy today.\nAll because we asked a simple question: Why? Causal inference is all about taking this question seriously. It posits that the human brain is the most advanced tool ever devised for managing causes and effects. Our brains store an incredible amount of causal knowledge which, supplemented by data, we could harness to answer some of the most pressing questions of our time. More ambitiously, once we really understand the logic behind causal thinking, we could emulate it on modern computers and create an “artificial scientist.” This smart robot would discover yet unknown phenomena, find explanations to pending scientific dilemmas, design new experiments, and continually extract more causal knowledge from the environment.\nBut before we can venture to speculate on such futuristic developments, it is important to understand the achievements that causal inference has tallied thus far. We will explore the way that it has transformed the thinking of scientists in almost every data-informed discipline and how it is about to change our lives.\nThe new science addresses seemingly straightforward questions like these: • How effective is a given treatment in preventing a disease? • Did the new tax law cause our sales to go up, or was it our advertising campaign? • What is the health-care cost attributable to obesity? • Can hiring records prove an employer is guilty of a policy of sex discrimination? • I’m about to quit my job. Should I? These questions have in common a concern with cause-and-effect relationships, recognizable through words such as “preventing,” “cause,” “attributable to,” “policy,” and “should I.” Such words are common in everyday language, and our society constantly demands answers to such questions. Yet, until very recently, science gave us no means even to articulate, let alone answer, them.\nBy far the most important contribution of causal inference to mankind has been to turn this scientific neglect into a thing of the past. The new science has spawned a simple mathematical language to articulate causal relationships that we know as well as those we wish to find out about. The ability to express this information in mathematical form has unleashed a wealth of powerful and principled methods for combining our knowledge with data and answering causal questions like the five above.\nI have been lucky to be part of this scientific development for the past quarter century. I have watched its progress take shape in students’ cubicles and research laboratories, and I have heard its breakthroughs resonate in somber scientific conferences, far from the limelight of public attention. Now, as we enter the era of strong artificial intelligence (AI) and many tout the endless possibilities of Big Data and deep learning, I find it timely and exciting to present to the reader some of the most adventurous paths that the new science is taking, how it impacts data science, and the many ways in which it will change our lives in the twenty-first century.\nWhen you hear me describe these achievements as a “new science,” you may be skeptical. You may even ask, Why wasn’t this done a long time ago? Say when Virgil first proclaimed, “Lucky is he who has been able to understand the causes of things” (29 BC). Or when the founders of modern statistics, Francis Galton and Karl Pearson, first discovered that population data can shed light on scientific questions. There is a long tale behind their unfortunate failure to embrace causation at this juncture, which the historical sections of this book will relate. But the most serious impediment, in my opinion, has been the fundamental gap between the vocabulary in which we cast causal questions and the traditional vocabulary in which we communicate scientific theories.\nTo appreciate the depth of this gap, imagine the difficulties that a scientist would face in trying to express some obvious causal relationships—say, that the barometer reading B tracks the atmospheric pressure P. We can easily write down this relationship in an equation such as B = kP, where k is some constant of proportionality. The rules of algebra now permit us to rewrite this same equation in a wild variety of forms, for example, P = B/k, k = B/P, or B–kP = 0. They all mean the same thing—that if we know any two of the three quantities, the third is determined. None of the letters k, B, or P is in any mathematical way privileged over any of the others. How then can we express our strong conviction that it is the pressure that causes the barometer to change and not the other way around? And if we cannot express even this, how can we hope to express the many other causal convictions that do not have mathematical formulas, such as that the rooster’s crow does not cause the sun to rise? My college professors could not do it and never complained. I would be willing to bet that none of yours ever did either. We now understand why: never were they shown a mathematical language of causes; nor were they shown its benefits. It is in fact an indictment of science that it has neglected to develop such a language for so many generations. Everyone knows that flipping a switch will cause a light to turn on or off and that a hot, sultry summer afternoon will cause sales to go up at the local ice-cream parlor. Why then have scientists not captured such obvious facts in formulas, as they did with the basic laws of optics, mechanics, or geometry? Why have they allowed these facts to languish in bare intuition, deprived of mathematical tools that have enabled other branches of science to flourish and mature? Part of the answer is that scientific tools are developed to meet scientific needs. Precisely because we are so good at handling questions about switches, ice cream, and barometers, our need for special mathematical machinery to handle them was not obvious. But as scientific curiosity increased and we began posing causal questions in complex legal, business, medical, and policy-making situations, we found ourselves lacking the tools and principles that mature science should provide.\nBelated awakenings of this sort are not uncommon in science. For example, until about four hundred years ago, people were quite happy with their natural ability to manage the uncertainties in daily life, from crossing a street to risking a fistfight. Only after gamblers invented intricate games of chance, sometimes carefully designed to trick us into making bad choices, did mathematicians like Blaise Pascal (1654), Pierre de Fermat (1654), and Christiaan Huygens (1657) find it necessary to develop what we today call probability theory. Likewise, only when insurance organizations demanded accurate estimates of life annuity did mathematicians like Edmond Halley (1693) and Abraham de Moivre (1725) begin looking at mortality tables to calculate life expectancies. Similarly, astronomers’ demands for accurate predictions of celestial motion led Jacob Bernoulli, Pierre-Simon Laplace, and Carl Friedrich Gauss to develop a theory of errors to help us extract signals from noise. These methods were all predecessors of today’s statistics.\nIronically, the need for a theory of causation began to surface at the same time that statistics came into being. In fact, modern statistics hatched from the causal questions that Galton and Pearson asked about heredity and their ingenious attempts to answer them using cross-generational data.\nUnfortunately, they failed in this endeavor, and rather than pause to ask why, they declared those questions off limits and turned to developing a thriving, causality-free enterprise called statistics.\nThis was a critical moment in the history of science. The opportunity to equip causal questions with a language of their own came very close to being realized but was squandered. In the following years, these questions were declared unscientific and went underground. Despite heroic efforts by the geneticist Sewall Wright (1889–1988), causal vocabulary was virtually prohibited for more than half a century. And when you prohibit speech, you prohibit thought and stifle principles, methods, and tools.\nReaders do not have to be scientists to witness this prohibition. In Statistics 101, every student learns to chant, “Correlation is not causation.” With good reason! The rooster’s crow is highly correlated with the sunrise; yet it does not cause the sunrise.\nUnfortunately, statistics has fetishized this commonsense observation. It tells us that correlation is not causation, but it does not tell us what causation is. In vain will you search the index of a statistics textbook for an entry on “cause.” Students are not allowed to say that X is the cause of Y—only that X and Y are “related” or “associated.” Because of this prohibition, mathematical tools to manage causal questions were deemed unnecessary, and statistics focused exclusively on how to summarize data, not on how to interpret it. A shining exception was path analysis, invented by geneticist Sewall Wright in the 1920s and a direct ancestor of the methods we will entertain in this book. However, path analysis was badly underappreciated in statistics and its satellite communities and languished for decades in its embryonic status. What should have been the first step toward causal inference remained the only step until the 1980s. The rest of statistics, including the many disciplines that looked to it for guidance, remained in the Prohibition era, falsely believing that the answers to all scientific questions reside in the data, to be unveiled through clever data- mining tricks.\nMuch of this data-centric history still haunts us today. We live in an era that presumes Big Data to be the solution to all our problems. Courses in “data science” are proliferating in our universities, and jobs for “data scientists” are lucrative in the companies that participate in the “data economy.” But I hope with this book to convince you that data are profoundly dumb. Data can tell you that the people who took a medicine recovered faster than those who did not take it, but they can’t tell you why. Maybe those who took the medicine did so because they could afford it and would have recovered just as fast without it.\nOver and over again, in science and in business, we see situations where mere data aren’t enough. Most big-data enthusiasts, while somewhat aware of these limitations, continue the chase after data-centric intelligence, as if we were still in the Prohibition era.\nAs I mentioned earlier, things have changed dramatically in the past three decades. Nowadays, thanks to carefully crafted causal models, contemporary scientists can address problems that would have once been considered unsolvable or even beyond the pale of scientific inquiry. For example, only a hundred years ago, the question of whether cigarette smoking causes a health hazard would have been considered unscientific. The mere mention of the words “cause” or “effect” would create a storm of objections in any reputable statistical journal.\nEven two decades ago, asking a statistician a question like “Was it the aspirin that stopped my headache?” would have been like asking if he believed in voodoo. To quote an esteemed colleague of mine, it would be “more of a cocktail conversation topic than a scientific inquiry.” But today, epidemiologists, social scientists, computer scientists, and at least some enlightened economists and statisticians pose such questions routinely and answer them with mathematical precision. To me, this change is nothing short of a revolution. I dare to call it the Causal Revolution, a scientific shakeup that embraces rather than denies our innate cognitive gift of understanding cause and effect.\nThe Causal Revolution did not happen in a vacuum; it has a mathematical secret behind it which can be best described as a calculus of causation, which answers some of the hardest problems ever asked about cause-effect relationships. I am thrilled to unveil this calculus not only because the turbulent history of its development is intriguing but even more because I expect that its full potential will be developed one day beyond what I can imagine… perhaps even by a reader of this book.\nThe calculus of causation consists of two languages: causal diagrams, to express what we know, and a symbolic language, resembling algebra, to express what we want to know. The causal diagrams are simply dot-and- arrow pictures that summarize our existing scientific knowledge. The dots represent quantities of interest, called “variables,” and the arrows represent known or suspected causal relationships between those variables—namely, which variable “listens” to which others. These diagrams are extremely easy to draw, comprehend, and use, and the reader will find dozens of them in the pages of this book. If you can navigate using a map of one-way streets, then you can understand causal diagrams, and you can solve the type of questions posed at the beginning of this introduction.\nThough causal diagrams are my tool of choice in this book, as in the last thirty-five years of my research, they are not the only kind of causal model possible. Some scientists (e.g., econometricians) like to work with mathematical equations; others (e.g., hard-core statisticians) prefer a list of assumptions that ostensibly summarizes the structure of the diagram.\nRegardless of language, the model should depict, however qualitatively, the process that generates the data—in other words, the cause-effect forces that operate in the environment and shape the data generated.\nSide by side with this diagrammatic “language of knowledge,” we also have a symbolic “language of queries” to express the questions we want answers to. For example, if we are interested in the effect of a drug (D) on lifespan (L), then our query might be written symbolically as: P(L | do(D)). In other words, what is the probability (P) that a typical patient would survive L years if made to take the drug? This question describes what epidemiologists would call an intervention or a treatment and corresponds to what we measure in a clinical trial. In many cases we may also wish to compare P(L | do(D)) with P(L | do(not-D)); the latter describes patients denied treatment, also called the “control” patients. The do-operator signifies that we are dealing with an intervention rather than a passive observation; classical statistics has nothing remotely similar to this operator.\nWe must invoke an intervention operator do(D) to ensure that the observed change in Lifespan L is due to the drug itself and is not confounded with other factors that tend to shorten or lengthen life. If, instead of intervening, we let the patient himself decide whether to take the drug, those other factors might influence his decision, and lifespan differences between taking and not taking the drug would no longer be solely due to the drug. For example, suppose only those who were terminally ill took the drug. Such persons would surely differ from those who did not take the drug, and a comparison of the two groups would reflect differences in the severity of their disease rather than the effect of the drug. By contrast, forcing patients to take or refrain from taking the drug, regardless of preconditions, would wash away preexisting differences and provide a valid comparison.\nMathematically, we write the observed frequency of Lifespan L among patients who voluntarily take the drug as P(L | D), which is the standard conditional probability used in statistical textbooks. This expression stands for the probability (P) of Lifespan L conditional on seeing the patient take Drug D. Note that P(L | D) may be totally different from P(L | do(D)). This difference between seeing and doing is fundamental and explains why we do not regard the falling barometer to be a cause of the coming storm. Seeing the barometer fall increases the probability of the storm, while forcing it to fall does not affect this probability.\nThis confusion between seeing and doing has resulted in a fountain of paradoxes, some of which we will entertain in this book. A world devoid of P(L | do(D)) and governed solely by P(L | D) would be a strange one indeed.\nFor example, patients would avoid going to the doctor to reduce the probability of being seriously ill; cities would dismiss their firefighters to reduce the incidence of fires; doctors would recommend a drug to male and female patients but not to patients with undisclosed gender; and so on. It is hard to believe that less than three decades ago science did operate in such a world: the do-operator did not exist.\nOne of the crowning achievements of the Causal Revolution has been to explain how to predict the effects of an intervention without actually enacting it. It would never have been possible if we had not, first of all, defined the do- operator so that we can ask the right question and, second, devised a way to emulate it by noninvasive means.\nWhen the scientific question of interest involves retrospective thinking, we call on another type of expression unique to causal reasoning called a counterfactual. For example, suppose that Joe took Drug D and died a month later; our question of interest is whether the drug might have caused his death.\nTo answer this question, we need to imagine a scenario in which Joe was about to take the drug but changed his mind. Would he have lived? Again, classical statistics only summarizes data, so it does not provide even a language for asking that question. Causal inference provides a notation and, more importantly, offers a solution. As with predicting the effect of interventions (mentioned above), in many cases we can emulate human retrospective thinking with an algorithm that takes what we know about the observed world and produces an answer about the counterfactual world. This “algorithmization of counterfactuals” is another gem uncovered by the Causal Revolution.\nCounterfactual reasoning, which deals with what-ifs, might strike some readers as unscientific. Indeed, empirical observation can never confirm or refute the answers to such questions. Yet our minds make very reliable and reproducible judgments all the time about what might be or might have been.\nWe all understand, for instance, that had the rooster been silent this morning, the sun would have risen just as well. This consensus stems from the fact that counterfactuals are not products of whimsy but reflect the very structure of our world model. Two people who share the same causal model will also share all counterfactual judgments.\nCounterfactuals are the building blocks of moral behavior as well as scientific thought. The ability to reflect on one’s past actions and envision alternative scenarios is the basis of free will and social responsibility. The algorithmization of counterfactuals invites thinking machines to benefit from this ability and participate in this (until now) uniquely human way of thinking about the world.\nMy mention of thinking machines in the last paragraph is intentional. I came to this subject as a computer scientist working in the area of artificial intelligence, which entails two points of departure from most of my colleagues in the causal inference arena. First, in the world of AI, you do not really understand a topic until you can teach it to a mechanical robot. That is why you will find me emphasizing and reemphasizing notation, language, vocabulary, and grammar. For example, I obsess over whether we can express a certain claim in a given language and whether one claim follows from others. It is amazing how much one can learn from just following the grammar of scientific utterances. My emphasis on language also comes from a deep conviction that language shapes our thoughts. You cannot answer a question that you cannot ask, and you cannot ask a question that you have no words for. As a student of philosophy and computer science, my attraction to causal inference has largely been triggered by the excitement of seeing an orphaned scientific language making it from birth to maturity.\nMy background in machine learning has given me yet another incentive for studying causation. In the late 1980s, I realized that machines’ lack of understanding of causal relations was perhaps the biggest roadblock to giving them human-level intelligence. In the last chapter of this book, I will return to my roots, and together we will explore the implications of the Causal Revolution for artificial intelligence. I believe that strong AI is an achievable goal and one not to be feared precisely because causality is part of the solution. A causal reasoning module will give machines the ability to reflect on their mistakes, to pinpoint weaknesses in their software, to function as moral entities, and to converse naturally with humans about their own choices and intentions.\nA BLUEPRINT OF REALITY In our era, readers have no doubt heard terms like “knowledge,” “information,” “intelligence,” and “data,” and some may feel confused about the differences between them or how they interact. Now I am proposing to throw another term, “causal model,” into the mix, and the reader may justifiably wonder if this will only add to the confusion.\nIt will not! In fact, it will anchor the elusive notions of science, knowledge, and data in a concrete and meaningful setting, and will enable us to see how the three work together to produce answers to difficult scientific questions. Figure I.1 shows a blueprint for a “causal inference engine” that might handle causal reasoning for a future artificial intelligence. It’s important to realize that this is not only a blueprint for the future but also a guide to how causal models work in scientific applications today and how they interact with data.\nThe inference engine is a machine that accepts three different kinds of inputs—Assumptions, Queries, and Data—and produces three kinds of outputs. The first of the outputs is a Yes/No decision as to whether the given query can in theory be answered under the existing causal model, assuming perfect and unlimited data. If the answer is Yes, the inference engine next produces an Estimand. This is a mathematical formula that can be thought of as a recipe for generating the answer from any hypothetical data, whenever they are available. Finally, after the inference engine has received the Data input, it will use the recipe to produce an actual Estimate for the answer, along with statistical estimates of the amount of uncertainty in that estimate.\nThis uncertainty reflects the limited size of the data set as well as possible measurement errors or missing data.\nF I How an “inference engine” combines data with causal knowledge to IGURE .\nproduce answers to queries of interest. The dashed box is not part of the engine but is required for building it. Arrows could also be drawn from boxes 4 and 9 to box 1, but I have opted to keep the diagram simple.\nTo dig more deeply into the chart, I have labeled the boxes 1 through 9, which I will annotate in the context of the query “What is the effect of Drug D on Lifespan L?” 1. “Knowledge” stands for traces of experience the reasoning agent has had in the past, including past observations, past actions, education, and cultural mores, that are deemed relevant to the query of interest. The dotted box around “Knowledge” indicates that it remains implicit in the mind of the agent and is not explicated formally in the model.\nFor the purpose of constructing the diagram, the definition of “causation” is simple, if a little metaphorical: a variable X is a cause of Y if Y “listens” to X and determines its value in response to what it hears. For example, if we suspect that a patient’s Lifespan L “listens” to whether Drug D was taken, then we call D a cause of L and draw an arrow from D to L in a causal diagram. Naturally, the answer to our query about D and L is likely to depend on other variables as well, which must also be represented in the diagram along with their causes and effects. (Here, we will denote them collectively by Z.) 4. The listening pattern prescribed by the paths of the causal model usually results in observable patterns or dependencies in the data. These patterns are called “testable implications” because they can be used for testing the model. These are statements like “There is no path connecting D and L,” which translates to a statistical statement, “D and L are independent,” that is, finding D does not change the likelihood of L. If the data contradict this implication, then we need to revise our model.\nSuch revisions require another engine, which obtains its inputs from boxes 4 and 7 and computes the “degree of fitness,” that is, the degree to which the Data are compatible with the model’s assumptions. For simplicity, I did not show this second engine in Figure I.1.\nIt’s very important to realize that, contrary to traditional estimation in statistics, some queries may not be answerable under the current causal model, even after the collection of any amount of data. For example, if our model shows that both D and L depend on a third variable Z (say, the stage of a disease), and if we do not have any way to measure Z, then the query P(L | do(D)) cannot be answered. In that case it is a waste of time to collect data. Instead we need to go back and refine the model, either by adding new scientific knowledge that might allow us to estimate Z or by making simplifying assumptions (at the risk of being wrong)—for example, that the effect of Z on D is negligible.\nNotice that the whole notion of estimands and in fact the whole top part of Figure I does not exist in traditional methods of statistical analysis. There, the estimand and the query coincide. For example, if we are interested in the proportion of people among those with Lifespan L who took the Drug D, we simply write this query as P(D | L). The same quantity would be our estimand. This already specifies what proportions in the data need to be estimated and requires no causal knowledge.\nFor this reason, some statisticians to this day find it extremely hard to understand why some knowledge lies outside the province of statistics and why data alone cannot make up for lack of scientific knowledge.\nThis flowchart may look complicated at first, and you might wonder whether it is really necessary. Indeed, in our ordinary lives, we are somehow able to make causal judgments without consciously going through such a complicated process and certainly without resorting to the mathematics of probabilities and proportions. Our causal intuition alone is usually sufficient for handling the kind of uncertainty we find in household routines or even in our professional lives. But if we want to teach a dumb robot to think causally, or if we are pushing the frontiers of scientific knowledge, where we do not have intuition to guide us, then a carefully structured procedure like this is mandatory.\nI especially want to highlight the role of data in the above process. First, notice that we collect data only after we posit the causal model, after we state the scientific query we wish to answer, and after we derive the estimand. This contrasts with the traditional statistical approach, mentioned above, which does not even have a causal model.\nBut our present-day scientific world presents a new challenge to sound reasoning about causes and effects. While awareness of the need for a causal model has grown by leaps and bounds among the sciences, many researchers in artificial intelligence would like to skip the hard step of constructing or acquiring a causal model and rely solely on data for all cognitive tasks. The hope—and at present, it is usually a silent one—is that the data themselves will guide us to the right answers whenever causal questions come up.\nI am an outspoken skeptic of this trend because I know how profoundly dumb data are about causes and effects. For example, information about the effects of actions or interventions is simply not available in raw data, unless it is collected by controlled experimental manipulation. By contrast, if we are in possession of a causal model, we can often predict the result of an intervention from hands-off, intervention-free data.\nThe case for causal models becomes even more compelling when we seek to answer counterfactual queries such as “What would have happened had we acted differently?” We will discuss counterfactuals in great detail because they are the most challenging queries for any artificial intelligence. They are also at the core of the cognitive advances that made us human and the imaginative abilities that have made science possible. We will also explain why any query about the mechanism by which causes transmit their effects— the most prototypical “Why?” question—is actually a counterfactual question in disguise. Thus, if we ever want robots to answer “Why?” questions or even understand what they mean, we must equip them with a causal model and teach them how to answer counterfactual queries, as in Figure I.1.\nAnother advantage causal models have that data mining and deep learning lack is adaptability. Note that in Figure I.1, the estimand is computed on the basis of the causal model alone, prior to an examination of the specifics of the data. This makes the causal inference engine supremely adaptable, because the estimand computed is good for any data that are compatible with the qualitative model, regardless of the numerical relationships among the variables.\nTo see why this adaptability is important, compare this engine with a learning agent—in this instance a human, but in other cases perhaps a deep- learning algorithm or maybe a human using a deep-learning algorithm— trying to learn solely from the data. By observing the outcome L of many patients given Drug D, she is able to predict the probability that a patient with characteristics Z will survive L years. Now she is transferred to a different hospital, in a different part of town, where the population characteristics (diet, hygiene, work habits) are different. Even if these new characteristics merely modify the numerical relationships among the variables recorded, she will still have to retrain herself and learn a new prediction function all over again.\nThat’s all that a deep-learning program can do: fit a function to data. On the other hand, if she possessed a model of how the drug operated and its causal structure remained intact in the new location, then the estimand she obtained in training would remain valid. It could be applied to the new data to generate a new population-specific prediction function.\nMany scientific questions look different “through a causal lens,” and I have delighted in playing with this lens, which over the last twenty-five years has been increasingly empowered by new insights and new tools. I hope and believe that readers of this book will share in my delight. Therefore, I’d like to close this introduction with a preview of some of the coming attractions in this book.\nChapter 1 assembles the three steps of observation, intervention, and counterfactuals into the Ladder of Causation, the central metaphor of this book. It will also expose you to the basics of reasoning with causal diagrams, our main modeling tool, and set you well on your way to becoming a proficient causal reasoner—in fact, you will be far ahead of generations of data scientists who attempted to interpret data through a model-blind lens, oblivious to the distinctions that the Ladder of Causation illuminates.\nChapter 2 tells the bizarre story of how the discipline of statistics inflicted causal blindness on itself, with far-reaching effects for all sciences that depend on data. It also tells the story of one of the great heroes of this book, the geneticist Sewall Wright, who in the 1920s drew the first causal diagrams and for many years was one of the few scientists who dared to take causality seriously.\nChapter 3 relates the equally curious story of how I became a convert to causality through my work in AI and particularly on Bayesian networks.\nThese were the first tool that allowed computers to think in “shades of gray”—and for a time I believed they held the key to unlocking AI. Toward the end of the 1980s I became convinced that I was wrong, and this chapter tells of my journey from prophet to apostate. Nevertheless, Bayesian networks remain a very important tool for AI and still encapsulate much of the mathematical foundation of causal diagrams. In addition to a gentle, causality-minded introduction to Bayes’s rule and Bayesian methods of reasoning, Chapter 3 will entertain the reader with examples of real-life applications of Bayesian networks.\nChapter 4 tells about the major contribution of statistics to causal inference: the randomized controlled trial (RCT). From a causal perspective, the RCT is a man-made tool for uncovering the query P(L | do(D)), which is a property of nature. Its main purpose is to disassociate variables of interest (say, D and L) from other variables (Z) that would otherwise affect them both.\nDisarming the distortions, or “confounding,” produced by such lurking variables has been a century-old problem. This chapter walks the reader through a surprisingly simple solution to the general confounding problem, which you will grasp in ten minutes of playfully tracing paths in a diagram.\nChapter 5 gives an account of a seminal moment in the history of causation and indeed the history of science, when statisticians struggled with the question of whether smoking causes lung cancer. Unable to use their favorite tool, the randomized controlled trial, they struggled to agree on an answer or even on how to make sense of the question. The smoking debate brings the importance of causality into its sharpest focus. Millions of lives were lost or shortened because scientists did not have an adequate language or methodology for answering causal questions.\nChapter 6 will, I hope, be a welcome diversion for the reader after the serious matters of Chapter 5. This is a chapter of paradoxes: the Monty Hall paradox, Simpson’s paradox, Berkson’s paradox, and others. Classical paradoxes like these can be enjoyed as brainteasers, but they have a serious side too, especially when viewed from a causal perspective. In fact, almost all of them represent clashes with causal intuition and therefore reveal the anatomy of that intuition. They were canaries in the coal mine that should have alerted scientists to the fact that human intuition is grounded in causal, not statistical, logic. I believe that the reader will enjoy this new twist on his or her favorite old paradoxes.\nChapters 7 to 9 finally take readers on a thrilling ascent of the Ladder of Causation. We start in Chapter 7 with questions about intervention and explain how my students and I went through a twenty-year struggle to automate the answers to do-type questions. We succeeded, and this chapter explains the guts of the “causal inference engine,” which produces the yes/no answer and the estimand in Figure I.1. Studying this engine will empower the reader to spot certain patterns in the causal diagram that deliver immediate answers to the causal query. These patterns are called back-door adjustment, front-door adjustment, and instrumental variables, the workhorses of causal inference in practice.\nChapter 8 takes you to the top of the ladder by discussing counterfactuals.\nThese have been seen as a fundamental part of causality at least since 1748, when Scottish philosopher David Hume proposed the following somewhat contorted definition of causation: “We may define a cause to be an object followed by another, and where all the objects, similar to the first, are followed by objects similar to the second. Or, in other words, where, if the first object had not been, the second never had existed.” David Lewis, a philosopher at Princeton University who died in 2001, pointed out that Hume really gave two definitions, not one, the first of regularity (i.e., the cause is regularly followed by the effect) and the second of the counterfactual (“if the first object had not been…”). While philosophers and scientists had mostly paid attention to the regularity definition, Lewis argued that the counterfactual definition aligns more closely with human intuition: “We think of a cause as something that makes a difference, and the difference it makes must be a difference from what would have happened without it.” Readers will be excited to find out that we can now move past the academic debates and compute an actual value (or probability) for any counterfactual query, no matter how convoluted. Of special interest are questions concerning necessary and sufficient causes of observed events. For example, how likely is it that the defendant’s action was a necessary cause of the claimant’s injury? How likely is it that man-made climate change is a sufficient cause of a heat wave? Finally, Chapter 9 discusses the topic of mediation. You may have wondered, when we talked about drawing arrows in a causal diagram, whether we should draw an arrow from Drug D to Lifespan L if the drug affects lifespan only by way of its effect on blood pressure Z (a mediator). In other words, is the effect of D on L direct or indirect? And if both, how do we assess their relative importance? Such questions are not only of great scientific interest but also have practical ramifications; if we understand the mechanism through which a drug acts, we might be able to develop other drugs with the same effect that are cheaper or have fewer side effects. The reader will be pleased to discover how this age-old quest for a mediation mechanism has been reduced to an algebraic exercise and how scientists are using the new tools in the causal tool kit to solve such problems.\nChapter 10 brings the book to a close by coming back to the problem that initially led me to causation: the problem of automating human-level intelligence (sometimes called “strong AI”). I believe that causal reasoning is essential for machines to communicate with us in our own language about policies, experiments, explanations, theories, regret, responsibility, free will, and obligations—and, eventually, to make their own moral decisions.\nIf I could sum up the message of this book in one pithy phrase, it would be that you are smarter than your data. Data do not understand causes and effects; humans do. I hope that the new science of causal inference will enable us to better understand how we do it, because there is no better way to understand ourselves than by emulating ourselves. In the age of computers, this new understanding also brings with it the prospect of amplifying our innate abilities so that we can make better sense of data, be it big or small.",
    "crumbs": [
      "Causal Inference",
      "The book of why"
    ]
  },
  {
    "objectID": "extracted/The Book of Why - Judea Pearl.html#the-ladder-of-causation",
    "href": "extracted/The Book of Why - Judea Pearl.html#the-ladder-of-causation",
    "title": "The book of why",
    "section": "1. THE LADDER OF CAUSATION",
    "text": "1. THE LADDER OF CAUSATION\nIN the beginning…\nI was probably six or seven years old when I first read the story of Adam and Eve in the Garden of Eden. My classmates and I were not at all surprised by God’s capricious demands, forbidding them to eat from the Tree of Knowledge. Deities have their reasons, we thought. What we were more intrigued by was the idea that as soon as they ate from the Tree of Knowledge, Adam and Eve became conscious, like us, of their nakedness.\nAs teenagers, our interest shifted slowly to the more philosophical aspects of the story. (Israeli students read Genesis several times a year.) Of primary concern to us was the notion that the emergence of human knowledge was not a joyful process but a painful one, accompanied by disobedience, guilt, and punishment. Was it worth giving up the carefree life of Eden? some asked.\nWere the agricultural and scientific revolutions that followed worth the economic hardships, wars, and social injustices that modern life entails? Don’t get me wrong: we were no creationists; even our teachers were Darwinists at heart. We knew, however, that the author who choreographed the story of Genesis struggled to answer the most pressing philosophical questions of his time. We likewise suspected that this story bore the cultural footprints of the actual process by which Homo sapiens gained dominion over our planet. What, then, was the sequence of steps in this speedy, super- evolutionary process? My interest in these questions waned in my early career as a professor of engineering but was reignited suddenly in the 1990s, when, while writing my book Causality, I confronted the Ladder of Causation.\nAs I reread Genesis for the hundredth time, I noticed a nuance that had somehow eluded my attention for all those years. When God finds Adam hiding in the garden, he asks, “Have you eaten from the tree which I forbade you?” And Adam answers, “The woman you gave me for a companion, she gave me fruit from the tree and I ate.” “What is this you have done?” God asks Eve. She replies, “The serpent deceived me, and I ate.” As we know, this blame game did not work very well on the Almighty, who banished both of them from the garden. But here is the point I had missed before: God asked “what,” and they answered “why.” God asked for the facts, and they replied with explanations. Moreover, both were thoroughly convinced that naming causes would somehow paint their actions in a different light. Where did they get this idea? For me, these nuances carried three profound implications. First, very early in our evolution, we humans realized that the world is not made up only of dry facts (what we might call data today); rather, these facts are glued together by an intricate web of cause-effect relationships. Second, causal explanations, not dry facts, make up the bulk of our knowledge, and should be the cornerstone of machine intelligence. Finally, our transition from processors of data to makers of explanations was not gradual; it was a leap that required an external push from an uncommon fruit. This matched perfectly with what I had observed theoretically in the Ladder of Causation: No machine can derive explanations from raw data. It needs a push.\nIf we seek confirmation of these messages from evolutionary science, we won’t find the Tree of Knowledge, of course, but we still see a major unexplained transition. We understand now that humans evolved from apelike ancestors over a period of 5 million to 6 million years and that such gradual evolutionary processes are not uncommon to life on earth. But in roughly the last 50,000 years, something unique happened, which some call the Cognitive Revolution and others (with a touch of irony) call the Great Leap Forward.\nHumans acquired the ability to modify their environment and their own abilities at a dramatically faster rate.\nFor example, over millions of years, eagles and owls have evolved truly amazing eyesight—yet they’ve never devised eyeglasses, microscopes, telescopes, or night-vision goggles. Humans have produced these miracles in a matter of centuries. I call this phenomenon the “super-evolutionary speedup.” Some readers might object to my comparing apples and oranges, evolution to engineering, but that is exactly my point. Evolution has endowed us with the ability to engineer our lives, a gift she has not bestowed on eagles and owls, and the question, again, is “Why?” What computational facility did humans suddenly acquire that eagles did not? Many theories have been proposed, but one is especially pertinent to the idea of causation. In his book Sapiens, historian Yuval Harari posits that our ancestors’ capacity to imagine nonexistent things was the key to everything, for it allowed them to communicate better. Before this change, they could only trust people from their immediate family or tribe. Afterward their trust extended to larger communities, bound by common fantasies (for example, belief in invisible yet imaginable deities, in the afterlife, and in the divinity of the leader) and expectations. Whether or not you agree with Harari’s theory, the connection between imagining and causal relations is almost self-evident.\nIt is useless to ask for the causes of things unless you can imagine their consequences. Conversely, you cannot claim that Eve caused you to eat from the tree unless you can imagine a world in which, counter to facts, she did not hand you the apple.\nBack to our Homo sapiens ancestors: their newly acquired causal imagination enabled them to do many things more efficiently through a tricky process we call “planning.” Imagine a tribe preparing for a mammoth hunt.\nWhat would it take for them to succeed? My mammoth-hunting skills are rusty, I must admit, but as a student of thinking machines, I have learned one thing: a thinking entity (computer, caveman, or professor) can only accomplish a task of such magnitude by planning things in advance—by deciding how many hunters to recruit; by gauging, given wind conditions, the direction from which to approach the mammoth; in short, by imagining and comparing the consequences of several hunting strategies. To do this, the thinking entity must possess, consult, and manipulate a mental model of its reality.\nF 1.1. Perceived causes of a successful mammoth hunt.\nIGURE Figure 1.1 shows how we might draw such a mental model. Each dot in Figure 1.1 represents a cause of success. Note that there are multiple causes and that none of them are deterministic. That is, we cannot be sure that having more hunters will enable success or that rain will prevent it, but these factors do change the probability of success.\nThe mental model is the arena where imagination takes place. It enables us to experiment with different scenarios by making local alterations to the model. Somewhere in our hunters’ mental model was a subroutine that evaluated the effect of the number of hunters. When they considered adding more, they didn’t have to evaluate every other factor from scratch. They could make a local change to the model, replacing “Hunters = 8” with “Hunters = 9,” and reevaluate the probability of success. This modularity is a key feature of causal models.\nI don’t mean to imply, of course, that early humans actually drew a pictorial model like this one. But when we seek to emulate human thought on a computer, or indeed when we try to solve unfamiliar scientific problems, drawing an explicit dots-and-arrows picture is extremely useful. These causal diagrams are the computational core of the “causal inference engine” described in the Introduction.\nTHE THREE LEVELS OF CAUSATION So far I may have given the impression that the ability to organize our knowledge of the world into causes and effects was monolithic and acquired all at once. In fact, my research on machine learning has taught me that a causal learner must master at least three distinct levels of cognitive ability: seeing, doing, and imagining.\nThe first, seeing or observing, entails detection of regularities in our environment and is shared by many animals as well as early humans before the Cognitive Revolution. The second, doing, entails predicting the effect(s) of deliberate alterations of the environment and choosing among these alterations to produce a desired outcome. Only a small handful of species have demonstrated elements of this skill. Use of tools, provided it is intentional and not just accidental or copied from ancestors, could be taken as a sign of reaching this second level. Yet even tool users do not necessarily possess a “theory” of their tool that tells them why it works and what to do when it doesn’t. For that, you need to have achieved a level of understanding that permits imagining. It was primarily this third level that prepared us for further revolutions in agriculture and science and led to a sudden and drastic change in our species’ impact on the planet.\nI cannot prove this, but I can prove mathematically that the three levels differ fundamentally, each unleashing capabilities that the ones below it do not. The framework I use to show this goes back to Alan Turing, the pioneer of research in artificial intelligence (AI), who proposed to classify a cognitive system in terms of the queries it can answer. This approach is exceptionally fruitful when we are talking about causality because it bypasses long and unproductive discussions of what exactly causality is and focuses instead on the concrete and answerable question “What can a causal reasoner do?” Or more precisely, what can an organism possessing a causal model compute that one lacking such a model cannot? F 1.2. The Ladder of Causation, with representative organisms at each IGURE level. Most animals, as well as present-day learning machines, are on the first rung, learning from association. Tool users, such as early humans, are on the second rung if they act by planning and not merely by imitation. We can also use experiments to learn the effects of interventions, and presumably this is how babies acquire much of their causal knowledge. Counterfactual learners, on the top rung, can imagine worlds that do not exist and infer reasons for observed phenomena. (Source: Drawing by Maayan Harel.) While Turing was looking for a binary classification—human or nonhuman—ours has three tiers, corresponding to progressively more powerful causal queries. Using these criteria, we can assemble the three levels of queries into one Ladder of Causation (Figure 1.2), a metaphor that we will return to again and again.\nLet’s take some time to consider each rung of the ladder in detail. At the first level, association, we are looking for regularities in observations. This is what an owl does when observing how a rat moves and figuring out where the rodent is likely to be a moment later, and it is what a computer Go program does when it studies a database of millions of Go games so that it can figure out which moves are associated with a higher percentage of wins. We say that one event is associated with another if observing one changes the likelihood of observing the other.\nThe first rung of the ladder calls for predictions based on passive observations. It is characterized by the question “What if I see …?” For instance, imagine a marketing director at a department store who asks, “How likely is a customer who bought toothpaste to also buy dental floss?” Such questions are the bread and butter of statistics, and they are answered, first and foremost, by collecting and analyzing data. In our case, the question can be answered by first taking the data consisting of the shopping behavior of all customers, selecting only those who bought toothpaste, and, focusing on the latter group, computing the proportion who also bought dental floss. This proportion, also known as a “conditional probability,” measures (for large data) the degree of association between “buying toothpaste” and “buying floss.” Symbolically, we can write it as P(floss | toothpaste). The “P” stands for “probability,” and the vertical line means “given that you see.” Statisticians have developed many elaborate methods to reduce a large body of data and identify associations between variables. “Correlation” or “regression,” a typical measure of association mentioned often in this book, involves fitting a line to a collection of data points and taking the slope of that line. Some associations might have obvious causal interpretations; others may not. But statistics alone cannot tell which is the cause and which is the effect, toothpaste or floss. From the point of view of the sales manager, it may not really matter. Good predictions need not have good explanations. The owl can be a good hunter without understanding why the rat always goes from point A to point B.\nSome readers may be surprised to see that I have placed present-day learning machines squarely on rung one of the Ladder of Causation, sharing the wisdom of an owl. We hear almost every day, it seems, about rapid advances in machine learning systems—self-driving cars, speech-recognition systems, and, especially in recent years, deep-learning algorithms (or deep neural networks). How could they still be only at level one? The successes of deep learning have been truly remarkable and have caught many of us by surprise. Nevertheless, deep learning has succeeded primarily by showing that certain questions or tasks we thought were difficult are in fact not. It has not addressed the truly difficult questions that continue to prevent us from achieving humanlike AI. As a result the public believes that “strong AI,” machines that think like humans, is just around the corner or maybe even here already. In reality, nothing could be farther from the truth. I fully agree with Gary Marcus, a neuroscientist at New York University, who recently wrote in the New York Times that the field of artificial intelligence is “bursting with microdiscoveries”—the sort of things that make good press releases—but machines are still disappointingly far from humanlike cognition. My colleague in computer science at the University of California, Los Angeles, Adnan Darwiche, has titled a position paper “Human-Level Intelligence or Animal-Like Abilities?” which I think frames the question in just the right way. The goal of strong AI is to produce machines with humanlike intelligence, able to converse with and guide humans. Deep learning has instead given us machines with truly impressive abilities but no intelligence. The difference is profound and lies in the absence of a model of reality.\nJust as they did thirty years ago, machine learning programs (including those with deep neural networks) operate almost entirely in an associational mode. They are driven by a stream of observations to which they attempt to fit a function, in much the same way that a statistician tries to fit a line to a collection of points. Deep neural networks have added many more layers to the complexity of the fitted function, but raw data still drives the fitting process. They continue to improve in accuracy as more data are fitted, but they do not benefit from the “super-evolutionary speedup.” If, for example, the programmers of a driverless car want it to react differently to new situations, they have to add those new reactions explicitly. The machine will not figure out for itself that a pedestrian with a bottle of whiskey in hand is likely to respond differently to a honking horn. This lack of flexibility and adaptability is inevitable in any system that works at the first level of the Ladder of Causation.\nWe step up to the next level of causal queries when we begin to change the world. A typical question for this level is “What will happen to our floss sales if we double the price of toothpaste?” This already calls for a new kind of knowledge, absent from the data, which we find at rung two of the Ladder of Causation, intervention.\nIntervention ranks higher than association because it involves not just seeing but changing what is. Seeing smoke tells us a totally different story about the likelihood of fire than making smoke. We cannot answer questions about interventions with passively collected data, no matter how big the data set or how deep the neural network. Many scientists have been quite traumatized to learn that none of the methods they learned in statistics is sufficient even to articulate, let alone answer, a simple question like “What happens if we double the price?” I know this because on many occasions I have helped them climb to the next rung of the ladder.\nWhy can’t we answer our floss question just by observation? Why not just go into our vast database of previous purchases and see what happened previously when toothpaste cost twice as much? The reason is that on the previous occasions, the price may have been higher for different reasons. For example, the product may have been in short supply, and every other store also had to raise its price. But now you are considering a deliberate intervention that will set a new price regardless of market conditions. The result might be quite different from when the customer couldn’t find a better deal elsewhere. If you had data on the market conditions that existed on the previous occasions, perhaps you could make a better prediction… but what data do you need? And then, how would you figure it out? Those are exactly the questions the science of causal inference allows us to answer.\nA very direct way to predict the result of an intervention is to experiment with it under carefully controlled conditions. Big-data companies like Facebook know this and constantly perform experiments to see what happens if items on the screen are arranged differently or the customer gets a different prompt (or even a different price).\nMore interesting and less widely known—even in Silicon Valley—is that successful predictions of the effects of interventions can sometimes be made even without an experiment. For example, the sales manager could develop a model of consumer behavior that includes market conditions. Even if she doesn’t have data on every factor, she might have data on enough key surrogates to make the prediction. A sufficiently strong and accurate causal model can allow us to use rung-one (observational) data to answer rung-two (interventional) queries. Without the causal model, we could not go from rung one to rung two. This is why deep-learning systems (as long as they use only rung-one data and do not have a causal model) will never be able to answer questions about interventions, which by definition break the rules of the environment the machine was trained in.\nAs these examples illustrate, the defining query of the second rung of the Ladder of Causation is “What if we do…?” What will happen if we change the environment? We can write this kind of query as P(floss | do(toothpaste)), which asks about the probability that we will sell floss at a certain price, given that we set the price of toothpaste at another price.\nAnother popular question at the second level of causation is “How?,” which is a cousin of “What if we do…?” For instance, the manager may tell us that we have too much toothpaste in our warehouse. “How can we sell it?” he asks. That is, what price should we set for it? Again, the question refers to an intervention, which we want to perform mentally before we decide whether and how to do it in real life. That requires a causal model.\nWe perform interventions all the time in our daily lives, although we don’t usually use such a fancy term for them. For example, when we take aspirin to cure a headache, we are intervening on one variable (the quantity of aspirin in our body) in order to affect another one (our headache status). If we are correct in our causal belief about aspirin, the “outcome” variable will respond by changing from “headache” to “no headache.” While reasoning about interventions is an important step on the causal ladder, it still does not answer all questions of interest. We might wonder, My headache is gone now, but why? Was it the aspirin I took? The food I ate? The good news I heard? These queries take us to the top rung of the Ladder of Causation, the level of counterfactuals, because to answer them we must go back in time, change history, and ask, “What would have happened if I had not taken the aspirin?” No experiment in the world can deny treatment to an already treated person and compare the two outcomes, so we must import a whole new kind of knowledge.\nCounterfactuals have a particularly problematic relationship with data because data are, by definition, facts. They cannot tell us what will happen in a counterfactual or imaginary world where some observed facts are bluntly negated. Yet the human mind makes such explanation-seeking inferences reliably and repeatably. Eve did it when she identified “The serpent deceived me” as the reason for her action. This ability most distinguishes human from animal intelligence, as well as from model-blind versions of AI and machine learning.\nYou may be skeptical that science can make any useful statement about “would haves,” worlds that do not exist and things that have not happened.\nBut it does and always has. The laws of physics, for example, can be interpreted as counterfactual assertions, such as “Had the weight on this spring doubled, its length would have doubled as well” (Hooke’s law). This statement is, of course, backed by a wealth of experimental (rung-two) evidence, derived from hundreds of springs, in dozens of laboratories, on thousands of different occasions. However, once anointed as a “law,” physicists interpret it as a functional relationship that governs this very spring, at this very moment, under hypothetical values of the weight. All of these different worlds, where the weight is x pounds and the length of the spring is L inches, are treated as objectively knowable and simultaneously active, x even though only one of them actually exists.\nGoing back to the toothpaste example, a top-rung question would be “What is the probability that a customer who bought toothpaste would still have bought it if we had doubled the price?” We are comparing the real world (where we know that the customer bought the toothpaste at the current price) to a fictitious world (where the price is twice as high).\nThe rewards of having a causal model that can answer counterfactual questions are immense. Finding out why a blunder occurred allows us to take the right corrective measures in the future. Finding out why a treatment worked on some people and not on others can lead to a new cure for a disease.\nAnswering the question “What if things had been different?” allows us to learn from history and the experience of others, something that no other species appears to do. It is not surprising that the ancient Greek philosopher Democritus (460–370 BC) said, “I would rather discover one cause than be the King of Persia.” The position of counterfactuals at the top of the Ladder of Causation explains why I place such emphasis on them as a key moment in the evolution of human consciousness. I totally agree with Yuval Harari that the depiction of imaginary creatures was a manifestation of a new ability, which he calls the Cognitive Revolution. His prototypical example is the Lion Man sculpture, found in Stadel Cave in southwestern Germany and now held at the Ulm Museum (see Figure 1.3). The Lion Man, roughly 40,000 years old, is a mammoth tusk sculpted into the form of a chimera, half man and half lion.\nWe do not know who sculpted the Lion Man or what its purpose was, but we do know that anatomically modern humans made it and that it represents a break with any art or craft that had gone before. Previously, humans had fashioned tools and representational art, from beads to flutes to spear points to elegant carvings of horses and other animals. The Lion Man is different: a creature of pure imagination.\nF 1.3. The Lion Man of Stadel Cave. The earliest known representation of IGURE an imaginary creature (half man and half lion), it is emblematic of a newly developed cognitive ability, the capacity to reason about counterfactuals.\n(Source: Photo by Yvonne Mühleis, courtesy of State Office for Cultural Heritage Baden-Württemberg/Ulmer Museum, Ulm, Germany.) As a manifestation of our newfound ability to imagine things that have never existed, the Lion Man is the precursor of every philosophical theory, scientific discovery, and technological innovation, from microscopes to airplanes to computers. Every one of these had to take shape in someone’s imagination before it was realized in the physical world.\nThis leap forward in cognitive ability was as profound and important to our species as any of the anatomical changes that made us human. Within 10,000 years after the Lion Man’s creation, all other hominids (except for the very geographically isolated Flores hominids) had become extinct. And humans have continued to change the natural world with incredible speed, using our imagination to survive, adapt, and ultimately take over. The advantage we gained from imagining counterfactuals was the same then as it is today: flexibility, the ability to reflect and improve on past actions, and, perhaps even more significant, our willingness to take responsibility for past and current actions.\nAs shown in Figure 1.2, the characteristic queries for the third rung of the Ladder of Causation are “What if I had done…?” and “Why?” Both involve comparing the observed world to a counterfactual world. Experiments alone cannot answer such questions. While rung one deals with the seen world, and rung two deals with a brave new world that is seeable, rung three deals with a world that cannot be seen (because it contradicts what is seen). To bridge the gap, we need a model of the underlying causal process, sometimes called a “theory” or even (in cases where we are extraordinarily confident) a “law of nature.” In short, we need understanding. This is, of course, a holy grail of any branch of science—the development of a theory that will enable us to predict what will happen in situations we have not even envisioned yet. But it goes even further: having such laws permits us to violate them selectively so as to create worlds that contradict ours. Our next section features such violations in action.\nTHE MINI-TURING TEST In 1950, Alan Turing asked what it would mean for a computer to think like a human. He suggested a practical test, which he called “the imitation game,” but every AI researcher since then has called it the “Turing test.” For all practical purposes, a computer could be called a thinking machine if an ordinary human, communicating with the computer by typewriter, could not tell whether he was talking with a human or a computer. Turing was very confident that this was within the realm of feasibility. “I believe that in about fifty years’ time it will be possible to program computers,” he wrote, “to make them play the imitation game so well that an average interrogator will not have more than a 70 percent chance of making the right identification after five minutes of questioning.” Turing’s prediction was slightly off. Every year the Loebner Prize competition identifies the most humanlike “chatbot” in the world, with a gold medal and $100,000 offered to any program that succeeds in fooling all four judges into thinking it is human. As of 2015, in twenty-five years of competition, not a single program has fooled all the judges or even half of them.\nTuring didn’t just suggest the “imitation game”; he also proposed a strategy to pass it. “Instead of trying to produce a program to simulate the adult mind, why not rather try to produce one which simulates the child’s?” he asked. If you could do that, then you could just teach it the same way you would teach a child, and presto, twenty years later (or less, given a computer’s greater speed), you would have an artificial intelligence. “Presumably the child brain is something like a notebook as one buys it from the stationer’s,” he wrote. “Rather little mechanism, and lots of blank sheets.” He was wrong about that: the child’s brain is rich in mechanisms and prestored templates.\nNonetheless, I think that Turing was on to something. We probably will not succeed in creating humanlike intelligence until we can create childlike intelligence, and a key component of this intelligence is the mastery of causation.\nHow can machines acquire causal knowledge? This is still a major challenge that will undoubtedly involve an intricate combination of inputs from active experimentation, passive observation, and (not least) the programmer—much the same inputs that a child receives, with evolution, parents, and peers substituted for the programmer.\nHowever, we can answer a slightly less ambitious question: How can machines (and people) represent causal knowledge in a way that would enable them to access the necessary information swiftly, answer questions correctly, and do it with ease, as a three-year-old child can? In fact, this is the main question we address in this book.\nI call this the mini-Turing test. The idea is to take a simple story, encode it on a machine in some way, and then test to see if the machine can correctly answer causal questions that a human can answer. It is “mini” for two reasons.\nFirst, it is confined to causal reasoning, excluding other aspects of human intelligence such as vision and natural language. Second, we allow the contestant to encode the story in any convenient representation, unburdening the machine of the task of acquiring the story from its own personal experience. Passing this mini-test has been my life’s work—consciously for the last twenty-five years and subconsciously even before that.\nObviously, as we prepare to take the mini-Turing test, the question of representation needs to precede the question of acquisition. Without a representation, we wouldn’t know how to store information for future use.\nEven if we could let our robot manipulate its environment at will, whatever information we learned this way would be forgotten, unless our robot were endowed with a template to encode the results of those manipulations. One major contribution of AI to the study of cognition has been the paradigm “Representation first, acquisition second.” Often the quest for a good representation has led to insights into how the knowledge ought to be acquired, be it from data or a programmer.\nWhen I describe the mini-Turing test, people commonly claim that it can easily be defeated by cheating. For example, take the list of all possible questions, store their correct answers, and then read them out from memory when asked. There is no way to distinguish (so the argument goes) between a machine that stores a dumb question-answer list and one that answers the way that you and I do—that is, by understanding the question and producing an answer using a mental causal model. So what would the mini-Turing test prove, if cheating is so easy? The philosopher John Searle introduced this cheating possibility, known as the “Chinese Room” argument, in 1980 to challenge Turing’s claim that the ability to fake intelligence amounts to having intelligence. Searle’s challenge has only one flaw: cheating is not easy; in fact, it is impossible. Even with a small number of variables, the number of possible questions grows astronomically. Say that we have ten causal variables, each of which takes only two values (0 or 1). We could ask roughly 30 million possible queries, such as “What is the probability that the outcome is 1, given that we see variable X equals 1 and we make variable Y equal 0 and variable Z equal 1?” If there were more variables, or more than two states for each one, the number of possibilities would grow beyond our ability to even imagine. Searle’s list would need more entries than the number of atoms in the universe. So, clearly a dumb list of questions and answers can never simulate the intelligence of a child, let alone an adult.\nHumans must have some compact representation of the information needed in their brains, as well as an effective procedure to interpret each question properly and extract the right answer from the stored representation.\nTo pass the mini-Turing test, therefore, we need to equip machines with a similarly efficient representation and answer-extraction algorithm.\nSuch a representation not only exists but has childlike simplicity: a causal diagram. We have already seen one example, the diagram for the mammoth hunt. Considering the extreme ease with which people can communicate their knowledge with dot-and-arrow diagrams, I believe that our brains indeed use a representation like this. But more importantly for our purposes, these models pass the mini-Turing test; no other model is known to do so. Let’s look at some examples.\nF Causal diagram for the firing squad example. A and B represent (the IGURE 1.4 actions of) Soldiers A and B.\nSuppose that a prisoner is about to be executed by a firing squad. A certain chain of events must occur for this to happen. First, the court orders the execution. The order goes to a captain, who signals the soldiers on the firing squad (A and B) to fire. We’ll assume that they are obedient and expert marksmen, so they only fire on command, and if either one of them shoots, the prisoner dies.\nFigure 1.4 shows a diagram representing the story I just told. Each of the unknowns (CO, C, A, B, D) is a true/false variable. For example, D = true means the prisoner is dead; D = false means the prisoner is alive. CO = false means the court order was not issued; CO = true means it was, and so on.\nUsing this diagram, we can start answering causal questions from different rungs of the ladder. First, we can answer questions of association (i.e., what one fact tells us about another). If the prisoner is dead, does that mean the court order was given? We (or a computer) can inspect the graph, trace the rules behind each of the arrows, and, using standard logic, conclude that the two soldiers wouldn’t have fired without the captain’s command. Likewise, the captain wouldn’t have given the command if he didn’t have the order in his possession. Therefore the answer to our query is yes. Alternatively, suppose we find out that A fired. What does that tell us about B? By following the arrows, the computer concludes that B must have fired too. (A would not have fired if the captain hadn’t signaled, so B must have fired as well.) This is true even though A does not cause B (there is no arrow from A to B).\nGoing up the Ladder of Causation, we can ask questions about intervention. What if Soldier A decides on his own initiative to fire, without waiting for the captain’s command? Will the prisoner be dead or alive? This question in fact already has a contradictory flavor to it. I just told you that A only shoots if commanded to, and yet now we are asking what happens if he fired without a command. If you’re just using the rules of logic, as computers typically do, the question is meaningless. As the robot in the 1960s sci-fi TV series Lost in Space used to say in such situations, “That does not compute.” If we want our computer to understand causation, we have to teach it how to break the rules. We have to teach it the difference between merely observing an event and making it happen. “Whenever you make an event happen,” we tell the computer, “remove all arrows that point to that event and continue the analysis by ordinary logic, as if the arrows had never been there.” Thus, we erase all the arrows leading into the intervened variable (A).\nWe also set that variable manually to its prescribed value (true). The rationale for this peculiar “surgery” is simple: making an event happen means that you emancipate it from all other influences and subject it to one and only one influence—that which enforces its happening.\nFigure 1.5 shows the causal diagram that results from our example. This intervention leads inevitably to the prisoner’s death. That is the causal function behind the arrow leading from A to D.\nF 1.5. Reasoning about interventions. Soldier A decides to fire; arrow from C IGURE to A is deleted, and A is assigned the value true.\nNote that this conclusion agrees with our intuitive judgment that A’s unauthorized firing will lead to the prisoner’s death, because the surgery leaves the arrow from A to D intact. Also, our judgment would be that B (in all likelihood) did not shoot; nothing about A’s decision should affect variables in the model that are not effects of A’s shot. This bears repeating. If we see A shoot, then we conclude that B shot too. But if A decides to shoot, or if we make A shoot, then the opposite is true. This is the difference between seeing and doing. Only a computer capable of grasping this difference can pass the mini-Turing test.\nNote also that merely collecting Big Data would not have helped us ascend the ladder and answer the above questions. Assume that you are a reporter collecting records of execution scenes day after day. Your data will consist of two kinds of events: either all five variables are true, or all of them are false. There is no way that this kind of data, in the absence of an understanding of who listens to whom, will enable you (or any machine learning algorithm) to predict the results of persuading marksman A not to shoot.\nFinally, to illustrate the third rung of the Ladder of Causation, let’s pose a counterfactual question. Suppose the prisoner is lying dead on the ground.\nFrom this we can conclude (using level one) that A shot, B shot, the captain gave the signal, and the court gave the order. But what if A had decided not to shoot? Would the prisoner be alive? This question requires us to compare the real world with a fictitious and contradictory world where A didn’t shoot. In the fictitious world, the arrow leading into A is erased to liberate A from listening to C. Instead A is set to false, leaving its past history the same as it was in the real world. So the fictitious world looks like Figure 1.6.\nF 1.6. Counterfactual reasoning. We observe that the prisoner is dead and ask IGURE what would have happened if Soldier A had decided not to fire.\nTo pass the mini-Turing test, our computer must conclude that the prisoner would be dead in the fictitious world as well, because B’s shot would have killed him. So A’s courageous change of heart would not have saved his life.\nUndoubtedly this is one reason firing squads exist: they guarantee that the court’s order will be carried out and also lift some of the burden of responsibility from the individual shooters, who can say with a (somewhat) clean conscience that their actions did not cause the prisoner’s death as “he would have died anyway.” It may seem as if we are going to a lot of trouble to answer toy questions whose answer was obvious anyway. I completely agree! Causal reasoning is easy for you because you are human, and you were once a three-year-old, and you had a marvelous three-year-old brain that understood causation better than any animal or computer. The whole point of the “mini-Turing problem” is to make causal reasoning feasible for computers too. In the process, we might learn something about how humans do it. As all three examples show, we have to teach the computer how to selectively break the rules of logic.\nComputers are not good at breaking rules, a skill at which children excel.\n(Cavemen too! The Lion Man could not have been created without a breach of the rules about what head goes with what body.) However, let’s not get too complacent about human superiority. Humans may have a much harder time reaching correct causal conclusions in a great many situations. For example, there could be many more variables, and they might not be simple binary (true/false) variables. Instead of predicting whether a prisoner is alive or dead, we might want to predict how much the unemployment rate will go up if we raise the minimum wage. This kind of quantitative causal reasoning is generally beyond the power of our intuition.\nAlso, in the firing squad example we ruled out uncertainties: maybe the captain gave his order a split second after rifleman A decided to shoot, maybe rifleman B’s gun jammed, and so forth. To handle uncertainty we need information about the likelihood that the such abnormalities will occur.\nLet me give you an example in which probabilities make all the difference.\nIt echoes the public debate that erupted in Europe when the smallpox vaccine was first introduced. Unexpectedly, data showed that more people died from smallpox inoculations than from smallpox itself. Naturally, some people used this information to argue that inoculation should be banned, when in fact it was saving lives by eradicating smallpox. Let’s look at some fictitious data to illustrate the effect and settle the dispute.\nSuppose that out of 1 million children, 99 percent are vaccinated, and 1 percent are not. If a child is vaccinated, he or she has one chance in one hundred of developing a reaction, and the reaction has one chance in one hundred of being fatal. On the other hand, he or she has no chance of developing smallpox. Meanwhile, if a child is not vaccinated, he or she obviously has zero chance of developing a reaction to the vaccine, but he or she has one chance in fifty of developing smallpox. Finally, let’s assume that smallpox is fatal in one out of five cases.\nI think you would agree that vaccination looks like a good idea. The odds of having a reaction are lower than the odds of getting smallpox, and the reaction is much less dangerous than the disease. But now let’s look at the data. Out of 1 million children, 990,000 get vaccinated, 9,900 have the reaction, and 99 die from it. Meanwhile, 10,000 don’t get vaccinated, 200 get smallpox, and 40 die from the disease. In summary, more children die from vaccination (99) than from the disease (40).\nI can empathize with the parents who might march to the health department with signs saying, “Vaccines kill!” And the data seem to be on their side; the vaccinations indeed cause more deaths than smallpox itself. But is logic on their side? Should we ban vaccination or take into account the deaths prevented? Figure 1.7 shows the causal diagram for this example.\nWhen we began, the vaccination rate was 99 percent. We now ask the counterfactual question “What if we had set the vaccination rate to zero?” Using the probabilities I gave you above, we can conclude that out of 1 million children, 20,000 would have gotten smallpox, and 4,000 would have died. Comparing the counterfactual world with the real world, we see that not vaccinating would have cost the lives of 3,861 children (the difference between 4,000 and 139). We should thank the language of counterfactuals for helping us to avoid such costs.\nF 1.7. Causal diagram for the vaccination example. Is vaccination beneficial or IGURE harmful? The main lesson for a student of causality is that a causal model entails more than merely drawing arrows. Behind the arrows, there are probabilities.\nWhen we draw an arrow from X to Y, we are implicitly saying that some probability rule or function specifies how Y would change if X were to change. We might know what the rule is; more likely, we will have to estimate it from data. One of the most intriguing features of the Causal Revolution, though, is that in many cases we can leave those mathematical details completely unspecified. Very often the structure of the diagram itself enables us to estimate all sorts of causal and counterfactual relationships: simple or complicated, deterministic or probabilistic, linear or nonlinear.\nFrom the computing perspective, our scheme for passing the mini-Turing test is also remarkable in that we used the same routine in all three examples: translate the story into a diagram, listen to the query, perform a surgery that corresponds to the given query (interventional or counterfactual; if the query is associational then no surgery is needed), and use the modified causal model to compute the answer. We did not have to train the machine in a multitude of new queries each time we changed the story. The approach is flexible enough to work whenever we can draw a causal diagram, whether it has to do with mammoths, firing squads, or vaccinations. This is exactly what we want for a causal inference engine: it is the kind of flexibility we enjoy as humans.\nOf course, there is nothing inherently magical about a diagram. It succeeds because it carries causal information; that is, when we constructed the diagram, we asked, “Who could directly cause the prisoner’s death?” or “What are the direct effects of vaccinations?” Had we constructed the diagram by asking about mere associations, it would not have given us these capabilities. For example, in Figure 1.7, if we reversed the arrow Vaccination Smallpox, we would get the same associations in the data but would erroneously conclude that smallpox affects vaccination.\nDecades’ worth of experience with these kinds of questions has convinced me that, in both a cognitive and a philosophical sense, the idea of causes and effects is much more fundamental than the idea of probability. We begin learning causes and effects before we understand language and before we know any mathematics. (Research has shown that three-year-olds already understand the entire Ladder of Causation.) Likewise, the knowledge conveyed in a causal diagram is typically much more robust than that encoded in a probability distribution. For example, suppose that times have changed and a much safer and more effective vaccine is introduced. Suppose, further, that due to improved hygiene and socioeconomic conditions, the danger of contracting smallpox has diminished. These changes will drastically affect all the probabilities involved; yet, remarkably, the structure of the diagram will remain invariant. This is the key secret of causal modeling. Moreover, once we go through the analysis and find how to estimate the benefit of vaccination from data, we do not have to repeat the entire analysis from scratch. As discussed in the Introduction, the same estimand (i.e., recipe for answering the query) will remain valid and, as long as the diagram does not change, can be applied to the new data and produce a new estimate for our query. It is because of this robustness, I conjecture, that human intuition is organized around causal, not statistical, relations.\nON PROBABILITIES AND CAUSATION The recognition that causation is not reducible to probabilities has been very hard-won, both for me personally and for philosophers and scientists in general. Understanding the meaning of “cause” has been the focus of a long tradition of philosophers, from David Hume and John Stuart Mill in the 1700s and 1800s, to Hans Reichenbach and Patrick Suppes in the mid-1900s, to Nancy Cartwright, Wolfgang Spohn, and Christopher Hitchcock today. In particular, beginning with Reichenbach and Suppes, philosophers have tried to define causation in terms of probability, using the notion of “probability raising”: X causes Y if X raises the probability of Y.\nThis concept is solidly ensconced in intuition. We say, for example, “Reckless driving causes accidents” or “You will fail this course because of your laziness,” knowing quite well that the antecedents merely tend to make the consequences more likely, not absolutely certain. One would expect, therefore, that probability raising should become the bridge between rung one and rung two of the Ladder of Causation. Alas, this intuition has led to decades of failed attempts.\nWhat prevented the attempts from succeeding was not the idea itself but the way it was articulated formally. Almost without exception, philosophers expressed the sentence “X raises the probability of Y” using conditional probabilities and wrote P(Y | X) &gt; P(Y). This interpretation is wrong, as you surely noticed, because “raises” is a causal concept, connoting a causal influence of X over Y. The expression P(Y | X) &gt; P(Y), on the other hand, speaks only about observations and means: “If we see X, then the probability of Y increases.” But this increase may come about for other reasons, including Y being a cause of X or some other variable (Z) being the cause of both of them. That’s the catch! It puts the philosophers back at square one, trying to eliminate those “other reasons.” Probabilities, as given by expressions like P(Y | X), lie on the first rung of the Ladder of Causation and cannot ever (by themselves) answer queries on the second or third rung. Any attempt to “define” causation in terms of seemingly simpler, first-rung concepts must fail. That is why I have not attempted to define causation anywhere in this book: definitions demand reduction, and reduction demands going to a lower rung. Instead, I have pursued the ultimately more constructive program of explaining how to answer causal queries and what information is needed to answer them. If this seems odd, consider that mathematicians take exactly the same approach to Euclidean geometry. Nowhere in a geometry book will you find a definition of the terms “point” and “line.” Yet we can answer any and all queries about them on the basis of Euclid’s axioms (or even better, the various modern versions of Euclid’s axioms).\nBut let’s look at this probability-raising criterion more carefully and see where it runs aground. The issue of a common cause, or confounder, of X and Y was among the most vexing for philosophers. If we take the probability- raising criterion at face value, we must conclude that high ice-cream sales cause crime because the probability of crime is higher in months when more ice cream is sold. In this particular case, we can explain the phenomenon because both ice-cream sales and crime are higher in summer, when the weather is warmer. Nevertheless, we are still left asking what general philosophical criterion could tell us that weather, not ice-cream sales, is the cause.\nPhilosophers tried hard to repair the definition by conditioning on what they called “background factors” (another word for confounders), yielding the criterion P(Y | X, K = k) &gt; P(Y | K = k), where K stands for some background variables. In fact, this criterion works for our ice-cream example if we treat temperature as a background variable. For example, if we look only at days when the temperature is ninety degrees (K = 90), we will find no residual association between ice-cream sales and crime. It’s only when we compare ninety-degree days to thirty-degree days that we get the illusion of a probability raising.\nStill, no philosopher has been able to give a convincingly general answer to the question “Which variables need to be included in the background set K and conditioned on?” The reason is obvious: confounding too is a causal concept and hence defies probabilistic formulation. In 1983, Nancy Cartwright broke this deadlock and enriched the description of the background context with a causal component. She proposed that we should condition on any factor that is “causally relevant” to the effect. By borrowing a concept from rung two of the Ladder of Causation, she essentially gave up on the idea of defining causes based on probability alone. This was progress, but it opened the door to the criticism that we are defining a cause in terms of itself.\nPhilosophical disputes over the appropriate content of K continued for more than two decades and reached an impasse. In fact, we will see a correct criterion in Chapter 4, and I will not spoil the surprise here. It suffices for the moment to say that this criterion is practically impossible to enunciate without causal diagrams.\nIn summary, probabilistic causality has always foundered on the rock of confounding. Every time the adherents of probabilistic causation try to patch up the ship with a new hull, the boat runs into the same rock and springs another leak. Once you misrepresent “probability raising” in the language of conditional probabilities, no amount of probabilistic patching will get you to the next rung of the ladder. As strange as it may sound, the notion of probability raising cannot be expressed in terms of probabilities.\nThe proper way to rescue the probability-raising idea is with the do- operator: we can say that X causes Y if P(Y | do(X)) &gt; P(Y). Since intervention is a rung-two concept, this definition can capture the causal interpretation of probability raising, and it can also be made operational through causal diagrams. In other words, if we have a causal diagram and data on hand and a researcher asks whether P(Y | do(X)) &gt; P(Y), we can answer his question coherently and algorithmically and thus decide if X is a cause of Y in the probability-raising sense.\nI usually pay a great deal of attention to what philosophers have to say about slippery concepts such as causation, induction, and the logic of scientific inference. Philosophers have the advantage of standing apart from the hurly-burly of scientific debate and the practical realities of dealing with data. They have been less contaminated than other scientists by the anticausal biases of statistics. They can call upon a tradition of thought about causation that goes back at least to Aristotle, and they can talk about causation without blushing or hiding it behind the label of “association.” However, in their effort to mathematize the concept of causation—itself a laudable idea—philosophers were too quick to commit to the only uncertainty-handling language they knew, the language of probability. They have for the most part gotten over this blunder in the past decade or so, but unfortunately similar ideas are being pursued in econometrics even now, under names like “Granger causality” and “vector autocorrelation.” Now I have a confession to make: I made the same mistake. I did not always put causality first and probability second. Quite the opposite! When I started working in artificial intelligence, in the early 1980s, I thought that uncertainty was the most important thing missing from AI. Moreover, I insisted that uncertainty be represented by probabilities. Thus, as I explain in Chapter 3, I developed an approach to reasoning under uncertainty, called Bayesian networks, that mimics how an idealized, decentralized brain might incorporate probabilities into its decisions. Given that we see certain facts, Bayesian networks can swiftly compute the likelihood that certain other facts are true or false. Not surprisingly, Bayesian networks caught on immediately in the AI community and even today are considered a leading paradigm in artificial intelligence for reasoning under uncertainty.\nThough I am delighted with the ongoing success of Bayesian networks, they failed to bridge the gap between artificial and human intelligence. I’m sure you can figure out the missing ingredient: causality. True, causal ghosts were all over the place. The arrows invariably pointed from causes to effects, and practitioners often noted that diagnostic systems became unmanageable when the direction of the arrows was reversed. But for the most part we thought that this was a cultural habit, or an artifact of old thought patterns, not a central aspect of intelligent behavior.\nAt the time, I was so intoxicated with the power of probabilities that I considered causality a subservient concept, merely a convenience or a mental shorthand for expressing probabilistic dependencies and distinguishing relevant variables from irrelevant ones. In my 1988 book Probabilistic Reasoning in Intelligent Systems, I wrote, “Causation is a language with which one can talk efficiently about certain structures of relevance relationships.” The words embarrass me today, because “relevance” is so obviously a rung-one notion. Even by the time the book was published, I knew in my heart that I was wrong. To my fellow computer scientists, my book became the bible of reasoning under uncertainty, but I was already feeling like an apostate.\nBayesian networks inhabit a world where all questions are reducible to probabilities, or (in the terminology of this chapter) degrees of association between variables; they could not ascend to the second or third rungs of the Ladder of Causation. Fortunately, they required only two slight twists to climb to the top. First, in 1991, the graph-surgery idea empowered them to handle both observations and interventions. Another twist, in 1994, brought them to the third level and made them capable of handling counterfactuals.\nBut these developments deserve a fuller discussion in a later chapter. The main point is this: while probabilities encode our beliefs about a static world, causality tells us whether and how probabilities change when the world changes, be it by intervention or by act of imagination.\nSir Francis Galton demonstrates his “Galton board” or “quincunx” at the Royal Institution. He saw this pinball-like apparatus as an analogy for the inheritance of genetic traits like stature. The pinballs accumulate in a bell-shaped curve that is similar to the distribution of human heights. The puzzle of why human heights don’t spread out from one generation to the next, as the balls would, led him to the discovery of “regression to the mean.” (Source: Drawing by Dakota Harr.)",
    "crumbs": [
      "Causal Inference",
      "The book of why"
    ]
  },
  {
    "objectID": "extracted/The Book of Why - Judea Pearl.html#from-buccaneers-to-guinea-pigs-the-genesis-of-causal-inference",
    "href": "extracted/The Book of Why - Judea Pearl.html#from-buccaneers-to-guinea-pigs-the-genesis-of-causal-inference",
    "title": "The book of why",
    "section": "2. FROM BUCCANEERS TO GUINEA PIGS: THE GENESIS OF CAUSAL INFERENCE",
    "text": "2. FROM BUCCANEERS TO GUINEA PIGS: THE GENESIS OF CAUSAL INFERENCE\nAnd yet it moves.\n—ATTRIBUTED TO GALILEO GALILEI (1564–1642) F OR close to two centuries, one of the most enduring rituals in British science has been the Friday Evening Discourse at the Royal Institution of Great Britain in London. Many discoveries of the nineteenth century were first announced to the public at this venue: Michael Faraday and the principles of photography in 1839; J. J. Thomson and the electron in 1897; James Dewar and the liquefaction of hydrogen in 1904.\nPageantry was an important part of the occasion; it was literally science as theater, and the audience, the cream of British society, would dress to the nines (tuxedos with black tie for men). At the appointed hour, a chime would strike, and the evening’s speaker would be ushered into the auditorium.\nTraditionally he would begin the lecture immediately, without introduction or preamble. Experiments and live demonstrations were part of the spectacle.\nOn February 9, 1877, the evening’s speaker was Francis Galton, FRS, first cousin of Charles Darwin, noted African explorer, inventor of fingerprinting, and the very model of a Victorian gentleman scientist. Galton’s title was “Typical Laws of Heredity.” His experimental apparatus for the evening was a curious contraption that he called a quincunx, now often called a “Galton board.” A similar game has often appeared on the televised game show The Price Is Right, where it is known as Plinko. The Galton board consists of a triangular array of pins or pegs, into which small metal balls can be inserted through an opening at the top. The balls bounce downward from one row to the next, pinball style, before settling into one of a line of slots at the bottom (see frontispiece). For any individual ball, the zigs and zags to the left or right look completely random. However, if you pour a lot of balls into the Galton board, a startling regularity emerges: the accumulated balls at the bottom will always form a rough approximation to a bell-shaped curve. The slots nearest the center will be stacked high with balls, and the number of the balls in each slot gradually tapers down to zero at the edges of the quincunx.\nThis pattern has a mathematical explanation. The path of any individual ball is like a sequence of independent coin flips. Each time a ball hits a pin, it bounces either to the left or the right, and from a distance its choice seems completely random. The sum of the results—say, the excess of the rights over the lefts—determines which slot the ball ends up in. According to the central limit theorem, proven in 1810 by Pierre-Simon Laplace, any such random process—one that amounts to a sum of a large number of coin flips—will lead to the same probability distribution, called the normal distribution (or bell- shaped curve). The Galton board is simply a visual demonstration of Laplace’s theorem.\nThe central limit theorem is truly a miracle of nineteenth-century mathematics. Think about it: even though the path of any individual ball is unpredictable, the path of 1,000 balls is extremely predictable—a convenient fact for the producers of The Price Is Right, who can estimate accurately how much money the contestants will win at Plinko over the long run. This is the same law that makes insurance companies so profitable, despite the uncertainties in human affairs.\nThe well-dressed audience at the Royal Institute must have wondered what all this had to do with the laws of heredity, the promised lecture topic. To illustrate the connection, Galton showed them some data collected in France on the heights of military recruits. These also follow a normal distribution: many men are of about average height, with a gradually diminishing number who are either extremely tall or extremely short. In fact, it does not matter whether you are talking about 1,000 military recruits or 1,000 balls in the Galton board: the numbers in each slot (or height category) are almost the same.\nThus, to Galton, the quincunx was a model for the inheritance of stature or, indeed, many other genetic traits. It is a causal model. In simplest terms, Galton believed the balls “inherit” their position in the quincunx in the same way that humans inherit their stature.\nBut if we accept this model—provisionally—it poses a puzzle, which was Galton’s chief subject for the evening. The width of the bell-shaped curve depends on the number of rows of pegs placed between the top and the bottom. Suppose we doubled the number of rows. This would create a model for two generations of inheritance, with the first half of the rows representing the first generation and the second half representing the second. You would inevitably find more variation in the second generation than in the first, and in succeeding generations, the bell-shaped curve would get wider and wider still.\nBut this is not what happens with actual human stature. In fact, the width of the distribution of human heights stays relatively constant over time. We didn’t have nine-foot humans a century ago, and we still don’t. What explains the stability of the population’s genetic endowment? Galton had been puzzling over this enigma for roughly eight years, since the publication of his book Hereditary Genius in 1869.\nAs the title of the book suggests, Galton’s true interest was not carnival games or human stature but human intelligence. As a member of an extended family with a remarkable amount of scientific genius, Galton naturally would have liked to prove that genius runs in families. And he had set out to do exactly that in his book. He painstakingly compiled pedigrees of 605 “eminent” Englishmen from the preceding four centuries. But he found that the sons and fathers of these eminent men were somewhat less eminent and the grandparents and grandchildren less eminent still.\nIt’s easy enough for us now to find flaws in Galton’s program. What, after all, is the definition of eminence? And isn’t it possible that people in eminent families are successful because of their privilege rather than their talent? Though Galton was aware of such difficulties, he pursued this futile quest for a genetic explanation at an increasing pace and determination.\nStill, Galton was on to something, which became more apparent once he started looking at features like height, which are easier to measure and more strongly linked to heredity than “eminence.” Sons of tall men tend to be taller than average—but not as tall as their fathers. Sons of short men tend to be shorter than average—but not as short as their fathers. Galton first called this phenomenon “reversion” and later “regression toward mediocrity.” It can be noted in many other settings. If students take two different standardized tests on the same material, the ones who scored high on the first test will usually score higher than average on the second test but not as high as they did the first time. This phenomenon of regression to the mean is ubiquitous in all facets of life, education, and business. For instance, in baseball the Rookie of the Year (a player who does unexpectedly well in his first season) often hits a “sophomore slump,” in which he does not do quite as well.\nGalton didn’t know all of this, and he thought he had stumbled onto a law of heredity rather than a law of statistics. He believed that regression to the mean must have some cause, and in his Royal Institution lecture he illustrated his point. He showed his audience a two-layered quincunx (Figure 2.1).\nAfter passing through the first array of pegs, the balls passed through sloping chutes that moved them closer to the center of the board. Then they would pass through a second array of pegs. Galton showed triumphantly that the chutes exactly compensated for the tendency of the normal distribution to spread out. This time, the bell-shaped probability distribution kept a constant width from generation to generation.\nF 2.1. The Galton board, used by Francis Galton as an analogy for the IGURE inheritance of human heights. (a) When many balls are dropped through the pinball-like apparatus, their random bounces cause them to pile up in a bell-shaped curve. (b) Galton noted that on two passes, A and B, through the Galton board (the analogue of two generations) the bell-shaped curve got wider. (c) To counteract this tendency, he installed chutes to move the “second generation” back closer to the center. The chutes are Galton’s causal explanation for regression to the mean.\n(Source: Francis Galton, Natural Inheritance [1889].) Thus, Galton conjectured, regression toward the mean was a physical process, nature’s way of ensuring that the distribution of height (or intelligence) remained the same from generation to generation. “The process of reversion cooperates with the general law of deviation,” Galton told his audience. He compared it to Hooke’s law, the physical law that describes the tendency of a spring to return to its equilibrium length.\nKeep in mind the date. In 1877, Galton was in pursuit of a causal explanation and thought that regression to the mean was a causal process, like a law of physics. He was mistaken, but he was far from alone. Many people continue to make the same mistake to this day. For example, baseball experts always look for causal explanations for a player’s sophomore slump. “He’s gotten overconfident,” they complain, or “the other players have figured out his weaknesses.” They may be right, but the sophomore slump does not need a causal explanation. It will happen more often than not by the laws of chance alone.\nThe modern statistical explanation is quite simple. As Daniel Kahneman summarizes it in his book Thinking, Fast and Slow, “Success = talent + luck.\nGreat success = a little more talent + a lot of luck.” A player who wins Rookie of the Year is probably more talented than average, but he also (probably) had a lot of luck. Next season, he is not likely to be so lucky, and his batting average will be lower.\nBy 1889, Galton had figured this out, and in the process—partly disappointed but also fascinated—he took the first huge step toward divorcing statistics from causation. His reasoning is subtle but worth making the effort to understand. It is the newborn discipline of statistics uttering its first cry.\nGalton had started gathering a variety of “anthropometric” statistics: height, forearm length, head length, head width, and so on. He noticed that when he plotted height against forearm length, for instance, the same phenomenon of regression to the mean took place. Tall men usually had longer-than-average forearms—but not as far above average as their height.\nClearly height is not a cause of forearm length, or vice versa. If anything, both are caused by genetic inheritance. Galton started using a new word for this kind of relationship: height and forearm length were “co-related.” Eventually, he opted for the more normal English word “correlated.” Later he realized an even more startling fact: in generational comparisons, the temporal order could be reversed. That is, the fathers of sons also revert to the mean. The father of a son who is taller than average is likely to be taller than average but shorter than his son (see Figure 2.2). Once Galton realized this, he had to give up any idea of a causal explanation for regression, because there is no way that the sons’ heights could cause the fathers’ heights.\nThis realization may sound paradoxical at first. “Wait!” you’re saying.\n“You’re telling me that tall dads usually have shorter sons, and tall sons usually have shorter dads. How can both of those statements be true? How can a son be both taller and shorter than his father?” F 2.2. The scatter plot shows a data set of heights, with each dot representing IGURE the height of a father (on the x-axis) and his son (on the y-axis). The dashed line coincides with the major axis of the ellipse, while the solid line (called the regression line) connects the rightmost and leftmost points on the ellipse. The difference between them accounts for regression to the mean. For example, the black star shows that 72″ fathers have, on the average, 71″ sons. (That is, the average height of all the data points in the vertical strip is 71″.) The horizontal strip and white star show that the same loss of height occurs in the noncausal direction (backward in time). (Source: Figure by Maayan Harel, with a contribution from Christopher Boucher.) The answer is that we are talking not about an individual father and an individual son but about two populations. We start with the population of six- foot fathers. Because they are taller than average, their sons will regress toward the mean; let’s say their sons average five feet, eleven inches.\nHowever, the population of father-son pairs with six-foot fathers is not the same as the population of father-son pairs with five-foot-eleven-inch sons.\nEvery father in the first group is by definition six feet tall. But the second group will have a few fathers who are taller than six feet and a lot of fathers who are shorter than six feet. Their average height will be shorter than five feet, eleven inches, again displaying regression to the mean.\nAnother way to illustrate regression is to use a diagram called a scatter plot (Figure 2.2). Each father-son pair is represented by one dot, with the x- coordinate being the father’s height and the y-coordinate being the son’s height. So a father and son who are both five feet, nine inches (or sixty-nine inches) will be represented by a dot at (69, 69), right at the center of the scatter plot. A father who is six feet (or seventy-two inches) with a son who is five-foot-eleven (or seventy-one inches) will be represented by a dot at (72, 71), in the northeast corner of the scatter plot. Notice that the scatter plot has a roughly elliptical shape—a fact that was crucial to Galton’s analysis and characteristic of bell-shaped distributions with two variables.\nAs shown in Figure 2.2, the father-son pairs with seventy-two-inch fathers lie in a vertical slice centered at 72; the father-son pairs with seventy-one-inch sons lie in a horizontal slice centered at 71. Here is visual proof that these are two different populations. If we focus only on the first population, the pairs with seventy-two-inch fathers, we can ask, “How tall are the sons on average?” It’s the same as asking where the center of that vertical slice is, and by eye you can see that the center is about 71. If we focus only on the second population with seventy-one-inch sons, we can ask, “How tall are the fathers on average?” This is the same as asking for the center of the horizontal slice, and by eye you can see that its center is about 70.3.\nWe can go farther and think about doing the same procedure for every vertical slice. That’s equivalent to asking, “For fathers of height x, what is the best prediction of the son’s height (y)?” Alternatively, we can take each horizontal slice and ask where its center is: for sons of height y, what is the best “prediction” (or retrodiction) of the father’s height? As he thought about this question, Galton stumbled on an important fact: the predictions always fall on a line, which he called the regression line, which is less steep than the major axis (or axis of symmetry) of the ellipse (Figure 2.3). In fact there are two such lines, depending on which variable is being predicted and which is being used as evidence. You can predict the son’s height based on the father’s or the father’s based on the son’s. The situation is completely symmetric. Once again this shows that where regression to the mean is concerned, there is no difference between cause and effect.\nThe slope of the regression enables you to predict the value of one variable, given that you know the value of the other. In the context of Galton’s problem, a slope of 0.5 would mean that each extra inch of height for the father would correspond, on average, to an extra half inch for the son, and vice versa. A slope of 1 would be perfect correlation, which means every extra inch for the father is passed deterministically to the son, who would also be an inch taller. The slope can never be greater than 1; if it were, the sons of tall fathers would be taller on average, and the sons of short fathers would be shorter—and this would force the distribution of heights to become wider over time. After a few generations we would start having 9-foot people and 2- foot people, which is not observed in nature. So, provided the distribution of heights stays the same from one generation to the next, the slope of the regression line cannot exceed 1.\nF 2.3. Galton’s regression lines. Line OM gives the best prediction of a son’s IGURE height if you know the height of the father; line ON gives the best prediction of a father’s height if you know the height of the son. Neither is the same as the major axis (axis of symmetry) of the scatter plot. (Source: Francis Galton, Journal of the Anthropological Institute of Great Britain and Ireland [1886], 246–263, Plate X.) The law of regression applies even when we correlate two different quantities, like height and IQ. If you plot one quantity against the other in a scatter plot and rescale the two axes properly, then the slope of the best-fit line always enjoys the same properties. It equals 1 only when one quantity can predict the other precisely; it is 0 whenever the prediction is no better than a random guess. The slope (after scaling) is the same no matter whether you plot X against Y or Y against X. In other words, the slope is completely agnostic as to cause and effect. One variable could cause the other, or they could both be effects of a third cause; for the purpose of prediction, it does not matter.\nFor the first time, Galton’s idea of correlation gave an objective measure, independent of human judgment or interpretation, of how two variables are related to one another. The two variables can stand for height, intelligence, or income; they can stand in causal, neutral, or reverse-causal relation. The correlation will always reflect the degree of cross predictability between the two variables. Galton’s disciple Karl Pearson later derived a formula for the slope of the (properly rescaled) regression line and called it the correlation coefficient. This is still the first number that statisticians all over the world compute when they want to know how strongly two different variables in a data set are related. Galton and Pearson must have been thrilled to find such a universal way of describing the relationships between random variables. For Pearson, especially, the slippery old concepts of cause and effect seemed outdated and unscientific, compared to the mathematically clear and precise concept of a correlation coefficient.\nGALTON AND THE ABANDONED QUEST It is an irony of history that Galton started out in search of causation and ended up discovering correlation, a relationship that is oblivious of causation.\nEven so, hints of causal thinking remained in his writing. “It is easy to see that correlation [between the sizes of two organs] must be the consequence of the variations of the two organs being partly due to common causes,” he wrote in 1889.\nThe first sacrifice on the altar of correlation was Galton’s elaborate machinery to explain the stability of the population’s genetic endowment. The quincunx simulated the creation of variations in height and their transmission from one generation to the next. But Galton had to invent the inclined chutes in the quincunx specifically to rein in the ever-growing diversity in the population. Having failed to find a satisfactory biological mechanism to account for this restoring force, Galton simply abandoned the effort after eight years and turned his attention to the siren song of correlation. Historian Stephen Stigler, who has written extensively about Galton, noticed this sudden shift in Galton’s aims and aspirations: “What was silently missing was Darwin, the chutes, and all the ‘survival of the fittest.’… In supreme irony, what had started out as an attempt to mathematize the framework of the Origin of Species ended with the essence of that great work being discarded as unnecessary!” But to us, in the modern era of causal inference, the original problem remains. How do we explain the stability of the population, despite Darwinian variations that one generation bestows on the next? Looking back on Galton’s machine in the light of causal diagrams, the first thing I notice is that the machine was wrongly constructed. The ever-growing dispersion, which begged Galton for a counterforce, should never have been there in the first place. Indeed, if we trace a ball dropping from one level to the next in the quincunx, we see that the displacement at the next level inherits the sum total of variations bestowed upon it by all the pegs along the way. This stands in blatant contradiction to Kahneman’s equations: Success = talent + luck Great success = A little more talent + a lot of luck.\nAccording to these equations, success in generation 2 does not inherit the luck of generation 1. Luck, by its very definition, is a transitory occurrence; hence it has no impact on future generations. But such transitory behavior is incompatible with Galton’s machine.\nTo compare these two conceptions side by side, let us draw their associated causal diagrams. In Figure 2.4(a) (Galton’s conception), success is transmitted across generations, and luck variations accumulate indefinitely.\nThis is perhaps natural if “success” is equated to wealth or eminence.\nHowever, for the inheritance of physical characteristics like stature, we must replace Galton’s model with that in Figure 2.4(b). Here only the genetic component, shown here as talent, is passed down from one generation to the next. Luck affects each generation independently, in such a way that the chance factors in one generation have no way of affecting later generations, either directly or indirectly.\nF 2.4. Two models of inheritance. (a) The Galton board model, in which luck IGURE accrues from generation to generation, leading to an ever-wider distribution of success. (b) A genetic model, in which luck does not accrue, leading to a constant distribution of success.\nBoth of these models are compatible with the bell-shaped distribution of heights. But the first model is not compatible with the stability of the distribution of heights (or success). The second model, on the other hand, shows that to explain the stability of success from one generation to the next, we only need explain the stability of the genetic endowment of the population (talent). That stability, now called the Hardy-Weinberg equilibrium, received a satisfactory mathematical explanation in the work of G. H. Hardy and Wilhelm Weinberg in 1908. And yes, they used yet another causal model— the Mendelian theory of inheritance.\nIn retrospect, Galton could not have anticipated the work of Mendel, Hardy, and Weinberg. In 1877, when Galton gave his lecture, Gregor Mendel’s work of 1866 had been forgotten (it was only rediscovered in 1900), and the mathematics of Hardy and Weinberg’s proofs would likely have been beyond him. But it is interesting to note how close he came to finding the right framework and also how the causal diagram makes it easy to zero in on his mistaken assumption: the transmission of luck from one generation to the next. Unfortunately, he was led astray by his beautiful but flawed causal model, and later, having discovered the beauty of correlation, he came to believe that causality was no longer needed.\nAs a final personal comment on Galton’s story, I confess to committing a cardinal sin of history writing, one of many sins I will commit in this book. In the 1960s, it became unfashionable to write history from the viewpoint of modern-day science, as I have done above. “Whig history” was the epithet used to mock the hindsighted style of history writing, which focused on successful theories and experiments and gave little credit to failed theories and dead ends. The modern style of history writing became more democratic, treating chemists and alchemists with equal respect and insisting on understanding all theories in the social context of their own time.\nWhen it comes to explaining the expulsion of causality from statistics, however, I accept the mantle of Whig historian with pride. There simply is no other way to understand how statistics became a model-blind data-reduction enterprise, except by putting on our causal lenses and retelling the stories of Galton and Pearson in the light of the new science of cause and effect. In fact, by so doing, I rectify the distortions introduced by mainstream historians who, lacking causal vocabulary, marvel at the invention of correlation and fail to note its casualty—the death of causation.\nPEARSON: THE WRATH OF THE ZEALOT It remained to Galton’s disciple, Karl Pearson, to complete the task of expunging causation from statistics. Yet even he was not entirely successful.\nReading Galton’s Natural Inheritance was one of the defining moments of Pearson’s life: “I felt like a buccaneer of Drake’s days—one of the order of men ‘not quite pirates, but with decidedly piratical tendencies,’ as the dictionary has it!” he wrote in 1934. “I interpreted… Galton to mean that there was a category broader than causation, namely correlation, of which causation was only the limit, and that this new conception of correlation brought psychology, anthropology, medicine and sociology in large part into the field of mathematical treatment. It was Galton who first freed me from the prejudice that sound mathematics could only be applied to natural phenomena under the category of causation.” In Pearson’s eyes, Galton had enlarged the vocabulary of science.\nCausation was reduced to nothing more than a special case of correlation (namely, the case where the correlation coefficient is 1 or –1 and the relationship between x and y is deterministic). He expresses his view of causation with great clarity in The Grammar of Science (1892): “That a certain sequence has occurred and reoccurred in the past is a matter of experience to which we give expression in the concept causation.… Science in no case can demonstrate any inherent necessity in a sequence, nor prove with absolute certainty that it must be repeated.” To summarize, causation for Pearson is only a matter of repetition and, in the deterministic sense, can never be proven. As for causality in a nondeterministic world, Pearson was even more dismissive: “the ultimate scientific statement of description of the relation between two things can always be thrown back upon… a contingency table.” In other words, data is all there is to science. Full stop. In this view, the notions of intervention and counterfactuals discussed in Chapter 1 do not exist, and the lowest rung of the Ladder of Causation is all that is needed for doing science.\nThe mental leap from Galton to Pearson is breathtaking and indeed worthy of a buccaneer. Galton had proved only that one phenomenon—regression to the mean—did not require a causal explanation. Now Pearson was completely removing causation from science. What made him take this leap? Historian Ted Porter, in his biography Karl Pearson, describes how Pearson’s skepticism about causation predated his reading of Galton’s book.\nPearson had been wrestling with the philosophical foundation of physics and wrote (for example), “Force as a cause of motion is exactly on the same footing as a tree-god as a cause of growth.” More generally, Pearson belonged to a philosophical school called positivism, which holds that the universe is a product of human thought and that science is only a description of those thoughts. Thus causation, construed as an objective process that happens in the world outside the human brain, could not have any scientific meaning.\nMeaningful thoughts can only reflect patterns of observations, and these can be completely described by correlations. Having decided that correlation was a more universal descriptor of human thought than causation, Pearson was prepared to discard causation completely.\nPorter paints a vivid picture of Pearson throughout his life as a self- described Schwärmer, a German word that translates as “enthusiast” but can also be interpreted more strongly as “zealot.” After graduating from Cambridge in 1879, Pearson spent a year abroad in Germany and fell so much in love with its culture that he promptly changed his name from Carl to Karl.\nHe was a socialist long before it became popular, and he wrote to Karl Marx in 1881, offering to translate Das Kapital into English. Pearson, arguably one of England’s first feminists, started the Men’s and Women’s Club in London for discussions of “the woman question.” He was concerned about women’s subordinate position in society and advocated for them to be paid for their work. He was extremely passionate about ideas while at the same time very cerebral about his passions. It took him nearly half a year to persuade his future wife, Maria Sharpe, to marry him, and their letters suggest that she was frankly terrified of not living up to his high intellectual ideals.\nWhen Pearson found Galton and his correlations, he at last found a focus for his passions: an idea that he believed could transform the world of science and bring mathematical rigor to fields like biology and psychology. And he moved with a buccaneer’s sense of purpose toward accomplishing this mission. His first paper on statistics was published in 1893, four years after Galton’s discovery of correlation. By 1901 he had founded a journal, Biometrika, which remains one of the most influential statistical journals (and, somewhat heretically, published my first full paper on causal diagrams in 1995). By 1903, Pearson had secured a grant from the Worshipful Company of Drapers to start a Biometrics Lab at University College London.\nIn 1911 it officially became a department when Galton passed away and left an endowment for a professorship (with the stipulation that Pearson be its first holder). For at least two decades, Pearson’s Biometrics Lab was the world center of statistics.\nOnce Pearson held a position of power, his zealotry came out more and more clearly. As Porter writes in his biography, “Pearson’s statistical movement had aspects of a schismatic sect. He demanded the loyalty and commitment of his associates and drove dissenters from the church biometric.” One of his earliest assistants, George Udny Yule, was also one of the first people to feel Pearson’s wrath. Yule’s obituary of Pearson, written for the Royal Society in 1936, conveys well the sting of those days, though couched in polite language.\nThe infection of his enthusiasm, it is true, was invaluable; but his dominance, even his very eagerness to help, could be a disadvantage.… This desire for domination, for everything to be just as he wanted it, comes out in other ways, notably the editing of Biometrika—surely the most personally edited journal that was ever published.… Those who left him and began to think for themselves were apt, as happened painfully in more instances than one, to find that after a divergence of opinion the maintenance of friendly relations became difficult, after express criticism impossible.\nEven so, there were cracks in Pearson’s edifice of causality-free science, perhaps even more so among the founders than among the later disciples. For instance, Pearson himself surprisingly wrote several papers about “spurious correlation,” a concept impossible to make sense of without making some reference to causation.\nPearson noticed that it’s relatively easy to find correlations that are just plain silly. For instance, for a fun example postdating Pearson’s time, there is a strong correlation between a nation’s per capita chocolate consumption and its number of Nobel Prize winners. This correlation seems silly because we cannot envision any way in which eating chocolate could cause Nobel Prizes.\nA more likely explanation is that more people in wealthy, Western countries eat chocolate, and the Nobel Prize winners have also been chosen preferentially from those countries. But this is a causal explanation, which, for Pearson, is not necessary for scientific thinking. To him, causation is just a “fetish amidst the inscrutable arcana of modern science.” Correlation is supposed to be the goal of scientific understanding. This puts him in an awkward position when he has to explain why one correlation is meaningful and another is “spurious.” He explains that a genuine correlation indicates an “organic relationship” between the variables, while a spurious correlation does not. But what is an “organic relationship”? Is it not causality by another name? Together, Pearson and Yule compiled several examples of spurious correlations. One typical case is now called confounding, and the chocolate- Nobel story is an example. (Wealth and location are confounders, or common causes of both chocolate consumption and Nobel frequency.) Another type of “nonsense correlation” often emerges in time series data. For example, Yule found an incredibly high correlation (0.95) between England’s mortality rate in a given year and the percentage of marriages conducted that year in the Church of England. Was God punishing marriage-happy Anglicans? No! Two separate historical trends were simply occurring at the same time: the country’s mortality rate was decreasing and membership in the Church of England was declining. Since both were going down at the same time, there was a positive correlation between them, but no causal connection.\nPearson discovered possibly the most interesting kind of “spurious correlation” as early as 1899. It arises when two heterogeneous populations are aggregated into one. Pearson, who, like Galton, was a fanatical collector of data on the human body, had obtained measurements of 806 male skulls and 340 female skulls from the Paris Catacombs (Figure 2.5). He computed the correlation between skull length and skull breadth. When the computation was done only for males or only for females, the correlations were negligible —there was no significant association between skull length and breadth. But when the two groups were combined, the correlation was 0.197, which would ordinarily be considered significant. This makes sense, because a small skull length is now an indicator that the skull likely belonged to a female and therefore that the breadth will also be small. However, Pearson considered it a statistical artifact. The fact that the correlation was positive had no biological or “organic” meaning; it was just a result of combining two distinct populations inappropriately.\nF 2.5. Karl Pearson with a skull from the Paris Catacombs. (Source: Drawing IGURE by Dakota Harr.) This example is a case of a more general phenomenon called Simpson’s paradox. Chapter 6 will discuss when it is appropriate to segregate data into separate groups and will explain why spurious correlations can emerge from aggregation. But let’s take a look at what Pearson wrote: “To those who persist in looking upon all correlations as cause and effect, the fact that correlation can be produced between two quite uncorrelated characters A and B by taking an artificial mixture of two closely allied races, must come rather as a shock.” As Stephen Stigler comments, “I cannot resist the speculation that he himself was the first one shocked.” In essence, Pearson was scolding himself for the tendency to think causally.\nLooking at the same example through the lens of causality, we can only say, What a missed opportunity! In an ideal world, such examples might have spurred a talented scientist to think about the reason for his shock and develop a science to predict when spurious correlations appear. At the very least, he should explain when to aggregate the data and when not to. But Pearson’s only guidance to his followers is that an “artificial” mixture (whatever that means) is bad. Ironically, using our causal lens, we now know that in some cases the aggregated data, not the partitioned data, give the correct result. The logic of causal inference can actually tell us which one to trust. I wish that Pearson were here to enjoy it! Pearson’s students did not all follow in lockstep behind him. Yule, who broke with Pearson for other reasons, broke with him over this too. Initially he was in the hard-line camp holding that correlations say everything we could ever wish to understand about science. However, he changed his mind to some extent when he needed to explain poverty conditions in London. In 1899, he studied the question of whether “out-relief” (that is, welfare delivered to a pauper’s home versus a poorhouse) increased the rate of poverty. The data showed that districts with more out-relief had a higher poverty rate, but Yule realized that the correlation was possibly spurious: these districts might also have more elderly people, who tend to be poorer.\nHowever, he then showed that even in comparisons of districts with equal proportions of elderly people, the correlation remained. This emboldened him to say that the increased poverty rate was due to out-relief. But after stepping out of line to make this assertion, he fell back into line again, writing in a footnote, “Strictly speaking, for ‘due to’ read ‘associated with.’” This set the pattern for generations of scientists after him. They would think “due to” and say “associated with.” With Pearson and his followers actively hostile toward causation, and with halfhearted dissidents such as Yule fearful of antagonizing their leader, the stage was set for another scientist from across the ocean to issue the first direct challenge to the causality-avoiding culture.\nSEWALL WRIGHT, GUINEA PIGS, AND PATH DIAGRAMS When Sewall Wright arrived at Harvard University in 1912, his academic background scarcely suggested the kind of lasting effect he would have on science. He had attended a small (and now defunct) college in Illinois, Lombard College, graduating in a class of only seven students. One of his teachers had been his own father, Philip Wright, an academic jack-of-all- trades who even ran the college’s printing press. Sewall and his brother Quincy helped out with the press, and among other things they published the first poetry by a not-yet-famous Lombard student, Carl Sandburg.\nSewall Wright’s ties with his father remained very close long after he graduated from college. Papa Philip moved to Massachusetts when Sewall did. Later, when Sewall worked in Washington, DC, Philip did likewise, first at the US Tariff Commission and then at the Brookings Institution as an economist. Although their academic interests diverged, they nevertheless found ways to collaborate, and Philip was the first economist to make use of his son’s invention of path diagrams.\nWright came to Harvard to study genetics, at the time one of the hottest topics in science because Gregor Mendel’s theory of dominant and recessive genes had just been rediscovered. Wright’s advisor, William Castle, had identified eight different hereditary factors (or genes, as we would call them today) that affected fur color in rabbits. Castle assigned Wright to do the same thing for guinea pigs. After earning his doctorate in 1915, Wright got an offer for which he was uniquely qualified: taking care of guinea pigs at the US Department of Agriculture (USDA).\nOne wonders if the USDA knew what it was getting when it hired Wright.\nPerhaps it expected a diligent animal caretaker who could straighten out the chaos of twenty years of poorly kept records. Wright did all that and much, much more. Wright’s guinea pigs were the springboard to his whole career and his whole theory of evolution, much like the finches on the Galapagos islands that had inspired Charles Darwin. Wright was an early advocate of the view that evolution is not gradual, as Darwin had posited, but takes place in relatively sudden bursts.\nIn 1925, Wright moved on to a faculty position at the University of Chicago that was probably better suited to someone with his wide-ranging theoretical interests. Even so, he remained very devoted to his guinea pigs. An often told anecdote says that he was once holding an unruly guinea pig under his arm while lecturing, and absentmindedly began using it to erase the blackboard (see Figure 2.6). While his biographers agree that this story is likely apocryphal, such stories often contain more truth than dry biographies do.\nWright’s early work at the USDA interests us most here. The inheritance of coat color in guinea pigs stubbornly refused to play by Mendelian rules. It proved virtually impossible to breed an all-white or all-colored guinea pig, and even the most inbred families (after multiple generations of brother-sister mating) still had pronounced variation, from mostly white to mostly colored.\nThis contradicted the prediction of Mendelian genetics that a particular trait should become “fixed” by multiple generations of inbreeding.\nWright began to doubt that genetics alone governed the amount of white and postulated that “developmental factors” in the womb were causing some of the variations. With hindsight, we know that he was correct. Different color genes are expressed in different places on the body, and the patterns of color depend not only on what genes the animal has inherited but where and in what combinations they happen to be expressed or suppressed.\nF 2.6. Sewall Wright was the first person to develop a mathematical method for IGURE answering causal questions from data, known as path diagrams. His love of mathematics surrendered only to his passion for guinea pigs. (Source: Drawing by Dakota Harr.) As it often happens (at least to the ingenious!), a pressing research problem leads to new methods of analysis, which vastly transcended their origins in guinea pig genetics. Yet, for Sewall Wright, estimating the developmental factors probably seemed like a college-level problem that he could have solved in his father’s math class at Lombard. When looking for the magnitude of some unknown quantity, you first assign a symbol to that quantity, next you express what you know about this and other quantities in the form of mathematical equations, and finally, if you have enough patience and enough equations, you can solve them and find your quantity of interest.\nIn Wright’s case, the desired and unknown quantity (shown in Figure 2.7) was d, the effect of “developmental factors” on white fur. Other causal quantities that entered into his equations included h, for “hereditary” factors, also unknown. Finally—and here comes Wright’s ingenuity—he showed that if we knew the causal quantities in Figure 2.7, we could predict correlations in the data (not shown in the diagram) by a simple graphical rule. This rule sets up a bridge from the deep, hidden world of causation to the surface world of correlations. It was the first bridge ever built between causality and probability, the first crossing of the barrier between rung two and rung one on the Ladder of Causation. Having built this bridge, Wright could travel backward over it, from the correlations measured in the data (rung one) to the hidden causal quantities, d and h (rung two). He did this by solving algebraic equations. This idea must have seemed simple to Wright but turned out to be revolutionary because it was the first proof that the mantra “Correlation does not imply causation” should give way to “Some correlations do imply causation.” F 2.7. Sewall Wright’s first path diagram, illustrating the factors leading to coat IGURE color in guinea pigs. D = developmental factors (after conception, before birth), E = environmental factors (after birth), G = genetic factors from each individual parent, H = combined hereditary factors from both parents, O, O′ = offspring. The objective of analysis was to estimate the strength of the effects of D, E, H (written as d, e, h in the diagram). (Source: Sewall Wright, Proceedings of the National Academy of Sciences [1920], 320–332.) In the end, Wright showed that the hypothesized developmental factors were more important than heredity. In a randomly bred population of guinea pigs, 42 percent of the variation in coat pattern was due to heredity, and 58 percent was developmental. By contrast, in a highly inbred family, only 3 percent of the variation in white fur coverage was due to heredity, and 92 percent was developmental. In other words, twenty generations of inbreeding had all but eliminated the genetic variation, but the developmental factors remained.\nAs interesting as this result is, the crux of the matter for our history is the way that Wright made his case. The path diagram in Figure 2.7 is the street map that tells us how to navigate over this bridge between rung one and rung two. It is a scientific revolution in one picture—and it comes complete with adorable guinea pigs! Notice that the path diagram shows every conceivable factor that could affect a baby guinea pig’s pigmentation. The letters D, E, and H refer to developmental, environmental, and hereditary factors, respectively. Each parent (the sire and the dam) and each child (offspring O and O′) has its own set of D, E, and H factors. The two offspring share environmental factors but have different developmental histories. The diagram incorporates the then novel insights of Mendelian genetics: a child’s heredity (H) is determined by its parents’ sperm and egg cells (G and G″), and these in turn are determined from the parents’ heredity (H″ and H‴) via a mixing process that was not yet understood (because DNA had not been discovered). It was understood, though, that the mixing process included an element of randomness (labeled “Chance” in the diagram).\nOne thing the diagram does not show explicitly is the difference between an inbred family and a normal family. In an inbred family there would be a strong correlation between the heredity of the sire and the dam, which Wright indicated with a two-headed arrow between H″ and H‴. Aside from that, every arrow in the diagram is one-way and leads from a cause to an effect.\nFor example, the arrow from G to H indicates that the sire’s sperm cell may have a direct causal effect on the offspring’s heredity. The absence of an arrow from G to H′ indicates that the sperm cell that gave rise to offspring O has no causal effect on the heredity of offspring O′.\nWhen you take apart the diagram arrow by arrow in this way, I think you will find that every one of them makes perfect sense. Note also that each arrow is accompanied by a small letter (a, b, c, etc.). These letters, called path coefficients, represent the strength of the causal effects that Wright wanted to solve for. Roughly speaking, a path coefficient represents the amount of variability in the target variable that is accounted for by the source variable.\nFor instance, it is fairly evident that 50 percent of each child’s hereditary makeup should come from each parent, so that a should be 1/2. (For technical reasons, Wright preferred to take the square root, so that a = 1/ and a2 = 1/2.) This interpretation of path coefficients, in terms of the amount of variation explained by a variable, was reasonable at the time. The modern causal interpretation is different: the path coefficients represent the results of a hypothetical intervention on the source variable. However, the notion of an intervention would have to wait until the 1940s, and Wright could not have anticipated it when he wrote his paper in 1920. Fortunately, in the simple models he analyzed then, the two interpretations yield the same result.\nI want to emphasize that the path diagram is not just a pretty picture; it is a powerful computational device because the rule for computing correlations (the bridge from rung two to rung one) involves tracing the paths that connect two variables to each other and multiplying the coefficients encountered along the way. Also, notice that the omitted arrows actually convey more significant assumptions than those that are present. An omitted arrow restricts the causal effect to zero, while a present arrow remains totally agnostic about the magnitude of the effect (unless we a priori impose some value on the path coefficient).\nWright’s paper was a tour de force and deserves to be considered one of the landmark results of twentieth-century biology. Certainly it is a landmark for the history of causality. Figure 2.7 is the first causal diagram ever published, the first step of twentieth-century science onto the second rung of the Ladder of Causation. And not a tentative step but a bold and decisive one! The following year Wright published a much more general paper called “Correlation and Causation” that explained how path analysis worked in other settings than guinea pig breeding.\nI don’t know what kind of reaction the thirty-year-old scientist expected, but the reaction he got surely must have stunned him. It came in the form of a rebuttal published in 1921 by one Henry Niles, a student of American statistician Raymond Pearl (no relation), who in turn was a student of Karl Pearson, the godfather of statistics.\nAcademia is full of genteel savagery, which I have had the honor to weather at times in my own otherwise placid career, but even so I have seldom seen a criticism as savage as Niles’s. He begins with a long series of quotes from his heroes, Karl Pearson and Francis Galton, attesting to the redundancy or even meaninglessness of the word “cause.” He concludes, “To contrast ‘causation’ and ‘correlation’ is unwarranted because causation is simply perfect correlation.” In this sentence he is directly echoing what Pearson wrote in Grammar of Science.\nNiles further disparages Wright’s entire methodology. He writes, “The basic fallacy of the method appears to be the assumption that it is possible to set up a priori a comparatively simple graphic system which will truly represent the lines of action of several variables upon each other, and upon a common result.” Finally, Niles works through some examples and, bungling the computations because he has not taken the trouble to understand Wright’s rules, he arrives at opposite conclusions. In summary, he declares, “We therefore conclude that philosophically the basis of the method of path coefficients is faulty, while practically the results of applying it where it can be checked prove it to be wholly unreliable.” From the scientific point of view a detailed discussion of Niles’s criticism is perhaps not worth the time, but his paper is very important to us as historians of causation. First, it faithfully reflects the attitude of his generation toward causation and the total grip that his mentor, Karl Pearson, had on the scientific thinking of his time. Second, we continue to hear Niles’s objections today.\nOf course, at times scientists do not know the entire web of relationships between their variables. In that case, Wright argued, we can use the diagram in exploratory mode; we can postulate certain causal relationships and work out the predicted correlations between variables. If these contradict the data, then we have evidence that the relationships we assumed were false. This way of using path diagrams, rediscovered in 1953 by Herbert Simon (a 1978 Nobel laureate in economics), inspired much work in the social sciences.\nAlthough we don’t need to know every causal relation between the variables of interest and might be able to draw some conclusions with only partial information, Wright makes one point with absolute clarity: you cannot draw causal conclusions without some causal hypotheses. This echoes what we concluded in Chapter 1: you cannot answer a question on rung two of the Ladder of Causation using only data collected from rung one.\nSometimes people ask me, “Doesn’t that make causal reasoning circular? Aren’t you just assuming what you want to prove?” The answer is no. By combining very mild, qualitative, and obvious assumptions (e.g., coat color of the son does not influence that of the parents) with his twenty years of guinea pig data, he obtained a quantitative and by no means obvious result: that 42 percent of the variation in coat color is due to heredity. Extracting the nonobvious from the obvious is not circular—it is a scientific triumph and deserves to be hailed as such.\nWright’s contribution is unique because the information leading to the conclusion (of 42 percent heritability) resided in two distinct, almost incompatible mathematical languages: the language of diagrams on one side and that of data on the other. This heretical idea of marrying qualitative “arrow-information” to quantitative “data-information” (two foreign languages!) was one of the miracles that first attracted me, as a computer scientist, to this enterprise.\nMany people still make Niles’s mistake of thinking that the goal of causal analysis is to prove that X is a cause of Y or else to find the cause of Y from scratch. That is the problem of causal discovery, which was my ambitious dream when I first plunged into graphical modeling and is still an area of vigorous research. In contrast, the focus of Wright’s research, as well as this book, is representing plausible causal knowledge in some mathematical language, combining it with empirical data, and answering causal queries that are of practical value. Wright understood from the very beginning that causal discovery was much more difficult and perhaps impossible. In his response to Niles, he writes, “The writer [i.e., Wright himself] has never made the preposterous claim that the theory of path coefficients provides a general formula for the deduction of causal relations. He wishes to submit that the combination of knowledge of correlations with knowledge of causal relations to obtain certain results, is a different thing from the deduction of causal relations from correlations implied by Niles’ statement.” E PUR SI MUOVE (AND YET IT MOVES) If I were a professional historian, I would probably stop here. But as the “Whig historian” that I promised to be, I cannot contain myself from expressing my sheer admiration for the precision of Wright’s words in the quote ending the previous section, which have not gone stale in the ninety years since he first articulated them and which essentially defined the new paradigm of modern causal analysis.\nMy admiration for Wright’s precision is second only to my admiration for his courage and determination. Imagine the situation in 1921. A self-taught mathematician faces the hegemony of the statistical establishment alone.\nThey tell him, “Your method is based on a complete misapprehension of the nature of causality in the scientific sense.” And he retorts, “Not so! My method generates something that is important and goes beyond anything that you can generate.” They say, “Our gurus looked into these problems already, two decades ago, and concluded that what you have done is nonsense. You have only combined correlations with correlations and gotten correlations.\nWhen you grow up, you will understand.” And he continues, “I am not dismissing your gurus, but a spade is a spade. My path coefficients are not correlations. They are something totally different: causal effects.” Imagine that you are in kindergarten, and your friends mock you for believing that 3 + 4 = 7, when everybody knows that 3 + 4 = 8. Then imagine going to your teacher for help and hearing her say, too, that 3 + 4 = 8. Would you not go home and ask yourself if perhaps there was something wrong with the way you were thinking? Even the strongest man would start to waver in his convictions. I have been in that kindergarten, and I know.\nBut Wright did not blink. And this was not just a matter of arithmetic, where there can be some sort of independent verification. Only philosophers had dared to express an opinion on the nature of causation. Where did Wright get this inner conviction that he was on the right track and the rest of the kindergarten class was just plain wrong? Maybe his Midwestern upbringing and the tiny college he went to encouraged his self-reliance and taught him that the surest kind of knowledge is what you construct yourself.\nOne of the earliest science books I read in school told of how the Inquisition forced Galileo to recant his teaching that Earth revolves around the sun and how he whispered under his breath, “And yet it moves” (E pur si muove). I don’t think that there is a child in the world who has read this legend and not been inspired by Galileo’s courage in defending his convictions. Yet as much as we admire him for his stand, I can’t help but think that he at least had his astronomical observations to fall back on. Wright had only untested conclusions—say, that developmental factors account for 58 percent, not 3 percent, of variation. With nothing to lean on except his internal conviction that path coefficients tell you what correlations do not, he still declared, “And yet it moves!” Colleagues tell me that when Bayesian networks fought against the artificial intelligence establishment (see Chapter 3), I acted stubbornly, single- mindedly, and uncompromisingly. Indeed, I recall being totally convinced of my approach, with not an iota of hesitation. But I had probability theory on my side. Wright didn’t have even one theorem to lean on. Scientists had abandoned causation, so Wright could not fall back on any theoretical framework. Nor could he rely on authorities, as Niles did, because there was no one for him to quote; the gurus had already pronounced their verdicts three decades earlier.\nBut one solace to Wright, and one sign that he was on the right path, must have been his understanding that he could answer questions that cannot be answered in any other way. Determining the relative importance of several factors was one such question. Another beautiful example of this can be found in his “Correlation and Causation” paper, from 1921, which asks how much a guinea pig’s birth weight will be affected if it spends one more day in the womb. I would like to examine Wright’s answer in some detail to enjoy the beauty of his method and to satisfy readers who would like to see how the mathematics of path analysis works.\nNotice that we cannot answer Wright’s question directly, because we can’t weigh a guinea pig in the womb. What we can do, though, is compare the birth weights of guinea pigs that spend (say) sixty-six days gestating with those that spend sixty-seven days. Wright noted that the guinea pigs that spent a day longer in the womb weighed an average of 5.66 grams more at birth.\nSo, one might naively suppose that a guinea pig embryo grows at 5.66 grams per day just before it is born.\n“Wrong!” says Wright. The pups born later are usually born later for a reason: they have fewer litter mates. This means that they have had a more favorable environment for growth throughout the pregnancy. A pup with only two siblings, for instance, will already weigh more on day sixty-six than a pup with four siblings. Thus the difference in birth weights has two causes, and we want to disentangle them. How much of the 5.66 grams is due to spending an additional day in utero and how much is due to having fewer siblings to compete with? Wright answered this question by setting up a path diagram (Figure 2.8). X represents the pup’s birth weight. Q and P represent the two known causes of the birth weight: the length of gestation (P) and rate of growth in utero (Q). L represents litter size, which affects both P and Q (a larger litter causes the pup to grow slower and also have fewer days in utero). It’s very important to realize that X, P, and L can be measured, for each guinea pig, but Q cannot.\nFinally, A and C are exogenous causes that we don’t have any data about (e.g., hereditary and environmental factors that control growth rate and gestation time independently of litter size). The important assumption that these factors are independent of each other is conveyed by the absence of any arrow between them, as well as of any common ancestor.\nF 2.8. Causal (path) diagram for birth-weight example.\nIGURE Now the question facing Wright was, “What is the direct effect of the gestation period P on the birth weight X?” The data (5.66 grams per day) don’t tell you the direct effect; they give you a correlation, biased by the litter size L. To get the direct effect, we need to remove this bias.\nIn Figure 2.8, the direct effect is represented by the path coefficient p, corresponding to the path P X. The bias due to litter size corresponds to the path P L Q X. And now the algebraic magic: the amount of bias is equal to the product of the path coefficients along that path (in other words, l times l′ times q). The total correlation, then, is just the sum of the path coefficients along the two paths: algebraically, p + (l × l′ × q) = 5.66 grams per day.\nIf we knew the path coefficients l, l′, and q, then we could just work out the second term and subtract it from 5.66 to get the desired quantity p. But we don’t know them, because Q (for example) is not measured. But here’s where the ingenuity of path coefficients really shines. Wright’s methods tell us how to express each of the measured correlations in terms of the path coefficients.\nAfter doing this for each of the measured pairs (P, X), (L, X), and (L, P), we obtain three equations that can be solved algebraically for the unknown path coefficients, p, l′, and l × q. Then we are done, because the desired quantity p has been obtained.\nToday we can skip the mathematics altogether and calculate p by cursory inspection of the diagram. But in 1920, this was the first time that mathematics was summoned to connect causation and correlation. And it worked! Wright calculated p to be 3.34 grams per day. In other words, had all the other variables (A, L, C, Q) been held constant and only the time of gestation increased by a day, the average increase in birth weight would be 3.34 grams per day. Note that this result is biologically meaningful. It tells us how rapidly the pups are growing per day before birth. By contrast, the number 5.66 grams per day has no biological significance, because it conflates two separate processes, one of which is not causal but anticausal (or diagnostic) in the link P L. Lesson one from this example: causal analysis allows us to quantify processes in the real world, not just patterns in the data.\nThe pups are growing at 3.34 grams per day, not 5.66 grams per day. Lesson two, whether you followed the mathematics or not: in path analysis you draw conclusions about individual causal relationships by examining the diagram as a whole. The entire structure of the diagram may be needed to estimate each individual parameter.\nIn a world where science progresses logically, Wright’s response to Niles should have produced a scientific excitement followed by an enthusiastic adoption of his methods by other scientists and statisticians. But that is not what happened. “One of the mysteries of the history of science from 1920 to 1960 is the virtual absence of any appreciable use of path analysis, except by Wright himself and by students of animal breeding,” wrote one of Wright’s geneticist colleagues, James Crow. “Although Wright had illustrated many diverse problems to which the method was applicable, none of these leads was followed.” Crow didn’t know it, but the mystery extended to social sciences as well.\nIn 1972, economist Arthur Goldberger lamented the “scandalous neglect” of Wright’s work during that period and noted, with the enthusiasm of a convert, that “[Wright’s] approach… sparked the recent upsurge of causal modeling in sociology.” If only we could go back and ask Wright’s contemporaries, “Why didn’t you pay attention?” Crow suggests one reason: path analysis “doesn’t lend itself to ‘canned’ programs. The user has to have a hypothesis and must devise an appropriate diagram of multiple causal sequences.” Indeed, Crow put his finger on an essential point: path analysis requires scientific thinking, as does every exercise in causal inference. Statistics, as frequently practiced, discourages it and encourages “canned” procedures instead. Scientists will always prefer routine calculations on data to methods that challenge their scientific knowledge.\nR. A. Fisher, the undisputed high priest of statistics in the generation after Galton and Pearson, described this difference succinctly. In 1925, he wrote, “Statistics may be regarded as… the study of methods of the reduction of data.” Pay attention to the words “methods,” “reduction,” and “data.” Wright abhorred the idea of statistics as merely a collection of methods; Fisher embraced it. Causal analysis is emphatically not just about data; in causal analysis we must incorporate some understanding of the process that produces the data, and then we get something that was not in the data to begin with. But Fisher was right about one point: once you remove causation from statistics, reduction of data is the only thing left.\nAlthough Crow did not mention it, Wright’s biographer William Provine points out another factor that may have affected the lack of support for path analysis. From the mid-1930s onward, Fisher considered Wright his enemy. I previously quoted Yule on how relations with Pearson became strained if you disagreed with him and impossible if you criticized him. Exactly the same thing could be said about Fisher. The latter carried out nasty feuds with anyone he disagreed with, including Pearson, Pearson’s son Egon, Jerzy Neyman (more will be said on these two in Chapter 8), and of course Wright.\nThe real focus of the Fisher-Wright rivalry was not path analysis but evolutionary biology. Fisher disagreed with Wright’s theory (called “genetic drift”) that a species can evolve rapidly when it undergoes a population bottleneck. The details of the dispute are beyond the scope of this book, and the interested reader should consult Provine. Relevant here is this: from the 1920s to the 1950s, the scientific world for the most part turned to Fisher as its oracle for statistical knowledge. And you can be certain that Fisher never said one kind word to anyone about path analysis.\nIn the 1960s, things began to change. A group of social scientists, including Otis Duncan, Hubert Blalock, and the economist Arthur Goldberger (mentioned earlier), rediscovered path analysis as a method of predicting the effect of social and educational policies. In yet another irony of history, Wright had actually been asked to speak to an influential group of econometricians called the Cowles Commission in 1947, but he utterly failed to communicate to them what path diagrams were about. Only when economists arrived at similar ideas themselves was a short-lived connection forged.\nThe fates of path analysis in economics and sociology followed different trajectories, each leading to a betrayal of Wright’s ideas. Sociologists renamed path analysis as structural equation modeling (SEM), embraced diagrams, and used them extensively until 1970, when a computer package called LISREL automated the calculation of path coefficients (in some cases). Wright would have predicted what followed: path analysis turned into a rote method, and researchers became software users with little interest in what was going on under the hood. In the late 1980s, a public challenge (by statistician David Freedman) to explain the assumptions behind SEM went unanswered, and some leading SEM experts even disavowed that SEMs had anything to do with causality.\nIn economics, the algebraic part of path analysis became known as simultaneous equation models (no acronym). Economists essentially never used path diagrams and continue not to use them to this day, relying instead on numerical equations and matrix algebra. A dire consequence of this is that, because algebraic equations are nondirectional (that is, x = y is the same as y = x), economists had no notational means to distinguish causal from regression equations and thus were unable to answer policy-related questions, even after solving the equations. As late as 1995, most economists refrained from explicitly attributing causal or counterfactual meaning to their equations.\nEven those who used structural equations for policy decisions remained incurably suspicious of diagrams, which could have saved them pages and pages of computation. Not surprisingly, some economists continue to claim that “it’s all in the data” to this very day.\nFor all these reasons, the promise of path diagrams remained only partially realized, at best, until the 1990s. In 1983, Wright himself was called back into the ring one more time to defend them, this time in the American Journal of Human Genetics. At the time he wrote this article, Wright was past ninety years old. It is both wonderful and tragic to read his essay, written in 1983, on the very same topic he had written about in 1923. How many times in the history of science have we had the privilege of hearing from a theory’s creator sixty years after he first set it down on paper? It would be like Charles Darwin coming back from the grave to testify at the Scopes Monkey Trial in 1925.\nBut it is also tragic, because in the intervening sixty years his theory should have developed, grown, and flourished; instead it had advanced little since the 1920s.\nThe motivation for Wright’s paper was a critique of path analysis, published in the same journal, by Samuel Karlin (a Stanford mathematician and recipient of the 1989 National Medal of Science, who made fundamental contributions to economics and population genetics) and two coauthors. Of interest to us are two of Karlin’s arguments.\nFirst, Karlin objects to path analysis for a reason that Niles did not raise: it assumes that all the relationships between any two variables in the path diagram are linear. This assumption allows Wright to describe the causal relationships with a single number, the path coefficient. If the equations were not linear, then the effect on Y of a one-unit change in X might depend on the current value of X. Neither Karlin nor Wright realized that a general nonlinear theory was just around the corner. (It would be developed three years later by a star student in my lab, Thomas Verma.) But Karlin’s most interesting criticism was also the one that he considered the most important: “Finally, and we think most fruitfully, one can adopt an essentially model-free approach, seeking to understand the data interactively by using a battery of displays, indices, and contrasts. This approach emphasizes the concept of robustness in interpreting results.” In this one sentence Karlin articulates how little had changed from the days of Pearson and how much influence Pearson’s ideology still had in 1983. He is saying that the data themselves already contain all scientific wisdom; they need only be cajoled and massaged (by “displays, indices, and contrasts”) into dispensing those pearls of wisdom. There is no need for our analysis to take into account the process that generated the data. We would do just as well, if not better, with a “model-free approach.” If Pearson were alive today, living in the era of Big Data, he would say exactly this: the answers are all in the data.\nOf course, Karlin’s statement violates everything we learned in Chapter 1.\nTo speak of causality, we must have a mental model of the real world. A “model-free approach” may take us to the first rung of the Ladder of Causation, but no farther.\nWright, to his great credit, understood the enormous stakes and stated in no uncertain terms, “In treating the model-free approach (3) as preferred alternative… Karlin et al. are urging not merely a change in method, but an abandonment of the purpose of path analysis and evaluation of the relative importance of varying causes. There can be no such analysis without a model.\nTheir advice to anyone with an urge to make such an evaluation is to repress it and do something else.” Wright understood that he was defending the very essence of the scientific method and the interpretation of data. I would give the same advice today to big-data, model-free enthusiasts. Of course, it is okay to tease out all the information that the data can provide, but let’s ask how far this will get us. It will never get us beyond the first rung of the Ladder of Causation, and it will never answer even as simple a question as “What is the relative importance of various causes?” E pur si muove! FROM OBJECTIVITY TO SUBJECTIVITY—THE BAYESIAN CONNECTION One other theme in Wright’s rebuttal may hint at another reason for the resistance of statisticians to causality. He repeatedly states that he did not want path analysis to become “stereotyped.” According to Wright, “The unstereotyped approach of path analysis differs profoundly from the stereotyped modes of description designed to avoid any departures from complete objectivity.” What does he mean? First, he means that path analysis should be based on the user’s personal understanding of causal processes, reflected in the causal diagram. It cannot be reduced to mechanical routines, such as those laid out in statistics manuals. For Wright, drawing a path diagram is not a statistical exercise; it is an exercise in genetics, economics, psychology, or whatever the scientist’s own field of expertise is.\nSecond, Wright traces the allure of “model-free” methods to their objectivity. This has indeed been a holy grail for statisticians since day one— or since March 15, 1834, when the Statistical Society of London was founded.\nIts founding charter said that data were to receive priority in all cases over opinions and interpretations. Data are objective; opinions are subjective. This paradigm long predates Pearson. The struggle for objectivity—the idea of reasoning exclusively from data and experiment—has been part of the way that science has defined itself ever since Galileo.\nUnlike correlation and most of the other tools of mainstream statistics, causal analysis requires the user to make a subjective commitment. She must draw a causal diagram that reflects her qualitative belief—or, better yet, the consensus belief of researchers in her field of expertise—about the topology of the causal processes at work. She must abandon the centuries-old dogma of objectivity for objectivity’s sake. Where causation is concerned, a grain of wise subjectivity tells us more about the real world than any amount of objectivity.\nIn the above paragraph, I said that “most of” the tools of statistics strive for complete objectivity. There is one important exception to this rule, though.\nA branch of statistics called Bayesian statistics has achieved growing popularity over the last fifty years or so. Once considered almost anathema, it has now gone completely mainstream, and you can attend an entire statistics conference without hearing any of the great debates between “Bayesians” and “frequentists” that used to thunder in the 1960s and 1970s.\nThe prototype of Bayesian analysis goes like this: Prior Belief + New Evidence Revised Belief. For instance, suppose you toss a coin ten times and find that in nine of those tosses the coin came up heads. Your belief that the coin is fair is probably shaken, but how much? An orthodox statistician would say, “In the absence of any additional evidence, I would believe that this coin is loaded, so I would bet nine to one that the next toss turns up heads.” A Bayesian statistician, on the other hand, would say, “Wait a minute. We also need to take into account our prior knowledge about the coin.” Did it come from the neighborhood grocery or a shady gambler? If it’s just an ordinary quarter, most of us would not let the coincidence of nine heads sway our belief so dramatically. On the other hand, if we already suspected the coin was weighted, we would conclude more willingly that the nine heads provided serious evidence of bias.\nBayesian statistics give us an objective way of combining the observed evidence with our prior knowledge (or subjective belief) to obtain a revised belief and hence a revised prediction of the outcome of the coin’s next toss.\nStill, what frequentists could not abide was that Bayesians were allowing opinion, in the form of subjective probabilities, to intrude into the pristine kingdom of statistics. Mainstream statisticians were won over only grudgingly, when Bayesian analysis proved a superior tool for a variety of applications, such as weather prediction and tracking enemy submarines. In addition, in many cases it can be proven that the influence of prior beliefs vanishes as the size of the data increases, leaving a single objective conclusion in the end.\nUnfortunately, the acceptance of Bayesian subjectivity in mainstream statistics did nothing to help the acceptance of causal subjectivity, the kind needed to specify a path diagram. Why? The answer rests on a grand linguistic barrier. To articulate subjective assumptions, Bayesian statisticians still use the language of probability, the native language of Galton and Pearson. The assumptions entering causal inference, on the other hand, require a richer language (e.g., diagrams) that is foreign to Bayesians and frequentists alike. The reconciliation between Bayesians and frequentists shows that philosophical barriers can be bridged with goodwill and a common language. Linguistic barriers are not surmounted so easily.\nMoreover, the subjective component in causal information does not necessarily diminish over time, even as the amount of data increases. Two people who believe in two different causal diagrams can analyze the same data and may never come to the same conclusion, regardless of how “big” the data are. This is a terrifying prospect for advocates of scientific objectivity, which explains their refusal to accept the inevitability of relying on subjective causal information.\nOn the positive side, causal inference is objective in one critically important sense: once two people agree on their assumptions, it provides a 100 percent objective way of interpreting any new evidence (or data). It shares this property with Bayesian inference. So the savvy reader will probably not be surprised to find out that I arrived at the theory of causality through a circuitous route that started with Bayesian probability and then took a huge detour through Bayesian networks. I will tell that story in the next chapter.\nSherlock Holmes meets his modern counterpart, a robot equipped with a Bayesian network. In different ways both are tackling the question of how to infer causes from observations. The formula on the computer screen is Bayes’s rule. (Source: Drawing by Maayan Harel.)",
    "crumbs": [
      "Causal Inference",
      "The book of why"
    ]
  },
  {
    "objectID": "extracted/The Book of Why - Judea Pearl.html#from-evidence-to-causes-reverend-bayes-meets-mr.-holmes",
    "href": "extracted/The Book of Why - Judea Pearl.html#from-evidence-to-causes-reverend-bayes-meets-mr.-holmes",
    "title": "The book of why",
    "section": "3. FROM EVIDENCE TO CAUSES: REVEREND BAYES MEETS MR. HOLMES",
    "text": "3. FROM EVIDENCE TO CAUSES: REVEREND BAYES MEETS MR. HOLMES\nDo two men travel together unless they have agreed?\nDoes the lion roar in the forest if he has no prey? —AMOS 3:3 “I T’S elementary, my dear Watson.” So spoke Sherlock Holmes (at least in the movies) just before dazzling his faithful assistant with one of his famously nonelementary deductions. But in fact, Holmes performed not just deduction, which works from a hypothesis to a conclusion. His great skill was induction, which works in the opposite direction, from evidence to hypothesis.\nAnother of his famous quotes suggests his modus operandi: “When you have eliminated the impossible, whatever remains, however improbable, must be the truth.” Having induced several hypotheses, Holmes eliminated them one by one in order to deduce (by elimination) the correct one. Although induction and deduction go hand in hand, the former is by far the more mysterious. This fact kept detectives like Sherlock Holmes in business.\nHowever, in recent years experts in artificial intelligence (AI) have made considerable progress toward automating the process of reasoning from evidence to hypothesis and likewise from effect to cause. I was fortunate enough to participate in the very earliest stages of this progress by developing one of its basic tools, called Bayesian networks. This chapter explains what these are, looks at some of their current-day applications, and discusses the circuitous route by which they led me to study causation.\nBONAPARTE, THE COMPUTER DETECTIVE On July 17, 2014, Malaysia Airlines Flight 17 took off from Amsterdam’s Schiphol Airport, bound for Kuala Lumpur. Alas, the airplane never reached its destination. Three hours into the flight, as the jet flew over eastern Ukraine, it was shot down by a Russian-made surface-to-air missile. All 298 people on board, 283 passengers and 15 crew members, were killed.\nJuly 23, the day the first bodies arrived in the Netherlands, was declared a national day of mourning. But for investigators at the Netherlands Forensic Institute (NFI) in The Hague, July 23 was the day when the clock started ticking. Their job was to identify the remains of the deceased as quickly as possible and return them to their loved ones for burial. Time was of the essence, because every day of uncertainty would bring fresh anguish to the grieving families.\nThe investigators faced many obstacles. The bodies had been badly burned, and many were stored in formaldehyde, which breaks down DNA.\nAlso, because eastern Ukraine was a war zone, forensics experts had only sporadic access to the crash site. Newly recovered remains continued to arrive for ten more months. Finally, the investigators did not have previous records of the victims’ DNA, for the simple reason that the victims were not criminals. They would have to rely instead on partial matches with family members.\nFortunately, the scientists at NFI had a powerful tool working in their favor, a state-of-the-art disaster victim identification program called Bonaparte. This software, developed in the mid-2000s by a team from Radboud University in Nijmegen, uses Bayesian networks to combine DNA information taken from several different family members of the victims.\nThanks in part to Bonaparte’s accuracy and speed, the NFI managed to identify remains from 294 of the 298 victims by December 2014. As of 2016, only two victims of the crash (both Dutch citizens) have vanished without a trace.\nBayesian networks, the machine-reasoning tool that underlies the Bonaparte software, affect our lives in many ways that most people are not aware of. They are used in speech-recognition software, in spam filters, in weather forecasting, in the evaluation of potential oil wells, and in the Food and Drug Administration’s approval process for medical devices. If you play video games on a Microsoft Xbox, a Bayesian network ranks your skill. If you own a cell phone, the codes that your phone uses to pick your call out of thousands of others are decoded by belief propagation, an algorithm devised for Bayesian networks. Vint Cerf, the chief Internet evangelist at another company you might have heard of, Google, puts it this way: “We’re huge consumers of Bayesian methods.” In this chapter I will tell the story of Bayesian networks from their roots in the eighteenth century to their development in the 1980s, and I will give some more examples of how they are used today. They are related to causal diagrams in a simple way: a causal diagram is a Bayesian network in which every arrow signifies a direct causal relation, or at least the possibility of one, in the direction of that arrow. Not all Bayesian networks are causal, and in many applications it does not matter. However, if you ever want to ask a rung- two or rung-three query about your Bayesian network, you must draw it with scrupulous attention to causality.\nREVEREND BAYES AND THE PROBLEM OF INVERSE PROBABILITY Thomas Bayes, after whom I named the networks in 1985, never dreamed that a formula he derived in the 1750s would one day be used to identify disaster victims. He was concerned only with the probabilities of two events, one (the hypothesis) occurring before the other (the evidence). Nevertheless, causality was very much on his mind. In fact, causal aspirations were the driving force behind his analysis of “inverse probability.” A Presbyterian minister who lived from 1702 to 1761, the Reverend Thomas Bayes appears to have been a mathematics geek. As a dissenter from the Church of England, he could not study at Oxford or Cambridge and was educated instead at the University of Scotland, where he likely picked up quite a bit of math. He continued to dabble in it and organize math discussion circles after he returned to England.\nIn an article published after his death (see Figure 3.1), Bayes tackled a problem that was the perfect match for him, pitting math against theology. To set the context, in 1748, the Scottish philosopher David Hume had written an essay titled “On Miracles,” in which he argued that eyewitness testimony could never prove that a miracle had happened. The miracle Hume had in mind was, of course, the resurrection of Christ, although he was smart enough not to say so. (Twenty years earlier, theologian Thomas Woolston had gone to prison for blasphemy for writing such things.) Hume’s main point was that inherently fallible evidence cannot overrule a proposition with the force of natural law, such as “Dead people stay dead.” F 3.1. Title page of the journal where Thomas Bayes’s posthumous article on IGURE inverse probability was published and the first page of Richard Price’s introduction.\nFor Bayes, this assertion provoked a natural, one might say Holmesian question: How much evidence would it take to convince us that something we consider improbable has actually happened? When does a hypothesis cross the line from impossibility to improbability and even to probability or virtual certainty? Although the question was phrased in the language of probability, the implications were intentionally theological. Richard Price, a fellow minister who found the essay among Bayes’s possessions after his death and sent it for publication with a glowing introduction that he wrote himself, made this point abundantly clear: The purpose I mean is, to shew what reason we have for believing that there are in the constitution of things fixt laws according to which things happen, and that, therefore, the frame of the world must be the effect of the wisdom and power of an intelligent cause; and thus to confirm the argument taken from final causes for the existence of the Deity. It will be easy to see that the converse problem solved in this essay is more directly applicable to this purpose; for it shews us, with distinctness and precision, in every case of any particular order or recurrency of events, what reason there is to think that such recurrency or order is derived from stable causes or regulations in nature, and not from any irregularities of chance.\nBayes himself did not discuss any of this in his paper; Price highlighted these theological implications, perhaps to make the impact of his friend’s paper more far-reaching. But it turned out that Bayes didn’t need the help. His paper is remembered and argued about 250 years later, not for its theology but because it shows that you can deduce the probability of a cause from an effect. If we know the cause, it is easy to estimate the probability of the effect, which is a forward probability. Going the other direction—a problem known in Bayes’s time as “inverse probability”—is harder. Bayes did not explain why it is harder; he took that as self-evident, proved that it is doable, and showed us how.\nTo appreciate the nature of the problem, let’s look at the example he suggested himself in his posthumous paper of 1763. Imagine that we shoot a billiard ball on a table, making sure that it bounces many times so that we have no idea where it will end up. What is the probability that it will stop within x feet of the left-hand end of the table? If we know the length of the table and it is perfectly smooth and flat, this is a very easy question (Figure 3.2, top). For example, on a twelve-foot snooker table, the probability of the ball stopping within a foot of the end would be 1/12. On an eight-foot billiard table, the probability would be 1/8.\nF 3.2. Thomas Bayes’s pool table example. In the first version, a forward- IGURE probability question, we know the length of the table and want to calculate the probability of the ball stopping within x feet of the end. In the second, an inverse- probability question, we observe that the ball stopped x feet from the end and want to estimate the likelihood that the table’s length is L. (Source: Drawing by Maayan Harel.) Our intuitive understanding of the physics tells us that, in general, if the length of the table is L feet, the probability of the ball’s stopping within x feet of the end is x/L. The longer the table length (L), the lower the probability, because there are more positions competing for the honor of being the ball’s resting place. On the other hand, the larger x is, the higher the probability, because it includes a larger set of stopping positions.\nNow consider the inverse-probability problem. We observe the final position of the ball to be x = 1 foot from the end, but we are not given the length L (Figure 3.2, bottom). Reverend Bayes asked, What is the probability that the length was, say, one hundred feet? Common sense tells us that L is more likely to be fifty feet than one hundred feet, because the longer table makes it harder to explain why the ball ended up so close to the end. But how much more likely is it? “Intuition” or “common sense” gives us no clear guidance.\nWhy was the forward probability (of x given L) so much easier to assess mentally than the probability of L given x? In this example, the asymmetry comes from the fact that L acts as the cause and x is the effect. If we observe a cause—for example, Bobby throws a ball toward a window—most of us can predict the effect (the ball will probably break the window). Human cognition works in this direction. But given the effect (the window is broken), we need much more information to deduce the cause (which boy threw the ball that broke it or even the fact that it was broken by a ball in the first place). It takes the mind of a Sherlock Holmes to keep track of all the possible causes. Bayes set out to break this cognitive asymmetry and explain how even ordinary humans can assess inverse probabilities.\nTo see how Bayes’s method works, let’s start with a simple example about customers in a teahouse, for whom we have data documenting their preferences. Data, as we know from Chapter 1, are totally oblivious to cause- effect asymmetries and hence should offer us a way to resolve the inverse- probability puzzle.\nSuppose two-thirds of the customers who come to the shop order tea, and half of the tea drinkers also order scones. What fraction of the clientele orders both tea and scones? There’s no trick to this question, and I hope that the answer is almost obvious. Because half of two-thirds is one-third, it follows that one-third of the customers order both tea and scones.\nFor a numerical illustration, suppose that we tabulate the orders of the next twelve customers who come in the door. As Table 3.1 shows, two-thirds of the customers (1, 5, 6, 7, 8, 9, 10, 12) ordered tea, and one-half of those people ordered scones (1, 5, 8, 12). So the proportion of customers who ordered both tea and scones is indeed (1/2) × (2/3) = 1/3, just as we predicted prior to seeing the specific data.\nTABLE 3.1. Fictitious data for the tea-scones example.\nThe starting point for Bayes’s rule is to notice that we could have analyzed the data in the reverse order. That is, we could have observed that five- twelfths of the customers (1, 2, 5, 8, 12) ordered scones, and four-fifths of these (1, 5, 8, 12) ordered tea. So the proportion of customers who ordered both tea and scones is (4/5) × (5/12) = 1/3. Of course it’s no coincidence that it came out the same; we were merely computing the same quantity in two different ways. The temporal order in which the customers announce their order makes no difference.\nTo make this a general rule, we can let P(T) denote the probability that a customer orders tea and P(S) denote the probability he orders scones. If we already know a customer has ordered tea, then P(S | T) denotes the probability that he orders scones. (Remember that the vertical line stands for “given that.”) Likewise, P(T | S) denotes the probability that he orders tea, given that we already know he ordered scones. Then the first calculation we did says, P(S AND T) = P(S | T) P(T).\nThe second calculation says, P(S AND T) = P(T | S) P(S).\nNow, as Euclid said 2,300 years ago, two things that each equal a third thing also equal one another. That means it must be the case that P(S | T) P(T) = P(T | S) P(S) (3.1) This innocent-looking equation came to be known as “Bayes’s rule.” If we look carefully at what it says, we find that it offers a general solution to the inverse-probability problem. It tells us that if we know the probability of S given T, P(S | T), we ought to be able to figure out the probability of T given S, P(T | S), assuming of course that we know P(T) and P(S). This is perhaps the most important role of Bayes’s rule in statistics: we can estimate the conditional probability directly in one direction, for which our judgment is more reliable, and use mathematics to derive the conditional probability in the other direction, for which our judgment is rather hazy. The equation also plays this role in Bayesian networks; we tell the computer the forward probabilities, and the computer tells us the inverse probabilities when needed.\nTo see how Bayes’s rule works in the teahouse example, suppose you didn’t bother to calculate P(T | S) and left your spreadsheet containing the data at home. However, you happen to remember that half of those who order tea also order scones, and two-thirds of the customers order tea and five- twelfths order scones. Unexpectedly, your boss asks you, “But what proportion of scone eaters order tea?” There’s no need to panic, because you can work it out from the other probabilities. Bayes’s rule says that P(T | S) (5/12) = (1/2)(2/3), so your answer is P(T | S) = 4/5, because 4/5 is the only value for P(T | S) that will make this equation true.\nWe can also look at Bayes’s rule as a way to update our belief in a particular hypothesis. This is extremely important to understand, because a large part of human belief about future events rests on the frequency with which they or similar events have occurred in the past. Indeed, when a customer walks in the door of the restaurant, we believe, based on our past encounters with similar customers, that she probably wants tea. But if she first orders scones, we become even more certain. In fact, we might even suggest it: “I presume you want tea with that?” Bayes’s rule simply lets us attach numbers to this reasoning process. From Table 3.1, we see that the prior probability that the customer wants tea (meaning when she walks in the door, before she orders anything) is two-thirds. But if the customer orders scones, now we have additional information about her that we didn’t have before. The updated probability that she wants tea, given that she has ordered scones, is P(T | S) = 4/5.\nMathematically, that’s all there is to Bayes’s rule. It seems almost trivial. It involves nothing more than the concept of conditional probability, plus a little dose of ancient Greek logic. You might justifiably ask how such a simple gimmick could make Bayes famous and why people have argued over his rule for 250 years. After all, mathematical facts are supposed to settle controversies, not create them.\nHere I must confess that in the teahouse example, by deriving Bayes’s rule from data, I have glossed over two profound objections, one philosophical and the other practical. The philosophical one stems from the interpretation of probabilities as a degree of belief, which we used implicitly in the teahouse example. Who ever said that beliefs act, or should act, like proportions in the data? The crux of the philosophical debate is whether we can legitimately translate the expression “given that I know” into the language of probabilities.\nEven if we agree that the unconditional probabilities P(S), P(T), and P(S AND T) reflect my degree of belief in those propositions, who says that my revised degree of belief in T should equal the ratio P(S AND T)/P(T), as dictated by Bayes’s rule? Is “given that I know T” the same as “among cases where T occurred”? The language of probability, expressed in symbols like P(S), was intended to capture the concept of frequencies in games of chance.\nBut the expression “given that I know” is epistemological and should be governed by the logic of knowledge, not that of frequencies and proportions.\nFrom the philosophical perspective, Thomas Bayes’s accomplishment lies in his proposing the first formal definition of conditional probability as the ratio P(S | T) = P(S AND T)/P(T). His essay was admittedly hazy; he has no term “conditional probability” and instead uses the cumbersome language “the probability of the 2nd [event] on supposition that the 1st happens.” The recognition that the relation “given that” deserves its own symbol evolved only in the 1880s, and it was not until 1931 that Harold Jeffreys (known more as a geophysicist than a probability theorist) introduced the now standard vertical bar in P(S | T).\nAs we saw, Bayes’s rule is formally an elementary consequence of his definition of conditional probability. But epistemologically, it is far from elementary. It acts, in fact, as a normative rule for updating beliefs in response to evidence. In other words, we should view Bayes’s rule not just as a convenient definition of the new concept of “conditional probability” but as an empirical claim to faithfully represent the English expression “given that I know.” It asserts, among other things, that the belief a person attributes to S after discovering T is never lower than the degree of belief that person attributes to S AND T before discovering T. Also, it implies that the more surprising the evidence T—that is, the smaller P(T) is—the more convinced one should become of its cause S. No wonder Bayes and his friend Price, as Episcopal ministers, saw this as an effective rejoinder to Hume. If T is a miracle (“Christ rose from the dead”), and S is a closely related hypothesis (“Christ is the son of God”), our degree of belief in S is very dramatically increased if we know for a fact that T is true. The more miraculous the miracle, the more credible the hypothesis that explains its occurrence. This explains why the writers of the New Testament were so impressed by their eyewitness evidence.\nNow let me discuss the practical objection to Bayes’s rule—which may be even more consequential when we exit the realm of theology and enter the realm of science. If we try to apply the rule to the billiard-ball puzzle, in order to find P(L | x) we need a quantity that is not available to us from the physics of billiard balls: we need the prior probability of the length L, which is every bit as tough to estimate as our desired P(L | x). Moreover, this probability will vary significantly from person to person, depending on a given individual’s previous experience with tables of different lengths. A person who has never in his life seen a snooker table would be very doubtful that L could be longer than ten feet. A person who has only seen snooker tables and never seen a billiard table would, on the other hand, give a very low prior probability to L being less than ten feet. This variability, also known as “subjectivity,” is sometimes seen as a deficiency of Bayesian inference. Others regard it as a powerful advantage; it permits us to express our personal experience mathematically and combine it with data in a principled and transparent way.\nBayes’s rule informs our reasoning in cases where ordinary intuition fails us or where emotion might lead us astray. We will demonstrate this power in a situation familiar to all of us.\nSuppose you take a medical test to see if you have a disease, and it comes back positive. How likely is it that you have the disease? For specificity, let’s say the disease is breast cancer, and the test is a mammogram. In this example the forward probability is the probability of a positive test, given that you have the disease: P(test | disease). This is what a doctor would call the “sensitivity” of the test, or its ability to correctly detect an illness. Generally it is the same for all types of patients, because it depends only on the technical capability of the testing instrument to detect the abnormalities associated with the disease. The inverse probability is the one you surely care more about: What is the probability that I have the disease, given that the test came out positive? This is P(disease | test), and it represents a flow of information in the noncausal direction, from the result of the test to the probability of disease. This probability is not necessarily the same for all types of patients; we would certainly view the positive test with more alarm in a patient with a family history of the disease than in one with no such history.\nNotice that we have started to talk about causal and noncausal directions.\nWe didn’t do that in the teahouse example because it did not matter which came first, ordering tea or ordering scones. It only mattered which conditional probability we felt more capable of assessing. But the causal setting clarifies why we feel less comfortable assessing the “inverse probability,” and Bayes’s essay makes clear that this is exactly the sort of problem that interested him.\nSuppose a forty-year-old woman gets a mammogram to check for breast cancer, and it comes back positive. The hypothesis, D (for “disease”), is that she has cancer. The evidence, T (for “test”), is the result of the mammogram.\nHow strongly should she believe the hypothesis? Should she have surgery? We can answer these questions by rewriting Bayes’s rule as follows: (Updated probability of D) = P(D | T) = (likelihood ratio) × (prior probability of D) (3.2) where the new term “likelihood ratio” is given by P(T | D)/P(T). It measures how much more likely the positive test is in people with the disease than in the general population. Equation 3.2 therefore tells us that the new evidence T augments the probability of D by a fixed ratio, no matter what the prior probability was.\nLet’s do an example to see how this important concept works. For a typical forty-year-old woman, the probability of getting breast cancer in the next year is about one in seven hundred, so we’ll use that as our prior probability.\nTo compute the likelihood ratio, we need to know P(T | D) and P(T). In the medical context, P(T | D) is the sensitivity of the mammogram—the probability that it will come back positive if you have cancer. According to the Breast Cancer Surveillance Consortium (BCSC), the sensitivity of mammograms for forty-year-old women is 73 percent.\nThe denominator, P(T), is a bit trickier. A positive test, T, can come both from patients who have the disease and from patients who don’t. Thus, P(T) should be a weighted average of P(T | D) (the probability of a positive test among those who have the disease) and P(T | ~D) (the probability of a positive test among those who don’t). The second is known as the false positive rate. According to the BCSC, the false positive rate for forty-year-old women is about 12 percent.\nWhy a weighted average? Because there are many more healthy women (~D) than women with cancer (D). In fact, only 1 in 700 women has cancer, and the other 699 do not, so the probability of a positive test for a randomly chosen woman should be much more strongly influenced by the 699 women who don’t have cancer than by the one woman who does.\nMathematically, we compute the weighted average as follows: P(T) = (1/700) × (73 percent) + (699/700) × (12 percent) ≈ 12.1 percent. The weights come about because only 1 in 700 women has a 73 percent chance of a positive test, and the other 699 have a 12 percent chance. Just as you might expect, P(T) came out very close to the false positive rate.\nNow that we know P(T), we finally can compute the updated probability —the woman’s chances of having breast cancer after the test comes back positive. The likelihood ratio is 73 percent/12.1 percent ≈ 6. As I said before, this is the factor by which we augment her prior probability to compute her updated probability of having cancer. Since her prior probability was one in seven hundred, her updated probability is 6 × 1/700 ≈ 1/116. In other words, she still has less than a 1 percent chance of having cancer.\nThe conclusion is startling. I think that most forty-year-old women who have a positive mammogram would be astounded to learn that they still have less than a 1 percent chance of having breast cancer. Figure 3.3 might make the reason easier to understand: the tiny number of true positives (i.e., women with breast cancer) is overwhelmed by the number of false positives. Our sense of surprise at this result comes from the common cognitive confusion between the forward probability, which is well studied and thoroughly documented, and the inverse probability, which is needed for personal decision making.\nThe conflict between our perception and reality partially explains the outcry when the US Preventive Services Task Force, in 2009, recommended that forty-year-old women should not get annual mammograms. The task force understood what many women did not: a positive test at that age is way more likely to be a false alarm than to detect cancer, and many women were unnecessarily terrified (and getting unnecessary treatment) as a result.\nF 3.3. In this example, based on false-positive and false-negative rates IGURE provided by the Breast Cancer Surveillance Consortium, only 3 out of 363 forty- year-old women who test positive for breast cancer actually have the disease.\n(Proportions do not exactly match the text because of rounding.) (Source: Infographic by Maayan Harel.) However, the story would be very different if our patient had a gene that put her at high risk for breast cancer—say, a one-in-twenty chance within the next year. Then a positive test would increase the probability to almost one in three. For a woman in this situation, the chances that the test provides lifesaving information are much higher. That is why the task force continued to recommend annual mammograms for high-risk women.\nThis example shows that P(disease | test) is not the same for everyone; it is context dependent. If you know that you are at high risk for a disease to begin with, Bayes’s rule allows you to factor that information in. Or if you know that you are immune, you need not even bother with the test! In contrast, P(test | disease) does not depend on whether you are at high risk or not. It is “robust” to such variations, which explains to some degree why physicians organize their knowledge and communicate with forward probabilities. The former are properties of the disease itself, its stage of progression, or the sensitivity of the detecting instruments; hence they remain relatively invariant to the reasons for the disease (epidemic, diet, hygiene, socioeconomic status, family history). The inverse probability, P(disease | test), is sensitive to these conditions.\nThe history-minded reader will surely wonder how Bayes handled the subjectivity of P(L), where L is the length of a billiard table. The answer has two parts. First, Bayes was interested not in the length of the table per se but in its future consequences (i.e., the probability that the next ball would end up at some specified location on the table). Second, Bayes assumed that L is determined mechanically by shooting a billiard ball from a greater distance, say L*. In this way he bestowed objectivity onto P(L) and transformed the problem into one where prior probabilities are estimable from data, as we see in the teahouse and cancer test examples.\nIn many ways, Bayes’s rule is a distillation of the scientific method. The textbook description of the scientific method goes something like this: (1) formulate a hypothesis, (2) deduce a testable consequence of the hypothesis, (3) perform an experiment and collect evidence, and (4) update your belief in the hypothesis. Usually the textbooks deal with simple yes-or-no tests and updates; the evidence either confirms or refutes the hypothesis. But life and science are never so simple! All evidence comes with a certain amount of uncertainty. Bayes’s rule tells us how to perform step (4) in the real world.\nFROM BAYES’S RULE TO BAYESIAN NETWORKS In the early 1980s, the field of artificial intelligence had worked itself into a cul-de-sac. Ever since Alan Turing first laid out the challenge in his 1950 paper “Computing Machinery and Intelligence,” the leading approach to AI had been so-called rule-based systems or expert systems, which organize human knowledge as a collection of specific and general facts, along with inference rules to connect them. For example: Socrates is a man (specific fact). All men are mortals (general fact). From this knowledge base we (or an intelligent machine) can derive the fact that Socrates is a mortal, using the universal rule of inference: if all A’s are B’s, and x is an A, then x is a B.\nThe approach was fine in theory, but hard-and-fast rules can rarely capture real-life knowledge. Perhaps without realizing it, we deal with exceptions to rules and uncertainties in evidence all the time. By 1980, it was clear that expert systems struggled with making correct inferences from uncertain knowledge. The computer could not replicate the inferential process of a human expert because the experts themselves were not able to articulate their thinking process within the language provided by the system.\nThe late 1970s, then, were a time of ferment in the AI community over the question of how to deal with uncertainty. There was no shortage of ideas.\nLotfi Zadeh of Berkeley offered “fuzzy logic,” in which statements are neither true nor false but instead take a range of possible truth values. Glen Shafer of the University of Kansas proposed “belief functions,” which assign two probabilities to each fact, one indicating how likely it is to be “possible,” the other, how likely it is to be “provable.” Edward Feigenbaum and his colleagues at Stanford University tried “certainty factors,” which inserted numerical measures of uncertainty into their deterministic rules for inference.\nUnfortunately, although ingenious, these approaches suffered a common flaw: they modeled the expert, not the world, and therefore tended to produce unintended results. For example, they could not operate in both diagnostic and predictive modes, the uncontested specialty of Bayes’s rule. In the certainty factor approach, the rule “If fire, then smoke (with certainty c )” could not 1 combine coherently with “If smoke, then fire (with certainty c )” without 2 triggering a runaway buildup of belief.\nProbability was also considered at the time but immediately fell into ill repute, since the demands on storage space and processing time became formidable. I entered the arena rather late, in 1982, with an obvious yet radical proposal: instead of reinventing a new uncertainty theory from scratch, let’s keep probability as a guardian of common sense and merely repair its computational deficiencies. More specifically, instead of representing probability in huge tables, as was previously done, let’s represent it with a network of loosely coupled variables. If we only allow each variable to interact with a few neighboring variables, then we might overcome the computational hurdles that had caused other probabilists to stumble.\nThe idea did not come to me in a dream; it came from an article by David Rumelhart, a cognitive scientist at University of California, San Diego, and a pioneer of neural networks. His article about children’s reading, published in 1976, made clear that reading is a complex process in which neurons on many different levels are active at the same time (see Figure 3.4). Some of the neurons are simply recognizing individual features—circles or lines. Above them, another layer of neurons is combining these shapes and forming conjectures about what the letter might be. In Figure 3.4, the network is struggling with a great deal of ambiguity about the second word. At the letter level, it could be “FHP,” but that doesn’t make much sense at the word level.\nAt the word level it could be “FAR” or “CAR” or “FAT.” The neurons pass this information up to the syntactic level, which decides that after the word “THE,” it’s expecting a noun. Finally this information gets passed all the way up to the semantic level, which realizes that the previous sentence mentioned a Volkswagen, so the phrase is likely to be “THE CAR,” referring to that same Volkswagen. The key point is that all the neurons are passing information back and forth, from the top down and from the bottom up and from side to side. It’s a highly parallel system, and one that is quite different from our self-perception of the brain as a monolithic, centrally controlled system.\nReading Rumelhart’s paper, I felt convinced that any artificial intelligence would have to model itself on what we know about human neural information processing and that machine reasoning under uncertainty would have to be constructed with a similar message-passing architecture. But what are the messages? This took me quite a few months to figure out. I finally realized that the messages were conditional probabilities in one direction and likelihood ratios in the other.\nF 3.4. David Rumelhart’s sketch of how a message-passing network would IGURE learn to read the phrase “THE CAR.” (Source: Courtesy of Center for Brain and Cognition, University of California, San Diego.) More precisely, I assumed that the network would be hierarchical, with arrows pointing from higher neurons to lower ones, or from “parent nodes” to “child nodes.” Each node would send a message to all its neighbors (both above and below in the hierarchy) about its current degree of belief about the variable it tracked (e.g., “I’m two-thirds certain that this letter is an R”). The recipient would process the message in two different ways, depending on its direction. If the message went from parent to child, the child would update its beliefs using conditional probabilities, like the ones we saw in the teahouse example. If the message went from child to parent, the parent would update its beliefs by multiplying them by a likelihood ratio, as in the mammogram example.\nApplying these two rules repeatedly to every node in the network is called belief propagation. In retrospect there is nothing arbitrary or invented about these rules; they are in strict compliance with Bayes’s rule. The real challenge was to ensure that no matter in what order these messages are sent out, things will settle eventually into a comfortable equilibrium; moreover, the final equilibrium will represent the correct state of belief in the variables. By “correct” I mean, as if we had conducted the computation by textbook methods rather than by message passing.\nThis challenge would occupy my students and me, as well as my colleagues, for several years. But by the end of the 1980s, we had resolved the difficulties to the point that Bayesian networks had become a practical scheme for machine learning. The next decade saw a continual increase in real-world applications, such as spam filtering and voice recognition.\nHowever, by then I was already trying to climb the Ladder of Causation, while entrusting the probabilistic side of Bayesian networks to the safekeeping of others.\nBAYESIAN NETWORKS: WHAT CAUSES SAY ABOUT DATA Although Bayes didn’t know it, his rule for inverse probability represents the simplest Bayesian network. We have seen this network in several guises now: Tea Scones, Disease Test, or, more generally, Hypothesis Evidence.\nUnlike the causal diagrams we will deal with throughout the book, a Bayesian network carries no assumption that the arrow has any causal meaning. The arrow merely signifies that we know the “forward” probability, P(scones | tea) or P(test | disease). Bayes’s rule tells us how to reverse the procedure, specifically by multiplying the prior probability by a likelihood ratio.\nBelief propagation formally works in exactly the same way whether the arrows are noncausal or causal. Nevertheless, you may have the intuitive feeling that we have done something more meaningful in the latter case than in the former. That is because our brains are endowed with special machinery for comprehending cause-effect relationships (such as cancer and mammograms). Not so for mere associations (such as tea and scones).\nThe next step after a two-node network with one link is, of course, a three- node network with two links, which I will call a “junction.” These are the building blocks of all Bayesian networks (and causal networks as well). There are three basic types of junctions, with the help of which we can characterize any pattern of arrows in the network.\n\nA B C. This junction is the simplest example of a “chain,” or of mediation. In science, one often thinks of B as the mechanism, or “mediator,” that transmits the effect of A to C. A familiar example is Fire Smoke Alarm. Although we call them “fire alarms,” they are really smoke alarms. The fire by itself does not set off an alarm, so there is no direct arrow from Fire to Alarm. Nor does the fire set off the alarm through any other variable, such as heat. It works only by releasing smoke molecules in the air. If we disable that link in the chain, for instance by sucking all the smoke molecules away with a fume hood, then there will be no alarm.\n\nThis observation leads to an important conceptual point about chains: the mediator B “screens off” information about A from C, and vice versa. (This was first pointed out by Hans Reichenbach, a German-American philosopher of science.) For example, once we know the value of Smoke, learning about Fire does not give us any reason to raise or lower our belief in Alarm. This stability of belief is a rung-one concept; hence it should also be seen in the data, when it is available. Suppose we had a database of all the instances when there was fire, when there was smoke, or when the alarm went off. If we looked at only the rows where Smoke = 1, we would expect Alarm = 1 every time, regardless of whether Fire = 0 or Fire = 1. This screening-off pattern still holds if the effect is not deterministic. For example, imagine a faulty alarm system that fails to respond correctly 5 percent of the time. If we look only at the rows where Smoke = 1, we will find that the probability of Alarm = 1 is the same (95 percent), regardless of whether Fire = 0 or Fire = 1.\nThe process of looking only at rows in the table where Smoke = 1 is called conditioning on a variable. Likewise, we say that Fire and Alarm are conditionally independent, given the value of Smoke. This is important to know if you are programming a machine to update its beliefs; conditional independence gives the machine a license to focus on the relevant information and disregard the rest. We all need this kind of license in our everyday thinking, or else we will spend all our time chasing false signals. But how do we decide which information to disregard, when every new piece of information changes the boundary between the relevant and the irrelevant? For humans, this understanding comes naturally. Even three- year-old toddlers understand the screening-off effect, though they don’t have a name for it. Their instinct must have come from some mental representation, possibly resembling a causal diagram. But machines do not have this instinct, which is one reason that we equip them with causal diagrams.\n\nA B C. This kind of junction is called a “fork,” and B is often called a common cause or confounder of A and C. A confounder will make A and C statistically correlated even though there is no direct causal link between them. A good example (due to David Freedman) is Shoe Size Age of Child Reading Ability. Children with larger shoes tend to read at a higher level. But the relationship is not one of cause and effect.\n\nGiving a child larger shoes won’t make him read better! Instead, both variables are explained by a third, which is the child’s age. Older children have larger shoes, and they also are more advanced readers.\nWe can eliminate this spurious correlation, as Karl Pearson and George Udny Yule called it, by conditioning on the child’s age. For instance, if we look only at seven-year-olds, we expect to see no relationship between shoe size and reading ability. As in the case of chain junctions, A and C are conditionally independent, given B.\nBefore we go on to our third junction, we need to add a word of clarification. The conditional independences I have just mentioned are exhibited whenever we look at these junctions in isolation. If additional causal paths surround them, these paths need also be taken into account. The miracle of Bayesian networks lies in the fact that the three kinds of junctions we are now describing in isolation are sufficient for reading off all the independencies implied by a Bayesian network, regardless of how complicated.\n\nA B C. This is the most fascinating junction, called a “collider.” Felix Elwert and Chris Winship have illustrated this junction using three features of Hollywood actors: Talent Celebrity Beauty. Here we are asserting that both talent and beauty contribute to an actor’s success, but beauty and talent are completely unrelated to one another in the general population.\n\nWe will now see that this collider pattern works in exactly the opposite way from chains or forks when we condition on the variable in the middle. If A and C are independent to begin with, conditioning on B will make them dependent. For example, if we look only at famous actors (in other words, we observe the variable Celebrity = 1), we will see a negative correlation between talent and beauty: finding out that a celebrity is unattractive increases our belief that he or she is talented.\nThis negative correlation is sometimes called collider bias or the “explain-away” effect. For simplicity, suppose that you don’t need both talent and beauty to be a celebrity; one is sufficient. Then if Celebrity A is a particularly good actor, that “explains away” his success, and he doesn’t need to be any more beautiful than the average person. On the other hand, if Celebrity B is a really bad actor, then the only way to explain his success is his good looks. So, given the outcome Celebrity = 1, talent and beauty are inversely related—even though they are not related in the population as a whole. Even in a more realistic situation, where success is a complicated function of beauty and talent, the explain-away effect will still be present.\nThis example is admittedly somewhat apocryphal, because beauty and talent are hard to measure objectively; nevertheless, collider bias is quite real, and we will see lots of examples in this book.\nThese three junctions—chains, forks, and colliders—are like keyholes through the door that separates the first and second levels of the Ladder of Causation. If we peek through them, we can see the secrets of the causal process that generated the data we observe; each stands for a distinct pattern of causal flow and leaves its mark in the form of conditional dependences and independences in the data. In my public lectures I often call them “gifts from the gods” because they enable us to test a causal model, discover new models, evaluate effects of interventions, and much more. Still, standing in isolation, they give us only a glimpse. We need a key that will completely open the door and let us step out onto the second rung. That key, which we will learn about in Chapter 7, involves all three junctions, and is called d-separation. This concept tells us, for any given pattern of paths in the model, what patterns of dependencies we should expect in the data. This fundamental connection between causes and probabilities constitutes the main contribution of Bayesian networks to the science of causal inference.\nWHERE IS MY BAG? FROM AACHEN TO ZANZIBAR So far I have emphasized only one aspect of Bayesian networks—namely, the diagram and its arrows that preferably point from cause to effect. Indeed, the diagram is like the engine of the Bayesian network. But like any engine, a Bayesian network runs on fuel. The fuel is called a conditional probability table.\nAnother way to put this is that the diagram describes the relation of the variables in a qualitative way, but if you want quantitative answers, you also need quantitative inputs. In a Bayesian network, we have to specify the conditional probability of each node given its “parents.” (Remember that the parents of a node are all the nodes that feed into it.) These are the forward probabilities, P(evidence | hypotheses).\nIn the case where A is a root node, with no arrows pointing into it, we need only specify the prior probability for each state of A. In our second network, Disease Test, Disease is a root node. Therefore we specified the prior probability that a person has the disease (1/700 in our example) and that she does not have the disease (699/700 in our example).\nBy depicting A as a root node, we do not really mean that A has no prior causes. Hardly any variable is entitled to such a status. We really mean that any prior causes of A can be adequately summarized in the prior probability P(A) that A is true. For example, in the Disease Test example, family history might be a cause of Disease. But as long as we are sure that this family history will not affect the variable Test (once we know the status of Disease), we need not represent it as a node in the graph. However, if there is a cause of Disease that also directly affects Test, then that cause must be represented explicitly in the diagram.\nIn the case where the node A has a parent, A has to “listen” to its parent before deciding on its own state. In our mammogram example, the parent of Test was Disease. We can show this “listening” process with a 2 × 2 table (see Table 3.2). For example, if Test “hears” that D = 0, then 88 percent of the time it will take the value T = 0, and 12 percent of the time it will take the value T = 1. Notice that the second column of this table contains the same information we saw earlier from the Breast Cancer Surveillance Consortium: the false positive rate (upper right corner) is 12 percent, and the sensitivity (lower right corner) is 73 percent. The remaining two entries are filled in to make each row sum to 100 percent.\nTABLE 3.2. A simple conditional probability table.\nAs we move to more complicated networks, the conditional probability table likewise gets more complicated. For example, if we have a node with two parents, the conditional probability table has to take into account the four possible states of both parents. Let’s look at a concrete example, suggested by Stefan Conrady and Lionel Jouffe of BayesiaLab, Inc. It’s a scenario familiar to all travelers: we can call it “Where Is My Bag?” Suppose you’ve just landed in Zanzibar after making a tight connection in Aachen, and you’re waiting for your suitcase to appear on the carousel. Other passengers have started to get their bags, but you keep waiting… and waiting… and waiting. What are the chances that your suitcase did not actually make the connection from Aachen to Zanzibar? The answer depends, of course, on how long you have been waiting. If the bags have just started to show up on the carousel, perhaps you should be patient and wait a little bit longer. If you’ve been waiting a long time, then things are looking bad. We can quantify these anxieties by setting up a causal diagram (Figure 3.5).\nF 3.5. Causal diagram for airport/bag example.\nIGURE This diagram reflects the intuitive idea that there are two causes for the appearance of any bag on the carousel. First, it had to be on the plane to begin with; otherwise, it will certainly never appear on the carousel. Second, the presence of the bag on the carousel becomes more likely as time passes… provided it was actually on the plane.\nTo turn the causal diagram into a Bayesian network, we have to specify the conditional probability tables. Let’s say that all the bags at Zanzibar airport get unloaded within ten minutes. (They are very efficient in Zanzibar!) Let’s also suppose that the probability your bag made the connection, P(bag on plane = true) is 50 percent. (I apologize if this offends anybody who works at the Aachen airport. I am only following Conrady and Jouffe’s example.\nPersonally, I would prefer to assume a higher prior probability, like 95 percent.) The real workhorse of this Bayesian network is the conditional probability table for “Bag on Carousel” (see Table 3.3).\nThis table, though large, should be easy to understand. The first eleven rows say that if your bag didn’t make it onto the plane (bag on plane = false) then, no matter how much time has elapsed, it won’t be on the carousel (carousel = false). That is, P(carousel = false | bag on plane = false) is 100 percent. That is the meaning of the 100s in the first eleven rows.\nThe other eleven rows say that the bags are unloaded from the plane at a steady rate. If your bag is indeed on the plane, there is a 10 percent probability it will be unloaded in the first minute, a 10 percent probability in the second minute, and so forth. For example, after 5 minutes there is a 50 percent probability it has been unloaded, so we see a 50 for P(carousel = true | bag on plane = true, time = 5). After ten minutes, all the bags have been unloaded, so P(carousel = true | bag on plane = true, time = 10) is 100 percent. Thus we see a 100 in the last entry of the table.\nThe most interesting thing to do with this Bayesian network, as with most Bayesian networks, is to solve the inverse-probability problem: if x minutes have passed and I still haven’t gotten my bag, what is the probability that it was on the plane? Bayes’s rule automates this computation and reveals an interesting pattern. After one minute, there is still a 47 percent chance that it was on the plane. (Remember that our prior assumption was a 50 percent probability.) After five minutes, the probability drops to 33 percent. After ten minutes, of course, it drops to zero. Figure 3.6 shows a plot of the probability over time, which one might call the “Curve of Abandoning Hope.” To me the interesting thing is that it is a curve: I think that most people would expect it to be a straight line. It actually sends us a pretty optimistic message: don’t give up hope too soon! According to this curve, you should abandon only one-third of your hope in the first half of the allotted time.\nTABLE 3.3. A more complicated conditional probability table.\nF 3.6. The probability of seeing your bag on the carousel decreases slowly at IGURE first, then more rapidly. (Source: Graph by Maayan Harel, data from Stefan Conrady and Lionel Jouffe.) Besides a life lesson, we’ve learned that you don’t want to do this by hand.\nEven with this tiny network of three nodes, there were 2 × 11 = 22 parent states, each contributing to the probability of the child state. For a computer, though, such computations are elementary… up to a point. If they aren’t done in an organized fashion, the sheer number of computations can overwhelm even the fastest supercomputer. If a node has ten parents, each of which has two states, the conditional probability table will have more than 1,000 rows.\nAnd if each of the ten parents has ten states, the table will have 10 billion rows! For this reason one usually has to winnow the connections in the network so that only the most important ones remain and the network is “sparse.” One technical advance in the development of Bayesian networks entailed finding ways to leverage sparseness in the network structure to achieve reasonable computation times.\nBAYESIAN NETWORKS IN THE REAL WORLD Bayesian networks are by now a mature technology, and you can buy off-the- shelf Bayesian network software from several companies. Bayesian networks are also embedded in many “smart” devices. To give you an idea of how they are used in real-world applications, let’s return to the Bonaparte DNA- matching software with which we began this chapter.\nThe Netherlands Forensic Institute uses Bonaparte every day, mostly for missing-persons cases, criminal investigations, and immigration cases.\n(Applicants for asylum must prove that they have fifteen family members in the Netherlands.) However, the Bayesian network does its most impressive work after a massive disaster, such as the crash of Malaysia Airlines Flight 17.\nFew, if any, of the victims of the plane crash could be identified by comparing DNA from the wreckage to DNA in a central database. The next best thing to do was to ask family members to provide DNA swabs and look for partial matches to the DNA of the victims. Conventional (non-Bayesian) methods can do this and have been instrumental in solving a number of cold cases in the Netherlands, the United States, and elsewhere. For example, a simple formula called the “Paternity Index” or the “Sibling Index” can estimate the likelihood that the unidentified DNA comes from the father or the brother of the person whose DNA was tested.\nHowever, these indices are inherently limited because they work for only one specified relation and only for close relations. The idea behind Bonaparte is to make it possible to use DNA information from more distant relatives or from multiple relatives. Bonaparte does this by converting the pedigree of the family (see Figure 3.7) into a Bayesian network.\nIn Figure 3.8, we see how Bonaparte converts one small piece of a pedigree to a (causal) Bayesian network. The central problem is that the genotype of an individual, detected in a DNA test, contains a contribution from both the father and the mother, but we cannot tell which part is which.\nThus these two contributions (called “alleles”) have to be treated as hidden, unmeasurable variables in the Bayesian network. Part of Bonaparte’s job is to infer the probability of the cause (the victim’s gene for blue eyes came from his father) from the evidence (e.g., he has a blue-eyed gene and a black-eyed gene; his cousins on the father’s side have blue eyes, but his cousins on the mother’s side have black eyes). This is an inverse-probability problem—just what Bayes’s rule was invented for.\nF 3.7. Actual pedigree of a family with multiple victims in the Malaysia IGURE Airlines crash. (Source: Data provided by Willem Burgers.) F 3.8. From DNA tests to Bayesian networks. In Bayesian network, unshaded IGURE nodes represent alleles, and shaded nodes represent genotypes. Data are only available on shaded nodes because genotypes cannot indicate which allele came from the father and which from the mother. The Bayesian network enables inference on the unobserved nodes and also allows us to estimate the likelihood that a given DNA sample came from the child. (Source: Infographic by Maayan Harel.) Once the Bayesian network is set up, the final step is to input the victim’s DNA and compute the likelihood that it fits into a specific slot in the pedigree.\nThis is done by belief propagation with Bayes’s rule. The network begins with a particular degree of belief in each possible statement about the nodes in the network, such as “this person’s paternal allele for eye color is blue.” As new evidence is entered into the network—at any place in the network—the degrees of belief at every node, up and down the network, will change in a cascading fashion. Thus, for example, once we find out that a given sample is a likely match for one person in the pedigree, we can propagate that information up and down the network. In this way, Bonaparte not only learns from the living family members’ DNA but also from the identifications it has already made.\nThis example vividly illustrates a number of advantages of Bayesian networks. Once the network is set up, the investigator does not need to intervene to tell it how to evaluate a new piece of data. The updating can be done very quickly. (Bayesian networks are especially good for programming on a distributed computer.) The network is integrative, which means that it reacts as a whole to any new information. That’s why even DNA from an aunt or a second cousin can help identify the victim. Bayesian networks are almost like a living organic tissue, which is no accident because this is precisely the picture I had in mind when I was struggling to make them work. I wanted Bayesian networks to operate like the neurons of a human brain; you touch one neuron, and the entire network responds by propagating the information to every other neuron in the system.\nThe transparency of Bayesian networks distinguishes them from most other approaches to machine learning, which tend to produce inscrutable “black boxes.” In a Bayesian network you can follow every step and understand how and why each piece of evidence changed the network’s beliefs.\nAs elegant as Bonaparte is, it’s worth noting one feature it does not (yet) incorporate: human intuition. Once it has finished the analysis, it provides the NFI’s experts with a ranking of the most likely identifications for each DNA sample and a likelihood ratio for each. The investigators are then free to combine the DNA evidence with other physical evidence recovered from the crash site, as well as their intuition, to make their final determinations. At present, no identifications are made by the computer acting alone. One goal of causal inference is to create a smoother human-machine interface, which might allow the investigators’ intuition to join the belief propagation dance.\nThis example of DNA identification with Bonaparte only scratches the surface of the applications of Bayesian networks to genomics. However, I would like to move on to a second application that has become ubiquitous in today’s society. In fact, there is a very good chance that you have a Bayesian network in your pocket right now. It’s called a cell phone, every one of which uses error-correction algorithms based on belief propagation.\nTo begin at the beginning, when you talk into a phone, it converts your beautiful voice into a string of ones and zeros (called bits) and transmits these using a radio signal. Unfortunately, no radio signal is received with perfect fidelity. As the signal makes its way to the cell tower and then to your friend’s phone, some random bits will flip from zero to one or vice versa.\nTo correct these errors, we can add redundant information. An ultrasimple scheme for error correction is simply to repeat each information bit three times: encode a one as “111” and a zero as “000.” The valid strings “111” and “000” are called codewords. If the receiver hears an invalid string, such as “101,” it will search for the most likely valid codeword to explain it. The zero is more likely to be wrong than both ones, so the decoder will interpret this message as “111” and therefore conclude that the information bit was a one.\nAlas, this code is highly inefficient, because it makes all our messages three times longer. However, communication engineers have worked for seventy years on finding better and better error-correcting codes.\nThe problem of decoding is identical to the other inverse-probability problems we have discussed, because we once again want to infer the probability of a hypothesis (the message sent was “Hello world!”) from evidence (the message received was “Hxllo wovld!”). The situation seems ripe for an application of belief propagation.\nIn 1993, an engineer for France Telecom named Claude Berrou stunned the coding world with an error-correcting code that achieved near-optimal performance. (In other words, the amount of redundant information required is close to the theoretical minimum.) His idea, called a “turbo code,” can be best illustrated by representing it with a Bayesian network.\nFigure 3.9(a) shows how a traditional code works. The information bits, which you speak into the phone, are shown in the first row. They are encoded, using any code you like—call it code A—into codewords (second row), which are then received with some errors (third row). This diagram is a Bayesian network, and we can use belief propagation to infer from the received bits what the information bits were. However, this would not in any way improve on code A.\nBerrou’s brilliant idea was to encode each message twice, once directly and once after scrambling the message. This results in the creation of two separate codewords and the receipt of two noisy messages (Figure 3.9b).\nThere is no known formula for directly decoding such a dual message. But Berrou showed empirically that if you apply the belief propagation formulas on Bayesian networks repeatedly, two amazing things happen. Most of the time (and by this I mean something like 99.999 percent of the time) you get the correct information bits. Not only that, you can use much shorter codewords. To put it simply, two copies of code A are way better than one.\nF 3.9. (a) Bayesian network representation of ordinary coding process.\nIGURE Information bits are transformed into codewords; these are transmitted and received at the destination with noise (errors). (b) Bayesian network representation of turbo code. Information bits are scrambled and encoded twice. Decoding proceeds by belief propagation on this network. Each processor at the bottom uses information from the other processor to improve its guess of the hidden codeword, in an iterative process.\nThis capsule history is correct except for one thing: Berrou did not know that he was working with Bayesian networks! He had simply discovered the belief propagation algorithm himself. It wasn’t until five years later that David MacKay of Cambridge realized that it was the same algorithm that he had been enjoying in the late 1980s while playing with Bayesian networks.\nThis placed Berrou’s algorithm in a familiar theoretical context and allowed information theorists to sharpen their understanding of its performance.\nIn fact, another engineer, Robert Gallager of the Massachusetts Institute of Technology, had discovered a code that used belief propagation (though not called by that name) way back in 1960, so long ago that MacKay describes his code as “almost clairvoyant.” In any event, it was too far ahead of its time.\nGallager needed thousands of processors on a chip, passing messages back and forth about their degree of belief that a particular information bit was a one or a zero. In 1960 this was impossible, and his code was virtually forgotten until MacKay rediscovered it in 1998. Today, it is in every cell phone.\nBy any measure, turbo codes have been a staggering success. Before the turbo revolution, 2G cell phones used “soft decoding” (i.e., probabilities) but not belief propagation. 3G cell phones used Berrou’s turbo codes, and 4G phones used Gallager’s turbo-like codes. From the consumer’s viewpoint, this means that your cell phone uses less energy and the battery lasts longer, because coding and decoding are your cell phone’s most energy-intensive processes. Also, better codes mean that you do not have to be as close to a cell tower to get high-quality transmission. In other words, Bayesian networks enabled phone manufacturers to deliver on their promise: more bars in more places.\nFROM BAYESIAN NETWORKS TO CAUSAL DIAGRAMS After a chapter devoted to Bayesian networks, you might wonder how they relate to the rest of this book and in particular to causal diagrams, the kind we met in Chapter 1. Of course, I have discussed them in such detail in part because they were my personal route into causality. But more importantly from both a theoretical and practical point of view, Bayesian networks hold the key that enables causal diagrams to interface with data. All the probabilistic properties of Bayesian networks (including the junctions we discussed earlier in this chapter) and the belief propagation algorithms that were developed for them remain valid in causal diagrams. They are in fact indispensable for understanding causal inference.\nThe main differences between Bayesian networks and causal diagrams lie in how they are constructed and the uses to which they are put. A Bayesian network is literally nothing more than a compact representation of a huge probability table. The arrows mean only that the probabilities of child nodes are related to the values of parent nodes by a certain formula (the conditional probability tables) and that this relation is sufficient. That is, knowing additional ancestors of the child will not change the formula. Likewise, a missing arrow between any two nodes means that they are independent, once we know the values of their parents. We saw a simple version of this statement earlier, when we discussed the screening-off effect in chains and links. In a chain A B C, the missing arrow between A and C means that A and C are independent once we know the values of their parents. Because A has no parents, and the only parent of C is B, it follows that A and C are independent once we know the value of B, which agrees with what we said before.\nIf, however, the same diagram has been constructed as a causal diagram, then both the thinking that goes into the construction and the interpretation of the final diagram change. In the construction phase, we need to examine each variable, say C, and ask ourselves which other variables it “listens” to before choosing its value. The chain structure A B C means that B listens to A only, C listens to B only, and A listens to no one; that is, it is determined by external forces that are not part of our model.\nThis listening metaphor encapsulates the entire knowledge that a causal network conveys; the rest can be derived, sometimes by leveraging data. Note that if we reverse the order of arrows in the chain, thus obtaining A B C, the causal reading of the structure will change drastically, but the independence conditions will remain the same. The missing arrow between A and C will still mean that A and C are independent once we know the value of B, as in the original chain. This has two enormously important implications.\nFirst, it tells us that causal assumptions cannot be invented at our whim; they are subject to the scrutiny of data and can be falsified. For instance, if the observed data do not show A and C to be independent, conditional on B, then we can safely conclude that the chain model is incompatible with the data and needs to be discarded (or repaired). Second, the graphical properties of the diagram dictate which causal models can be distinguished by data and which will forever remain indistinguishable, no matter how large the data. For example, we cannot distinguish the fork A B C from the chain A B C by data alone, because the two diagrams imply the same independence conditions.\nAnother convenient way of thinking about the causal model is in terms of hypothetical experiments. Each arrow can be thought of as a statement about the outcome of a hypothetical experiment. An arrow from A to C means that if we could wiggle only A, then we would expect to see a change in the probability of C. A missing arrow from A to C means that in the same experiment we would not see any change in C, once we held constant the parents of C (in other words, B in the example above). Note that the probabilistic expression “once we know the value of B” has given way to the causal expression “once we hold B constant,” which implies that we are physically preventing B from varying and disabling the arrow from A to B.\nThe causal thinking that goes into the construction of the causal network will pay off, of course, in the type of questions the network can answer.\nWhereas a Bayesian network can only tell us how likely one event is, given that we observed another (rung-one information), causal diagrams can answer interventional and counterfactual questions. For example, the causal fork A B C tells us in no uncertain terms that wiggling A would have no effect on C, no matter how intense the wiggle. On the other hand, a Bayesian network is not equipped to handle a “wiggle,” or to tell the difference between seeing and doing, or indeed to distinguish a fork from a chain. In other words, both a chain and a fork would predict that observed changes in A are associated with changes in C, making no prediction about the effect of “wiggling” A.\nNow we come to the second, and perhaps more important, impact of Bayesian networks on causal inference. The relationships that were discovered between the graphical structure of the diagram and the data that it represents now permit us to emulate wiggling without physically doing so.\nSpecifically, applying a smart sequence of conditioning operations enables us to predict the effect of actions or interventions without actually conducting an experiment. To demonstrate, consider again the causal fork A B C, in which we proclaimed the correlation between A and C to be spurious. We can verify this by an experiment in which we wiggle A and find no correlation between A and C. But we can do better. We can ask the diagram to emulate the experiment and tell us if any conditioning operation can reproduce the correlation that would prevail in the experiment. The answer would come out affirmative: “The correlation between A and C that would be measured after conditioning on B would equal the correlation seen in the experiment.” This correlation can be estimated from the data, and in our case it would be zero, faithfully confirming our intuition that wiggling A would have no effect on C.\nThis ability to emulate interventions by smart observations could not have been acquired had the statistical properties of Bayesian networks not been unveiled between 1980 and 1988. We can now decide which set of variables we must measure in order to predict the effects of interventions from observational studies. We can also answer “Why?” questions. For example, someone may ask why wiggling A makes C vary. Is it really the direct effect of A, or is it the effect of a mediating variable B? If both, can we assess what portion of the effect is mediated by B? To answer such mediation questions, we have to envision two simultaneous interventions: wiggling A and holding B constant (to be distinguished from conditioning on B). If we can perform this intervention physically, we obtain the answer to our question. But if we are at the mercy of observational studies, we need to emulate the two actions with a clever set of observations. Again, the graphical structure of the diagram will tell us whether this is possible.\nAll these capabilities were still in the future in 1988, when I started thinking about how to marry causation to diagrams. I only knew that Bayesian networks, as then conceived, could not answer the questions I was asking.\nThe realization that you cannot even tell A B C apart from A B C from data alone was a painful frustration.\nI know that you, the reader, are eager now to learn how causal diagrams enable us to do calculations like the ones I have just described. And we will get there—in Chapters 7 through 9. But we are not ready yet, because the moment we start talking about observational versus experimental studies, we leave the relatively friendly waters of the AI community for the much stormier waters of statistics, which have been stirred up by its unhappy divorce from causality. In retrospect, fighting for the acceptance of Bayesian networks in AI was a picnic—no, a luxury cruise!—compared with the fight I had to wage for causal diagrams. That battle is still ongoing, with a few remaining islands of resistance.\nTo navigate these new waters, we will have to understand the ways in which orthodox statisticians have learned to address causation and the limitations of those methods. The questions we raised above, concerning the effect of interventions, including direct and indirect effects, are not part of mainstream statistics, primarily because the field’s founding fathers purged it of the language of cause and effect. But statisticians nevertheless consider it permissible to talk about causes and effects in one situation: a randomized controlled trial (RCT) in which a treatment A is randomly assigned to some individuals and not to others and the observed changes in B are then compared. Here, both orthodox statistics and causal inference agree on the meaning of the sentence “A causes B.” Before we turn to the new science of cause and effect—illuminated by causal models—we should first try to understand the strengths and limitations of the old, model-blind science: why randomization is needed to conclude that A causes B and the nature of the threat (called “confounding”) that RCTs are intended to disarm. The next chapter takes up these topics. In my experience, most statisticians as well as modern data analysts are not comfortable with any of these questions, since they cannot articulate them using a data-centric vocabulary. In fact, they often disagree on what “confounding” means! After we examine these issues in the light of causal diagrams, we can place randomized controlled trials into their proper context. Either we can view them as a special case of our inference engine, or we can view causal inference as a vast extension of RCTs. Either viewpoint is fine, and perhaps people trained to see RCTs as the arbiter of causation will find the latter more congenial.\nThe biblical story of Daniel, often cited as the first controlled experiment. Daniel (third from left?) realized that a proper comparison of two diets could only be made when they were given to two groups of similar individuals, chosen in advance. King Nebuchadnezzar (rear) was impressed with the results. (Source: Drawing by Dakota Harr.)",
    "crumbs": [
      "Causal Inference",
      "The book of why"
    ]
  },
  {
    "objectID": "extracted/The Book of Why - Judea Pearl.html#confounding-and-deconfounding-or-slaying-the-lurking-variable",
    "href": "extracted/The Book of Why - Judea Pearl.html#confounding-and-deconfounding-or-slaying-the-lurking-variable",
    "title": "The book of why",
    "section": "4. CONFOUNDING AND DECONFOUNDING: OR, SLAYING THE LURKING VARIABLE",
    "text": "4. CONFOUNDING AND DECONFOUNDING: OR, SLAYING THE LURKING VARIABLE\nIf our conception of causal effects had anything to do with randomized\nexperiments, the latter would have been invented 500 years before Fisher.\n—THE AUTHOR (2016) A SHPENAZ, the overseer of King Nebuchadnezzar’s court, had a major problem. In 597 BC, the king of Babylon had sacked the kingdom of Judah and brought back thousands of captives, many of them the nobility of Jerusalem. As was customary in his kingdom, Nebuchadnezzar wanted some of them to serve in his court, so he commanded Ashpenaz to seek out “children in whom was no blemish, but well favoured, and skilful in all wisdom, and cunning in knowledge, and understanding science.” These lucky children were to be educated in the language and culture of Babylon so that they could serve in the administration of the empire, which stretched from the Persian Gulf to the Mediterranean Sea. As part of their education, they would get to eat royal meat and drink royal wine.\nAnd therein lay the problem. One of his favorites, a boy named Daniel, refused to touch the food. For religious reasons, he could not eat meat not prepared according to Jewish laws, and he asked that he and his friends be given a diet of vegetables instead. Ashpenaz would have liked to comply with the boy’s wishes, but he was afraid that the king would notice: “Once he sees your frowning faces, different from the other children your age, it will cost me my head.” Daniel tried to assure Ashpenaz that the vegetarian diet would not diminish their capacity to serve the king. As befits a person “cunning in knowledge, and understanding science,” he proposed an experiment. Try us for ten days, he said. Take four of us and feed us only vegetables; take another group of children and feed them the king’s meat and wine. After ten days, compare the two groups. Said Daniel, “And as thou seest, deal with thy servants.” Even if you haven’t read the story, you can probably guess what happened next. Daniel and his three companions prospered on the vegetarian diet. The king was so impressed with their wisdom and learning—not to mention their healthy appearance—that he gave them a favored place in his court, where “he found them ten times better than all the magicians and astrologers that were in all his realm.” Later Daniel became an interpreter of the king’s dreams and survived a memorable encounter in a lion’s den.\nBelieve it or not, the biblical story of Daniel encapsulates in a profound way the conduct of experimental science today. Ashpenaz asks a question about causation: Will a vegetarian diet cause my servants to lose weight? Daniel proposes a methodology to deal with any such questions: Set up two groups of people, identical in all relevant ways. Give one group a new treatment (a diet, a drug, etc.), while the other group (called the control group) either gets the old treatment or no special treatment at all. If, after a suitable amount of time, you see a measurable difference between the two supposedly identical groups of people, then the new treatment must be the cause of the difference.\nNowadays we call this a controlled experiment. The principle is simple. To understand the causal effect of the diet, we would like to compare what happens to Daniel on one diet with what would have happened if he had stayed on the other. But we can’t go back in time and rewrite history, so instead we do the next best thing: we compare a group of people who get the treatment with a group of similar people who don’t. It’s obvious, but nevertheless crucial, that the groups be comparable and representative of some population. If these conditions are met, then the results should be transferable to the population at large. To Daniel’s credit, he seems to understand this. He isn’t just asking for vegetables on his own behalf: if the trial shows the vegetarian diet is better, then all the Israelite servants should be allowed that diet in the future. That, at least, is how I interpret the phrase, “As thou seest, deal with thy servants.” Daniel also understood that it was important to compare groups. In this respect he was already more sophisticated than many people today, who choose a fad diet (for example) just because a friend went on that diet and lost weight. If you choose a diet based only on one friend’s experience, you are essentially saying that you believe you are similar to your friend in all relevant details: age, heredity, home environment, previous diet, and so forth.\nThat is a lot to assume.\nAnother key point of Daniel’s experiment is that it was prospective: the groups were chosen in advance. By contrast, suppose that you see twenty people in an infomercial who all say they lost weight on a diet. That seems like a pretty large sample size, so some viewers might consider it convincing evidence. But that would amount to basing their decision on the experience of people who already had a good response. For all you know, for every person who lost weight, ten others just like him or her tried the diet and had no success. But of course, they weren’t chosen to appear on the infomercial.\nDaniel’s experiment was strikingly modern in all these ways. Prospective controlled trials are still a hallmark of sound science. However, Daniel didn’t think of one thing: confounding bias. Suppose that Daniel and his friends are healthier than the control group to start with. In that case, their robust appearance after ten days on the diet may have nothing to do with the diet itself; it may reflect their overall health. Maybe they would have prospered even more if they had eaten the king’s meat! Confounding bias occurs when a variable influences both who is selected for the treatment and the outcome of the experiment. Sometimes the confounders are known; other times they are merely suspected and act as a “lurking third variable.” In a causal diagram, confounders are extremely easy to recognize: in Figure 4.1, the variable Z at the center of the fork is a confounder of X and Y. (We will see a more universal definition later, but this triangle is the most recognizable and common situation.) F 4.1. The most basic version of confounding: Z is a confounder of the IGURE proposed causal relationship between X and Y.\nThe term “confounding” originally meant “mixing” in English, and we can understand from the diagram why this name was chosen. The true causal effect X Y is “mixed” with the spurious correlation between X and Y induced by the fork X Z Y. For example, if we are testing a drug and give it to patients who are younger on average than the people in the control group, then age becomes a confounder—a lurking third variable. If we don’t have any data on the ages, we will not be able to disentangle the true effect from the spurious effect.\nHowever, the converse is also true. If we do have measurements of the third variable, then it is very easy to deconfound the true and spurious effects.\nFor instance, if the confounding variable Z is age, we compare the treatment and control groups in every age group separately. We can then take an average of the effects, weighting each age group according to its percentage in the target population. This method of compensation is familiar to all statisticians; it is called “adjusting for Z” or “controlling for Z.” Oddly, statisticians both over- and underrate the importance of adjusting for possible confounders. They overrate it in the sense that they often control for many more variables than they need to and even for variables that they should not control for. I recently came across a quote from a political blogger named Ezra Klein who expresses this phenomenon of “overcontrolling” very clearly: “You see it all the time in studies. ‘We controlled for…’ And then the list starts. The longer the better. Income. Age. Race. Religion. Height. Hair color. Sexual preference. Crossfit attendance. Love of parents. Coke or Pepsi.\nThe more things you can control for, the stronger your study is—or, at least, the stronger your study seems. Controls give the feeling of specificity, of precision.… But sometimes, you can control for too much. Sometimes you end up controlling for the thing you’re trying to measure.” Klein raises a valid concern. Statisticians have been immensely confused about what variables should and should not be controlled for, so the default practice has been to control for everything one can measure. The vast majority of studies conducted in this day and age subscribe to this practice. It is a convenient, simple procedure to follow, but it is both wasteful and ridden with errors. A key achievement of the Causal Revolution has been to bring an end to this confusion.\nAt the same time, statisticians greatly underrate controlling in the sense that they are loath to talk about causality at all, even if the controlling has been done correctly. This too stands contrary to the message of this chapter: if you have identified a sufficient set of deconfounders in your diagram, gathered data on them, and properly adjusted for them, then you have every right to say that you have computed the causal effect X Y (provided, of course, that you can defend your causal diagram on scientific grounds).\nThe textbook approach of statisticians to confounding is quite different and rests on an idea most effectively advocated by R. A. Fisher: the randomized controlled trial (RCT). Fisher was exactly right, but not for exactly the right reasons. The randomized controlled trial is indeed a wonderful invention—but until recently the generations of statisticians who followed Fisher could not prove that what they got from the RCT was indeed what they sought to obtain. They did not have a language to write down what they were looking for—namely, the causal effect of X on Y. One of my goals in this chapter is to explain, from the point of view of causal diagrams, precisely why RCTs allow us to estimate the causal effect X Y without falling prey to confounder bias. Once we have understood why RCTs work, there is no need to put them on a pedestal and treat them as the gold standard of causal analysis, which all other methods should emulate. Quite the opposite: we will see that the so-called gold standard in fact derives its legitimacy from more basic principles.\nThis chapter will also show that causal diagrams make possible a shift of emphasis from confounders to deconfounders. The former cause the problem; the latter cure it. The two sets may overlap, but they don’t have to. If we have data on a sufficient set of deconfounders, it does not matter if we ignore some or even all of the confounders.\nThis shift of emphasis is a main way in which the Causal Revolution allows us to go beyond Fisherian experiments and infer causal effects from nonexperimental studies. It enables us to determine which variables should be controlled for to serve as deconfounders. This question has bedeviled both theoretical and practical statisticians; it has been an Achilles’ heel of the field for decades. That is because it has nothing to do with data or statistics.\nConfounding is a causal concept—it belongs on rung two of the Ladder of Causation.\nGraphical methods, beginning in the 1990s, have totally deconfounded the confounding problem. In particular, we will soon meet a method called the back-door criterion, which unambiguously identifies which variables in a causal diagram are deconfounders. If the researcher can gather data on those variables, she can adjust for them and thereby make predictions about the result of an intervention even without performing it.\nIn fact, the Causal Revolution has gone even farther than this. In some cases we can control for confounding even when we do not have data on a sufficient set of deconfounders. In these cases we can use different adjustment formulas—not the conventional one, which is only appropriate for use with the back-door criterion—and still eradicate all confounding. We will save these exciting developments for Chapter 7.\nAlthough confounding has a long history in all areas of science, the recognition that the problem requires causal, not statistical, solutions is very recent. Even as recently as 2001, reviewers rebuked a paper of mine while insisting, “Confounding is solidly founded in standard statistics.” Fortunately, the number of such reviewers has shrunk dramatically in the past decade.\nThere is now an almost universal consensus, at least among epidemiologists, philosophers, and social scientists, that (1) confounding needs and has a causal solution, and (2) causal diagrams provide a complete and systematic way of finding that solution. The age of confusion over confounding has come to an end! THE CHILLING FEAR OF CONFOUNDING In 1998, a study in the New England Journal of Medicine revealed an association between regular walking and reduced death rates among retired men. The researchers used data from the Honolulu Heart Program, which has followed the health of 8,000 men of Japanese ancestry since 1965.\nThe researchers, led by Robert Abbott, a biostatistician at the University of Virginia, wanted to know whether the men who exercised more lived longer.\nThey chose a sample of 707 men from the larger group of 8,000, all of whom were physically healthy enough to walk. Abbott’s team found that the death rate over a twelve-year period was two times higher among men who walked less than a mile a day (I’ll call them “casual walkers”) than among men who walked more than two miles a day (“intense walkers”). To be precise, 43 percent of the casual walkers had died, while only 21.5 percent of the intense walkers had died.\nHowever, because the experimenters did not prescribe who would be a casual walker and who would be an intense walker, we have to take into consideration the possibility of confounding bias. An obvious confounder might be age: younger men might be more willing to do a vigorous workout and also would be less likely to die. So we would have a causal diagram like that in Figure 4.2.\nF 4.2. Causal diagram for walking example.\nIGURE The classic forking pattern at the “Age” node tells us that age is a confounder of walking and mortality. I’m sure you can think of other possible confounders. Perhaps the casual walkers were slacking off for a reason; maybe they couldn’t walk as much. Thus, physical condition could be a confounder. We could go on and on like this. What if the light walkers were alcohol drinkers? What if they ate more? The good news is, the researchers thought about all these factors. The study has accounted and adjusted for every reasonable factor—age, physical condition, alcohol consumption, diet, and several others. For example, it’s true that the intense walkers tended to be slightly younger. So the researchers adjusted the death rate for age and found that the difference between casual and intense walkers was still very large. (The age-adjusted death rate for the casual walkers was 41 percent, compared to 24 percent for the intense walkers.) Even so, the researchers were very circumspect in their conclusions. At the end of the article, they wrote, “Of course, the effects on longevity of intentional efforts to increase the distance walked per day by physically capable older men cannot be addressed in our study.” To use the language of Chapter 1, they decline to say anything about your probability of surviving twelve years given that you do(exercise).\nIn fairness to Abbott and the rest of his team, they may have had good reasons for caution. This was a first study, and the sample was relatively small and homogeneous. Nevertheless, this caution reflects a more general attitude, transcending issues of homogeneity and sample size. Researchers have been taught to believe that an observational study (one where subjects choose their own treatment) can never illuminate a causal claim. I assert that this caution is overexaggerated. Why else would one bother adjusting for all these confounders, if not to get rid of the spurious part of the association and thereby get a better view of the causal part? Instead of saying “Of course we can’t,” as they did, we should proclaim that of course we can say something about an intentional intervention. If we believe that Abbott’s team identified all the important confounders, we must also believe that intentional walking tends to prolong life (at least in Japanese males).\nThis provisional conclusion, predicated on the assumption that no other confounders could play a major role in the relationships found, is an extremely valuable piece of information. It tells a potential walker precisely what kind of uncertainty remains in taking the claim at face value. It tells him that the remaining uncertainty is not higher than the possibility that additional confounders exist that were not taken into account. It is also valuable as a guide to future studies, which should focus on those other factors (if they exist), not the ones neutralized in the current study. In short, knowing the set of assumptions that stand behind a given conclusion is not less valuable than attempting to circumvent those assumptions with an RCT, which, as we shall see, has complications of its own.\nTHE SKILLFUL INTERROGATION OF NATURE: WHY RCTS WORK As I have mentioned already, the one circumstance under which scientists will abandon some of their reticence to talk about causality is when they have conducted a randomized controlled trial. You can read it on Wikipedia or in a thousand other places: “The RCT is often considered the gold standard of a clinical trial.” We have one person to thank for this, R. A. Fisher, so it is very interesting to read what a person very close to him wrote about his reasons.\nThe passage is lengthy, but worth quoting in full: The whole art and practice of scientific experimentation is comprised in the skillful interrogation of Nature. Observation has provided the scientist with a picture of Nature in some aspect, which has all the imperfections of a voluntary statement. He wishes to check his interpretation of this statement by asking specific questions aimed at establishing causal relationships. His questions, in the form of experimental operations, are necessarily particular, and he must rely on the consistency of Nature in making general deductions from her response in a particular instance or in predicting the outcome to be anticipated from similar operations on other occasions. His aim is to draw valid conclusions of determinate precision and generality from the evidence he elicits.\nFar from behaving consistently, however, Nature appears vacillating, coy, and ambiguous in her answers. She responds to the form of the question as it is set out in the field and not necessarily to the question in the experimenter’s mind; she does not interpret for him; she gives no gratuitous information; and she is a stickler for accuracy.\nIn consequence, the experimenter who wants to compare two manurial treatments wastes his labor if, dividing his field into two equal parts, he dresses each half with one of his manures, grows a crop, and compares the yields from the two halves. The form of his question was: what is the difference between the yield of plot A under the first treatment and that of plot B under the second? He has not asked whether plot A would yield the same as plot B under uniform treatment, and he cannot distinguish plot effects from treatment effects, for Nature has recorded, as requested, not only the contribution of the manurial differences to the plot yields but also the contributions of differences in soil fertility, texture, drainage, aspect, microflora, and innumerable other variables.\nThe author of this passage is Joan Fisher Box, the daughter of Ronald Aylmer Fisher, and it is taken from her biography of her illustrious father.\nThough not a statistician herself, she has clearly absorbed very deeply the central challenge statisticians face. She states in no uncertain terms that the questions they ask are “aimed at establishing causal relationships.” And what gets in their way is confounding, although she does not use that word. They want to know the effect of a fertilizer (or “manurial treatment,” as fertilizers were called in that era)—that is, the expected yield under one fertilizer compared with the yield under an alternative. Nature, however, tells them about the effect of the fertilizer mixed (remember, this is the original meaning of “confounded”) with a variety of other causes.\nI like the image that Fisher Box provides in the above passage: Nature is like a genie that answers exactly the question we pose, not necessarily the one we intend to ask. But we have to believe, as Fisher Box clearly does, that the answer to the question we wish to ask does exist in nature. Our experiments are a sloppy means of uncovering the answer, but they do not by any means define the answer. If we follow her analogy exactly, then do(X = x) must come first, because it is a property of nature that represents the answer we seek: What is the effect of using the first fertilizer on the whole field? Randomization comes second, because it is only a man-made means to elicit the answer to that question. One might compare it to the gauge on a thermometer, which is a means to elicit the temperature but is not the temperature itself.\nIn his early years at Rothamsted Experimental Station, Fisher usually took a very elaborate, systematic approach to disentangling the effects of fertilizer from other variables. He would divide his fields into a grid of subplots and plan carefully so that each fertilizer was tried with each combination of soil type and plant (see Figure 4.3). He did this to ensure the comparability of each sample; in reality, he could never anticipate all the confounders that might determine the fertility of a given plot. A clever enough genie could defeat any structured layout of the field.\nAround 1923 or 1924, Fisher began to realize that the only experimental design that the genie could not defeat was a random one. Imagine performing the same experiment one hundred times on a field with an unknown distribution of fertility. Each time you assign fertilizers to subplots randomly.\nSometimes you may be very unlucky and use Fertilizer 1 in all the least fertile subplots. Other times you may get lucky and apply it to the most fertile subplots. But by generating a new random assignment each time you perform the experiment, you can guarantee that the great majority of the time you will be neither lucky nor unlucky. In those cases, Fertilizer 1 will be applied to a selection of subplots that is representative of the field as a whole. This is exactly what you want for a controlled trial. Because the distribution of fertility in the field is fixed throughout your series of experiments—the genie can’t change it—he is tricked into answering (most of the time) the causal question you wanted to ask.\nF 4.3. R. A. Fisher with one of his many innovations: a Latin square IGURE experimental design, intended to ensure that one plot of each plant type appears in each row (fertilizer type) and column (soil type). Such designs are still used in practice, but Fisher would later argue convincingly that a randomized design is even more effective. (Source: Drawing by Dakota Harr.) From our perspective, in an era when randomized trials are the gold standard, all of this may appear obvious. But at the time, the idea of a randomly designed experiment horrified Fisher’s statistical colleagues.\nFisher’s literally drawing from a deck of cards to assign subplots to each fertilizer may have contributed to their dismay. Science subjected to the whims of chance? But Fisher realized that an uncertain answer to the right question is much better than a highly certain answer to the wrong question. If you ask the genie the wrong question, you will never find out what you want to know. If you ask the right question, getting an answer that is occasionally wrong is much less of a problem. You can still estimate the amount of uncertainty in your answer, because the uncertainty comes from the randomization procedure (which is known) rather than the characteristics of the soil (which are unknown).\nThus, randomization actually brings two benefits. First, it eliminates confounder bias (it asks Nature the right question). Second, it enables the researcher to quantify his uncertainty. However, according to historian Stephen Stigler, the second benefit was really Fisher’s main reason for advocating randomization. He was the world’s master of quantifying uncertainty, having developed many new mathematical procedures for doing so. By comparison, his understanding of deconfounding was purely intuitive, for he lacked a mathematical notation for articulating what he sought.\nNow, ninety years later, we can use the do-operator to fill in what Fisher wanted to but couldn’t ask. Let’s see, from a causal point of view, how randomization enables us to ask the genie the right question.\nLet’s start, as usual, by drawing a causal diagram. Model 1, shown in Figure 4.4, describes how the yield of each plot is determined under normal conditions, where the farmer decides by whim or bias which fertilizer is best for each plot. The query he wants to pose to the genie Nature is “What is the yield under a uniform application of Fertilizer 1 (versus Fertilizer 2) to the entire field?” Or, in do-operator notation, what is P(yield | do(fertilizer = 1))? F 4.4. Model 1: an improperly controlled experiment.\nIGURE If the farmer performs the experiment naively, for example applying Fertilizer 1 to the high end of his field and Fertilizer 2 to the low end, he is probably introducing Drainage as a confounder. If he uses Fertilizer 1 one year and Fertilizer 2 the next year, he is probably introducing Weather as a confounder. In either case, he will get a biased comparison.\nThe world that the farmer wants to know about is described by Model 2, where all plots receive the same fertilizer (see Figure 4.5). As explained in Chapter 1, the effect of the do-operator is to erase all the arrows pointing to Fertilizer and force this variable to a particular value—say, Fertilizer = 1.\nF 4.5. Model 2: the world we would like to know about.\nIGURE Finally, let’s see what the world looks like when we apply randomization.\nNow some plots will be subjected to do(fertilizer = 1) and others to do(fertilizer = 2), but the choice of which treatment goes to which plot is random. The world created by such a model is shown by Model 3 in Figure 4.6, showing the variable Fertilizer obtaining its assignment by a random device—say, Fisher’s deck of cards.\nNotice that all the arrows pointing toward Fertilizer have been erased, reflecting the assumption that the farmer listens only to the card when deciding which fertilizer to use. It is equally important to note that there is no arrow from Card to Yield, because the plants cannot read the cards. (This is a fairly safe assumption for plants, but for human subjects in a randomized trial it is a serious concern.) Therefore Model 3 describes a world in which the relation between Fertilizer and Yield is unconfounded (i.e., there is no common cause of Fertilizer and Yield). This means that in the world described by Figure 4.6, there is no difference between seeing Fertilizer = 1 and doing Fertilizer = 1.\nF 4.6. Model 3: the world simulated by a randomized controlled trial.\nIGURE That brings us to the punch line: randomization is a way of simulating Model 2. It disables all the old confounders without introducing any new confounders. That is the source of its power; there is nothing mysterious or mystical about it. It is nothing more or less than, as Joan Fisher Box said, “the skillful interrogation of Nature.” The experiment would, however, fail in its objective of simulating Model 2 if either the experimenter were allowed to use his own judgment to choose a fertilizer or the experimental subjects, in this case the plants, “knew” which card they had drawn. This is why clinical trials with human subjects go to great lengths to conceal this information from both the patients and the experimenters (a procedure known as double blinding).\nI will add to this a second punch line: there are other ways of simulating Model 2. One way, if you know what all the possible confounders are, is to measure and adjust for them. However, randomization does have one great advantage: it severs every incoming link to the randomized variable, including the ones we don’t know about or cannot measure (e.g., “Other” factors in Figures 4.4 to 4.6).\nBy contrast, in a nonrandomized study, the experimenter must rely on her knowledge of the subject matter. If she is confident that her causal model accounts for a sufficient number of deconfounders and she has gathered data on them, then she can estimate the effect of Fertilizer on Yield in an unbiased way. But the danger is that she may have missed a confounding factor, and her estimate may therefore be biased.\nAll things being equal, RCTs are still preferred to observational studies, just as safety nets are recommended for tightrope walkers. But all things are not necessarily equal. In some cases, intervention may be physically impossible (for instance, in a study of the effect of obesity on heart disease, we cannot randomly assign patients to be obese or not). Or intervention may be unethical (in a study of the effects of smoking, we can’t ask randomly selected people to smoke for ten years). Or we may encounter difficulties recruiting subjects for inconvenient experimental procedures and end up with volunteers who do not represent the intended population.\nFortunately, the do-operator gives us scientifically sound ways of determining causal effects from nonexperimental studies, which challenge the traditional supremacy of RCTs. As discussed in the walking example, such causal estimates produced by observational studies may be labeled “provisional causality,” that is, causality contingent upon the set of assumptions that our causal diagram advertises. It is important that we not treat these studies as second-class citizens: they have the advantage of being conducted in the natural habitat of the target population, not in the artificial setting of a laboratory, and they can be “pure” in the sense of not being contaminated by issues of ethics or feasibility.\nNow that we understand that the principal objective of an RCT is to eliminate confounding, let’s look at the other methods that the Causal Revolution has given us. The story begins with a 1986 paper by two of my longtime colleagues, which started a reevaluation of what confounding means.\nTHE NEW PARADIGM OF CONFOUNDING “While confounding is widely recognized as one of the central problems in epidemiological research, a review of the literature will reveal little consistency among the definitions of confounding or confounder.” With this one sentence, Sander Greenland of the University of California, Los Angeles, and Jamie Robins of Harvard University put their finger on the central reason why the control of confounding had not advanced one bit since Fisher.\nLacking a principled understanding of confounding, scientists could not say anything meaningful in observational studies where physical control over treatments is infeasible.\nHow was confounding defined then, and how should it be defined? Armed with what we now know about the logic of causality, the answer to the second question is easier. The quantity we observe is the conditional probability of the outcome given the treatment, P(Y | X). The question we want to ask of Nature has to do with the causal relationship between X and Y, which is captured by the interventional probability P(Y | do(X)). Confounding, then, should simply be defined as anything that leads to a discrepancy between the two: P(Y | X) ≠ P(Y | do(X)). Why all the fuss? Unfortunately, things were not as easy as that before the 1990s because the do-operator had yet to be formalized. Even today, if you stop a statistician in the street and ask, “What does ‘confounding’ mean to you?” you will probably get one of the most convoluted and confounded answers you ever heard from a scientist. One recent book, coauthored by leading statisticians, spends literally two pages trying to explain it, and I have yet to find a reader who understood the explanation.\nThe reason for the difficulty is that confounding is not a statistical notion.\nIt stands for the discrepancy between what we want to assess (the causal effect) and what we actually do assess using statistical methods. If you can’t articulate mathematically what you want to assess, you can’t expect to define what constitutes a discrepancy.\nHistorically, the concept of “confounding” has evolved around two related conceptions: incomparability and a lurking third variable. Both of these concepts have resisted formalization. When we talked about comparability, in the context of Daniel’s experiment, we said that the treatment and control groups should be identical in all relevant ways. But this begs us to distinguish relevant from irrelevant attributes. How do we know that age is relevant in the Honolulu walking study? How do we know that the alphabetical order of a participant’s name is not relevant? You might say it’s obvious or common sense, but generations of scientists have struggled to articulate that common sense formally, and a robot cannot rely on our common sense when asked to act properly.\nThe same ambiguity plagues the third-variable definition. Should a confounder be a common cause of both X and Y or merely correlated with each? Today we can answer such questions by referring to the causal diagram and checking which variables produce a discrepancy between P(X | Y) and P(X | do(Y)). Lacking a diagram or a do-operator, five generations of statisticians and health scientists had to struggle with surrogates, none of which were satisfactory. Considering that the drugs in your medicine cabinet may have been developed on the basis of a dubious definition of “confounders,” you should be somewhat concerned.\nLet’s take a look at some of the surrogate definitions of confounding.\nThese fall into two main categories, declarative and procedural. A typical (and wrong) declarative definition would be “A confounder is any variable that is correlated with both X and Y.” On the other hand, a procedural definition would attempt to characterize a confounder in terms of a statistical test. This appeals to statisticians, who love any test that can be performed on the data directly without appealing to a model.\nHere is a procedural definition that goes by the scary name of “noncollapsibility.” It comes from a 1996 paper by the Norwegian epidemiologist Sven Hernberg: “Formally one can compare the crude relative risk and the relative risk resulting after adjustment for the potential confounder. A difference indicates confounding, and in that case one should use the adjusted risk estimate. If there is no or a negligible difference, confounding is not an issue and the crude estimate is to be preferred.” In other words, if you suspect a confounder, try adjusting for it and try not adjusting for it. If there is a difference, it is a confounder, and you should trust the adjusted value. If there is no difference, you are off the hook. Hernberg was by no means the first person to advocate such an approach; it has misguided a century of epidemiologists, economists, and social scientists, and it still reigns in certain quarters of applied statistics. I have picked on Hernberg only because he was unusually explicit about it and because he wrote this in 1996, well after the Causal Revolution was already underway.\nThe most popular of the declarative definitions evolved over a period of time. Alfredo Morabia, author of A History of Epidemiologic Methods and Concepts, calls it “the classic epidemiological definition of confounding,” and it consists of three parts. A confounder of X (the treatment) and Y (the outcome) is a variable Z that is (1) associated with X in the population at large, and (2) associated with Y among people who have not been exposed to the treatment X. In recent years, this has been supplemented by a third condition: (3) Z should not be on the causal path between X and Y.\nObserve that all the terms in the “classic” version (1 and 2) are statistical.\nIn particular, Z is only assumed to be associated with—not a cause of—X and Y. Edward Simpson proposed the rather convoluted condition “Y is associated with Z among the unexposed” in 1951. From the causal point of view, it seems that Simpson’s idea was to discount the part of the correlation of Z with Y that is due to the causal effect of X on Y; in other words, he wanted to say that Z has an effect on Y independent of its effect on X. The only way he could think to express this discounting was to condition on X by focusing on the control group (X = 0). Statistical vocabulary, deprived of the word “effect,” gave him no other way of saying it.\nIf this is a bit confusing, it should be! How much easier it would have been if he could have simply written a causal diagram, like Figure 4.1, and said, “Y is associated with Z via paths not going through X.” But he didn’t have this tool, and he couldn’t talk about paths, which were a forbidden concept.\nThe “classical epidemiological definition” of a confounder has other flaws, as the following two examples show: and In example (i), Z satisfies conditions (1) and (2) but is not a confounder. It is known as a mediator: it is the variable that explains the causal effect of X on Y. It is a disaster to control for Z if you are trying to find the causal effect of X on Y. If you look only at those individuals in the treatment and control groups for whom Z = 0, then you have completely blocked the effect of X, because it works by changing Z. So you will conclude that X has no effect on Y. This is exactly what Ezra Klein meant when he said, “Sometimes you end up controlling for the thing you’re trying to measure.” In example (ii), Z is a proxy for the mediator M. Statisticians very often control for proxies when the actual causal variable can’t be measured; for instance, party affiliation might be used as a proxy for political beliefs.\nBecause Z isn’t a perfect measure of M, some of the influence of X on Y might “leak through” if you control for Z. Nevertheless, controlling for Z is still a mistake. While the bias might be less than if you controlled for M, it is still there.\nFor this reason later statisticians, notably David Cox in his textbook The Design of Experiments (1958), warned that you should only control for Z if you have a “strong prior reason” to believe that it is not affected by X. This “strong prior reason” is nothing more or less than a causal assumption. He adds, “Such hypotheses may be perfectly in order, but the scientist should always be aware when they are being appealed to.” Remember that it’s 1958, in the midst of the great prohibition on causality. Cox is saying that you can go ahead and take a swig of causal moonshine when adjusting for confounders, but don’t tell the preacher. A daring suggestion! I never fail to commend him for his bravery.\nBy 1980, Simpson’s and Cox’s conditions had been combined into the three-part test for confounding that I mentioned above. It is about as trustworthy as a canoe with only three leaks. Even though it does make a halfhearted appeal to causality in part (3), each of the first two parts can be shown to be both unnecessary and insufficient.\nGreenland and Robins drew that conclusion in their landmark 1986 paper.\nThe two took a completely new approach to confounding, which they called “exchangeability.” They went back to the original idea that the control group (X = 0) should be comparable to the treatment group (X = 1). But they added a counterfactual twist. (Remember from Chapter 1 that counterfactuals are at rung three of the Ladder of Causation and therefore powerful enough to detect confounding.) Exchangeability requires the researcher to consider the treatment group, imagine what would have happened to its constituents if they had not gotten treatment, and then judge whether the outcome would be the same as for those who (in reality) did not receive treatment. Only then can we say that no confounding exists in the study.\nIn 1986, talking counterfactuals to an audience of epidemiologists took some courage, because they were still very much under the influence of classical statistics, which holds that all the answers are in the data—not in what might have been, which will remain forever unobserved. However, the statistical community was somewhat prepared to listen to such heresy, thanks to the pioneering work of another Harvard statistician, Donald Rubin. In Rubin’s “potential outcomes” framework, proposed in 1974, counterfactual variables like “Blood Pressure of Person X had he received Drug D” and “Blood Pressure of Person X had he not received Drug D” are just as legitimate as a traditional variable like Blood Pressure—despite the fact that one of those two variables will remain forever unobserved.\nRobins and Greenland set out to express their conception of confounding in terms of potential outcomes. They partitioned the population into four types of individuals: doomed, causative, preventive, and immune. The language is suggestive, so let’s think of the treatment X as a flu vaccination and the outcome Y as coming down with flu. The doomed people are those for whom the vaccine doesn’t work; they will get flu whether they get the vaccine or not. The causative group (which may be nonexistent) includes those for whom the vaccine actually causes the disease. The preventive group consists of people for whom the vaccine prevents the disease: they will get flu if they are not vaccinated, and they will not get flu if they are vaccinated. Finally, the immune group consists of people who will not get flu in either case. Table 4.1 sums up these considerations.\nIdeally, each person would have a sticker on his forehead identifying which group he belonged to. Exchangeability simply means that the percentage of people with each kind of sticker (d percent, c percent, p percent, and i percent, respectively) should be the same in both the treatment and control groups. Equality among these proportions guarantees that the outcome would be just the same if we switched the treatments and controls. Otherwise, the treatment and control groups are not alike, and our estimate of the effect of the vaccine will be confounded. Note that the two groups may be different in many ways. They can differ in age, sex, health conditions, and a variety of other characteristics. Only equality among d, c, p, and i determines whether they are exchangeable or not. So exchangeability amounts to equality between two sets of four proportions, a vast reduction in complexity from the alternative of assessing the innumerable factors by which the two groups may differ.\nTABLE 4.1. Classification of individuals according to response type.\nUsing this commonsense definition of confounding, Greenland and Robins showed that the “statistical” definitions, both declarative and procedural, give incorrect answers. A variable can satisfy the three-part test of epidemiologists and still increase bias, if adjusted for.\nGreenland and Robins’s definition was a great achievement, because it enabled them to give explicit examples showing that the previous definitions of confounding were inadequate. However, the definition could not be translated into practice. To put it simply, those stickers on the forehead don’t exist. We do not even have a count of the proportions d, c, p, and i. In fact, this is precisely the kind of information that the genie of Nature keeps locked inside her magic lantern and doesn’t show to anybody. Lacking this information, the researcher is left to intuit whether the treatment and control groups are exchangeable or not.\nBy now, I hope that your curiosity is well piqued. How can causal diagrams turn this massive headache of confounding into a fun game? The trick lies in an operational test for confounding, called the back-door criterion.\nThis criterion turns the problem of defining confounding, identifying confounders, and adjusting for them into a routine puzzle that is no more challenging than solving a maze. It has thus brought the thorny, age-old problem to a happy conclusion.\nTHE DO-OPERATOR AND THE BACK-DOOR CRITERION To understand the back-door criterion, it helps first to have an intuitive sense of how information flows in a causal diagram. I like to think of the links as pipes that convey information from a starting point X to a finish Y. Keep in mind that the conveying of information goes in both directions, causal and noncausal, as we saw in Chapter 3.\nIn fact, the noncausal paths are precisely the source of confounding.\nRemember that I define confounding as anything that makes P(Y | do(X)) differ from P(Y | X). The do-operator erases all the arrows that come into X, and in this way it prevents any information about X from flowing in the noncausal direction. Randomization has the same effect. So does statistical adjustment, if we pick the right variables to adjust.\nIn the last chapter, we looked at three rules that tell us how to stop the flow of information through any individual junction. I will repeat them for emphasis: (a) In a chain junction, A B C, controlling for B prevents information about A from getting to C or vice versa.\n\nLikewise, in a fork or confounding junction, A B C, controlling for B prevents information about A from getting to C or vice versa.\nFinally, in a collider, A B C, exactly the opposite rules hold.\n\nThe variables A and C start out independent, so that information about A tells you nothing about C. But if you control for B, then information starts flowing through the “pipe,” due to the explain- away effect.\nWe must also keep in mind another fundamental rule: (d) Controlling for descendants (or proxies) of a variable is like “partially” controlling for the variable itself. Controlling for a descendant of a mediator partly closes the pipe; controlling for a descendant of a collider partly opens the pipe.\nNow, what if we have longer pipes with more junctions, like this: A B C D E F G H I J? The answer is very simple: if a single junction is blocked, then J cannot “find out” about A through this path. So we have many options to block communication between A and J: control for B, control for C, don’t control for D (because it’s a collider), control for E, and so forth. Any one of these is sufficient. This is why the usual statistical procedure of controlling for everything that we can measure is so misguided. In fact, this particular path is blocked if we don’t control for anything! The colliders at D and G block the path without any outside help. Controlling for D and G would open this path and enable J to listen to A.\nFinally, to deconfound two variables X and Y, we need only block every noncausal path between them without blocking or perturbing any causal paths. More precisely, a back-door path is any path from X to Y that starts with an arrow pointing into X. X and Y will be deconfounded if we block every back-door path (because such paths allow spurious correlation between X and Y). If we do this by controlling for some set of variables Z, we also need to make sure that no member of Z is a descendant of X on a causal path; otherwise we might partly or completely close off that path.\nThat’s all there is to it! With these rules, deconfounding becomes so simple and fun that you can treat it like a game. I urge you to try a few examples just to get the hang of it and see how easy it is. If you still find it hard, be assured that algorithms exist that can crack all such problems in a matter of nanoseconds. In each case, the goal of the game is to specify a set of variables that will deconfound X and Y. In other words, they should not be descended from X, and they should block all the back-door paths.\nGAME 1.\nThis one is easy! There are no arrows leading into X, therefore no back- door paths. We don’t need to control for anything.\nNevertheless, some researchers would consider B a confounder. It is associated with X because of the chain X A B. It is associated with Y among individuals with X = 0 because there is an open path B A Y that does not pass through X. And B is not on the causal path X A Y. It therefore passes the three-step “classical epidemiological definition” for confounding, but it does not pass the back-door criterion and will lead to disaster if controlled for.\nGAME 2.\nIn this example you should think of A, B, C, and D as “pretreatment” variables. (The treatment, as usual, is X.) Now there is one back-door path X A B D E Y. This path is already blocked by the collider at B, so we don’t need to control for anything. Many statisticians would control for B or C, thinking there is no harm in doing so as long as they occur before the treatment. A leading statistician even recently wrote, “To avoid conditioning on some observed covariates… is nonscientific ad hockery.” He is wrong; conditioning on B or C is a poor idea because it would open the noncausal path and therefore confound X and Y. Note that in this case we could reclose the path by controlling for A or D. This example shows that there may be different strategies for deconfounding. One researcher might take the easy way and not control for anything; a more traditional researcher might control for C and D. Both would be correct and should get the same result (provided that the model is correct, and we have a large enough sample).\nGAME 3.\nIn Games 1 and 2 you didn’t have to do anything, but this time you do.\nThere is one back-door path from X to Y, X B Y, which can only be blocked by controlling for B. If B is unobservable, then there is no way of estimating the effect of X on Y without running a randomized controlled experiment. Some (in fact, most) statisticians in this situation would control for A, as a proxy for the unobservable variable B, but this only partially eliminates the confounding bias and introduces a new collider bias.\nGAME 4.\nThis one introduces a new kind of bias, called “M-bias” (named for the shape of the graph). Once again there is only one back-door path, and it is already blocked by a collider at B. So we don’t need to control for anything.\nNevertheless, all statisticians before 1986 and many today would consider B a confounder. It is associated with X (via X A B) and associated with Y via a path that doesn’t go through X (B C Y). It does not lie on a causal path and is not a descendant of anything on a causal path, because there is no causal path from X to Y. Therefore B passes the traditional three-step test for a confounder.\nM-bias puts a finger on what is wrong with the traditional approach. It is incorrect to call a variable, like B, a confounder merely because it is associated with both X and Y. To reiterate, X and Y are unconfounded if we do not control for B. B only becomes a confounder when you control for it! When I started showing this diagram to statisticians in the 1990s, some of them laughed it off and said that such a diagram was extremely unlikely to occur in practice. I disagree! For example, seat-belt usage (B) has no causal effect on smoking (X) or lung disease (Y); it is merely an indicator of a person’s attitudes toward societal norms (A) as well as safety and health- related measures (C). Some of these attitudes may affect susceptibility to lung disease (Y). In practice, seatbelt usage was found to be correlated with both X and Y; indeed, in a study conducted in 2006 as part of a tobacco litigation, seat-belt usage was listed as one of the first variables to be controlled for. If you accept the above model, then controlling for B alone would be a mistake.\nNote that it’s all right to control for B if you also control for A or C.\nControlling for the collider B opens the “pipe,” but controlling for A or C closes it again. Unfortunately, in the seat-belt example, A and C are variables relating to people’s attitudes and not likely to be observable. If you can’t observe it, you can’t adjust for it.\nGAME 5.\nGame 5 is just Game 4 with a little extra wrinkle. Now a second back-door path X B C Y needs to be closed. If we close this path by controlling for B, then we open up the M-shaped path X A B C Y. To close that path, we must control for A or C as well. However, notice that we could just control for C alone; that would close the path X B C Y and not affect the other path.\nGames 1 through 3 come from a 1993 paper by Clarice Weinberg, a deputy chief at the National Institutes of Health, called “Toward a Clearer Definition of Confounding.” It came out during the transitional period between 1986 and 1995, when Greenland and Robins’s paper was available but causal diagrams were still not widely known. Weinberg therefore went through the considerable arithmetic exercise of verifying exchangeability in each of the cases shown. Although she used graphical displays to communicate the scenarios involved, she did not use the logic of diagrams to assist in distinguishing confounders from deconfounders. She is the only person I know of who managed this feat. Later, in 2012, she collaborated on an updated version that analyzes the same examples with causal diagrams and verifies that all her conclusions from 1993 were correct.\nIn both of Weinberg’s papers, the medical application was to estimate the effect of smoking (X) on miscarriages, or “spontaneous abortions” (Y). In Game 1, A represents an underlying abnormality that is induced by smoking; this is not an observable variable because we don’t know what the abnormality is. B represents a history of previous miscarriages. It is very, very tempting for an epidemiologist to take previous miscarriages into account and adjust for them when estimating the probability of future miscarriages. But that is the wrong thing to do here! By doing so we are partially inactivating the mechanism through which smoking acts, and we will thus underestimate the true effect of smoking.\nGame 2 is a more complicated version where there are two different smoking variables: X represents whether the mother smokes now (at the beginning of the second pregnancy), while A represents whether she smoked during the first pregnancy. B and E are underlying abnormalities caused by smoking, which are unobservable, and D represents other physiological causes of those abnormalities. Note that this diagram allows for the fact that the mother could have changed her smoking behavior between pregnancies, but the other physiological causes would not change. Again, many epidemiologists would adjust for prior miscarriages (C), but this is a bad idea unless you also adjust for smoking behavior in the first pregnancy (A).\nGames 4 and 5 come from a paper published in 2014 by Andrew Forbes, a biostatistician at Monash University in Australia, along with several collaborators. He is interested in the effect of smoking on adult asthma. In Game 4, X represents an individual’s smoking behavior, and Y represents whether the person has asthma as an adult. B represents childhood asthma, which is a collider because it is affected by both A, parental smoking, and C, an underlying (and unobservable) predisposition toward asthma. In Game 5 the variables have the same meanings, but Forbes added two arrows for greater realism. (Game 4 was only meant to introduce the M-graph.) In fact, the full model in Forbes’ paper has a few more variables and looks like the diagram in Figure 4.7. Note that Game 5 is embedded in this model in the sense that the variables A, B, C, X, and Y have exactly the same relationships. So we can transfer our conclusions over and conclude that we have to control for A and B or for C; but C is an unobservable and therefore uncontrollable variable. In addition we have four new confounding variables: D = parental asthma, E = chronic bronchitis, F = sex, and G = socioeconomic status. The reader might enjoy figuring out that we must control for E, F, and G, but there is no need to control for D. So a sufficient set of variables for deconfounding is A, B, E, F, and G.\nF 4.7. Andrew Forbes’s model of smoking (X) and asthma (Y).\nIGURE In the end, Forbes found that smoking had a small and statistically insignificant association with adult asthma in the raw data, and the effect became even smaller and more insignificant after adjusting for the confounders. The null result should not detract, however, from the fact that his paper is a model for the “skillful interrogation of Nature.” One final comment about these “games”: when you start identifying the variables as smoking, miscarriage, and so forth, they are quite obviously not games but serious business. I have referred to them as games because the joy of being able to solve them swiftly and meaningfully is akin to the pleasure a child feels on figuring out that he can crack puzzles that stumped him before.\nFew moments in a scientific career are as satisfying as taking a problem that has puzzled and confused generations of predecessors and reducing it to a straightforward game or algorithm. I consider the complete solution of the confounding problem one of the main highlights of the Causal Revolution because it ended an era of confusion that has probably resulted in many wrong decisions in the past. It has been a quiet revolution, raging primarily in research laboratories and scientific meetings. Yet, armed with these new tools and insights, the scientific community is now tackling harder problems, both theoretical and practical, as subsequent chapters will show.\n“Abe and Yak” (left and right, respectively) took opposite positions on the hazards of cigarette smoking. As was typical of the era, both were smokers (though Abe used a pipe). The smoking-cancer debate was unusually personal for many of the scientists who participated in it. (Source: Drawing by Dakota Harr.)",
    "crumbs": [
      "Causal Inference",
      "The book of why"
    ]
  },
  {
    "objectID": "extracted/The Book of Why - Judea Pearl.html#the-smoke-filled-debate-clearing-the-air",
    "href": "extracted/The Book of Why - Judea Pearl.html#the-smoke-filled-debate-clearing-the-air",
    "title": "The book of why",
    "section": "5. THE SMOKE-FILLED DEBATE: CLEARING THE AIR",
    "text": "5. THE SMOKE-FILLED DEBATE: CLEARING THE AIR\nAt last the sailors said to each other, Come and let us cast lots to find\nout who is to blame for this ordeal.\n—JONAH 1:7 I N the late 1950s and early 1960s, statisticians and doctors clashed over one of the highest-profile medical questions of the century: Does smoking cause lung cancer? Half a century after this debate, we take the answer for granted.\nBut at that time, the issue was by no means clear. Scientists, and even families, were divided.\nJacob Yerushalmy’s was one such divided family. A biostatistician at the University of California, Berkeley, Yerushalmy (1904–1973) was one of the last of the pro-tobacco holdouts in academia. “Yerushalmy opposed the notion that cigarette smoking caused cancer until his dying day,” wrote his nephew David Lilienfeld many years later. On the other hand, Lilienfeld’s father, Abe Lilienfeld, was an epidemiologist at Johns Hopkins University and one of the most outspoken proponents of the theory that smoking did cause cancer. The younger Lilienfeld recalled how Uncle “Yak” (short for Jacob) and his father would sit around and debate the effects of smoking, wreathed all the while in a “haze of smoke from Yak’s cigarette and Abe’s pipe” (see chapter frontispiece).\nIf only Abe and Yak had been able to summon the Causal Revolution to clear the air! As this chapter shows, one of the most important scientific arguments against the smoking-cancer hypothesis was the possible existence of unmeasured factors that cause both craving for nicotine and lung cancer.\nWe have just discussed such confounding patterns and noted that today’s causal diagrams have driven the menace of confounding out of existence. But we are now in the 1950s and 1960s, two decades before Sander Greenland and Jamie Robins and three decades before anyone had heard of the do- operator. It is interesting to examine, therefore, how scientists of that era dealt with the issue and showed that the confounding argument is all smoke and mirrors.\nNo doubt the subject of many of Abe and Yak’s smoke-filled debates was neither tobacco nor cancer. It was that innocuous word “caused.” It wasn’t the first time that physicians confronted perplexing causal questions: some of the greatest milestones in medical history dealt with identifying causative agents.\nIn the mid-1700s, James Lind had discovered that citrus fruits could prevent scurvy, and in the mid-1800s, John Snow had figured out that water contaminated with fecal matter caused cholera. (Later research identified a more specific causative agent in each case: vitamin C deficiency for scurvy, the cholera bacillus for cholera.) These brilliant pieces of detective work had in common a fortunate one-to-one relation between cause and effect. The cholera bacillus is the only cause of cholera; or as we would say today, it is both necessary and sufficient. If you aren’t exposed to it, you won’t get the disease. Likewise, a vitamin C deficiency is necessary to produce scurvy, and given enough time, it is also sufficient.\nThe smoking-cancer debate challenged this monolithic concept of causation. Many people smoke their whole lives and never get lung cancer.\nConversely, some people get lung cancer without ever lighting up a cigarette.\nSome people may get it because of a hereditary disposition, others because of exposure to carcinogens, and some for both reasons.\nOf course, statisticians already knew of one excellent way to establish causation in a more general sense: the randomized controlled trial (RCT). But such a study would be neither feasible nor ethical in the case of smoking.\nHow could you assign people chosen at random to smoke for decades, possibly ruining their health, just to see if they would get lung cancer after thirty years? It’s impossible to imagine anyone outside North Korea “volunteering” for such a study.\nWithout a randomized controlled trial, there was no way to convince skeptics like Yerushalmy and R. A. Fisher, who were committed to the idea that the observed association between smoking and lung cancer was spurious.\nTo them, some lurking third factor could be producing the observed association. For example, there could be a smoking gene that caused people to crave cigarettes and also, at the same time, made them more likely to develop lung cancer (perhaps because of other lifestyle choices). The confounders they suggested were implausible at best. Still, the onus was on the antismoking contingent to prove there was no confounder—to prove a negative, which Fisher and Yerushalmy well knew is almost impossible.\nThe final breach of this stalemate is a tale at once of a great triumph and a great opportunity missed. It was a triumph for public health because the epidemiologists did get it right in the end. The US surgeon general’s report, in 1964, stated in no uncertain terms, “Cigarette smoking is causally related to lung cancer in men.” This blunt statement forever shut down the argument that smoking was “not proven” to cause cancer. The rate of smoking in the United States among men began to decrease the following year and is now less than half what it was in 1964. No doubt millions of lives have been saved and lifespans lengthened.\nOn the other hand, the triumph is incomplete. The period it took to reach the above conclusion, roughly from 1950 to 1964, might have been shorter if scientists had been able to call upon a more principled theory of causation.\nAnd most significantly from the point of view of this book, the scientists of the 1960s did not really put together such a theory. To justify the claim that smoking caused cancer, the surgeon general’s committee relied on an informal series of guidelines, called Hill’s criteria, named for University of London statistician Austin Bradford Hill. Every one of these criteria has demonstrable exceptions, although collectively they have a compelling commonsense value and even wisdom. From the overly methodological world of Fisher, the Hill guidelines take us to the opposite realm, to a methodology-free world where causality is decided on the basis of qualitative patterns of statistical trends.\nThe Causal Revolution builds a bridge between these two extremes, empowering our intuitive sense of causality with mathematical rigor. But this job would be left to the next generation.\nTOBACCO: A MANMADE EPIDEMIC In 1902, cigarettes comprised only 2 percent of the US tobacco market; spittoons rather than ashtrays were the most ubiquitous symbol of tobacco consumption. But two powerful forces worked together to change Americans’ habits: automation and advertising. Machine-made cigarettes easily outcompeted handcrafted cigars and pipes on the basis of availability and cost. Meanwhile, the tobacco industry invented and perfected many tricks of the trade of advertising (see Figure 5.1). People who watched TV in the 1960s can easily remember any number of catchy cigarette jingles, from “You get a lot to like in a Marlboro” to “You’ve come a long way, baby.” By 1952, cigarettes’ share of the tobacco market had rocketed from 2 to 81 percent, and the market itself had grown dramatically. This sea change in the habits of a country had unexpected ramifications for public health. Even in the early years of the twentieth century, there had been suspicions that smoking was unhealthy, that it “irritated” the throat and caused coughing.\nAround mid-century, the evidence started to become a good deal more ominous. Before cigarettes, lung cancer had been so rare that a doctor might encounter it only once in a lifetime of practice. But between 1900 and 1950, the formerly rare disease quadrupled in frequency, and by 1960 it would become the most common form of cancer among men. Such a huge change in the incidence of a lethal disease begged for an explanation.\nF 5.1. Highly manipulative advertisements were intended to reassure the public IGURE that cigarettes were not injurious to their health—including this 1948 ad from the Journal of the American Medical Association targeting the doctors themselves.\n(Source: From the collection of Stanford Research into the Impact of Tobacco Advertising.) With hindsight, it is easy to point the finger of blame at smoking. If we plot the rates of lung cancer and tobacco consumption on a graph (see Figure 5.2), the connection is impossible to miss. But time series data are poor evidence for causality. Many other things had changed between 1900 and 1950 and were equally plausible culprits: the paving of roads, the inhalation of leaded gasoline fumes, and air pollution in general. British epidemiologist Richard Doll said in 1991, “Motor cars… were a new factor and if I had had to put money on anything at the time, I should have put it on motor exhausts or possibly the tarring of roads.” F 5.2. A graph of the per capita cigarette consumption rate in the United States IGURE (black) and the lung cancer death rate among men (gray) shows a stunning similarity: the cancer curve is almost a replica of the smoking curve, delayed by about thirty years. Nevertheless, this evidence is circumstantial, not proof of causation. Certain key dates are noted here, including the publication of Richard Doll and Austin Bradford Hill’s paper in 1950, which first alerted many medical professionals to the association between smoking and lung cancer. (Source: Graph by Maayan Harel, using data from the American Cancer Society, Centers for Disease Control, and Office of the Surgeon General.) The job of science is to put supposition aside and look at the facts. In 1948, Doll and Austin Bradford Hill teamed up to see if they could learn anything about the causes of the cancer epidemic. Hill had been the chief statistician on a highly successful randomized controlled trial, published earlier that year, which had proved that streptomycin—one of the first antibiotics—was effective against tuberculosis. The study, a landmark in medical history, not only introduced doctors to “wonder drugs” but also cemented the reputation of randomized controlled trials, which soon became the standard for clinical research in epidemiology.\nOf course Hill knew that an RCT was impossible in this case, but he had learned the advantages of comparing a treatment group to a control group. So he proposed to compare patients who had already been diagnosed with cancer to a control group of healthy volunteers. Each group’s members were interviewed on their past behaviors and medical histories. To avoid bias, the interviewers were not told who had cancer and who was a control.\nThe results of the study were shocking: out of 649 lung cancer patients interviewed, all but two had been smokers. This was a statistical improbability so extreme that Doll and Hill couldn’t resist working out the exact odds against it: 1.5 million to 1. Also, the lung cancer patients had been heavier smokers on average than the controls, but (in an inconsistency that R.\nA. Fisher would later pounce on) a smaller percentage reported inhaling their smoke.\nThe type of study Doll and Hill conducted is now called a case-control study because it compares “cases” (people with a disease) to controls. It is clearly an improvement over time series data, because researchers can control for confounders like age, sex, and exposure to environmental pollutants.\nNevertheless, the case-control design has some obvious drawbacks. It is retrospective; that means we study people known to have cancer and look backward to discover why. The probability logic is backward too. The data tell us the probability that a cancer patient is a smoker instead of the probability that a smoker will get cancer. It is the latter probability that really matters to a person who wants to know whether he should smoke or not.\nIn addition, case-control studies admit several possible sources of bias.\nOne of them is called recall bias: although Doll and Hill ensured that the interviewers didn’t know the diagnoses, the patients certainly knew whether they had cancer or not. This could have affected their recollections. Another problem is selection bias. Hospitalized cancer patients were in no way a representative sample of the population, or even of the smoking population.\nIn short, Doll and Hill’s results were extremely suggestive but could not be taken as proof that smoking causes cancer. The two researchers were careful at first to call the correlation an “association.” After dismissing several confounders, they ventured a stronger assertion that “smoking is a factor, and an important factor, in the production of carcinoma of the lung.” Over the next few years, nineteen case-control studies conducted in different countries all arrived at basically the same conclusion. But as R. A.\nFisher was only too happy to point out, repeating a biased study nineteen times doesn’t prove anything. It’s still biased. Fisher wrote in 1957 that these studies “were mere repetitions of evidence of the same kind, and it is necessary to try to examine whether that kind is sufficient for any scientific conclusion.” Doll and Hill realized that if there were hidden biases in the case-control studies, mere replication would not overcome them. Thus, in 1951 they began a prospective study, for which they sent out questionnaires to 60,000 British physicians about their smoking habits and followed them forward in time.\n(The American Cancer Society launched a similar and larger study around the same time.) Even in just five years, some dramatic differences emerged.\nHeavy smokers had a death rate from lung cancer twenty-four times that of nonsmokers. In the American Cancer Society study, the results were even grimmer: smokers died from lung cancer twenty-nine times more often than nonsmokers, and heavy smokers died ninety times more often. On the other hand, people who had smoked and then stopped reduced their risk by a factor of two. The consistency of all these results—more smoking leads to a higher risk of cancer, stopping leads to a lower risk—was another strong piece of evidence for causality. Doctors call it a “dose-response effect”: if substance A causes a biological effect B, then usually (though not always) a larger dose of A causes a stronger response B.\nNevertheless, skeptics like Fisher and Yerushalmy would not be convinced. The prospective studies still failed to compare smokers to otherwise identical nonsmokers. In fact, it is not clear that such a comparison can be made. Smokers are self-selecting. They may be genetically or “constitutionally” different from nonsmokers in a number of ways—more risk taking, likelier to drink heavily. Some of these behaviors might cause adverse health effects that might otherwise be attributed to smoking. This was an especially convenient argument for a skeptic to make because the constitutional hypothesis was almost untestable. Only after the sequencing of the human genome in 2000 did it become possible to look for genes linked to lung cancer. (Ironically, Fisher was proven right, albeit in a very limited way: such genes do exist.) However, in 1959 Jerome Cornfield, writing with Abe Lilienfeld, published a point-by-point rebuttal of Fisher’s arguments that, in many physicians’ eyes, settled the issue. Cornfield, who worked at the National Institutes of Health, was an unusual participant in the smoking- cancer debate. Neither a statistician nor a biologist by training, he had majored in history and learned statistics at the US Department of Agriculture.\nThough somewhat self-taught, he eventually became a highly sought consultant and president of the American Statistical Association. He also had been a 2.5-pack-a-day smoker but gave up his habit when he started seeing the data on lung cancer. (It is interesting to see how personal the smoking debate was for the scientists involved. Fisher never gave up his pipe, and Yerushalmy never gave up his cigarettes.) Cornfield took direct aim at Fisher’s constitutional hypothesis, and he did so on Fisher’s own turf: mathematics. Suppose, he argued, that there is a confounding factor, such as a smoking gene, that completely accounts for the cancer risk of smokers. If smokers have nine times the risk of developing lung cancer, the confounding factor needs to be at least nine times more common in smokers to explain the difference in risk. Think of what this means. If 11 percent of nonsmokers have the “smoking gene,” then 99 percent of the smokers would have to have it. And if even 12 percent of nonsmokers happen to have the cancer gene, then it becomes mathematically impossible for the cancer gene to account fully for the association between smoking and cancer.\nTo biologists, this argument, called Cornfield’s inequality, reduced Fisher’s constitutional hypothesis to smoking ruins. It is inconceivable that a genetic variation could be so tightly linked to something as complex and unpredictable as a person’s choice to smoke.\nCornfield’s inequality was actually a causal argument in embryonic form: it gives us a criterion for adjudicating between Diagram 5.1 (in which the constitutional hypothesis cannot fully explain the association between smoking and lung cancer) and Diagram 5.2 (in which the smoking gene would fully account for the observed association).\nD 5.1.\nIAGRAM D 5.2.\nIAGRAM As explained above, the association between smoking and lung cancer was much too strong to be explained by the constitutional hypothesis.\nIn fact, Cornfield’s method planted the seeds of a very powerful technique called “sensitivity analysis,” which today supplements the conclusions drawn from the inference engine described in the Introduction. Instead of drawing inferences by assuming the absence of certain causal relationships in the model, the analyst challenges such assumptions and evaluates how strong alternative relationships must be in order to explain the observed data. The quantitative result is then submitted to a judgment of plausibility, not unlike the crude judgments invoked in positing the absence of those causal relationships. Needless to say, if we want to extend Cornfield’s approach to a model with more than three or four variables, we need algorithms and estimation techniques that are unthinkable without the advent of graphical tools.\nEpidemiologists in the 1950s faced the criticism that their evidence was “only statistical.” There was allegedly no “laboratory proof.” But even a look at history shows that this argument was specious. If the standard of “laboratory proof” had been applied to scurvy, then sailors would have continued dying right up until the 1930s, because until the discovery of vitamin C, there was no “laboratory proof” that citrus fruits prevented scurvy.\nFurthermore, in the 1950s some types of laboratory proof of the effects of smoking did start to appear in medical journals. Rats painted with cigarette tar developed cancer. Cigarette smoke was proven to contain benzopyrenes, a previously known carcinogen. These experiments increased the biological plausibility of the hypothesis that smoking could cause cancer.\nBy the end of the decade, the accumulation of so many different kinds of evidence had convinced almost all experts in the field that smoking indeed caused cancer. Remarkably, even researchers at the tobacco companies were convinced—a fact that stayed deeply hidden until the 1990s, when litigation and whistle-blowers forced tobacco companies to release many thousands of previously secret documents. In 1953, for example, a chemist at R.J.\nReynolds, Claude Teague, had written to the company’s upper management that tobacco was “an important etiologic factor in the induction of primary cancer of the lung,” nearly a word-for-word repetition of Hill and Doll’s conclusion.\nIn public, the cigarette companies sang a different tune. In January 1954, the leading tobacco companies (including Reynolds) published a nationwide newspaper advertisement, “A Frank Statement to Cigarette Smokers,” that said, “We believe the products we make are not injurious to health. We always have and always will cooperate closely with those whose task it is to safeguard the public health.” In a speech given in March 1954, George Weissman, vice president of Philip Morris and Company, said, “If we had any thought or knowledge that in any way we were selling a product harmful to consumers, we would stop business tomorrow.” Sixty years later, we are still waiting for Philip Morris to keep that promise.\nThis brings us to the saddest episode in the whole smoking-cancer controversy: the deliberate efforts of the tobacco companies to deceive the public about the health risks. If Nature is like a genie that answers a question truthfully but only exactly as it is asked, imagine how much more difficult it is for scientists to face an adversary that intends to deceive us. The cigarette wars were science’s first confrontation with organized denialism, and no one was prepared. The tobacco companies magnified any shred of scientific controversy they could. They set up their own Tobacco Industry Research Committee, a front organization that gave money to scientists to study issues related to cancer or tobacco—but somehow never got around to the central question. When they could find legitimate skeptics of the smoking-cancer connection—such as R. A. Fisher and Jacob Yerushalmy—the tobacco companies paid them consulting fees.\nThe case of Fisher is particularly sad. Of course, skepticism has its place.\nStatisticians are paid to be skeptics; they are the conscience of science. But there is a difference between reasonable and unreasonable skepticism. Fisher crossed that line and then some. Always unable to admit his own mistakes, and surely influenced by his lifetime pipe-smoking habit, he could not acknowledge that the tide of evidence had turned against him. His arguments became desperate. He seized on one counterintuitive result in Doll and Hill’s first paper—the finding (which barely reached the level of statistical significance) that lung cancer patients described themselves as inhalers less often than the controls—and would not let it go. None of the subsequent studies found any such effect. Although Fisher knew as well as anybody that “statistically significant” results sometimes fail to be replicated, he resorted to mockery. He argued that their study had showed that inhaling cigarette smoke might be beneficial and called for further research on this “extremely important point.” Perhaps the only positive thing we can say about Fisher’s role in the debate is that it is very unlikely that tobacco money corrupted him in any way. His own obstinacy was sufficient.\nFor all these reasons, the link between smoking and cancer remained controversial in the public mind long after it had ended among epidemiologists. Even doctors, who should have been more attuned to the science, remained unconvinced: a poll conducted by the American Cancer Society in 1960 showed that only a third of American doctors agreed with the statement that smoking was “a major cause of lung cancer,” and 43 percent of doctors were themselves smokers.\nWhile we may justly blame Fisher for his obduracy and the tobacco companies for their deliberate deception, we must also acknowledge that the scientific community was laboring in an ideological straightjacket. Fisher had been right to promote randomized controlled trials as a highly effective way to assess a causal effect. However, he and his followers failed to realize that there is much we can learn from observational studies. That is the benefit of a causal model: it leverages the experimenter’s scientific knowledge. Fisher’s methods assume that the experimenter begins with no prior knowledge of or opinions about the hypothesis to be tested. They impose ignorance on the scientist, a situation that the denialists eagerly took advantage of.\nBecause scientists had no straightforward definition of the word “cause” and no way to ascertain a causal effect without a randomized controlled trial, they were ill prepared for a debate over whether smoking caused cancer. They were forced to fumble their way toward a definition in a process that lasted throughout the 1950s and reached a dramatic conclusion in 1964.\nTHE SURGEON GENERAL’S COMMISSION AND HILL’S CRITERIA The paper by Cornfield and Lilienfeld had paved the way for a definitive statement by health authorities about the effects of smoking. The Royal College of Physicians in the United Kingdom took the lead, issuing a report in 1962 concluding that cigarette smoking was a causative agent in lung cancer.\nShortly thereafter, US Surgeon General Luther Terry (quite possibly on the urging of President John F. Kennedy) announced his intention to appoint a special advisory committee to study the matter (see Figure 5.3).\nThe committee was carefully balanced to include five smokers and five nonsmokers, two people suggested by the tobacco industry, and nobody who had previously made public statements for or against smoking. For that reason, people like Lilienfeld and Cornfield were ineligible. The members of the committee were distinguished experts in medicine, chemistry, or biology.\nOne of them, William Cochran of Harvard University, was a statistician. In fact, Cochran’s credentials in statistics were the best possible: he was a student of a student of Karl Pearson.\nF 5.3. In 1963, a surgeon general’s advisory committee wrestled with the IGURE problem of how to assess the causal effects of smoking. Depicted here are William Cochran (the committee’s statistician), Surgeon General Luther Terry, and chemist Louis Fieser. (Source: Drawing by Dakota Harr.) The committee labored for more than a year on its report, and a major issue was the use of the word “cause.” The committee members had to put aside nineteenth-century deterministic conceptions of causality, and they also had to put aside statistics. As they (probably Cochran) wrote in the report, “Statistical methods cannot establish proof of a causal relationship in an association. The causal significance of an association is a matter of judgment which goes beyond any statement of statistical probability. To judge or evaluate the causal significance of the association between the attribute or agent and the disease, or effect upon health, a number of criteria must be utilized, no one of which is an all-sufficient basis for judgment.” The committee listed five such criteria: consistency (many studies, in different populations, show similar results); strength of association (including the dose- response effect: more smoking is associated with a higher risk); specificity of the association (a particular agent should have a particular effect and not a long litany of effects); temporal relationship (the effect should follow the cause); and coherence (biological plausibility and consistency with other types of evidence such as laboratory experiments and time series).\nIn 1965, Austin Bradford Hill, who was not on the committee, attempted to summarize the arguments in a way that could be applied to other public health problems and added four more criteria to the list; as a result, the whole list of nine criteria have become known as “Hill’s criteria.” Actually Hill called them “viewpoints,” not requirements, and emphasized that any of them might be lacking in any particular case. “None of my nine viewpoints can bring indisputable evidence for or against the cause-and-effect hypothesis, and none can be required as a sine qua non,” he wrote.\nIndeed, it is quite easy to find arguments against each of the criteria on either Hill’s list or the advisory committee’s shorter list. Consistency by itself proves nothing; if thirty studies each ignore the same confounder, all can easily be biased. Strength of association is vulnerable for the same reason; as pointed out earlier, children’s shoe sizes are strongly associated with but not causally related to their reading aptitude. Specificity has always been a particularly controversial criterion. It makes sense in the context of infectious disease, where one agent typically produces one illness, but less so in the context of environmental exposure. Smoking leads to an increased risk of a variety of other diseases, such as emphysema and cardiovascular disease.\nDoes this really weaken the evidence that it causes cancer? Temporal relation has some exceptions, as mentioned before—for example, a rooster crow does not cause the sun to rise, even though it always precedes the sun. Finally, coherence with established theory or facts is certainly desirable, but the history of science is filled with overturned theories and mistaken laboratory findings.\nHill’s “viewpoints” are still useful as a description of how a discipline comes to accept a causal hypothesis, using a variety of evidence, but they came with no methodology to implement them. For example, biological plausibility and consistency with experiments are supposedly good things.\nBut how, precisely, are we supposed to weigh these kinds of evidence? How do we bring preexisting knowledge into the picture? Apparently each scientist just has to decide for him- or herself. But gut decisions can be wrong, especially if there are political pressures or monetary considerations or if the scientist is addicted to the substance being studied.\nNone of these comments is intended to denigrate the work of the committee. Its members did the best they could in an environment that provided them with no mechanism for discussing causality. Their recognition that nonstatistical criteria were necessary was a great step forward. And the difficult personal decisions that the smokers on the committee made attest to the seriousness of their conclusions. Luther Terry, who had been a cigarette smoker, switched to a pipe. Leonard Schuman announced that he was quitting. William Cochran acknowledged that he could reduce his risk of cancer by quitting but felt that the “comfort of my cigarettes” was sufficient compensation for the risk. Most painfully, Louis Fieser, a four-pack-a-day smoker, was diagnosed with lung cancer less than a year after the report. He wrote to the committee, “You may recall that although fully convinced by the evidence, I continued heavy smoking throughout the deliberations of our committee and invoked all the usual excuses.… My case seems to me more convincing than any statistics.” Minus one lung, he finally stopped smoking.\nViewed from the perspective of public health, the report of the advisory committee was a landmark. Within two years, Congress had required manufacturers to place health warnings on all cigarette packs. In 1971, cigarette advertisements were banned from radio and television. The percentage of US adults who smoke declined from its all-time maximum of 45 percent in 1965 to 19.3 percent in 2010. The antismoking campaign has been one of the largest and most successful, though painfully slow and incomplete, public health interventions in history. The committee’s work also provided a valuable template for achieving scientific consensus and served as a model for future surgeon general’s reports on smoking and many other topics in the years to come (including secondhand smoke, which became a major issue in the 1980s).\nViewed from the perspective of causality, the report was at best a modest success. It clearly established the gravity of causal questions and that data alone could not answer them. But as a roadmap for future discovery, its guidelines were uncertain and flimsy. Hill’s criteria are best read as a historical document, summarizing the types of evidence that had emerged in the 1950s, and ultimately convinced the medical community. But as a guide to future research, they are inadequate. For all but the broadest causal questions, we need a more precise instrument. In retrospect, Cornfield’s inequality, which planted the seeds of sensitivity analysis, was a step in that direction.\nSMOKING FOR NEWBORNS Even after the smoking and cancer debate died down, one major paradox lingered. In the mid-1960s, Jacob Yerushalmy pointed out that a mother’s smoking during pregnancy seemed to benefit the health of her newborn baby, if the baby happened to be born underweight. This puzzle, called the birth- weight paradox, flew in the face of the emerging medical consensus about smoking and was not satisfactorily explained until 2006—more than forty years after Yerushalmy’s original paper. I am absolutely convinced it took so long because the language of causality was not available from 1960 to 1990.\nIn 1959, Yerushalmy had launched a long-term public health study that collected pre- and postnatal data on more than 15,000 children in the San Francisco Bay Area. The data included information on mothers’ smoking habits, as well as the birth weights and mortality rates of their babies in the first month of life.\nSeveral studies had already shown that the babies of smoking mothers weighed less at birth on average than the babies of nonsmokers, and it was natural to suppose that this would translate to poorer survival. Indeed, a nationwide study of low-birth-weight infants (defined as those who weigh less than 5.5 pounds at birth) had shown that their death rate was more than twenty times higher than that of normal-birth-weight infants. Thus, epidemiologists posited a chain of causes and effects: Smoking Low Birth Weight Mortality.\nWhat Yerushalmy found in the data was unexpected even to him. It was true that the babies of smokers were lighter on average than the babies of nonsmokers (by seven ounces). However, the low-birth-weight babies of smoking mothers had a better survival rate than those of nonsmokers. It was as if the mother’s smoking actually had a protective effect.\nIf Fisher had discovered something like this, he probably would have loudly proclaimed it as one of the benefits of smoking. Yerushalmy, to his credit, did not. He wrote, much more cautiously, “These paradoxical findings raise doubts and argue against the proposition that cigarette smoking acts as an exogenous factor which interferes with intrauterine development of the fetus.” In short, there is no causal path from Smoking to Mortality.\nModern epidemiologists believe that Yerushalmy was wrong. Most believe that smoking does increase neonatal mortality—for example, because it interferes with oxygen transfer across the placenta. But how can we reconcile this hypothesis with the data? Statisticians and epidemiologists insisted on analyzing the paradox in probabilistic terms and seeing it as an anomaly peculiar to birth weight. As it turns out, it has little to do with birth weight and everything to do with colliders. When viewed in that light, it is not paradoxical but instructive.\nIn fact, Yerushalmy’s data were completely consistent with the model Smoking Low Birth Weight Mortality once we add a little bit more to it.\nSmoking may be harmful in that it contributes to low birth weight, but certain other causes of low birth weight, such as serious or life-threatening genetic abnormalities, are much more harmful. There are two possible explanations for low birth weight in one particular baby: it might have a smoking mother, or it might be affected by one of those other causes. If we find out that the mother is a smoker, this explains away the low weight and consequently reduces the likelihood of a serious birth defect. But if the mother does not smoke, we have stronger evidence that the cause of the low birth weight is a birth defect, and the baby’s prognosis becomes worse.\nAs before, a causal diagram makes everything clearer. When we incorporate the new assumptions, the causal diagram looks like Figure 5.4.\nWe can see that the birth-weight paradox is a perfect example of collider bias.\nThe collider is Birth Weight. By looking only at babies with low birth weight, we are conditioning on that collider. This opens up a back-door path between Smoking and Mortality that goes Smoking Birth Weight Birth Defect Mortality. This path is noncausal because one of the arrows goes the wrong way. Nevertheless, it induces a spurious correlation between Smoking and Mortality and biases our estimate of the actual (direct) causal effect, Smoking Mortality. In fact, it biases the estimate to such a large extent that smoking actually appears beneficial.\nThe beauty of causal diagrams is that they make the source of bias obvious. Lacking such diagrams, epidemiologists argued about the paradox for forty years. In fact, they are still discussing it: the October 2014 issue of the International Journal of Epidemiology contains several articles on this topic. One of them, by Tyler VanderWeele of Harvard, nails the explanation perfectly and contains a diagram just like the one below.\nF 5.4. Causal diagram for the birth-weight paradox.\nIGURE Of course, this diagram is likely too simple to capture the full story behind smoking, birth weight, and infant mortality. However, the principle of collider bias is robust. In this case the bias was detected because the apparent phenomenon was too implausible, but just imagine how many cases of collider bias go undetected because the bias does not conflict with theory.\nPASSIONATE DEBATES: SCIENCE VS. CULTURE After I began work on this chapter, I had occasion to contact Allen Wilcox, the epidemiologist probably most identified with this paradox. He has asked a very inconvenient question about the diagram in Figure 5.4: How do we know that low birth weight is actually a direct cause of mortality? In fact, he believes that doctors have misinterpreted low birth weight all along. Because it is strongly associated with infant mortality, doctors have interpreted it as a cause. In fact, that association could be due entirely to confounders (represented by “Birth Defect” in Figure 5.4, though Wilcox is not so specific).\nTwo points are worth making about Wilcox’s argument. First, even if we delete the arrow Birth Weight Mortality, the collider remains. Thus the causal diagram continues to account for the birth-weight paradox successfully. Second, the causal variable that Wilcox has studied the most is not smoking but race. And race still incites passionate debate in our society.\nIn fact, the same birth-weight paradox is observed in children of black mothers as in children of smokers. Black women give birth to underweight babies more often than white women do, and their babies have a higher mortality rate. Yet their low-birth-weight babies have a better survival rate than the low-birth-weight babies of white women. Now what conclusions should we draw? We can tell a pregnant smoker that she would help her baby by stopping smoking. But we can’t tell a pregnant black woman to stop being black.\nInstead, we should address the societal issues that cause the children of black mothers to have a higher mortality rate. This is surely not a controversial statement. But what causes should we address, and how should we measure our progress? For better or for worse, many advocates for racial justice have assumed birth weight as an intermediate step in the chain Race Birth Weight Mortality. Not only that, they have taken birth weight as a proxy for infant mortality, assuming that improvements in the one will automatically lead to improvements in the other. It’s easy to understand why they did this. Measurements of average birth weights are easier to come by than measurements of infant mortality.\nNow imagine what happens when someone like Wilcox comes along and asserts that low birth weight by itself is not a medical condition and has no causal relation to infant mortality. It upsets the entire applecart. Wilcox was accused of racism when he first suggested this idea back in the 1970s, and he didn’t dare to publish it until 2001. Even then, two commentaries accompanied his article, and one of them brought up the race issue: “In the context of a society whose dominant elements justify their positions by arguing the genetic inferiority of those they dominate, it is hard to be neutral,” wrote Richard David of Cook County Hospital in Chicago. “In the pursuit of ‘pure science’ a well-meaning investigator may be perceived as—and may be —aiding and abetting a social order he abhors.” This harsh accusation, conceived out of the noblest of motivations, is surely not the first instance in which a scientist has been reprimanded for elucidating truths that might have adverse social consequences. The Vatican’s objections to Galileo’s ideas surely arose out of genuine concerns for the social order of the time. The same can be said about Charles Darwin’s evolution and Francis Galton’s eugenics. However, the cultural shocks that emanate from new scientific findings are eventually settled by cultural realignments that accommodate those findings—not by concealment. A prerequisite for this realignment is that we sort out the science from the culture before opinions become inflamed. Fortunately, the language of causal diagrams now gives us a way to be dispassionate about causes and effects not only when it is easy but also when it is hard.\nThe “Monty Hall paradox,” an enduring and for many people infuriating puzzle, highlights how our brains can be fooled by probabilistic reasoning when causal reasoning should apply. (Source: Drawing by Maayan Harel.)",
    "crumbs": [
      "Causal Inference",
      "The book of why"
    ]
  },
  {
    "objectID": "extracted/The Book of Why - Judea Pearl.html#paradoxes-galore",
    "href": "extracted/The Book of Why - Judea Pearl.html#paradoxes-galore",
    "title": "The book of why",
    "section": "6. PARADOXES GALORE!",
    "text": "6. PARADOXES GALORE!\nHe who confronts the paradoxical exposes himself to reality.\n—FRIEDRICH DÜRRENMATT (1962) T HE birth-weight paradox, with which we ended Chapter 5, is representative of a surprisingly large class of paradoxes that reflect the tensions between causation and association. The tension starts because they stand on two different rungs of the Ladder of Causation and is aggravated by the fact that human intuition operates under the logic of causation, while data conform to the logic of probabilities and proportions. Paradoxes arise when we misapply the rules we have learned in one realm to the other.\nWe are going to devote a chapter to some of the most baffling and well- known paradoxes in probability and statistics because, first of all, they’re fun.\nIf you haven’t seen the Monty Hall and Simpson’s paradoxes before, I can promise that they will give your brain a workout. And even if you think you know all about them, I think that you will enjoy viewing them through the lens of causality, which makes everything look quite a bit different.\nHowever, we study paradoxes not just because they are fun and games.\nLike optical illusions, they also reveal the way the brain works, the shortcuts it takes, and the things it finds conflicting. Causal paradoxes shine a spotlight onto patterns of intuitive causal reasoning that clash with the logic of probability and statistics. To the extent that statisticians have struggled with them—and we’ll see that they whiffed rather badly—it’s a warning sign that something might be amiss with viewing the world without a causal lens.\nTHE PERPLEXING MONTY HALL PROBLEM In the late 1980s, a writer named Marilyn vos Savant started a regular column in Parade magazine, a weekly supplement to the Sunday newspaper in many US cities. Her column, “Ask Marilyn,” continues to this day and features her answers to various puzzles, brainteasers, and scientific questions submitted by readers. The magazine billed her as “the world’s smartest woman,” which undoubtedly motivated readers to come up with a question that would stump her.\nOf all the questions she ever answered, none created a greater furor than this one, which appeared in a column in September 1990: “Suppose you’re on a game show, and you’re given the choice of three doors. Behind one door is a car, behind the others, goats. You pick a door, say #1, and the host, who knows what’s behind the doors, opens another door, say #3, which has a goat.\nHe says to you, ‘Do you want to pick door #2?’ Is it to your advantage to switch your choice of doors?” For American readers, the question was obviously based on a popular televised game show called Let’s Make a Deal, whose host, Monty Hall, used to play precisely this sort of mind game with the contestants. In her answer, vos Savant argued that contestants should switch doors. By not switching, they would have only a one-in-three probability of winning; by switching, they would double their chances to two in three.\nEven the smartest woman in the world could never have anticipated what happened next. Over the next few months, she received more than 10,000 letters from readers, most of them disagreeing with her, and many of them from people who claimed to have PhDs in mathematics or statistics. A small sample of the comments from academics includes “You blew it, and you blew it big!” (Scott Smith, PhD); “May I suggest that you obtain and refer to a standard textbook on probability before you try to answer a question of this type again?” (Charles Reid, PhD); “You blew it!” (Robert Sachs, PhD); and “You are utterly incorrect” (Ray Bobo, PhD). In general, the critics argued that it shouldn’t matter whether you switch doors or not—there are only two doors left in the game, and you have chosen your door completely at random, so the probability that the car is behind your door must be one-half either way.\nWho was right? Who was wrong? And why does the problem incite such passion? All three questions deserve closer examination.\nLet’s take a look first at how vos Savant solved the puzzle. Her solution is actually astounding in its simplicity and more compelling than any I have seen in many textbooks. She made a list (Table 6.1) of the three possible arrangements of doors and goats, along with the corresponding outcomes under the “Switch” strategy and the “Stay” strategy. All three cases assume that you picked Door 1. Because all three possibilities listed are (initially) equally likely, the probability of winning if you switch doors is two-thirds, and the probability of winning if you stay with Door 1 is only one-third.\nNotice that vos Savant’s table does not explicitly state which door was opened by the host. That information is implicitly embedded in columns 4 and 5. For example, in the second row, we kept in mind that the host must open Door 3; therefore switching will land you on Door 2, a win. Similarly, in the first row, the door opened could be either Door 2 or Door 3, but column 4 states correctly that you lose in either case if you switch.\nEven today, many people seeing the puzzle for the first time find the result hard to believe. Why? What intuitive nerve is jangled? There are probably 10,000 different reasons, one for each reader, but I think the most compelling argument is this: vos Savant’s solution seems to force us to believe in mental telepathy. If I should switch no matter what door I originally chose, then it means that the producers somehow read my mind. How else could they position the car so that it is more likely to be behind the door I did not choose? TABLE 6.1. The three possible arrangements of doors and goats in Let’s Make a Deal, showing that switching doors is twice as attractive as not.\nThe key element in resolving this paradox is that we need to take into account not only the data (i.e., the fact that the host opened a particular door) but also the data-generating process—in other words, the rules of the game.\nThey tell us something about the data that could have been but has not been observed. No wonder statisticians in particular found this puzzle hard to comprehend. They are accustomed to, as R. A. Fisher (1922) put it, “the reduction of data” and ignoring the data-generating process.\nFor starters, let’s try changing the rules of the game a bit and see how that affects our conclusion. Imagine an alternative game show, called Let’s Fake a Deal, where Monty Hall opens one of the two doors you didn’t choose, but his choice is completely random. In particular, he might open the door that has a car behind it. Tough luck! As before, we will assume that you chose Door 1 to begin the game, and the host, again, opens Door 3, revealing a goat, and offers you an option to switch. Should you? We will show that, under the new rules, although the scenario is identical, you will not gain by switching.\nTo do that, we make a table like the previous one, taking into account that there are two random and independent events—the location of the car (three possibilities) and Monty Hall’s choice of a door to open (two possibilities).\nThus the table needs to have six rows, each of which is equally likely because the events are independent.\nNow what happens if Monty Hall opens Door 3 and reveals a goat? This gives us some significant information: we must be in row 2 or 4 of the table.\nFocusing just on lines 2 and 4, we can see that the strategy of switching no longer offers us any advantage; we have a one-in-two probability of winning either way. So in the game Let’s Fake a Deal, all of Marilyn vos Savant’s critics would be right! Yet the data are the same in both games. The lesson is quite simple: the way that we obtain information is no less important than the information itself.\nTABLE 6.2. Let’s Fake a Deal possibilities.\nLet’s use our favorite trick and draw a causal diagram, which should illustrate immediately how the two games differ. First, Figure 6.1 shows a diagram for the actual Let’s Make a Deal game, in which Monty Hall must open a door that does not have a car behind it. The absence of an arrow between Your Door and Location of Car means that your choice of a door and the producers’ choice of where to put the car are independent. This means we are explicitly ruling out the possibility that the producers can read your mind (or that you can read theirs!). Even more important are the two arrows that are present in the diagram. They show that Door Opened is affected by both your choice and the producers’ choice. That is because Monty Hall must pick a door that is different both from both Your Door and Location of Car; he has to take both factors into account.\nF 6.1. Causal diagram for Let’s Make a Deal.\nIGURE As you can see from Figure 6.1, Door Opened is a collider. Once we obtain information on this variable, all our probabilities become conditional on this information. But when we condition on a collider, we create a spurious dependence between its parents. The dependence is borne out in the probabilities: if you chose Door 1, the car location is twice as likely to be behind Door 2 as Door 1; if you chose Door 2, the car location is twice as likely to be behind Door 1.\nIt is a bizarre dependence for sure, one of a type that most of us are unaccustomed to. It is a dependence that has no cause. It does not involve physical communication between the producers and us. It does not involve mental telepathy. It is purely an artifact of Bayesian conditioning: a magical transfer of information without causality. Our minds rebel at this possibility because from earliest infancy, we have learned to associate correlation with causation. If a car behind us takes all the same turns that we do, we first think it is following us (causation!). We next think that we are going to the same place (i.e., there is a common cause behind each of our turns). But causeless correlation violates our common sense. Thus, the Monty Hall paradox is just like an optical illusion or a magic trick: it uses our own cognitive machinery to deceive us.\nWhy do I say that Monty Hall’s opening of Door 3 was a “transfer of information”? It didn’t, after all, provide any evidence about whether your initial choice of Door 1 was correct. You knew in advance that he was going to open a door that hid a goat, and so he did. No one should ask you to change your beliefs if you witness the inevitable. So how come your belief in Door 2 has gone up from one-third to two-thirds? The answer is that Monty could not open Door 1 after you chose it—but he could have opened Door 2. The fact that he did not makes it more likely that he opened Door 3 because he was forced to. Thus there is more evidence than before that the car is behind Door 2. This is a general theme of Bayesian analysis: any hypothesis that has survived some test that threatens its validity becomes more likely. The greater the threat, the more likely it becomes after surviving. Door 2 was vulnerable to refutation (i.e., Monty could have opened it), but Door 1 was not. Therefore, Door 2 becomes a more likely location, while Door 1 does not. The probability that the car is behind Door 1 remains one in three.\nNow, for comparison, Figure 6.2 shows the causal diagram for Let’s Fake a Deal, the game in which Monty Hall chooses a door that is different from yours but otherwise chosen at random. This diagram still has an arrow pointing from Your Door to Door Opened because he has to make sure that his door is different from yours. However, the arrow from Location of Car to Door Opened would be deleted because he no longer cares where the car is. In this diagram, conditioning on Door Opened has absolutely no effect: Your Door and Location of Car were independent to start with, and they remain independent after we see the contents of Monty’s door. So in Let’s Fake a Deal, the car is just as likely to be behind your door as the other door, as observed in Table 6.2.\nF 6.2. Causal diagram for Let’s Fake a Deal.\nIGURE From the Bayesian point of view, the difference between the two games is that in Let’s Fake a Deal, Door 1 is vulnerable to refutation. Monty Hall could have opened Door 3 and revealed the car, which would have proven that your door choice was wrong. Because your door and Door 2 were equally vulnerable to refutation, they still have equal probability.\nAlthough purely qualitative, this analysis could be made quantitative by using Bayes’s rule or by thinking of the diagrams as a simple Bayesian network. Doing so places this problem in a unifying framework that we use for thinking about other problems. We don’t have to invent a method for solving the puzzle; the belief propagation scheme described in Chapter 3 will deliver the correct answer: that is, P(Door 2) = 2/3 for Let’s Make a Deal, and P(Door 2) = 1/2 for Let’s Fake a Deal.\nNotice that I have really given two explanations of the Monty Hall paradox. The first one uses causal reasoning to explain why we observe a spurious dependence between Your Door and Location of Car; the second uses Bayesian reasoning to explain why the probability of Door 2 goes up in Let’s Make a Deal. Both explanations are valuable. The Bayesian one accounts for the phenomenon but does not really explain why we perceive it as so paradoxical. In my opinion, a true resolution of a paradox should explain why we see it as a paradox in the first place. Why did the people who read her column believe so strongly that vos Savant was wrong? It wasn’t just the know-it-alls. Paul Erdos, one of the most brilliant mathematicians of modern times, likewise could not believe the solution until a computer simulation showed him that switching is advantageous. What deep flaw in our intuitive view of the world does this reveal? “Our brains are just not wired to do probability problems very well, so I’m not surprised there were mistakes,” said Persi Diaconis, a statistician at Stanford University, in a 1991 interview with the New York Times. True, but there’s more to it. Our brains are not wired to do probability problems, but they are wired to do causal problems. And this causal wiring produces systematic probabilistic mistakes, like optical illusions. Because there is no causal connection between My Door and Location of Car, either directly or through a common cause, we find it utterly incomprehensible that there is a probabilistic association. Our brains are not prepared to accept causeless correlations, and we need special training—through examples like the Monty Hall paradox or the ones discussed in Chapter 3—to identify situations where they can arise. Once we have “rewired our brains” to recognize colliders, the paradox ceases to be confusing.\nMORE COLLIDER BIAS: BERKSON’S PARADOX In 1946, Joseph Berkson, a biostatistician at the Mayo Clinic, pointed out a peculiarity of observational studies conducted in a hospital setting: even if two diseases have no relation to each other in the general population, they can appear to be associated among patients in a hospital.\nTo understand Berkson’s observation, let’s start with a causal diagram (Figure 6.3). It’s also helpful to think of a very extreme possibility: neither Disease 1 nor Disease 2 is ordinarily severe enough to cause hospitalization, but the combination is. In this case, we would expect Disease 1 to be highly correlated with Disease 2 in the hospitalized population.\nF 6.3. Causal diagram for Berkson’s paradox.\nIGURE By performing a study on patients who are hospitalized, we are controlling for Hospitalization. As we know, conditioning on a collider creates a spurious association between Disease 1 and Disease 2. In many of our previous examples the association was negative because of the explain-away effect, but here it is positive because both diseases have to be present for hospitalization (not just one).\nHowever, for a long time epidemiologists refused to believe in this possibility. They still didn’t believe it in 1979, when David Sackett of McMaster University, an expert on all sorts of statistical bias, provided strong evidence that Berkson’s paradox is real. In one example (see Table 6.3), he studied two groups of diseases: respiratory and bone. About 7.5 percent of people in the general population have a bone disease, and this percentage is independent of whether they have respiratory disease. But for hospitalized people with respiratory disease, the frequency of bone disease jumps to 25 percent! Sackett called this phenomenon “admission rate bias” or “Berkson bias.” TABLE 6.3. Sackett’s data illustrating Berkson’s paradox.\nSackett admits that we cannot definitively attribute this effect to Berkson bias because there could also be confounding factors. The debate is, to some extent, ongoing. However, unlike in 1946 and 1979, researchers in epidemiology now understand causal diagrams and what biases they entail.\nThe discussion has now moved on to finer points of how large the bias can be and whether it is large enough to observe in causal diagrams with more variables. This is progress! Collider-induced correlations are not new. They have been found in work dating back to a 1911 study by the English economist Arthur Cecil Pigou, who compared children of alcoholic and nonalcoholic parents. They are also found, though not by that name, in the work of Barbara Burks (1926), Herbert Simon (1954), and of course Berkson. They are also not as esoteric as they may seem from my examples. Try this experiment: Flip two coins simultaneously one hundred times and write down the results only when at least one of them comes up heads. Looking at your table, which will probably contain roughly seventy-five entries, you will see that the outcomes of the two simultaneous coin flips are not independent. Every time Coin 1 landed tails, Coin 2 landed heads. How is this possible? Did the coins somehow communicate with each other at light speed? Of course not. In reality you conditioned on a collider by censoring all the tails-tails outcomes.\nIn The Direction of Time, published posthumously in 1956, philosopher Hans Reichenbach made a daring conjecture called the “common cause principle.” Rebutting the adage “Correlation does not imply causation,” Reichenbach posited a much stronger idea: “No correlation without causation.” He meant that a correlation between two variables, X and Y, cannot come about by accident. Either one of the variables causes the other, or a third variable, say Z, precedes and causes them both.\nOur simple coin-flip experiment proves that Reichenbach’s dictum was too strong, because it neglects to account for the process by which observations are selected. There was no common cause of the outcome of the two coins, and neither coin communicated its result to the other. Nevertheless, the outcomes on our list were correlated. Reichenbach’s error was his failure to consider collider structures—the structure behind the data selection. The mistake was particularly illuminating because it pinpoints the exact flaw in the wiring of our brains. We live our lives as if the common cause principle were true. Whenever we see patterns, we look for a causal explanation. In fact, we hunger for an explanation, in terms of stable mechanisms that lie outside the data. The most satisfying kind of explanation is direct causation: X causes Y. When that fails, finding a common cause of X and Y will usually satisfy us. By comparison, colliders are too ethereal to satisfy our causal appetites. We still want to know the mechanism through which the two coins coordinate their behavior. The answer is a crushing disappointment. They do not communicate at all. The correlation we observe is, in the purest and most literal sense, an illusion. Or perhaps even a delusion: that is, an illusion we brought upon ourselves by choosing which events to include in our data set and which to ignore. It is important to realize that we are not always conscious of making this choice, and this is one reason that collider bias can so easily trap the unwary. In the two-coin experiment, the choice was conscious: I told you not to record the trials with two tails. But on plenty of occasions we aren’t aware of making the choice, or the choice is made for us.\nIn the Monty Hall paradox, the host opens the door for us. In Berkson’s paradox, an unwary researcher might choose to study hospitalized patients for reasons of convenience, without realizing that he is biasing his study.\nThe distorting prism of colliders is just as prevalent in everyday life. As Jordan Ellenberg asks in How Not to Be Wrong, have you ever noticed that, among the people you date, the attractive ones tend to be jerks? Instead of constructing elaborate psychosocial theories, consider a simpler explanation.\nYour choice of people to date depends on two factors: attractiveness and personality. You’ll take a chance on dating a mean attractive person or a nice unattractive person, and certainly a nice attractive person, but not a mean unattractive person. It’s the same as the two-coin example, when you censored tails-tails outcomes. This creates a spurious negative correlation between attractiveness and personality. The sad truth is that unattractive people are just as mean as attractive people—but you’ll never realize it, because you’ll never date somebody who is both mean and unattractive.\nSIMPSON’S PARADOX Now that we have shown that TV producers don’t really have telepathic abilities and coins cannot communicate with one another, what other myths can we explode? Let’s start with the myth of the bad/bad/good, or BBG, drug.\nImagine a doctor—Dr. Simpson, we’ll call him—reading in his office about a promising new drug (Drug D) that seems to reduce the risk of a heart attack. Excitedly, he looks up the researchers’ data online. His excitement cools a little when he looks at the data on male patients and notices that their risk of a heart attack is actually higher if they take Drug D. “Oh well, he says, “Drug D must be very effective for women.” But then he turns to the next table, and his disappointment turns to bafflement. “What is this?” Dr. Simpson exclaims. “It says here that women who took Drug D were also at higher risk of a heart attack. I must be losing my marbles! This drug seems to be bad for women, bad for men, but good for people.” Are you perplexed too? If so, you are in good company. This paradox, first discovered by a real-life statistician named Edward Simpson in 1951, has been bothering statisticians for more than sixty years—and it remains vexing to this very day. Even in 2016, as I was writing this book, four new articles (including a PhD dissertation) came out, attempting to explain Simpson’s paradox from four different points of view.\nIn 1983 Melvin Novick wrote, “The apparent answer is that when we know that the gender of the patient is male or when we know that it is female we do not use the treatment, but if the gender is unknown we should use the treatment! Obviously that conclusion is ridiculous.” I completely agree. It is ridiculous for a drug to be bad for men and bad for women but good for people. So one of these three assertions must be wrong. But which one? And why? And how is this confusion even possible? To answer these questions, we of course need to look at the (fictional) data that puzzled our good Dr. Simpson so much. The study was observational, not randomized, with sixty men and sixty women. This means that the patients themselves decided whether to take or not to take the drug. Table 6.4 shows how many of each gender received Drug D and how many were subsequently diagnosed with heart attack.\nLet me emphasize where the paradox is. As you can see, 5 percent (one in twenty) of the women in the control group later had a heart attack, compared to 7.5 percent of the women who took the drug. So the drug is associated with a higher risk of heart attack for women. Among the men, 30 percent in the control group had a heart attack, compared to 40 percent in the treatment group. So the drug is associated with a higher risk of heart attack among men.\nDr. Simpson was right.\nTABLE 6.4. Fictitious data illustrating Simpson’s paradox.\nBut now look at the third line of the table. Among the control group, 22 percent had a heart attack, but in the treatment group only 18 percent did. So, if we judge on the basis of the bottom line, Drug D seems to decrease the risk of heart attack in the population as a whole. Welcome to the bizarre world of Simpson’s paradox! For almost twenty years, I have been trying to convince the scientific community that the confusion over Simpson’s paradox is a result of incorrect application of causal principles to statistical proportions. If we use causal notation and diagrams, we can clearly and unambiguously decide whether Drug D prevents or causes heart attacks. Fundamentally, Simpson’s paradox is a puzzle about confounding and can thus be resolved by the same methods we used to resolve that mystery. Curiously, three of the four 2016 papers that I mentioned continue to resist this solution.\nAny claim to resolve a paradox (especially one that is decades old) should meet some basic criteria. First, as I said above in connection with the Monty Hall paradox, it should explain why people find the paradox surprising or unbelievable. Second, it should identify the class of scenarios in which the paradox can occur. Third, it should inform us of scenarios, if any, in which the paradox cannot occur. Finally, when the paradox does occur, and we have to make a choice between two plausible yet contradictory statements, it should tell us which statement is correct.\nLet’s start with the question of why Simpson’s paradox is surprising. To explain this, we should distinguish between two things: Simpson’s reversal and Simpson’s paradox.\nSimpson’s reversal is a purely numerical fact: as seen in Table 6.4, it is a reversal in relative frequency of a particular event in two or more different samples upon merging the samples. In our example, we saw that 3/40 &gt; 1/20 (these were the frequencies of heart attack among women with and without Drug D) and 8/20 &gt; 12/40 (the frequencies among men). Yet when we combined women and men, the inequality reversed direction: (3 + 8)/(40 + 20) &lt; (1 + 12)/(20 + 40). If you thought such a reversal mathematically impossible, then you were probably basing your reaction on misapplied or misremembered properties of fractions. Many people seem to believe that if A/B &gt; a/b and C/D &gt; c/d, then it follows that (A + C)/(B + D) &gt; (a + c)/(b + d).\nBut this folk wisdom is simply wrong. The example we have just given refutes it.\nSimpson’s reversal can be found in real-world data sets. For baseball fans, here is a lovely example concerning two star baseball players, David Justice and Derek Jeter. In 1995, Justice had a higher batting average, .253 to .250. In 1996, Justice had a higher batting average again, .321 to .314. And in 1997, he had a higher batting average than Jeter for the third season in a row, .329 to .291. Yet over all three seasons combined, Jeter had the higher average! Table 6.5 shows the calculations for readers who would like to check them.\nHow can one player be a worse hitter than the other in 1995, 1996, and 1997 but better over the three-year period? This reversal seems just like the BBG drug. In fact it isn’t possible; the problem is that we have used an overly simple word (“better”) to describe a complex averaging process over uneven seasons. Notice that the at bats (the denominators) are not distributed evenly year to year. Jeter had very few at bats in 1995, so his rather low batting average that year had little effect on his overall average. On the other hand, Justice had many more at bats in his least productive year, 1995, and that brought his overall batting average down. Once you realize that “better hitter” is defined not by an actual head-to-head competition but by a weighted average that takes into account how often each player played, I think the surprise starts to wane.\nTABLE 6.5. Data (not fictitious) illustrating Simpson’s reversal.\nThere is no question that Simpson’s reversal is surprising to some people, even baseball fans. Every year I have some students who cannot believe it at first. But then they go home, work out some examples like the two I have shown here, and come to terms with it. It simply becomes part of their new and slightly deeper understanding of how numbers (and especially aggregates of populations) work. I do not call Simpson’s reversal a paradox because it is, at most, simply a matter of correcting a mistaken belief about the behavior of averages. A paradox is more than that: it should entail a conflict between two deeply held convictions.\nFor professional statisticians who work with numbers every day of their lives, there is even less reason to consider Simpson’s reversal a paradox. A simple arithmetic inequality could not possibly puzzle and fascinate them to such an extent that they would still be writing articles about it sixty years later.\nNow let’s go back to our main example, the paradox of the BBG drug. I’ve explained why the three statements “bad for men,” “bad for women,” and “good for people,” when interpreted as an increase or decrease in proportions, are not mathematically contradictory. Yet it may still seem to you that they are physically impossible. A drug can’t simultaneously cause me and you to have a heart attack and at the same time prevent us both from having heart attacks.\nThis intuition is universal; we develop it as two-year-olds, long before we start learning about numbers and fractions. So I think you will be relieved to find out that you do not have to abandon your intuition. A BBG drug indeed does not exist and will never be invented, and we can prove it mathematically.\nThe first person to bring attention to this intuitively obvious principle was the statistician Leonard Savage, who in 1954 called it the “sure-thing principle.” He wrote, A businessman contemplates buying a certain piece of property. He considers the outcome of the next presidential election relevant. So, to clarify the matter to himself, he asks whether he would buy if he knew that the Democratic candidate were going to win, and decides that he would. Similarly, he considers whether he would buy if he knew that the Republican candidate were going to win, and again finds that he would. Seeing that he would buy in either event, he decides that he should buy, even though he does not know which event obtains, or will obtain, as we would ordinarily say. It is all too seldom that a decision can be arrived at on the basis of this principle, but… I know of no other extra-logical principle governing decisions that finds such ready acceptance.\nSavage’s last statement is particularly perceptive: he realizes that the “sure- thing principle” is extralogical. In fact, when properly interpreted it is based on causal, not classical, logic. Also, he says he “know[s] of no other… principle… that finds such ready acceptance.” Obviously he has talked about it with many people and they found the line of reasoning very compelling.\nTo connect Savage’s sure-thing principle to our previous discussion, suppose that the choice is actually between two properties, A and B. If the Democrat wins, the businessman has a 5 percent chance of making $1 on Property A and an 8 percent chance of making $1 on Property B. So B is preferred to A. If the Republican wins, he has a 30 percent chance of making $1 on Property A and a 40 percent chance of making $1 on Property B. Again, B is preferred to A. According to the sure-thing principle, he should definitely buy Property B. But sharp-eyed readers may notice that the numerical quantities are the same as in the Simpson story, and this may alert us that buying Property B may be too hasty a decision.\nIn fact, the argument above has a glaring flaw. If the businessman’s decision to buy can change the election’s outcome (for example, if the media watched his actions), then buying Property A may be in his best interest. The harm of electing the wrong president may outweigh whatever financial gain he might extract from the deal, once a president is elected.\nTo make the sure-thing principle valid, we must insist that the businessman’s decision will not affect the outcome of the election. As long as the businessman is sure his decision won’t affect the likelihood of a Democratic or Republican victory, he can go ahead and buy Property B.\nOtherwise, all bets are off. Note that the missing ingredient (which Savage neglected to state explicitly) is a causal assumption. A correct version of his principle would read as follows: an action that increases the probability of a certain outcome assuming either that Event C occurred or that Event C did not occur will also increase its probability if we don’t know whether C occurred… provided that the action does not change the probability of C. In particular, there is no such thing as a BBG drug. This corrected version of Savage’s sure-thing principle does not follow from classical logic: to prove it, you need a causal calculus invoking the do-operator. Our strong intuitive belief that a BBG drug is impossible suggests that humans (as well as machines programmed to emulate human thought) use something like the do- calculus to guide their intuition.\nAccording to the corrected sure-thing principle, one of the following three statements must be false: Drug D increases the probability of heart attack in men and women; Drug D decreases the probability of heart attack in the population as a whole; and the drug does not change the number of men and women. Since it’s very implausible that a drug would change a patient’s sex, one of the first two statements must be false.\nWhich is it? In vain will you seek guidance from Table 6.4. To answer the question, we must look beyond the data to the data-generating process. As always, it is practically impossible to discuss that process without a causal diagram.\nThe diagram in Figure 6.4 encodes the crucial information that gender is unaffected by the drug and, in addition, gender affects the risk of heart attack (men being at greater risk) and whether the patient chooses to take Drug D. In the study, women clearly had a preference for taking Drug D and men preferred not to. Thus Gender is a confounder of Drug and Heart Attack. For an unbiased estimate of the effect of Drug on Heart Attack, we must adjust for the confounder. We can do that by looking at the data for men and women separately, then taking the average: F 6.4. Causal diagram for the Simpson’s paradox example.\nIGURE • For women, the rate of heart attacks was 5 percent without Drug D and 7.5 percent with Drug D.\n• For men, the rate of heart attacks was 30 percent without Drug D and 40 percent with.\n• Taking the average (because men and women are equally frequent in the general population), the rate of heart attacks without Drug D is 17.5 percent (the average of 5 and 30), and the rate with Drug D is 23.75 percent (the average of 7.5 and 40).\nThis is the clear and unambiguous answer we were looking for. Drug D isn’t BBG, it’s BBB: bad for women, bad for women, and bad for people.\nI don’t want you to get the impression from this example that aggregating the data is always wrong or that partitioning the data is always right. It depends on the process that generated the data. In the Monty Hall paradox, we saw that changing the rules of the game also changed the conclusion. The same principle works here. I’ll use a different story to demonstrate when pooling the data would be appropriate. Even though the data will be precisely the same, the role of the “lurking third variable” will differ and so will the conclusion.\nLet’s begin with the assumption that blood pressure is known to be a possible cause of heart attack, and Drug B is supposed to reduce blood pressure. Naturally, the Drug B researchers wanted to see if it might also reduce heart attack risk, so they measured their patients’ blood pressure after treatment, as well as whether they had a heart attack.\nTable 6.6 shows the data from the study of Drug B. It should look amazingly familiar: the numbers are the same as in Table 6.4! Nevertheless, the conclusion is exactly the opposite. As you can see, taking Drug B succeeded in lowering the patients’ blood pressure: among the people who took it, twice as many had low blood pressure afterward (forty out of sixty, compared to twenty out of sixty in the control group). In other words, it did exactly what an anti–heart attack drug should do. It moved people from the higher-risk category into the lower-risk category. This factor outweighs everything else, and we can justifiably conclude that the aggregated part of Table 6.6 gives us the correct result.\nTABLE 6.6. Fictitious data for blood pressure example.\nAs usual, a causal diagram will make everything clear and allow us to derive the result mechanically, without even thinking about the data or whether the drug lowers or increases blood pressure. In this case our “lurking third variable” is Blood Pressure, and the diagram looks like Figure 6.5. Here, Blood Pressure is a mediator rather than a confounder. A single glance at the diagram reveals that there is no confounder of the Drug Heart Attack relationship (i.e., no back-door path), so stratifying the data is unnecessary. In fact, conditioning on Blood Pressure would disable one of the causal paths (maybe the main causal path) by which the drug works. For both these reasons, our conclusion is the exact opposite of what it was for Drug D: Drug B works, and the aggregate data reveal this fact.\nFrom a historical point of view, it is noteworthy that Simpson, in his 1951 paper that started all the ruckus, did exactly the same thing that I have just done. He presented two stories with exactly the same data. In one example, it was intuitively clear that aggregating the data was, in his words, “the sensible interpretation”; in the other example, partitioning the data was more sensible.\nSo Simpson understood that there was a paradox, not just a reversal.\nHowever, he suggested no resolution to the paradox other than common sense. Most importantly, he did not suggest that, if the story contains extra information that makes the difference between “sensible” and “not sensible,” perhaps statisticians should embrace that extra information in their analysis.\nF 6.5. Causal diagram for the Simpson’s paradox example (second version).\nIGURE Dennis Lindley and Melvin Novick considered this suggestion in 1981, but they could not reconcile themselves to the idea that the correct decision depends on the causal story, not on the data. They confessed, “One possibility would be to use the language of causation.… We have not chosen to do this; nor to discuss causation, because the concept, although widely used, does not seem to be well-defined.” With these words, they summarized the frustration of five generations of statisticians, recognizing that causal information is badly needed but the language for expressing it is hopelessly lacking. In 2009, four years before his death at age ninety, Lindley confided in me that he would not have written those words if my book had been available in 1981.\nSome readers of my books and articles have suggested that the rule governing data aggregation and separation rests simply on the temporal precedence of the treatment and the “lurking third variable.” They argue that we should aggregate the data in the case of blood pressure because the blood pressure measurement comes after the patient takes the drug, but we should stratify the data in the case of gender because it is determined before the patient takes the drug. While this rule will work in a great many cases, it is not foolproof. A simple case is that of M-bias (Game 4 in Chapter 4). Here B can precede A; yet we should still not condition on B, because that would violate the back-door criterion. We should consult the causal structure of the story, not the temporal information.\nFinally, you might wonder if Simpson’s paradox occurs in the real world.\nThe answer is yes. It is certainly not common enough for statisticians to encounter on a daily basis, but nor is it completely unknown, and it probably happens more often than journal articles report. Here are two documented cases: • In an observational study published in 1996, open surgery to remove kidney stones had a better success rate than endoscopic surgery for small kidney stones. It also had a better success rate for large kidney stones. However, it had a lower success rate overall. Just as in our first example, this was a case where the choice of treatment was related to the severity of the patients’ case: larger stones were more likely to lead to open surgery and also had a worse prognosis.\n• In a study of thyroid disease published in 1995, smokers had a higher survival rate (76 percent) over twenty years than nonsmokers (69 percent). However, the nonsmokers had a better survival rate in six out of seven age groups, and the difference was minimal in the seventh. Age was clearly a confounder of Smoking and Survival: the average smoker was younger than the average nonsmoker (perhaps because the older smokers had already died). Stratifying the data by age, we conclude that smoking has a negative impact on survival.\nBecause Simpson’s paradox has been so poorly understood, some statisticians take precautions to avoid it. All too often, these methods avoid the symptom, Simpson’s reversal, without doing anything about the disease, confounding. Instead of suppressing the symptoms, we should pay attention to them. Simpson’s paradox alerts us to cases where at least one of the statistical trends (either in the aggregated data, the partitioned data, or both) cannot represent the causal effects. There are, of course, other warning signs of confounding. The aggregated estimate of the causal effect could, for example, be larger than each of the estimates in each of the strata; this likewise should not happen if we have controlled properly for confounders.\nCompared to such signs, however, Simpson’s reversal is harder to ignore precisely because it is a reversal, a qualitative change in the sign of the effect.\nThe idea of a BBG drug would evoke disbelief even from a three-year-old child—and rightly so.\nSIMPSON’S PARADOX IN PICTURES So far most of our examples of Simpson’s reversal and paradox have involved binary variables: a patient either got Drug D or didn’t and either had a heart attack or didn’t. However, the reversal can also occur with continuous variables and is perhaps easier to understand in that case because we can draw a picture.\nConsider a study that measures weekly exercise and cholesterol levels in various age groups. When we plot hours of exercise on the x-axis and cholesterol on the y-axis, as in Figure 6.6(a), we see in each age group a downward trend, indicating perhaps that exercise reduces cholesterol. On the other hand, if we use the same scatter plot but don’t segregate the data by age, as in Figure 6.6(b), then we see a pronounced upward trend, indicating that the more people exercise, the higher their cholesterol becomes. Once again we seem to have a BBG drug situation, where Exercise is the drug: it seems to have a beneficial effect in each age group but a harmful effect on the population as a whole.\nTo decide whether Exercise is beneficial or harmful, as always, we need to consult the story behind the data. The data show that older people in our population exercise more. Because it seems more likely that Age causes Exercise rather than vice versa, and since Age may have a causal effect on Cholesterol, we conclude that Age may be a confounder of Exercise and Cholesterol. So we should control for Age. In other words, we should look at the age-segregated data and conclude that exercise is beneficial, regardless of age.\nF 6.6. Simpson’s paradox: exercise appears to be beneficial (downward slope) IGURE in each age group but harmful (upward slope) in the population as a whole.\nA cousin of Simpson’s paradox has also been lurking in the statistical literature for decades and lends itself nicely to a visual interpretation. Frederic Lord originally stated this paradox in 1967. It’s again fictitious, but fictitious examples (like Einstein’s thought experiments) always provide a good way to probe the limits of our understanding.\nLord posits a school that wants to study the effects of the diet it is providing in its dining halls and in particular whether it has different effects on girls and boys. To this end, the students’ weight is measured in September and again the following June. Figure 6.7 plots the results, with the ellipses once again representing a scatter plot of data. The university retains two statisticians, who look at the data and come to opposite conclusions.\nThe first statistician looks at the weight distribution for girls as a whole and notes that the average weight of the girls is the same in June as in September. (This can be seen from the symmetry of the scatter plot around the line W = W , i.e., final weight = initial weight.) Individual girls may, of F I course, gain or lose weight, but the average weight gain is zero. The same observation is true for the boys. Therefore, the statistician concludes that the diet has no differential effect on the sexes.\nF 6.7. Lord’s paradox. (Ellipses represent scatter plots of data.) As a whole, IGURE neither boys nor girls gain weight during the year, but in each stratum of the initial weight, boys tend to gain more than girls.\nThe second statistician, on the other hand, argues that because the final weight of a student is strongly influenced by his or her initial weight, we should stratify the students by initial weight. If you make a vertical slice through both ellipses, which corresponds to looking only at the boys and girls with a particular value of the initial weight (say W in Figure 6.7), you will 0 notice that the vertical line intersects the Boys ellipse higher up than it does the Girls ellipse, although there is a certain amount of overlap. This means that boys who started with weight W will have, on average, a higher final 0 weight (W ) than the girls who started with weight W . Accordingly, Lord F 0 writes, “the second statistician concludes, as is customary in such cases, that the boys showed significantly more gain in weight than the girls when proper allowance is made for differences in initial weight between the sexes.” What is the school’s dietitian to do? Lord writes, “The conclusions of each statistician are visibly correct.” That is, you don’t have to crunch any numbers to see that two solid arguments are leading to two different conclusions. You need only look at the figure. In Figure 6.7, we can see that boys gain more weight than girls in every stratum (every vertical cross section). Yet it’s equally obvious that both boys and girls gained nothing overall. How can that be? Is not the overall gain just an average of the stratum-specific gains? Now that we are experienced pros at the fine points of Simpson’s paradox and the sure-thing principle, we know what is wrong with that argument. The sure-thing principle works only in cases where the relative proportion of each subpopulation (each weight class) does not change from group to group. Yet, in Lord’s case, the “treatment” (gender) very strongly affects the percentage of students in each weight class.\nSo we can’t rely on the sure-thing principle, and that brings us back to square one. Who is right? Is there or isn’t there a difference in the average weight gains between boys and girls when proper allowance is made for differences in the initial weight between the sexes? Lord’s conclusion is very pessimistic: “The usual research study of this type is attempting to answer a question that simply cannot be answered in any rigorous way on the basis of available data.” Lord’s pessimism spread beyond statistics and has led to a rich and quite pessimistic literature in epidemiology and biostatistics on how to compare groups that differ in “baseline” statistics.\nI will show now why Lord’s pessimism is unjustified. The dietitian’s question can be answered in a rigorous way, and as usual the starting point is to draw a causal diagram, as in Figure 6.8. In this diagram, we see that Sex (S) is a cause of initial weight (W ) and final weight (W ). Also, W affects W I F I F independently of gender, because students of either gender who weigh more at the beginning of the year tend to weigh more at the end of the year, as shown by the scatter plots in Figure 6.7. All these causal assumptions are commonsensical; I would not expect Lord to disagree with them.\nThe variable of interest to Lord is the weight gain, shown as Y in this diagram. Note that Y is related to W and W in a purely mathematical, I F deterministic way: Y = W –W . This means that the correlations between Y F I and W (or Y and W ) are equal to –1 (or 1), and I have shown this I F information on the diagram with the coefficients –1 and +1.\nF 6.8. Causal diagram for Lord’s paradox.\nIGURE The first statistician simply compares the difference in weight gain between girls and boys. No back doors between S and Y need to be blocked, so the observed, aggregated data provide the answer: no effect, as the first statistician concluded.\nBy contrast, it is hard to even formulate the question that the second statistician is trying to answer (that is, the “correctly formulated query” described in the Introduction). He wants to ensure that “proper allowance is made for differences in initial weight between the two sexes,” which is language you would usually use when controlling for a confounder. But W is I not a confounder of S and Y. It is actually a mediating variable if we consider Sex to be the treatment. Thus, the query answered by controlling for W does I not have the usual causal effect interpretation. Such control may at best provide an estimate of the “direct effect” of gender on weight, which we will discuss in Chapter 9. However, it seems unlikely that this is what the second statistician had in mind; more likely he was adjusting out of habit. And yet his argument is such an easy trap to fall into: “Is not the overall gain just an average of the stratum-specific gains?” Not if the strata themselves are shifting under treatment! Remember that Sex, not Diet, is the treatment, and Sex definitely changes the proportion of students in each stratum of W .\nI This last comment brings up one more curious point about Lord’s paradox as originally phrased. Although the stated intention of the school dietitian is to “determine the effects of the diet,” nowhere in his original paper does Lord mention a control diet. Therefore we can’t even say anything about the diet’s effects. A 2006 paper by Howard Wainer and Lisa Brown attempts to remedy this defect. They change the story so that the quantity of interest is the effect of diet (not gender) on weight gain, while gender differences are not considered. In their version, the students eat in one of two dining halls with different diets. Accordingly, the two ellipses of Figure 6.7 represent two dining halls, each serving a different diet, as depicted in Figure 6.9(a). Note that the students who weigh more in the beginning tend to eat in dining hall B, while the ones who weigh less eat in dining hall A.\nLord’s paradox now surfaces with greater clarity, since the query is well defined as the effect of diet on gain. The first statistician claims, based on symmetry considerations, that switching from Diet A to B would have no effect on weight gain (the difference W – W has the same distribution in F I both ellipses). The second statistician compares the final weights under Diet A to those of Diet B for a group of students starting with weight W and 0 concludes that the students on Diet B gain more weight.\nAs before, the data (Figure 6.9[a]) can’t tell you whom to believe, and this is indeed what Wainer and Brown conclude. However, a causal diagram (Figure 6.9[b]) can settle the issue. There are two significant changes between Figure 6.8 and Figure 6.9(b). First, the causal variable becomes D (for “diet”), not S. Second, the arrow that originally pointed from S to W now reverses I direction: the initial weight now affects the diet, so the arrow points from W I to D.\nIn this diagram, W is a confounder of D and W , not a mediator.\nI F Therefore, the second statistician would be unambiguously correct here.\nControlling for the initial weight is essential to deconfound D and W (as well F as D and Y). The first statistician would be wrong, because he would only be measuring statistical associations, not causal effects.\nTo summarize, for us the main lesson of Lord’s paradox is that it is no more of a paradox than Simpson’s. In one paradox, the association reverses; in the other, it disappears. In either case, the causal diagram will tell us what procedure we need to use. However, for statisticians who are trained in “conventional” (i.e., model-blind) methodology and avoid using causal lenses, it is deeply paradoxical that the correct conclusion in one case would be incorrect in another, even though the data look exactly the same.\nF 6.9. Wainer and Brown’s revised version of Lord’s paradox and the IGURE corresponding causal diagram.\nNow that we have a thorough grounding in colliders, confounders, and the perils that both pose, we are at last prepared to reap the fruits of our labor. In the next chapter we begin our ascent up the Ladder of Causation, beginning with rung two: intervention.\nScaling “Mount Intervention.” The most familiar methods to estimate the effect of an intervention, in the presence of confounders, are the back-door adjustment and instrumental variables. The method of front-door adjustment was unknown before the introduction of causal diagrams. The do-calculus, which my students have fully automated, makes it possible to tailor the adjustment method to any particular causal diagram. (Source: Drawing by Dakota Harr.)",
    "crumbs": [
      "Causal Inference",
      "The book of why"
    ]
  },
  {
    "objectID": "extracted/The Book of Why - Judea Pearl.html#beyond-adjustment-the-conquest-of-mount-intervention",
    "href": "extracted/The Book of Why - Judea Pearl.html#beyond-adjustment-the-conquest-of-mount-intervention",
    "title": "The book of why",
    "section": "7. BEYOND ADJUSTMENT: THE CONQUEST OF MOUNT INTERVENTION",
    "text": "7. BEYOND ADJUSTMENT: THE CONQUEST OF MOUNT INTERVENTION\nHe whose actions exceed his theory, his theory shall endure.\n—RABBI HANINA BEN DOSA (FIRST CENTURY AD) I N this chapter we finally make our bold ascent onto the second level of the Ladder of Causation, the level of intervention—the holy grail of causal thinking from antiquity to the present day. This level is involved in the struggle to predict the effects of actions and policies that haven’t been tried yet, ranging from medical treatments to social programs, from economic policies to personal choices. Confounding was the primary obstacle that caused us to confuse seeing with doing. Having removed this obstacle with the tools of “path blocking” and the back-door criterion, we can now map the routes up Mount Intervention with systematic precision. For the novice climber, the safest routes up the mountain are the back-door adjustment and its various cousins, some going under the rubric of “front-door adjustment” and some under “instrumental variables.” But these routes may not be available in all cases, so for the experienced climber this chapter describes a “universal mapping tool” called the do- calculus, which allows the researcher to explore and plot all possible routes up Mount Intervention, no matter how twisty. Once a route has been mapped, and the ropes and carabiners and pitons are in place, our assault on the mountain will assuredly result in a successful conquest! THE SIMPLEST ROUTE: THE BACK-DOOR ADJUSTMENT FORMULA For many researchers, the most (perhaps only) familiar method of predicting the effect of an intervention is to “control” for confounders using the adjustment formula. This is the method to use if you are confident that you have data on a sufficient set of variables (called deconfounders) to block all the back-door paths between the intervention and the outcome. To do this, we measure the average causal effect of an intervention by first estimating its effect at each “level,” or stratum, of the deconfounder. We then compute a weighted average of those strata, where each stratum is weighted according to its prevalence in the population. If, for example, the deconfounder is gender, we first estimate the causal effect for males and females. Then we average the two, if the population is (as usual) half male and half female. If the proportions are different—say, two-thirds male and one-third female—then to estimate the average causal effect we would take a correspondingly weighted average.\nThe role that the back-door criterion plays in this procedure is to guarantee that the causal effect in each stratum of the deconfounder is none other than the observed trend in this stratum. So the causal effect can be estimated stratum by stratum from the data. Absent the back-door criterion, researchers have no guarantee that any adjustment is legitimate.\nThe fictitious drug example in Chapter 6 was the simplest situation possible: one treatment variable (Drug D), one outcome (Heart Attack), one confounder (Gender), and all three variables are binary. The example shows how we take a weighted average of the conditional probabilities P(heart attack | drug) in each gender stratum. But the procedure described above can be adapted easily to handle more complicated situations, including multiple (de)confounders and multiple strata.\nHowever, in many cases, the variables X, Y, or Z take numerical values— for example, income or height or birth weight. We saw this in our visual example of Simpson’s paradox. Because the variable could take (at least, for all practical purposes) infinite possible values, we cannot make a table listing all the possibilities, as we did in Chapter 6.\nAn obvious remedy is to separate the numerical values into a finite and manageable number of categories. There is nothing in principle wrong with this option, but the choice of categories is a bit arbitrary. Worse, if we have more than a handful of adjusted variables, we get an exponential blowup in the number of categories. This will make the procedure computationally prohibitive; worse yet, many of the strata will end up devoid of samples and thus incapable of providing any probability estimates whatsoever.\nStatisticians have devised ingenious methods for handling this “curse of dimensionality” problem. Most involve some sort of extrapolation, whereby a smooth function is fitted to the data and used to fill in the holes created by the empty strata.\nThe most widely used smoothing function is of course a linear approximation, which served as the workhorse of most quantitative work in the social and behavioral sciences in the twentieth century. We have seen how Sewall Wright embedded his path diagrams into the context of linear equations, and we noted there one computational advantage of this embedding: every causal effect can be represented by a single number (the path coefficient). A second and no less important advantage of linear approximations is the astonishing simplicity of computing the adjustment formula.\nWe have previously seen Francis Galton’s invention of a regression line, which takes a cloud of data points and interpolates the best-fitting line through that cloud. In the case of one treatment variable (X) and one outcome variable (Y), the equation of the regression line will look like this: Y = aX + b.\nThe parameter a (often denoted by r , the regression coefficient of Y on X) YX tells us the average observed trend: a one-unit increase of X will, on average, produce an a-unit increase in Y. If there are no confounders of Y and X, then we can use this as our estimate of an intervention to increase X by one unit.\nBut what if there is a confounder, Z? In this case, the correlation coefficient r will not give us the average causal effect; it only gives us the YX average observed trend. That was the case in Wright’s problem of the guinea pig birth weights, discussed in Chapter 2, where the apparent benefit (5.66 grams) of an extra day’s gestation was biased because it was confounded with the effect of a smaller litter size. But there is still a way out: by plotting all three variables together, with each value of (X, Y, Z) describing one point in space. In this case, the data will form a cloud of points in XYZ-space. The analogue of a regression line is a regression plane, which has an equation that looks like Y = aX + bZ + c. We can easily compute a, b, c from the data. Here something wonderful happens, which Galton did not realize but Karl Pearson and George Udny Yule certainly did. The coefficient a gives us the regression coefficient of Y on X already adjusted for Z. (It is called a partial regression coefficient and written r .) YX.Z Thus we can skip the cumbersome procedure of regressing Y on X for each level of Z and computing the weighted average of the regression coefficients.\nNature already does all the averaging for us! We need only compute the plane that best fits the data. A statistical package will do it in no time. The coefficient a in the equation of that plane, Y = aX + bZ + c, will automatically adjust the observed trend of Y on X to account for the confounder Z. If Z is the only confounder, then a is the average causal effect of X on Y. A truly miraculous simplification! You can easily extend the procedure to deal with multiple variables as well. If the set of variables Z should happen to satisfy the back-door condition, then the coefficient of X in the regression equation, a, will be none other than the average causal effect of X on Y.\nFor this reason generations of researchers came to believe that adjusted (or partial) regression coefficients are somehow endowed with causal information that unadjusted regression coefficients lack. Nothing could be further from the truth. Regression coefficients, whether adjusted or not, are only statistical trends, conveying no causal information in themselves. r represents the YX.Z causal effect of X on Y, whereas r does not, exclusively because we have a YX diagram showing Z as a confounder of X and Y.\nIn short, sometimes a regression coefficient represents a causal effect, and sometimes it does not—and you can’t rely on the data alone to tell you the difference. Two additional ingredients are required to endow r with YX.Z causal legitimacy. First, the path diagram should represent a plausible picture of reality, and second, the adjusted variable(s) Z should satisfy the back-door criterion.\nThat is why it was so crucial that Sewall Wright distinguished path coefficients (which represent causal effects) from regression coefficients (which represent trends of data points). Path coefficients are fundamentally different from regression coefficients, although they can often be computed from the latter. Wright failed to realize, however, as did all path analysts and econometricians after him, that his computations were unnecessarily complicated. He could have gotten the path coefficients from partial correlation coefficients, if only he had known that the proper set of adjusting variables can be identified, by inspection, from the path diagram itself.\nKeep in mind also that the regression-based adjustment works only for linear models, which involve a major modeling assumption. With linear models, we lose the ability to model nonlinear interactions, such as when the effect of X on Y depends on the level of Z. The back-door adjustment, on the other hand, still works fine even when we have no idea what functions are behind the arrows in the diagrams. But in this so-called nonparametric case, we need to employ other extrapolation methods to deal with the curse of dimensionality.\nTo sum up, the back-door adjustment formula and the back-door criterion are like the front and back of a coin. The back-door criterion tells us which sets of variables we can use to deconfound our data. The adjustment formula actually does the deconfounding. In the simplest case of linear regression, partial regression coefficients perform the back-door adjustment implicitly. In the nonparametric case, we must do the adjustment explicitly, either using the back-door adjustment formula directly on the data or on some extrapolated version of it.\nYou might think that our assault on Mount Intervention would end there with complete success. Unfortunately, though, adjustment does not work at all if there is a back-door path we cannot block because we don’t have the requisite data. Yet we can still use certain tricks even in this situation. I will tell you about one of my favorite methods next, called the front-door adjustment. Even though it was published more than twenty years ago, only a handful of researchers have taken advantage of this shortcut up Mount Intervention, and I am convinced that its full potential remains untapped.\nTHE FRONT-DOOR CRITERION The debate over the causal effect of smoking occurred at least two generations too early for causal diagrams to make any contribution. We have already seen how Cornfield’s inequality helped persuade researchers that the smoking gene, or “constitutional hypothesis,” was highly implausible. But a more radical approach, using causal diagrams, could have shed more light on the hypothetical gene and possibly eliminated it from further consideration.\nSuppose that researchers had measured the tar deposits in smokers’ lungs.\nEven in the 1950s, the formation of tar deposits was suspected as one of the possible intermediate stages in the development of lung cancer. Suppose also that, just like the Surgeon General’s committee, we want to rule out R. A.\nFisher’s hypothesis that a smoking gene confounds smoking behavior and lung cancer. We might then arrive at the causal diagram in Figure 7.1.\nFigure 7.1 incorporates two very important assumptions, which we’ll suppose are valid for the purpose of our example. The first assumption is that the smoking gene has no effect on the formation of tar deposits, which are exclusively due to the physical action of cigarette smoke. (This assumption is indicated by the lack of an arrow between Smoking Gene and Tar; it does not rule out, however, random factors unrelated to Smoking Gene.) The second significant assumption is that Smoking leads to Cancer only through the accumulation of tar deposits. Thus we assume that no direct arrow points from Smoking to Cancer, and there are no other indirect pathways.\nF 7.1. Hypothetical causal diagram for smoking and cancer, suitable for front- IGURE door adjustment.\nSuppose we are doing an observational study and have collected data on Smoking, Tar, and Cancer for each of the participants. Unfortunately, we cannot collect data on the Smoking Gene because we do not know whether such a gene exists. Lacking data on the confounding variable, we cannot block the back-door path Smoking Smoking Gene Cancer. Thus we cannot use back-door adjustment to control for the effect of the confounder.\nSo we must look for another way. Instead of going in the back door, we can go in the front door! In this case, the front door is the direct causal path Smoking Tar Cancer, for which we do have data on all three variables.\nIntuitively, the reasoning is as follows. First, we can estimate the average causal effect of Smoking on Tar, because there is no unblocked back-door path from Smoking to Cancer, as the Smoking Smoking Gene Cancer Tar path is already blocked by the collider at Cancer. Because it is blocked already, we don’t even need back-door adjustment. We can simply observe P(tar | smoking) and P(tar | no smoking), and the difference between them will be the average causal effect of Smoking on Tar.\nLikewise, the diagram allows us to estimate the average causal effect of Tar on Cancer. To do this we can block the back-door path from Tar to Cancer, Tar Smoking Smoking Gene Cancer, by adjusting for Smoking. Our lessons from Chapter 4 come in handy: we only need data on a sufficient set of deconfounders (i.e., Smoking). Then the back-door adjustment formula will give us P(cancer | do(tar)) and P(cancer | do(no tar)). The difference between these is the average causal effect of Tar on Cancer.\nNow we know the average increase in the likelihood of tar deposits due to smoking and the average increase of cancer due to tar deposits. Can we combine these somehow to obtain the average increase in cancer due to smoking? Yes, we can. The reasoning goes as follows. Cancer can come about in two ways: in the presence of Tar or in the absence of Tar. If we force a person to smoke, then the probabilities of these two states are P(tar | do(smoking)) and P(no tar | do(no smoking)), respectively. If a Tar state evolves, the likelihood of causing Cancer is P(cancer | do(tar)). If, on the other hand, a No-Tar state evolves, then it would result in a Cancer likelihood of P(cancer | do(no tar)). We can weight the two scenarios by their respective probabilities under do(smoking) and in this way compute the total probability of cancer due to smoking. The same argument holds if we prevent a person from smoking, do(no smoking). The difference between the two gives us the average causal effect on cancer of smoking versus not smoking.\nAs I have just explained, we can estimate each of the do-probabilities discussed from the data. That is, we can write them mathematically in terms of probabilities that do not involve the do-operator. In this way, mathematics does for us what ten years of debate and congressional testimony could not: quantify the causal effect of smoking on cancer—provided our assumptions hold, of course.\nThe process I have just described, expressing P(cancer | do (smoking)) in terms of do-free probabilities, is called the front-door adjustment. It differs from the back-door adjustment in that we adjust for two variables (Smoking and Tar) instead of one, and these variables lie on the front-door path from Smoking to Cancer rather than the back-door path. For those readers who “speak mathematics,” I can’t resist showing you the formula (Equation 7.1), which cannot be found in ordinary statistics textbooks. Here X stands for Smoking, Y stands for Cancer, Z stands for Tar, and U (which is conspicuously absent from the formula) stands for the unobservable variable, the Smoking Gene.\nP(Y | do(X)) = ∑ P(Z = z, X) ∑ P(Y | X = x, Z = z) P(X = x) (7.1) z x Readers with an appetite for mathematics might find it interesting to compare this to the formula for the back-door adjustment, which looks like Equation 7.2.\nP(Y | do(X)) = ∑ P(Y | X, Z = z) P(Z = z) (7.2) z Even for readers who do not speak mathematics, we can make several interesting points about Equation 7.1. First and most important, you don’t see U (the Smoking Gene) anywhere. This was the whole point. We have successfully deconfounded U even without possessing any data on it. Any statistician of Fisher’s generation would have seen this as an utter miracle.\nSecond, way back in the Introduction I talked about an estimand as a recipe for computing the quantity of interest in a query. Equations 7.1 and 7.2 are the most complicated and interesting estimands that I will show you in this book.\nThe left-hand side represents the query “What is the effect of X on Y?” The right-hand side is the estimand, a recipe for answering the query. Note that the estimand contains no do’s, only see’s, represented by the vertical bars, and this means it can be estimated from data.\nAt this point, I’m sure that some readers are wondering how close this fictional scenario is to reality. Could the smoking-cancer controversy have been resolved by one observational study and one causal diagram? If we assume that Figure 7.1 accurately reflects the causal mechanism for cancer, the answer is absolutely yes. However, we now need to discuss whether our assumptions are valid in the real world.\nDavid Freedman, a longtime friend and a Berkeley statistician, took me to task over this issue. He argued that the model in Figure 7.1 is unrealistic in three ways. First, if there is a smoking gene, it might also affect how the body gets rid of foreign matter in the lungs, so that people with the gene are more vulnerable to the formation of tar deposits and people without it are more resistant. Therefore, he would draw an arrow from Smoking Gene to Tar, and in that case the front-door formula would be invalid.\nFreedman also considered it unlikely that Smoking affects Cancer only through Tar. Certainly other mechanisms could be imagined; perhaps smoking produces chronic inflammation that leads to cancer. Finally, he said, tar deposits in a living person’s lungs cannot be measured with sufficient accuracy anyway—so an observational study such as the one I have proposed cannot be conducted in the real world.\nI have no quarrel with Freedman’s criticism in this particular example. I am not a cancer specialist, and I would always have to defer to the expert opinion on whether such a diagram represents the real-world processes accurately. In fact, one of the major accomplishments of causal diagrams is to make the assumptions transparent so that they can be discussed and debated by experts and policy makers.\nHowever, the point of my example was not to propose a new mechanism for the effect of smoking but to demonstrate how mathematics, given the right situation, can eliminate the effect of confounders even without data on the confounder. And the situation can be clearly recognized. Anytime the causal effect of X on Y is confounded by one set of variables (C) and mediated by another (M) (see Figure 7.2), and, furthermore, the mediating variables are shielded from the effects of C, then you can estimate X’s effect from observational data. Once scientists are made aware of this fact, they should seek shielded mediators whenever they face incurable confounders. As Louis Pasteur said, “Fortune favors the prepared mind.” Fortunately, the virtues of front-door adjustment have not remained completely unappreciated. In 2014, Adam Glynn and Konstantin Kashin, both political scientists at Harvard (Glynn subsequently moved to Emory University), wrote a prize-winning paper that should be required reading for all quantitative social scientists. They applied the new method to a data set well scrutinized by social scientists, called the Job Training Partnership Act (JTPA) Study, conducted from 1987 to 1989. As a result of the 1982 JTPA, the Department of Labor created a job-training program that, among other services, provided participants with occupational skills, job-search skills, and work experience. It collected data on people who applied for the program, people who actually used the services, and their earnings over the subsequent eighteen months. Notably, the study included both a randomized controlled trial (RCT), where people were randomly assigned to receive services or not, and an observational study, in which people could choose for themselves.\nF 7.2. The basic setup for the front-door criterion.\nIGURE Glynn and Kashin did not draw a causal diagram, but from their description of the study, I would draw it as shown in Figure 7.3. The variable Signed Up records whether a person did or did not register for the program; the variable Showed Up records whether the enrollee did or did not actually use the services. Obviously the program can only affect earnings if the user actually shows up, so the absence of a direct arrow from Signed Up to Earnings is easy to justify.\nGlynn and Kashin refrain from specifying the nature of the confounders, but I have summed them up as Motivation. Clearly, a person who is highly motivated to increase his or her earnings is more likely to sign up. That person is also more likely to earn more after eighteen months, regardless of whether he or she shows up. The goal of the study is, of course, to disentangle the effect of this confounding factor and find out just how much the services themselves are helping.\nF 7.3. Causal diagram for the JTPA Study.\nIGURE Comparing Figure 7.2 to Figure 7.3, we can see that the front-door criterion would apply if there were no arrow from Motivation to Showed Up, the “shielding” I mentioned earlier. In many cases we could justify the absence of that arrow. For example, if the services were only offered by appointment and people only missed their appointments because of chance events unrelated to Motivation (a bus strike, a sprained ankle, etc.), then we could erase that arrow and use the front-door criterion.\nUnder the actual circumstances of the study, where the services were available all the time, such an argument is hard to make. However—and this is where things get really interesting—Glynn and Kashin tested out the front- door criterion anyway. We might think of this as a sensitivity test. If we suspect that the middle arrow is weak, then the bias introduced by treating it as absent may be very small. Judging from their results, that was the case.\nBy making certain reasonable assumptions, Glynn and Kashin derived inequalities saying whether the adjustment was likely to be too high or too low and by how much. Finally, they compared the front-door predictions and back-door predictions to the results from the randomized controlled experiment that was run at the same time. The results were impressive. The estimates from the back-door criterion (controlling for known confounders like Age, Race, and Site) were wildly incorrect, differing from the experimental benchmarks by hundreds or thousands of dollars. This is exactly what you would expect to see if there is an unobserved confounder, such as Motivation. The back-door criterion cannot adjust for it.\nOn the other hand, the front-door estimates succeeded in removing almost all of the Motivation effect. For males, the front-door estimates were well within the experimental error of the randomized controlled trial, even with the small positive bias that Glynn and Kashin predicted. For females, the results were even better: The front-door estimates matched the experimental benchmark almost perfectly, with no apparent bias. Glynn and Kashin’s work gives both empirical and methodological proof that as long as the effect of C on M (in Figure 7.2) is weak, front-door adjustment can give a reasonably good estimate of the effect of X on Y. It is much better than not controlling for C.\nGlynn and Kashin’s results show why the front-door adjustment is such a powerful tool: it allows us to control for confounders that we cannot observe (like Motivation), including those that we can’t even name. RCTs are considered the “gold standard” of causal effect estimation for exactly the same reason. Because front-door estimates do the same thing, with the additional virtue of observing people’s behavior in their own natural habitat instead of a laboratory, I would not be surprised if this method eventually becomes a serious competitor to randomized controlled trials.\nTHE DO-CALCULUS, OR MIND OVER MATTER In both the front- and back-door adjustment formulas, the ultimate goal is to calculate the effect of an intervention, P(Y | do(X)), in terms of data such as P(Y | X, A, B, Z,…) that do not involve a do-operator. If we are completely successful at eliminating the do’s, then we can use observational data to estimate the causal effect, allowing us to leap from rung one to rung two of the Ladder of Causation.\nThe fact that we were successful in these two cases (front- and back-door) immediately raises the question of whether there are other doors through which we can eliminate all the do’s. Thinking more generally, we can ask whether there is some way to decide in advance if a given causal model lends itself to such an elimination procedure. If so, we can apply the procedure and find ourselves in possession of the causal effect, without having to lift a finger to intervene. Otherwise, we would at least know that the assumptions imbedded in the model are not sufficient to uncover the causal effect from observational data, and no matter how clever we are, there is no escape from running an interventional experiment of some kind.\nThe prospect of making these determinations by purely mathematical means should dazzle anybody who understands the cost and difficulty of running randomized controlled trials, even when they are physically feasible and legally permissible. The idea dazzled me, too, in the early 1990s, not as an experimenter but as a computer scientist and part-time philosopher. Surely one of the most exhilarating experiences you can have as a scientist is to sit at your desk and realize that you can finally figure out what is possible or impossible in the real world—especially if the problem is important to society and has baffled those who have tried to solve it before you. I imagine this is how Hipparchus of Nicaea felt when he discovered he could figure out the height of a pyramid from its shadow on the ground, without actually climbing the pyramid. It was a clear victory of mind over matter.\nIndeed, the approach I took was very much inspired by the ancient Greeks (including Hipparchus) and their invention of a formal logical system for geometry. At the center of the Greeks’ logic, we find a set of axioms or self- evident truths, such as “Between any two points one can draw one and only one line.” With the help of those axioms, the Greeks could construct complex statements, called theorems, whose truth is far from evident. Take, for instance, the statement that the sum of the angles in a triangle is 180 degrees (or two right angles), regardless of its size or shape. The truth of this statement is not self-evident by any means; yet the Pythagorean philosophers of the fifth century BC were able to prove its universal truth using those self- evident axioms as building blocks.\nIf you remember your high school geometry, even just the gist of it, you will recall that proofs of theorems invariably consist of auxiliary constructions: for example, drawing a line parallel to an edge of a triangle, marking certain angles as equal, drawing a circle with a given segment as its radius, and so on. These auxiliary constructions can be regarded as temporary mathematical sentences that make assertions (or claims) about properties of the figure drawn. Each new construction is licensed by the previous ones, as well as by the axioms of geometry and perhaps some already derived theorems. For example, drawing a line parallel to one edge of a triangle is licensed by Euclid’s fifth axiom, that it is possible to draw one and only one parallel to a given line from a point outside that line. The act of drawing any of these auxiliary constructions is just a mechanical “symbol manipulation” operation; it takes the sentence previously written (or picture previously drawn) and rewrites it in a new format, whenever the rewriting is licensed by the axioms. Euclid’s greatness was to identify a short list of five elementary axioms, from which all other true geometric statements can be derived.\nNow let us return to our central question of when a model can replace an experiment, or when a “do” quantity can be reduced to a “see” quantity.\nInspired by the ancient Greek geometers, we want to reduce the problem to symbol manipulation and in this way wrest causality from Mount Olympus and make it available to the average researcher.\nFirst, let us rephrase the task of finding the effect of X on Y using the language of proofs, axioms, and auxiliary constructions, the language of Euclid and Pythagoras. We start with our target sentence, P(Y | do(X)). Our task will be complete if we can succeed in eliminating the do-operator from it, leaving only classical probability expressions, like P(Y | X) or P(Y | X, Z, W).\nWe cannot, of course, manipulate our target expression at will; the operations must conform to what do(X) means as a physical intervention. Thus, we must pass the expression through a sequence of legitimate manipulations, each licensed by the axioms and the assumptions of our model. The manipulations should preserve the meaning of the manipulated expression, only changing the format it is written in. An example of a “meaning preserving” transformation is the algebraic transformation that turns y = ax + b into ax = y – b. The relationship between x and y remains intact; only the format changes.\nWe are already familiar with some “legitimate” transformations on do- expressions. For example, Rule 1 says when we observe a variable W that is irrelevant to Y (possibly conditional on other variables Z), then the probability distribution of Y will not change. For example, in Chapter 3 we saw that the variable Fire is irrelevant to Alarm once we know the state of the mediator (Smoke). This assertion of irrelevance translates into a symbolic manipulation: P(Y | do(X), Z, W) = P(Y | do(X), Z) The stated equation holds provided that the variable set Z blocks all the paths from W to Y after we have deleted all the arrows leading into X. In the example of Fire Smoke Alarm, we have W = Fire, Z = Smoke, Y = Alarm, and Z blocks all the paths from W to Y. (In this case we do not have a variable X.) Another legitimate transformation is familiar to us from our back-door discussion. We know that if a set Z of variables blocks all back-door paths from X to Y, then conditional on Z, do(X) is equivalent to see(X). We can, therefore, write P(Y | do(X), Z) = P(Y | X, Z) if Z satisfies the back-door criterion. We adopt this as Rule 2 of our axiomatic system. While this is perhaps less self-evident than Rule 1, in the simplest cases it is Hans Reichenbach’s common-cause principle, amended so that we won’t mistake colliders for confounders. In other words, we are saying that after we have controlled for a sufficient deconfounding set, any remaining correlation is a genuine causal effect.\nRule 3 is quite simple: it essentially says that we can remove do(X) from P(Y | do(X)) in any case where there are no causal paths from X to Y. That is, P(Y | do(X)) = P(Y) if there is no path from X to Y with only forward-directed arrows. We can paraphrase this rule is follows: if we do something that does not affect Y, then the probability distribution of Y will not change. Aside from being just as self- evident as Euclid’s axioms, Rules 1 to 3 can also be proven mathematically using our arrow-deleting definition of the do-operator and basic laws of probability.\nNote that Rules 1 and 2 include conditional probabilities involving auxiliary variables Z other than X and Y. These variables can be thought of as a context in which the probability is being computed. Sometimes the presence of this context itself licenses the transformation. Rule 3 may also have auxiliary variables, but I omitted them for simplicity.\nNote that each rule has a simple syntactic interpretation. Rule 1 permits the addition or deletion of observations. Rule 2 permits the replacement of an intervention with an observation, or vice versa. Rule 3 permits the deletion or addition of interventions. All of these permits are issued under appropriate conditions, which have to be verified in any particular case from the causal diagram.\nWe are ready now to demonstrate how Rules 1 to 3 allow us to transform one formula into another until, if we are smart, we obtain an expression to our liking. Although it’s a bit elaborate, I think that nothing can substitute for actually showing you how the front-door formula is derived using a successive application of the rules of do-calculus (Figure 7.4). You do not need to follow all the steps, but I am showing you the derivation to give you the flavor of do-calculus. We begin the journey with a target expression P(Y | do(X)). We introduce auxiliary variables and transform the target expression into a do-free expression that coincides, of course, with the front-door adjustment formula. Each step of the argument gets its license from the causal diagram that relates X, Y, and the auxiliary variables or, in several cases, from subdiagrams that have had arrows erased to account for interventions. These licenses are displayed on the right-hand side.\nI feel a special attachment to the do-calculus. With these three humble rules I was able to derive the front-door formula. This was the first causal effect estimated by means other than control for confounders. I believed no one could do this without the do-calculus, so I presented it as a challenge in a statistics seminar at Berkeley in 1993 and even offered a $100 prize to anyone who could solve it. Paul Holland, who attended the seminar, wrote that he had assigned the problem as a class project and would send me the solution when ripe. (Colleagues tell me that he eventually presented a long solution at a conference in 1995, and I may owe him $100 if I could only find his proof.) Economists James Heckman and Rodrigo Pinto made the next attempt to prove the front-door formula using “standard tools” in 2015. They succeeded, albeit at the cost of eight pages of hard labor.\nF 7.4. Derivation of the front-door adjustment formula from the rules of do- IGURE calculus.\nIn a restaurant the evening before the talk, I had written the proof (very much like the one in Figure 7.4) on a napkin for David Freedman. He wrote me later to say that he had lost the napkin. He could not reconstruct the argument and asked if I had kept a copy. The next day, Jamie Robins wrote to me from Harvard, saying that he had heard about the “napkin problem” from Freedman, and he straightaway offered to fly to California to check the proof with me. I was thrilled to share with Robins the secrets of the do-calculus, and I believe that his trip to Los Angeles that year has been the key to his enthusiastic acceptance of causal diagrams. Through his and Sander Greenland’s influence, diagrams have become a second language for epidemiologists. This explains why I am so fond of the “napkin problem.” The front-door adjustment formula was a delightful surprise and an indication that do-calculus had something important to offer. However, at this point I still wondered whether the three rules of do-calculus were enough.\nWas it possible that we had missed a fourth rule that would help us solve problems that are unsolvable with only three? In 1994, when I first proposed the do-calculus, I selected these three rules because they were sufficient in any case that I knew of. I had no idea whether, like Ariadne’s thread, they would always lead me out of the maze, or I would someday encounter a maze of such fiendish complexity that I could not escape. Of course, I hoped for the best. I conjectured that whenever a causal effect is estimable from data, a sequence of steps using these three rules would eliminate the do-operator. But I could not prove it.\nThis type of problem has many precedents in mathematics and logic. The property is usually called “completeness” in mathematical logic; an axiom system that is complete has the property that the axioms suffice to derive every true statement in that language. Some very good axiom systems are incomplete: for instance, Philip Dawid’s axioms describing conditional independence in probability theory.\nIn this modern-day labyrinth tale, two groups of researchers played the role of Ariadne to my wandering Theseus: Yiming Huang and Marco Valtorta at the University of South Carolina and my own student, Ilya Shpitser, at the University of California, Los Angeles (UCLA). Both groups independently and simultaneously proved that Rules 1 to 3 suffice to get out of any do- labyrinth that has an exit. I am not sure whether the world was waiting breathlessly for their completeness result, because by then most researchers had become content with just using the front- and back-door criteria. Both teams were, however, recognized with best student paper awards at the Uncertainty in Artificial Intelligence conference in 2006.\nI confess that I was the one waiting breathlessly for this result. It tells us that if we cannot find a way to estimate P(Y | do(X)) from Rules 1 to 3, then a solution does not exist. In that case, we know that there is no alternative to conducting a randomized controlled trial. It further tells us what additional assumptions or experiments might make the causal effect estimable.\nBefore declaring total victory, we should discuss one issue with the do- calculus. Like any other calculus, it enables the construction of a proof, but it does not help us find one. It is an excellent verifier of a solution but not such a good searcher for one. If you know the correct sequence of transformations, it is easy to demonstrate to others (who are familiar with Rules 1 to 3) that the do-operator can be eliminated. However, if you do not know the correct sequence, it is not easy to discover it, or even to determine whether one exists.\nUsing the analogy with geometrical proofs, we need to decide which auxiliary construction to try next. A circle around point A? A line parallel to AB? The number of possibilities is limitless, and the axioms themselves provide no guidance about what to try next. My high school geometry teacher used to say that you need “mathematical eyeglasses.” In mathematical logic, this is known as the “decision problem.” Many logical systems are plagued with intractable decision problems. For instance, given a pile of dominos of various sizes, we have no tractable way to decide if we can arrange them to fill a square of a given size. But once an arrangement is proposed, it takes no time at all to verify whether it constitutes a solution.\nLuckily (again) for do-calculus, the decision problem turns out to be manageable. Ilya Shpitser, building on earlier work by one of my other students, Jin Tian, found an algorithm that decides if a solution exists in “polynomial time.” This is a somewhat technical term, but continuing our analogy with solving a maze, it means that we have a much more efficient way out of the labyrinth than hunting at random through all possible paths.\nShpitser’s algorithm for finding each and every causal effect does not eliminate the need for the do-calculus. In fact, we need it even more, and for several independent reasons. First, we need it in order to go beyond observational studies. Suppose that worst comes to worst, and our causal model does not permit estimation of the causal effect P(Y | do(X)) from observations alone. Perhaps we also cannot conduct a randomized experiment with random assignment of X. A clever researcher might ask whether we might estimate P(Y | do(X)) by randomizing some other variable, say Z, that is more accessible to control than X. For instance, if we want to assess the effect of cholesterol levels (X) on heart disease (Y), we might be able to manipulate the subjects’ diet (Z) instead of exercising direct control over the cholesterol levels in their blood.\nWe then ask if we can find such a surrogate Z that will enable us to answer the causal question. In the world of do-calculus, the question is whether we can find a Z such that we can transform P(Y | do(X)) into an expression in which the variable Z, but not X, is subjected to a do-operator. This is a completely different problem not covered by Shpitser’s algorithm. Luckily, it has a complete answer too, with a new algorithm discovered by Elias Bareinboim at my lab in 2012. Even more problems of this sort arise when we consider problems of transportability or external validity—assessing whether an experimental result will still be valid when transported to a different environment that may differ in several key ways from the one studied. This more ambitious set of questions touches on the heart of scientific methodology, for there is no science without generalization. Yet the question of generalization has been lingering for at least two centuries, without an iota of progress. The tools for producing a solution were simply not available. In 2015, Bareinboim and I presented a paper at the National Academy of Sciences that solves the problem, provided that you can express your assumptions about both environments with a causal diagram. In this case the rules of do-calculus provide a systematic method to determine whether causal effects found in the study environment can help us estimate effects in the intended target environment.\nYet another reason that the do-calculus remains important is transparency.\nAs I wrote this chapter, Bareinboim (now a professor at Purdue) sent me a new puzzle: a diagram with just four observed variables, X, Y, Z, and W, and two unobservable variables, U , U (see Figure 7.5). He challenged me to 1 2 figure out if the effect of X on Y was estimable. There was no way to block the back-door paths and no front-door condition. I tried all my favorite shortcuts and my otherwise trustworthy intuitive arguments, both pro and con, and I couldn’t see how to do it. I could not find a way out of the maze. But as soon as Bareinboim whispered to me, “Try the do-calculus,” the answer came shining through like a baby’s smile. Every step was clear and meaningful.\nThis is now the simplest model known to us in which the causal effect needs to be estimated by a method that goes beyond the front- and back-door adjustments.\nF 7.5. A new napkin problem? IGURE In order not to leave the reader with the impression that the do-calculus is good only for theory and to serve as a recreational brainteaser, I will end this section with a practical problem recently brought up by two leading statisticians, Nanny Wermuth and David Cox. It demonstrates how a friendly whisper, “Try the do-calculus,” can help expert statisticians solve difficult practical problems.\nAround 2005, Wermuth and Cox became interested in a problem called “sequential decisions” or “time-varying treatments,” which are common, for example, in the treatment of AIDS. Typically treatments are administered over a length of time, and in each time period physicians vary the strength and dosage of a follow-up treatment according to the patient’s condition. The patient’s condition, on the other hand, is influenced by the treatments taken in the past. We thus end up with a scenario like the one depicted in Figure 7.6, showing two time periods and two treatments. The first treatment is randomized (X), and the second (Z) is given in response to an observation (W) that depends on X. Given data collected under such a treatment regime, Cox and Wermuth’s task was to predict the effect of X on the outcome Y, assuming that they were to keep Z constant through time, independent of the observation W.\nF 7.6. Wermuth and Cox’s example of a sequential treatment.\nIGURE Jamie Robins first brought the problem of time-varying treatments to my attention in 1994, and with the help of do-calculus, we were able to derive a general solution invoking a sequential version of the back-door adjustment formula. Wermuth and Cox, unaware of this method, called their problem “indirect confounding” and published three papers on its analysis (2008, 2014, and 2015). Unable to solve it in general, they resorted to a linear approximation, and even in the linear case they found it difficult to handle, because it is not solvable by standard regression methods.\nFortunately, when a muse whispered in my ear, “Try the do-calculus,” I noticed that their problem can be solved in three lines of calculation. The logic goes as follows. Our target quantity is P(Y | do(X), do(Z)), while the data we have available to us are of the form P(Y | do(X), Z, W) and P(W | do(X)).\nThese reflect the fact that, in the study from which we have data, Z is not controlled externally but follows W through some (unknown) protocol. Thus, our task is to transform the target expression to another expression, reflecting the study conditions in which the do-operator applies only to X and not to Z. It so happens that a single application of the three rules of do-calculus can accomplish this. The moral of the story is nothing but a deep appreciation of the power of mathematics to solve difficult problems, which occasionally entail practical consequences.\nTHE TAPESTRY OF SCIENCE, OR THE HIDDEN PLAYERS IN THE DO-ORCHESTRA I’ve already mentioned the role of some of my students in weaving this beautiful do-calculus tapestry. Like any tapestry, it gives a sense of completeness that may conceal how painstaking making it was and how many hands contributed to the process. In this case, it took more than twenty years and contributions from several students and colleagues.\nThe first was Thomas Verma, whom I met when he was a sixteen-year-old boy. His father brought him to my office one day and said, essentially, “Give him something to do.” He was too talented for any of his high school math teachers to keep him interested. What he eventually accomplished was truly amazing. Verma finally proved what became known as the d-separation property (i.e., the fact that you can use the rules of path blocking to determine which independencies should hold in the data). Astonishingly, he told me that he proved the d-separation property thinking it was a homework problem, not an unsolved conjecture! Sometimes it pays to be young and naive. You can still see his legacy in Rule 1 of the do-calculus and in any imprint that path blocking leaves on rung one of the Ladder of Causation.\nThe power of Verma’s proof would have remained only partially appreciated without a complementary result to show that it cannot be improved. That is, no other independencies are implied by a causal diagram except those revealed through path blocking. This step was completed by another student, Dan Geiger. He had switched to my research lab from another group at UCLA, after I promised to give him an “instant PhD” if he could prove two theorems. He did, and I did! He is now Dean of computer science at the Technion in Israel, my alma mater.\nBut Dan was not the only student I raided from another department. One day in 1997, as I was getting dressed in the locker room of the UCLA pool, I struck up a conversation with a Chinese fellow next to me. He was a PhD student in physics, and, as was my usual habit at the time, I tried to convince him to switch over to artificial intelligence, where the action was. He was not completely convinced, but the very next day I received an email from a friend of his, Jin Tian, saying that he would like to switch from physics to computer science and did I have a challenging summer project for him? Two days later, he was working in my lab.\nFour years later, in April 2001, he stunned the world with a simple graphical criterion that generalizes the front door, the back door, and all doors we could think of at the time. I recall presenting Tian’s criterion at a Santa Fe conference. One by one, leaders in the research community stared at my poster and shook their heads in disbelief. How could such a simple criterion work for all diagrams? Tian (now a professor at Iowa State University) came to our lab with a style of thinking that was foreign to us then, in the 1990s. Our conversations were always loaded with wild metaphors and half-baked conjectures. But Tian would never utter a word unless it was rigorous, proven, and baked five times over. The mixture of the two styles proved its merit. Tian’s method, called c-decomposition, enabled Ilya Shpitser to develop his complete algorithm for the do-calculus. The moral: never underestimate the power of a locker-room conversation! Ilya Shpitser came in at the end of the ten-year battle to understand interventions. He arrived during a very difficult period, when I had to take time off to set up a foundation in honor of my son, Daniel, a victim of anti- Western terrorism. I have always expected my students to be self-reliant, but for my students at that time, this expectation was pushed to the extreme. They gave me the best of all possible gifts by putting the final but crucial touches on the tapestry of do-calculus, which I could not have done myself. In fact, I tried to discourage Ilya from trying to prove the completeness of do-calculus.\nCompleteness proofs are notoriously difficult and are best avoided by any student who aims to finish his PhD on time. Luckily, Ilya did it behind my back.\nColleagues, too, exert a profound effect on your thinking at crucial moments. Peter Spirtes, a professor of philosophy at Carnegie-Mellon, preceded me in the network approach to causality, and his influence was pivotal. At a lecture of his in Uppsala, Sweden, I first learned that performing interventions could be thought of as deleting arrows from a causal diagram.\nUntil then I had been laboring under the same burden as generations of statisticians, trying to think of causality in terms of only one diagram representing one static probability distribution.\nThe idea of arrow deletion was not entirely Spirtes’s, either. In 1960, two Swedish economists, Robert Strotz and Herman Wold, proposed essentially the same idea. In the world of economics at the time, diagrams were never used; instead, economists relied on structural equation models, which are Sewall Wright’s equations without the diagrams. Arrow deletion in a path diagram corresponds to deleting an equation from a structural equation model.\nSo, in a rough sense, Strotz and Wold had the idea first, unless we want to go even further back in history: they were preceded by Trygve Haavelmo (a Norwegian economist and Nobel laureate), who in 1943 advocated equation modification to represent interventions.\nNevertheless, Spirtes’s translation of equation deletion into the world of causal diagrams unleashed an avalanche of new insights and new results. The back-door criterion was one of the first beneficiaries of the translation, while the do-calculus came second. The avalanche, however, is not yet over.\nAdvances in such areas as counterfactuals, generalizability, missing data, and machine learning are still coming up.\nIf I were less modest, I would close here with Isaac Newton’s famous saying about “standing on the shoulders of giants.” But given who I am, I am tempted to quote from the Mishnah instead: “Harbe lamadeti mirabotai um’haverai yoter mehem, umitalmidai yoter mikulam”—that is, “I have learned much from my teachers, and more so from my colleagues, and most of all from my students” (Taanit 7a). The do-operator and do-calculus would not exist as they do today without the contributions of Verma, Geiger, Tian, and Shpitser, among others.\nTHE CURIOUS CASE(S) OF DR. SNOW In 1853 and 1854, England was in the grips of a cholera epidemic. In that era, cholera was as terrifying as Ebola is today; a healthy person who drinks cholera-tainted water can die within twenty-four hours. We know today that cholera is caused by a bacterium that attacks the intestines. It spreads through the “rice water” diarrhea of its victims, who excrete this diarrhea in copious amounts before dying.\nBut in 1853, disease-causing germs had never yet been seen under a microscope for any illness, let alone cholera. The prevailing wisdom held that a “miasma” of unhealthy air caused cholera, a theory seemingly supported by the fact that the epidemic hit harder in the poorer sections of London, where sanitation was worse.\nDr. John Snow, a physician who had taken care of cholera victims for more than twenty years, was always skeptical of the miasma theory. He argued, sensibly, that since the symptoms manifested themselves in the intestinal tract, the body must first come into contact with the pathogen there.\nBut because he couldn’t see the culprit, he had no way to prove this—until the epidemic of 1854.\nThe John Snow story has two chapters, one much more famous than the other. In what we could call the “Hollywood” version, he painstakingly goes from house to house, recording where victims of cholera died, and notices a cluster of dozens of victims near a pump in Broad Street. Talking with people who live in the area, he discovers that almost all the victims had drawn their water from that particular pump. He even learns of a fatal case that occurred far away, in Hampstead, to a woman who liked the taste of the water from the Broad Street pump. She and her niece drank the water from Broad Street and died, while no one else in her area even got sick. Putting all this evidence together, Snow asks the local authorities to remove the pump handle, and on September 8 they agree. As Snow’s biographer wrote, “The pump-handle was removed, and the plague was stayed.” All of this makes a wonderful story. Nowadays a John Snow Society even reenacts the removal of the famous pump handle every year. Yet, in truth, the removal of the pump handle hardly made a dent in the citywide cholera epidemic, which went on to claim nearly 3,000 lives.\nIn the non-Hollywood chapter of the story, we again see Dr. Snow walking the streets of London, but this time his real object is to find out where Londoners get their water. There were two main water companies at the time: the Southwark and Vauxhall Company and the Lambeth Company. The key difference between the two, as Snow knew, was that the former drew its water from the area of the London Bridge, which was downstream from London’s sewers. The latter had moved its water intake several years earlier so that it would be upstream of the sewers. Thus, Southwark customers were getting water tainted by the excrement of cholera victims. Lambeth customers, on the other hand, were getting uncontaminated water. (None of this has anything to do with the contaminated Broad Street water, which came from a well.) The death statistics bore out Snow’s grim hypothesis. Districts supplied by the Southwark and Vauxhall Company were especially hard-hit by cholera and had a death rate eight times higher. Even so, the evidence was merely circumstantial. A proponent of the miasma theory could argue that the miasma was strongest in those districts, and there would be no way to disprove it. In terms of a causal diagram, we have the situation diagrammed in Figure 7.7.\nWe have no way to observe the confounder Miasma (or other confounders like Poverty), so we can’t control for it using back-door adjustment.\nHere Snow had his most brilliant idea. He noticed that in those districts served by both companies, the death rate was still much higher in the households that received Southwark water. Yet these households did not differ in terms of miasma or poverty. “The mixing of the supply is of the most intimate kind,” Snow wrote. “The pipes of each Company go down all the streets, and into nearly all the courts and alleys.… Each company supplies both rich and poor, both large houses and small; there is no difference either in the condition or occupation of the persons receiving the water of the different Companies.” Even though the notion of an RCT was still in the future, it was very much as if the water companies had conducted a randomized experiment on Londoners. In fact, Snow even notes this: “No experiment could have been devised which would more thoroughly test the effect of water supply on the progress of cholera than this, which circumstances placed ready made before the observer. The experiment, too, was on the grandest scale. No fewer than three hundred thousand people of both sexes, of every age and occupation, and of every rank and station, from gentlefolks down to the very poor, were divided into two groups without their choice, and in most cases, without their knowledge.” One group had received pure water; the other had received water tainted with sewage.\nF 7.7. Causal diagram for cholera (before discovery of the cholera bacillus).\nIGURE Snow’s observations introduced a new variable into the causal diagram, which now looks like Figure 7.8. Snow’s painstaking detective work had showed two important things: (1) there is no arrow between Miasma and Water Company (the two are independent), and (2) there is an arrow between Water Company and Water Purity. Left unstated by Snow, but equally important, is a third assumption: (3) the absence of a direct arrow from Water Company to Cholera, which is fairly obvious to us today because we know the water companies were not delivering cholera to their customers by some alternate route.\nF 7.8. Diagram for cholera after introduction of an instrumental variable.\nIGURE A variable that satisfies these three properties is today called an instrumental variable. Clearly Snow thought of this variable as similar to a coin flip, which simulates a variable with no incoming arrows. Because there are no confounders of the relation between Water Company and Cholera, any observed association must be causal. Likewise, since the effect of Water Company on Cholera must go through Water Purity, we conclude (as did Snow) that the observed association between Water Purity and Cholera must also be causal. Snow stated his conclusion in no uncertain terms: if the Southwark and Vauxhall Company had moved its intake point upstream, more than 1,000 lives would have been saved.\nFew people took note of Snow’s conclusion at the time. He printed a pamphlet of the results at his own expense, and it sold a grand total of fifty- six copies. Nowadays, epidemiologists view his pamphlet as the seminal document of their discipline. It showed that through “shoe-leather research” (a phrase I have borrowed from David Freedman) and causal reasoning, you can track down a killer.\nAlthough the miasma theory has by now been discredited, poverty was undoubtedly a confounder, as was location. But even without measuring these (because Snow’s door-to-door detective work only went so far), we can still use instrumental variables to determine how many lives would have been saved by purifying the water supply.\nHere’s how the trick works. For simplicity we’ll go back to the names Z, X, Y, and U for our variables and redraw Figure 7.8 as seen in Figure 7.9. I have included path coefficients (a, b, c, d) to represent the strength of the causal effects. This means we are assuming that the variables are numerical and the functions relating them are linear. Remember that the path coefficient a means that an intervention to increase Z by one standard unit will cause X to increase by a standard units. (I will omit the technical details of what the “standard units” are.) F 7.9. General setup for instrumental variables.\nIGURE Because Z and X are unconfounded, the causal effect of Z on X (that is, a) can be estimated from the slope r of the regression line of X on Z.\nXZ Likewise, the variables Z and Y are unconfounded, because the path Z X U Y is blocked by the collider at X. So the slope of the regression line of Z on Y (r ) will equal the causal effect on the direct path Z X Y, which is ZY the product of the path coefficients: ab. Thus we have two equations: ab = r ZY and a = r . If we divide the first equation by the second, we get the causal ZX effect of X on Y: b = r /r .\nZY ZX In this way, instrumental variables allow us to perform the same kind of magic trick that we did with front-door adjustment: we have found the effect of X on Y even without being able to control for, or collect data on, the confounder, U. We can therefore provide decision makers with a conclusive argument that they should move their water supply—even if those decision makers still believe in the miasma theory. Also notice that we have gotten information on the second rung of the Ladder of Causation (b) from information about the first rung (the correlations, r and r ). We were able ZY ZX to do this because the assumptions embodied in the path diagram are causal in nature, especially the crucial assumption that there is no arrow between U and Z. If the causal diagram were different—for example, if Z were a confounder of X and Y—the formula b = r /r would not correctly estimate the causal ZY ZX effect of X on Y. In fact, these two models cannot be told apart by any statistical method, regardless of how big the data.\nInstrumental variables were known before the Causal Revolution, but causal diagrams have brought new clarity to how they work. Indeed, Snow was using an instrumental variable implicitly, although he did not have a quantitative formula. Sewall Wright certainly understood this use of path diagrams; the formula b = r /r can be derived directly from his method of ZY ZX path coefficients. And it seems that the first person other than Sewall Wright to use instrumental variables in a deliberate way was… Sewall Wright’s father, Philip! Recall that Philip Wright was an economist who worked at what later became the Brookings Institution. He was interested in predicting how the output of a commodity would change if a tariff were imposed, which would raise the price and therefore, in theory, encourage production. In economic terms, he wanted to know the elasticity of supply.\nIn 1928 Wright wrote a long monograph dedicated to computing the elasticity of supply for flaxseed oil. In a remarkable appendix, he analyzed the problem using a path diagram. This was a brave thing to do: remember that no economist had ever seen or heard of such a thing before. (In fact, he hedged his bets and verified his calculations using more traditional methods.) Figure 7.10 shows a somewhat simplified version of Wright’s diagram.\nUnlike most diagrams in this book, this one has “two-way” arrows, but I would ask the reader not to lose too much sleep over it. With some mathematical trickery we could equally well replace the Demand Price Supply chain with a single arrow Demand Supply, and the figure would then look like Figure 7.9 (though it would be less acceptable to economists).\nThe important point to note is that Philip Wright deliberately introduced the variable Yield per Acre (of flaxseed) as an instrument that directly affects supply but has no correlation to demand. He then used an analysis like the one I just gave to deduce both the effect of supply on price and the effect of price on supply.\nF 7.10. Simplified version of Wright’s supply-price causal diagram.\nIGURE Historians quarrel about who invented instrumental variables, a method that became extremely popular in modern econometrics. There is no question in my mind that Philip Wright borrowed the idea of path coefficients from his son. No economist had ever before insisted on the distinction between causal coefficients and regression coefficients; they were all in the Karl Pearson– Henry Niles camp that causation is nothing more than a limiting case of correlation. Also, no one before Sewall Wright had ever given a recipe for computing regression coefficients in terms of path coefficients, then reversing the process to get the causal coefficients from the regression. This was Sewall’s exclusive invention.\nNaturally, some economic historians have suggested that Sewall wrote the whole mathematical appendix himself. However, stylometric analysis has shown that Philip was indeed the author. To me, this historical detective work makes the story more beautiful. It shows that Philip took the trouble to understand his son’s theory and articulate it in his own language.\nNow let’s move forward from the 1850s and 1920s to look at a present-day example of instrumental variables in action, one of literally dozens I could have chosen.\nGOOD AND BAD CHOLESTEROL Do you remember when your family doctor first started talking to you about “good” and “bad” cholesterol? It may have happened in the 1990s, when drugs that lowered blood levels of “bad” cholesterol, low-density lipoprotein (LDL), first came on the market. These drugs, called statins, have turned into multibillion-dollar revenue generators for pharmaceutical companies.\nThe first cholesterol-modifying drug subjected to a randomized controlled trial was cholestyramine. The Coronary Primary Prevention Trial, begun in 1973 and concluded in 1984, showed a 12.6 percent reduction in cholesterol among men given the drug cholestyramine and a 19 percent reduction in the risk of heart attack.\nBecause this was a randomized controlled trial, you might think we wouldn’t need any of the methods in this chapter, because they are specifically designed to replace RCTs in situations where you only have observational data. But that is not true. This trial, like many RCTs, faced the problem of noncompliance, when subjects randomized to receive a drug don’t actually take it. This will reduce the apparent effectiveness of the drug, so we may want to adjust the results to account for the noncompliers. But as always, confounding rears its ugly head. If the noncompliers are different from the compliers in some relevant way (maybe they are sicker to start with?), we cannot predict how they would have responded had they adhered to instructions.\nIn this situation, we have a causal diagram that looks like Figure 7.11. The variable Assigned (Z) will take the value 1 if the patient is randomly assigned to receive the drug and 0 if he is randomly assigned a placebo. The variable Received will be 1 if the patient actually took the drug and 0 otherwise. For convenience, we’ll also use a binary definition for Cholesterol, recording an outcome of 1 if the cholesterol levels were reduced by a certain fixed amount.\nF 7.11. Causal diagram for an RCT with noncompliance.\nIGURE Notice that in this case our variables are binary, not numerical. This means right away that we cannot use a linear model, and therefore we cannot apply the instrumental variables formula that we derived earlier. However, in such cases we can often replace the linearity assumption with a weaker condition called monotonicity, which I’ll explain below.\nBut before we do that, let’s make sure our other necessary assumptions for instrumental variables are valid. First, is the instrumental variable Z independent of the confounder? The randomization of Z ensures that the answer is yes. (As we saw in Chapter 4, randomization is a great way to make sure that a variable isn’t affected by any confounders.) Is there any direct path from Z to Y? Common sense says that there is no way that receiving a particular random number (Z) would affect cholesterol (Y), so the answer is no. Finally, is there a strong association between Z and X? This time the data themselves should be consulted, and the answer again is yes. We must always ask the above three questions before we apply instrumental variables. Here the answers are obvious, but we should not be blind to the fact that we are using causal intuition to answer them, intuition that is captured, preserved, and elucidated in the diagram.\nTable 7.1 shows the observed frequencies of outcomes X and Y. For example, 91.9 percent of the people who were not assigned the drug had the outcome X = 0 (didn’t take drug) and Y = 0 (no reduction in cholesterol). This makes sense. The other 8.1 percent had the outcome X = 0 (didn’t take drug) and Y = 1 (did have a reduction in cholesterol). Evidently they improved for other reasons than taking the drug. Notice also that there are two zeros in the table: there was nobody who was not assigned the drug (Z = 0) but nevertheless procured some (X = 1). In a well-run randomized study, especially in the medical field where the physicians have exclusive access to the experimental drug, this will typically be true. The assumption that there are no individuals with Z = 0 and X = 1 is called monotonicity.\nTABLE 7.1. Data from cholestyramine trial.\nNow let’s see how we can estimate the effect of the treatment. First let’s take the worst-case scenario: none of the noncompliers would have improved if they had complied with treatment. In that case, the only people who would have taken the drug and improved would be the 47.3 percent who actually did comply and improve. But we need to correct this estimate for the placebo effect, which is in the third row of the table. Out of the people who were assigned the placebo and took the placebo, 8.1 percent improved. So the net improvement above and beyond the placebo effect is 47.3 percent minus 8.1 percent, or 39.2 percent.\nWhat about the best-case scenario, in which all the noncompliers would have improved if they had complied? In this case we add the noncompliers’ 31.5 percent plus 7.3 percent to the 39.2 percent baseline we just computed, for a total of 78.0 percent.\nThus, even in the worst-case scenario, where the confounding goes completely against the drug, we can still say that the drug improves cholesterol for 39 percent of the population. In the best-case scenario, where the confounding works completely in favor of the drug, 78 percent of the population would see an improvement. Even though the bounds are quite far apart, due to the large number of noncompliers, the researcher can categorically state that the drug is effective for its intended purpose.\nThis strategy of taking the worst case and then the best case will usually give us a range of estimates. Obviously it would be nice to have a point estimate, as we did in the linear case. There are ways to narrow the range if necessary, and in some cases it is even possible to get point estimates. For example, if you are interested only in the complying subpopulation (those people who will take X if and only if assigned), you can derive a point estimate known as the Local Average Treatment Effect (LATE). In any event, I hope this example shows that our hands are not tied when we leave the world of linear models.\nInstrumental variable methods have continued to develop since 1984, and one particular version has become extremely popular: Mendelian randomization. Here’s an example. Although the effect of LDL, or “bad,” cholesterol is now settled, there is still considerable uncertainty about high- density lipoprotein (HDL), or “good,” cholesterol. Early observational studies, such as the Framingham Heart Study in the late 1970s, suggested that HDL had a protective effect against heart attacks. But high HDL often goes hand in hand with low LDL, so how can we tell which lipid is the true causal factor? To answer this question, suppose we knew of a gene that caused people to have higher HDL levels, with no effect on LDL. Then we could set up the causal diagram in Figure 7.12, where I have used Lifestyle as a possible confounder. Remember that it is always advantageous, as in Snow’s example, to use an instrumental variable that is randomized. If it’s randomized, no causal arrows point toward it. For this reason, a gene is a perfect instrumental variable. Our genes are randomized at the time of conception, so it’s just as if Gregor Mendel himself had reached down from heaven and assigned some people a high-risk gene and others a low-risk gene. That’s the reason for the term “Mendelian randomization.” Could there be an arrow going the other way, from HDL Gene to Lifestyle? Here we again need to do “shoe-leather work” and think causally.\nThe HDL gene could only affect people’s lifestyle if they knew which version they had, the high-HDL version or the low-HDL one. But until 2008 no such genes were known, and even today, people do not routinely have access to this information. So it’s highly likely that no such arrow exists.\nFigure 7.12. Causal diagram for Mendelian randomization example.\nAt least two studies have taken this Mendelian randomization approach to the cholesterol question. In 2012, a giant collaborative study led by Sekar Kathiresan of Massachusetts General Hospital showed that there was no observable benefit from higher HDL levels. On the other hand, the researchers found that LDL has a very large effect on heart attack risk.\nAccording to their figures, decreasing your LDL count by 34 mg/dl would reduce your chances of a heart attack by about 50 percent. So lowering your “bad” cholesterol levels, whether by diet or exercise or statins, seems to be a smart idea. On the other hand, increasing your “good” cholesterol levels, despite what some fish-oil salesmen might tell you, does not seem likely to change your heart attack risk at all.\nAs always, there is a caveat. The second study, published in the same year, pointed out that people with the lower-risk variant of the LDL gene have had lower cholesterol levels for their entire lives. Mendelian randomization tells us that decreasing your LDL by thirty-four units over your entire lifetime will decrease your heart attack risk by 50 percent. But statins can’t lower your LDL cholesterol over your entire lifetime—only from the day you start taking the drug. If you’re sixty years old, your arteries have already sustained sixty years of damage. For that reason it’s very likely that Mendelian randomization overestimates the true benefits of statins. On the other hand, starting to reduce your cholesterol when you’re young—whether through diet or exercise or even statins—will have big effects later.\nFrom the point of view of causal analysis, this teaches us a good lesson: in any study of interventions, we need to ask whether the variable we’re actually manipulating (lifetime LDL levels) is the same as the variable we think we are manipulating (current LDL levels). This is part of the “skillful interrogation of nature.” To sum up, instrumental variables are an important tool in that they help us uncover causal information that goes beyond the do-calculus. The latter insists on point estimates rather than inequalities and would give up on cases like Figure 7.12, in which all we can get are inequalities. On the other hand, it’s also important to realize that the do-calculus is vastly more flexible than instrumental variables. In do-calculus we make no assumptions whatsoever regarding the nature of the functions in the causal model. But if we can justify an assumption like monotonicity or linearity on scientific grounds, then a more special-purpose tool like instrumental variables is worth considering.\nInstrumental variable methods can be extended beyond simple four- variable models like Figure 7.9 (or 7.11 or 7.12), but it is not possible to go very far without guidance from causal diagrams. For example, in some cases an imperfect instrument (e.g., one that is not independent of the confounder) can be used after conditioning on a cleverly chosen set of auxiliary variables, which block the paths between the instrument and the confounder. My former student Carlos Brito, now a professor at the Federal University of Ceara, Brazil, fully developed this idea of turning noninstrumental variables into instrumental variables.\nIn addition, Brito studied many cases where a set of variables can be used successfully as an instrument. Although the identification of instrumental sets goes beyond do-calculus, it still uses the tools of causal diagrams. For researchers who understand this language, the possible research designs are rich and varied; they need not feel constrained to use only the four-variable model shown in Figures 7.9, 7.11, and 7.12. The possibilities are limited only by our imaginations.\nRobert Frost’s famous lines show a poet’s acute insight into counterfactuals. We cannot travel both roads, and yet our brains are equipped to judge what would have happened if we had taken the other path. Armed with this judgment, Frost ends the poem pleased with his choice, realizing that it “made all the difference.” (Source: Drawing by Maayan Harel.)",
    "crumbs": [
      "Causal Inference",
      "The book of why"
    ]
  },
  {
    "objectID": "extracted/The Book of Why - Judea Pearl.html#counterfactuals-mining-worlds-that-could-have-been",
    "href": "extracted/The Book of Why - Judea Pearl.html#counterfactuals-mining-worlds-that-could-have-been",
    "title": "The book of why",
    "section": "8. COUNTERFACTUALS: MINING WORLDS THAT COULD HAVE BEEN",
    "text": "8. COUNTERFACTUALS: MINING WORLDS THAT COULD HAVE BEEN\nHad Cleopatra’s nose been shorter, the whole face of the world would\nhave changed.\n—BLAISE PASCAL (1669) A S we prepare to move up to the top rung of the Ladder of Causation, let’s recapitulate what we have learned from the second rung. We have seen several ways to ascertain the effect of an intervention in various settings and under a variety of conditions. In Chapter 4, we discussed randomized controlled trials, the widely cited “gold standard” for medical trials. We have also seen methods that are suitable for observational studies, in which the treatment and control groups are not assigned at random. If we can measure variables that block all the back-door paths, we can use the back-door adjustment formula to obtain the needed effect. If we can find a front-door path that is “shielded” from confounders, we can use front-door adjustment. If we are willing to live with the assumption of linearity or monotonicity, we can use instrumental variables (assuming that an appropriate variable can be found in the diagram or created by an experiment). And truly adventurous researchers can plot other routes to the top of Mount Intervention using the do-calculus or its algorithmic version.\nIn all these endeavors, we have dealt with effects on a population or a typical individual selected from a study population (the average causal effect).\nBut so far we are missing the ability to talk about personalized causation at the level of particular events or individuals. It’s one thing to say, “Smoking causes cancer,” but another to say that my uncle Joe, who smoked a pack a day for thirty years, would have been alive had he not smoked. The difference is both obvious and profound: none of the people who, like Uncle Joe, smoked for thirty years and died can ever be observed in the alternate world where they did not smoke for thirty years.\nResponsibility and blame, regret and credit: these concepts are the currency of a causal mind. To make any sense of them, we must be able to compare what did happen with what would have happened under some alternative hypothesis. As argued in Chapter 1, our ability to conceive of alternative, nonexistent worlds separated us from our protohuman ancestors and indeed from any other creature on the planet. Every other creature can see what is. Our gift, which may sometimes be a curse, is that we can see what might have been.\nThis chapter shows how to use observational and experimental data to extract information about counterfactual scenarios. It explains how to represent individual-level causes in the context of a causal diagram, a task that will force us to explain some nuts and bolts of causal diagrams that we have not talked about yet. I also discuss a highly related concept called “potential outcomes,” or the Neyman-Rubin causal model, initially proposed in the 1920s by Jerzy Neyman, a Polish statistician who later became a professor at Berkeley. But only after Donald Rubin began writing about potential outcomes in the mid-1970s did this approach to causal analysis really begin to flourish.\nI will show how counterfactuals emerge naturally in the framework developed over the last several chapters—Sewall Wright’s path diagrams and their extension to structural causal models (SCMs). We got a good taste of this in Chapter 1, in the example of the firing squad, which showed how to answer counterfactual questions such as “Would the prisoner be alive if rifleman A had not shot?” I will compare how counterfactuals are defined in the Neyman-Rubin paradigm and in SCMs, where they enjoy the benefit of causal diagrams. Rubin has steadfastly maintained over the years that diagrams serve no useful purpose. So we will examine how students of the Rubin causal model must navigate causal problems blindfolded, lacking a facility to represent causal knowledge or to derive its testable implications.\nFinally, we will look at two applications where counterfactual reasoning is essential. For decades or even centuries, lawyers have used a relatively straightforward test of a defendant’s culpability called “but-for causation”: the injury would not have occurred but for the defendant’s action. We will see how the language of counterfactuals can capture this elusive notion and how to estimate the probability that a defendant is culpable.\nNext, I will discuss the application of counterfactuals to climate change.\nUntil recently, climate scientists have found it very difficult and awkward to answer questions like “Did global warming cause this storm [or this heat wave, or this drought]?” The conventional answer has been that individual weather events cannot be attributed to global climate change. Yet this answer seems rather evasive and may even contribute to public indifference about climate change.\nCounterfactual analysis allows climate scientists to make much more precise and definite statements than before. It requires, however, a slight addition to our everyday vocabulary. It will be helpful to distinguish three different kinds of causation: necessary causation, sufficient causation, and necessary-and-sufficient causation. (Necessary causation is the same as but- for causation.) Using these words, a climate scientist can say, “There is a 90 percent probability that man-made climate change was a necessary cause of this heat wave,” or “There is an 80 percent probability that climate change will be sufficient to produce a heat wave this strong at least once every 50 years.” The first sentence has to do with attribution: Who was responsible for the unusual heat? The second has to do with policy. It says that we had better prepare for such heat waves because they are likely to occur sooner or later.\nEither of these statements is more informative than shrugging our shoulders and saying nothing about the causes of individual weather events.\nFROM THUCYDIDES AND ABRAHAM TO HUME AND LEWIS Given that counterfactual reasoning is part of the mental apparatus that makes us human, it is not surprising that we can find counterfactual statements as far back as we want to go in human history. For example, in Thucydides’s History of the Peloponnesian War, the ancient Greek historian, often described as the pioneer of a “scientific” approach to history, describes a tsunami that occurred in 426 BC: About the same time that these earthquakes were so common, the sea at Orobiae, in Euboea, retiring from the then line of coast, returned in a huge wave and invaded a great part of the town, and retreated leaving some of it still under water; so that what was once land is now sea; such of the inhabitants perishing as could not run up to the higher ground in time.… The cause, in my opinion, of this phenomenon must be sought in the earthquake. At the point where its shock has been the most violent the sea is driven back, and suddenly recoiling with redoubled force, causes the inundation. Without an earthquake I do not see how such an accident could happen.\nThis is a truly remarkable passage when you consider the era in which it was written. First, the precision of Thucydides’s observations would do credit to any modern scientist, and all the more so because he was working in an era when there were no satellites, no video cameras, no 24/7 news organizations broadcasting images of the disaster as it unfolded. Second, he was writing at a time in human history when natural disasters were ordinarily ascribed to the will of the gods. His predecessor Homer or his contemporary Herodotus would undoubtedly have attributed this event to the wrath of Poseidon or some other deity. Yet Thucydides proposes a causal model without any supernatural processes: the earthquake drives back the sea, which recoils and inundates the land. The last sentence of the quote is especially interesting because it expresses the notion of necessary or but-for causation: but for the earthquake, the tsunami could not have occurred. This counterfactual judgment promotes the earthquake from a mere antecedent of the tsunami to an actual cause.\nAnother fascinating and revealing instance of counterfactual reasoning occurs in the book of Genesis in the Bible. Abraham is talking with God about the latter’s intention to destroy the cities of Sodom and Gomorrah as retribution for their evil ways.\nAnd Abraham drew near, and said, Wilt thou really destroy the righteous with the wicked? Suppose there be fifty righteous within the city: wilt thou also destroy and not spare the place for the sake of the fifty righteous that are therein?… And the Lord said, If I find in Sodom fifty righteous within the city, then I will spare all the place for their sakes.\nBut the story does not end there. Abraham is not satisfied and asks the Lord, what if there are only forty-five righteous men? Or forty? Or thirty? Or twenty? Or even ten? Each time he receives an affirmative answer, and God ultimately assures him that he will spare Sodom even for the sake of ten righteous men, if he can find that many.\nWhat is Abraham trying to accomplish with this haggling and bargaining? Surely he does not doubt God’s ability to count. And of course, Abraham knows that God knows how many righteous men live in Sodom. He is, after all, omniscient.\nKnowing Abraham’s obedience and devotion, it is hard to believe that the questions are meant to convince the Lord to change his mind. Instead, they are meant for Abraham’s own comprehension. He is reasoning just as a modern scientist would, trying to understand the laws that govern collective punishment. What level of wickedness is sufficient to warrant destruction? Would thirty righteous men be enough to save a city? Twenty? We do not have a complete causal model without such information. A modern scientist might call it a dose-response curve or a threshold effect.\nWhile Thucydides and Abraham probed counterfactuals through individual cases, the Greek philosopher Aristotle investigated more generic aspects of causation. In his typically systematic style, Aristotle set up a whole taxonomy of causation, including “material causes,” “formal causes,” “efficient causes,” and “final causes.” For example, the material cause of the shape of a statue is the bronze from which it is cast and its properties; we could not make the same statue out of Silly Putty. However, Aristotle nowhere makes a statement about causation as a counterfactual, so his ingenious classification lacks the simple clarity of Thucydides’s account of the cause of the tsunami.\nTo find a philosopher who placed counterfactuals at the heart of causality, we have to move ahead to David Hume, the Scottish philosopher and contemporary of Thomas Bayes. Hume rejected Aristotle’s classification scheme and insisted on a single definition of causation. But he found this definition quite elusive and was in fact torn between two different definitions.\nLater these would turn into two incompatible ideologies, which ironically could both cite Hume as their source! In his Treatise of Human Nature (Figure 8.1), Hume denies that any two objects have innate qualities or “powers” that make one a cause and the other an effect. In his view, the cause-effect relationship is entirely a product of our own memory and experience. “Thus we remember to have seen that species of object we call flame, and to have felt that species of sensation we call heat,” he writes. “We likewise call to mind their constant conjunction in all past instances. Without any further ceremony, we call the one cause and the other effect, and infer the existence of the one from the other.” This is now known as the “regularity” definition of causation.\nThe passage is breathtaking in its chutzpah. Hume is cutting off the second and third rungs of the Ladder of Causation and saying that the first rung, observation, is all that we need. Once we observe flame and heat together a sufficient number of times (and note that flame has temporal precedence), we agree to call flame the cause of heat. Like most twentieth-century statisticians, Hume in 1739 seems happy to consider causation as merely a species of correlation.\nF 8.1. Hume’s “regularity” definition of cause and effect, proposed in 1739.\nIGURE And yet Hume, to his credit, did not remain satisfied with this definition.\nNine years later, in An Enquiry Concerning Human Understanding, he wrote something quite different: “We may define a cause to be an object followed by another, and where all the objects, similar to the first, are followed by objects similar to the second. Or, in other words, where, if the first object had not been, the second never had existed” (emphasis in the original). The first sentence, the version where A is consistently observed together with B, simply repeats the regularity definition. But by 1748, he seems to have some misgivings and finds it in need of some repair. As authorized Whiggish historians, we can understand why. According to his earlier definition, the rooster’s crow would cause sunrise. To patch over this difficulty, he adds a second definition that he never even hinted at in his earlier book, a counterfactual definition: “if the first object had not been, the second had never existed.” Note that the second definition is exactly the one that Thucydides used when he discussed the tsunami at Orobiae. The counterfactual definition also explains why we do not consider the rooster’s crow a cause of sunrise. We know that if the rooster was sick one day, or capriciously refused to crow, the sun would rise anyway.\nAlthough Hume tries to pass these two definitions off as one, by means of his innocent interjection “in other words,” the second version is completely different from the first. It explicitly invokes a counterfactual, so it lies on the third rung of the Ladder of Causation. Whereas regularities can be observed, counterfactuals can only be imagined.\nIt is worth thinking for a moment about why Hume chooses to define causes in terms of counterfactuals, rather than the other way around.\nDefinitions are intended to reduce a more complicated concept to a simpler one. Hume surmises that his readers will understand the statement “if the first object had not been, the second had never existed” with less ambiguity than they will understand “the first object caused the second.” He is absolutely right. The latter statement invites all sorts of fruitless metaphysical speculation about what quality or power inherent in the first object brings about the second one. The former statement merely asks us to perform a simple mental test: imagine a world without the earthquake and ask whether it also contains a tsunami. We have been making judgments like this since we were children, and the human species has been making them since Thucydides (and probably long before).\nNevertheless, philosophers ignored Hume’s second definition for most of the nineteenth and twentieth centuries. Counterfactual statements, the “would haves,” have always appeared too squishy and uncertain to satisfy academics.\nInstead, philosophers tried to rescue Hume’s first definition through the theory of probabilistic causation, as discussed in Chapter 1.\nOne philosopher who defied convention, David Lewis, called in his 1973 book Counterfactuals for abandoning the regularity account altogether and for interpreting “A has caused B” as “B would not have occurred if not for A.” Lewis asked, “Why not take counterfactuals at face value: as statements about possible alternatives to the actual situation?” Like Hume, Lewis was evidently impressed by the fact that humans make counterfactual judgments without much ado, swiftly, comfortably, and consistently. We can assign them truth values and probabilities with no less confidence than we do for factual statements. In his view, we do this by envisioning “possible worlds” in which the counterfactual statements are true.\nWhen we say, “Joe’s headache would have gone away if he had taken aspirin,” we are saying (according to Lewis) that there are other possible worlds in which Joe did take an aspirin and his headache went away. Lewis argued that we evaluate counterfactuals by comparing our world, where he did not take aspirin, to the most similar world in which he did take an aspirin.\nUpon finding no headache in that world, we declare the counterfactual statement to be true. “Most similar” is key. There may be some “possible worlds” in which his headache did not go away—for example, a world in which he took the aspirin and then bumped his head on the bathroom door.\nBut that world contains an extra, adventitious circumstance. Among all possible worlds in which Joe took aspirin, the one most similar to ours would be one not where he bumped his head but where his headache is gone.\nMany of Lewis’s critics pounced on the extravagance of his claims for the literal existence of many other possible worlds. “Mr. Lewis was once dubbed a ‘mad-dog modal realist’ for his idea that any logically possible world you can think of actually exists,” said his New York Times obituary in 2001. “He believed, for instance, that there was a world with talking donkeys.” But I think that his critics (and perhaps Lewis himself) missed the most important point. We do not need to argue about whether such worlds exist as physical or even metaphysical entities. If we aim to explain what people mean by saying “A causes B,” we need only postulate that people are capable of generating alternative worlds in their heads, judging which world is “closer” to ours and, most importantly, doing it coherently so as to form a consensus.\nSurely we could not communicate about counterfactuals if one person’s “closer” was another person’s “farther.” In this view, Lewis’s appeal “Why not take counterfactuals at face value?” called not for metaphysics but for attention to the amazing uniformity of the architecture of the human mind.\nAs a licensed Whiggish philosopher, I can explain this consistency quite well: it stems from the fact that we experience the same world and share the same mental model of its causal structure. We talked about this all the way back in Chapter 1. Our shared mental models bind us together into communities. We can therefore judge closeness not by some metaphysical notion of “similarity” but by how much we must take apart and perturb our shared model before it satisfies a given hypothetical condition that is contrary to fact (Joe not taking aspirin).\nIn structural models we do a very similar thing, albeit embellished with more mathematical detail. We evaluate expressions like “had X been x” in the same way that we handled interventions do(X = x), by deleting arrows in a causal diagram or equations in a structural model. We can describe this as making the minimal alteration to a causal diagram needed to ensure that X equals x. In this respect, structural counterfactuals are compatible with Lewis’s idea of the most similar possible world.\nStructural models also offer a resolution of a puzzle Lewis kept silent about: How do humans represent “possible worlds” in their minds and compute the closest one, when the number of possibilities is far beyond the capacity of the human brain? Computer scientists call this the “representation problem.” We must have some extremely economical code to manage that many worlds. Could structural models, in some shape or form, be the actual shortcut that we use? I think it is very likely, for two reasons. First, structural causal models are a shortcut that works, and there aren’t any competitors around with that miraculous property. Second, they were modeled on Bayesian networks, which in turn were modeled on David Rumelhart’s description of message passing in the brain. It is not too much of a stretch to think that 40,000 years ago, humans co-opted the machinery in their brain that already existed for pattern recognition and started to use it for causal reasoning.\nPhilosophers tend to leave it to psychologists to make statements about how the mind does things, which explains why the questions above were not addressed until quite recently. However, artificial intelligence (AI) researchers could not wait. They aimed to build robots that could communicate with humans about alternate scenarios, credit and blame, responsibility and regret.\nThese are all counterfactual notions that AI researchers had to mechanize before they had the slightest chance of achieving what they call “strong AI”— humanlike intelligence.\nWith these motivations I entered counterfactual analysis in 1994 (with my student Alex Balke). Not surprisingly, the algorithmization of counterfactuals made a bigger splash in artificial intelligence and cognitive science than in philosophy. Philosophers tended to view structural models as merely one of many possible implementations of Lewis’s possible-worlds logic. I dare to suggest that they are much more than that. Logic void of representation is metaphysics. Causal diagrams, with their simple rules of following and erasing arrows, must be close to the way that our brains represent counterfactuals.\nThis assertion must remain unproven for the time being, but the upshot of the long story is that counterfactuals have ceased to be mystical. We understand how humans manage them, and we are ready to equip robots with similar capabilities to the ones our ancestors acquired 40,000 years ago.\nPOTENTIAL OUTCOMES, STRUCTURAL EQUATIONS, AND THE ALGORITHMIZATION OF COUNTERFACTUALS Just a year after the release of Lewis’s book, and independently of it, Donald Rubin (Figure 8.2) began writing a series of papers that introduced potential outcomes as a language for asking causal questions. Rubin, at that time a statistician for the Educational Testing Service, single-handedly broke the silence about causality that had persisted in statistics for seventy-five years and legitimized the concept of counterfactuals in the eyes of many health scientists. It is impossible to overstate the importance of this development. It provided researchers with a flexible language to express almost every causal question they might wish to ask, at both the population and individual levels.\nF 8.2. Donald Rubin (right) with the author in 2014. (Source: Photo courtesy of IGURE Grace Hyun Kim.) In the Rubin causal model, a potential outcome of a variable Y is simply “the value that Y would have taken for individual u, had X been assigned the value x.” That’s a lot of words, so it’s often convenient to write this quantity more compactly as Y (u). Often we abbreviate this further as Y (u) if it is X = x x apparent from the context what variable is being set to the value x.\nTo appreciate how audacious this notation is, you have to step back from the symbols and think about the assumptions they embody. By writing down the symbol Y , Rubin asserted that Y definitely would have taken some value x if X had been x, and this has just as much objective reality as the value Y actually did take. If you don’t buy this assumption (and I’m pretty sure Heisenberg wouldn’t), you can’t use potential outcomes. Also, note that the potential outcome, or counterfactual, is defined at the level of an individual, not a population.\nThe very first scientific appearance of a potential outcome came in the master’s thesis of Jerzy Neyman, written in 1923. Neyman, a descendant of Polish nobility, had grown up in exile in Russia and did not set foot in his native land until 1921, when he was twenty-seven years old. He had received a very strong mathematical education in Russia and would have liked to continue research in pure mathematics, but it was easier for him to find employment as a statistician. Much like R. A. Fisher in England, he did his first statistical research at an agricultural institute, a job for which he was hugely overqualified. Not only was he the only statistician in the institute, but he was really the only person in the country thinking about statistics as a discipline.\nNeyman’s first mention of potential outcomes came in the context of an agricultural experiment, where the subscript notation represents the “unknown potential yield of the i-th variety [of a given seed] on the respective plot.” The thesis remained unknown and untranslated into English until 1990. However, Neyman himself did not remain unknown. He arranged to spend a year at Karl Pearson’s statistical laboratory at University College London, where he made friends with Pearson’s son Egon. The two kept in touch for the next seven years, and their collaboration paid great dividends: the Neyman- Pearson approach to statistical hypothesis testing was a milestone that every beginning statistics student learns about.\nIn 1933, Karl Pearson’s long autocratic leadership finally came to an end with his retirement, and Egon was his logical successor—or would have been, if not for the singular problem of R. A. Fisher, by then the most famous statistician in England. The university came up with a unique and disastrous solution, dividing Pearson’s position into a chair of statistics (Egon Pearson) and a chair of eugenics (Fisher). Egon wasted no time hiring his Polish friend.\nNeyman arrived in 1934 and almost immediately locked horns with Fisher.\nFisher was already spoiling for a fight. He knew he was the world’s leading statistician and had practically invented large parts of the subject, yet was forbidden from teaching in the statistics department. Relations were extraordinarily tense. “The Common Room was carefully shared,” writes Constance Reid in her biography of Neyman. “Pearson’s group had tea at 4; and at 4:30, when they were safely out of the way, Fisher and his group trooped in.” In 1935, Neyman gave a lecture at the Royal Statistical Society titled “Statistical Problems in Agricultural Experimentation,” in which he called into question some of Fisher’s own methods and also, incidentally, discussed the idea of potential outcomes. After Neyman was done, Fisher stood up and told the society that “he had hoped that Dr. Neyman’s paper would be on a subject with which the author was fully acquainted.” “[Neyman had] asserted that Fisher was wrong,” wrote Oscar Kempthorne years later about the incident. “This was an unforgivable offense—Fisher was never wrong and indeed the suggestion that he might be was treated by him as a deadly assault. Anyone who did not accept Fisher’s writing as the God- given truth was at best stupid and at worst evil.” Neyman and Pearson saw the extent of Fisher’s fury a few days later, when they went to the department in the evening and found Neyman’s wooden models, with which he had illustrated his lecture, strewn all over the floor. They concluded that only Fisher could have been responsible for the wreckage.\nWhile Fisher’s fit of rage may seem amusing now, his attitude did have serious consequences. Of course he could not swallow his pride and use Neyman’s potential outcome notation, even though it would have helped him later with problems of mediation. The lack of potential outcome vocabulary led him and many other people into the so-called Mediation Fallacy, which we will discuss in Chapter 9.\nAt this point some readers might still find the concept of counterfactuals somewhat mystical, so I’d like to show how some of Rubin’s followers would infer potential outcomes and contrast this model-free approach with the structural causal model approach.\nSuppose that we are looking at a certain firm to see whether education or years of experience is a more important factor in determining an employee’s salary. We have collected some data on the existing salaries at this firm, reproduced in Table 8.1. We’re letting EX represent years of experience, ED represent education, and S represent salary. We’re also assuming, for simplicity, just three levels of education: 0 = high school degree, 1 = college degree, 2 = graduate degree. Thus S (u), or S (u), represents the salary of ED = 0 0 individual u if u were a high school graduate but not a college graduate, and S (u) represents u’s salary if u were a college graduate. A typical 1 counterfactual question we might want to ask is, “What would Alice’s salary be if she had a college degree?” In other words, what is S (Alice)? 1 The first thing to notice about Table 8.1 is all the missing data, indicated by question marks. We can never observe more than one potential outcome in the same individual. Although obvious, nevertheless this statement is important. Statistician Paul Holland once called it the “fundamental problem of causal inference,” a name that has stuck. If we could only fill in the question marks, we could answer all our causal questions.\nI have never agreed with Holland’s characterization of the missing values in Table 8.1 as a “fundamental problem,” perhaps because I have rarely described causal problems in terms of a table. But more fundamentally, viewing causal inference as a missing-data problem can be terribly misleading, as we will soon see. Observe that, aside from the decorative headings of the last three columns, Table 8.1 is totally devoid of causal information about ED, EX, and S—for example, whether education affects salary or the other way around. Worse yet, it does not allow us to represent such information when available. But for statisticians who perceive the “fundamental problem” to be missing data, such a table appears to present endless opportunities. Indeed, if we look at S , S , and S not as potential 0 1 2 outcomes but as ordinary variables, we have dozens of interpolation techniques to fill in the blanks or, as statisticians would say, “impute the missing data,” in some optimal way.\nTABLE 8.1. Fictitious data for potential outcomes example.\nOne common approach is matching. We look for pairs of individuals who are well matched in all variables except the one of interest and then fill in their rows to match each other. The clearest case here is that of Bert and Caroline, who match perfectly on experience. So we assume that Bert’s salary, if he had a graduate degree, would be the same as Caroline’s ($97,000), and Caroline’s salary, if she had only an undergraduate degree, would be the same as Bert’s ($92,500). Note that matching invokes the same idea as conditioning (or stratifying): we select for comparison groups that share an observed characteristic and use the comparison to infer characteristics that they do not seem to share.\nIt is hard to estimate Alice’s salary this way because there is no good match for her in the data I have given. Nevertheless, statisticians have developed techniques of considerable subtlety to impute missing data from approximate matches, and Rubin has been a pioneer of this approach.\nUnfortunately, even the most gifted matchmaker in the world cannot turn data into potential outcomes, not even approximately. I will show below that the correct answer depends critically on whether education affects experience or the other way around, information nowhere to be found in the table.\nA second possible method is linear regression (not to be conflated with structural equations). In this approach we pretend that the data came from some unknown random source and use standard statistical methods to find the line (or, in this case, plane) that best fits the data. The output of such an approach might be an equation that looks like this: S = $65,000 + 2,500 × EX + 5,000 × ED (8.1) Equation 8.1 tells us that (on average) the base salary of an employee with no experience and only a high school diploma is $65,000. For each year of experience, the salary increases by $2,500, and for each additional educational degree (up to two), the salary increases by $5,000. Accordingly, a regression analyst would claim, our estimate of Alice’s salary, if she had a college degree, is $65,000 + $2,500 × 6 + $5,000 × 1 = $85,000.\nThe ease and familiarity of such imputation techniques explain why Rubin’s conception of causal inference as a missing-data problem has enjoyed broad popularity. Alas, as innocuous as these interpolation methods appear, they are fundamentally flawed. They are data driven, not model driven. All the missing data are filled in by examining other values in the table. As we have learned from the Ladder of Causation, any such method is doomed to start with; no methods based only on data (rung one) can answer counterfactual questions (rung three).\nBefore contrasting these methods with the structural causal model approach, let us examine intuitively what goes wrong with model-blind imputation. In particular, let us explain why Bert and Caroline, who match perfectly in experience, may in fact be quite incomparable when it comes to comparing their potential outcomes. More surprising, a reasonable causal story (fitting Table 8.1) would show that the best match for Caroline for Salary would be someone who does not match her on Experience.\nThe first key point to realize is that Experience is likely to depend on Education. After all, those employees who got an extra educational degree took four years of their lives to do so. Thus, if Caroline had only one degree of education (like Bert), she would have been able to use that extra time to gain more experience compared to what she now has. This would have given her equal education to and greater experience than Bert. We can thus conclude that S (Caroline) &gt; S (Bert), contrary to what naive matching would predict.\n1 1 We see that, once we have a causal story in which Education affects Experience, it is inevitable that “matching” on Experience will create a mismatch on potential Salary.\nIronically, equal Experience, which started out as an invitation for matching, has now turned into a loud warning against it. Table 8.1 will, of course, continue its silence about such dangers. For this reason I cannot share Holland’s enthusiasm for casting causal inference as a missing-data problem.\nQuite the contrary. Recent work of Karthika Mohan, a former student of mine, reveals that even standard problems of missing data require causal modeling for their solution.\nNow let’s see how a structural causal model would treat the same data.\nFirst, before we even look at the data, we draw a causal diagram (Figure 8.3).\nThe diagram encodes the causal story behind the data, according to which Experience listens to Education and Salary listens to both. In fact, we can already tell something very important just by looking at the diagram. If our model were wrong and EX were a cause of ED, rather than vice versa, then Experience would be a confounder, and matching employees with similar experience would be completely appropriate. With ED as the cause of EX, Experience is a mediator. As you surely know by now, mistaking a mediator for a confounder is one of the deadliest sins in causal inference and may lead to the most outrageous errors. The latter invites adjustment; the former forbids it.\nF 8.3. Causal diagram for the effect of education (ED) and experience (EX) on IGURE salary (S).\nSo far in this book, I have used a very informal word—“listening”—to express what I mean by the arrows in a causal diagram. But now it’s time to put a little bit of mathematical meat on this concept, and this is in fact where structural causal models differ from Bayesian networks or regression models.\nWhen I say that Salary listens to Education and Experience, I mean that it is a mathematical function of those variables: S = f (EX, ED). But we need to S allow for individual variations, so we extend this function to read S = f (EX, S ED, U ), where U stands for “unobserved variables that affect salary.” We S S know these variables exist (e.g., Alice is a friend of the company’s president), but they are too diverse and too numerous to incorporate explicitly into our model.\nLet’s see how this would play out in our education/experience/salary example, assuming linear functions throughout. We can use the same statistical methods as before to find the best-fitting linear equation. The result would look just like Equation 8.1 with one small difference: S = $65,000 + 2,500 × EX + 5,000 × ED + U (8.2) S However, the formal similarity between Equations 8.1 and 8.2 is profoundly deceptive; their interpretations differ like night and day. The fact that we chose to regress S on ED and EX in Equation 8.1 in no way implies that S listens to ED and EX in the real world. That choice was purely ours, and nothing in the data would prevent us from regressing EX on ED and S or following any other order. (Remember Francis Galton’s discovery in Chapter 2 that regressions are cause blind.) We lose this freedom once we proclaim an equation to be “structural.” In other words, the author of Equation 8.2 must commit to writing equations that mirror his belief about who listens to whom in the world. In our case, he believes that S truly listens to EX and ED. More importantly, the absence of an equation ED = f (EX, S, U ) from the model ED ED means that ED is believed to be oblivious to changes in EX or S. This difference in commitment gives structural equations the power to support counterfactuals, a power denied to regression equations.\nIn compliance with Figure 8.3, we must also have a structural equation for EX, but now we will force the coefficient of S to zero, to reflect the absence of an arrow from S to EX. Once we estimate the coefficients from the data, the equation might look something like this: EX = 10–4 × ED + U (8.3) EX This equation says that the average experience for people with no advanced degrees is ten years, and each degree of education (up to two) decreases EX by four years on average. Again, note the key difference between structural and regression equations: variable S does not enter into Equation 8.3, despite the fact that S and EX are likely to be highly correlated. This reflects the analyst’s belief that the experience EX acquired by any individual is totally unaffected by his current salary.\nNow let’s demonstrate how to derive counterfactuals from a structural model. To estimate Alice’s salary if she had a college education, we perform three steps: 1. (Abduction) Use the data about Alice and about the other employees to estimate Alice’s idiosyncratic factors, U (Alice) S and U (Alice).\nEX 2. (Action) Use the do-operator to change the model to reflect the counterfactual assumption being made, in this case that she has a college degree: ED(Alice) = 1.\n\n(Prediction) Calculate Alice’s new salary using the modified model and the updated information about the exogenous variables U (Alice), U (Alice), and ED(Alice). This newly S EX calculated salary is equal to S (Alice).\n\nED = 1 For step 1, we observe from the data that EX(Alice) = 6 and ED(Alice) = 0.\nWe substitute these values into Equations 8.2 and 8.3. The equations then tell us Alice’s idiosyncratic factors: U (Alice) = $1,000 and U (Alice) = –4.\nS EX This represents everything that is unique, special, and wonderful about Alice.\nWhatever that is, it adds $1,000 to her predicted salary.\nStep 2 tells us to use the do-operator to erase the arrows pointing to the variable that is being set to a counterfactual value (Education) and set Alice’s Education to a college degree (Education = 1). In this example, Step 2 is trivial, because there are no arrows pointing to Education and hence no arrows to erase. In more complicated models, though, this step of erasing the arrows cannot be left out, because it affects the computation in Step 3.\nVariables that might have affected the outcome through the intervened variable will no longer be allowed to do so.\nFinally, Step 3 says to update the model to reflect the new information that U = $1,000, U = –4, and ED = 1. First we use Equation 8.3 to recompute S EX what Alice’s Experience would be if she had gone to college: EX (Alice) ED = 1 = 10 – 4 – 4 = 2 years. Then we use Equation 8.2 to recompute her potential Salary: S (Alice) = $65,000 + 2,500 × 2 + 5,000 × 1 + 1,000 = $76,000.\nED = 1 Our result, S (Alice) = $76,000, is a valid estimate of Alice’s would-be 1 salary; that is, the two will coincide if the model assumptions are valid.\nBecause this example entails a very simple causal model and very simple (linear) functions, the differences between it and the data-driven regression method may seem rather minor. But the minor differences on the surface reflect vast differences underneath. Whatever counterfactual (potential) outcome we obtain from the structural method follows logically from the assumptions displayed in the model, while the answer obtained by the data- driven method is as whimsical as spurious correlations because it leaves important modeling assumptions unaccounted for.\nThis example has forced us to go further into the “nuts and bolts” of causal models than we have previously done in this book. But let me step back a little to celebrate and appreciate the miracle that came into being through Alice’s example. Using a combination of data and model, we were able to predict the behavior of an individual (Alice) under totally hypothetical conditions. Of course, there is no such thing as a free lunch: we got these strong results because we made strong assumptions. In addition to asserting the causal relationships between the observed variables, we also assumed that the functional relationships were linear. But the linearity matters less here than knowing what those specific functions are. That enabled us to compute Alice’s idiosyncrasies from her observed characteristics and update the model as required in the three-step procedure.\nAt the risk of adding a sober note to our celebration, I have to tell you that this functional information will not always be available to us in practice. In general, we call a model “completely specified” if the functions behind the arrows are known and “partially specified” otherwise. For instance, as in Bayesian networks, we may only know probabilistic relationships between parents and children in the graph. If the model is partially specified, we may not be able to estimate Alice’s salary exactly; instead we may have to make a probability-interval statement, such as “There is a 10 to 20 percent chance that her salary would be $76,000.” But even such probabilistic answers are good enough for many applications. Moreover, it is truly remarkable how much information we can extract from the causal diagram even when we have no information on the specific functions lying behind the arrows or only very general information, such as the “monotonicity” assumption we encountered in the last chapter.\nSteps 1 to 3 above can be summed up in what I call the “first law of causal inference”: Y (u) = Y (u). This is the same rule that we used in the firing x Mx squad example in Chapter 1, except that the functions are different. The first law says that the potential outcome Y (u) can be imputed by going to the x model M (with arrows into X deleted) and computing the outcome Y(u) there.\nx All estimable quantities on rungs two and three of the Ladder of Causation follow from there. In short, the reduction of counterfactuals to an algorithm allows us to conquer as much territory from rung three as mathematics will permit—but, of course, not a bit more.\nTHE VIRTUE OF SEEING YOUR ASSUMPTIONS The SCM method I have shown for computing counterfactuals is not the same method that Rubin would use. A major point of difference between us is the use of causal diagrams. They allow researchers to represent causal assumptions in terms that they can understand and then treat all counterfactuals as derived properties of their world model. The Rubin causal model treats counterfactuals as abstract mathematical objects that are managed by algebraic machinery but not derived from a model.\nDeprived of a graphical facility, the user of the Rubin causal model is usually asked to accept three assumptions. The first one, called the “stable unit treatment value assumption,” or SUTVA, is reasonably transparent. It says that each individual (or “unit,” the preferred term of causal modelers) will have the same effect of treatment regardless of what treatment the other individuals (or “units”) receive. In many cases, barring epidemics and other collective interactions, this makes perfectly good sense. For example, assuming headache is not contagious, my response to aspirin will not depend on whether Joe receives aspirin.\nThe second assumption in Rubin’s model, also benign, is called “consistency.” It says that a person who took aspirin and recovered would also recover if given aspirin by experimental design. This reasonable assumption, which is a theorem in the SCM framework, says in effect that the experiment is free of placebo effects and other imperfections.\nBut the major assumption that potential outcome practitioners are invariably required to make is called “ignorability.” It is more technical, but it’s the crucial part of the transaction, for it is in essence the same thing as Jamie Robins and Sander Greenland’s condition of exchangeability discussed in Chapter 4. Ignorability expresses this same requirement in terms of the potential outcome variable Y . It requires that Y be independent of the x x treatment actually received, namely X, given the values of a certain set of (de)confounding variables Z. Before exploring its interpretation, we should acknowledge that any assumption expressed as conditional independence inherits a large body of familiar mathematical machinery developed by statisticians for ordinary (noncounterfactual) variables. For example, statisticians routinely use rules for deciding when one conditional independence follows from another. To Rubin’s credit, he recognized the advantages of translating the causal notion of “nonconfoundedness” into the syntax of probability theory, albeit on counterfactual variables. The ignorability assumption makes the Rubin causal model actually a model; Table 8.1 in itself is not a model because it contains no assumptions about the world.\nUnfortunately, I have yet to find a single person who can explain what ignorability means in a language spoken by those who need to make this assumption or assess its plausibility in a given problem. Here is my best try.\nThe assignment of patients to either treatment or control is ignorable if, within any stratum of the confounder Z, patients who would have one potential outcome, Y = y, are just as likely to be in the treatment or control group as x the patients who would have a different potential outcome, Y = y′. This x definition is perfectly legitimate for someone in possession of a probability function over counterfactuals. But how is a biologist or economist with only scientific knowledge for guidance supposed to assess whether this is true or not? More concretely, how is a scientist to assess whether ignorability holds in any of the examples discussed in this book? To understand the difficulty, let us attempt to apply this explanation to our example. To determine if ED is ignorable (conditional on EX), we are supposed to judge whether employees who would have one potential salary, say S = s, are just as likely to have one level of education as the employees 1 who would have a different potential salary, say S = s′. If you think that this 1 sounds circular, I can only agree with you! We want to determine Alice’s potential salary, and even before we start—even before we get a hint about the answer—we are supposed to speculate on whether the result is dependent or independent of ED, in every stratum of EX. It is quite a cognitive nightmare.\nAs it turns out, ED in our example is not ignorable with respect to S, conditional on EX, and this is why the matching approach (setting Bert and Caroline equal) would yield the wrong answer for their potential salaries. In fact, their estimates should differ by an amount S (Bert)–S (Caroline) = 1 1 $5,000. (The reader should be able to show this from the numbers in Table 8.1 and the three-step procedure.) I will now show that with the help of a causal diagram, a student could see immediately that ED is not ignorable and would not attempt matching here. Lacking a diagram, a student would be tempted to assume that ignorability holds by default and would fall into this trap. (This is not a speculation. I borrowed the idea for this example from an article in Harvard Law Review where the story was essentially the same as in Figure 8.3 and the author did use matching.) Here is how we can use a causal diagram to test for (conditional) ignorability. To determine if X is ignorable relative to outcome Y, conditional on a set Z of matching variables, we need only test to see if Z blocks all the back-door paths between X and Y and no member of Z is a descendant of X. It is as simple as that! In our example, the proposed matching variable (Experience) blocks all the back-door paths (because there aren’t any), but it fails the test because it is a descendant of Education. Therefore ED is not ignorable, and EX cannot be used for matching. No elaborate mental gymnastics are needed, just a look at a diagram. Never is a researcher required to mentally assess how likely a potential outcome is given one treatment or another.\nUnfortunately, Rubin does not consider causal diagrams to “aid the drawing of causal inferences.” Therefore, researchers who follow his advice will be deprived of this test for ignorability and will either have to perform formidable mental gymnastics to convince themselves that the assumption holds or else simply accept the assumption as a “black box.” Indeed, a prominent potential outcome researcher, Marshall Joffe, wrote in 2010 that ignorability assumptions are usually made because they justify the use of available statistical methods, not because they are truly believed.\nClosely related to transparency is the notion of testability, which has come up several times in this book. A model cast as a causal diagram can easily be tested for compatibility with the data, whereas a model cast in potential outcome language lacks this feature. The test goes like this: whenever all paths between X and Y in the diagram are blocked by a set of nodes Z, then in the data X and Y should be independent, conditional on Z. This is the d- separation property mentioned in Chapter 7, which allows us to reject a model whenever the independence fails to show up in the data. In contrast, if the same model is expressed in the language of potential outcomes (i.e., as a collection of ignorability statements), we lack the mathematical machinery to unveil the independencies that the model entails, and researchers are unable to subject the model to a test. It is hard to understand how potential outcome researchers managed to live with this deficiency without rebelling. My only explanation is that they were kept away from graphical tools for so long that they forgot that causal models can and should be testable.\nNow I must apply the same standards of transparency to myself and say a little bit more about the assumptions embodied in a structural causal model.\nRemember the story of Abraham that I related earlier? Abraham’s first response to the news of Sodom’s imminent destruction was to look for a dose- response relationship, or a response function, relating the wickedness of the city to its punishment. It was a sound scientific instinct, but I suspect few of us would have been calm enough to react that way.\nThe response function is the key ingredient that gives SCMs the power to handle counterfactuals. It is implicit in Rubin’s potential outcome paradigm but a major point of difference between SCMs and Bayesian networks, including causal Bayesian networks. In a probabilistic Bayesian network, the arrows into Y mean that the probability of Y is governed by the conditional probability tables for Y, given observations of its parent variables. The same is true for causal Bayesian networks, except that the conditional probability tables specify the probability of Y given interventions on the parent variables.\nBoth models specify probabilities for Y, not a specific value of Y. In a structural causal model, there are no conditional probability tables. The arrows simply mean Y is a function of its parents, as well as the exogenous variable U : Y Y = f (X, A, B, C,…, U ) (8.4) Y Y Thus, Abraham’s instinct was sound. To turn a noncausal Bayesian network into a causal model—or, more precisely, to make it capable of answering counterfactual queries—we need a dose-response relationship at each node.\nThis realization did not come to me easily. Even before delving into counterfactuals, I tried for a very long time to formulate causal models using conditional probability tables. One obstacle I faced was cyclic models, which were totally resistant to conditional probability formulations. Another obstacle was that of coming up with a notation to distinguish probabilistic Bayesian networks from causal ones. In 1991, it suddenly hit me that all the difficulties would vanish if we made Y a function of its parent variables and let the U term handle all the uncertainties concerning Y. At the time, it Y seemed like a heresy against my own teaching. After devoting several years to the cause of probabilities in artificial intelligence, I was now proposing to take a step backward and use a nonprobabilistic, quasi-deterministic model. I can still remember my student at the time, Danny Geiger, asking incredulously, “Deterministic equations? Truly deterministic?” It was as if Steve Jobs had just told him to buy a PC instead of a Mac. (This was 1990!) On the surface, there was nothing revolutionary about these equations.\nEconomists and sociologists had been using such models since the 1950s and 1960s and calling them structural equation models (SEMs). But this name signaled controversy and confusion over the causal interpretation of the equations. Over time, economists lost sight of the fact that the pioneers of these models, Trygve Haavelmo in economics and Otis Dudley Duncan in sociology, had intended them to represent causal relationships. They began to confuse structural equations with regression lines, thus stripping the substance from the form. For example, in 1988, when David Freedman challenged eleven SEM researchers to explain how to apply interventions to a structural equation model, not one of them could. They could tell you how to estimate the coefficients from data, but they could not tell you why anyone should bother. If the response-function interpretation I presented between 1990 and 1994 did anything new, it was simply to restore and formalize Haavelmo’s and Duncan’s original intentions and lay before their disciples the bold conclusions that follow from those intentions if you take them seriously.\nSome of these conclusions would be considered astounding, even by Haavelmo and Duncan. Take for example the idea that from every SEM, no matter how simple, we can compute all the counterfactuals that one can imagine among the variables in the model. Our ability to compute Alice’s potential salary, had she had college education, followed from this idea. Even today modern-day economists have not internalized this idea.\nOne other important difference between SEMs and SCMs, besides the middle letter, is that the relationship between causes and effects in an SCM is not necessarily linear. The techniques that emerge from SCM analysis are valid for nonlinear as well as linear functions, discrete as well as continuous variables.\nLinear structural equation models have many advantages and many disadvantages. From the viewpoint of methodology, they are seductively simple. They can be estimated from observational data by linear regression, and you can choose between dozens of statistical software packages to do this for you.\nOn the other hand, linear models cannot represent dose-response curves that are not straight lines. They cannot represent threshold effects, such as a drug that has increasing effects up to a certain dosage and then no further effect. They also cannot represent interactions between variables. For instance, a linear model cannot describe a situation in which one variable enhances or inhibits the effect of another variable. (For example, Education might enhance the effect of Experience by putting the individual in a faster- track job that gets bigger annual raises.) While debates about the appropriate assumptions to make are inevitable, our main message is quite simple: Rejoice! With a fully specified structural causal model, entailing a causal diagram and all the functions behind it, we can answer any counterfactual query. Even with a partial SCM, in which some variables are hidden or the dose-response relationships are unknown, we can still in many cases answer our query. The next two sections give some examples.\nCOUNTERFACTUALS AND THE LAW In principle, counterfactuals should find easy application in the courtroom. I say “in principle” because the legal profession is very conservative and takes a long time to accept new mathematical methods. But using counterfactuals as a mode of argument is actually very old and known in the legal profession as “but-for causation.” The Model Penal Code expresses the “but-for” test as follows: “Conduct is the cause of a result when: (a) it is an antecedent but for which the result in question would not have occurred.” If the defendant fired a gun and the bullet struck and killed the victim, the firing of the gun is a but-for, or necessary, cause of the death, since the victim would be alive if not for the firing. But-for causes can also be indirect. If Joe blocks a building’s fire exit with furniture, and Judy dies in a fire after she could not reach the exit, then Joe is legally responsible for her death even though he did not light the fire.\nHow can we express necessary or but-for causes in terms of potential outcomes? If we let the outcome Y be “Judy’s death” (with Y = 0 if Judy lives and Y = 1 if Judy dies) and the treatment X be “Joe’s blocking the fire escape” (with X = 0 if he does not block it and X = 1 if he does), then we are instructed to ask the following question: Given that we know the fire escape was blocked (X = 1) and Judy died (Y = 1), what is the probability that Judy would have lived (Y = 0) if X had been 0? Symbolically, the probability we want to evaluate is P(Y = 0 | X = 1, Y = X = 0 1). Because this expression is rather cumbersome, I will later abbreviate it as “PN,” the probability of necessity (i.e., the probability that X = 1 is a necessary or but-for cause of Y = 1).\nNote that the probability of necessity involves a contrast between two different worlds: the actual world where X = 1 and the counterfactual world where X = 0 (expressed by the subscript X = 0). In fact, hindsight (knowing what happened in the actual world) is a critical distinction between counterfactuals (rung three of the Ladder of Causation) and interventions (rung two). Without hindsight, there is no difference between P(Y = 0) X = 0 and P(Y = 0 | do(X = 0)). Both express the probability that, under normal conditions, Judy will be alive if we ensure that the exit is not blocked; they do not mention the fire, Judy’s death, or the blocked exit. But hindsight may change our estimate of the probabilities. Suppose we observe that X = 1 and Y = 1 (hindsight). Then P(Y = 0 | X = 1, Y = 1) is not the same as P(Y = X = 0 X = 0 0 | X = 1). Knowing that Judy died (Y = 1) gives us information on the circumstances that we would not get just by knowing that the door was blocked (X = 1). For one thing, it is evidence of the strength of the fire.\nIn fact, it can be shown that there is no way to capture P(Y = 0 | X = 1, X = 0 Y = 1) in a do-expression. While this may seem like a rather arcane point, it does give mathematical proof that counterfactuals (rung three) lie above interventions (rung two) on the Ladder of Causation.\nIn the last few paragraphs, we have almost surreptitiously introduced probabilities into our discussion. Lawyers have long understood that mathematical certainty is too high a standard of proof. For criminal cases in the United States, the Supreme Court in 1880 established that guilt has to be proven “to the exclusion of all reasonable doubt.” The court said not “beyond all doubt” or “beyond a shadow of a doubt” but beyond reasonable doubt. The Supreme Court has never given a precise definition of that term, but one might conjecture that there is some threshold, perhaps 99 percent or 99.9 percent probability of guilt, above which doubt becomes unreasonable and it is in society’s interest to lock the defendant up. In civil rather than criminal proceedings, the standard of proof is somewhat clearer. The law requires a “preponderance of evidence” that the defendant caused the injury, and it seems reasonable to interpret this to mean that the probability is greater than 50 percent.\nAlthough but-for causation is generally accepted, lawyers have recognized that in some cases it might lead to a miscarriage of justice. One classic example is the “falling piano” scenario, where the defendant fires a shot at the victim and misses, and in the process of fleeing the scene, the victim happens to run under a falling piano and is killed. By the but-for test the defendant would be guilty of murder, because the victim would not have been anywhere near the falling piano if he hadn’t been running away. But our intuition says that the defendant is not guilty of murder (though he may be guilty of attempted murder), because there was no way that he could have anticipated the falling piano. A lawyer would say that the piano, not the gunshot, is the proximate cause of death.\nThe doctrine of proximate cause is much more obscure than but-for cause.\nThe Model Penal Code says that the outcome should not be “too remote or accidental in its occurrence to have a [just] bearing on the actor’s liability or the gravity of his offense.” At present this determination is left to the intuition of the judge. I would suggest that it is a form of sufficient cause. Was the defendant’s action sufficient to bring about, with high enough probability, the event that actually caused the death? While the meaning of proximate cause is very vague, the meaning of sufficient cause is quite precise. Using counterfactual notation, we can define the probability of sufficiency, or PS, to be P(Y = 1 | X = 0, Y = 0). This X = 1 tells us to imagine a situation where X = 0 and Y = 0: the shooter did not fire at the victim, and the victim did not run under a piano. Then we ask how likely it is that in such a situation, firing the shot (X = 1) would result in outcome Y = 1 (running under a piano)? This calls for counterfactual judgment, but I think that most of us would agree that the likelihood of such an outcome would be extremely small. Both intuition and the Model Penal Code suggest that if PS is too small, we should not convict the defendant of causing Y = 1.\nBecause the distinction between necessary and sufficient causes is so important, I think it may help to anchor these two concepts in simple examples. Sufficient cause is the more common of the two, and we have already encountered this concept in the firing squad example of Chapter 1.\nThere, the firing of either Soldier A or Soldier B is sufficient to cause the prisoner’s death, and neither (in itself) is necessary. So PS = 1 and PN = 0.\nThings get a bit more interesting when uncertainty strikes—for example, if each soldier has some probability of disobeying orders or missing the target.\nFor example, if Soldier A has a probability p of missing the target, then his A PS would be 1–p , since this is his probability of hitting the target and A causing death. His PN, however, would depend on how likely Soldier B is to refrain from shooting or to miss the target. Only under such circumstances would the shooting of Soldier A be necessary; that is, the prisoner would be alive had Soldier A not shot.\nA classic example demonstrating necessary causation tells the story of a fire that broke out after someone struck a match, and the question is “What caused the fire, striking the match or the presence of oxygen in the room?” Note that both factors are equally necessary, since the fire would not have occurred absent one of them. So, from a purely logical point of view, the two factors are equally responsible for the fire. Why, then, do we consider lighting the match a more reasonable explanation of the fire than the presence of oxygen? To answer this, consider the two sentences: 1. The house would still be standing if only the match had not been struck.\n\nThe house would still be standing if only the oxygen had not been present.\n\nBoth sentences are true. Yet the overwhelming majority of readers, I’m sure, would come up with the first scenario if asked to explain what caused the house to burn down, the match or the oxygen. So, what accounts for the difference? The answer clearly has something to do with normality: having oxygen in the house is quite normal, but we can hardly say that about striking a match.\nThe difference does not show up in the logic, but it does show up in the two measures we discussed above, PS and PN.\nIf we take into account that the probability of striking a match is much lower than that of having oxygen, we find quantitatively that for Match, both PN and PS are high, while for Oxygen, PN is high but PS is low. Is this why, intuitively, we blame the match and not the oxygen? Quite possibly, but it may be only part of the answer.\nIn 1982, psychologists Daniel Kahneman and Amos Tversky investigated how people choose an “if only” culprit to “undo” an undesired outcome and found consistent patterns in their choices. One was that people are more likely to imagine undoing a rare event than a common one. For example, if we are undoing a missed appointment, we are more likely to say, “If only the train had left on schedule,” than “If only the train had left early.” Another pattern was people’s tendency to blame their own actions (e.g., striking a match) rather than events not under their control. Our ability to estimate PN and PS from our model of the world suggests a systematic way of accounting for these considerations and eventually teaching robots to produce meaningful explanations of peculiar events.\nWe have seen that PN captures the rationale behind the “but-for” criterion in a legal setting. But should PS enter legal considerations in criminal and tort law? I believe that it should, because attention to sufficiency implies attention to the consequences of one’s action. The person who lit the match ought to have anticipated the presence of oxygen, whereas nobody is generally expected to pump all the oxygen out of the house in anticipation of a match- striking ceremony.\nWhat weight, then, should the law assign to the necessary versus sufficient components of causation? Philosophers of law have not discussed the legal status of this question, perhaps because the notions of PS and PN were not formalized with such precision. However, from an AI perspective, clearly PN and PS should take part in generating explanations. A robot instructed to explain why a fire broke out has no choice but to consider both. Focusing on PN only would yield the untenable conclusion that striking a match and having oxygen are equally adequate explanations for the fire. A robot that issues this sort of explanation will quickly lose its owner’s trust.\nNECESSARY CAUSES, SUFFICIENT CAUSES, AND CLIMATE CHANGE In August 2003, the most intense heat wave in five centuries struck western Europe, concentrating its most severe effects on France. The French government blamed the heat wave for nearly 15,000 deaths, many of them among elderly people who lived by themselves and did not have air- conditioning. Were they victims of global warming or of bad luck—of living in the wrong place at the wrong time? Before 2003, climate scientists had avoided speculating on such questions.\nThe conventional wisdom was something like this: “Although this is the kind of phenomenon that global warming might make more frequent, it is impossible to attribute this particular event to past emissions of greenhouse gases.” Myles Allen, a physicist at the University of Oxford and author of the above quote, suggested a way to do better: use a metric called fraction of attributable risk (FAR) to quantify the effect of climate change. The FAR requires us to know two numbers: p , the probability of a heat wave like the 0 2003 heat wave before climate change (e.g., before 1800), and p , the 1 probability after climate change. For example, if the probability doubles, then we can say that half of the risk is due to climate change. If it triples, then two- thirds of the risk is due to climate change.\nBecause the FAR is defined purely from data, it does not necessarily have any causal meaning. It turns out, however, that under two mild causal assumptions, it is identical to the probability of necessity. First, we need to assume that the treatment (greenhouse gases) and outcome (heat waves) are not confounded: there is no common cause of each. This is very reasonable, because as far as we know, the only cause of the increase in greenhouse gases is ourselves. Second, we need to assume monotonicity. We discussed this assumption briefly in the last chapter; in this context, it means that the treatment never has the opposite effect from what we expect: that is, greenhouse gases can never protect us from a heat wave.\nProvided the assumptions of no confounding and no protection hold, the rung-one metric of FAR is promoted to rung three, where it becomes PN. But Allen did not know the causal interpretation of the FAR—it is probably not common knowledge among meteorologists—and this forced him to present his results using somewhat tortuous language.\nBut what data can we use to estimate the FAR (or PN)? We have observed only one such heat wave. We can’t do a controlled experiment, because that would require us to control the level of carbon dioxide as if we were flicking a switch. Fortunately, climate scientists have a secret weapon: they can conduct an in silico experiment—a computer simulation.\nAllen and Peter Stott of the Met Office (the British weather service) took up the challenge, and in 2004 they became the first climate scientists to commit themselves to a causal statement about an individual weather event.\nOr did they? Judge for yourself. This is what they wrote: “It is very likely that over half the risk of European summer temperature anomalies exceeding a threshold of 1.6° C. is attributable to human influence.” Although I commend Allen and Stott’s bravery, it is a pity that their important finding was buried in such a thicket of impenetrable language. Let me unpack this statement and then try to explain why they had to express it in such a convoluted way. First, “temperature anomaly exceeding a threshold of 1.6° C.” was their way of defining the outcome. They chose this threshold because the average temperature in Europe that summer was more than 1.6° C above normal, which had never previously happened in recorded history.\nTheir choice balanced the competing objectives of picking an outcome that is sufficiently extreme to capture the effect of global warming but not too closely tailored to the specifics of the 2003 event. Instead of using, for example, the average temperature in France during August, they chose the broader criterion of the average temperature in Europe over the entire summer.\nNext, what did they mean by “very likely” and “half the risk”? In mathematical terms, Allen and Stott meant that there was a 90 percent chance that the FAR was over 50 percent. Or, equivalently, there is a 90 percent chance that summers like 2003 are more than twice as likely with current levels of carbon dioxide as they would be with preindustrial levels. Notice that there are two layers of probability here: we are talking about a probability of a probability! No wonder our mind boggles and our eyes swim when we read such a statement. The reason for the double whammy is that the heat wave is subject to two kinds of uncertainty. First, there is uncertainty over the amount of long-term climate change. This is the uncertainty that goes into the first 90 percent figure. Even if we know the amount of long-term climate change exactly, there is uncertainty about the weather in any given year. That is the kind of variability that is built into the 50 percent fraction of attributable risk.\nSo we have to grant that Allen and Stott were trying to communicate a complicated idea. Nevertheless, one thing is missing from their conclusion: causality. Their statement does not contain even a hint of causation—or maybe just a hint, in the ambiguous and inscrutable phrase “attributable to human influence.” Now compare this with a causal version of the same conclusion: “CO 2 emissions are very likely to have been a necessary cause of the 2003 heat wave.” Which sentence, theirs or ours, will you still remember tomorrow? Which one could you explain to your next-door neighbor? I am not personally an expert on climate change, so I got this example from one of my collaborators, Alexis Hannart of the Franco-Argentine Institute on the Study of Climate and Its Impacts in Buenos Aires, who has been a big proponent of causal analysis in climate science. Hannart draws the causal graph in Figure 8.4. Because Greenhouse Gases is a top-level node in the climate model, with no arrows going into it, he argues that there is no confounding between it and Climate Response. Likewise, he vouches for the no-protection assumption (i.e., greenhouse gases cannot protect us from heat waves).\nHannart goes beyond Allen and Stott and uses our formulas to compute the probability of sufficiency (PS) and of necessity (PN). In the case of the 2003 European heat wave, he finds that PS was extremely low, about 0.0072, meaning that there was no way to predict that this event would happen in this particular year. On the other hand, the probability of necessity PN was 0.9, in agreement with Allen and Stott’s results. This means that it is highly likely that, without greenhouse gases, the heat wave would not have happened.\nThe apparently low value of PS has to be put into a larger context. We don’t just want to know the probability of a heat wave this year; we would like to know the probability of a recurrence of such a severe heat wave over a longer time frame—say in the next ten or fifty years. As the time frame lengthens, PN decreases because other possible mechanisms for a heat wave might come into play. On the other hand, PS increases because we are in effect giving the dice more chances to come up snake eyes. So, for example, Hannart computes that there is an 80 percent probability that climate change will be a sufficient cause of another European heat wave like the 2003 one (or worse) in a two-hundred-year period. That might not sound too terrifying, but that’s assuming the greenhouse gas levels of today. In reality, CO levels are 2 certain to continue rising, which can only increase PS and shorten the window of time until the next heat wave.\nF 8.4. Causal diagram for the climate change example.\nIGURE Can ordinary people learn to understand the difference between necessary and sufficient causes? This is a nontrivial question. Even scientists sometimes struggle. In fact, two conflicting studies came out that analyzed the 2010 heat wave in Russia, when Russia had its hottest summer ever and peat fires darkened the skies of Moscow. One group concluded that natural variability caused the heat wave; another concluded that climate change caused it. In all likelihood, the disagreement occurred because the two groups defined their outcome differently. One group apparently based its argument on PN and got a high likelihood that climate change was the cause, while the other used PS and got a low likelihood. The second group attributed the heat wave to a persistent high-pressure or “blocking pattern” over Russia—which sounds to me like a sufficient cause—and found that greenhouse gases had little to do with this phenomenon. But any study that uses PS as a metric, over a short period, is setting a high bar for proving causation.\nBefore leaving this example, I would like to comment again on the computer models. Most other scientists have to work very hard to get counterfactual information, for example by painfully combining data from observational and experimental studies. Climate scientists can get counterfactuals very easily from their computer models: just enter in a new number for the carbon dioxide concentration and let the program run.\n“Easily” is, of course, relative. Behind the simple causal diagram of Figure 8.4 lies a fabulously complex response function, given by the millions of lines of computer code that go into a climate simulation.\nThis brings up a natural question: How much can we trust the computer simulations? The question has political ramifications, especially here in the United States. However, I will try to give an apolitical answer. I would consider the response function in this example much more credible than the linear models that one sees so often in natural and social sciences. Linear models are often chosen for no good reason other than convenience. By comparison, the climate models reflect more than a century of study by physicists, meteorologists, and climate scientists. They represent the best efforts of a community of scientists to understand the processes that govern our weather and climate. By any normal scientific standards, the climate models are strong and compelling evidence, but with one caveat. Though they are excellent at forecasting the weather a few days ahead, they have never been verified in a prospective trial over century-long timescales, so they could still contain systematic errors that we don’t know about.\nA WORLD OF COUNTERFACTUALS I hope that by now it is obvious that counterfactuals are an essential part of how humans learn about the world and how our actions affect it. While we can never walk down both the paths that diverge in a wood, in a great many cases we can know, with some degree of confidence, what lies down each.\nBeyond doubt, the variety and richness of causal queries that we can pose to our “inference engine” are greatly enhanced when we can include counterfactuals in the mix. Another very popular kind of query, which I have not discussed here, called the effect of treatment on the treated (ETT), is used to evaluate whether people who gain access to a treatment are those who would benefit most from it. This measure is in many cases superior to the conventional measure of a treatment’s effectiveness, the average causal effect (ACE). The ACE, which you can get from a randomized controlled trial, averages treatment efficacy over the entire population. But what if, in actual implementation, those recruited for a treatment program are the ones least likely to benefit from it? To assess the overall effectiveness of the program, ETT measures how adversely treated patients would be affected had they not been treated—a counterfactual measure of critical significance in practical decision making. My former student Ilya Shpitser (now at Johns Hopkins) has now done for ETT what the do-calculus did for ACE—provided a complete understanding of when it is estimable from data, given a causal diagram.\nUndoubtedly the most popular application of counterfactuals in science today is called mediation analysis. For that reason, I devote a separate chapter to it (Chapter 9). Oddly, many people, especially if using classical mediation analysis techniques, may not realize that they are talking about a counterfactual effect.\nIn a scientific context, a mediator, or mediating variable, is one that transmits the effect of the treatment to the outcome. We have seen many mediation examples in this book, such as Smoking Tar Cancer (where Tar is the mediator). The main question of interest in such cases is whether the mediating variable accounts for the entire effect of the treatment variable or some part of the effect does not require a mediator. We would represent such an effect by a separate arrow leading directly from the treatment to the outcome, such as Smoking Cancer.\nMediation analysis aims to disentangle the direct effect (which does not pass through the mediator) from the indirect effect (the part that passes through the mediator). The importance is easy to see. If smoking causes lung cancer only through the formation of tar deposits, then we could eliminate the excess cancer risk by giving smokers tar-free cigarettes, such as e-cigarettes.\nOn the other hand, if smoking causes cancer directly or through a different mediator, then e-cigarettes might not solve the problem. At present this medical question is unresolved.\nAt this point it is probably not obvious to you that direct and indirect effects involve counterfactual statements. It was definitely not obvious to me! In fact, it was one of the biggest surprises of my career. The next chapter tells this story and gives many real-life applications of mediation analysis.\nIn 1912, a cairn of snow and a cross of skis mark the final resting place of Captain Robert Falcon Scott (right) and the last two men from his ill-fated expedition to the South Pole. Among numerous hardships, Scott’s men suffered from scurvy. This part of the tragedy could have been averted if scientists had understood the mechanism by which citrus fruits prevent the disease. (Source: left, photograph by Tryggve Gran (presumed); right, photograph by Herbert Ponting. Courtesy of Canterbury Museum, New Zealand.)",
    "crumbs": [
      "Causal Inference",
      "The book of why"
    ]
  },
  {
    "objectID": "extracted/The Book of Why - Judea Pearl.html#mediation-the-search-for-a-mechanism",
    "href": "extracted/The Book of Why - Judea Pearl.html#mediation-the-search-for-a-mechanism",
    "title": "The book of why",
    "section": "9. MEDIATION: THE SEARCH FOR A MECHANISM",
    "text": "9. MEDIATION: THE SEARCH FOR A MECHANISM\nFor want of a nail the shoe was lost.\nFor want of a shoe the horse was lost.… For want of a battle the kingdom was lost.\nAnd all for the want of a nail.\n—ANONYMOUS I N ordinary language, the question “Why?” has at least two versions. The first is straightforward: you see an effect, and you want to know the cause.\nYour grandfather is lying in the hospital, and you ask, “Why? How could he have had a heart attack when he seemed so healthy?” But there is a second version of the “Why?” question, which we ask when we want to better understand the connection between a known cause and a known effect. For instance, we observe that Drug B prevents heart attacks. Or, like James Lind, we observe that citrus fruits prevent scurvy. The human mind is restless and always wants to know more. Before long we start asking the second version of the question: “Why? What is the mechanism by which citrus fruits prevent scurvy?” This chapter focuses on this second version of “why.” The search for mechanisms is critical to science, as well as to everyday life, because different mechanisms call for different actions when circumstances change. Suppose we run out of oranges. Knowing the mechanism by which oranges work, we can still prevent scurvy. We simply need another source of vitamin C. If we didn’t know the mechanism, we might be tempted to try bananas.\nThe word that scientists use for the second type of “Why?” question is “mediation.” You might read in a journal a statement like this: “The effect of Drug B on heart attacks is mediated by its effect on blood pressure.” This statement encodes a simple causal model: Drug A Blood Pressure Heart Attack. In this case, the drug reduces high blood pressure, which in turn reduces the risk of heart attack. (Biologists typically use a different symbol, A —| B, when cause A inhibits effect B, but in the causality literature it is customary to use A B both for positive and negative causes.) Likewise, we can summarize the effect of citrus fruits on scurvy by the causal model Citrus Fruits Vitamin C Scurvy.\nWe want to ask certain typical questions about a mediator: Does it account for the entire effect? Does Drug B work exclusively through blood pressure or perhaps through other mechanisms as well? The placebo effect is a common type of mediator in medicine: if a drug acts only through the patient’s belief in its benefit, most doctors will consider it ineffective. Mediation is also an important concept in the law. If we ask whether a company discriminated against women when it paid them lower salaries, we are asking a mediation question. The answer depends on whether the observed salary disparity is produced directly in response to the applicant’s sex or indirectly, through a mediator such as qualification, over which the employer has no control.\nAll the above questions require a sensitive ability to tease apart total effects, direct effects (which do not pass through a mediator), and indirect effects (which do). Even defining these terms has been a major challenge for scientists over the past century. Inhibited by the taboos against uttering the word “causation,” some tried to define mediation using a causality-free vocabulary. Others dismissed mediation analysis altogether and declared the concepts of direct and indirect effects as “more deceptive than helpful to clear statistical thinking.” For me, too, mediation was a struggle—ultimately one of the most rewarding of my career, because I was wrong at first, and as I was learning from my mistake, I came up with an unexpected solution. For a while, I was of the opinion that indirect effects have no operational implications because, unlike direct effects, they cannot be defined in the language of interventions.\nIt was a personal breakthrough when I realized that they can be defined in terms of counterfactuals and that they can also have important policy implications. They can be quantified only after we have reached the third rung of the Ladder of Causation, and that is why I have placed them at the end of this book. Mediation has flourished in its new habitat and enabled us to quantify, often from the bare data, the portion of the effect mediated by any desired path.\nUnderstandably, due to their counterfactual dressing, indirect effects remain somewhat enigmatic even among champions of the Causal Revolution. I believe that their overwhelming usefulness, however, will eventually overcome any lingering doubts over the metaphysics of counterfactuals. Perhaps they could be compared to irrational and imaginary numbers: they made people uncomfortable at first (hence the name “irrational”), but eventually their usefulness transformed discomfort into delight.\nTo illustrate this point, I will give several examples of how researchers in various disciplines have gleaned useful insights from mediation analysis. One researcher studied an education reform called “Algebra for All,” which at first seemed a failure but later turned into a success. A study of tourniquet use in the Iraq and Afghanistan wars failed to show that it had any benefit; careful mediation analysis explains why the benefit may have been masked in the study.\nIn summary, over the last fifteen years, the Causal Revolution has uncovered clear and simple rules for quantifying how much of a given effect is direct and how much is indirect. It has transformed mediation from a poorly understood concept with doubtful legitimacy into a popular and widely applicable tool for scientific analysis.\nSCURVY: THE WRONG MEDIATOR I would like to begin with a truly appalling historical example that highlights the importance of understanding the mediator.\nOne of the earliest examples of a controlled experiment was sea captain James Lind’s study of scurvy, published in 1747. In Lind’s time scurvy was a terrifying disease, estimated to have killed 2 million sailors between 1500 and 1800. Lind established, as conclusively as anybody could at that time, that a diet of citrus fruit prevented sailors from developing this dread disease. By the early 1800s, scurvy had become a problem of the past for the British navy, as all its ships took to the seas with an adequate supply of citrus fruit. This is usually the point at which history books end the story, celebrating a great triumph of the scientific method.\nIt seems very surprising, then, that this completely preventable disease made an unexpected comeback a century later, when British expeditions started to explore the polar regions. The British Arctic Expedition of 1875, the Jackson-Harmsworth Expedition to the Arctic in 1894, and most notably the two expeditions of Robert Falcon Scott to Antarctica in 1903 and 1911 all suffered greatly from scurvy.\nHow could this have happened? In two words: ignorance and arrogance— always a potent combination. By 1900 the leading physicians in Britain had forgotten the lessons of a century before. Scott’s physician on the 1903 expedition, Dr. Reginald Koettlitz, attributed scurvy to tainted meat. Further, he added, “the benefit of the so-called ‘antiscorbutics’ [i.e., scurvy preventatives, such as lime juice] is a delusion.” In his 1911 expedition, Scott stocked dried meat that had been scrupulously inspected for signs of decay but no citrus fruits or juices (see Figure 9.1). The trust he placed in the doctor’s opinion may have contributed to the tragedy that followed. All of the five men who made it to the South Pole died, two of an unspecified illness that was most likely scurvy. One team member turned back before the pole and made it back alive, but with a severe case of scurvy.\nWith hindsight, Koettlitz’s advice borders on criminal malpractice. How could the lesson of James Lind have been so thoroughly forgotten—or worse, dismissed—a century later? The explanation, in part, is that doctors did not really understand how citrus fruits worked against scurvy. In other words, they did not know the mediator.\nF 9.1. Daily rations for the men on Scott’s trek to the pole: chocolate, IGURE pemmican (a preserved meat dish), sugar, biscuits, butter, tea. Conspicuously absent: any fruit containing vitamin C. (Source: Photograph by Herbert Ponting, courtesy of Canterbury Museum, New Zealand.) From Lind’s day onward, it had always been believed (but never proved) that citrus fruits prevented scurvy as a result of their acidity. In other words, doctors understood the process to be governed by the following causal diagram: Citrus Fruits Acidity Scurvy From this point of view, any acid would do. Even Coca-Cola would work (although it had not yet been invented). At first sailors used Spanish lemons; then, for economic reasons, they substituted West Indian limes, which were as acidic as the Spanish lemons but contained only a quarter of the vitamin C. To make things worse, they started “purifying” the lime juice by cooking it, which may have broken down whatever vitamin C it still contained. In other words, they were disabling the mediator.\nWhen the sailors on the 1875 Arctic expedition fell ill with scurvy despite taking lime juice, the medical community was thrown into utter confusion.\nThose sailors who had eaten freshly killed meat did not get scurvy, while those who had eaten tinned meat did. Koettlitz and others blamed improperly preserved meat as the culprit. Sir Almroth Wright concocted a theory that bacteria in the (supposedly) tainted meat caused “ptomaine poisoning,” which then led to scurvy. Meanwhile the theory that citrus fruits could prevent scurvy was consigned to the dustbin.\nThe situation was not straightened out until the true mediator was discovered. In 1912, a Polish biochemist named Casimir Funk proposed the existence of micronutrients that he called “vitamines” (the e was intentional).\nBy 1930 Albert Szent-Gyorgyi had isolated the particular nutrient that prevented scurvy. It was not any old acid but one acid in particular, now known as vitamin C or ascorbic acid (a nod to its “antiscorbutic” past). Szent- Gyorgyi received the Nobel Prize for his discovery in 1937. Thanks to Szent- Gyorgyi, we now know the actual causal path: Citrus Fruits Vitamin C Scurvy.\nI think that it is fair to predict that scientists will never “forget” this causal path again. And I think the reader will agree that mediation analysis is more than an abstract mathematical exercise.\nNATURE VERSUS NURTURE: THE TRAGEDY OF BARBARA BURKS To the best of my knowledge, the first person to explicitly represent a mediator with a diagram was a Stanford graduate student named Barbara Burks, in 1926. This very little-known pioneer in women’s science is one of the true heroes of this book. There is reason to believe that she actually invented path diagrams independently of Sewall Wright. And in regard to mediation, she was ahead of Wright and decades ahead of her time.\nBurks’s main research interest, throughout her unfortunately brief career, was the role of nature versus nurture in determining human intelligence. Her advisor at Stanford was Lewis Terman, a psychologist famous for developing the Stanford-Binet IQ test and a firm believer that intelligence was inherited, not acquired. Bear in mind that this was the heyday of the eugenics movement, now discredited but at that time legitimized by the active research of people like Francis Galton, Karl Pearson, and Terman.\nThe nature-versus-nurture debate is, of course, a very old one that continued long after Burks. Her unique contribution was to boil it down to a causal diagram (see Figure 9.2), which she used to ask (and answer) the query “How much of the causal effect is due to the direct path Parental Intelligence Child’s Intelligence (nature), and how much is due to the indirect path Parental Intelligence Social Status Child’s Intelligence (nurture)?” In this diagram, Burks has used some double-headed arrows, either to represent mutual causation or simply out of uncertainty about the direction of causation. For simplicity we are going to assume that the main effect of both arrows goes from left to right, which makes Social Status a mediator, so that the parents’ intelligence elevates their social standing, and this in turn gives the child a better opportunity to develop his or her intelligence. The variable X represents “other unmeasured remote causes.” F 9.2. The nature-versus-nurture debate, as framed by Barbara Burks.\nIGURE In her dissertation Burks collected data from extensive home visits to 204 families with foster children, who would presumably get only the benefits of nurture and none of the benefits of nature from their foster parents (see Figure 9.3). She gave IQ tests to all of them and to a control group of 105 families without foster children. In addition, she gave them questionnaires that she used to grade various aspects of the child’s social environment. Using her data and path analysis, she computed the direct effect of parental IQ on children’s IQ and found that only 35 percent, or about one-third, of IQ variation is inherited. In other words, parents with an IQ fifteen points above average would typically have children five points above average.\nF 9.3. Barbara Burks (right) was interested in separating the “nature” and IGURE “nurture” components of intelligence. As a graduate student, she visited the homes of more than two hundred foster children, gave them IQ tests, and collected data on their social environment. She was the first researcher other than Sewall Wright to use path diagrams, and in some ways she anticipated Wright. (Source: Drawing by Dakota Harr.) As a disciple of Terman, Burks must have been disappointed to see such a small effect. (In fact, her estimates have held up quite well over time.) So she questioned the then accepted method of analysis, which was to control for Social Status. “The true measure of contribution of a cause to an effect is mutilated,” she wrote, “if we have rendered constant variables which may in part or in whole be caused by either of the two factors whose true relationship is to be measured, or by still other unmeasured remote causes which also affect either of the two isolated factors” (emphasis in the original). In other words, if you are interested in the total effect of Parental Intelligence on Child’s Intelligence, you should not adjust for (render constant) any variable on the pathway between them.\nBut Burks didn’t stop there. Her italicized criterion, translated into modern language, reads that a bias will be introduced if we condition on variables that are (a) effects of either Parental Intelligence or Child’s Intelligence, or (b) effects of unmeasured causes of either Parental Intelligence or Child’s Intelligence (such as X in Figure 9.2).\nThese criteria were far ahead of their time and unlike anything that Sewall Wright had written. In fact, criterion (b) is one of the earliest examples ever of collider bias. If we look at Figure 9.2, we see that Social Status is a collider (Parental Intelligence Social Status X). Therefore, controlling for Social Status opens the back-door path Parental Intelligence Social Status X Child’s Intelligence. Any resulting estimate of the indirect and direct effects will be biased. Because statisticians before (and after) Burks did not think in terms of arrows and diagrams, they were totally immersed in the myth that, while simple correlation has no causal implications, controlled correlation (or partial regression coefficients, see p. 222) is a step in the direction of causal explanation.\nBurks was not the first person to discover the collider effect, but one can argue that she was the first to characterize it generally in graphical terms. Her criterion (b) applies perfectly to the examples of M-bias in Chapter 4. Hers is the first warning ever against conditioning on a pretreatment factor, a habit deemed safe by all twentieth-century statisticians and oddly still considered safe by some.\nNow put yourself in Barbara Burks’s shoes. You’ve just discovered that all your colleagues have been controlling for the wrong variables. You have two strikes against you: you’re only a student, and you’re a woman. What do you do? Do you put your head down, pretend to accept the conventional wisdom, and communicate with your colleagues in their inadequate vocabulary? Not Barbara Burks! She titled her first published paper “On the Inadequacy of the Partial and Multiple Correlation Technique” and started it out by saying, “Logical considerations lead to the conclusion that the techniques of partial and multiple correlation are fraught with dangers that seriously restrict their applicability.” Fighting words from someone who doesn’t have a PhD yet! As Terman wrote, “Her ability was somewhat tempered by her tendency to rub people the wrong way. I think the trouble lay partly in the fact that she was more aggressive in standing up for her own ideas than many teachers and male graduate students liked.” Evidently Burks was ahead of her time in more ways than one.\nBurks may actually have invented path diagrams independently of Sewall Wright, who preceded her by only six years. We can say for sure that she didn’t learn them in any class. Figure 9.2 is the first appearance of a path diagram outside Sewall Wright’s work and the first ever in the social or behavioral sciences. True, she credits Wright at the very end of her 1926 paper, but she does so in a manner that looks like a last-minute addition. I have a hunch that she found out about Wright’s diagrams only after she had drawn her own, possibly after being tipped off by Terman or an astute reviewer.\nIt is fascinating to wonder what Burks might have become, had she not been a victim of her times. After obtaining her doctorate she never managed to get a job as a professor at a university, for which she was certainly qualified. She had to make do with less secure research positions, for example at the Carnegie Institution. In 1942 she got engaged, which one might have expected to mark an upturn in her fortunes; instead, she went into a deep depression. “I am convinced that, whether right or not, she was sure some sinister change was going on in her brain, from which she could never recover,” her mother, Frances Burks, wrote to Terman. “So in tenderest love to us all she chose to spare us the grief of sharing with her the spectacle of such a tragic decline.” On May 25, 1943, at age forty, she jumped to her death from the George Washington Bridge in New York.\nBut ideas have a way of surviving tragedies. When sociologists Hubert Blalock and Otis Duncan resuscitated path analysis in the 1960s, Burks’s paper served as the source of their inspiration. Duncan explained that one of his mentors, William Fielding Ogburn, had briefly mentioned path coefficients in his 1946 lecture on partial correlations. “Ogburn had a report of a brief paper by Wright, the one that dealt with Burks’ material, and I acquired this reprint,” Duncan said.\nSo there we have it! Burks’s 1926 paper got Wright interested in the inappropriate use of partial correlations. Wright’s response found its way into Ogburn’s lecture twenty years later and implanted itself into Duncan’s mind.\nTwenty years after that, when Duncan read Blalock’s work on path diagrams, it called back this half-forgotten memory from his student years. It’s truly amazing to see how this fragile butterfly of an idea fluttered almost unnoticed through two generations before reemerging triumphantly into the light.\nIN SEARCH OF A LANGUAGE (THE BERKELEY ADMISSIONS PARADOX) Despite Burks’s early work, half a century later statisticians were struggling even to express the idea of, let alone estimate, direct and indirect effects. A case in point is a well-known paradox, related to Simpson’s paradox but with a twist.\nIn 1973 Eugene Hammel, an associate dean at the University of California, noticed a worrisome trend in the university’s admission rates for men and women. His data showed that 44 percent of the men who applied to graduate school at Berkeley had been accepted, compared to only 35 percent of the women. Gender discrimination was coming to wide public attention, and Hammel didn’t want to wait for someone else to start asking questions. He decided to investigate the reasons for the disparity.\nGraduate admissions decisions, at Berkeley as at other universities, are made by individual departments rather than by the university as a whole. So it made sense to look at the admissions data department by department to isolate the culprit. But when he did so, Hammel discovered an amazing fact.\nDepartment after department, the admissions decisions were consistently more favorable to women than to men. How could this be? At this point Hammel did something smart: he called a statistician. Peter Bickel, when asked to look at the data, immediately recognized a form of Simpson’s paradox. As we saw in Chapter 6, Simpson’s paradox refers to a trend that seems to go one direction in each layer of a population (women are accepted at a higher rate in each department) but in the opposite direction for the whole population (men are accepted at a higher rate in the university as a whole). We also saw in Chapter 6 that the correct resolution of the paradox depends very much on the question you want to answer. In this case the question is clear: Is the university (or someone within the university) discriminating against women? When I first told my wife about this example, her reaction was, “It’s impossible. If each department discriminates one way, the school cannot discriminate the other way.” And she’s right! The paradox offends our understanding of discrimination, which is a causal concept, involving preferential response to an applicant’s reported sex. If all actors prefer one sex over the other, the group as a whole must show that same preference. If the data seem to say otherwise, it must mean that we are not processing the data properly, in accordance with the logic of causation. Only with such logic, and with a clear causal story, can we determine the university’s innocence or guilt.\nIn fact, Bickel and Hammel found a causal story that completely satisfied them. They wrote an article, published in Science magazine in 1975, proposing a simple explanation: women were rejected in greater numbers because they applied to harder departments to get into.\nTo be specific, a higher proportion of females than males applied to departments in the humanities and social sciences. There they faced a double whammy: the number of students applying to get in was greater, and the number of places for those students was smaller. On the other hand, females did not apply as often to departments like mechanical engineering, which were easier to get into. These departments had more money and more spaces for graduate students—in short, a higher acceptance rate.\nWhy did women apply to departments that are harder to get into? Perhaps they were discouraged from applying to technical fields because they had more math requirements or were perceived as more “masculine.” Perhaps they had been discriminated against at earlier stages of their education: society tended to push women away from technical fields, as Barbara Burks’s story shows far too clearly. But these circumstances were not under Berkeley’s control and hence would not constitute discrimination by the university. Bickel and Hammel concluded, “The campus as a whole did not engage in discrimination against women applicants.” At least in passing, I would like to take note of the precision of Bickel’s language in this paper. He carefully distinguishes between two terms that, in common English, are often taken as synonyms: “bias” and “discrimination.” He defines bias as “a pattern of association between a particular decision and a particular sex of applicant.” Note the words “pattern” and “association.” They tell us that bias is a phenomenon on rung one of the Ladder of Causation. On the other hand, he defines discrimination as “the exercise of decision influenced by the sex of the applicant when that is immaterial to the qualifications for entry.” Words like “exercise of decision,” “influence,” and “immaterial” are redolent of causation, even if Bickel could not bring himself to utter that word in 1975. Discrimination, unlike bias, belongs on rung two or three of the Ladder of Causation.\nIn his analysis, Bickel felt that the data should be stratified by department because the departments were the decision-making units. Was this the right call? To answer that question, we start by drawing a causal diagram (Figure 9.4). It is also very illuminating to look at the definition of discrimination in US case law. It uses counterfactual terminology, a clear signal that we have climbed to level three of the Ladder of Causation. In Carson v. Bethlehem Steel Corp. (1996), the Seventh Circuit Court wrote, “The central question in any employment-discrimination case is whether the employer would have taken the same action had the employee been of a different race (age, sex, religion, national origin, etc.) and everything else had been the same.” This definition clearly expresses the idea that we should disable or “freeze” all causal pathways that lead from gender to admission through any other variable (e.g., qualification, choice of department, etc.). In other words, discrimination equals the direct effect of gender on the admission outcome.\nF 9.4. Causal diagram for Berkeley admission paradox—simple version.\nIGURE We have seen before that conditioning on a mediator is incorrect if we want to estimate the total effect of one variable on another. But in a case of discrimination, according to the court, it is not the total effect but the direct effect that matters. Thus Bickel and Hammel are vindicated: under the assumptions shown in Figure 9.4, they were right to partition the data by departments, and their result provides a valid estimate of the direct effect of Gender on Outcome. They succeeded even though the language of direct and indirect effects was not available to Bickel in 1973.\nHowever, the most interesting part of this story is not the original paper that Bickel and Hammel wrote but the discussion that followed it. After their paper was published, William Kruskal of the University of Chicago wrote a letter to Bickel arguing that their explanation did not really exonerate Berkeley. In fact, Kruskal queried whether any purely observational study (as opposed to a randomized experiment—say, using fake application forms) could ever do so.\nTo me their exchange of letters is fascinating. It is not very often that we can witness two great minds struggling with a concept (causation) for which they lacked an adequate vocabulary. Bickel would later go on to earn a MacArthur Foundation “genius” grant in 1984. But in 1975 he was at the beginning of his career, and it must have been both an honor and a challenge for him to match wits with Kruskal, a giant of the American statistics community.\nIn his letter to Bickel, Kruskal pointed out that the relation between Department and Outcome could have an unmeasured confounder, such as State of Residence. He worked out a numerical example for a hypothetical university with two sex-discriminating departments that produce exactly the same data as in Bickel’s example. He did this by assuming that both departments accept all in-state males and out-of-state females and reject all out-of-state males and in-state females and that this is their only decision criterion. Clearly this admissions policy is a blatant, textbook example of discrimination. But because the total numbers of applicants of each gender accepted and rejected were exactly the same as in Bickel’s example, Bickel would have to conclude that there was no discrimination. According to Kruskal, the departments appear innocent because Bickel has controlled for only one variable instead of two.\nKruskal put his finger exactly on the weak spot in Bickel’s paper: the lack of a clearly justified criterion for determining which variables to control for.\nKruskal did not offer a solution, and in fact his letter despairs of ever finding one.\nUnlike Kruskal, we can draw a diagram and see exactly what the problem is. Figure 9.5 shows the causal diagram representing Kruskal’s counterexample. Does it look slightly familiar? It should! It is exactly the same diagram that Barbara Burks drew in 1926, but with different variables.\nOne is tempted to say, “Great minds think alike,” but perhaps it would be more appropriate to say that great problems attract great minds.\nF 9.5. Causal diagram for Berkeley admissions paradox—Kruskal’s version.\nIGURE Kruskal argued that the analysis in this situation should control for both the department and the state of residence, and a look at Figure 9.5 explains why this is so. To disable all but the direct path, we need to stratify by department. This closes the indirect path Gender Department Outcome.\nBut in so doing, we open the spurious path Gender Department State of Residence Outcome, because of the collider at Department. If we control for State of Residence as well, we close this path, and therefore any correlation remaining must be due to the (discriminatory) direct path Gender Outcome. Lacking diagrams, Kruskal had to convince Bickel with numbers, and in fact his numbers showed the same thing. If we do not adjust for any variables, then females have a lower admission rate. If we adjust for Department, then females appear to have a higher admission rate. If we adjust for both Department and State of Residence, then once again the numbers show a lower admission rate for females.\nFrom arguments like this, you can see why the concept of mediation aroused (and still arouses) such suspicions. It seems unstable and hard to pin down. First the admission rates are biased against women, then against men, then against women. In his reply to Kruskal, Bickel continued to maintain that conditioning on a decision-making unit (Department) is somehow different from conditioning on a criterion for a decision (State of Residence). But he did not sound at all confident about it. He asks plaintively, “I see a nonstatistical question here: What do we mean by bias?” Why does the bias sign change depending on the way we measure it? In fact he had the right idea when he distinguished between bias and discrimination. Bias is a slippery statistical notion, which may disappear if you slice the data a different way.\nDiscrimination, as a causal concept, reflects reality and must remain stable.\nThe missing phrase in both their vocabularies was “hold constant.” To disable the indirect path from Gender to Outcome, we must hold constant the variable Department and then tweak the variable Gender. When we hold the department constant, we prevent (figuratively speaking) the applicants from choosing which department to apply to. Because statisticians do not have a word for this concept, they do something superficially similar: they condition on Department. That was exactly what Bickel had done: he looked at the data department-by-department and concluded that there was no evidence of discrimination against women. That procedure is valid when Department and Outcome are unconfounded; in that case, seeing is the same as doing. But Kruskal correctly asked, “What if there is a confounder, State of Residence?” He probably didn’t realize that he was following in the footsteps of Burks, who had drawn essentially the same diagram.\nI cannot stress enough how often this blunder has been repeated over the years—conditioning on the mediator instead of holding the mediator constant.\nFor that reason I call it the Mediation Fallacy. Admittedly, the blunder is harmless if there is no confounding of the mediator and the outcome.\nHowever, if there is confounding, it can completely reverse the analysis, as Kruskal’s numerical example showed. It can lead the investigator to conclude there is no discrimination when in fact there is.\nBurks and Kruskal were unusual in recognizing the Mediation Fallacy as a blunder, although they didn’t exactly offer a solution. R. A. Fisher fell victim to the same blunder in 1936, and eighty years later statisticians are still struggling with the problem. Fortunately there has been huge progress since the time of Fisher. Epidemiologists, for example, know now that one has to watch out for confounders between mediator and outcome. Yet those who eschew the language of diagrams (some economists still do) complain and confess that it is a torture to explain what this warning means.\nThankfully, the problem that Kruskal once called “perhaps insoluble” was solved two decades ago. I have this strange feeling that Kruskal would have enjoyed the solution, and in my fantasy I imagine showing him the power of the do-calculus and the algorithmization of counterfactuals. Unfortunately, he retired in 1990, just when the rules of do-calculus were being shaped, and he died in 2005.\nI’m sure that some readers are wondering: What finally happened in the Berkeley case? The answer is, nothing. Hammel and Bickel were convinced that Berkeley had nothing to worry about, and indeed no lawsuits or federal investigations ever materialized. The data hinted at reverse discrimination against males, and in fact there was explicit evidence of this: “In most of the cases involving favored status for women it appears that the admissions committees were seeking to overcome long-established shortages of women in their fields,” Bickel wrote. Just three years later, a lawsuit over affirmative action on another campus of the University of California went all the way to the Supreme Court. Had the Supreme Court struck down affirmative action, such “favored status for women” might have become illegal. However, the Supreme Court upheld affirmative action, and the Berkeley case became a historical footnote.\nA wise man leaves the final word not with the Supreme Court but with his wife. Why did mine have such a strong intuitive conviction that it is utterly impossible for a school to discriminate while each of its departments acts fairly? It is a theorem of causal calculus similar to the sure-thing principle.\nThe sure-thing principle, as Jimmie Savage originally stated it, pertains to total effects, while this theorem holds for direct effects. The very definition of a direct effect on a global level relies on aggregating direct effects in the subpopulations.\nTo put it succinctly, local fairness everywhere implies global fairness. My wife was right.\nDAISY, THE KITTENS AND INDIRECT EFFECTS So far we have discussed the concepts of direct and indirect effects in a vague and intuitive way, but I have not given them a precise scientific meaning. It is long past time for us to rectify this omission.\nLet’s start with the direct effect, because it is undoubtedly easier, and we can define a version of it using the do-calculus (i.e., at rung two of the Ladder of Causation). We’ll consider first the simplest case, which includes three variables: a treatment X, an outcome Y, and a mediator M. We get the direct effect of X on Y when we “wiggle” X without allowing M to change. In the context of the Berkeley admissions paradox example, we force everybody to apply to the history department—that is, we do(M = 0). We randomly assign some people to report their sex (on the application) as male (do(X = 1)) and some to report it as female (do(X = 0)), regardless of their actual genders.\nThen we observe the difference in admission rates between the two reporting groups. The result is called the controlled direct effect, or CDE(0). In symbols, CDE(0) = P(Y = 1 | do(X = 1), do(M = 0)) – P(Y = 1 | do(X = 0), do(M = 0)) (9.1) The “0” in CDE(0) indicates that we forced the mediator to take on the value zero. We could also do the same experiment, forcing everybody to apply to engineering: do(M = 1). We would denote the resulting controlled direct effect as CDE(1).\nAlready we see one difference between direct effects and total effects: we have two different versions of the controlled direct effect, CDE(0) and CDE(1). Which one is right? One option is simply to report both versions.\nIndeed, it is not unthinkable that one department will discriminate against females and the other against males, and it would be interesting to find out who does what. That was, after all, Hammel’s original intention.\nHowever, I would not recommend running this experiment, and here is why. Imagine an applicant named Joe whose lifetime dream is to study engineering and who happened to be (randomly) assigned to apply to the history department. Having sat on a few admissions committees, I can categorically vow that Joe’s application would look awfully strange to the committee. His A+ in electromagnetic waves and B–in European nationalism would totally distort the committee’s decision, regardless of whether he marked “male” or “female” on his application. The proportion of males and females admitted under these distortions would hardly reflect the admissions policy compared to applicants who normally apply to the history department.\nLuckily, an alternative avoids the pitfalls of this overcontrolled experiment. We instruct the applicants to report a randomized gender but to apply to the department they would have preferred. We call this the natural direct effect (NDE), because every applicant ends up in a department of his or her choice. The “would have” phrasing is a clue that NDE’s formal definition requires counterfactuals. For readers who enjoy mathematics, here is the definition expressed as a formula: NDE = P(Y = 1 | do(X = 1)) – P(Y = 1 | do(X = 0)) (9.2) M = M0 M = M0 The interesting term is the first, which stands for the probability that a female student selecting a department of her choice (M = M ) would be admitted if 0 she faked her sex to read “male” (do(X = 1)). Here the choice of department is governed by the actual sex while admission is decided by the reported (fake) sex. Since the former cannot be mandated, we cannot translate this term to one involving do-operators; we need to invoke the counterfactual subscript.\nNow you know how we define the controlled direct effect and the natural direct effect, but how do we compute them? The task is simple for the controlled direct effect; because it can be expressed as a do-expression, we need only use the laws of do-calculus to reduce the do-expressions to see- expressions (i.e., conditional probabilities, which can be estimated from observational data).\nThe natural direct effect poses a greater challenge, though, because it cannot be defined in a do-expression. It requires the language of counterfactuals, and hence it cannot be estimated using the do-calculus. It was one of the greatest thrills in my life when I managed to strip the formula for the NDE from all of its counterfactual subscripts. The result, called the Mediation Formula, makes the NDE a truly practical tool because we can estimate it from observational data.\nIndirect effects, unlike direct effects, have no “controlled” version because there is no way to disable the direct path by holding some variable constant.\nBut they do have a “natural” version, the natural indirect effect (NIE), which is defined (like NDE) using counterfactuals. To motivate the definition, I will consider a somewhat playful example that my coauthor suggested.\nMy coauthor and his wife adopted a dog named Daisy, a rambunctious poodle-and-Chihuahua mix with a mind of her own. Daisy was not as easy to house-train as their previous dog, and after several weeks she was still having occasional “accidents” inside the house. But then something very odd happened. Dana and his wife brought home three foster kittens from the animal shelter, and the “accidents” stopped. The foster kittens remained with them for three weeks, and Daisy did not break her training a single time during that period.\nWas it just coincidence, or had the kittens somehow inspired Daisy to civilized behavior? Dana’s wife suggested that the kittens might have given Daisy a sense of belonging to a “pack,” and she would not want to mess up the area where the pack lived. This theory was reinforced when, a few days after the kittens went back to the shelter, Daisy started urinating in the house again, as if she had never heard of good manners.\nBut then it occurred to Dana that something else had changed when the kittens arrived and departed. While the kittens had been there, Daisy had to be either separated from them or carefully supervised. So she spent long periods in her crate or being closely watched by a human, even leashed to a human.\nBoth interventions, crating and leashing, also happen to be recognized methods for housebreaking.\nWhen the kittens left, the Mackenzies stopped the intensive supervision, and the uncouth behavior returned. Dana hypothesized that the effect of the kittens was not direct (as in the pack theory) but indirect, mediated by crating and supervision. Figure 9.6 shows a causal graph. At this point, Dana and his wife tried an experiment. They treated Daisy as they would have with kittens around, keeping her in a crate and supervising her carefully outside the crate.\nIf the accidents stopped, they could reasonably conclude that the mediator was responsible. If they didn’t stop, then the direct effect (the pack psychology) would become more plausible.\nF 9.6. Causal diagram for Daisy’s house training.\nIGURE In the hierarchy of scientific evidence, their experiment would be considered very shaky—certainly not one that could ever be published in a scientific journal. A real experiment would have to be carried out on more than just one dog and in both the presence and absence of the kittens.\nNevertheless, it is the causal logic behind the experiment that concerns us here. We are intending to recreate what would have happened had the kittens not been present and had the mediator been set to the value it would take with the kittens present. In other words, we remove the kittens (intervention number one) and supervise the dog as we would if the kittens were present (intervention number two).\nWhen you look carefully at the above paragraph, you might notice two “would haves,” which are counterfactual conditions. The kittens were present when the dog changed her behavior—but we ask what would have happened if they had not been present. Likewise, if the kittens had not been present, Dana would not have supervised Daisy—but we ask what would have happened if he had.\nYou can see why statisticians struggled for so long to define indirect effects. If even a single counterfactual was outlandish, then double-nested counterfactuals were completely beyond the pale. Nevertheless, this definition conforms closely with our natural intuition about causation. Our intuition is so compelling that Dana’s wife, with no special training, readily understood the logic of the proposed experiment.\nFor readers who are comfortable with formulas, here is how to define the NIE that we have just described in words: NIE = P(Y = 1 | do(X = 0))–P(Y = 1 | do(X = 0)) (9.3) M = M1 M = M0 The first P term is the outcome of the Daisy experiment: the probability of successful house training (Y = 1), given that we do not introduce other pets (X = 0) but set the mediator to the value it would have if we had introduced them (M = M ). We contrast this with the probability of successful house training 1 under “normal” conditions, with no other pets. Note that the counterfactual, M , has to be computed for each animal on a case-by-case basis: different 1 dogs might have different needs for Crating/Supervision. This puts the indirect effect out of reach of the do-calculus. It may also render the experiment unfeasible, because the experimenter may not know M (u) for a 1 particular dog u. Nevertheless, assuming there is no confounding between M and Y, the natural indirect effect can still be computed. It is possible to remove all the counterfactuals from the NIE and arrive at a Mediation Formula for it, like the one for the NDE. This quantity, which requires information from the third rung of the Ladder of Causation, can nevertheless be reduced to an expression that can be computed with rung-one data. Such a reduction is only possible because we have made an assumption of no confounding, which, owing to the deterministic nature of the equations in a structural causal model, is on rung three.\nTo finish Daisy’s story, the experiment was inconclusive. It’s questionable whether Dana and his wife monitored Daisy as carefully as they would have if they had been keeping her away from kittens. (So it’s not clear that M was truly set to M .) With patience and time—it took several months—Daisy 1 eventually learned to “do her business” outside. Even so, Daisy’s story holds some useful lessons. Simply by being attuned to the possibility of a mediator, Dana was able to conjecture another causal mechanism. That mechanism had an important practical consequence: he and his wife did not have to keep the house filled with a foster kitten “pack” for the rest of Daisy’s life.\nMEDIATION IN LINEAR WONDERLAND When you first hear about counterfactuals, you might wonder if such an elaborate machinery is really needed to express an indirect effect. Surely, you might argue, an indirect effect is simply what is left over after you take away the direct effect. Alternatively, we could write, Total Effect = Direct Effect + Indirect Effect (9.4) The short answer is that this does not work in models that involve interactions (sometimes called moderation). For example, imagine a drug that causes the body to secrete an enzyme that acts as a catalyst: it combines with the drug to cure a disease. The total effect of the drug is, of course, positive.\nBut the direct effect is zero, because if we disable the mediator (for example, by preventing the body from stimulating the enzyme), the drug will not work.\nThe indirect effect is also zero, because if we don’t receive the drug and do artificially get the enzyme, then the disease will not be cured. The enzyme itself has no curing power. Thus Equation 9.4 does not hold: the total effect is positive but the direct and indirect effects are zero.\nHowever, Equation 9.4 does hold automatically in one situation, with no apparent need to invoke counterfactuals. That is the case of a linear causal model, of the sort that we saw in Chapter 8. As discussed there, linear models do not allow interactions, which can be both a virtue and a drawback. It is a virtue in the sense that it makes mediation analysis much easier, but it is a drawback if we want to describe a real-world causal process that does involve interactions.\nBecause mediation analysis is so much easier for linear models, let’s see how it is done and what the pitfalls are. Suppose we have a causal diagram that looks like Figure 9.7. Because we are working with a linear model, we can represent the strength of each effect with a single number. The labels (path coefficients) indicate that increasing the Treatment variable by one unit will increase the Mediator variable by two units. Similarly, a one-unit increase in Mediator will increase Outcome by three units, and a one-unit increase in Treatment will increase Outcome by seven units. These are all direct effects.\nHere we come to the first reason why linear models are so simple: direct effects do not depend on the level of the mediator. That is, the controlled direct effect CDE(m) is the same for all values m, and we can simply speak of “the” direct effect.\nWhat would be the total effect of an intervention that causes Treatment to increase by one unit? First, this intervention directly causes Outcome to increase by seven units (if we hold Mediator constant). It also causes Mediator to increase by two units. Finally, because each one-unit increase in Mediator directly causes a three-unit increase in Outcome, a two-unit increase in Mediator will lead to an additional six-unit increase in Outcome. So the net increase in Outcome, from both causal pathways, will be thirteen units. The first seven units correspond to the direct effect, and the remaining six units correspond to the indirect effect. Easy as pie! F 9.7. Example of a linear model (path diagram) with mediation.\nIGURE In general, if there is more than one indirect pathway from X to Y, we evaluate the indirect effect along each pathway by taking the product of all the path coefficients along that pathway. Then we get the total indirect effect by adding up all the indirect causal pathways. Finally, the total effect of X on Y is the sum of the direct and indirect effects. This “sum of products” rule has been used since Sewall Wright invented path analysis, and, formally speaking, it indeed follows from the do-operator definition of total effect.\nIn 1986, Reuben Baron and David Kenny articulated a set of principles for detecting and evaluating mediation in a system of equations. The essential principles are, first, that the variables are all related by linear equations, which are estimated by fitting them to the data. Second, direct and indirect effects are computed by fitting two equations to the data: one with the mediator included and one with the mediator excluded. Significant change in the coefficients when the mediator is introduced is taken as evidence of mediation.\nThe simplicity and plausibility of the Baron-Kenny method took the social sciences by storm. As of 2014, their article ranks thirty-third on the list of most frequently cited scientific papers of all time. As of 2017, Google Scholar reports that 73,000 scholarly articles have cited Baron and Kenny. Just think about that! They’ve been cited more times than Albert Einstein, more than Sigmund Freud, more than almost any other famous scientist you can think of. Their article ranks second among all papers in psychology and psychiatry, and yet it’s not about psychology at all. It’s about noncausal mediation.\nThe unprecedented popularity of the Baron-Kenny approach undoubtedly stems from two factors. First, mediation is in high demand. Our desire to understand “how nature works” (i.e., to find the M in X M Y) is perhaps even stronger than our desire to quantify it. Second, the method reduces easily to a cookbook procedure that is based on familiar concepts from statistics, a discipline that has long claimed to have exclusive ownership of objectivity and empirical validity. So hardly anyone noticed the grand leap forward involved, the fact that a causal quantity (mediation) was defined and assessed by purely statistical means.\nHowever, cracks in this regression-based edifice began to appear in the early 2000s, when practitioners tried to generalize the sum-of-products rule to nonlinear systems. That rule involves two assumptions—effects along distinct paths are additive, and path coefficients along one path multiply—and both of them lead to wrong answers in nonlinear models, as we will see below.\nIt has taken a long time, but the practitioners of mediation analysis have finally woken up. In 2001, my late friend and colleague Rod McDonald wrote, “I think the best way to discuss the question of detecting or showing moderation or mediation in a regression is to set aside the entire literature on these topics and start from scratch.” The latest literature on mediation seems to heed McDonald’s advice; counterfactual and graphical methods are pursued much more actively than the regression approach. And in 2014, the father of the Baron-Kenny approach, David Kenny, posted a new section on his website called “causal mediation analysis.” Though I would not call him a convert yet, Kenny clearly recognizes that times are changing and that mediation analysis is entering a new era.\nFor now, let’s look at one very simple example of how our expectations go wrong when we leave Linear Wonderland. Consider Figure 9.8, a slight modification of Figure 9.7, where a job applicant will decide to take a job if and only if the salary offered exceeds a certain threshold value, in our case ten. The salary offer is determined, as shown in the diagram, by 7 × Education + 3 × Skill. Note that the functions determining Skill and Salary are still assumed to be linear, but the relationship of Salary to Outcome is nonlinear, because it has a threshold effect.\nLet us compute, for this model, the total, direct, and indirect effects associated with increasing Education by one unit. The total effect is clearly equal to one, because as Education shifts from zero to one, Salary goes from zero to (7 × 1) + (3 × 2) = 13, which is above the threshold of ten, making Outcome switch from zero to one.\nRemember that the natural indirect effect is the expected change in the outcome, given that we make no change to Education but set Skill at the level it would take if we had increased Education by one. It’s easy to see that in this case, Salary goes from zero to 2 × 3 = 6. This is below the threshold of ten, so the applicant will turn the offer down. Thus NIE = 0.\nF 9.8. Mediation combined with a threshold effect.\nIGURE Now what about the direct effect? As mentioned before, we have the problem of figuring out what value to hold the mediator at. If we hold Skill at the level it had before we changed Education, then Salary will increase from zero to seven, making Outcome = 0. Thus, CDE(0) = 0. On the other hand, if we hold Skill at the level it attains after the change in Education (namely two), Salary will increase from six to thirteen. This changes the Outcome from zero to one, because thirteen is above the applicant’s threshold for accepting the job offer. So CDE(2) = 1.\nThus, the direct effect is either zero or one depending on the constant value we choose for the mediator. Unlike in Linear Wonderland, the choice of a value for the mediator makes a difference, and we have a dilemma. If we want to preserve the additive principle, Total Effect = Direct Effect + Indirect Effect, we need to use CDE(2) as our definition of the causal effect. But this seems arbitrary and even somewhat unnatural. If we are contemplating a change in Education and we want to know its direct effect, we would most likely want to keep Skill at the level it already has. In other words, it makes more intuitive sense to use CDE(0) as our direct effect. Not only that, this agrees with the natural direct effect in this example. But then we lose additivity: Total Effect ≠ Direct Effect + Indirect Effect.\nHowever—quite surprisingly—a somewhat modified version of additivity does hold true, not only in this example but in general. Readers who don’t mind doing a little computation might be interested in computing the NIE of going back from X = 1 to X = 0. In this case the salary offer drops from thirteen to seven, and the Outcome drops from one to zero (i.e., the applicant does not accept the offer). So computed in the reverse direction, NIE = –1.\nThe cool and amazing fact is that Total Effect (X = 0 X = 1) = NDE (X = 0 X = 1) – NIE (X = 1 X = 0) or in this case, 1 = 0–(–1). This is the “natural effects” version of the additivity principle, only it is a subtractivity principle! I was extremely happy to see this version of additivity emerging from the analysis, despite the nonlinearity of the equations.\nA staggering amount of ink has been spilled on the “right” way to generalize direct and indirect effects from linear to nonlinear models.\nUnfortunately, most of the articles go at the problem backward. Instead of rethinking from scratch what we mean by direct and indirect effects, they start from the supposition that we only have to tweak the linear definitions a little bit. For example, in Linear Wonderland we saw that the indirect effect is given by a product of two path coefficients. So some researchers tried to define the indirect effect in the form of a product of two quantities, one measuring the effect of X on M, the other the effect of M on Y. This came to be known as the “product of coefficients” method. But we also saw that in Linear Wonderland the indirect effect is given by the difference between the total effect and the direct effect. So another, equally dedicated group of researchers defined the indirect effect as a difference of two quantities, one measuring the total effect, the other the direct effect. This came to be known as the “difference in coefficients” method.\nWhich of these is right? Neither! Both groups of researchers confused the procedure with the meaning. The procedure is mathematical; the meaning is causal. In fact, the problem goes even deeper: the indirect effect never had a meaning for regression analysts outside the bubble of linear models. The indirect effect’s only meaning was as the outcome of an algebraic procedure (“multiply the path coefficients”). Once that procedure was taken away from them, they were cast adrift, like a boat without an anchor.\nOne reader of my book Causality described this lost feeling beautifully in a letter to me. Melanie Wall, now at Columbia University, used to teach a modeling course to biostatistics and public health students. One time, she explained to her students as usual how to compute the indirect effect by taking the product of direct path coefficients. A student asked her what the indirect effect meant. “I gave the answer that I always give, that the indirect effect is the effect that a change in X has on Y through its relationship with the mediator, Z,” Wall told me.\nBut the student was persistent. He remembered how the teacher had explained the direct effect as the effect remaining after holding the mediator fixed, and he asked, “Then what is being held constant when we interpret an indirect effect?” Wall didn’t know what to say. “I’m not sure I have a good answer for you,” she said. “How about I get back to you?” This was in October 2001, just four months after I had presented a paper on causal mediation at the Uncertainty in Artificial Intelligence conference in Seattle. Needless to say, I was eager to impress Melanie with my newly acquired solution to her puzzle, and I wrote to her the same answer I have given you here: “The indirect effect of X on Y is the increase we would see in Y while holding X constant and increasing M to whatever value M would attain under a unit increase in X.” I am not sure if Melanie was impressed with my answer, but her inquisitive student got me thinking, quite seriously, about how science progresses in our times. Here we are, I thought, forty years after Blalock and Duncan introduced path analysis to social science. Dozens of textbooks and hundreds of research papers are published every year on direct and indirect effects, some with oxymoronic titles like “Regression-Based Approach to Mediation.” Each generation passes along to the next the received wisdom that the indirect effect is just the product of two other effects, or the difference between the total and direct effects. Nobody dares to ask the simple question “But what does the indirect effect mean in the first place?” Just like the boy in Hans Christian Andersen’s fable “The Emperor’s New Clothes,” we needed an innocent student with unabashed chutzpah to shatter our faith in the oracular role of scientific consensus.\nEMBRACE THE “WOULD-HAVES” At this point I should tell my own conversion story, because for quite a while I was stymied by the same question that puzzled Melanie Wall’s student.\nI wrote in Chapter 4 about Jamie Robins (Figure 9.9), a pioneering statistician and epidemiologist at Harvard University who, together with Sander Greenland at the University of California, Los Angeles, is largely responsible for the widespread adoption of graphical models in epidemiology today. We collaborated for a couple of years, from 1993 to 1995, and he got me thinking about the problem of sequential intervention plans, which was one of his principal research interests.\nF 9.9. Jamie Robins, a pioneer of causal inference in epidemiology. (Source: IGURE Photograph by Kris Snibbe, courtesy of Harvard University Photo Services.) Years earlier, as an expert in occupational health and safety, Robins had been asked to testify in court about the likelihood that chemical exposure in the workplace had caused a worker’s death. He was dismayed to discover that statisticians and epidemiologists had no tools to answer such questions. This was still the era when causal language was taboo in statistics. It was only allowed in the case of a randomized controlled trial, and for ethical reasons one could never conduct such a trial on the effects of exposure to formaldehyde.\nUsually a factory worker is exposed to a harmful chemical not just once but over a long period. For that reason, Robins became keenly interested in exposures or treatments that vary over time. Such exposures can also be beneficial: for example, AIDS treatment is given over the course of many years, with different plans of action depending on how a patient’s CD4 count responds. How can you sort out the causal effect of treatment when it may occur in many stages and the intermediate variables (which you might want to use as controls) depend on earlier stages of treatment? This has been one of the defining questions of Robins’s career.\nAfter Jamie flew out to California to meet me on hearing about the “napkin problem” (Chapter 7), he was keenly interested in applying graphical methods to the sequential treatment plans that were his métier. Together we came up with a sequential back-door criterion for estimating the causal effect of such a treatment stream. I learned some important lessons from this collaboration. In particular, he showed me that two actions are sometimes easier to analyze than one because an action corresponds to erasing arrows on a graph, which makes it sparser.\nOur back-door criterion dealt with a long-term treatment consisting of some arbitrarily large number of do-operations. But even two operations will produce some interesting mathematics—including the controlled direct effect, which consists of one action that “wiggles” the value of the treatment, while another action fixes the value of the mediator. More importantly, the idea of defining direct effects in terms of do-operations liberated them from the confines of linear models and grounded them in causal calculus.\nBut I didn’t really get interested in mediation until later, when I saw that people were still making elementary mistakes, such as the Mediation Fallacy mentioned earlier. I was also frustrated that the action-based definition of the direct effect did not extend to the indirect effect. As Melanie Wall’s student said, we have no variable or set of variables to intervene on to disable the direct path and let the indirect path stay active. For this reason the indirect effect seemed to me like a figment of the imagination, devoid of independent meaning except to remind us that the total effect may differ from the direct effect. I even said so in the first edition (2000) of my book Causality. This was one of the three greatest blunders of my career.\nIn retrospect, I was blinded by the success of the do-calculus, which had led me to believe that the only way to disable a causal path was to take a variable and set it to one particular value. This is not so; if I have a causal model, I can manipulate it in many creative ways, by dictating who listens to whom, when, and how. In particular, I can fix the primary variable for the purpose of suppressing its direct effect and, hypothetically yet simultaneously, energize the primary variable for the purpose of transmitting its effect through the mediator. That allows me to set the treatment variable (e.g., kittens) at zero and to set the mediator at the value it would have had if I had set kittens to one. My model of the data-generating process then tells me how to compute the effect of the split intervention.\nI am indebted to one reader of the first edition, Jacques Hagenaars (author of Categorical Longitudinal Data), for urging me not to give up on the indirect effect. “Many experts in social science agree on the input and output, but differ exactly with respect to the mechanism,” he wrote to me. But I was stuck for almost two years on the dilemma I wrote about in the last section: How can I disable the direct effect? All these struggles came to sudden resolution, almost like a divine revelation, when I read the legal definition of discrimination that I quoted earlier in this chapter: “had the employee been of a different race… and everything else had been the same.” Here we have it—the crux of the issue! It’s a make-believe game. We deal with each individual on his or her own merits, and we keep all characteristics of the individual constant at whatever level they had prior to the change in the treatment variable.\nHow does this solve our dilemma? It means, first of all, that we have to redefine both the direct effect and the indirect effect. For the direct effect, we let the mediator choose the value it would have—for each individual—in the absence of treatment, and we fix it there. Now we wiggle the treatment and register the difference. This is different from the controlled direct effect I discussed earlier, where the mediator is fixed at one value for everyone.\nBecause we let the mediator choose its “natural” value, I called it the natural direct effect. Similarly, for the natural indirect effect I first deny treatment to everyone, and then I let the mediator choose the value it would have, for each individual, in the presence of treatment. Finally I record the difference.\nI don’t know if the legal words in the definition of discrimination would have moved you, or anyone else, in the same way. But by 2000 I could already speak counterfactuals like a native. Having learned how to read them in causal models, I realized that they were nothing but quantities computed by innocent operations on equations or diagrams. As such, they stood ready to be encapsulated in a mathematical formula. All I had to do was embrace the “would-haves.” In a second, I realized that every direct and indirect effect could be translated into a counterfactual expression. Once I saw how to do that, it was a snap to derive a formula that tells you how to estimate the natural direct and indirect effects from data and when it is permissible. Importantly, the formula makes no assumptions about the specific functional form of the relationship between X, M, and Y. We have escaped from Linear Wonderland.\nI called the new rule the Mediation Formula, though there are actually two formulas, one for the natural direct effect and one for the natural indirect effect. Subject to transparent assumptions, explicitly displayed in the graph, it tells you how they can be estimated from data. For example, in a situation like Figure 9.4, where there is no confounding between any of the variables, and M is the mediator between treatment X and outcome Y: NIE = Σ [P(M = m | X = 1)–P(M = m | X = 0)] × × P(Y = 1 | X = 0, M = m m) (9.5) The interpretation of this formula is illuminating. The expression in brackets stands for the effect of X on M, and the following expression stands for the effect of M on Y (when X = 0). So it reveals the origin of the product-of- coefficients idea, cast as a product of two nonlinear effects. Note also that unlike Equation 9.3, Equation 9.5 has no subscripts and no do-operators, so it can be estimated from rung-one data.\nWhether you are a scientist in a laboratory or a child riding a bicycle, it is always a thrill to find you can do something today that you could not do yesterday. And that is how I felt when the Mediation Formula first appeared on paper. I could see at a glance everything about direct and indirect effects: what is needed to make them large or small, when we can estimate them from observational or interventional data, and when we can deem a mediator “responsible” for transmitting observed changes to the outcome variable. The relationship between cause and effect can be linear or nonlinear, numerical or logical. Previously each of these cases had to be handled in a different way, if they were discussed at all. Now a single formula would apply to all of them.\nGiven the right data and the right model, we could determine if an employer was guilty of discrimination or what kinds of confounders would prevent us from making that determination. From Barbara Burks’s data, we could estimate how much of the child’s IQ comes from nature and how much from nurture. We could even calculate the percentage of the total effect explained by mediation and the percentage owed to mediation—two complementary concepts that collapse to one in linear models.\nAfter I wrote down the counterfactual definition of the direct and indirect effects, I learned that I was not the first to hit on the idea. Robins and Greenland got there before me, all the way back in 1992. But their paper describes the concept of the natural effect in words, without committing it to a mathematical formula.\nMore seriously, they took a pessimistic view of the whole idea of natural effects and stated that such effects cannot be estimated from experimental studies and certainly not from observational studies. This statement prevented other researchers from seeing the potential of natural effects. It is hard to tell if Robins and Greenland would have switched to a more optimistic view had they taken the extra step of expressing the natural effect as a formula in counterfactual language. For me, this extra step was crucial.\nThere is possibly another reason for their pessimistic view, which I do not agree with but will try to explain. They examined the counterfactual definition of the natural effect and saw that it combines information from two different worlds, one in which you hold the treatment constant at zero and another in which you change the mediator to what it would have been if you had set the treatment to one. Because you cannot replicate this “cross-worlds” condition in any experiment, they believed it was out of bounds.\nThis is a philosophical difference between their school and mine. They believe that the legitimacy of causal inference lies in replicating a randomized experiment as closely as possible, on the assumption that this is the only route to the scientific truth. I believe that there may be other routes, which derive their legitimacy from a combination of data and established (or assumed) scientific knowledge. To that end, there may be methods more powerful than a randomized experiment, based on rung-three assumptions, and I do not hesitate to use them. Where they gave researchers a red light, I gave them a green light, which was the Mediation Formula: if you feel comfortable with these assumptions, here is what you can do! Unfortunately, Robins and Greenland’s red light kept the field of mediation at a standstill for nine full years.\nMany people find formulas daunting, seeing them as a way of concealing rather than revealing information. But to a mathematician, or to a person who is adequately trained in the mathematical way of thinking, exactly the reverse is true. A formula reveals everything: it leaves nothing to doubt or ambiguity.\nWhen reading a scientific article, I often catch myself jumping from formula to formula, skipping the words altogether. To me, a formula is a baked idea.\nWords are ideas in the oven.\nA formula serves two purposes, one practical and one social. From the practical point of view, students or colleagues can read it as they would a recipe. The recipe may be simple or complex, but at the end of the day it promises that if you follow the steps, you will know the natural direct and indirect effects—provided, of course, your causal model accurately reflects the real world.\nThe second purpose is subtler. I had a friend in Israel who was a famous artist. I visited his studio to acquire one of his paintings, and his canvases were all over the place—a hundred under the bed, dozens in the kitchen. They were priced at between $300 and $500 each, and I had a hard time deciding.\nFinally, I pointed to one on the wall and said, “I like this one.” “This one is $5,000,” he said. “How come?” I asked, partly surprised and partly protesting.\nHe answered, “This one is framed.” It took me a few minutes to figure out, but then I understood what he meant. It wasn’t valuable because it was framed; it was framed because it was valuable. Out of all the hundreds of paintings in his apartment, that one was his personal choice. It best expressed what he had labored to express in the others, and it was thus anointed with a seal of completeness—a frame.\nThat is the second purpose of a formula. It is a social contract. It puts a frame around an idea and says, “This is something I believe is important. This is something that deserves sharing.” That is why I have chosen to put a frame around the Mediation Formula. It deserves sharing because, to me and many like me, it represents the end to an age-old dilemma. And it is important, because it offers a practical tool for identifying mechanisms and assessing their importance. This is the social promise that the Mediation Formula expresses.\nSince then, once the realization took hold that nonlinear mediation analysis is possible, research in the field has taken off. If you go to a database of academic articles and search for titles with the words “mediation analysis,” you will find almost nothing before 2004. Then there were seven papers a year, then ten, then twenty; now there are more than a hundred papers a year.\nI’d like to end this chapter with three examples, which I hope will illustrate the variety of possibilities of mediation analysis.\nCASE STUDIES OF MEDIATION “Algebra for All”: A Program and Its Side Effects Like many big-city public school systems, the Chicago Public Schools face problems that sometimes seem intractable: high poverty rates, low budgets, and big achievement gaps between black, Latino, white, and Asian students.\nIn 1988, then US secretary of education William Bennett called Chicago’s public schools the worst in the nation.\nBut in the 1990s, under new leadership, the Chicago Public Schools undertook a number of reforms and moved from “worst in the nation” to “innovator for the nation.” Some of the superintendents responsible for these changes gained nationwide prominence, such as Arne Duncan, who became secretary of education under President Barack Obama.\nOne innovation that actually predated Duncan was a policy, adopted in 1997, eliminating remedial courses in high school and requiring all ninth graders to take college-prep courses like English I and Algebra I. The math part of this policy was called “Algebra for All.” Was “Algebra for All” a success? That question, it turned out, was surprisingly difficult to answer. There was both good news and bad news. The good news was that test scores did improve. Math scores rose by 7.8 points over three years, a statistically significant change that is equivalent to about 75 percent of students scoring above the mean that existed before the policy change.\nBut before we can talk about causality, we have to rule out confounders, and in this case there is an important one. By 1997, the qualifications of incoming ninth-grade students were already improving thanks to earlier changes in the K–8 curriculum. So we are not comparing apples to apples.\nBecause these children began ninth grade with better math skills than students had in 1994, the higher scores could be due to the already instituted K–8 changes, not to “Algebra for All.” Guanglei Hong, a professor of human development at the University of Chicago, studied the data and found no significant improvement in test scores once this confounder was taken into account. At this point it would have been easy for Hong to jump to the conclusion that “Algebra for All” was not a success. But she didn’t, because there was another factor—this time a mediator, not a confounder—to take into account.\nAs any good teacher knows, students’ success depends not only on what you teach them but on how you teach them. When the “Algebra for All” policy was introduced, more than the curriculum changed. The lower- achieving students found themselves in classrooms with higher-achieving students and could not keep up. This led to all sorts of negative consequences: discouragement, class cutting, and, of course, lower test scores. Also, in a mixed-ability classroom, the low-achieving students may have received less attention from their teachers than they would have in a remedial class. Finally, the teachers themselves may have struggled with the new demands placed on them. The teachers experienced in teaching Algebra I probably were not experienced in teaching low-ability students, and the teachers experienced with low-ability students may not have been as qualified to teach algebra. All of these were unanticipated side effects of “Algebra for All.” Mediation analysis is ideally suited for evaluating the influence of side effects.\nHong hypothesized, therefore, that classroom environment had changed and had strongly affected the outcome of the intervention. In other words, she postulated the causal diagram shown in Figure 9.10. Environment (which Hong measured by the median skill level of all the students in the classroom) functions as a mediator between the “Algebra for All” intervention and the students’ learning outcomes. The question, as usual in mediation analysis, is how much of the effect of the policy was direct and how much was indirect.\nInterestingly, the two effects worked in opposing directions. Hong found that the direct effect was positive: the new policy directly led to a roughly 2.7- point increase in test scores. This was at least a change in the right direction, and it was statistically significant (meaning that such an improvement would be unlikely to happen by chance). However, because of the changes in classroom environment, the indirect effect had almost completely cancelled out this improvement, reducing test scores by 2.3 points.\nF 9.10. Causal diagram for “Algebra for All” experiment.\nIGURE Hong concluded that the implementation of “Algebra for All” had seriously undermined the policy. Maintaining the curricular change but returning to the prepolicy classroom environment should result in a modest increase in student test scores (and hopefully, student learning).\nSerendipitously, that is exactly what happened. In 2003 the Chicago Public Schools (now led by Duncan) instituted a new reform called “Double-Dose Algebra.” This reform would still require all students to take algebra, but students who scored below the national median in eighth grade would take two classes of algebra a day instead of one. This repaired the adverse side effect of the previous reform. Now, at least once a day, lower-achieving students got a classroom environment closer to the one they enjoyed before the “Algebra for All” reform. The “Double-Dose Algebra” reform was generally deemed a success and continues to this day.\nI consider the story of “Algebra for All” a success for mediation analysis as well, because the analysis explains both the unimpressive results of the original policy and the improved results under the modified policy. Even though causal inference came along too late to affect the policy in real time, it does answer our “Why?” questions after the fact: Why did the original reform have little effect? Why did the second reform work better? In this way it can guide policy for the future.\nI want to point out one other interesting thing about Hong’s work. She was well aware of the Baron-Kenny approach to direct and indirect effects that I have called the Linear Wonderland. In her paper she actually performed the same analysis twice: once using a variation of the Mediation Formula, the other using the “conventional procedures” (her term) of Baron and Kenny.\nThe Baron-Kenny method failed to detect the indirect effect. The reason is most likely just what I discussed before: linear methods cannot spot interactions between the treatment and the mediator. Perhaps the combination of more difficult material and a less supportive classroom environment caused the low-achieving students to become discouraged. Is this plausible? I think so. Algebra is a hard subject. Perhaps its difficulty made the extra attention from the teachers under the double-dose policy that much more valuable.\nThe Smoking Gene: Mediation and Interaction In Chapter 5 I wrote about the scientific and political war over smoking in the 1950s and 1960s. The skeptics of that era, who included R. A. Fisher and Jacob Yerushalmy, argued that the apparent link between smoking and cancer might be a statistical artifact due to a confounding variable. Yerushalmy thought in terms of a smoking personality type, while Fisher suggested the possibility of a gene that would predispose people both toward smoking and toward developing lung cancer.\nIronically, genomics researchers discovered in 2008 that Fisher was right: there is a “smoking gene” that operates exactly in the way he suggested. This discovery came about through a new genomic analysis technique called a genome-wide association study (GWAS for short, pronounced “gee-wahss.”) This is a prototypical “big-data” method that allows researchers to comb through the whole genome statistically, looking for genes that happen to show up more often in people with a certain disease, such as diabetes or schizophrenia or lung cancer.\nIt is important to notice the word “association” in the term GWAS. This method does not prove causality; it only identifies genes associated with a certain disease in the given sample. It is a data-driven rather than hypothesis- driven method, and this presents problems for causal inference.\nAlthough previous hypothesis-driven gene studies had failed to find any clear evidence of genes related to smoking or to lung cancer, things changed overnight in 2008. In that year researchers identified a gene located in a region of the fifteenth chromosome that codes for nicotine receptors in lung cells. It has an official name, rs16969968, but that is a mouthful even for genomics experts. So they started calling it “the Big One” or “Mr. Big” because of its extremely strong association with lung cancer. “In the smoking field, if you say Mr. Big, people will know what you are talking about,” says Laura Bierut, a smoking expert at Washington University in St. Louis. I’ll just call it the smoking gene.\nAt this point I think I hear the cantankerous ghost of R. A. Fisher rattling his chains in the basement and demanding a retraction of all the things I wrote in Chapter 5. Yes, the smoking gene is associated with lung cancer. It has two variants, one common and one less common. People who inherit two copies of the less common variant (about one-ninth of the population) have about a 77 percent greater risk of getting lung cancer. The smoking gene also seems related to smoking behavior. People who have the risky variant seem to need more nicotine to feel satisfied and have more difficulty stopping. However, there is also some good news: these people respond better to nicotine replacement therapy than people without the smoking gene.\nThe discovery of the smoking gene should not change anybody’s mind about the overwhelmingly more important causal factor in lung cancer, which is smoking. We know that smoking is associated with more than a tenfold increase in the risk of contracting lung cancer. By comparison, even a double dose of the smoking gene less than doubles your risk. This is serious business, no doubt, but it does not compare to the danger you face (for no good reason) if you are a regular smoker.\nF 9.11. Causal diagram for the smoking gene example.\nIGURE As always, it helps to visualize the discussion with a causal diagram.\nFisher thought of the (at that time purely hypothetical) smoking gene as a confounder of smoking and cancer (Figure 9.11). But as a confounder, it is not nearly strong enough to account for the overwhelmingly strong effect of smoking on the risk of lung cancer. This is, in essence, the argument that Jerome Cornfield made in his 1959 paper that settled the argument about the genetic hypothesis.\nWe can easily rewrite the same causal diagram as shown in Figure 9.12.\nWhen we look at the diagram this way, we see that smoking behavior is a mediator between the smoking gene and lung cancer. This tiny change in perspective completely revamps the scientific debate. Instead of asking whether smoking causes cancer (a question we know the answer to), we ask instead how the gene works. Does it make people smoke more and inhale harder? Or does it somehow make lung cells more vulnerable to cancer? Which is stronger, the indirect effect or the direct effect? The answer makes a difference for treatment. If the effect is direct, then people who have the high-risk gene should perhaps receive extra screening for lung cancer. On the other hand, if the effect is indirect, smoking behavior becomes crucial. We should counsel such patients about their increased risk and the importance of not smoking in the first place. If they already smoke, we may need to intervene more aggressively, perhaps with nicotine replacement therapy.\nF 9.12. Figure 9.11, slightly rearranged.\nIGURE Tyler VanderWeele, an epidemiologist at Harvard University, read the first report about the smoking gene in Nature, and he contacted a research group at Harvard led by David Christiani. Since 1992, Christiani had asked his lung cancer patients, as well as their friends and family, to fill out questionnaires and provide DNA samples to help the research effort. By the mid-2000s he had collected data on 1,800 patients with cancer as well as 1,400 people without lung cancer, who served as controls. The DNA samples were still chilling in a freezer when VanderWeele called.\nThe results of VanderWeele’s analysis were surprising at first. He found that the increased risk of lung cancer due to the indirect effect was only 1 to 3 percent. The people with the high-risk variant of the gene smoked only one additional cigarette per day on average, which was not enough to be clinically relevant. However, their bodies responded differently to smoking. The effect of the smoking gene on lung cancer was large and significant, but only for those people who smoked.\nThis poses an interesting conundrum in reporting the results. In this case, CDE(0) would be essentially zero: if you don’t smoke, the gene won’t hurt you. On the other hand, if we set the mediator to one pack a day or two packs a day, which I would denote CDE(1) or CDE(2), then the effect of the gene is strong. The natural direct effect averages these controlled effects. So the natural direct effect, NDE, is positive, and that is how VanderWeele reported it.\nThis example is a textbook case of interaction. In the end, VanderWeele’s analysis proves three important things about the smoking gene. First, it does not significantly increase cigarette consumption. Second, it does not cause lung cancer through a smoking-independent path. Third, for those people who do smoke, it significantly increases the risk of lung cancer. The interaction between the gene and the subject’s behavior is everything.\nAs is the case with any new result, of course more research is needed.\nBierut points out one problem with VanderWeele and Christiani’s analysis: they had only one measure of smoking behavior—the number of cigarettes per day. The gene could possibly cause people to inhale more deeply to get a larger dose of nicotine per puff. The Harvard study simply didn’t have data to test this theory.\nEven if some uncertainty remains, the research on the smoking gene provides a glimpse into the future of personalized medicine. It seems quite clear that in this case the important thing is how the gene and behavior interact. We still don’t know for sure whether the gene changes behavior (as Bierut suggests) or merely interacts with behavior that would have happened anyway (as VanderWeele’s analysis suggests). Nevertheless, we may be able to use genetic status to give people better information about the risks they face. In the future, causal models capable of detecting interactions between genes and behavior or genes and environment are sure to be an important tool in the epidemiologist’s kit.\nTourniquets: A Hidden Fallacy When John Kragh, an army surgeon, arrived for his first day of duty in a Baghdad hospital in 2006, he received an immediate awakening to the new realities of wartime medicine. Seeing a clipboard with the current day’s cases, he remarked to the nurse on duty, “Hey, that’s interesting—you’ve had an emergency tourniquet used during your shift.” The nurse replied, “That’s not interesting. We have one every shift.” In his first five minutes on the job, Kragh had stumbled upon a sea change in trauma care that took place during the Iraq and Afghanistan wars. Though used for centuries, both on the battlefield and in the operating room, tourniquets have always been somewhat controversial. A tourniquet left on too long will lead to loss of a limb. Also, tourniquets have often been improvised under duress, from straps or other handy materials, so their effectiveness is unsurprisingly a hit-or-miss affair. After World War II they were considered a treatment of last resort, and their use was officially discouraged.\nThe Iraq and Afghanistan wars radically changed that policy. Two things happened: more of the severe injuries required tourniquet use and better tourniquet designs became available. In 2005, the surgeon general of the US Army recommended that premanufactured tourniquets be provided to all soldiers. By 2006, as Kragh noted, the arrival of injured soldiers at the hospital with a tourniquet around an arm or leg was an everyday occurrence —a situation unprecedented in medical history.\nFrom 2002 to 2012, Kragh estimates, tourniquets saved 2,000 military lives. Soldiers on the front lines noticed. According to US Army surgeon David Welling, “Combat troops are reportedly going out on dangerous patrol missions with tourniquets already in place on extremities, as they wish to be fully ready to respond to extremity bleeding, if and when the mine or the improvised explosive devices (IED) should go off.” Judging from the anecdotal evidence and the popularity of tourniquets with frontline soldiers, their value should be beyond question by now.\nHowever, few, if any, large-scale studies of tourniquet use had ever been performed. In civilian life, the kinds of injuries that necessitate them are too rare, and in military life the chaos of war makes it difficult to conduct a proper scientific study. But Kragh saw the opportunity to document the effects of their use. He and the nurses collected data on every case that came through the hospital doors, and the former tourniquet newbie became known as “the tourniquet guy.” The study results, published in 2015, were not what Kragh expected.\nAccording to the data, the patients who had tourniquets applied before arriving at the hospital did not survive at a higher rate than those with similar injuries who had not received tourniquets. Of course, Kragh reasoned, the ones with tourniquets possibly had more severe injuries to begin with. But even when he controlled for this factor by comparing cases of equal severity, the tourniquets did not appear to improve survival rates (see Table 9.1).\nTABLE 9.1. Data on survival with and without tourniquets.\nThis is not a Simpson’s paradox situation. It doesn’t matter whether we aggregate the data or stratify it; in every severity category, as well as in the aggregate, survival was slightly greater for soldiers who did not get tourniquets. (The difference in survival rates was, however, too small to be statistically significant.) What went wrong? One possibility, of course, is that tourniquets aren’t better. Our belief in them could be a case of confirmation bias. When a soldier gets a tourniquet and survives, his doctors and his buddies will say, “That tourniquet saved his life.” But if the soldier doesn’t get a tourniquet and survives, nobody will say, “Not putting on a tourniquet saved his life.” So tourniquets might get more credit than their due, and nonintervention doesn’t get any credit.\nBut there was another possible bias in this study, which Kragh himself pointed out: the doctors only collected data on those soldiers who survived long enough to get to the hospital in the first place. To see why this matters, let’s draw a causal diagram (Figure 9.13).\nF 9.13. Causal diagram for tourniquet example. The dashed line is a IGURE hypothetical causal effect (not supported by the data).\nIn this figure, we can see that Injury Severity is a confounder of all three variables, the treatment (Tourniquet Use), the mediator (Pre-Admission Survival), and the outcome (Post-Admission Survival). It is therefore appropriate and necessary to condition on Injury Severity, as Kragh did in his paper.\nHowever, because Kragh studied only the patients who actually survived long enough to get to the hospital, he was also conditioning on the mediator, Pre-Admission Survival. In effect, he was blocking the indirect path from tourniquet use to post-admission survival, and therefore he was computing the direct effect, indicated by the dashed arrow in Figure 9.13. That effect was essentially zero. Nevertheless, there still could be an indirect effect. If tourniquets enabled more soldiers to survive until they got to the hospital, then the tourniquet would be a very favorable intervention. This would mean that the job of a tourniquet is to get the patient to the hospital alive; once it has done that, it has no further value. Unfortunately, nothing in the data (Table 9.1) can either confirm or refute this hypothesis.\nWilliam Kruskal once lamented that there is no Homer to sing the praise of statisticians. I would like to sing the praise of Kragh, who under the most adverse conditions imaginable had the presence of mind to collect data and subject the standard treatment to a scientific test. His example is a shining light for anyone who wants to practice evidence-based medicine. It’s a particularly bitter irony that his study could not succeed because he had no way to collect data on soldiers who didn’t survive to the hospital. We may wish that he could have proved once and for all that tourniquets save lives.\nKragh himself wrote in an email, “I have no doubt that tourniquets are a desirable intervention.” But in the end he had to report a “null result,” the kind that doesn’t make headlines. Even so, he deserves credit for sound scientific instincts.",
    "crumbs": [
      "Causal Inference",
      "The book of why"
    ]
  },
  {
    "objectID": "extracted/The Book of Why - Judea Pearl.html#big-data-artificial-intelligence-and-the-big-questions",
    "href": "extracted/The Book of Why - Judea Pearl.html#big-data-artificial-intelligence-and-the-big-questions",
    "title": "The book of why",
    "section": "10. BIG DATA, ARTIFICIAL INTELLIGENCE, AND THE BIG QUESTIONS",
    "text": "10. BIG DATA, ARTIFICIAL INTELLIGENCE, AND THE BIG QUESTIONS\nAll is pre-determined, yet permission is always granted.\n—MAIMONIDES (MOSHE BEN MAIMON) (1138–1204) W HEN I began my journey into causation, I was following the tracks of an anomaly. With Bayesian networks, we had taught machines to think in shades of gray, and this was an important step toward humanlike thinking. But we still couldn’t teach machines to understand causes and effects. We couldn’t explain to a computer why turning the dial of a barometer won’t cause rain.\nNor could we teach it what to expect when one of the riflemen on a firing squad changes his mind and decides not to shoot. Without the ability to envision alternate realities and contrast them with the currently existing reality, a machine cannot pass the mini-Turing test; it cannot answer the most basic question that makes us human: “Why?” I took this as an anomaly because I did not anticipate such natural and intuitive questions to reside beyond the reach of the most advanced reasoning systems of the time.\nOnly later did I realize that the same anomaly was afflicting more than just the field of artificial intelligence (AI). The very people who should care the most about “Why?” questions—namely, scientists—were laboring under a statistical culture that denied them the right to ask those questions. Of course they asked them anyway, informally, but they had to cast them as associational questions whenever they wanted to subject them to mathematical analysis.\nThe pursuit of this anomaly brought me into contact with people in a variety of fields, like Clark Glymour and his team (Richard Scheines and Peter Spirtes) from philosophy, Joseph Halpern from computer science, Jamie Robins and Sander Greenland from epidemiology, Chris Winship from sociology, and Don Rubin and Philip Dawid from statistics, who were thinking about the same problem. Together we lit the spark of a Causal Revolution, which has spread like a chain of firecrackers from one discipline to the next: epidemiology, psychology, genetics, ecology, geology, climate science, and so on. With every passing year I see a greater and greater willingness among scientists to speak and write about causes and effects, not with apologies and downcast eyes but with confidence and assertiveness. A new paradigm has evolved according to which it is okay to base your claims on assumptions as long as you make your assumptions transparent so that you and others can judge how plausible they are and how sensitive your claims are to their violation. The Causal Revolution has perhaps not led to any particular gadget that has changed our lives, but it has led to a transformation in attitudes that will inevitably lead to healthier science.\nI often think of this transformation as “the second gift of AI to humanity,” and it has been our main focus in this book. But as we bring the story to a conclusion, it is time for us to go back and inquire about the first gift, which has taken an unexpectedly long time to materialize. Are we in fact getting any closer to the day when computers or robots can understand causal conversations? Can we make artificial intelligences with as much imagination as a three-year-old human? I share some thoughts, but give no definitive conclusions, in this final chapter.\nCAUSAL MODELS AND “BIG DATA” Throughout science, business, government, and even sports, the amount of raw data we have about our world has grown at a staggering rate in recent years. The change is perhaps most visible to those of us who use the Internet and social media. In 2014, the last year for which I’ve seen data, Facebook reportedly was warehousing 300 petabytes of data about its 2 billion active users, or 150 megabytes of data per user. The games people play, the products they like to buy, the names of all their Facebook friends, and of course all their cat videos—all of them are out there in a glorious ocean of ones and zeros.\nLess obvious to the public, but just as important, is the rise of huge databases in science. For example, the 1000 Genomes Project collected two hundred terabytes of information in what it calls “the largest public catalogue of human variation and genotype data.” NASA’s Mikulski Archive for Space Telescopes has collected 2.5 petabytes of data from several deep-space surveys. But Big Data hasn’t only affected high-profile sciences; it’s made inroads into every science. A generation ago, a marine biologist might have spent months doing a census of his or her favorite species. Now the same biologist has immediate access online to millions of data points on fish, eggs, stomach contents, or anything else he or she wants. Instead of just doing a census, the biologist can tell a story.\nMost relevant for us is the question of what comes next. How do we extract meaning from all these numbers, bits, and pixels? The data may be immense, but the questions we ask are simple. Is there a gene that causes lung cancer? What kinds of solar systems are likely to harbor Earth-like planets? What factors are causing the population of our favorite fish to decrease, and what can we do about it? In certain circles there is an almost religious faith that we can find the answers to these questions in the data itself, if only we are sufficiently clever at data mining. However, readers of this book will know that this hype is likely to be misguided. The questions I have just asked are all causal, and causal questions can never be answered from data alone. They require us to formulate a model of the process that generates the data, or at least some aspects of that process. Anytime you see a paper or a study that analyzes the data in a model-free way, you can be certain that the output of the study will merely summarize, and perhaps transform, but not interpret the data.\nThis is not to say that data mining is useless. It may be an essential first step to search for interesting patterns of association and pose more precise interpretive questions. Instead of asking, “Are there any lung-cancer-causing genes?” we can now start scanning the genome for genes with a high correlation with lung cancer (such as the “Mr. Big” gene mentioned in Chapter 9). Then we can ask, “Does this gene cause lung cancer? (And how?)” We never could have asked about the “Mr. Big” gene if we did not have data mining. To get any farther, though, we need to develop a causal model specifying (for example) what variables we think the gene affects, what confounders might exist, and what other causal pathways might bring about the result. Data interpretation means hypothesizing on how things operate in the real world.\nAnother role of Big Data in causal inference problems lies in the last stage of the inference engine described in the Introduction (step 8), which takes us from the estimand to the estimate. This step of statistical estimation is not trivial when the number of variables is large, and only big-data and modern machine-learning techniques can help us to overcome the curse of dimensionality. Likewise, Big Data and causal inference together play a crucial role in the emerging area of personalized medicine. Here, we seek to make inferences from the past behavior of a set of individuals who are similar in as many characteristics as possible to the individual in question. Causal inference permits us to screen off the irrelevant characteristics and to recruit these individuals from diverse studies, while Big Data allows us to gather enough information about them.\nIt’s easy to understand why some people would see data mining as the finish rather than the first step. It promises a solution using available technology. It saves us, as well as future machines, the work of having to consider and articulate substantive assumptions about how the world operates.\nIn some fields our knowledge may be in such an embryonic state that we have no clue how to begin drawing a model of the world. But Big Data will not solve this problem. The most important part of the answer must come from such a model, whether sketched by us or hypothesized and fine-tuned by machines.\nLest I seem too critical of the big-data enterprise, I would like to mention one new opportunity for symbiosis between Big Data and causal inference.\nThis is called transportability.\nThanks to Big Data, not only can we access an enormous number of individuals in any given study, but we can also access an enormous number of studies, conducted in different locations and under different conditions. Often we want to combine the results of these studies and translate them to new populations that may be different even in ways we have not anticipated.\nThe process of translating the results of a study from one setting to another is fundamental to science. In fact, scientific progress would grind to a halt were it not for the ability to generalize results from laboratory experiments to the real world—for example, from test tubes to animals to humans. But until recently each science had to develop its own criteria for sorting out valid from invalid generalizations, and there have been no systematic methods for addressing “transportability” in general.\nWithin the last five years, my former student (now colleague) Elias Bareinboim and I have succeeded in giving a complete criterion for deciding when results are transportable and when they are not. As usual, the proviso for using this criterion is that you represent the salient features of the data- generating process with a causal diagram, marked with locations of potential disparities. “Transporting” a result does not necessarily mean taking it at face value and applying it to the new environment. The researcher may have to recalibrate it to allow for disparities between the two environments.\nSuppose we want to know the effect of an online advertisement (X) on the likelihood that a consumer will purchase the product (Y)—say, a surfboard.\nWe have data from studies in five different places: Los Angeles, Boston, San Francisco, Toronto, and Honolulu. Now we want to estimate how effective the advertisement will be in Arkansas. Unfortunately, each population and each study differs slightly. For example, the Los Angeles population is younger than our target population, and the San Francisco population differs in click- through rate. Figure 10.1 shows the unique characteristics of each population and each study. Can we combine the data from these remote and disparate studies to estimate the ad’s effectiveness in Arkansas? Can we do it without taking any data in Arkansas? Or perhaps by measuring merely a small set of variables or conducting a pilot observational study? F 10.1. The transportability problem.\nIGURE Figure 10.2 translates these differences into graphical form. The variable Z represents age, which is a confounder; young people may be more likely to see the ad and more likely to buy the product even if they don’t see the ad.\nThe variable W represents clicking on a link to get more information. This is a mediator, a step that must take place in order to convert “seeing the advertisement” into “buying the product.” The letter S, in each case, stands for a “difference-producing” variable, a hypothetical variable that points to the characteristic by which the two populations differ. For example, in Los Angeles (b), the indicator S points to Z, age. In each of the other cities the indicator points to the distinguishing feature of the population mentioned in Figure 10.1.\nF 10.2. Differences between the studied populations, expressed in graphical IGURE form.\nFor the advertising agency, the good news is that a computer can now manage this complicated “data fusion” problem and, guided by the do- calculus, tell us which studies we can use to answer our query and by what means, as well as what information we need to collect in Arkansas to support the conclusion. In some cases the effect may transport directly, with no further work and without our even setting foot in Arkansas. For example, the effect of the ad in Arkansas should be the same as in Boston, because according to the diagram, Boston (c) differs from Arkansas only in the variable V, which does not affect either treatment X or outcome Y.\nWe need to reweight the data in some of the other studies—for instance, to account for the different age structure of the population in the Los Angeles study (b). Interestingly, the experimental study in Toronto (e) is sufficient for estimating our query in Arkansas despite the disparity at W, if we can only measure X, W, and Y in Arkansas.\nRemarkably, we have found examples in which no transport is feasible from any one of the available studies; yet the target quantity is nevertheless estimable from their combination. Also, even studies that are not transportable are not entirely useless. Take, for example, the Honolulu (f) study in Figure 10.2, which is not transportable due to the arrow S Y. The arrow X W, on the other hand, is not contaminated by S, and so the data available from Honolulu can be used to estimate P(W | X). By combining this with estimates of P(W | X) from other studies, we can increase the precision of this subexpression. By carefully combining such subexpressions, we may be able to synthesize an accurate overall estimate of the target quantity.\nAlthough in simple cases these results are intuitively reasonable, when the diagrams get more complicated, we need the help of a formal method. The do-calculus provides a general criterion for determining transportability in such cases. The rule is quite simple: if you can perform a valid sequence of do-operations (using the rules from Chapter 7) that transforms the target quantity into another expression in which any factor involving S is free of do- operators, then the estimate is transportable. The logic is simple; any such factor can be estimated from the available data, uncontaminated by the disparity factor S.\nElias Bareinboim has managed to do the same thing for the problem of transportability that Ilya Shpitser did for the problem of interventions. He has developed an algorithm that can automatically determine for you whether the effect you are seeking is transportable, using graphical criteria alone. In other words, it can tell you whether the required separation of S from the do- operators can be accomplished or not.\nBareinboim’s results are exciting because they change what was formerly seen as a threat to validity into an opportunity to leverage the many studies in which participation cannot be mandated and where we therefore cannot guarantee that the study population would be the same as the population of interest. Instead of seeing the difference between populations as a threat to the “external validity” of a study, we now have a methodology for establishing validity in situations that would have appeared hopeless before. It is precisely because we live in the era of Big Data that we have access to information on many studies and on many of the auxiliary variables (like Z and W) that will allow us to transport results from one population to another.\nI will mention in passing that Bareinboim has also proved analogous results for another problem that has long bedeviled statisticians: selection bias. This kind of bias occurs when the sample group being studied differs from the target population in some relevant way. This sounds a lot like the transportability problem—and it is, except for one very important modification: instead of drawing an arrow from the indicator variable S to the affected variable, we draw the arrow toward S. We can think of S as standing for “selection” (into the study). For example, if our study observes only hospitalized patients, as in the Berkson bias example, we would draw an arrow from Hospitalization to S, indicating that hospitalization is a cause of selection for our study. In Chapter 6 we saw this situation only as a threat to the validity of our study. But now, we can look at it as an opportunity. If we understand the mechanism by which we recruit subjects for the study, we can recover from bias by collecting data on the right set of deconfounders and using an appropriate reweighting or adjustment formula. Bareinboim’s work allows us to exploit causal logic and Big Data to perform miracles that were previously inconceivable.\nWords like “miracles” and “inconceivable” are rare in scientific discourse, and the reader may wonder if I am being a little too enthusiastic. But I use them for a good reason. The concept of external validity as a threat to experimental science has been around for at least half a century, ever since Donald Campbell and Julian Stanley recognized and defined the term in 1963.\nI have talked to dozens of experts and prominent authors who have written about this topic. To my amazement, not one of them was able to tackle any of the toy problems presented in Figure 10.2. I call them “toy problems” because they are easy to describe, easy to solve, and easy to verify if a given solution is correct.\nAt present, the culture of “external validity” is totally preoccupied with listing and categorizing the threats to validity rather than fighting them. It is in fact so paralyzed by threats that it looks with suspicion and disbelief on the very idea that threats can be disarmed. The experts, who are novices to graphical models, find it easier to configure additional threats than to attempt to remedy any one of them. Language like “miracles,” so I hope, should jolt my colleagues into looking at such problems as intellectual challenges rather than reasons for despair.\nI wish that I could present the reader with successful case studies of a complex transportability task and recovery from selection bias, but the techniques are still too new to have penetrated into general usage. I am very confident, though, that researchers will discover the power of Bareinboim’s algorithms before long, and then external validity, like confounding before it, will cease to have its mystical and terrifying power.\nSTRONG AI AND FREE WILL The ink was scarcely dry on Alan Turing’s great paper, “Computing Machinery and Intelligence,” when science fiction writers and futurologists began toying with the prospect of machines that think. Sometimes they envisioned these machines as benign or even noble figures, like the whirry, chirpy R2D2 and the oddly British android C3PO from Star Wars. Other times the machines are much more sinister, plotting the destruction of the human species, as in the Terminator movies, or enslaving humans in a virtual reality, as in The Matrix.\nIn all these cases, the AIs say more about the anxieties of the writers or the capabilities of the movie’s special effects department than they do about actual artificial intelligence research. Artificial intelligence has turned out to be a more elusive goal than Turing ever suspected, even though the sheer computational power of our computers has no doubt exceeded his expectations.\nIn Chapter 3 I wrote about some of the reasons for this slow progress. In the 1970s and early 1980s, artificial intelligence research was hampered by its focus on rule-based systems. But rule-based systems proved to be on the wrong track. They were very brittle. Any slight change to their working assumptions required that they be rewritten. They could not cope well with uncertainty or with contradictory data. Finally, they were not scientifically transparent; you could not prove mathematically that they would behave in a certain way, and you could not pinpoint exactly what needed repair when they didn’t. Not all AI researchers objected to the lack of transparency. The field at the time was divided into “neats” (who wanted transparent systems with guarantees of behavior) and “scruffies” (who just wanted something that worked). I was always a “neat.” I was lucky to come along at a time when the field was ready for a new approach. Bayesian networks were probabilistic; they could cope with a world full of conflicting and uncertain data. Unlike the rule-based systems, they were modular and easily implemented on a distributed computing platform, which made them fast. Finally, as was important to me (and other “neats”), Bayesian networks dealt with probabilities in a mathematically sound way.\nThis guaranteed that if anything went wrong, the bug was in the program, not in our thinking.\nEven with all these advantages, Bayesian networks still could not understand causes and effects. By design, in a Bayesian network, information flows in both directions, causal and diagnostic: smoke increases the likelihood of fire, and fire increases the likelihood of smoke. In fact, a Bayesian network can’t even tell what the “causal direction” is. The pursuit of this anomaly— this wonderful anomaly, as it turned out—drew me away from the field of machine learning and toward the study of causation. I could not reconcile myself to the idea that future robots would not be able to communicate with us in our native language of cause and effect. Once in causality land, I was naturally drawn toward the vast spectrum of other sciences where causal asymmetry is of the utmost importance.\nSo, for the past twenty-five years, I have been somewhat of an expatriate from the land of automated reasoning and machine learning. Nevertheless, from my distant vantage point I can still see the current trends and fashions.\nIn recent years, the most remarkable progress in AI has taken place in an area called “deep learning,” which uses methods like convolutional neural networks. These networks do not follow the rules of probability; they do not deal with uncertainty in a rigorous or transparent way. Still less do they incorporate any explicit representation of the environment in which they operate. Instead, the architecture of the network is left free to evolve on its own. When finished training a new network, the programmer has no idea what computations it is performing or why they work. If the network fails, she has no idea how to fix it.\nPerhaps the prototypical example is AlphaGo, a convolutional neural- network-based program that plays the ancient Asian game of Go, developed by DeepMind, a subsidiary of Google. Among human games of perfect information, Go had always been considered the toughest nut for AI. Though computers conquered humans in chess in 1997, they were not considered a match even for the lowest-level professional Go players as recently as 2015.\nThe Go community thought that computers were still a decade or more away from giving humans a real battle.\nThat changed almost overnight with the advent of AlphaGo. Most Go players first heard about the program in late 2015, when it trounced a human professional 5–0. In March 2016, AlphaGo defeated Lee Sedol, for years considered the strongest human player, 4–1. A few months later it played sixty online games against top human players without losing a single one, and in 2017 it was officially retired after beating the current world champion, Ke Jie. The one game it lost to Sedol is the only one it will ever lose to a human.\nAll of this is exciting, and the results leave no doubt: deep learning works for certain tasks. But it is the antithesis of transparency. Even AlphaGo’s programmers cannot tell you why the program plays so well. They knew from experience that deep networks have been successful at tasks in computer vision and speech recognition. Nevertheless, our understanding of deep learning is completely empirical and comes with no guarantees. The AlphaGo team could not have predicted at the outset that the program would beat the best human in a year, or two, or five. They simply experimented, and it did.\nSome people will argue that transparency is not really needed. We do not understand in detail how the human brain works, and yet it runs well, and we forgive our meager understanding. So, they argue, why not unleash deep- learning systems and create a new kind of intelligence without understanding how it works? I cannot say they are wrong. The “scruffies,” at this moment in time, have taken the lead. Nevertheless, I can say that I personally don’t like opaque systems, and that is why I do not choose to do research on them.\nMy personal taste aside, there is another factor to add to this analogy with the human brain. Yes, we forgive our meager understanding of how human brains work, but we can still communicate with other humans, learn from them, instruct them, and motivate them in our own native language of cause and effect. We can do that because our brains work the same way. If our robots will all be as opaque as AlphaGo, we will not be able to hold a meaningful conversation with them, and that would be quite unfortunate.\nWhen my house robot turns on the vacuum cleaner while I am still asleep (Figure 10.3) and I tell it, “You shouldn’t have woken me up,” I want it to understand that the vacuuming was at fault, but I don’t want it to interpret the complaint as an instruction never to vacuum the upstairs again. It should understand what you and I perfectly understand: vacuum cleaners make noise, noise wakes people up, and that makes some people unhappy. In other words, our robot will have to understand cause-and-effect relations—in fact, counterfactual relations, such as those encoded in the phrase “You shouldn’t have.” Indeed, observe the rich content of this short sentence of instructions. We should not need to tell the robot that the same applies to vacuum cleaning downstairs or anywhere else in the house, but not when I am awake or not at home, when the vacuum cleaner is equipped with a silencer, and so forth. Can a deep-learning program understand the richness of this instruction? That is why I am not satisfied with the apparently superb performance of opaque systems. Transparency enables effective communication.\nF 10.3. A smart robot contemplating the causal ramifications of his/her actions.\nIGURE (Source: Drawing by Maayan Harel.) One aspect of deep learning does interest me: the theoretical limitations of these systems, primarily limitations that stem from their inability to go beyond rung one of the Ladder of Causation. This limitation does not hinder the performance of AlphaGo in the narrow world of go games, since the board description together with the rules of the game constitutes an adequate causal model of the go-world. Yet it hinders learning systems that operate in environments governed by rich webs of causal forces, while having access merely to surface manifestations of those forces. Medicine, economics, education, climatology, and social affairs are typical examples of such environments. Like the prisoners in Plato’s famous cave, deep-learning systems explore the shadows on the cave wall and learn to accurately predict their movements. They lack the understanding that the observed shadows are mere projections of three-dimensional objects moving in a three-dimensional space. Strong AI requires this understanding.\nDeep-learning researchers are not unaware of these basic limitations. For example, economists using machine learning have noted that their methods do not answer key questions of interest, such as estimating the impact of untried policies and actions. Typical examples are introducing new price structures or subsidies or changing the minimum wage. In technical terms, machine- learning methods today provide us with an efficient way of going from finite sample estimates to probability distributions, and we still need to get from distributions to cause-effect relations.\nWhen we start talking about strong AI, causal models move from a luxury to a necessity. To me, a strong AI should be a machine that can reflect on its actions and learn from past mistakes. It should be able to understand the statement “I should have acted differently,” whether it is told as much by a human or arrives at that conclusion itself. The counterfactual interpretation of this statement reads, “I have done X = x, and the outcome was Y = y. But if I had acted differently, say X = x′, then the outcome would have been better, perhaps Y = y′.” As we have seen, the estimation of such probabilities has been completely automated, given enough data and an adequately specified causal model.\nIn fact, I think that a very important target for machine learning is the simpler probability P(Y 1 = y′ | X = x), where the machine observes an X = x event X = x but not the outcome Y, and then asks for the outcome under an alternative event X = x′. If it can compute this quantity, the machine can treat its intended action as an observed event (X = x) and ask, “What if I change my mind and do X = x′ instead?” This expression is mathematically the same as the effect of treatment on the treated (mentioned in Chapter 8), and we have lots of results indicating how to estimate it.\nIntent is a very important part of personal decision making. If a former smoker feels himself tempted to light up a cigarette, he should think very hard about the reasons behind that intention and ask whether a contrary action might in fact lead to a better outcome. The ability to conceive of one’s own intent and then use it as a piece of evidence in causal reasoning is a level of self-awareness (if not consciousness) that no machine I know of has achieved.\nI would like to be able to lead a machine into temptation and have it say, “No.” Any discussion of intent leads to another major issue for strong AI: free will. If we are asking a machine to have the intent to do X = x, become aware of it, and choose to do X = x′ instead, we seem to be asking it to have free will. But how can a robot have free will if it just follows instructions stored in its program? Berkeley philosopher John Searle has labeled the free will problem “a scandal in philosophy,” partly due to the zero progress made on the problem since antiquity and partly because we cannot brush it off as an optical illusion.\nOur entire conception of “self” presupposes that we have such a thing as choices. For example, there seems to be no way to reconcile my vivid, unmistakable sensation of having an option (say, to touch or not to touch my nose) with my understanding of reality that presupposes causal determinism: all our actions are triggered by electrical neural signals emanating from the brain.\nWhile many philosophical problems have disappeared over time in the light of scientific progress, free will remains stubbornly enigmatic, as fresh as it appeared to Aristotle and Maimonides. Moreover, while human free will has sometimes been justified on spiritual or theological grounds, these explanations would not apply to a programmed machine. So any appearance of robotic free will must be a gimmick—at least this is the conventional dogma.\nNot all philosophers are convinced that there really is a clash between free will and determinism. A group called “compatibilists,” among whom I count myself, consider it only an apparent clash between two levels of description: the neural level at which processes appear deterministic (barring quantum indeterminism) and the cognitive level at which we have a vivid sensation of options. Such apparent clashes are not infrequent in science. For example, the equations of physics are time reversible on a microscopic level, yet appear irreversible on the macroscopic level of description; the smoke never flows back into the chimney. But that opens up new questions: Granted that free will is (or may be) an illusion, why is it so important to us as humans to have this illusion? Why did evolution labor to endow us with this conception? Gimmick or no gimmick, should we program the next generation of computers to have this illusion? What for? What computational benefits does it entail? I think that understanding the benefits of the illusion of free will is the key to the stubbornly enigmatic problem of reconciling it with determinism. The problem will dissolve before our eyes once we endow a deterministic machine with the same benefits.\nTogether with this functional issue, we must also cope with questions of simulation. If neural signals from the brain trigger all our actions, then our brains must be fairly busy decorating some actions with the title “willed” or “intentional” and others with “unintentional.” What precisely is this labeling process? What neural path would earn a given signal the label “willed”? In many cases, voluntary actions are recognized by a trace they leave in short-term memory, with the trace reflecting a purpose or motivation. For example, “Why did you do it?” “Because I wanted to impress you.” Or, as Eve innocently answered, “The serpent deceived me, and I ate.” But in many other cases an intentional action is taken, and yet no reason or motives come to mind. Rationalization of actions may be a reconstructive, post-action process. For example, a soccer player may explain why he decided to pass the ball to Joe instead of Charlie, but it is rarely the case that those reasons consciously triggered the action. In the heat of the game, thousands of input signals compete for the player’s attention. The crucial decision is which signals to prioritize, and the reasons can hardly be recalled and articulated.\nAI researchers are therefore trying to answer two questions—about function and simulation—with the first driving the second. Once we understand what computational function free will serves in our lives, then we can attend to equipping machines with such functions. It becomes an engineering problem, albeit a hard one.\nTo me, certain aspects of the functional question stand out clearly. The illusion of free will gives us the ability to speak about our intents and to subject them to rational thinking, possibly using counterfactual logic. When the coach pulls us out of a soccer game and says, “You should have passed the ball to Charlie,” consider all the complex meanings embedded in these eight words.\nFirst, the purpose of such a “should have” instruction is to swiftly transmit valuable information from the coach to the player: in the future, when faced with a similar situation, choose action B rather than action A. But the “similar situations” are far too numerous to list and are hardly known even to the coach himself. Instead of listing the features of these “similar situations,” the coach points to the player’s action, which is representative of his intent at decision time. By proclaiming the action inadequate, the coach is asking the player to identify the software packages that led to his decision and then reset priorities among those packages so that “pass to Charlie” becomes the preferred action. There is profound wisdom in this instruction because who, if not the player himself, would know the identities of those packages? They are nameless neural paths that cannot be referenced by the coach or any external observer. Asking the player to take an action different from the one taken amounts to encouraging an intent-specific analysis, like the one we mentioned above. Thinking in terms of intents, therefore, offers us a shorthand to convert complicated causal instructions into simple ones.\nI would conjecture, then, that a team of robots would play better soccer if they were programmed to communicate as if they had free will. No matter how technically proficient the individual robots are at soccer, their team’s performance will improve when they can speak to each other as if they are not preprogrammed robots but autonomous agents believing they have options.\nAlthough it remains to be seen whether the illusion of free will enhances robot-to-robot communication, there is much less uncertainty about robot-to- human communication. In order to communicate naturally with humans, strong AIs will certainly need to understand the vocabulary of options and intents, and thus they will need to emulate the illusion of free will. As I explained above, they may also find it advantageous to “believe” in their own free will themselves, to the extent of being able to observe their intent and act differently.\nThe ability to reason about one’s own beliefs, intents, and desires has been a major challenge to AI researchers and defines the notion of “agency.” Philosophers, on the other hand, have studied these abilities as part of the classical question of consciousness. Questions such as “Can machines have consciousness?” or “What makes a software agent different from an ordinary program?” have engaged the best minds of many generations, and I would not pretend to answer them in full. I believe, nevertheless, that the algorithmization of counterfactuals is a major step toward understanding these questions and making consciousness and agency a computational reality. The methods described for equipping a machine with a symbolic representation of its environment and the capacity to imagine a hypothetical perturbation of that environment can be extended to include the machine itself as part of the environment. No machine can process a complete copy of its own software, but it can have a blueprint summary of its major software components. Other components can then reason about that blueprint and mimic a state of self- awareness.\nTo create the perception of agency, we must also equip this software package with a memory to record past activations, to which it can refer when asked, “Why did you do that?” Actions that pass certain patterns of path activation will receive reasoned explanations, such as “Because the alternative proved less attractive.” Others will end up with evasive and useless answers, such as “I wish I knew why” or “Because that’s the way you programmed me.” In summary, I believe that the software package that can give a thinking machine the benefits of agency would consist of at least three parts: a causal model of the world; a causal model of its own software, however superficial; and a memory that records how intents in its mind correspond to events in the outside world.\nThis may even be how our own causal education as infants begins. We may have something like an “intention generator” in our minds, which tells us that we are supposed to take action X = x. But children love to experiment—to defy their parents’, their teachers’, even their own initial intentions—and to something different, just for fun. Fully aware that we are supposed to do X = x, we playfully do X = x′ instead. We watch what happens, repeat the process, and keep a record of how good our intention generator is. Finally, when we start to adjust our own software, that is when we begin to take moral responsibility for our actions. This responsibility may be an illusion at the level of neural activation but not at the level of self-awareness software.\nEncouraged by these possibilities, I believe that strong AI with causal understanding and agency capabilities is a realizable promise, and this raises the question that science fiction writers have been asking since the 1950s: Should we be worried? Is strong AI a Pandora’s box that we should not open? Recently public figures like Elon Musk and Stephen Hawking have gone on record saying that we should be worried. On Twitter, Musk said that AIs were “potentially more dangerous than nukes.” In 2015, John Brockman’s website Edge.org posed as its annual question, that year asking, “What do you think about machines that think?” It drew 186 thoughtful and provocative answers (since collected into a book titled What to Think About Machines That Think).\nBrockman’s intentionally vague question can be subdivided into at least five related ones: 1. Have we already made machines that think? 2. Can we make machines that think? 3. Will we make machines that think? 4. Should we make machines that think? And finally, the unstated question that lies at the heart of our anxieties: 5. Can we make machines that are capable of distinguishing good from evil? The answer to the first question is no, but I believe that the answer to all of the others is yes. We certainly have not yet made machines that think in any humanlike interpretation of the word. So far we can only simulate human thinking in narrowly defined domains that have only the most primitive causal structures. There we can actually make machines that outperform humans, but this should be no surprise because these domains reward the one thing that computers do well: compute.\nThe answer to the second question is almost certainly yes, if we define thinking as being able to pass the Turing test. I say that on the basis of what we have learned from the mini-Turing test. The ability to answer queries at all three levels of the Ladder of Causation provides the seeds of “agency” software so that the machine can think about its own intentions and reflect on its own mistakes. The algorithms for answering causal and counterfactual queries already exist (thanks in large part to my students), and they are only waiting for industrious AI researchers to implement them.\nThe third question depends, of course, on human events that are difficult to predict. But historically, humans have seldom refrained from making or doing things that they are technologically capable of. Partly this is because we do not know we are technologically capable of something until we actually do it, whether it’s cloning animals or sending astronauts to the moon. The detonation of the atomic bomb, however, was a turning point: many people think this technology should not have been developed.\nSince World War II, a good example of scientists pulling back from the feasible was the 1975 Asilomar conference on DNA recombination, a new technology seen by the media in somewhat apocalyptic terms. The scientists working in the field managed to come to a consensus on good-sense safety practices, and the agreement they reached then has held up well over the ensuing four decades. Recombinant DNA is now a common, mature technology.\nIn 2017, the Future of Life Institute convened a similar Asilomar conference on artificial intelligence and agreed on a set of twenty-three principles for future research in “beneficial AI.” While most of the guidelines are not relevant to the topics discussed in this book, the recommendations on ethics and values are definitely worthy of attention. For example, recommendations 6, “AI systems should be safe and secure throughout their operational lifetime, and verifiably so,” and 7, “If an AI system causes harm, it should be possible to ascertain why,” clearly speak to the importance of transparency. Recommendation 10, “Highly autonomous AI systems should be designed so that their goals and behaviors can be assured to align with human values throughout their operation,” is rather vague as stated but could be given operational meaning if these systems were required to be able to declare their own intents and communicate with humans about causes and effects.\nMy answer to the fourth question is also yes, based on the answer to the fifth. I believe that we will be able to make machines that can distinguish good from evil, at least as reliably as humans and hopefully more so. The first requirement of a moral machine is the ability to reflect on its own actions, which falls under counterfactual analysis. Once we program self-awareness, however limited, empathy and fairness follow, for it is based on the same computational principles, with another agent added to the equation.\nThere is a big difference in spirit between the causal approach to building the moral robot and an approach that has been studied and rehashed over and over in science fiction since the 1950s: Asimov’s laws of robotics. Isaac Asimov proposed three absolute laws, starting with “A robot may not injure a human being or, through inaction, allow a human being to come to harm.” But as science fiction has shown over and over again, Asimov’s laws always lead to contradictions. To AI scientists, this comes as no surprise: rule-based systems never turn out well. But it does not follow that building a moral robot is impossible. It means that the approach cannot be prescriptive and rule based. It means that we should equip thinking machines with the same cognitive abilities that we have, which include empathy, long-term prediction, and self-restraint, and then allow them to make their own decisions.\nOnce we have built a moral robot, many apocalyptic visions start to recede into irrelevance. There is no reason to refrain from building machines that are better able to distinguish good from evil than we are, better able to resist temptation, better able to assign guilt and credit. At this point, like chess and Go players, we may even start to learn from our own creation. We will be able to depend on our machines for a clear-eyed and causally sound sense of justice. We will be able to learn how our own free will software works and how it manages to hide its secrets from us. Such a thinking machine would be a wonderful companion for our species and would truly qualify as AI’s first and best gift to humanity.",
    "crumbs": [
      "Causal Inference",
      "The book of why"
    ]
  },
  {
    "objectID": "extracted/The Book of Why - Judea Pearl.html#acknowledgments",
    "href": "extracted/The Book of Why - Judea Pearl.html#acknowledgments",
    "title": "The book of why",
    "section": "ACKNOWLEDGMENTS",
    "text": "ACKNOWLEDGMENTS\nTo enumerate the entire cast of students, friends, colleagues, and teachers who\nhave contributed ideas to this book would amount to writing another book.\nStill, a few players deserve special mention, from my personal persective. I would like to thank Phil Dawid, for giving me my first audition on the pages of Biometrika; Jamie Robins and Sander Greenland, for turning epidemiology into a graph-speaking community; the late Dennis Lindley, for giving me the assurance that even seasoned statisticians can recognize flaws in their field and rally for its reform; Chris Winship, Steven Morgan, and Felix Elwert for ushering social science into the age of causation; and, finally, Peter Spirtes, Clark Glymour, and Richard Scheines, for their help in pushing me over the cliff of probabilities into the stormy waters of causation.\nDigging deeper into my ancient history, I must thank Joseph Hermony, Dr.\nShimshon Lange, Professor Franz Ollendorff, and other dedicated science teachers who inspired me from grade school to college. They instilled in many of us first-generation Israelis a sense of mission and historical responsibility to pursue scientific explorations as mankind’s most noble and fun challenge.\nThis book would have remained a relic of wishful thinking if it were not for my co-author, Dana Mackenzie, who took my wishful thinking seriously and made it a reality. He not only corrected my foreign accent but also took me to distant lands, from the Navy ships of Captain James Lind to the Antarctic expedition of Captain Robert Scott, adding knowledge, stories, structure, and clarity to a mess of mathematical equations that were awaiting an organizing narrative.\nI owe a great debt to members of the Cognitive Systems Laboratory at UCLA whose work and ideas over the past three and a half decades formed the scientific basis of this book: Alex Balke, Elias Bareinboim, Blai Bonet, Carlo Brito, Avin Chen, Bryant Chen, David Chickering, Adnan Darwiche, Rina Dechter, Andrew Forney, David Galles, Hector Geffner, Dan Geiger, Moises Goldszmidt, David Heckerman, Mark Hopkins, Jin Kim, Manabu Kuroki, Trent Kyono, Karthika Mohan, Azaria Paz, George Rebane, Ilya Shpitser, Jin Tian, and Thomas Verma.\nFunding agencies receive ritualized thanks in scholarly publications but far too little real credit, considering their crucial role in recognizing seeds of ideas before they become fashionable. I must acknowledge the steady and unfailing support of the National Science Foundation and the Office of Naval Research, through the Machine Learning and Intelligence program headed by Behzad Kamgar-Parsi.\nDana and I would like to thank our agent, John Brockman, who gave us timely encouragement and the benefit of his professional expertise. Our editor at Basic Books, TJ Kelleher, asked us just the right questions and persuaded Basic Books that a story this ambitious could not be told in 200 pages. Our illustrators, Maayan Harel and Dakota Harr, managed to cope with our sometimes conflicting instructions and brought abstract subjects to life with humor and beauty. Kaoru Mulvihill at UCLA deserves much credit for proofing several versions of the manuscript and illustrating the hordes of graphs and diagrams.\nDana will be forever grateful to John Wilkes, who founded the Science Communication Program at UC Santa Cruz, which is still going strong and is the best possible route into a career as a science writer. Dana would also like to thank his wife, Kay, who encouraged him to pursue his childhood dream of being a writer, even when it meant pulling up stakes, crossing the country, and starting over.\nFinally, my deepest debt is owed to my family, for their patience, understanding, and support. Especially to my wife, Ruth, my moral compass, for her endless love and wisdom. To my late son, Danny, for showing me the silent audacity of truth. To my daughters Tamara and Michelle for trusting my perennial promise that the book will eventually be done. And to my grandchildren, Leora, Tori, Adam, Ari and Evan, for giving a purpose to my long journeys and for always dissolving my “why” questions away.\nJudea Pearl is professor of computer science at the University of California, Los Angeles, winner of the 2011 Turing Award, and author of three classic technical books on causality. He lives in Los Angeles, California.\nDana Mackenzie is an award-winning science writer and author of The Big Splat, or How Our Moon Came to Be. He lives in Santa Cruz, California.\nALSO BY JUDEA PEARL: Causal Inference in Statistics: A Primer (with Madelyn Glymour and Nicholas Jewell) An Introduction to Causal Inference I Am Jewish: Personal Reflections Inspired by the Last Words of Daniel Pearl (coedited with Ruth Pearl) Causality: Models, Reasoning and Inference Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference Heuristics: Intelligent Search Strategies for Computer Problem Solving ALSO BY DANA MACKENZIE: The Universe in Zero Words: The Story of Mathematics as Told Through Equations What’s Happening in the Mathematical Sciences (volumes 6–10) The Big Splat, or How Our Moon Came to Be",
    "crumbs": [
      "Causal Inference",
      "The book of why"
    ]
  },
  {
    "objectID": "extracted/The Book of Why - Judea Pearl.html#notes",
    "href": "extracted/The Book of Why - Judea Pearl.html#notes",
    "title": "The book of why",
    "section": "NOTES",
    "text": "NOTES\nNOTES TO INTRODUCTION\nStudents are never allowed: With possibly one exception: if we have performed a randomized controlled trial, as discussed in Chapter 4.\nNOTES TO CHAPTER ONE then the opposite is true: In other words, when evaluating an intervention in a causal model, we make the minimum changes possible to enforce its immediate effect. So we “break” the model where it comes to A but not B.\nWe should thank the language: I should also mention here that counterfactuals allow us to talk about causality in individual cases: What would have happened to Mr. Smith, who was not vaccinated and died of smallpox, if he had been vaccinated? Such questions, the backbone of personalized medicine, cannot be answered from rung-two information.\nYet we can answer: To be more precise, in geometry, undefined terms like “point” and “line” are primitives. The primitive in causal inference is the relation of “listening to,” indicated by an arrow.\nNOTES TO CHAPTER TWO And now the algebraic magic: For anyone who takes the trouble to read Wright’s paper, let me warn you that he does not compute his path coefficients in grams per day. He computes them in “standard units” and then converts to grams per day at the end.\nNOTES TO CHAPTER FIVE “Cigarette smoking is causally related”: The evidence for women was less clear at that time, primarily because women had smoked much less than men in the early decades of the century.\nNOTES TO CHAPTER EIGHT And Abraham drew near: As before, I have used the King James translation but made small changes to align it more closely with the Hebrew.\nThe ease and familiarity of such: The 2013 Joint Statistical Meetings dedicated a whole session to the topic “Causal Inference as a Missing Data Problem”—Rubin’s traditional mantra. One provocative paper at that session was titled “What Is Not a Missing Data Problem?” This title sums up my thoughts precisely.\nThis difference in commitment: Readers who are seeing this distinction for the first time should not feel alone; there are well over 100,000 regression analysts in the United States who are confused by this very issue, together with most authors of statistical textbooks. Things will only change when readers of this book take those authors to task.\nUnfortunately, Rubin does not consider: “Pearl’s work is clearly interesting, and many researchers find his arguments that path diagrams are a natural and convenient way to express assumptions about causal structures appealing. In our own work, perhaps influenced by the type of examples arising in social and medical sciences, we have not found this approach to aid the drawing of causal inferences” (Imbens and Rubin 2013, p. 25).\nOne obstacle I faced was cyclic models: These are models with arrows that form a loop. I have avoided discussing them in this book, but such models are quite important in economics, for example.\nEven today modern-day economists: Between 1995 and 1998, I presented the following toy puzzle to hundreds of econometrics students and faculty across the United States: Consider the classical supply-and-demand equations that every economics student solves in Economics 101.\n\nWhat is the expected value of the demand Q if the price is reported to be P = p ? 0\nWhat is the expected value of the demand Q if the price is set to P = p ? 0\nGiven that the current price is P = p , what would the expected 0 value of the demand Q be if we were to set the price at P = p ? 1 The reader should recognize these queries as coming from the three levels of the Ladder of Causation: predictions, actions, and counterfactuals. As I expected, respondents had no trouble answering question 1, one person (a distinguished professor) was able to solve question 2, and nobody managed to answer question 3.\n\nThe Model Penal Code expresses: This is a set of standard legal principles proposed by the American Law Institute in 1962 to bring uniformity to the various state legal codes. It does not have full legal force in any state, but according to Wikipedia, as of 2016, more than two-thirds of the states have enacted parts of the Model Penal Code.\nNOTES TO CHAPTER NINE Those sailors who had eaten: The reason is that polar bear livers do contain vitamin C.\n“On the Inadequacy of the Partial”: The title refers to partial correlation, a standard method of controlling for a confounder that we discussed in Chapter 7.\nhere is how to define the NIE: In the original delivery room, NIE was expressed using nested subscripts, as in Y . I hope the reader will find (0,M1) the mixture of counterfactual subscripts and do-operators above more transparent.\nIn that year researchers identified: To be technically correct it should be called a “single nucleotide polymorphism,” or SNP. It is a single letter in the genetic code, while a gene is more like a word or a sentence. However, in order not to burden the reader with unfamiliar terminology, I will simply refer to it as a gene.",
    "crumbs": [
      "Causal Inference",
      "The book of why"
    ]
  },
  {
    "objectID": "extracted/The Book of Why - Judea Pearl.html#bibliography",
    "href": "extracted/The Book of Why - Judea Pearl.html#bibliography",
    "title": "The book of why",
    "section": "BIBLIOGRAPHY",
    "text": "BIBLIOGRAPHY\nINTRODUCTION: MIND OVER DATA\nAnnotated Bibliography The history of probability and statistics from antiquity to modern days is covered in depth by Hacking (1990); Stigler (1986, 1999, 2016). A less technical account is given in Salsburg (2002). Comprehensive accounts of the history of causal thought are unfortunately lacking, though interesting material can be found in Hoover (2008); Kleinberg (2015); Losee (2012); Mumford and Anjum (2014). The prohibition on causal talk can be seen in almost every standard statistical text, for example, Freedman, Pisani, and Purves (2007) or Efron and Hastie (2016). For an analysis of this prohibition as a linguistic impediment, see Pearl (2009, Chapters 5 and 11), and as a cultural barrier, see Pearl (2000b).\nRecent accounts of the achievements and limitations of Big Data and machine learning are Darwiche (2017); Pearl (2017); Mayer-Schönberger and Cukier (2013); Domingos (2015); Marcus (July 30, 2017). Toulmin (1961) provides historical context to this debate.\nReaders interested in “model discovery” and more technical treatments of the do-operator can consult Pearl (1994, 2000a, Chapters 2–3); Spirtes, Glymour, and Scheines (2000). For a gentler introduction, see Pearl, Glymour, and Jewell (2016). This last source is recommended for readers with college-level mathematical skills but no background in statistics or computer science. It also provides basic introduction to conditional probabilities, Bayes’s rule, regression, and graphs.\nEarlier versions of the inference engine shown in Figure 1.1 can be found in Pearl (2012); Pearl and Bareinboim (2014).\nReferences Darwiche, A. (2017). Human-level intelligence or animal-like abilities? Tech.\nrep., Department of Computer Science, University of California, Los Angeles, CA. Submitted to Communications of the ACM. Accessed online at https://arXiv:1707.04327.\nDomingos, P. (2015). The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World. Basic Books, New York, NY.\nEfron, B., and Hastie, T. (2016). Computer Age Statistical Inference.\nCambridge University Press, New York, NY.\nFreedman, D., Pisani, R., and Purves, R. (2007). Statistics. 4th ed. W. W.\nNorton & Company, New York, NY.\nHacking, I. (1990). The Taming of Chance (Ideas in Context). Cambridge University Press, Cambridge, UK.\nHoover, K. (2008). Causality in economics and econometrics. In The New Palgrave Dictionary of Economics (S. Durlauf and L. Blume, eds.), 2nd ed.\nPalgrave Macmillan, New York, NY.\nKleinberg, S. (2015). Why: A Guide to Finding and Using Causes. O’Reilly Media, Sebastopol, CA.\nLosee, J. (2012). Theories of Causality: From Antiquity to the Present.\nRoutledge, New York, NY.\nMarcus, G. (July 30, 2017). Artificial intelligence is stuck. Here’s how to move it forward. New York Times, SR6.\nMayer-Schönberger, V., and Cukier, K. (2013). Big Data: A Revolution That Will Transform How We Live, Work, and Think. Houghton Mifflin Harcourt Publishing, New York, NY.\nMorgan, S., and Winship, C. (2015). Counterfactuals and Causal Inference: Methods and Principles for Social Research (Analytical Methods for Social Research). 2nd ed. Cambridge University Press, New York, NY.\nMumford, S., and Anjum, R. L. (2014). Causation: A Very Short Introduction (Very Short Introductions). Oxford University Press, New York, NY.\nPearl, J. (1988). Probabilistic Reasoning in Intelligent Systems. Morgan Kaufmann, San Mateo, CA.\nPearl, J. (1994). A probabilistic calculus of actions. In Uncertainty in Artificial Intelligence 10 (R. L. de Mantaras and D. Poole, eds.). Morgan Kaufmann, San Mateo, CA, 454–462.\nPearl, J. (1995). Causal diagrams for empirical research. Biometrika 82: 669– 710.\nPearl, J. (2000a). Causality: Models, Reasoning, and Inference. Cambridge University Press, New York, NY.\nPearl, J. (2000b). Comment on A. P. Dawid’s Causal inference without counterfactuals. Journal of the American Statistical Association 95: 428– 431.\nPearl, J. (2009). Causality: Models, Reasoning, and Inference. 2nd ed.\nCambridge University Press, New York, NY.\nPearl, J. (2012). The causal foundations of structural equation modeling. In Handbook of Structural Equation Modeling (R. Hoyle, ed.). Guilford Press, New York, NY, 68–91.\nPearl, J. (2017). Advances in deep neural networks, at ACM Turing 50 Celebration. Available at: https://www.youtube.com/watch?v =mFYM9j8bGtg (June 23, 2017).\nPearl, J., and Bareinboim, E. (2014). External validity: From do-calculus to transportability across populations. Statistical Science 29: 579–595.\nPearl, J., Glymour, M., and Jewell, N. (2016). Causal Inference in Statistics: A Primer. Wiley, New York, NY.\nProvine, W. B. (1986). Sewall Wright and Evolutionary Biology. University of Chicago Press, Chicago, IL.\nSalsburg, D. (2002). The Lady Tasting Tea: How Statistics Revolutionized Science in the Twentieth Century. Henry Holt and Company, LLC, New York, NY.\nSpirtes, P., Glymour, C., and Scheines, R. (2000). Causation, Prediction, and Search. 2nd ed. MIT Press, Cambridge, MA.\nStigler, S. M. (1986). The History of Statistics: The Measurement of Uncertainty Before 1900. Belknap Press of Harvard University Press, Cambridge, MA.\nStigler, S. M. (1999). Statistics on the Table: The History of Statistical Concepts and Methods. Harvard University Press, Cambridge, MA.\nStigler, S. M. (2016). The Seven Pillars of Statistical Wisdom. Harvard University Press, Cambridge, MA.\nToulmin, S. (1961). Foresight and Understanding: An Enquiry into the Aims of Science. University of Indiana Press, Bloomington, IN.\nVirgil. (29 BC). Georgics. Verse 490, Book 2.\nCHAPTER 1. THE LADDER OF CAUSATION Annotated Bibliography A technical account of the distinctions between the three levels of the Ladder of Causation can be found in Chapter 1 of Pearl (2000).\nOur comparisons between the Ladder of Causation and human cognitive development were inspired by Harari (2015) and by the recent findings by Kind et al. (2014). Kind’s article contains details about the Lion Man and the site where it was found. Related research on the development of causal understanding in babies can be found in Weisberg and Gopnik (2013).\nThe Turing test was first proposed as an imitation game in 1950 (Turing, 1950). Searle’s “Chinese Room” argument appeared in Searle (1980) and has been widely discussed in the years since. See Russell and Norvig (2003); Preston and Bishop (2002); Pinker (1997).\nThe use of model modification to represent intervention has its conceptual roots with the economist Trygve Haavelmo (1943); see Pearl (2015) for a detailed account. Spirtes, Glymour, and Scheines (1993) gave it a graphical representation in terms of arrow deletion. Balke and Pearl (1994a, 1994b) extended it to simulate counterfactual reasoning, as demonstrated in the firing squad example.\nA comprehensive summary of probabilistic causality is given in Hitchcock (2016). Key ideas can be found in Reichenbach (1956); Suppes (1970); Cartwright (1983); Spohn (2012). My analyses of probabilistic causality and probability raising are presented in Pearl (2000; 2009, Section 7.5; 2011).\nReferences Balke, A., and Pearl, J. (1994a). Counterfactual probabilities: Computational methods, bounds, and applications. In Uncertainty in Artificial Intelligence 10 (R. L. de Mantaras and D. Poole, eds.). Morgan Kaufmann, San Mateo, CA, 46–54.\nBalke, A., and Pearl, J. (1994b). Probabilistic evaluation of counterfactual queries. In Proceedings of the Twelfth National Conference on Artificial Intelligence, vol. 1. MIT Press, Menlo Park, CA, 230–237.\nCartwright, N. (1983). How the Laws of Physics Lie. Clarendon Press, Oxford, UK.\nHaavelmo, T. (1943). The statistical implications of a system of simultaneous equations. Econometrica 11: 1–12. Reprinted in D. F. Hendry and M. S.\nMorgan (Eds.), The Foundations of Econometric Analysis, Cambridge University Press, Cambridge, UK, 477–490, 1995.\nHarari, Y. N. (2015). Sapiens: A Brief History of Humankind. Harper Collins Publishers, New York, NY.\nHitchcock, C. (2016). Probabilistic causation. In Stanford Encyclopedia of Philosophy (Winter 2016) (E. N. Zalta, ed.). Metaphysics Research Lab, Stanford, CA. Available at: https://stanford.library .sydney.edu.au/archives/win2016/entries/causation-probabilistic.\nKind, C.-J., Ebinger-Rist, N., Wolf, S., Beutelspacher, T., and Wehrberger, K.\n(2014). The smile of the Lion Man. Recent excavations in Stadel cave (Baden-Württemberg, south-western Germany) and the restoration of the famous upper palaeolithic figurine. Quartär 61: 129–145.\nPearl, J. (2000). Causality: Models, Reasoning, and Inference. Cambridge University Press, New York, NY.\nPearl, J. (2009). Causality: Models, Reasoning, and Inference. 2nd ed.\nCambridge University Press, New York, NY.\nPearl, J. (2011). The structural theory of causation. In Causality in the Sciences (P. M. Illari, F. Russo, and J. Williamson, eds.), chap. 33.\nClarendon Press, Oxford, UK, 697–727.\nPearl, J. (2015). Trygve Haavelmo and the emergence of causal calculus.\nEconometric Theory 31: 152–179. Special issue on Haavelmo centennial.\nPinker, S. (1997). How the Mind Works. W. W. Norton and Company, New York, NY.\nPreston, J., and Bishop, M. (2002). Views into the Chinese Room: New Essays on Searle and Artificial Intelligence. Oxford University Press, New York, NY.\nReichenbach, H. (1956). The Direction of Time. University of California Press, Berkeley, CA.\nRussell, S. J., and Norvig, P. (2003). Artificial Intelligence: A Modern Approach. 2nd ed. Prentice Hall, Upper Saddle River, NJ.\nSearle, J. (1980). Minds, brains, and programs. Behavioral and Brain Sciences 3: 417–457.\nSpirtes, P., Glymour, C., and Scheines, R. (1993). Causation, Prediction, and Search. Springer-Verlag, New York, NY.\nSpohn, W. (2012). The Laws of Belief: Ranking Theory and Its Philosophical Applications. Oxford University Press, Oxford, UK.\nSuppes, P. (1970). A Probabilistic Theory of Causality. North-Holland Publishing Co., Amsterdam, Netherlands.\nTuring, A. (1950). Computing machinery and intelligence. Mind 59: 433–460.\nWeisberg, D. S., and Gopnik, A. (2013). Pretense, counterfactuals, and Bayesian causal models: Why what is not real really matters. Cognitive Science 37: 1368–1381.\nCHAPTER 2. FROM BUCCANEERS TO GUINEA PIGS: THE GENESIS OF CAUSAL INFERENCE Annotated Bibliography Galton’s explorations of heredity and correlation are described in his books (Galton, 1869, 1883, 1889) and are also documented in Stigler (2012, 2016).\nFor a basic introduction to the Hardy-Weinberg equilibrium, see Wikipedia (2016a). For the origin of Galileo’s quote “E pur si muove,” see Wikipedia (2016b). The story of the Paris catacombs and Pearson’s shock at correlations induced by “artificial mixtures” can be found in Stigler (2012, p. 9).\nBecause Wright lived such a long life, he had the rare privilege of seeing a biography (Provine, 1986) come out while he was still alive. Provine’s biography is still the best place to learn about Wright’s career, and we particularly recommend Chapter 5 on path analysis. Crow’s two biographical sketches (Crow, 1982, 1990) also provide a very useful biographical perspective. Wright (1920) is the seminal paper on path diagrams; Wright (1921) is a fuller exposition and the source for the guinea pig birth-weight example. Wright (1983) is Wright’s response to Karlin’s critique, written when he was over ninety years old.\nThe fate of path analysis in economics and social science is narrated in Chapter 5 of Pearl (2000) and in Bollen and Pearl (2013). Blalock (1964), Duncan (1966), and Goldberger (1972) introduced Wright’s ideas to social science with great enthusiasm, but their theoretical underpinnings were not well articulated. A decade later, when Freedman (1987) challenged path analysts to explain how interventions are modelled, the enthusiasm disappeared, and leading researchers retreated to viewing SEM as an exercise in statistical analysis. This revealing discussion among twelve scholars is documented in the same issue of the Journal of Educational Statistics as Freedman’s article.\nThe reluctance of economists to embrace diagrams and structural notation is described in Pearl (2015). The painful consequences for economic education are documented in Chen and Pearl (2013).\nA popular exposition of the Bayesian-versus-frequentist debate is given in McGrayne (2011).\nMore technical discussions can be found in Efron (2013) and Lindley (1987).\nReferences Blalock, H., Jr. (1964). Causal Inferences in Nonexperimental Research.\nUniversity of North Carolina Press, Chapel Hill, NC.\nBollen, K., and Pearl, J. (2013). Eight myths about causality and structural equation models. In Handbook of Causal Analysis for Social Research (S.\nMorgan, ed.). Springer, Dordrecht, Netherlands, 301–328.\nChen, B., and Pearl, J. (2013). Regression and causation: A critical examination of econometrics textbooks. Real-World Economics Review 65: 2–20.\nCrow, J. F. (1982). Sewall Wright, the scientist and the man. Perspectives in Biology and Medicine 25: 279–294.\nCrow, J. F. (1990). Sewall Wright’s place in twentieth-century biology.\nJournal of the History of Biology 23: 57–89.\nDuncan, O. D. (1966). Path analysis. American Journal of Sociology 72: 1– 16.\nEfron, B. (2013). Bayes’ theorem in the 21st century. Science 340: 1177– 1178.\nFreedman, D. (1987). As others see us: A case study in path analysis (with discussion). Journal of Educational Statistics 12: 101–223.\nGalton, F. (1869). Hereditary Genius. Macmillan, London, UK.\nGalton, F. (1883). Inquiries into Human Faculty and Its Development.\nMacmillan, London, UK.\nGalton, F. (1889). Natural Inheritance. Macmillan, London, UK.\nGoldberger, A. (1972). Structural equation models in the social sciences.\nEconometrica: Journal of the Econometric Society 40: 979–1001.\nLindley, D. (1987). Bayesian Statistics: A Review. CBMS-NSF Regional Conference Series in Applied Mathematics (Book 2). Society for Industrial and Applied Mathematics, Philadelphia, PA.\nMcGrayne, S. B. (2011). The Theory That Would Not Die. Yale University Press, New Haven, CT.\nPearl, J. (2000). Causality: Models, Reasoning, and Inference. Cambridge University Press, New York, NY.\nPearl, J. (2015). Trygve Haavelmo and the emergence of causal calculus.\nEconometric Theory 31: 152–179. Special issue on Haavelmo centennial.\nProvine, W. B. (1986). Sewall Wright and Evolutionary Biology. University of Chicago Press, Chicago, IL.\nStigler, S. M. (2012). Studies in the history of probability and statistics, L: Karl Pearson and the rule of three. Biometrika 99: 1–14.\nStigler, S. M. (2016). The Seven Pillars of Statistical Wisdom. Harvard University Press, Cambridge, MA.\nWikipedia. (2016a). Hardy-Weinberg principle. Available at: https://en.wikipedia.org/wiki/Hardy-Weinberg-principle (last edited: October 2, 2016).\nWikipedia. (2016b). Galileo Galilei. Available at: https://en.wikipedia .org/wiki/Galileo_Galilei (last edited: October 6, 2017).\nWright, S. (1920). The relative importance of heredity and environment in determining the piebald pattern of guinea-pigs. Proceedings of the National Academy of Sciences of the United States of America 6: 320–332.\nWright, S. (1921). Correlation and causation. Journal of Agricultural Research 20: 557–585.\nWright, S. (1983). On “Path analysis in genetic epidemiology: A critique.” American Journal of Human Genetics 35: 757–768.\nCHAPTER 3. FROM EVIDENCE TO CAUSES: REVEREND BAYES MEETS MR. HOLMES Annotated Bibliography Elementary introductions to Bayes’s rule and Bayesian thinking can be found in Lindley (2014) and Pearl, Glymour, and Jewell (2016). Debates with competing representations of uncertainty are presented in Pearl (1988); see also the extensive list of references given there.\nOur mammogram data are based primarily on information from the Breast Cancer Surveillance Consortium (BCSC, 2009) and US Preventive Services Task Force (USPSTF, 2016) and are presented for instructional purposes only.\n“Bayesian networks” received their name in 1985 (Pearl, 1985) and were first presented as a model of self-activated memory. Applications to expert systems followed the development of belief updating algorithms for loopy networks (Pearl, 1986; Lauritzen and Spiegelhalter, 1988).\nThe concept of d-separation, which connects path blocking in a diagram to dependencies in the data, has its roots in the theory of graphoids (Pearl and Paz, 1985). The theory unveils the common properties of graphs (hence the name) and probabilities and explains why these two seemingly alien mathematical objects can support one another in so many ways. See also “Graphoid,” Wikipedia.\nThe amusing example of the bag on the airline flight can be found in Conrady and Jouffe (2015, Chapter 4).\nThe Malaysia Airlines Flight 17 disaster was well covered in the media; see Clark and Kramer (October 14, 2015) for an update on the investigation a year after the incident. Wiegerinck, Burgers, and Kappen (2013) describes how Bonaparte works. Further details on the identification of Flight 17 victims, including the pedigree shown in Figure 3.7, came from personal correspondence from W. Burgers to D. Mackenzie (August 24, 2016) and from a phone interview with W. Burgers and B. Kappen by D. Mackenzie (August 23, 2016).\nThe complex and fascinating story of turbo and low-density parity-check codes has not been told in a truly layman-friendly form, but good starting points are Costello and Forney (2007) and Hardesty (2010a, 2010b). The crucial realization that turbo codes work by the belief propagation algorithm stems from McEliece, David, and Cheng (1998).\nEfficient codes continue to be a battleground for wireless communications; Carlton (2016) takes a look at the current contenders for “5G” phones (due out in the 2020s).\nReferences Breast Cancer Surveillance Consortium (BCSC). (2009). Performance measures for 1,838,372 screening mammography examinations from 2004 to 2008 by age. Available at: http://www.bcsc-research .org/statistics/performance/screening/2009/perf_age.html (accessed October 12, 2016).\nCarlton, A. (2016). Surprise! Polar codes are coming in from the cold.\nComputerworld. Available at: https://www.computerworld.com/article/3151866/mobile-wireless/surprise- polar-codes-are-coming-in-from-the-cold.html (posted December 22, 2016).\nClark, N., and Kramer, A. (October 14, 2015). Malaysia Airlines Flight 17 most likely hit by Russian-made missile, inquiry says. New York Times.\nConrady, S., and Jouffe, L. (2015). Bayesian Networks and Bayesia Lab: A Practical Introduction for Researchers. Bayesia USA, Franklin, TN.\nCostello, D. J., and Forney, G. D., Jr. (2007). Channel coding: The road to channel capacity. Proceedings of IEEE 95: 1150–1177.\nHardesty, L. (2010a). Explained: Gallager codes. MIT News. Available at: http://news.mit.edu/2010/gallager-codes-0121 (posted: January 21, 2010).\nHardesty, L. (2010b). Explained: The Shannon limit. MIT News. Available at: http://news.mit.edu/2010/explained-shannon-0115 (posted January 19, 2010).\nLauritzen, S., and Spiegelhalter, D. (1988). Local computations with probabilities on graphical structures and their application to expert systems (with discussion). Journal of the Royal Statistical Society, Series B 50: 157–224.\nLindley, D. V. (2014). Understanding Uncertainty. Rev. ed. John Wiley and Sons, Hoboken, NJ.\nMcEliece, R. J., David, J. M., and Cheng, J. (1998). Turbo decoding as an instance of Pearl’s “belief propagation” algorithm. IEEE Journal on Selected Areas in Communications 16: 140–152.\nPearl, J. (1985). Bayesian networks: A model of self-activated memory for evidential reasoning. In Proceedings, Cognitive Science Society (CSS-7).\nUCLA Computer Science Department, Irvine, CA.\nPearl, J. (1986). Fusion, propagation, and structuring in belief networks.\nArtificial Intelligence 29: 241–288.\nPearl, J. (1988). Probabilistic Reasoning in Intelligent Systems. Morgan Kaufmann, San Mateo, CA.\nPearl, J., Glymour, M., and Jewell, N. (2016). Causal Inference in Statistics: A Primer. Wiley, New York, NY.\nPearl, J., and Paz, A. (1985). GRAPHOIDS: A graph-based logic for reasoning about relevance relations. Tech. Rep. 850038 (R-53-L).\nComputer Science Department, University of California, Los Angeles.\nShort version in B. DuBoulay, D. Hogg, and L. Steels (Eds.) Advances in Artificial Intelligence—II, Amsterdam, North Holland, 357–363, 1987.\nUS Preventive Services Task Force (USPSTF) (2016). Final recommendation statement: Breast cancer: Screening. Available at: https://www.uspreventiveservicestaskforce.org/Page/Document/RecommendationStatementFinal/breast- cancer-screening1 (updated: January 2016).\nWikipedia. (2018). Graphoid. Available at: https://en.wikipedia.org/wiki/Graphoid (last edited: January 8, 2018).\nWiegerinck, W., Burgers, W., and Kappen, B. (2013). Bayesian networks, introduction and practical applications. In Handbook on Neural Information Processing (M. Bianchini, M. Maggini, and L. C. Jain, eds.).\nIntelligent Systems Reference Library (Book 49). Springer, Berlin, Germany, 401–431.\nCHAPTER 4. CONFOUNDING AND DECONFOUNDING: OR, SLAYING THE LURKING VARIABLE Annotated Bibliography The story of Daniel has frequently been cited as the first controlled trial; see, for example, Lilienfeld (1982) or Stigler (2016). The results of the Honolulu walking study were reported in Hakim (1998).\nFisher Box’s lengthy quote about “the skillful interrogation of Nature” comes from her excellent biography of her father (Box, 1978, Chapter 6).\nFisher, too, wrote about experiments as a dialogue with Nature; see Stigler (2016). Thus I believe we can think of her quote as nearly coming from the patriarch himself, only more beautifully expressed.\nIt is fascinating to read Weinberg’s papers on confounding (Weinberg, 1993; Howards et al., 2012) back-to-back. They are like two snapshots of the history of confounding, one taken just before causal diagrams became widespread and the second taken twenty years later, revisiting the same examples using causal diagrams. Forbes’s complicated diagram of the causal network for asthma and smoking can be found in Williamson et al. (2014).\nMorabia’s “classic epidemiological definition of confounding” can be found in Morabia (2011). The quotes from David Cox come from Cox (1992, pp. 66–67). Other good sources on the history of confounding are Greenland and Robins (2009) and Wikipedia (2016).\nThe back-door criterion for eliminating confounding bias, together with its adjustment formula, were introduced in Pearl (1993). Its impact on epidemiology can be seen through Greenland, Pearl, and Robins (1999).\nExtensions to sequential interventions and other nuances are developed in Pearl (2000, 2009) and more gently described in Pearl, Glymour, and Jewell (2016). Software for computing causal effects using do-calculus is available in Tikka and Karvanen (2017).\nThe paper by Greenland and Robins (1986) was revisited by the authors a quarter century later, in light of the extensive developments since that time, including the advent of causal diagrams (Greenland and Robins, 2009).\nReferences Box, J. F. (1978). R. A. Fisher: The Life of a Scientist. John Wiley and Sons, New York, NY.\nCox, D. (1992). Planning of Experiments. Wiley-Interscience, New York, NY.\nGreenland, S., Pearl, J., and Robins, J. (1999). Causal diagrams for epidemiologic research. Epidemiology 10: 37–48.\nGreenland, S., and Robins, J. (1986). Identifiability, exchangeability, and epidemiological confounding. International Journal of Epidemiology 15: 413–419.\nGreenland, S., and Robins, J. (2009). Identifiability, exchangeability, and confounding revisited. Epidemiologic Perspectives & Innovations 6.\ndoi:10.1186/1742-5573-6-4.\nHakim, A. (1998). Effects of walking on mortality among nonsmoking retired men. New England Journal of Medicine 338: 94–99.\nHernberg, S. (1996). Significance testing of potential confounders and other properties of study groups—Misuse of statistics. Scandinavian Journal of Work, Environment and Health 22: 315–316.\nHowards, P. P., Schisterman, E. F., Poole, C., Kaufman, J. S., and Weinberg, C. R. (2012). “Toward a clearer definition of confounding” revisited with directed acyclic graphs. American Journal of Epidemiology 176: 506–511.\nLilienfeld, A. (1982). Ceteris paribus: The evolution of the clinical trial.\nBulletin of the History of Medicine 56: 1–18.\nMorabia, A. (2011). History of the modern epidemiological concept of confounding. Journal of Epidemiology and Community Health 65: 297– 300.\nPearl, J. (1993). Comment: Graphical models, causality, and intervention.\nStatistical Science 8: 266–269.\nPearl, J. (2000). Causality: Models, Reasoning, and Inference. Cambridge University Press, New York, NY.\nPearl, J. (2009). Causality: Models, Reasoning, and Inference. 2nd ed.\nCambridge University Press, New York, NY.\nPearl, J., Glymour, M., and Jewell, N. (2016). Causal Inference in Statistics: A Primer. Wiley, New York, NY.\nStigler, S. M. (2016). The Seven Pillars of Statistical Wisdom. Harvard University Press, Cambridge, MA.\nTikka, J., and Karvanen, J. (2017). Identifying causal effects with the R Package causaleffect. Journal of Statistical Software 76, no. 12.\ndoi:10.18637/jss.r076.i12.\nWeinberg, C. (1993). Toward a clearer definition of confounding. American Journal of Epidemiology 137: 1–8.\nWikipedia. (2016). Confounding. Available at: https://en.wikipedia .org/wiki/Confounding (accessed: September 16, 2016).\nWilliamson, E., Aitken, Z., Lawrie, J., Dharmage, S., Burgess, H., and Forbes, A. (2014). Introduction to causal diagrams for confounder selection.\nRespirology 19: 303–311.\nCHAPTER 5. THE SMOKE-FILLED DEBATE: CLEARING THE AIR Annotated Bibliography Two book-length studies, Brandt (2007) and Proctor (2012a), contain all the information any reader could ask for about the smoking–lung cancer debate, short of reading the actual tobacco company documents (which are available online). Shorter surveys of the smoking-cancer debate in the 1950s are Salsburg (2002, Chapter 18), Parascandola (2004), and Proctor (2012b).\nStolley (1991) takes a look at the unique role of R. A. Fisher, and Greenhouse (2009) comments on Jerome Cornfield’s importance. The shot heard around the world was Doll and Hill (1950), which first implicated smoking in lung cancer; though technical, it is a scientific classic.\nFor the story of the surgeon general’s committee and the emergence of the Hill guidelines for causation, see Blackburn and Labarthe (2012) and Morabia (2013). Hill’s own description of his criteria can be found in Hill (1965).\nLilienfeld (2007) is the source of the “Abe and Yak” story with which we began the chapter.\nVanderWeele (2014) and Hernández-Díaz, Schisterman, and Hernán (2006) resolve the birth-weight paradox using causal diagrams. An interesting “before-and-after” pair of articles is Wilcox (2001, 2006), written before and after the author learned about causal diagrams; his excitement in the latter article is palpable.\nReaders interested in the latest statistics and historical trends in cancer mortality and smoking may consult US Department of Health and Human Services (USDHHS, 2014), American Cancer Society (2017), and Wingo (2003).\nReferences American Cancer Society. (2017). Cancer facts and figures. Available at: https://www.cancer.org/research/cancer-facts-statistics.html (posted: February 19, 2015).\nBlackburn, H., and Labarthe, D. (2012). Stories from the evolution of guidelines for causal inference in epidemiologic associations: 1953–1965.\nAmerican Journal of Epidemiology 176: 1071–1077.\nBrandt, A. (2007). The Cigarette Century. Basic Books, New York, NY.\nDoll, R., and Hill, A. B. (1950). Smoking and carcinoma of the lung. British Medical Journal 2: 739–748.\nGreenhouse, J. (2009). Commentary: Cornfield, epidemiology, and causality.\nInternational Journal of Epidemiology 38: 1199–1201.\nHernández-Díaz, S., Schisterman, E., and Hernán, M. (2006). The birth weight “paradox” uncovered? American Journal of Epidemiology 164: 1115–1120.\nHill, A. B. (1965). The environment and disease: Association or causation? Journal of the Royal Society of Medicine 58: 295–300.\nLilienfeld, A. (2007). Abe and Yak: The interactions of Abraham M.\nLilienfeld and Jacob Yerushalmy in the development of modern epidemiology (1945–1973). Epidemiology 18: 507–514.\nMorabia, A. (2013). Hume, Mill, Hill, and the sui generis epidemiologic approach to causal inference. American Journal of Epidemiology 178: 1526–1532.\nParascandola, M. (2004). Two approaches to etiology: The debate over smoking and lung cancer in the 1950s. Endeavour 28: 81–86.\nProctor, R. (2012a). Golden Holocaust: Origins of the Cigarette Catastrophe and the Case for Abolition. University of California Press, Berkeley, CA.\nProctor, R. (2012b). The history of the discovery of the cigarette–lung cancer link: Evidentiary traditions, corporate denial, and global toll. Tobacco Control 21: 87–91.\nSalsburg, D. (2002). The Lady Tasting Tea: How Statistics Revolutionized Science in the Twentieth Century. Henry Holt and Company, New York, NY.\nStolley, P. (1991). When genius errs: R. A. Fisher and the lung cancer controversy. American Journal of Epidemiology 133: 416–425.\nUS Department of Health and Human Services (USDHHS). (2014). The health consequences of smoking—50 years of progress: A report of the surgeon general. USDHHS and Centers for Disease Control and Prevention, Atlanta, GA.\nVanderWeele, T. (2014). Commentary: Resolutions of the birthweight paradox: Competing explanations and analytical insights. International Journal of Epidemiology 43: 1368–1373.\nWilcox, A. (2001). On the importance—and the unimportance—of birthweight. International Journal of Epidemiology 30: 1233–1241.\nWilcox, A. (2006). The perils of birth weight—A lesson from directed acyclic graphs. American Journal of Epidemiology 164: 1121–1123.\nWingo, P. (2003). Long-term trends in cancer mortality in the United States, 1930–1998. Cancer 97: 3133–3275.\nCHAPTER 6. PARADOXES GALORE! Annotated Bibliography The Monty Hall paradox appears in many introductory books on probability theory (e.g., Grinstead and Snell, 1998, p. 136; Lindley, 2014, p. 201). The equivalent “three prisoners dilemma” was used to demonstrate the inadequacy of non-Bayesian approaches in Pearl (1988, pp. 58–62).\nTierney (July 21, 1991) and Crockett (2015) tell the amazing story of vos Savant’s column on the Monty Hall paradox; Crockett gives several other entertaining and embarrassing comments that vos Savant received from so- called experts. Tierney’s article tells what Monty Hall himself thought of the fuss—an interesting human-interest angle! An extensive account of the history of Simpson’s paradox is given in Pearl (2009, pp. 174–182), including many attempts by statisticians and philosophers to resolve it without invoking causation. A more recent account, geared for educators, is given in Pearl (2014).\nSavage (2009), Julious and Mullee (1994), and Appleton, French, and Vanderpump (1996) give the three real-world examples of Simpson’s paradox mentioned in the text (relating to baseball, kidney stones, and smoking, respectively).\nSavage’s sure-thing principle (Savage, 1954) is treated in Pearl (2016b), and its corrected causal version is derived in Pearl (2009, pp. 181–182).\nVersions of Lord’s paradox (Lord, 1967) are described in Glymour (2006); Hernández-Díaz, Schisterman, and Hernán (2006); Senn (2006); Wainer (1991). A comprehensive analysis can be found in Pearl (2016a).\nParadoxes invoking counterfactuals are not included in this chapter but are no less intriguing. For a sample, see Pearl (2013).\nReferences Appleton, D., French, J., and Vanderpump, M. (1996). Ignoring a covariate: An example of Simpson’s paradox. American Statistician 50: 340–341.\nCrockett, Z. (2015). The time everyone “corrected” the world’s smartest woman. Priceonomics. Available at: http://priceonomics.com/the-time- everyone-corrected-the-worlds-smartest (posted: February 19, 2015).\nGlymour, M. M. (2006). Using causal diagrams to understand common problems in social epidemiology. In Methods in Social Epidemiology. John Wiley and Sons, San Francisco, CA, 393–428.\nGrinstead, C. M., and Snell, J. L. (1998). Introduction to Probability. 2nd rev.\ned. American Mathematical Society, Providence, RI.\nHernández-Díaz, S., Schisterman, E., and Hernán, M. (2006). The birth weight “paradox” uncovered? American Journal of Epidemiology 164: 1115–1120.\nJulious, S., and Mullee, M. (1994). Confounding and Simpson’s paradox.\nBritish Medical Journal 309: 1480–1481.\nLindley, D. V. (2014). Understanding Uncertainty. Rev. ed. John Wiley and Sons, Hoboken, NJ.\nLord, F. M. (1967). A paradox in the interpretation of group comparisons.\nPsychological Bulletin 68: 304–305.\nPearl, J. (1988). Probabilistic Reasoning in Intelligent Systems. Morgan Kaufmann, San Mateo, CA.\nPearl, J. (2009). Causality: Models, Reasoning, and Inference. 2nd ed.\nCambridge University Press, New York, NY.\nPearl, J. (2013). The curse of free-will and paradox of inevitable regret.\nJournal of Causal Inference 1: 255–257.\nPearl, J. (2014). Understanding Simpson’s paradox. American Statistician 88: 8–13.\nPearl, J. (2016a). Lord’s paradox revisited—(Oh Lord! Kumbaya!). Journal of Causal Inference 4. doi:10.1515/jci-2016-0021.\nPearl, J. (2016b). The sure-thing principle. Journal of Causal Inference 4: 81– 86.\nSavage, L. (1954). The Foundations of Statistics. John Wiley and Sons, New York, NY.\nSavage, S. (2009). The Flaw of Averages: Why We Underestimate Risk in the Face of Uncertainty. John Wiley and Sons, Hoboken, NJ.\nSenn, S. (2006). Change from baseline and analysis of covariance revisited.\nStatistics in Medicine 25: 4334–4344.\nSimon, H. (1954). Spurious correlation: A causal interpretation. Journal of the American Statistical Association 49: 467–479.\nTierney, J. (July 21, 1991). Behind Monty Hall’s doors: Puzzle, debate and answer? New York Times.\nWainer, H. (1991). Adjusting for differential base rates: Lord’s paradox again.\nPsychological Bulletin 109: 147–151.\nCHAPTER 7. BEYOND ADJUSTMENT: THE CONQUEST OF MOUNT INTERVENTION Annotated Bibliography Extensions of the back-door and front-door adjustments were first reported in Tian and Pearl (2002) based on Tian’s c-component factorization. These were followed by Shpitser’s algorithmization of the do-calculus (Shpitser and Pearl, 2006a) and then the completeness results of Shpitser and Pearl (2006b) and Huang and Valtorta (2006).\nThe economists among our readers should note that the cultural resistance of some economists to graphical tools of analysis (Heckman and Pinto, 2015; Imbens and Rubin, 2015) is not shared by all economists. White and Chalak (2009), for example, have generalized and applied the do-calculus to economic systems involving equilibrium and learning. Recent textbooks in the social and behavioral sciences, Morgan and Winship (2007) and Kline (2016), further signal to young researchers that cultural orthodoxy, like the fear of telescopes in the seventeenth century, is not long lasting in the sciences.\nJohn Snow’s investigation of cholera was very little appreciated during his lifetime, and his one-paragraph obituary in Lancet did not even mention it.\nRemarkably, the premier British medical journal “corrected” its obituary 155 years later (Hempel, 2013). For more biographical material on Snow, see Hill (1955) and Cameron and Jones (1983). Glynn and Kashin (2018) is one of the first papers to demonstrate empirically that front-door adjustment is superior to back-door adjustment when there are unobserved confounders. Freedman’s critique of the smoking–tar–lung cancer example can be found in a chapter of Freedman (2010) titled “On Specifying Graphical Models for Causation.” Introductions to instrumental variables can be found in Greenland (2000) and in many textbooks of econometrics (e.g., Bowden and Turkington, 1984; Wooldridge, 2013).\nGeneralized instrumental variables, extending the classical definition given in our text, were introduced in Brito and Pearl (2002).\nThe program DAGitty (available online at http://www.dagitty.net/dags.html) permits users to search the diagram for generalized instrumental variables and reports the resulting estimands (Textor, Hardt, and Knüppel, 2011). Another diagram-based software package for decision making is BayesiaLab (www.bayesia.com).\nBounds on instrumental variable estimates are studied at length in Chapter 8 of Pearl (2009) and are applied to the problem of noncompliance. The LATE approximation is advocated and debated in Imbens (2010).\nReferences Bareinboim, E., and Pearl, J. (2012). Causal inference by surrogate experiments: z-identifiability. In Proceedings of the Twenty-Eighth Conference on Uncertainty in Artificial Intelligence (N. de Freitas and K.\nMurphy, eds.). AUAI Press, Corvallis, OR.\nBowden, R., and Turkington, D. (1984). Instrumental Variables. Cambridge University Press, Cambridge, UK.\nBrito, C., and Pearl, J. (2002). Generalized instrumental variables. In Uncertainty in Artificial Intelligence, Proceedings of the Eighteenth Conference (A. Darwiche and N. Friedman, eds.). Morgan Kaufmann, San Francisco, CA, 85–93.\nCameron, D., and Jones, I. (1983). John Snow, the Broad Street pump, and modern epidemiology. International Journal of Epidemiology 12: 393–396.\nCox, D., and Wermuth, N. (2015). Design and interpretation of studies: Relevant concepts from the past and some extensions. Observational Studies 1. Available at: https://arxiv.org/pdf/1505.02452 .pdf.\nFreedman, D. (2010). Statistical Models and Causal Inference: A Dialogue with the Social Sciences. Cambridge University Press, New York, NY.\nGlynn, A., and Kashin, K. (2018). Front-door versus back-door adjustment with unmeasured confounding: Bias formulas for front-door and hybrid adjustments. Journal of the American Statistical Association. To appear.\nGreenland, S. (2000). An introduction to instrumental variables for epidemiologists. International Journal of Epidemiology 29: 722–729.\nHeckman, J. J., and Pinto, R. (2015). Causal analysis after Haavelmo.\nEconometric Theory 31: 115–151.\nHempel, S. (2013). Obituary: John Snow. Lancet 381: 1269–1270.\nHill, A. B. (1955). Snow—An appreciation. Journal of Economic Perspectives 48: 1008–1012.\nHuang, Y., and Valtorta, M. (2006). Pearl’s calculus of intervention is complete. In Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence (R. Dechter and T. Richardson, eds.). AUAI Press, Corvallis, OR, 217–224.\nImbens, G. W. (2010). Better LATE than nothing: Some comments on Deaton (2009) and Heckman and Urzua (2009). Journal of Economic Literature 48: 399–423.\nImbens, G. W., and Rubin, D. B. (2015). Causal Inference for Statistics, Social, and Biomedical Sciences: An Introduction. Cambridge University Press, Cambridge, MA.\nKline, R. B. (2016). Principles and Practice of Structural Equation Modeling.\n3rd ed. Guilford, New York, NY.\nMorgan, S., and Winship, C. (2007). Counterfactuals and Causal Inference: Methods and Principles for Social Research (Analytical Methods for Social Research). Cambridge University Press, New York, NY.\nPearl, J. (2009). Causality: Models, Reasoning, and Inference. 2nd ed.\nCambridge University Press, New York, NY.\nPearl, J. (2013). Reflections on Heckman and Pinto’s “Causal analysis after Haavelmo.” Tech. Rep. R-420. Department of Computer Science, University of California, Los Angeles, CA. Working paper.\nPearl, J. (2015). Indirect confounding and causal calculus (on three papers by Cox and Wermuth). Tech. Rep. R-457. Department of Computer Science, University of California, Los Angeles, CA.\nShpitser, I., and Pearl, J. (2006a). Identification of conditional interventional distributions. In Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence (R. Dechter and T. Richardson, eds.).\nAUAI Press, Corvallis, OR, 437–444.\nShpitser, I., and Pearl, J. (2006b). Identification of joint interventional distributions in recursive semi-Markovian causal models. In Proceedings of the Twenty-First National Conference on Artificial Intelligence. AAAI Press, Menlo Park, CA, 1219–1226.\nStock, J., and Trebbi, F. (2003). Who invented instrumental variable regression? Journal of Economic Perspectives 17: 177–194.\nTextor, J., Hardt, J., and Knüppel, S. (2011). DAGitty: A graphical tool for analyzing causal diagrams. Epidemiology 22: 745.\nTian, J., and Pearl, J. (2002). A general identification condition for causal effects. In Proceedings of the Eighteenth National Conference on Artificial Intelligence. AAAI Press/MIT Press, Menlo Park, CA, 567–573.\nWermuth, N., and Cox, D. (2008). Distortion of effects caused by indirect confounding. Biometrika 95: 17–33. (See Pearl [2009, Chapter 4] for a general solution.) Wermuth, N., and Cox, D. (2014). Graphical Markov models: Overview.\nArXiv: 1407.7783.\nWhite, H., and Chalak, K. (2009). Settable systems: An extension of Pearl’s causal model with optimization, equilibrium and learning. Journal of Machine Learning Research 10: 1759–1799.\nWooldridge, J. (2013). Introductory Econometrics: A Modern Approach. 5th ed. South-Western, Mason, OH.\nCHAPTER 8. COUNTERFACTUALS: MINING WORLDS THAT COULD HAVE BEEN Annotated Bibliography The definition of counterfactuals as derivatives of structural equations was introduced by Balke and Pearl (1994a, 1994b) and was used to estimate probabilities of causation in legal settings. The relationships between this framework and those developed by Rubin and Lewis are discussed at length in Pearl (2000, Chapter 7), where they are shown to be logically equivalent; a problem solved in one framework would yield the same solution in another.\nRecent books in social science (e.g., Morgan and Winship, 2015) and in health science (e.g., VanderWeele, 2015) are taking the hybrid, graph- counterfactual approach pursued in our book.\nThe section on linear counterfactuals is based on Pearl (2009, pp. 389– 391), which also provides the solution to the problem posed in note 12. Our discussion of ETT is based on Shpitser and Pearl (2009).\nLegal questions of attribution, as well as probabilities of causation, are discussed at length in Greenland (1999), who pioneered the counterfactual approach to such questions. Our treatment of PN, PS, and PNS is based on Tian and Pearl (2000) and Pearl (2009, Chapter 9). A gentle approach to counterfactual attribution, including a tool kit for estimation, is given in Pearl, Glymour, and Jewell (2016). An advanced formal treatment of actual causation can be found in Halpern (2016).\nMatching techniques for estimating causal effects are used routinely by potential outcome researchers (Sekhon, 2007), though they usually ignore the pitfalls shown in our education-experience-salary example. My realization that missing-data problems should be viewed in the context of causal modeling was formed through the analysis of Mohan and Pearl (2014).\nCowles (2016) and Reid (1998) tell the story of Neyman’s tumultuous years in London, including the anecdote about Fisher and the wooden models.\nGreiner (2008) is a long and substantive introduction to “but-for” causation in the law. Allen (2003), Stott et al. (2013), Trenberth (2012), and Hannart et al.\n\naddress the problem of attribution of weather events to climate change, and Hannart in particular invokes the ideas of necessary and sufficient probability, which bring more clarity to the subject.\n\nReferences Allen, M. (2003). Liability for climate change. Nature 421: 891–892.\nBalke, A., and Pearl, J. (1994a). Counterfactual probabilities: Computational methods, bounds, and applications. In Uncertainty in Artificial Intelligence 10 (R. L. de Mantaras and D. Poole, eds.). Morgan Kaufmann, San Mateo, CA, 46–54.\nBalke, A., and Pearl, J. (1994b). Probabilistic evaluation of counterfactual queries. In Proceedings of the Twelfth National Conference on Artificial Intelligence, vol. 1. MIT Press, Menlo Park, CA, 230–237.\nCowles, M. (2016). Statistics in Psychology: An Historical Perspective. 2nd ed. Routledge, New York, NY.\nDuncan, O. (1975). Introduction to Structural Equation Models. Academic Press, New York, NY.\nFreedman, D. (1987). As others see us: A case study in path analysis (with discussion). Journal of Educational Statistics 12: 101–223.\nGreenland, S. (1999). Relation of probability of causation, relative risk, and doubling dose: A methodologic error that has become a social problem.\nAmerican Journal of Public Health 89: 1166–1169.\nGreiner, D. J. (2008). Causal inference in civil rights litigation. Harvard Law Review 81: 533–598.\nHaavelmo, T. (1943). The statistical implications of a system of simultaneous equations. Econometrica 11: 1–12. Reprinted in D. F. Hendry and M. S.\nMorgan (Eds.), The Foundations of Econometric Analysis, Cambridge University Press, Cambridge, UK, 477–490, 1995.\nHalpern, J. (2016). Actual Causality. MIT Press, Cambridge, MA.\nHannart, A., Pearl, J., Otto, F., Naveu, P., and Ghil, M. (2016). Causal counterfactual theory for the attribution of weather and climate-related events. Bulletin of the American Meteorological Society (BAMS) 97: 99– 110.\nHolland, P. (1986). Statistics and causal inference. Journal of the American Statistical Association 81: 945–960.\nHume, D. (1739). A Treatise of Human Nature. Oxford University Press, Oxford, UK. Reprinted 1888.\nHume, D. (1748). An Enquiry Concerning Human Understanding. Reprinted Open Court Press, LaSalle, IL, 1958.\nJoffe, M. M., Yang, W. P., and Feldman, H. I. (2010). Selective ignorability assumptions in causal inference. International Journal of Biostatistics 6.\ndoi:10.2202/1557-4679.1199.\nLewis, D. (1973a). Causation. Journal of Philosophy 70: 556–567. Reprinted with postscript in D. Lewis, Philosophical Papers, vol. 2, Oxford University Press, New York, NY, 1986.\nLewis, D. (1973b). Counterfactuals. Harvard University Press, Cambridge, MA.\nLewis, M. (2016). The Undoing Project: A Friendship That Changed Our Minds. W. W. Norton and Company, New York, NY.\nMohan, K., and Pearl, J. (2014). Graphical models for recovering probabilistic and causal queries from missing data. Proceedings of Neural Information Processing 27: 1520–1528.\nMorgan, S., and Winship, C. (2015). Counterfactuals and Causal Inference: Methods and Principles for Social Research (Analytical Methods for Social Research). 2nd ed. Cambridge University Press, New York, NY.\nNeyman, J. (1923). On the application of probability theory to agricultural experiments. Essay on principles. Section 9. Statistical Science 5: 465–480.\nPearl, J. (2000). Causality: Models, Reasoning, and Inference. Cambridge University Press, New York, NY.\nPearl, J. (2009). Causality: Models, Reasoning, and Inference. 2nd ed.\nCambridge University Press, New York, NY.\nPearl, J., Glymour, M., and Jewell, N. (2016). Causal Inference in Statistics: A Primer. Wiley, New York, NY.\nReid, C. (1998). Neyman. Springer-Verlag, New York, NY.\nRubin, D. (1974). Estimating causal effects of treatments in randomized and nonrandomized studies. Journal of Educational Psychology 66: 688–701.\nSekhon, J. (2007). The Neyman-Rubin model of causal inference and estimation via matching methods. In The Oxford Handbook of Political Methodology (J. M. Box-Steffensmeier, H. E. Brady, and D. Collier, eds.).\nOxford University Press, Oxford, UK.\nShpitser, I., and Pearl, J. (2009). Effects of treatment on the treated: Identification and generalization. In Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence. AUAI Press, Montreal, Quebec, 514–521.\nStott, P. A., Allen, M., Christidis, N., Dole, R. M., Hoerling, M., Huntingford, C., Pardeep Pall, J. P., and Stone, D. (2013). Attribution of weather and climate-related events. In Climate Science for Serving Society: Research, Modeling, and Prediction Priorities (G. R. Asrar and J. W. Hurrell, eds.).\nSpringer, Dordrecht, Netherlands, 449–484.\nTian, J., and Pearl, J. (2000). Probabilities of causation: Bounds and identification. Annals of Mathematics and Artificial Intelligence 28: 287– 313.\nTrenberth, K. (2012). Framing the way to relate climate extremes to climate change. Climatic Change 115: 283–290.\nVanderWeele, T. (2015). Explanation in Causal Inference: Methods for Mediation and Interaction. Oxford University Press, New York, NY.\nCHAPTER 9. MEDIATION: THE SEARCH FOR A MECHANISM Annotated Bibliography There are several books dedicated to the topic of mediation. The most up-to- date reference is VanderWeele (2015); MacKinnon (2008) also contains many examples. The dramatic transition from the statistical approach of Baron and Kenny (1986) to the counterfactual-based approach of causal mediation is described in Pearl (2014) and Kline (2015). McDonald’s quote (to discuss mediation, “start from scratch”) is taken from McDonald (2001).\nNatural direct and indirect effects were conceptualized in Robins and Greenland (1992) and deemed problematic. They were later formalized and legitimized in Pearl (2001), leading to the Mediation Formula.\nIn addition to the comprehensive text of VanderWeele (2015), new results and applications of mediation analysis can be found in De Stavola et al.\n(2015); Imai, Keele, and Yamamoto (2010); and Muthén and Asparouhov (2015). Shpitser (2013) provides a general criterion for estimating arbitrary path-specific effects in graphs.\nThe Mediation Fallacy and the fallacy of “conditioning” on a mediator are demonstrated in Pearl (1998) and Cole and Hernán (2002). Fisher’s falling for this fallacy is told in Rubin (2005), whereas Rubin’s dismissal of mediation analysis as “deceptive” is expressed in Rubin (2004).\nThe startling story of how the cure for scurvy was “lost” is told in Lewis (1972) and Ceglowski (2010). Barbara Burks’s story is told in King, Montañez Ramírez, and Wertheimer (1996); the quotes from Terman and Burks’s mother are drawn from the letters (L. Terman to R. Tolman, 1943).\nThe source paper for the Berkeley admissions paradox is Bickel, Hammel, and O’Connell (1975), and the ensuing correspondence between him and Kruskal is found in Fairley and Mosteller (1977).\nVanderWeele (2014) is the source for the “smoking gene” example, and Bierut and Cesarini (2015) tells the story of how the gene was discovered.\nThe surprising history of tourniquets, before and during the Gulf War, is told in Welling et al. (2012) and Kragh et al. (2013). The latter article is written in a personal and entertaining style that is quite unusual for a scholarly publication. Kragh et al. (2015) describes the research that unfortunately failed to prove that tourniquets improve the chances for survival.\nReferences Baron, R., and Kenny, D. (1986). The moderator-mediator variable distinction in social psychological research: Conceptual, strategic, and statistical considerations. Journal of Personality and Social Psychology 51: 1173– 1182.\nBickel, P. J., Hammel, E. A., and O’Connell, J. W. (1975). Sex bias in graduate admissions: Data from Berkeley. Science 187: 398–404.\nBierut, L., and Cesarini, D. (2015). How genetic and other biological factors interact with smoking decisions. Big Data 3: 198–202.\nBurks, B. S. (1926). On the inadequacy of the partial and multiple correlation technique (parts I–II). Journal of Experimental Psychology 17: 532–540, 625–630.\nBurks, F., to Mrs. Terman. (June 16, 1943). Correspondence. Lewis M.\nTerman Archives, Stanford University.\nCeglowski, M. (2010). Scott and scurvy. Idle Words (blog). Available at: http://www.idlewords.com/2010/03/scott_and_scurvy.htm (posted: March 6, 2010).\nCole, S., and Hernán, M. (2002). Fallibility in estimating direct effects.\nInternational Journal of Epidemiology 31: 163–165.\nDe Stavola, B. L., Daniel, R. M., Ploubidis, G. B., and Micali, N. (2015).\nMediation analysis with intermediate confounding. American Journal of Epidemiology 181: 64–80.\nFairley, W. B., and Mosteller, F. (1977). Statistics and Public Policy.\nAddison-Wesley, Reading, MA.\nImai, K., Keele, L., and Yamamoto, T. (2010). Identification, inference, and sensitivity analysis for causal mediation effects. Statistical Science 25: 51– 71.\nKing, D. B., Montañez Ramírez, L., and Wertheimer, M. (1996). Barbara Stoddard Burks: Pioneer behavioral geneticist and humanitarian. In Portraits of Pioneers in Psychology (C. W. G. A. Kimble and M.\nWertheimer, eds.), vol. 2. Erlbaum Associates, Hillsdale, NJ, 212–225.\nKline, R. B. (2015). The mediation myth. Chance 14: 202–213.\nKragh, J. F., Jr., Nam, J. J., Berry, K. A., Mase, V. J., Jr., Aden, J. K., III, Walters, T. J., Dubick, M. A., Baer, D. G., Wade, C. E., and Blackbourne, L. H. (2015). Transfusion for shock in U.S. military war casualties with and without tourniquet use. Annals of Emergency Medicine 65: 290–296.\nKragh, J. F., Jr., Walters, T. J., Westmoreland, T., Miller, R. M., Mabry, R. L., Kotwal, R. S., Ritter, B. A., Hodge, D. C., Greydanus, D. J., Cain, J. S., Parsons, D. S., Edgar, E. P., Harcke, T., Baer, D. G., Dubick, M. A., Blackbourne, L. H., Montgomery, H. R., Holcomb, J. B., and Butler, F. K.\n(2013). Tragedy into drama: An American history of tourniquet use in the current war. Journal of Special Operations Medicine 13: 5–25.\nLewis, H. (1972). Medical aspects of polar exploration: Sixtieth anniversary of Scott’s last expedition. Journal of the Royal Society of Medicine 65: 39– 42.\nMacKinnon, D. (2008). Introduction to Statistical Mediation Analysis.\nLawrence Erlbaum Associates, New York, NY.\nMcDonald, R. (2001). Structural equations modeling. Journal of Consumer Psychology 10: 92–93.\nMuthén, B., and Asparouhov, T. (2015). Causal effects in mediation modeling. Structural Equation Modeling 22: 12–23.\nPearl, J. (1998). Graphs, causality, and structural equation models.\nSociological Methods and Research 27: 226–284.\nPearl, J. (2001). Direct and indirect effects. In Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence. Morgan Kaufmann, San Francisco, CA, 411–420.\nPearl, J. (2014). Interpretation and identification of causal mediation.\nPsychological Methods 19: 459–481.\nRobins, J., and Greenland, S. (1992). Identifiability and exchangeability for direct and indirect effects. Epidemiology 3: 143–155.\nRubin, D. (2004). Direct and indirect causal effects via potential outcomes.\nScandinavian Journal of Statistics 31: 161–170.\nRubin, D. (2005). Causal inference using potential outcomes: Design, modeling, decisions. Journal of the American Statistical Association 100: 322–331.\nShpitser, I. (2013). Counterfactual graphical models for longitudinal mediation analysis with unobserved confounding. Cognitive Science 37: 1011–1035.\nTerman, L., to Tolman, R. (August 6, 1943). Correspondence. Lewis M.\nTerman Archives, Stanford University.\nVanderWeele, T. (2014). A unification of mediation and interaction: A four- way decomposition. Epidemiology 25: 749–761.\nVanderWeele, T. (2015). Explanation in Causal Inference: Methods for Mediation and Interaction. Oxford University Press, New York, NY.\nWelling, D., MacKay, P., Rasmussen, T., and Rich, N. (2012). A brief history of the tourniquet. Journal of Vascular Surgery 55: 286–290.\nCHAPTER 10. BIG DATA, ARTIFICIAL INTELLIGENCE, AND THE BIG QUESTIONS Annotated Bibliography An accessible source for the perpetual free will debate is Harris (2012). The compatibilist school of philosophers is represented in the writings of Mumford and Anjum (2014) and Dennett (2003).\nArtificial intelligence conceptualizations of agency can be found in Russell and Norvig (2003) and Wooldridge (2009). Philosophical views on agency are compiled in Bratman (2007). An intent-based learning system is described in Forney et al. (2017).\nThe twenty-three principles for “beneficial AI” agreed to at the 2017 Asilomar meeting can be found at Future of Life Institute (2017).\nReferences Bratman, M. E. (2007). Structures of Agency: Essays. Oxford University Press, New York, NY.\nBrockman, J. (2015). What to Think About Machines That Think.\nHarperCollins, New York, NY.\nDennett, D. C. (2003). Freedom Evolves. Viking Books, New York, NY.\nForney, A., Pearl, J., and Bareinboim, E. (2017). Counterfactual data-fusion for online reinforcement learners. Proceedings of the 34th International Conference on Machine Learning. Proceedings of Machine Learning Research 70: 1156–1164.\nFuture of Life Institute. (2017). Asilomar AI principles. Available at: https://futureoflife.org/ai-principles (accessed December 2, 2017).\nHarris, S. (2012). Free Will. Free Press, New York, NY.\nMumford, S., and Anjum, R. L. (2014). Causation: A Very Short Introduction (Very Short Introductions). Oxford University Press, New York, NY.\nRussell, S. J., and Norvig, P. (2003). Artificial Intelligence: A Modern Approach. 2nd ed. Prentice Hall, Upper Saddle River, NJ.\nWooldridge, J. (2009). Introduction to Multi-agent Systems. 2nd ed. John Wiley and Sons, New York, NY.",
    "crumbs": [
      "Causal Inference",
      "The book of why"
    ]
  },
  {
    "objectID": "extracted/The Book of Why - Judea Pearl.html#index",
    "href": "extracted/The Book of Why - Judea Pearl.html#index",
    "title": "The book of why",
    "section": "INDEX",
    "text": "INDEX\nAbbott, Robert, 141, 143\nabduction, 278, 280 ACE. See average causal effect acquisition, representation and, 38 action, in counterfactuals, 278, 280 agency, 367 AI. See artificial intelligence Allen, Myles, 291–294 American Cancer Society, 174, 178–179 anthropometric statistics, 58 Aristotle, 50, 264 artificial intelligence (AI), ix–x, 10 Bayesian networks in, 18, 93–94, 108–109, 112, 132 message-passing network of, 110–111, 111 (fig.) of robots, 291 Turing on, 27, 108–109 uncertainty in, 109 weak, 362 “why?” question in, 349 See also strong AI Asimov, Isaac, 370 association, 50, 340 causation and, 181, 189 in Ladder of Causation, 28 (fig.), 29–30, 51 pattern of, 311 specificity, strength of, 181 See also correlation, genome-wide association study assumptions, 12–13, 12 (fig.) astronomy, 5 attribution, 261, 291, 293, 393-394 average causal effect (ACE), 296–297 backdoor adjustment formula, 220–224 backdoor criterion and causal effects, 220, 225–226 confounding and, 157, 219 in do-calculus, 234 do-operator and, 157–165, 330 backdoor path, 158–159 background factors, 48 Bareinboim, Elias, 239, 353, 356–358 Baron, Reuben, 324–325, 339 Bayes, Thomas, 95–96, 96 (fig.), 264 on data, 100, 102 on inverse probability, 97–99, 98 (fig.), 101, 104–105, 112–113 method of, 99–100 on miracles, 103 on probability, 97–98, 102 and subjectivity, 90, 104, 108 Bayesian analysis, 194–195 Bayesian conditioning, 194 Bayesian networks, 50–51, 81, 92 (photo) in AI, 18, 93–94, 108–109, 112, 132 in Bonaparte software, 95 causal diagrams and, 128–133 codewords, turbo codes in, 126, 127 (fig.) 128 conditional probability table in, 117, 119, 120 (table) DNA tests and, 122, 123 (fig.), 124 inverse-probability problem in, 112–113, 119–120 junctions in, 113–116 in machine learning, 125 parent nodes in, 117 probability in, 358–359 probability tables in, 128–129 SCMs versus, 284 Bayesian statistics, 89–91 Bayes’s rule, 101–104, 196 BCSC. See Breast Cancer Surveillance Consortium belief, 101–102 belief propagation, 112–113, 128 Berkeley admission paradox, 197–198 Berkson, Joseph, 197–200, 197 (fig.), 198 (table) Bernoulli, Jacob, 5 Berrou, Claude, 126–127 Bickel, Peter, 310–312, 315–316 Big Data, 3, 350–358, 354 (fig.) birth weight, 82–83, 82 (fig.) birth-weight paradox, 185–186, 185 (fig.), 189 black box analysis, 125, 283 Blalock, Hubert, 309, 326 Bonaparte, 94–95, 122, 123 (fig.), 124–125 brain managing causes, effects, 2 representation, of information in, 39 See also human mind Breast Cancer Surveillance Consortium (BCSC), 105–106, 107 (fig.), 118 Brito, Carlos, 257 Brockman, John, 367–368 Brown, Lisa, 216, 217 (fig.) Burks, Barbara, 198, 304, 311, 333 on nature-versus-nurture debate, 305–306, 305 (fig.), 306 (fig.) path diagram of, 308–309 on social status, 307 but-for causation, 261–263, 286–288 canned procedures, 84–85 Cartwright, Nancy, 49 case studies. See examples case-control studies, 173 Castle, William, 72–73 causal analysis data in, 85 subjectivity and, 89 causal diagram, 7, 39–40, 39 (fig.), 41–42, 41 (fig.), 118 (fig.), 142 (fig.) for “Algebra for All,” 337, 338 (fig.) Bayesian network and, 128–133 for Berkeley admission paradox, 311–312, 312 (fig.), 314 (fig.) for Berkson’s paradox, 197 (fig.) for birth-weight paradox, 185, 185 (fig.) for cholera, 247–248, 247 (fig.), 248 (fig.) for climate change, 294, 294 (fig.) confounder in, 138, 138 (fig.), 140 of counterfactual, 42–43, 42 (fig.) direct effect in, 320–321 do-operator in, 148 (fig.) front-door adjustment in, 225 (fig.) of Galton board, 64–65, 64 (fig.) of genetic model, 64–65, 64 (fig.) graphical structure of, 131 for improperly controlled experiment, 147–148, 147 (fig.) instrumental variables and, 250 of JTPA Study, 229–231, 230 (fig.) for Lord’s paradox, 214, 215 (fig.) for Mendelian randomization, 255–256, 256 (fig.) for Monty Hall paradox, 193–194, 193 (fig.), 195 (fig.) of napkin problem, 239–240, 240 (fig.) of nature-versus-nurture debate, 305, 305 (fig.) noncausal path in, 157, 160 for RCT, with noncompliance, 252–253, 253 (fig.) RCT in, 140, 148–149, 149 (fig.) of Simpson’s paradox, 206–207, 206 (fig.), 209 (fig.) for smoking gene example, 341, 341 (fig.), 342 (fig.) supply-side, 250–251, 251 (fig.) for tourniquet example, 346, 346 (fig.) of vaccination, 44–46, 45 (fig.) See also path diagram causal effect backdoor criterion for, 220, 225–226 through path coefficients, 77 through regression coefficients, 222–223 causal inference cause, effect in, 2–3 human mind and, 1–2, 43 mathematical language of, 3–8 objectivity of, 91 by robots, 2, 350, 361, 361 (fig.) in statistics, 18 technology of, 1–2 causal inference engine, 11–15, 12 (fig.), 26–27, 46 causal knowledge, of machines, 37 causal model, 12 (fig.), 13, 16–17, 45–46 Big Data and, 350–358, 354 (fig.) as hypothetical experiments, 130 doing in, 27 imagining in, 27 mediation in, 300–301 seeing vs. doing, 27 of Rubin, 261, 280–281 testing of, 116 See also linear causal model; structural causal model causal paradoxes, 189–190 causal questions, language of, 5 causal reasoning, 20–21, 43 the Causal Revolution, ix–x, 7, 9, 11, 45, 140, 301, 350 causal subjectivity, 90 causal vocabulary, 5 causality, ix provisional, 150 queries of, 27, 183 statistics and, 66, 190 Causality (Pearl), ix, 24, 328, 331 causation association and, 181, 189 computers understanding, 40–41 correlation and, 5–6, 82–84 intuition about, 321 necessary, 289–290 Pearson, K., and, 71–72 probability and, 47–51 RCT for, 169 repetition and, 66–67 smoking-cancer debate in, 168 in statistics, 18 three levels of, 27–36 Wright, S., on, 79–81 See also Ladder of Causation cause defining, 47–48, 179–180 proximate, 288–289 sufficient and necessary, 288–291, 295 See also common cause principle causes, effects and, 2–3 in causal diagrams, 187 probability versus, 46 c-decomposition, 243 Cerf, Vint, 95 child nodes, 111–112, 129 Chinese Room argument, 38–39 cholera, 168 See also examples climate change causal diagram of, 294, 294 (fig.) computer simulation of, 292–296 counterfactuals and, 261–262, 295 FAR and, 291–292 See also examples Cochran, William, 180, 182 codewords, 126, 127 (fig.), 128 coefficients difference in, 327 path, 77, 223, 251 product of, 327 regression, 222–223 Cognitive Revolution, 24–25, 34–35 coherence, 181–182 collider bias, 185–186, 197–200 common cause principle, 199 compatibilists, 364 completeness, 237, 243–244 computer simulation, in climate science, 292–296 computers causation and, 40–41 counterfactuals and, 43 “Computing Machinery and Intelligence” (Turing), 358 conditional probability, 101, 103 conditional probability table, 117 (table), 119, 120 (table) confounders, 137, 138 (fig.), 140 of mediator, outcome, 315–316 mediators and, 276 provisional conclusions and, 143 RCT and, 149–150 in smoking risk, 175 in statistics, 138–139, 141–142 See also deconfounders confounding backdoor criterion for, 157, 219 classical epidemiological definition of, 153–154, 159 defining, 150–151, 156, 162 in epidemiology, 152–154 incomparability in, 151 indirect, 241 in Ladder of Causation, 140 statistics and, 141, 151, 156 surrogates in, 152 third-variable definition, 151–152 confounding bias, 137–138, 147 Conrady, Stefan, 118–119 consistency, 181, 281 controlled experiment, 136–137, 147 (fig.) See also experimental design; randomized controlled trial Cornfield, Jerome, 175, 179–180, 183, 224, 341 Cornfield’s inequality, 175 Coronary Primary Prevention Trial, 252 correlation, 29 causation and, 5–6, 82–84 Galton on, 62–63 spurious, 69–72 See also association, collider bias “Correlation and Causation” (Wright, S.), 82 counterfactual analysis, 261–262 counterfactuals, 9–10 causal diagram for, 42–43, 42 (fig.) climate change and, 261–262, 295 computers and, 43 data and, 33 do-expression of, 287–288 exchangeability and, 154–155 Frost and, 258 (photo) in human mind, 33 Hume and, 19–20, 265–267 indirect effects and, 322 in inference engine, 296 in Ladder of Causation, 266 law and, 286–291 Lewis on, 266–269 mediation analysis for, 297 and possible worlds, 266–269 queries as, 20, 28 (fig.), 36, 260–261, 284 reasoning, 10 SCMs for, 276–280, 283–284 for strong AI, 269 Cox, David, 154, 240–241, 241 (fig.) Crow, James, 84–85 culpability, 261 curse of dimensionality, 221 Curve of Abandoning Hope, 120–121 d-separation, 116, 242, 283, 381 Darwiche, Adnan, 30 Darwin, Charles, 63, 73, 87 data, 11, 12 (fig.), 14–16 Bayes on, 100, 102 in causal analysis, 85 counterfactuals and, 33 economists and, 86 fusion, 355 interpretation, 352 in machine learning, 30–31 methods and, 84–85 mining, 351–352 objectivity of, 89 Pearson, K., on, 87–88 reduction of, 85 in science, 6, 84–85 See also Big Data David, Richard, 187 Dawid, Phillip, 237, 350 de Fermat, Pierre, 4–5 de Moivre, Abraham, 5 death, proximate cause of, 288 decision problem, 238–239 decoding, 125–126, 127 (fig.), 128 deconfounders, 139–140 back-door paths for, 158–159 in intervention, 220 deconfounding games, 159–165 deduction, induction and, 93 deep learning, 3, 30, 359, 362 Democritus, 34 The Design of Experiments (Cox), 154 developmental factors, of guinea pigs, 74–76, 75 (fig.) Dewar, James, 53 Diaconis, Persi, 196 difference, in coefficients, 327 direct effect, 297, 300–301, 317–318 in causal diagram, 320–321 of intervention, 323–324 in mediation formula, 333 mediators and, 326, 332 See also indirect effects; natural direct effect The Direction of Time (Reichenbach), 199 discrimination, 311–312, 315–316 DNA test, 94–95, 122, 123 (fig.), 124, 342 do-calculus, 241–242 backdoor criterion in, 234 completeness of, 243–244 decision problem in, 238–239 elimination procedure in, 231–232 front-door adjustment in, 235–237, 236 (fig.) instrumental variables in, 257 transformations in, 233–234, 238 transparency in, 239–240 as universal mapping tool, 219–220 do-expression, 8, 32, 49, 287–288 Doll, Richard, 171–174, 172 (fig.) do-operator, 8–9, 49, 147–148, 148 (fig.), 151 backdoor criterion and, 157–165, 330 elimination procedure for, 237 for intervention, 231 in noncausal paths, 157 do-probabilities, 226 Duncan, Arne, 336 Duncan, Otis, 285, 309, 326 economics, path analysis in, 79, 84, 86, 236, 244, 250, 285, 362, 376 effects of treatment on the treated (ETT), 296–297 elimination procedure, 231–232, 237 Ellenberg, Jordan, 200 Elwert, Felix, 115 An Enquiry Concerning Human Understanding (Hume), 265–266 epidemiology, 169 admission rate bias in, 197–198 confounding in, 152–154 mediation fallacy in, 315–316 RCT in, 172–173 Robins in, 329 (fig.) equation deletion, 244 Erdos, Paul, 196 error-correcting code, 126 estimand, 12 (fig.), 14–15, 17 estimate, 12 (fig.), 15 ETT. See effects of treatment on the treated Euclidean geometry, 48, 101, 233 evolution, human, 23–26 examples Abraham and fifty righteous men, 263–264, 283–284 “Algebra for All,” 301, 336–339, 338 (fig.) AlphaGo, 359–362 aspirin and headache, 33, 267 attractive men are jerks, 200 bag on plane, 118–121, 118 (fig.) Bayes’s billiard ball, 98–99, 98 (fig.), 104, 108 Berkeley admissions and discrimination, 309–316, 312 (fig.), 314 (fig.), 317–318 Berkson’s paradox, 197–200, 197 (fig.), 198 (table) birth weight in guinea pigs, 82–83, 82 (fig.) blocked fire escape, 286–291 chocolate and Nobel Prize winners, 69 cholera, 245–249, 247 (fig.), 248 (fig.) coat color in guinea pigs, 72–76, 74 (fig.), 75 (fig.) coin flip experiment, 199–200 Daisy and kittens, 319–322, 320 (fig.) Daniel and vegetarian diet, 134 (photo), 135–137 education, skill and salary, 325–326 falling piano, 288–289 fertilizer and crop yield, 145–149 fire, smoke, and alarm, 113–114 firing squad, 39–43, 39 (fig.) flaxseed, elasticity of supply, 250–251, 251 (fig.) flu vaccine, 155–156, 156 (table) Galton board, 52 (photo), 54–55, 56–57, 57 (fig.), 63–65, 64 (fig.) Garden of Eden, 23–25 HDL cholesterol and heart attack, 254–257 ice cream and crime rates, 48 inheritance of stature, 55–60, 59 (fig.) intelligence, nature versus nurture, 304–309 job training and earnings, 228–231 LDL cholesterol, 252–257, 254 (table) Let’s Fake a Deal, 192–196, 195 (fig.) Lord’s paradox: diet and weight gain, 215–217, 215 (fig.), 217 (fig.) Lord’s paradox: gender and weight gain, 212–215, 213 (fig.) mammogram and cancer risk, 104–108 mammoth hunt, 25–26, 26 (fig.) matches or oxygen as cause of fire, 289–290 Monty Hall paradox, 188 (photo), 189–197, 191 (table), 193 (fig.), 193 (table), 195 (fig.), 200 mortality rate and Anglican weddings, 70 online advertising, 354–355 robot soccer, 365–366 salary, education, and experience, 272–283, 273 (table), 276 (fig.) scurvy and Scott expedition, 298 (photo), 299–300, 302–304, 303 (fig.) shoe size, age, and reading ability, 114–115 Simpson’s paradox: BBG drug, 189, 200–204, 201 (table), 206–210, 206 (fig.), 208 (table), 209 (fig.), 221 Simpson’s paradox: exercise and cholesterol, 211–212, 212 (fig.) Simpson’s paradox: kidney stones, 210 Simpson’s paradox: smoking and thyroid disease, 210 Simpson’s reversal: batting averages, 203–204, 203 (table), 211 skull length and breadth, 70–71, 70 (fig.) smoking, birth weight, and infant mortality, 183–187, 185 (fig.) smoking, tar, and cancer, 224–228, 297 smoking and adult asthma, 164, 164 (fig.) smoking and lung cancer, 18–19, 167–179, 172 (fig.), 176 (fig.) smoking and miscarriages, 162–163 smoking gene, 339–343, 341 (fig.), 342 (fig.) sure-thing principle, 204–206, 316 talent, success, and beauty, 115–116 tea and scones, 99–102, 100 (table), 104–105, 112–113 toothpaste and dental floss, 29–30, 32, 34 tourniquets, 343–347, 345 (table), 346 (fig.) tsunami at Orobiae, 262–263, 266 turbo codes, 125–126, 127 (fig.), 128 2003 heat wave and climate change, 292–296, 294 (fig.) vaccination and smallpox, 43–44, 45 (fig.) victim DNA identification, 94–95 walking and death rate, 141–143, 142 (fig.) exchangeability, 154–156, 162, 181 experimental design, 145–146, 146 (fig.) external validity, 357 Facebook, 32, 351 false positives, 106–107, 107 (fig.) false negatives, 107 (fig.) FAR. See fraction of attributable risk Faraday, Michael, 53 Feigenbaum, Edward, 109 feminism, 67–68 Fieser, Louis, 182 Fisher, R. A., 169, 224, 271–272 experimental design of, 145–146, 146 (fig.) Neyman, J., and, 271–272 on RCT, 139–140, 143–144 on smoking gene, 174–175 in smoking-cancer debate, 178–179 on statistics, 85 Wright, S., and, 85 Fisher Box, Joan, 144–145, 149 Forbes, Andrew, 163–164, 164 (fig.) formulas, 334–335 forward probability, 104, 112–113 fraction of attributable risk (FAR), 291–292 free will, 358–370 Freedman, David, 227–228, 236, 285 front-door adjustment, 225 (fig.), 235–237, 236 (fig.) front-door criterion, 224–231, 225 (fig.), 229 (fig.) Frost, Robert, 258 (photo) Galileo, 81, 187 Gallagher, Robert, 128 Galton, Francis, 3, 5, 52 (photo), 53, 78 anthropometric statistics of, 58 on correlation, 62–63 on eminence, 56 Hereditary Genius by, 55–56 Natural Inheritance by, 66 Pearson, K., and, 66–68 on regression to the mean, 57–58, 67 on regression line, 60–62, 61 (fig.), 221–222 “Typical Laws of Heredity” by, 54 See also examples games, deconfounding, 159–165 Gauss, Carl Friedrich, 5 Geiger, Dan, 242–243, 245, 285 Genesis, 23–25, 263 genetic modeling, 64–65, 64 (fig.) genetics. See DNA test; examples; Mendelian genetics genome-wide association study (GWAS), 339–340 geometry, 232–233 Glymour, Clark, 350 Glynn, Adam, 228–230 God, 23–24 Goldberger, Arthur, 84–85 graphoids, 381 Greek logic, 232 Greenland, Sander, 150, 154–156, 168, 237, 333–334 See also Robins, Jamie guilt, probability of, 288 guinea pigs. See examples GWAS. See genome-wide association study Haavelmo, Trygve, 285 Hagenaars, Jacques, 331 Halley, Edmond, 5 Halpern, Joseph, 350 Hammel, Eugene, 309–311 Hannart, Alexis, 294–295 Harari, Yuval, 25, 34 Hardy, G. H., 65 HDL. See high-density lipoprotein cholesterol Heckman, James, 236 Hereditary Genius (Galton), 55–56 Hernberg, Sven, 152 high-density lipoprotein (HDL) cholesterol, 254–257 Hill, Austin Bradford, 169–170, 172–174, 172 (fig.), 181 Hill’s criteria, 181–183 Hipparchus, 232 A History of Epidemiologic Methods and Concepts (Morabia), 152–153 History of the Peloponnesian War (Thucydides), 262 Hitchcock, Christopher, 350 Holland, Paul, 236, 273, 275 Hooke’s Law, 33 Hong, Guanglei, 337–338 How Not to Be Wrong (Ellenberg), 200 human cognition, 99 communicating, with robot, 366 evolution, 23–26 human mind causal inference of, 1–2, 43 counterfactuals in, 33 humanlike intelligence, 30, 269 Hume, David, 103 on counterfactuals, 19–20, 265–267 An Enquiry Concerning Human Understanding by, 265–266 “On Miracles” by, 96–97 Treatise of Human Nature by, 264–265, 265 (fig.) Huygens, Christiaan, 4–5 hypothetical experiments, 130 ignorability, 281–282 imagination in causation, 27 the Lion Man as, 34–35 in mental model, 26, 26 (fig.) imitation game, 36–37 incomparability, 151 indirect confounding, 241 indirect effects counterfactuals and, 322 in mediation analysis, 297, 300–301 as product, 328–329 See also natural indirect effect induction, deduction and, 93 inference engine, 296, 352 See also causal inference engine information flow of, 157–158 representing, in brain, 97 transfer of, 194 instrumental variables, 249–250, 249 (fig.), 257 intention, 367 intervention, 9, 131, 150 deconfounders in, 220 direct effect of, 323–324 do-operator for, 149–150, 231 in Ladder of Causation, 28 (fig.), 31–33, 40, 219, 231 prediction and, 32 variables in, 257 See also Mount Intervention intuition, 47, 99, 125, 189, 321 inverse probability Bayes on, 97–99, 98 (fig.), 101, 104–105 in Bayesian network, 112–113, 119–120 likelihood ratio and, 105, 113 Jeffreys, Harold, 103 Jeter, Derek, 203, 203 (table) Job Training Partnership Act (JTPA) Study, 228–231, 229 (fig.), 230 (fig.) Joffe, Marshall, 283 Jouffe, Lionel, 118–119 JTPA. See Job Training Partnership Act Study junctions in Bayesian networks, 113–116 in flow, of information, 157–158 Justice, David, 203, 203 (table) Kahneman, Daniel, 58, 63–64, 290 Karl Pearson (Porter), 67 Karlin, Samuel, 87 Kashin, Konstantin, 228–230 Kathiresan, Sekar, 256 Ke Jie, 360 Kempthorne, Oscar, 272 Kenny, David, 324–325, 339 Klein, Ezra, 139, 154 knowledge, 8, 11–12, 12 (fig.) Koettlitz, Reginald, 302–304 Kragh, John, 343–347 Kruskal, William, 312–316, 346 Ladder of Causation, 17–19, 24, 116 association in, 28 (fig.), 29–30, 51 bias in, 311 confounding in, 140 counterfactuals in, 266 intervention in, 28 (fig.), 31–33, 40, 219, 231 model-free approach to, 88 observation in, 264 probabilities and, 47–49, 75 queries in, 28 (fig.), 29, 32 language of knowledge, 8 mathematical, 3–8 of probability, 102–103 of queries, 8, 10 Laplace, Pierre-Simon, 5 Latin square, 145, 146 (fig.) law, counterfactuals and, 286–291 LDL. See low-density lipoprotein cholesterol Let’s Make a Deal. See examples Lewis, David, 20, 266–269 likelihood ratio, 105–106, 113 Lilienfeld, Abe, 175, 179–180 Lind, James, 168, 299, 302–303 Lindley, Dennis, 209 linear causal model, 322–323, 327 linear models, 295–296 linear regression, 285–286 linear SCMs, 285–286 the Lion Man, 34–36, 35 (fig.) LISREL, 86 logic, 232, 238 Lord’s paradox. See examples low-density lipoprotein (LDL) cholesterol, 252–257, 254 (table) lung cancer, smoking in, 18–19, 167–168 machine learning, 10–11, 30–31, 125, 363 See also artificial intelligence (AI) machines causal knowledge of, 37 thinking, 367–368 See also robots MacKay, David, 127–128 Malaysia Airlines crash, 122, 123 (fig.) Marcus, Gary, 30 matching, 274 mathematical certainty, 288 mathematical language, 3–8 mathematics, science and, 4–5, 84–85 See also geometry M-bias, 161 McDonald, Rod, 325 mediation, 20 “Algebra for All” as, 336–339, 338 (fig.) analysis, 297, 300–301, 322–323 in causation, 300–301 fallacy, 272, 315–316 formula, 319, 332–333, 335 questions, 131 smoking gene example as, 339–343, 341 (fig.), 342 (fig.) threshold effect and, 325, 326 (fig.) mediators, 153–154, 228, 297 confounders and, 276 direct effect and, 326, 332 outcomes and, 315–316 Mendel, Gregor, 65 Mendelian genetics, 73 Mendelian randomization, 255–256, 256 (fig.) mental model, 26, 26 (fig.) message-passing network, 110–111, 111 (fig.) methods, data and, 84–85 mini-Turing test, 36–46 miracles, 103, 357 model discovery, 373 model-blind, 33, 66, 132, 217, 275 Model Penal Code, 286, 288 model-free approach, 87–89, 272, 351 See also model-blind Morabia, Alfredo, 152–153 Mount Intervention, 218 (photo), 219–220, 224, 259–260 Musk, Elon, 367 napkin problem, 239–240, 240 (fig.), 330 natural direct effect (NDE), 318–319, 332–333 natural effects, 327 natural indirect effect (NIE), 319, 321, 325–326, 332–333 Natural Inheritance (Galton), 66 nature, 144–145, 147, 149, 156, 257 nature-versus-nurture debate, 304–309, 305 (fig.), 306 (fig.) NDE. See natural direct effect necessary causation, 289–290, 295 necessity, probability of, 294 Netherlands Forensic Institute (NFI), 94, 122, 125 Neyman, Jerzy, 85, 261, 270–272 NFI. See Netherlands Forensic Institute NIE. See natural indirect effect Niles, Henry, 78–81, 84 noncausal path, in causal diagram, 157, 160 noncollapsibility, 152 noncompliance, RCT with, 252–253, 253 (fig.) nonconfoundedness, 281 nonlinear analysis, 335 nonrandomized studies, 149 Novick, Melvin, 201, 209 objectivity in Bayesian inference, 89 of causal inference, 91 observational studies, 150–151, 229 Ogburn, William Fielding, 309 “On Miracles” (Hume), 96–97 “On the Inadequacy of the Partial and Multiple Correlation Technique” (Burks), 308 Origin of Species (Darwin), 63 paradox, 9, 19, 189–190 birth-weight, 185–186, 185 (fig.), 189 as optical illusion, 189–190 See also examples parent nodes, 111–112, 117–118, 129 Pascal, Blaise, 4–5 Pasteur, Louis, 228 path analysis in economics, 86 in social sciences, 85–86 Wright, S., on, 86–89, 324 path coefficients, 77, 223, 251 path diagram for birth-weight example, 82–83, 82 (fig.) of Burks, 308–309 of Wright, S., 74–77, 75 (fig.), 85–86, 221, 260–261 Paz, Azaria, 381 Pearl, Judea, ix, 24, 51, 328, 331 Pearson, Egon, 271–272 Pearson, Karl, 5, 62, 78, 85, 180, 222 causation and, 71–72 on data, 87–88 Galton and, 66–68 on skull size, 70 (fig.) on spurious correlation, 69 as zealot, 67–68 philosophers, on causation, 47–51, 81 physics, 33–34, 67, 99 Pigou, Arthur Cecil, 198 Pinto, Rodrigo, 236 placebo effect, 300 polynomial time, 238 Porter, Ted, 67 potential outcomes, 155, 260 potential outcomes framework, 155 prediction, 278, 280 intervention and, 32 in science, 36 preponderance of evidence, 288 pretreatment variables, 160 Price, Richard, 97 prior knowledge, 90, 104 probabilistic causality, 47–51 Probabilistic Reasoning in Intelligent Systems (Pearl), 51 probability, 43–44, 46, 90, 110 Bayes on, 97–98, 102 Bayesian networks and, 358–359 in but-for causation, 287 causation and, 47–51 of guilt, 288 Ladder of Causation and, 47–49, 75 language of, 102–103 or necessity, 294 over time, 120–121, 121 (fig.) raising, 49 of sufficiency, 294 See also conditional probability; inverse probability probability table, 117 (table), 128–129 probability theory, 4–5 product of coefficients, 327 indirect effect as, 328–329 Provine, William, 85 provisional causality, 150 proximate cause, 288–289 Pythagoras, 233 quantitative causal reasoning, 43 queries, 8, 10, 12 (fig.), 14–15 causal, 27, 183 counterfactual, 20, 28 (fig.), 36, 260–261, 284 in Ladder of Causation, 28 (fig.), 29, 32 mediation, 131 See also “Why?” question randomized controlled trial (RCT), 18, 132–133, 143–147 in causal diagram, 140, 148–149, 149 (fig.) confounders and, 149–150 in epidemiology, 172–173 Fisher on, 139–140, 143–144 as “gold standard,” 231 with noncompliance, causal diagram for, 252–253, 253 (fig.) observational studies versus, 150, 229 recombinant DNA, 369 reduction, of data, 85 regression, 29, 325 See also linear regression regression coefficient, 222–223 regression line, 60–62, 61 (fig.), 221–222 regression to the mean, 57–58, 67 Reichenbach, Hans, 199, 234 Reid, Constance, 271–272 representation acquisition and, 38 of information, in brain, 39 representation problem, 268 reversion, 56–57 Robins, Jamie, 168, 329–330, 329 (fig.), 333–334 on confounding, 150 do-calculus and, 236–237, 241 on exchangeability, 154–156 robots, ix–x AI, 291 causal inference by, 2, 350, 361, 361 (fig.) communicating, with humans, 366 as moral, 370 soccer, 365–366 root node, 117 Rubin, Donald, 269–270, 270 (photo), 275, 283 causal model of, 261, 280–281 on potential outcomes, 155 Rumelhart, David, 110, 111 (fig.), 268 Sackett, David, 197–198, 198 (table) Sapiens (Harari), 25 Savage, Jimmie, 316 Savage, Leonard, 204–206 scatter plot, 59 (fig.), 60, 62 Scheines, Richard, 350 Schuman, Leonard, 182 science data in, 6, 84–85 history of, 4–5 mathematics and, 4–5, 84–85 prediction in, 36 See also causal inference; social sciences scientific method, 108, 302 SCMs. See structural causal models Scott, Robert Falcon, 298 (photo), 302, 303 (fig.) Searle, John, 38, 363 seatbelt usage, 161–162 Sedol, Lee, 360 Seeing vs. doing, 8–9, 27, 130, 149, 233 self-awareness, 363, 367 SEM. See structural equation model sensitivity analysis, 176 sequential treatment, 241 (fig.) Shafer, Glen, 109 Sharpe, Maria, 68 Sherlock Holmes, 92 (photo), 93 Shpitser, Ilya, 24, 238–239, 243, 245, 296–297 Silicon Valley, 32 Simon, Herbert, 79, 198 Simpson, Edward, 153–154, 208–209 Simpson’s paradox. See examples smoking. See examples; surgeon general’s advisory committee; tobacco industry smoking gene, 174–175, 224–227, 339–343, 341 (fig.), 342 (fig.) smoking-cancer debate, 166 (photo), 167–179 Snow, John, 168, 245–249 social sciences, 84–86 social status, 307 sophomore slump, 56–58 Spirtes, Peter, 244 Spohn, Wolfgang, 350 spurious correlation, 69–72 spurious effects, 138 stable unit treatment value assumption (SUTVA), 280–281 Stanford-Binet IQ test, 305–306 statistical estimation, 12 (fig.), 15 statistics, 5–6, 9 anthropometric and, 58 canned procedures in, 84–85 causal inference in, 18 causality and, 18, 66, 190 confounders in, 138–139, 141–142 methods of, 31, 180–181 objectivity and, 89 skepticism in, 178 See also Bayesian statistics Stigler, Stephen, 63, 71, 147 Stott, Peter, 292–294 strong AI, 3, 11 causal reasoning of, 20–21 counterfactuals for, 269 free will and, 358–370 as humanlike intelligence, 30, 269 Strotz, Robert, 244 structural causal models (SCMs), 260–261, 276–280, 276 (fig.), 283–286 structural equation model (SEM), 86, 285 subjectivity Bayes on, 90, 104, 108 causal, 90 causal analysis and, 89 sufficiency, probability of, 294 sufficient cause, 288–291, 295 sum of products rule, 324 Supreme Court, U. S., 288, 316 sure-thing principle, 204–206, 316 surgeon general’s advisory committee, 179–183, 180 (fig.) surrogates, 152 SUTVA. See stable unit treatment value assumption Szent-Gyorgyi, Albert, 304 Teague, Claude, 177 temporal relationship, 181 Terman, Lewis, 305, 307 Terry, Luther, 179, 182 testability, 116, 242, 283, 381 testable implications, 12 (fig.), 13, 283 theology, 97 Thinking, Fast and Slow (Kahneman), 58 thinking machines, 10 Thomson, J. J., 53 threshold effect, mediation and, 325, 326 (fig.) Thucydides, 262 Tian, Jin, 238, 243 time-varying treatments, 241 tobacco industry, 170, 171 (fig.), 177–179 total effects, 300, 317 tourniquet. See examples “Toward a Clearer Definition of Confounding” (Weinberg, C.), 162 transfer, of information, 194 transformations, in do-calculus, 233–234, 238 transparency, in do-calculus, 239–240 transportability, 353, 354 (fig.), 356 Treatise of Human Nature (Hume), 264–265, 265 (fig.) Turing, Alan, 27, 29, 36–37, 108–109, 358 Tversky, Amos, 290 “Typical Laws of Heredity” (Galton), 54 uncertainty, 4, 109, 143 United States Department of Agriculture (USDA), 73 universal mapping tool, 219–220 VanderWeele, Tyler, 185, 342–343 Variables causally relevant, 48–49 instrumental, 249–250, 249 (fig.), 257 in intervention, 257 pretreatment, 160 in probability, 48–49 Verma, Thomas, 87, 242, 245 Virgil, 3 vos Savant, Marilyn, 190–193, 191 (table), 196 Wainer, Howard, 216, 217 (fig.) Wall, Melanie, 328, 331 weak AI, 362 weighted average, 106 Weinberg, Clarice, 162–163 Weinberg, Wilhelm, 65 Weissman, George, 177 Welling, David, 344 Wermuth, Nanny, 240–241, 241 (fig.) Whig history, 65–66, 80 “Why?” question, 299–300, 349–350 Wilcox, Allen, 186–187 Winship, Christopher, 115, 350 Wold, Herman, 244 would-haves, 329–336 Wright, Philip, 72, 250–252, 251 (fig.) Wright, Sewall, 5–6, 18, 244, 309 on causation, 79–81 “Correlation and Causation” by, 82 on developmental factors, 74–76, 75 (fig.) Fisher and, 85 guinea pigs of, 72–74, 74 (fig.), 222 on model-free approach, 88–89 Niles on, 78–81, 84 on path analysis, 86–89, 324 on path coefficients, 223, 251 path diagram of, 74–77, 75 (fig.), 85–86, 221, 260–261 Yerushalmy, Jacob, 167–169, 174, 183–184 Yule, George Udny, 68–72, 222 Zadeh, Lotfi, 109",
    "crumbs": [
      "Causal Inference",
      "The book of why"
    ]
  },
  {
    "objectID": "extracted/Probably Overthinking It.html",
    "href": "extracted/Probably Overthinking It.html",
    "title": "Probably Overthinking It",
    "section": "",
    "text": "How to Use Data to answer QUestions,\navoid statistical traps, and Make Better Decisions\nALLEN B. DOWNEY\ntHe University of cHicago press\nChicago and London The University of Chicago Press, Chicago 60637 The University of Chicago Press, Ltd., London © 2023 by Allen B. Downey All rights reserved. No part of this book may be used or reproduced in any manner whatsoever without written permission, except in the case of brief quotations in critical articles and reviews. For more information, contact the University of Chicago Press, 1427 E.\n60th St., Chicago, IL 60637.\nPublished 2023 Printed in the United States of America 32 31 30 29 28 27 26 25 24 23 1 2 3 4 5 ISBN- 13: 978- 0- 226- 82258- 7 (cloth) ISBN- 13: 978- 0- 226- 82259- 4 (e- book) DOI: https:// doi .org /10 .7208 /chicago /9780226822594 .001 .0001 Library of Congress Cataloging- in- Publication Data Names: Downey, Allen, author.\nTitle: Probably overthinking it : how to use data to answer questions, avoid statistical traps, and make better decisions / Allen B. Downey.\nOther titles: How to use data to answer questions, avoid statistical traps, and make better decisions Description: Chicago ; London : The University of Chicago Press, 2023. | Includes bibliographical references and index.\nIdentifiers: LCCN 2023016550 | ISBN 9780226822587 (cloth) | ISBN 9780226822594 (ebook) Subjects: LCSH: Statistics.\nClassification: LCC QA276 .D67 2023 | DDC 519.5—dc23/eng20230710 LC record available at https:// lccn .loc .gov /2023016550 ♾ This paper meets the requirements of ANSI/NISO Z39.48- 1992 (Permanence of Paper).\n\n\nIntroduction 1\n\nAre You Normal? Hint: No 5\nRelay Races and Revolving Doors 27\nDefy Tradition, Save the World 45\nExtremes, Outliers, and GOATs 59\nBetter Than New 79\nJumping to Conclusions 99\nCausation, Collision, and Confusion 113\nThe Long Tail of Disaster 127\nFairness and Fallacy 151\nPenguins, Pessimists, and Paradoxes 179\nChanging Hearts and Minds 201\nChasing the Overton Window 217 Epilogue 231 Acknowledgments 235 Bibliography 237 Index 247 # INTRODUCTION\n\nLet me start with a premise: we are better off when our decisions are\nguided by evidence and reason. By “evidence,” I mean data that is relevant to a question. By “reason” I mean the thought processes we use to interpret evidence and make decisions. And by “better off,” I mean we are more likely to accomplish what we set out to do— and more likely to avoid undesired outcomes.\nSometimes interpreting data is easy. For example, one of the rea- sons we know that smoking causes lung cancer is that when only 20% of the population smoked, 80% of people with lung cancer were smokers. If you are a doctor who treats patients with lung cancer, it does not take long to notice numbers like that.\nBut interpreting data is not always that easy. For example, in 1971 a researcher at the University of California, Berkeley, published a pa- per about the relationship between smoking during pregnancy, the weight of babies at birth, and mortality in the first month of life. He found that babies of mothers who smoke are lighter at birth and more likely to be classified as “low birthweight.” Also, low- birthweight ba- bies are more likely to die within a month of birth, by a factor of 22.\nThese results were not surprising.\nHowever, when he looked specifically at the low- birthweight ba- bies, he found that the mortality rate for children of smokers is lower, by a factor of two. That was surprising. He also found that among low- birthweight babies, children of smokers are less likely to have birth defects, also by a factor of 2. These results make maternal smoking seem beneficial for low-b irthweight babies, somehow protecting them from birth defects and mortality.\nThe paper was influential. In a 2014 retrospective in the Inter- national Journal of Epidemiology, one commentator suggests it was responsible for “holding up anti- smoking measures among pregnant women for perhaps a decade” in the United States. Another sug- gests it “postponed by several years any campaign to change moth- ers’ smoking habits” in the United Kingdom.\nBut it was a mistake. In fact, maternal smoking is bad for babies, low birthweight or not. The reason for the apparent benefit is a sta- tistical error I will explain in chapter 7.\nAmong epidemiologists, this example is known as the low- birthweight paradox. A related phenomenon is called the obesity paradox. Other examples in this book include Berkson’s paradox and Simpson’s paradox. As you might infer from the prevalence of “paradoxes,” using data to answer questions can be tricky. But it is not hopeless. Once you have seen a few examples, you will start to recognize them, and you will be less likely to be fooled. And I have collected a lot of examples.\nSo we can use data to answer questions and resolve debates. We can also use it to make better decisions, but it is not always easy. One of the challenges is that our intuition for probability is sometimes dangerously misleading. For example, in October 2021, a guest on a well- known podcast reported with alarm that “in the [United King- dom] 70- plus percent of the people who die now from COVID are fully vaccinated.” He was correct; that number was from a report published by Public Health England, based on reliable national sta- tistics. But his implication— that the vaccine is useless or actually harmful— is wrong.\nAs I’ll show in chapter 9, we can use data from the same report to compute the effectiveness of the vaccine and estimate the number of lives it saved. It turns out that the vaccine was more than 80% ef- fective at preventing death and probably saved more than 7000 lives, in a four- week period, out of a population of 48 million. If you ever find yourself with the opportunity to save 7000 people in a month, you should take it.\nThe error committed by this podcast guest is known as the base rate fallacy, and it is an easy mistake to make. In this book, we will see examples from medicine, criminal justice, and other domains where decisions based on probability can be a matter of health, free- dom, and life.\nThe Ground rules Not long ago, the only statistics in newspapers were in the sports sec- tion. Now, newspapers publish articles with original research, based on data collected and analyzed by journalists, presented with well- designed, effective visualization. And data visualization has come a long way. When USA Today started publishing in 1982, the infograph- ics on their front page were a novelty. But many of them presented a single statistic, or a few percentages in the form of a pie chart.\nSince then, data journalists have turned up the heat. In 2015, “The Upshot,” an online feature of the New York Times, published an in- teractive, three- dimensional representation of the yield curve— a notoriously difficult concept in economics. I am not sure I fully un- derstand this figure, but I admire the effort, and I appreciate the will- ingness of the authors to challenge the audience. I will also challenge my audience, but I won’t assume that you have prior knowledge of statistics beyond a few basics. Everything else, I’ll explain as we go.\nSome of the examples in this book are based on published re- search; others are based on my own observations and exploration of data. Rather than report results from a prior work or copy a figure, I get the data, replicate the analysis, and make the figures myself. In some cases, the original work did not hold up to scrutiny; those ex- amples are not in the book. For some examples, I was able to repeat the analysis with more recent data. These updates are enlightening.\nFor example, the low-b irthweight paradox, which was first observed in the 1970s, persisted into the 1990s, but it has disappeared in the most recent data.\nAll of the work for this book is based on tools and practices of reproducible science. I wrote each chapter in a Jupyter notebook, which combines the text, computer code, and results in a single doc- ument. These documents are organized in a version- control system that helps to ensure they are consistent and correct. In total, I wrote about 6000 lines of Python code using reliable, open- source libraries like NumPy, SciPy, and pandas. Of course, it is possible that there are bugs in my code, but I have tested it to minimize the chance of errors that substantially affect the results. My Jupyter notebooks are available online so that anyone can replicate the analysis I’ve done with the push of a button.\nWith all that out of the way, let’s get started.\nsources and relaTed readinG The bracketed numbers in the “Sources” sections refer to numbered entries in the bibliography.\n• You can view the three-d imensional visualization of the yield curve at the New York Times blog “The Upshot” [5].\n• My Jupyter notebooks are available from GitHub [35].",
    "crumbs": [
      "Data Science",
      "Probably Overthinking It"
    ]
  },
  {
    "objectID": "extracted/Probably Overthinking It.html#contents",
    "href": "extracted/Probably Overthinking It.html#contents",
    "title": "Probably Overthinking It",
    "section": "",
    "text": "Introduction 1\n\nAre You Normal? Hint: No 5\nRelay Races and Revolving Doors 27\nDefy Tradition, Save the World 45\nExtremes, Outliers, and GOATs 59\nBetter Than New 79\nJumping to Conclusions 99\nCausation, Collision, and Confusion 113\nThe Long Tail of Disaster 127\nFairness and Fallacy 151\nPenguins, Pessimists, and Paradoxes 179\nChanging Hearts and Minds 201\nChasing the Overton Window 217 Epilogue 231 Acknowledgments 235 Bibliography 237 Index 247 # INTRODUCTION\n\nLet me start with a premise: we are better off when our decisions are\nguided by evidence and reason. By “evidence,” I mean data that is relevant to a question. By “reason” I mean the thought processes we use to interpret evidence and make decisions. And by “better off,” I mean we are more likely to accomplish what we set out to do— and more likely to avoid undesired outcomes.\nSometimes interpreting data is easy. For example, one of the rea- sons we know that smoking causes lung cancer is that when only 20% of the population smoked, 80% of people with lung cancer were smokers. If you are a doctor who treats patients with lung cancer, it does not take long to notice numbers like that.\nBut interpreting data is not always that easy. For example, in 1971 a researcher at the University of California, Berkeley, published a pa- per about the relationship between smoking during pregnancy, the weight of babies at birth, and mortality in the first month of life. He found that babies of mothers who smoke are lighter at birth and more likely to be classified as “low birthweight.” Also, low- birthweight ba- bies are more likely to die within a month of birth, by a factor of 22.\nThese results were not surprising.\nHowever, when he looked specifically at the low- birthweight ba- bies, he found that the mortality rate for children of smokers is lower, by a factor of two. That was surprising. He also found that among low- birthweight babies, children of smokers are less likely to have birth defects, also by a factor of 2. These results make maternal smoking seem beneficial for low-b irthweight babies, somehow protecting them from birth defects and mortality.\nThe paper was influential. In a 2014 retrospective in the Inter- national Journal of Epidemiology, one commentator suggests it was responsible for “holding up anti- smoking measures among pregnant women for perhaps a decade” in the United States. Another sug- gests it “postponed by several years any campaign to change moth- ers’ smoking habits” in the United Kingdom.\nBut it was a mistake. In fact, maternal smoking is bad for babies, low birthweight or not. The reason for the apparent benefit is a sta- tistical error I will explain in chapter 7.\nAmong epidemiologists, this example is known as the low- birthweight paradox. A related phenomenon is called the obesity paradox. Other examples in this book include Berkson’s paradox and Simpson’s paradox. As you might infer from the prevalence of “paradoxes,” using data to answer questions can be tricky. But it is not hopeless. Once you have seen a few examples, you will start to recognize them, and you will be less likely to be fooled. And I have collected a lot of examples.\nSo we can use data to answer questions and resolve debates. We can also use it to make better decisions, but it is not always easy. One of the challenges is that our intuition for probability is sometimes dangerously misleading. For example, in October 2021, a guest on a well- known podcast reported with alarm that “in the [United King- dom] 70- plus percent of the people who die now from COVID are fully vaccinated.” He was correct; that number was from a report published by Public Health England, based on reliable national sta- tistics. But his implication— that the vaccine is useless or actually harmful— is wrong.\nAs I’ll show in chapter 9, we can use data from the same report to compute the effectiveness of the vaccine and estimate the number of lives it saved. It turns out that the vaccine was more than 80% ef- fective at preventing death and probably saved more than 7000 lives, in a four- week period, out of a population of 48 million. If you ever find yourself with the opportunity to save 7000 people in a month, you should take it.\nThe error committed by this podcast guest is known as the base rate fallacy, and it is an easy mistake to make. In this book, we will see examples from medicine, criminal justice, and other domains where decisions based on probability can be a matter of health, free- dom, and life.\nThe Ground rules Not long ago, the only statistics in newspapers were in the sports sec- tion. Now, newspapers publish articles with original research, based on data collected and analyzed by journalists, presented with well- designed, effective visualization. And data visualization has come a long way. When USA Today started publishing in 1982, the infograph- ics on their front page were a novelty. But many of them presented a single statistic, or a few percentages in the form of a pie chart.\nSince then, data journalists have turned up the heat. In 2015, “The Upshot,” an online feature of the New York Times, published an in- teractive, three- dimensional representation of the yield curve— a notoriously difficult concept in economics. I am not sure I fully un- derstand this figure, but I admire the effort, and I appreciate the will- ingness of the authors to challenge the audience. I will also challenge my audience, but I won’t assume that you have prior knowledge of statistics beyond a few basics. Everything else, I’ll explain as we go.\nSome of the examples in this book are based on published re- search; others are based on my own observations and exploration of data. Rather than report results from a prior work or copy a figure, I get the data, replicate the analysis, and make the figures myself. In some cases, the original work did not hold up to scrutiny; those ex- amples are not in the book. For some examples, I was able to repeat the analysis with more recent data. These updates are enlightening.\nFor example, the low-b irthweight paradox, which was first observed in the 1970s, persisted into the 1990s, but it has disappeared in the most recent data.\nAll of the work for this book is based on tools and practices of reproducible science. I wrote each chapter in a Jupyter notebook, which combines the text, computer code, and results in a single doc- ument. These documents are organized in a version- control system that helps to ensure they are consistent and correct. In total, I wrote about 6000 lines of Python code using reliable, open- source libraries like NumPy, SciPy, and pandas. Of course, it is possible that there are bugs in my code, but I have tested it to minimize the chance of errors that substantially affect the results. My Jupyter notebooks are available online so that anyone can replicate the analysis I’ve done with the push of a button.\nWith all that out of the way, let’s get started.\nsources and relaTed readinG The bracketed numbers in the “Sources” sections refer to numbered entries in the bibliography.\n• You can view the three-d imensional visualization of the yield curve at the New York Times blog “The Upshot” [5].\n• My Jupyter notebooks are available from GitHub [35].",
    "crumbs": [
      "Data Science",
      "Probably Overthinking It"
    ]
  },
  {
    "objectID": "extracted/Probably Overthinking It.html#acknowledgments",
    "href": "extracted/Probably Overthinking It.html#acknowledgments",
    "title": "Probably Overthinking It",
    "section": "ACKNOWLEDGMENTS",
    "text": "ACKNOWLEDGMENTS\nThank you to my editor at University of Chicago Press, Joseph Ca-\nlamia, and the other people at UCP who worked on this book: Matt Lang in acquisitions, Tamara Ghattas in manuscript editing, Brian Chartier in design, Skye Agnew and Annika Rae in production, and Anne Strother in promotions. Special thanks to the reviewers and technical reviewers.\nThanks to my former employer, Olin College of Engineering, for their support of this project from the earliest days of the “Probably Overthinking It” blog, and to my colleagues, Professors Jonathan Adler, Sara Hendren, and Carrie Nugent for their comments and suggestions.\nThanks to my current employer, DrivenData, for their ongoing support, and thanks to my colleagues who read chapters and gave helpful feedback on my practice talk.\nWhenever possible, I have sent draft chapters to relevant experts for comments. I appreciate the time they took and the suggestions they made. They include student of data science Kayla Brand; Pro- fessor Ryan Burge at Eastern Illinois University; Professor Aaron Clauset at the University of Colorado Boulder; Professor Dennis Culhane at the University of Pennsylvania; data scientist Cameron Davidson-P ilon, author of the lifelines package for survival analysis; Professor Allison Horst at the University of California, Santa Bar- bara; Dr. Frietson Galis at the Naturalis Biodiversity Center; Philip Gingerich, Professor Emeritus at the University of Michigan; Pro- fessor Sonia Hernández- Díaz at Harvard University; Dr. Nidhi Kalra and Dr. Shawn Bushway at the RAND Corporation; Professor Jeffrey Morris at the University of Pennsylvania; Professor Sergey Nigai at the University of Colorado Boulder; Floyd Norris, formerly Chief Fi- nancial Correspondent of the New York Times and now at Johns Hop- kins University; NOAA research scientist Dr. Courtney Peck; Sam- uel Preston, Professor at the University of Pennsylvania; Dr. Adrian Price- Whelan at the Flatiron Institute; Todd Rose, author of The End of Average; data scientist Ethan Rosenthal; scientist and statistician Dr. Patrick Royston; Professor Enrique Schisterman at the University of Pennsylvania; economist Dr. Andrea Stella at The Federal Reserve; Dr. Francisco Villavicencio at Johns Hopkins University; research scientist at the Planetary Science Institute, Dr. Kat Volk. Of course none of them are responsible for my errors.\nSpecial thanks to people who read several early chapters, includ- ing June Downey and Dr. Jennifer Tirnauer.\nAnd extra special thanks to the child who was one week early and the child who was two weeks late for inspiring the article that got the whole thing started, and to Lisa Downey for her love and support throughout this project, not to mention copyediting every chapter.\nThank you! ## BIBLIOGRAPHY\n[1] “Distribution of Women Age 40– 50 by Number of Children Ever Born and Mar-\nital Status: CPS, Selected Years, 1976– 2018.” United States Census Bureau, 2018.\nhttps:// www .census .gov /data /tables /time - series /demo /fertility /his - cps .html.\n[2] “27th Anniversary Edition James Joyce Ramble 10K.” Cool Running, 2010. https:// web .archive .org /web /20100429073703 /http:// coolrunning .com /results /10 /ma /Apr25 _27thAn _set1 .shtml.\n[3] “A Message from the Gay Community.” San Francisco Gay Men’s Chorus, You- Tube, July 1, 2021. https:// www .youtube .com /watch ?v = ArOQF4kadHA.\n[4] Alex Abad- Santos. “Lizard People: The Greatest Political Conspiracy Ever Cre- ated.” Vox, February 20, 2015. https:// www .vox .com /2014 /11 /5 /7158371 /lizard - people - conspiracy - theory - explainer.\n[5] Gregor Aisch and Amanda Cox. “A 3- D View of a Chart That Predicts the Eco- nomic Future: The Yield Curve.” New York Times, March 19, 2015. https:// www .nytimes .com /interactive /2015 /03 /19 /upshot /3d - yield - curve - economic - growth.html.\n[6] Robin George Andrews. “How a Tiny Asteroid Strike May Save Earthlings from City- Killing Space Rocks.” New York Times, March 21, 2022. https:// www .nytimes .com /2022 /03 /21 /science /nasa - asteroid - strike .html.\n[7] Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner. “Machine Bias: There’s Software Used across the Country to Predict Future Criminals. And It’s Biased Against Blacks.” ProPublica, May 23, 2016. https:// www .propublica. org /article /machine - bias - risk - assessments - in - criminal - sentencing.\n[8] “Anthropometric Survey of US Army Personnel.” US Army Natick Soldier Re- search, Development and Engineering Center. 2012. https:// www .openlab. psu .edu /ansur2/.\n[9] “Archive of Wednesday, 7 September 2005.” SpaceWeatherLive .com, 2005.\nhttps:// www .spaceweatherlive .com /en /archive /2005 /09 /07 /xray .html.\n[10] Hailey R. Banack and Jay S. Kaufman. “The “Obesity Paradox” Explained.” Epi- demiology 24.3 (2013): 461– 62.\n[11] “Behavioral Risk Factor Surveillance System Survey Data.” Centers for Disease Control and Prevention (CDC), 2020. https:// www .cdc .gov /brfss.\n[12] Hiram Beltrán- Sánchez, Eileen M. Crimmins, and Caleb E. Finch. “Early Cohort Mortality Predicts the Rate of Aging in the Cohort: A Historical Analysis.” Jour- nal of Developmental Origins of Health and Disease 3.5 (2012): 380– 86.\n[13] Big Five Personality Test. Open- Source Psychometrics Project. 2019. https:// openpsychometrics .org /tests /IPIP - BFFM.\n[14] George E. Bigelow, Warren E. Bickel, John D. Roache, Ira A. Liebson, and Pat Nowowieski. “Identifying Types of Drug Intoxication: Laboratory Evaluation of a Subject- Examination Procedure.” Tech. rep. DOT HS 806 753. National High- way Traffic Safety Administration, 1985. http:// www .decp .us /pdfs /Bigelow _1985 _DRE _validation _study .pdf.\n[15] “Carrington Event.” Wikipedia, 2022. https:// en .wikipedia .org /wiki /Carrington _Event.\n[16] C. R. Charig, D. R. Webb, S. R. Payne, and J. E. A. Wickham. “Comparison of Treatment of Renal Calculi by Open Surgery, Percutaneous Nephrolithotomy, and Extracorporeal Shockwave Lithotripsy.” British Medical Journal (Clinical Re- search Edition) 292.6524 (1986): 879– 82.\n[17] Y. B. Cheung, P. S. F. Yip, and J. P. E. Karlberg. “Mortality of Twins and Single- tons by Gestational Age: A Varying- Coefficient Approach.” American Journal of Epidemiology 152.12 (2000): 1107– 16.\n[18] “Child Mortality Rate, under Age Five.” Gapminder Foundation. 2022. https:// www .gapminder .org /data /documentation /gd005/.\n[19] “China Is Trying to Get People to Have More Babies.” The Economist, Septem- ber 29, 2022. https:// www .economist .com /china /2022 /09 /29 /china - is - trying - to - get - people - to - have - more - babies.\n[20] Richard P. Compton. “Field Evaluation of the Los Angeles Police Department Drug Detection Program.” Tech. rep. DOT HS 807 012, 1986. https:// trid .trb. org /view /466854.\n[21] John D. Cook. “Student- t as a Mixture of Normals.” 2009. https:// www .johndcook .com /blog /2009 /10 /30 /student - t - mixture - normals/.\n[22] Sam Corbett- Davies, Emma Pierson, Avi Feller, and Sharad Goel. “A Computer Program Used for Bail and Sentencing Decisions Was Labeled Biased against Blacks. It’s Actually Not That Clear.” Washington Post, October 17, 2016. https:// www .washingtonpost .com /news /monkey - cage /wp /2016 /10 /17 /can - an - algorithm - be - racist - our - analysis - is - more - cautious - than - propublicas/.\n[23] “Could Solar Storms Destroy Civilization? Solar Flares & Coronal Mass Ejec- tions.” Kurzgesagt— In a Nutshell. YouTube, June 7, 2020. https:// www .youtube .com /watch ?v = oHHSSJDJ4oo.\n[24] “COVID- 19 Vaccine Surveillance Report, Week 38.” Public Health England, Sep- tember 23, 2021. https:// assets .publishing .service .gov .uk /government /uploads /system /uploads /attachment _data /file /1019992 /Vaccine _surveillance report  - _week _38 .pdf.\n[25] Tyler Cowen. “Six Rules for Dining Out: How a Frugal Economist Finds the Perfect Lunch.” The Atlantic, May 2012. https:// www .theatlantic .com /magazine /archive /2012 /05 /six - rules - for - dining - out /308929/.\n[26] Gilbert S. Daniels. “The ‘Average Man’?” Tech. rep. RDO No. 695- 71. Air Force Aerospace Medical Research Lab, Wright- Patterson AFB, Ohio, 1952. https://a pps .dtic .mil /sti /pdfs /AD0010203 .pdf.\n[27] D. Scott Davis, David A. Briscoe, Craig T. Markowski, Samuel E. Saville, and Christopher J. Taylor. “Physical Characteristics That Predict Vertical Jump Per- formance in Recreational Male Athletes.” Physical Therapy in Sport 4.4 (2003): 167– 74.\n[28] Jill De Ron, Eiko I. Fried, and Sacha Epskamp. “Psychological Networks in Clin- ical Populations: Investigating the Consequences of Berkson’s Bias.” Psychologi- cal Medicine 51.1 (2021): 168– 76.\n[29] “Deaths by Vaccination Status, England.” UK Office for National Statis- tics, July 6, 2022. https:// www .ons .gov .uk /peoplepopulationandcommunity /birthsdeathsandmarriages /deaths /datasets /deathsbyvaccinationstatusengland.\n[30] “Democrats and Republicans Differ on Conspiracy Theory Beliefs.” Public Pol- icy Polling. April 2, 2013. https:// www .publicpolicypolling .com /wp - content /uploads /2017 /09 /PPP _Release _National _ConspiracyTheories _040213 .pdf.\n[31] “Birth to 36 Months: Boys; Length- for- Age and Weight- for- Age Percentiles.” Centers for Disease Control and Prevention (CDC), 2022. https:// www .cdc. gov /growthcharts /data /set1clinical /cj41l017 .pdf.\n[32] “Distribution of Undergraduate Classes by Course Level and Class Size.” Pur- due University, 2016. https:// web .archive .org /web /20160415011613 /https:// www .purdue .edu /datadigest /2013 - 14 /InstrStuLIfe /DistUGClasses .html.\n[33] Allen B. Downey. Elements of Data Science: Getting Started with Data Science and Python. Green Tea Press, 2021.\n[34] ———. Elements of Data Science: Recidivism Case Study. 2021. https:// allendowney .github .io /RecidivismCaseStudy.\n[35] ———. Probably Overthinking It: Online Resources. 2022. https:// allendowney .github .io /ProbablyOverthinkingIt.\n[36] Ebner v. Cobb County. ACLU. September 25, 2017. https:// acluga .org /ebner - v - cobb - county.\n[37] Shah Ebrahim. “Yerushalmy and the Problems of Causal Inference.” Interna- tional Journal of Epidemiology 43.5 (2014): 1349– 51.\n[38] Jordan Ellenberg. How Not to Be Wrong: The Power of Mathematical Thinking.\nPenguin, 2015.\n[39] The Joe Rogan Experience podcast, episode 1717. October 15, 2021. https:// open .spotify .com /episode /1VNcMVzwgdU2gXdbw7yqCL ?si = WjK0 _EQ7TXGgFdVmda_gRw.\n[40] K. Anders Ericsson. “Training History, Deliberate Practice and Elite Sports Per- formance: An Analysis in Response to Tucker and Collins Review— What Makes Champions?” British Journal of Sports Medicine 47.9 (2013): 533– 35.\n[41] Scott L. Feld. “Why Your Friends Have More Friends Than You Do.” American Journal of Sociology 96.6 (1991): 1464– 77.\n[42] Erwin Fleischmann, Nancy Teal, John Dudley, Warren May, John D. Bower, and Abdulla K. Salahudeen. “Influence of Excess Weight on Mortality and Hospital Stay in 1346 Hemodialysis Patients.” Kidney International 55.4 (1999): 1560– 67.\n[43] Frietson Galis, Inke Van Der Sluijs, Tom J. M. Van Dooren, Johan A. J. Metz, and Marc Nussbaumer. “Do Large Dogs Die Young?” Journal of Experimental Zoology, Part B: Molecular and Developmental Evolution 308.2 (2007): 119– 26.\n[44] “General Social Survey.” NORC at the University of Chicago, 2022. https://g ss .norc .org /Get - The - Data.\n[45] Philip D. Gingerich. “Arithmetic or Geometric Normality of Biological Varia- tion: An Empirical Test of Theory.” Journal of Theoretical Biology 204.2 (2000): 201– 21.\n[46] Malcolm Gladwell. Outliers: The Story of Success. Little, Brown, 2008.\n[47] Global Leaderboard. Chess .com, March 1, 2022. https:// www .chess .com /leaderboard /live.\n[48] Harvey Goldstein. “Commentary: Smoking in Pregnancy and Neonatal Mortal- ity.” International Journal of Epidemiology 43.5 (2014): 1366– 68.\n[49] Kristen B. Gorman, Tony D. Williams, and William R. Fraser. “Ecological Sexual Dimorphism and Environmental Variability within a Community of Antarctic Penguins (Genus Pygoscelis).” PLOS One 9.3 (2014): e90081.\n[50] Gareth J. Griffith, Tim T. Morris, Matthew J. Tudball, Annie Herbert, Giulia Mancano, Lindsey Pike, et al. “Collider Bias Undermines Our Understanding of COVID- 19 Disease Risk and Severity.” Nature Communications 11.1 (2020): 1–1 2.\n[51] Sara Hendren. What Can a Body Do? How We Meet the Built World. Penguin, 2020.\n[52] Sonia Hernández- Díaz, Enrique F. Schisterman, and Miguel A. Hernán. “The Birth Weight ‘Paradox’ Uncovered?” American Journal of Epidemiology 164.11 (2006): 1115– 20.\n[53] Allison Horst. “Example Graphs Using the Penguins Data.” Palmerpenguins, n.d. https:// allisonhorst .github .io /palmerpenguins /articles /examples .html.\n[54] Jennifer Hotzman, Claire C. Gordon, Bruce Bradtmiller, Brian D. Corner, Mi- chael Mucher, Shirley Kristensen, et al. “Measurer’s Handbook: US Army and Marine Corps Anthropometric Surveys, 2010– 2011.” Tech. rep. US Army Natick Soldier Research, Development and Engineering Center, 2011.\n[55] Steven Johnson. Extra Life: A Short History of Living Longer. Penguin, 2022.\n[56] JPL Small- Body Database. Jet Propulsion Laboratory, August 15, 2018. https://s sd .jpl .nasa .gov /tools /sbdb _lookup .html.\n[57] D. Kahneman, O. Sibony, and C. R. Sunstein. Noise: A Flaw in Human Judgment.\nHarperCollins, 2021.\n[58] Brendan Keefe and Michael King. “The Drug Whisperer: Drivers Arrested while Stone Cold Sober.” 11 Alive, WXIA- TV, January 31, 2018. https:// www .11alive .com /article /news /investigations /the - drug - whisperer - drivers - arrested - while - stone - cold - sober /85 - 502132144.\n[59] Katherine M. Keyes, George Davey Smith, and Ezra Susser. “Commentary: Smoking in Pregnancy and Offspring Health: Early Insights into Family- Based and ‘Negative Control’ Studies?” International Journal of Epidemiology 43.5 (2014): 1381– 88.\n[60] Sarah Kliff and Aatish Bhatia. When They Warn of Rare Disorders, These Prenatal Tests Are Usually Wrong. New York Times, January. 1, 2022. https:// www .nytimes .com /2022 /01 /01 /upshot /pregnancy - birth - genetic - testing .html.\n[61] Gina Kolata. “Blood Tests That Detect Cancers Create Risks for Those Who Use Them.” New York Times, June 10, 2022. https:// www .nytimes .com /2022 /06 /10 /health /cancer - blood - tests .html.\n[62] Michael S. Kramer, Xun Zhang, and Robert W. Platt. “Commentary: Yerushalmy, Maternal Cigarette Smoking and the Perinatal Mortality Crossover Paradox.” International Journal of Epidemiology 43.5 (2014): 1378– 81.\n[63] William Edward Hartpole Lecky. History of European Morals, from Augustus to Charlemagne. Vol. 1. D. Appleton, 1897. https:// www .gutenberg .org /files /39273 /39273 - h /39273 - h .html.\n[64] Ellen Lee. “At- Home COVID- 19 Antigen Test Kits: Where to Buy and What You Should Know.” New York Times, December 21, 2021. https:// www .nytimes. com /wirecutter /reviews /at - home - covid - test - kits.\n[65] Daniel J. Levitin. This Is Your Brain on Music: The Science of a Human Obsession.\nPenguin, 2006.\n[66] Dyani Lewis. “Why Many Countries Failed at COVID Contact- Tracing— but Some Got It Right.” Nature 588.7838 (2020): 384– 88.\n[67] Michael Lewis. The Premonition: A Pandemic Story. Penguin UK, 2021.\n[68] Rolv T. Lie. “Invited Commentary: Intersecting Perinatal Mortality Curves by Gestational Age— Are Appearances Deceiving?” American Journal of Epidemiology 152.12 (2000): 1117– 19.\n[69] “Life Tables by Country.” WHO Global Health Observatory, 2022. https://a pps .who .int /gho /data /node .main .LIFECOUNTRY ?lang = en.\n[70] “List of Disasters by Cost.” Wikipedia, 2022. https:// en .wikipedia .org /wiki /List _of _disasters _by _cost.\n[71] David Lusseau, Karsten Schneider, Oliver J. Boisseau, Patti Haase, Elisabeth Slooten, and Steve M. Dawson. “The Bottlenose Dolphin Community of Doubt- ful Sound Features a Large Proportion of Long- Lasting Associations.” Behavioral Ecology and Sociobiology 54.4 (2003): 396– 405.\n[72] William MacAskill, Teruji Thomas, and Aron Vallinder. “The Significance, Persistence, Contingency Framework.” GPI Technical Report No. T1- 2022.\nGlobal Priorities Institute, 2022. https:// globalprioritiesinstitute .org /wp - content /uploads /William - MacAskill - Teruji - Thomas - and - Aron - Vallinder - The - Significance - Persistence - Contingency - Framework .pdf.\n[73] Benoit B. Mandelbrot. The Fractal Geometry of Nature. Vol. 1. Freeman, 1982.\n[74] Arjun K. Manrai, Gaurav Bhatia, Judith Strymish, Isaac S. Kohane, and Sachin H. Jain. “Medicine’s Uncomfortable Relationship with Math: Calculating Positive Predictive Value.” JAMA Internal Medicine 174.6 (2014): 991– 93.\n[75] “MBTA Data.” Massachusetts Bay Transportation Authority, 2021. https:// www .mbta .com /developers.\n[76] Julian J. McAuley and Jure Leskovec. “Learning to Discover Social Circles in Ego Networks.” In Advances in Neural Information Processing Systems 25 (NIPS 2012), ed. Peter L. Bartlett et al., 2012, 548– 56. http:// dblp .uni - trier .de /db /conf /nips /nips2012 .html #McAuleyL12.\n[77] Richard McElreath. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. Chapman and Hall/CRC, 2020.\n[78] H. Jay Melosh. Planetary Surface Processes. Vol. 13. Cambridge University Press, 2011.\n[79] V. J. Menon and D. C. Agrawal. “Renewal Rate of Filament Lamps: Theory and Experiment.” Journal of Failure Analysis and Prevention 7.6 (2007): 419– 23.\n[80] Dasia Moore. “State Suspends COVID- 19 Testing at Orig3n, Boston Lab Re- sponsible for at Least 383 False Positive Results.” Boston Globe, Septem- ber 8, 2020. https:// www .bostonglobe .com /2020 /09 /08 /nation /state - suspends - covid- 19- testing - orig3n - boston - based - lab - responsible - least - 383 - false - positive - results/.\n[81] Jeffrey Morris. “UK Data: Impact of Vaccines on Deaths.” November 27, 2021.\nhttps:// www .covid - datascience .com /post /what - do - uk - data - say - about - real - world - impact - of - vaccines - on - all - cause - deaths.\n[82] Randall Munroe. “Base Rate.” xkcd, 2021. https:// xkcd .com /2476/.\n[83] “National Longitudinal Survey of Youth 1997 (NLSY97).” US Bureau of Labor Sta- tistics, 2018. https:// www .nlsinfo .org /content /cohorts /nlsy97.\n[84] “National Survey of Family Growth.” Centers for Disease Control and Preven- tion (CDC), 2019. https:// www .cdc .gov /nchs /nsfg.\n[85] Floyd Norris. “Can Every Group Be Worse Than Average? Yes.” New York Times, May 1, 2013. https:// economix .blogs. nytimes .com /2013 /05 /01 /can - every - group - be - worse - than - average - yes.\n[86] ———. “Median Pay in U.S. Is Stagnant, but Low- Paid Workers Lose.” New York Times, April 27, 2013. https:// www .nytimes .com /2013 /04 /27 /business /economy /wage - disparity - continues - to - grow .html.\n[87] Numberphile. “Does Hollywood Ruin Books?” YouTube, August 28, 2018. https:// www .youtube .com /watch ?v = FUD8h9JpEVQ.\n[88] Garson O’Toole. “If You Are Not a Liberal at 25, You Have No Heart. If You Are Not a Conservative at 35, You Have No Brain.” Quote Investigator, February 24, 2014. https:// quoteinvestigator .com /2014 /02 /24 /heart - head.\n[89] Clarence Page and a member of the Chicago Tribune’s editorial board. “When Did ‘Liberal’ Become a Dirty Word?” Chicago Tribune, July 20, 2007. https:// www .chicagotribune .com /news /ct - xpm - 2007 - 07 - 29 - 0707280330 - story .html.\n[90] Lionel Page. “Everybody Should Know about Berkson’s Paradox.” Twitter, 2021.\nhttps:// twitter .com /page _eco /status /1373266475230789633.\n[91] Mark Parascandola. “Commentary: Smoking, Birthweight and Mortality: Jacob Yerushalmy on Self- Selection and the Pitfalls of Causal Inference.” International Journal of Epidemiology 43.5 (2014): 1373– 77.\n[92] John Allen Paulos. “Why You’re Probably Less Popular Than Your Friends.” Sci- entific American 304.2 (2011): 33.\n[93] Judea Pearl and Dana Mackenzie. The Book of Why: The New Science of Cause and Effect. Basic Books, 2018.\n[94] Caroline Criado Perez. Invisible Women: Data Bias in a World Designed for Men.\nAbrams, 2019.\n[95] ———. “The Deadly Truth about a World Built for Men— From Stab Vests to Car Crashes.” The Guardian, February 23, 2019. https:// www .theguardian. com /lifeandstyle /2019 /feb /23 /truth - world - built - for - men - car - crashes.\n[96] “Personal Protective Equipment and Women.” Trades Union Congress (TUC), 2017. https:// www .tuc .org .uk /research - analysis /reports /personal - protective - equipment - and - women.\n[97] Steven Pinker. The Better Angels of Our Nature: Why Violence Has Declined. Pen- guin, 2012.\n[98] Max Planck. Scientific Autobiography and Other Papers. Open Road Media, 2014.\n[99] Samuel H. Preston. “Family Sizes of Children and Family Sizes of Women.” De- mography 13.1 (1976): 105– 14.\n[100] William Rhodes, Gerald Gaes, Jeremy Luallen, Ryan King, Tom Rich, and Mi- chael Shively. “Following Incarceration, Most Released Offenders Never Return to Prison.” Crime & Delinquency 62.8 (2016): 1003– 25.\n[101] Stuart Robbins. Lunar Crater Database. Vol. 1. August 15, 2018. https:// astrogeology .usgs .gov /search /map /Moon /Research /Craters /lunar _crater _database _robbins _2018.\n[102] ———. “A New Global Database of Lunar Impact Craters &gt; 1– 2 km: 1. Crater Lo- cations and Sizes, Comparisons with Published Databases, and Global Analysis.” Journal of Geophysical Research: Planets 124.4 (2019): 871– 92.\n[103] Derek Robertson. “How an Obscure Conservative Theory Became the Trump Era’s Go- to Nerd Phrase.” Politico, February 25, 2018. https:// www .politico. com /magazine /story /2018 /02 /25 /overton - window - explained - definition - meaning - 217010/.\n[104] Oliver Roeder. Seven Games: A Human History. W. W. Norton, 2022.\n[105] Todd Rose. The End of Average: How to Succeed in A World That Values Sameness.\nPenguin UK, 2016.\n[106] Tom Rosentiel. Four- in- Ten Americans Have Close Friends or Relatives Who Are Gay. Pew Research Center, May 27, 2007. https:// www .pewresearch .org /2007 /05 /22 /fourinten - americans - have - close - friends - or - relatives - who - are - gay/.\n[107] Ryan A. Rossi and Nesreen K. Ahmed. “The Network Data Repository with Interactive Graph Analytics and Visualization.” AAAI, 2015. http:// networkrepository .com.\n[108] Sigal Samuel. “Should Animals, Plants, and Robots Have the Same Rights as You?” Vox, April 4, 2019. https:// www .vox .com/ future - perfect /2019 /4 /4 /18285986 /robot - animal - nature - expanding - moral - circle - peter - singer.\n[109] “SARS- CoV- 2 Variants of Concern and Variants Under Investigation In En- gland.” Technical Briefing 44, UK Health Security Agency, July 22, 2022.\nhttps:// assets .publishing .service .gov .uk /government /uploads /system /uploads /attachment _data /file /1093275 /covid- technical - briefing - 44 - 22 - july - 2022 .pdf.\n[110] Jonathan Schaeffer. Marion Tinsley: Human Perfection at Checkers? 2004.\nhttps:// web .archive .org /web /20220407101006 /http:// www .wylliedraughts .com /Tinsley.htm.\n[111] “Sentences Imposed.” Federal Bureau of Prisons, 2019. https://www. bop. gov /about /statistics /statistics _inmate _sentences .jsp.\n[112] “September 2005 Aurora Gallery.” SpaceWeather .com, 2005. https:// spaceweather .com /aurora /gallery _01sep05 _page3 .htm.\n[113] Peter Singer. The Expanding Circle. Princeton University Press, 1981.\n[114] Charles Percy Snow and Baron Snow. The Two Cultures and the Scientific Revolu- tion. Cambridge University Press, 1959.\n[115] Southern California Earthquake Data Center. Caltech/USGS Southern California Seismic Network, 2022. https:// scedc .caltech .edu/.\n[116] “Spud Webb.” Wikipedia, 2022. https:// en .wikipedia .org /wiki /Spud _Webb.\n[117] Steven Strogatz. “Friends You Can Count On.” New York Times, Septem- ber 17, 2012. https:// opinionator .blogs .nytimes .com /2012 /09 /17 /friends - you - can - count- on.\n[118] “Supplemental Surveys.” United States Census Bureau, 2022. https:// www .census .gov /programs - surveys /cps /about /supplemental - surveys .html.\n[119] Surveillance, Epidemiology, and End Results (SEER) Program. National Cancer In- stitute. 2016. https:// seer .cancer .gov /data/.\n[120] SWPC Data Service. Space Weather Prediction Center. 2022. https:// www .ngdc .noaa .gov /stp /space - weather /solar - data /solar - features /solar - flares /x - rays /goes/xrs/.\n[121] Nassim Nicholas Taleb. The Black Swan: The Impact of the Highly Improbable.\nVol. 2. Random House, 2007.\n[122] “The Overton Window of Political Possibility Explained.” Mackinac Center.\nYouTube, February 21, 2020. https://w ww .youtube .com /watch ?v = ArOQF4kadHA.\n[123] Derek Thompson. “The Pandemic’s Wrongest Man: In a Crowded Field of Wrongness, One Person Stands Out: Alex Berenson.” The Atlantic, April 1, 2021.\nhttps:// www .theatlantic .com /ideas /archive /2021 /04 /pandemics - wrongest - man /618475.\n[124] Benjamin Todd. 80,000 Hours: Find a Fulfilling Career That Does Good. 2022.\nhttps:// 80000hours .org/.\n[125] Zeynep Tufekci. “This Overlooked Variable Is the Key to the Pandemic.” The At- lantic, September 30, 2020. https:// www .theatlantic .com /health /archive /2020 /09 /k - overlooked - variable - driving - pandemic /616548/.\n[126] “Tunguska Event.” Wikipedia, 2022. https:// en .wikipedia .org /wiki /Tunguska _event.\n[127] Johan Ugander, Brian Karrer, Lars Backstrom, and Cameron Marlow. “The Anatomy of the Facebook Social Graph.” 2011. https:// arxiv .org /abs /1111 .4503.\n[128] Tyler J. VanderWeele. “Commentary. Resolutions of the Birthweight Paradox: Competing Explanations and Analytical Insights.” International Journal of Epide- miology 43.5 (2014): 1368– 73.\n[129] James W. Vaupel, Francisco Villavicencio, and Marie- Pier Bergeron-B oucher.\n“Demographic Perspectives on the Rise of Longevity.” Proceedings of the National Academy of Sciences 118.9 (2021): e2019536118.\n[130] Vital Statistics Online Data Portal. Centers for Disease Control and Prevention (CDC), 2018. https:// www .cdc .gov /nchs /nsfg.\n[131] Allen J. Wilcox and Ian T. Russell. “Perinatal Mortality: Standardizing for Birthweight Is Biased.” American Journal of Epidemiology 118.6 (1983): 857–6 4.\n[132] Samuel H. Williamson. “Daily Closing Value of the Dow Jones Average, 1885 to Present.” MeasuringWorth, 2022. https:// www .measuringworth .com /datasets/DJA.\n[133] J. Yerushalmy. “The Relationship of Parents’ Cigarette Smoking to Outcome of Pregnancy— Implications as to the Problem of Inferring Causation from Ob- served Associations.” American Journal of Epidemiology 93.6 (1971): 443– 56.\n[134] ———. “The Relationship of Parents’ Cigarette Smoking to Outcome of Pregnancy— Implications as to the Problem of Inferring Causation from Ob- served Associations.” International Journal of Epidemiology 43.5 (2014): 1355–6 6.",
    "crumbs": [
      "Data Science",
      "Probably Overthinking It"
    ]
  },
  {
    "objectID": "extracted/Probably Overthinking It.html#index",
    "href": "extracted/Probably Overthinking It.html#index",
    "title": "Probably Overthinking It",
    "section": "INDEX",
    "text": "INDEX\naberration, 75 basketball, 99\naccretion, 144 bathtub curves, 89 accuracy, 153 Behavioral Risk Factor Surveillance Sys- ACT (standardized test), 100 tem (BRFSS), 60 age effects, 207, 219 bell curves, 6, 131 age- period- cohort analysis, 202, 207, Berkson, Joseph, 105 216 Berkson’s paradox, 100, 105– 11, 123, 126 Air Force Anthropometric Survey, 15 Berkson’s toaster, 123 airlines, 42 Big Five Personality Test, 18 alcohol prohibition, 216 birth cohorts, 203, 205, 207, 209, 212, algorithmic fairness, 151 217– 18, 222 American Civil Liberties Union (ACLU), birth defects, 118 158 birth weights, 63, 83, 113, 120, 240 ANSUR- II, 6 Black Monday, 145 Antarctica, 187 black swans, 147 Anthropometric Survey of US Army Per- blog, 232 sonnel (ANSUR), 60 Bolt, Usain, 67 asteroids, 140 BRFSS (Behavioral Risk Factor Surveil- asymptotic behavior, 145 lance System), 60 Atlanta Braves, 67 brood size, 46 “‘Average Man’?, The” (Daniels), 14 Broward County (Florida), 166 average remaining lifetime, 82, 90, 97 Bureau of Labor Statistics, 185 average remaining survival time, 86 calibration, 173 Baby Boom, 48 call center, 43 backward tracing, 36 Carlin, George, 38 Bahadur Dangi, Chandra, 66 Carlsen, Magnus, 75 base rate fallacy, 3, 152, 158, 161, 166, 175 causal diagrams, 123– 24, 126 base rates, 153, 165 causal relationships, 124, 191 CDFs (cumulative distribution func- disasters, 127– 32, 136, 140, 150 tions), 11– 13, 19, 61, 81, 85, 130 divorces, 188 Centers for Disease Control and Preven- dogs, 188 tion (CDC), 25 dolphins, 35 Central Limit Theorem, 10, 64– 65 Doubtful Sound, 35 checkers, 75 Dow Jones Industrial Average, 145 Chernobyl disaster, 128 draughts (checkers), 75 cherry- picking, 193 “drugged driving,” 158– 61 chess, 60, 70, 74 Drug Recognition Expert (DRE), 158– 59 Chess.com, 70 child mortality, 90– 92, 97 earthquakes, 128– 36, 147 China, 56 education, 184 cholecystic disease, 105– 7 80,000 Hours project, 76 class size, 28– 32, 39 Elite University, 101– 2 CMEs (coronal mass ejections), 137 Elo chess- rating system, 70, 74 cohort effects, 207– 8, 210, 212– 13, 222, End of Average, The (Rose), 25 224 Ericsson, K. Anders, 72 college admissions, 100, 103 error rates, 170– 74 collider bias, 111, 126, 231 event- based samples, 41 COMPAS, 166– 73 evidence, 1, 231 conservative (political alignment), 221, 224, 226– 27 Facebook, 34 convenience samples, 156– 57 facilities engineer, 79 coronal mass ejections (CMEs), 137 fairness, 151 correlation, 100– 110, 187– 95 faith in humanity, 181 counterfactual model, 162, 212, 224 false negative rates (FNRs), 152– 53, COVID- 19, 2, 35, 107– 8, 152– 58, 192– 98 169– 70, 173 COVID vaccine, 162– 66, 179– 80, 192– 98 false positive rates (FPRs), 152– 59, 169– Criado Perez, Caroline, 24, 25 70, 173, 176– 77, 205 criminal justice, 40– 42, 151– 52, 166, family of orientation, 47, 53 173– 75 family size, 42, 45– 57 cumulative distribution functions fear, 188– 90 (CDFs), 11– 13, 19, 61, 81, 85, 130 Feld, Scott, 33 Current Population Survey (CPS), 47, 185 feminism, 205 FNRs (false negative rates), 152– 53, Daniels, Gilbert, 15, 20 169– 70, 173 Darwin, Charles, 188 forearm length, 14 data bias, 172 forward tracing, 36 data visualization, 3, 232 fourfold table, 106 death rates, 162– 65, 179, 192– 98 FPRs (false positive rates), 152– 59, 169– depression, 109 70, 173, 176– 77, 205 deviation, 12– 19, 146 Fractal Geometry of Nature, The (Mandel- diabetes, 105– 7, 121, 125 brot), 144 diagnostic tests, 176 Freeze (baseball mascot), 67 friendship paradox, 34– 35, 43 Holder, Eric, 169– 70 Fukushima nuclear disaster, 128 homophobia, 208– 14 Hong Kong, 36 Gapminder, 90 Horst, Allison, 187 Gauss, Carl Friedrich, 8 hospital samples, 107 Gaussian curves, 6– 9, 23, 32, 63 hurricanes, 127 Gaussian distributions, 12– 14, 59– 60, 64– 69, 74– 75, 87– 89, 129– 32, 147 immortal Swede, 92– 97 gay agenda, 211– 12 individual- based sample, 41 Gay Pride Day Parade, 211 infant mortality, 113– 16, 120 gender bias, 168 inspection paradox, 27– 43 General Social Survey (GSS), 111, 180, integrated flux, 137– 39 188, 199– 202, 228 intergenerational stability, 55 generational replacement, 183, 201, International Personality Item Pool 213, 224 (IPIP), 18 Geostationary Operational Environ- interracial marriage, 204 mental Satellite system (GOES), 137 Invisible Women (Criado Perez), 24, 25 Gingerich, Philip, 61 Gladwell, Malcolm, 72 James Joyce Ramble, 38, 68 glioblastoma, 79, 84 Jet Propulsion Laboratory (JPL), 142 Global Health Observatory, World Jordan, Michael, 73 Health Organization (WHO), 91 Jupyter notebook, 3 GOAT (greatest of all time), 73 GOES (Geostationary Operational Envi- Kaplan- Meier estimation, 85 ronmental Satellite system), 137 Kasparov, Garry, 75 Gompertz, Benjamin, 93 Kepler space telescope, 140 Gompertz Law, 93 Kerman, Piper, 38– 40 Gosset, William Sealy, 131 kidney failure, 121– 22 gray swans, 147 kidney stones, 190– 91 Great Depression, 46– 48 Kirk, Marshall, 211 greatest of all time (GOAT), 73 Great Leap Forward, 91 Late Heavy Bombardment, 142 Gretzky, Wayne, 73– 74 Lecky, William, 201 GSS (General Social Survey), 111, 180, length- biased sampling, 27– 28, 35, 231 188, 199– 202, 228 leptokurtotic, 32 Guinness World Records, 66 Levitin, Daniel, 73 Lewis, Michael, 37 Hamilton Rating Scale for Depression liberal (political alignment), 217– 28 (HRSD), 109 life expectancy, 88– 95 heart failure, 121– 25 lifespan, 81, 89, 188 height, 5– 16, 59, 66– 68, 99– 100, 129, light bulbs, 79– 82, 87, 92 148– 49 lizard people, 204, 215 high altitude, 117 logarithmic scales, 68, 128 histograms, 11, 19 logarithms, 59– 68, 131– 33 logistic regression, 212 National Longitudinal Survey of Youth lognormal distributions, 59– 77, 83, 88, 1997 (NLSY97), 100– 101, 103– 4 129– 49 National Survey of Family Growth log- t distributions, 131– 48 (NSFG), 63, 83, 232 long- tailed distributions, 129– 31, 143– 50 NBUE (new better than used in expecta- Long- Tailed World, 148– 50 tion), 87, 92, 96 low- birthweight paradox, 1– 3, 113– 26 NCHS (National Center for Health Sta- LOWESS curves, 180 tistics), 115, 119, 126 Lunar Crater Database, 141, 149 negative predictive value (NPV), 166– 67, lunar craters, 140– 50 170, 173– 74 Lunar Reconnaissance Orbiter, 141 new better than used in expectation (NBUE), 87, 92, 96 MacFarlane, Seth, 24 new worse than used in expectation Madsen, Hunter, 211 (NWUE), 87 Mandelbrot, Benoit, 144 New York Times, 3 marketplace of ideas, 199 New Zealand, 35 Massachusetts Institute of Technology Nigeria, 91 (MIT), 99 NIH (National Institutes of Health), 84, maternal smoking, 1– 2, 113– 25 115 maternity wards, 82 1918 influenza pandemic, 91 MBTA (Massachusetts Bay Transporta- normality, 5– 6, 22– 23 tion Authority), 32 Norris, Floyd, 184 MeasuringWorth Foundation, 145 NPV (negative predictive value), 166– 67, medical tests, 152– 58 170, 173– 74 mixture, 186, 190 NSFG (National Survey of Family moderate (political alignment), 225 Growth), 63, 83, 232 moment magnitude scale, 133 NumPy (software), 4 moral circle, 201 NWUE (new worse than used in expec- Morris, Jeffrey, 195 tation), 87 mortality rates, 88– 98, 113– 20 multiple births, 120 obesity paradox, 121– 26 multiplication, 68– 69, 72, 76 obstetrician, 79 musical ability, 72 oncologist, 79 one- child policy, 56 NASA, 141, 142 open data, 18, 198 Natick Soldier Center, 6 open science, 233 National Center for Health Statistics Open- Source Psychometrics Project, 18 (NCHS), 115, 119, 126 optimism, 180 National Coming Out Day, 211 Orange Is the New Black (Kerman), 38 National Death Index, 122 Our World in Data, 198 National Health and Nutrition Examina- outliers, 60, 75, 129– 30 tion Survey, 122 Outliers (Gladwell), 72 National Institutes of Health (NIH), 84, oversampling, 28, 32, 40– 41, 47 115 Overton window, 202, 214– 17, 223, 226– 28 Palmer Research Station, 186– 87 rapid antigen tests, 153 pandas (software), 4 Reagan era, 225 paradox, 2– 3, 27–4 6, 52, 100, 105– 26, real wages, 184– 86 180, 183– 203, 212, 216– 17, 222, 231 recidivism, 40– 44, 166– 75 PCR (polymerase chain reaction), 155 Red Line (Boston), 32 penguins, 186– 88 relay races, 27, 37 percentile ranks, 11– 14 reproducible science, 3, 233 period effects, 207– 13, 222– 24, 231 resampling, 31 pessimism, 180 Richter scale, 133 Pew Research Center, 211 Rose, Todd, 25 Planck, Max, 201 Rosser, Tim, 213 polarization (political), 226 Royal Demographer, 45 political alignment, 221, 226 Russell, Ian, 115 political center, 222– 27 political opinions, 219– 28 sampling, 28– 48, 61– 64, 74, 84, 100– 110, popliteal height, 13 123, 130– 31, 157, 167, 180, 187, 232 PopulationPyramid, 195 Samuelson, Paul A., 201 positive predictive value (PPV), 167, 170, San Francisco Gay Men’s Chorus, 213 173 SAT (standardized test), 100 PPV (positive predictive value), 167, 170, SciPy (software), 4 173 screening tests, 158, 176– 77 predictive values, 169– 74 Secondtier College, 104– 5 pregnancy, smoking during, 1, 113– 19 SEER (Surveillance, Epidemiology, and pregnancy duration, 79, 82– 84, 232 End Results) program, 84 prejudice, 172 selection bias, 101, 103, 108, 231 Premonition, The (Lewis), 37 sensitivity, 153– 57, 160– 61, 166– 69, 176 Preston, Samuel, 46 sentence length, prison, 28, 39– 44 Preston’s paradox, 46– 57 sexist beliefs, 205– 8, 214 prevalence, 154, 157, 204– 5 sexual orientation, 208– 14 prisons, 39– 44, 151, 166, 174– 75 significance- persistence- contingency prognosis, 85– 86 (SPC) framework, 75– 76 prohibition, alcohol, 216 Simpson, Abe, 228 propaganda, 211 Simpson, Edward H., 183 proportional growth, 64– 66, 71– 72 Simpsons, The (television show), 228 ProPublica, 166 Simpson’s paradox, 180, 187, 199, 203, psychology, Berkson’s paradox and, 217, 222 109 simulation, 10, 29, 54– 56, 64– 65, 70, 115, Public Health England, 2, 161, 164 143– 44 Public Policy Polling, 204 skewed distributions, 19, 61, 64, 83 Purdue University, 28 slam dunks, 99 Snow, C. P., 102 racial bias, 168– 75 social media, 199 racist beliefs, 201– 5, 214 Sohne, Charlie, 213 rank- size plots, 128 solar flares, 136 Southern California Earthquake Data UK Health Security Agency, 195 Center, 132 UK Office for National Statistics, 179, Space Weather Prediction Center 192, 196 (SWPC), 137 unbiasing, 30– 39, 172 SPC (significance- persistence- Uniform California Earthquake Rupture contingency) framework, 75– 76 Forecast (UCERF3), 135 Spearmon, Wallace, 67 United Nations Department of Eco- specificity, 153– 57, 160– 61, 166– 69, 176 nomic and Social Affairs, 195 spurious correlations, 107 unnamed journalist, 161– 63, 179, 192– 99 standard deviations, 16– 17, 49, 69, 100– “Upshot, The,” 3 101 USA Today, 3 standardized tests, 11, 100– 105 US Census Bureau, 47, 185 stock market crash, 145– 46 US Centers for Disease Control and Pre- Student’s t distribution, 131– 48 vention (CDC), 60 Super Bulbs, 82 US Federal Bureau of Prisons (BOP), 39 superflares, 140, 147– 48 US Geological Survey (USGS), 135 superspreaders, 28, 35– 37 USGS (US Geological Survey), 135 Supreme Court, US, 204 US National Institutes of Health (NIH), 84 Surveillance, Epidemiology, and End US Supreme Court, 204 Results (SEER) program, 84 survival curves, 85, 94– 97 vaccines, 152, 161– 66, 179– 80, 192– 98 survival times, 80– 81, 84– 88, 121 variance, 49, 74 Sweden, 88– 92, 120 vertical leap, 99 SWPC (Space Weather Prediction Cen- volleyball, 99 ter), 137 symmetric distributions, 61, 64, 66, 129 Wadlow, Robert, 66 Washington Post, 170 tail distributions, 130– 34, 138– 46 weakest link, 70– 72 Taleb, Nassim, 147 Webb, Michael Anthony Jerome Talton, Nigel, 67 “Spud,” 99 10,000 hours, 72– 73 weight, adult, 59– 66, 129 time machine, 227 weight, at birth, 63, 83, 113, 120, 240 Tinsley, Marion, 75 weight, correlation with lifespan, 188 Trades Union Congress, 24, 25 weighted resampling, 31 traditionalism, 55 weight gain, 64– 66 tungsten, 81 weirdness, 5– 6, 22– 23 twin paradox, 120– 21 Wilcox, Allen, 115 “Two Cultures, The” (Snow), 102 Williams, Serena, 73 World War II, 91 UCERF3 (Uniform California Earth- quake Rupture Forecast), 135 Yerushalmy, Jacob, 113 UK BioBank, 108",
    "crumbs": [
      "Data Science",
      "Probably Overthinking It"
    ]
  },
  {
    "objectID": "extracted/On_the_material_supports_of_subjectivity.html",
    "href": "extracted/On_the_material_supports_of_subjectivity.html",
    "title": "On the material supports of subjectivity",
    "section": "",
    "text": "Article in Social Science Information · July 2022 DOI: 10.1177/05390184221109772 CITATIONS READS 2 88 1 author: Fabrício Cardoso de Mello Rio de Janeiro State University 13 PUBLICATIONS 11 CITATIONS SEE PROFILE [This is the accepted version of a text published in 2022 in Social Science Information: https://doi.org/10.1177/05390184221109772. Please refer to the published version for quoting.]",
    "crumbs": [
      "General",
      "On the material supports of subjectivity"
    ]
  },
  {
    "objectID": "extracted/On_the_material_supports_of_subjectivity.html#on-the-material-supports-of-subjectivity-mead-the-self-and-the-new-mastery-of-nature",
    "href": "extracted/On_the_material_supports_of_subjectivity.html#on-the-material-supports-of-subjectivity-mead-the-self-and-the-new-mastery-of-nature",
    "title": "On the material supports of subjectivity",
    "section": "On the material supports of subjectivity: Mead, the self and the new mastery of nature",
    "text": "On the material supports of subjectivity: Mead, the self and the new mastery of nature\nFabrício Cardoso de Mello Postdoctoral researcher (PNPD-CAPES), Graduate Program in Political Sociology – Vila Velha University (Brazil)",
    "crumbs": [
      "General",
      "On the material supports of subjectivity"
    ]
  },
  {
    "objectID": "extracted/On_the_material_supports_of_subjectivity.html#abstract",
    "href": "extracted/On_the_material_supports_of_subjectivity.html#abstract",
    "title": "On the material supports of subjectivity",
    "section": "Abstract:",
    "text": "Abstract:\nThe pragmatism of George Herbert Mead has been fundamental to the sociological understanding of the self. However, the complexity of his work is largely unrecognized in the discipline. This mainly affects the way Mead intertwined discursivity with the materiality of experience in his conception of human subjectivity. Through a metatheoretical analysis, the present paper proposes a straightforward approximation between Mead’s theories of the self and the act in order to contemplate the incidence of processes encompassed by the latter upon the former. Based on this movement, and after a dialogue with Francis Chateauraynaud’s pragmatic sociology, the paper suggests a new Meadian-inspired sociological alternative to the concept of self, attentive to its material dimension and centered on the concepts of outer and inner grasps. The current discussion about the ontological politics in the context of a new mastery of nature allows for an empirical exercise of the argument.\nKeywords: George Herbert Mead; materiality; self; pragmatic sociology; risk\nIntroduction The prominence enjoyed by the idea of interaction in the theoretical framework of sociology is much indebted to George Herbert Mead’s pragmatist philosophy. His proposal of a socially developed individual self (Mead, 1903, 1910, 1912, 1913, 1922, 1925, 1967 [1934], 2011 [n.d.]) has been taken by different approaches within the sociological discipline as an axis for the solution of the polarization between structure and agency. The communicative properties of interaction, which stand out in his discussions on social psychology, have been pivotal in this aspect. However, sociology has underexplored the fact that neither interaction nor the self are restricted to such properties in Mead’s work.\nAlthough not focused directly or systematically on the topic of the self, his theory of the act and his general discussion on the human perception of physical objects (Mead, 1912, 1926, 1932, 2011 [n.d.], especially 1972 [1938]), suggest that the material dimension of experience is elementary for the self’s constitution and performance. The overall goal of the present article is of metatheoretical nature, namely, to develop a Meadian-inspired sociological alternative to the concept of self which is not limited to its internal and external symbolic transactions, but which is also attentive to the material groundings of such interactions.\nThe first section of the text sets the problem of the sociological undervaluation of Mead’s concern with the material properties of the self. I analyze the form in which three specific authors, Herbert Blumer, Jürgen Habermas and Axel Honneth were central for the reduction of Mead’s complexity to his proposition of symbolically mediated intersubjectivity as the pillar of the dynamics of socialization. A fourth scholar, Hans Joas, partially departs from the problem, but still joins the others in a limiting view on the internal composition of the self which, due to the wide reach of their readings of Mead, became hegemonic in the social sciences. A counter-hegemonic understanding of the inner structure of the self is addressed in the following section, which presents an internal reconstruction of Mead that straightforwardly brings together his theories of the self and the act. It addresses the issue of materiality in the Meadian act based on Markell’s reading of the concepts of “I” and “me” (Markell, 2007) and puts into dialogue three different faces of Mead, which are not systematized in his own work due to its fragmented characteristic: the Jamesian, Deweyan and Whiteheadian ones. The purpose behind this move is to seek in Mead’s own conceptual edifice the foundation for a conception of the self where the materiality of experience plays active role in the construction of subjectivity.\nThe third and last section sets off seeking to empirically ground the previous conceptual work. The social sciences have recently faced epistemological challenges set by technological advancements in ventures such as biotechnology and geoengineering, which promote what Pellizzoni (2015) has named the new mastery of nature. Based on new forms of structural intervention in matter, these new technologies increasingly guide considerations about the relations between nature, capitalism and risk towards an ontological dimension of analysis. They also set the stage for renewed reflections on the intersection between the material contact with the world and the production of subjectivity within contemporary modernity. Accordingly, I draw upon the aforementioned metatheoretical endeavor in order to tackle the vicissitudes of this new historical formation. My starting point for this task lies in considering that Mead’s pragmatism is as important to detail the engine moving the political ontology of this new relationship with nature as it is to build an inquiry critique based on practical consequences as the most adequate criterion for judgement. In a decisive point of this last section I signal the need for a sociological interlocutor able to back up Mead’s material concerns, suggesting Francis Chateauraynaud’s pragmatic sociology, and specifically his discussion around the concept of grasps (prises), as fit for this purpose. I then settle my argument with a Meadian rendering of Chateauraynaud, advancing the idea of the individual self as composed by inner and outer grasps. By taking such a step, on the one hand, the operationalization of elements such as conflict, asymmetry and domination in Mead is enabled, whereas, on the other hand, Chateauraynaud’s sociology benefits from a valuable input for the construction of a pragmatics of interiority.\n\nThe neglect of Mead’s ecological view of the self in social theory and the hegemonic interpretation of the “I” and the “me” Not a sociologist himself, Mead’s incorporation into the discipline often relied on the mediation of authors directly affiliated to sociology or with a wide margin of influence over its academic field. Throughout the 20th century, symbolic interactionism and critical theory provided decisive entry points for the “sociologization” of Mead, imprinting their marks on the form which sociologists absorbed his concepts (Silva, 2007; Huebner, 2014).\n\nIn this section I draw a critical appraisal of four interpretations of Mead made by different authors: Herbert Blumer (symbolic interactionism), Jürgen Habermas and Axel Honneth (critical theory) and Hans Joas (linked to both critical theory and Chicago’s sociological tradition). Notwithstanding notable differences among them, the first three authors converge on what can be deemed as a problematic understanding of Mead’s conception of self, which has as one of its outcomes the omission of the importance of materiality in his pragmatism.\nJoas, on the other hand, hints at the direction for the solution of this problem, but does not follow the path to the end, since he stands by the same limiting understanding of the Meadian concepts of “I” and “me” as that of the other three authors.\nIt is worth discussing briefly some of the most substantial elements of Mead’s thought about the social construction of the self and its communicative properties in order to understand the role the aforementioned authors reserve for him in their own respective works. By assuming an anti-Cartesian position, Mead does not consider the self as an anthropological starting point but conceives it as the outcome of ecologically contextualized communicative processes that evolve both phylogenetically and ontogenetically. Two influences are central to him in this assertion: the integrating view that, by late 19th century, Dewey (1896) launched over the concepts of stimulus and response in perception and the relevance proposed by Wundt of the interchange of gestures as a foundational factor of language (Mead, 1903, 1910, 1922)1. Mead locates the origins of the self in the conversation of gestures among two or more individuals belonging to a given species in the animal world.\nSuch conversation sets stimuli and response circuits that coordinate the succession of acts in the behavior of those individuals. The distinctive feature of the conversation of gestures in human species lies on its qualitative remark supported by the development of a reflective intelligence, or reflective conscience, capable of giving meaning to the expression of attitudes through significant symbols (Mead, 1910: 178, 1922: 161, 1967 [1934]: 45ff, 90- 100). A gesture brings along a significant symbol “[…] when it has the same effect on the individual making it that it has on the individual to whom it is addressed, or who explicitly responds to it […]” (Mead, 1967 [1934]: 46), whereas the origins of meaning lie on concrete interactions throughout the course of communicative experiences among individuals, when they mutually alter their responses by taking a specific goal as reference and reach a substantial degree of symbolic unity (Mead, 1967 [1934]: pp.77-80).\nOne of the most relevant consequences Mead extracts from his idea of reflective intelligence is that a gesture imprinted by an individual towards a companion of action, in other words, a stimulus to the other’s response, already carries along the projective anticipation of such a response, so that the uttering individual is also stimulated by its own gesture. The extension of this dynamics opens room for the continuous process of reciprocal 1 In regard to Mead’s intellectual relations with Dewey, it is correct to say they both influenced each other throughout their careers.\nmodification of gestures that structures the collective coordination of behaviors. By acting this way, the individual continuously relies upon the attitudes that others address towards it in order to become an object for oneself. In its turn, this subjective movement implies that the individual also acts as the very subject of oneself by rebuilding its position within the social act in a manner attuned to information provided by the world around to it (Mead, 1913: 379-380, 1922: 160, 1925: 267, 1967 [1934]: 135ff). We can observe, at this point, the socialized nature of the self. It is constituted as a psychosocial structure with interactive characteristics that expresses itself as an inner conversation, or forum, where both its subjective and objective aspects take part in. It encompasses reminiscences acquired by the individual actor through the environments it has experienced and the people it has lived and communicated with, directly or indirectly, throughout its life. These elements work out as raw material for the construction of this actor’s own individuality.\nMead’s social-psychological outline sketched above was taken by Blumer as the main pillar of his symbolic interactionist approach. Blumer (1969) relies on Mead’s discussion of the relation between mind, reflective intelligence and the significant symbol in order to suggest that society might be seen as comprised by the interlinkage of symbolic and non-symbolic interactions among individuals, and that sociology’s main task is to develop its analytical work specifically focused on the former. This is so because, in his view, Mead’s major legacy to sociology would be to portray society as constructed characteristically out of the conscious organization of meanings found in the intersubjective relations of a plurality of selves. For Blumer (1969: 23ff), therefore, “the obdurate character of the empirical world” that repeatedly challenges the rigid models of the sociologist is marked by the contingency and fluidity of the interchange of meanings that forms the core of people’s social experiences.\nSymbolic interactionism turned out to be a richly diversified sociological current, unrestricted to Blumer’s own ideas and with different degrees of proximity to Mead’s philosophy depending on each author (Joas, 1993: ch.1). However, it is notorious that over the years Blumer acted not as an ordinary epigone, but as heir apparent and legitimate interpreter of Mead, adapting his philosophical work to the language and empirical methodology of sociology. His particular approach was key for the reception of Meadian concepts in the American social sciences (Huebner, 2014: 158ff).\nAlthough critical theory’s first generation was quite skeptical about the validity of American pragmatism (Joas, 1993: ch.4), Mead’s social psychology was of great importance to the theoretical synthesis developed by Habermas, one of the leading figures of Frankfurt School’s second generation. Habermas found in Mead’s theoretical framework elements he believed were capable of restituting the emancipatory potential of the concept of reason within the universe of the German critique, since the pragmatist’s decentralized conception of conscience allowed him to wander about a consensual social dynamics based on cognitively and normatively justified actions. The Meadian concept of the generalized other was essential for Habermas to locate the construction of legitimacy within the communicative practices of the phenomenological concept of the lifeworld. In Mead’s work (1922: 161ff, 1925: 268ff, 1932: 87, 1967 [1934]: 154), the generalized other refers to the internalization of the structural organization of the attitudes of community by the individual.\nAkin to Blumer, but with structural inclinations, Habermas (1987 [1985]: 37-44) sees in this set of roles and expectations the key point of the production of norms, notwithstanding his conclusion that Mead, in his own work, shied away from a satisfactory solution to the problem of institutions.\nMead’s ideas are also an important reference for the architecture of Axel Honneth’s theory of recognition, which sought a new reformulation of Frankfurt’s critical tradition by introducing social conflict as the driving force of historical transformation. Honneth saw in the struggle for recognition the collectivized instance of the inner tensions of Mead’s self, the ones deriving from conversations or discussions between its two phases. In a very general way (to be further worked out shortly) we may define the“I” as the element which corresponds to the self’s subjective facet and the “me” as the one which is correlated to its objective facet (Mead, 1912, 1913, 1925, 1967 [1934], 2011 [n.d.]). According to Honneth’s reasoning (Honneth, 2002: 502), by taking the reciprocity of recognition “[…] as the individual evolution of a ‘me’ that consists in the consciousness of legitimate social expectations, then the ‘I’ could perhaps be conceptualized as the source of continuous rebellion against established forms of recognition […]”. By resorting to Mead, Honneth (1995 [1992]: 84-85) saw an opportunity to fill the motivational gap in Hegel’s theory of recognition. The “I” would be a force behind demands for the extension of society’s structures of recognition in favor of causes hitherto not incorporated by them, since it would be a source of irradiation of individuals’ creativity that stands up to the conventionality of the “me”.\nWhat has been discussed so far allows the realization that the form through which Blumer, Habermas and Honneth imported Mead’s thought does not make justice to it, since they access his discussion on the self from only one of the angles available in his work, namely: a social psychology concerned with the symbolic properties of the formation of consciousness and communication. Hans Joas, another student of Habermas trained in the Frankfurtian lineage, but who also established strong bonds to the Chicago tradition, shined light on some consequences of this limited view of Mead’s thought. According to Joas (1993: 137), Habermas’ restriction (also observed in Blumer and Honneth) of the Meadian conception of social interaction at gestural language level is a “misunderstanding” that would, furthermore, explain the assessment that a satisfactory discussion about the institutionalized social order is absent in Mead. Not only would that be untrue (given Mead’s concerns about democracy and science - Joas, 1993: 137, also see 1985 [1980]: ch.9; Silva, 2008), but the same interpretation puts aside other extremely important objects of Mead’s philosophy.\nAs suggested by Joas (1985 [1980]: 145ff), there was never a border in Mead’s writings between a world of action exclusively inhabited by humans and a world of non- human beings and inanimate objects fully excluded from linguistic exchanges. For the pragmatist philosopher, subjectivity and the production of meaning take place in complex milieus where human behavior is engaged with entities of plural constitutions. This feature evidences Mead’s connection to the strong naturalist profile spread over the pragmatist environment of Chicago during the passage from the 19th to the 20th century (Dewey et al, 1945; Cefaï, 2001). Reflecting on the ethical implications of this environmental characteristic of Mead, Brewster and Puddephatt (2016: 155) claim that his would be an “ecological view of the self”, which becomes “[…] more expansive both by being progressively more inclusive of diverse others [i.e. human and non-human] into our existing groups and communities and by progressively identifying with larger groups and communities […]”.\nBy stripping Brewster and Puddephatt’s proposition of its moral aspect (however relevant this is) we observe that an ecological view of the self also holds ontological and cognitive grounds in Mead’s thought. We may return to Joas (1985 [1980]: 159-161) for a relevant entry point to this argument when he recalls that, in Mead’s theory of the act (1932: 119-139, 1972 [1938], 2011 [n.d.]) the construction of the physical object by a perceptive subject is socially mediated and linked to the apprehension of the unity of the subject’s own body as the likely object of its action. However, Joas (1996: 181-184) does not move forward in order to in-depth explore the questions this observation brings over the constitution and maintenance of the self, and rather remains bound to the discussion about the link between creativity and the formation of body image. By thinking both with and against Joas I argue that, if a truly ecological treatment to the self should not be limited to linguistic interchanges that substantiate human intersubjectivity, it must also not be narrowed down to the mere valuing of corporeal elements linked to the interactive experiences of individuals. It is essential investing in an integrative view between both aspects, so we may contemplate the inseparability of the material and symbolic dimensions in the continuous counterpoint between subjectivity and objectivity in the inner domains of each individual.\nIn addition to the point highlighted by Joas about Habermas, which is extensible to Blumer and Honneth, there are two deficiencies related to the form of appropriation of Mead which can be claimed common to all these four authors. The first one regards the conceptual selection they carried out in Mead’s work in order to integrate sections of it to their own respective synthesis. The absence of the notions of problem and inquiry (both central to pragmatism) in each of those four conceptual cores separates the theoretical analysis of the self from the practical context of its formation, as well as from the (re)constructive work of reflective intelligence in the course of continuous displacements between the worlds of matter and meaning. I shall explore the relevance of this pair of concepts for the reconstruction of Mead herein envisaged later (section two) in this article.\nFor now I will focus on the second common deficiency of the appropriation of Mead by the authors discussed in the current topic, which rests on the interpretative alternative that they followed regarding the inner structure of the self. It is implicit in Joas’ formulation that the maximum participation of materialility within the self occurs when the material world itself is taken as object for the self’s action during the process of consolidation of the bodily unity. Such a lack of consideration with the active role of materiality in human action and subjectivity results from the interpretation of relations between the Meadian concepts of “I” and “me” that was sanctioned by Joas and shared with Blumer, Habermas and Honneth. Both the American and the German authors welcomed into their respective theoretical works a problematic definition which largely reduces the “I” to individual and the “me” to collective personifications within the self.\nThis specific approach to the roles of the “I” and the “me” in Mead’s self has been called into question by Markell (2007) in the wake of a critique to what he understands as a disabling feature of Honneth’s theory of recognition. The main line of his argument (Markell, 2007: 102-107) lies on the proposition that the definition of recognition as necessary crossing point for the transformation of personhood from something potential to actual means the submission of its self-realization to an external authority. According to Markell (2007: 112- 114, 125-128), this problem derives from the reifying reading of the “I” and the “me” that Honneth made of Mead . Such an approach defines these two concepts as clearly different and counterposed agencies. On the one hand, the “I” would encompass an irreducible individuality, with nature similar to the unconsciousness of psychoanalysis and whose contingency and creativity would represent the potential of renovation. On the other hand, the “me” would be formed by a collective force, a habitual agent that is transposed from the community to the individual in order to censor its “I”. Honneth would not be alone in this interpretation of the Meadian self, for both Habermas and Joas would share with him the idea that the “I” is “[…] something like a source or seat within the individual of creativity, novelty, spontaneity, or resistance to social norms.” (Markell, 2007: 112-113, emphasis in original)2.\nAs pointed out before, Blumer’s understanding on the matter is not distant to that of the Frankfurtians. While acknowledging an ambiguity in the form Mead used the two terms, the sociologist sees the “I” as that thing that brings into the self “[…] expression and release to organic impulse and tendency […]” and the “me” as something that “[…] reflects the attitude of the community […]” (Blumer, 2004: 65-66).\nFor the purposes of the present discussion, the main problem with relating the “I” and the “me” in this way is that it compromises the linkage between Mead’s social psychology and his reflections on perception and the human engagement with matter present in his theory of the act. The delimitation of the self to a symbolically mediated dialogue between a radically individual agency and an interiorized force representing society (in its minimal definition of a collective of individuals) rules out the incidence of the material dimension of human experience on the production of subjectivity. If, as stated by Mead (2011 [n.d.]: 27), “the relations of the environment and the individuals is one of mutual influence.”, 2 Markell (2007: 112) recalls that for Habermas (1992: 180) “[…] the “I” appears on the one hand as the pressure of presocial, natural drives, and on the other hand as the impulse of creative fantasy […]” while for Joas (1985 [1980]: 118) it represents “[…] the endowment of the human being with impulses.”. Despite not identifying such impulses with “[…] some natural compulsion […]”, Joas (1985 [1980]: 118) sees them as unceasing individual drives, finding “[…] expression in fantasies […]”.\nit is necessary to recognize that the interpersonal relations of the self traverse and are traversed by constellations of physical entities. The expansion of the ecological view of Mead’s concept of self can contribute to a more complex and environmentally promising version of his idea of subjectivity.\n\nThe materiality of the “I” at the confluence of self and act 2.1. – Actuality, materiality and the “I” Blumer’s observation about the ambiguity of Mead’s utilization of the “I” and the “me” in his own discussion on the self should not be overlooked. In fact, the problematic understanding of the two concepts portrayed in the last section does not lay roots either in symbolic interactionism or critical theory’s incorporation of Mead, but in Mead’s own writings, on the polyphony he adopted to treat both concepts along his career. There are basically two forms which Mead dealt with the dynamics of the “I” and the “me”. Later in his work, the idea of counterposed individual and social agencies within the self predominates.\n\nThis version has prevailed in his canonization in sociology and sustains the hegemonic interpretation of the Meadian self, as we have seen in the previous section. But another interpretation of the conceptual pair, more aligned with the pragmatism of James and Dewey, finds substance in Mead’s early discussions on the self (Mead: 1903, 1912, 1913)3. It is the intent of the present section to show that this alternative, counter-hegemonic interpretation of the “I” and “me” dynamics is more suitable for dealing with the material properties of subjectivity and, therefore, to serve as starting point for a sociological reconstruction of Mead concerned with an ecological conception of the self.\nSome years ago, Markell (2007) took a stance adopted later by other authors (Silva, 2007: 106-107; Cook, 2013) and set forth a diligent rescue of Mead’s earlier conception of the “I” and the “me”. More specifically, Markell has reclaimed Meads’ articulation (1903: 101- 102) between the original Jamesian formulation of the self, which is constituted by the pure 3 Mead clearly adheres to this approach in texts such as The Definition of the Psychical, The Mechanism of Social Consciousness and The Social Self, all published during the two first decades of the 20th century. In Mind, Self & Society, which is composed mainly of notes taken from Mead’s lectures in Chicago during 1928, the two interpretations of the “I” and the “me” contents coexist. Markell (2007) and Cook (2013) explore the contrast between them in detail.\nego (“I”) and the empirical self (“me”), and the proposition by Dewey (1896: 364) that stimulus and response do not have separate and empirically definable contents, since they are rather referentially composed and only distinguishable through the function they fulfill in the coordination of the sensory-motor circuit.\nIn this specific formulation, Mead concludes that the self is a continuous encounter, in the flow of the individual’s experiences, between subjectivity and objectivity as phases, i.e. aspects4, of its understanding about the world and about itself. The self’s interaction with the rest of the individuals’ internal and external experience field is particularly dynamic in situations when uncertainties break that flow and disrupt the constitution of the object of action, a process which Dewey has called “disintegration” (Mead, 1903: 101). Within this individual innerscape, the subjective aspect of the self is given by the “I”, the “[…] reconstructive activity […]” (Mead, 1903: 109, emphasis added) responsible for the emergence of new objects in action, which takes place in the “[…] very process of replying to one’s own talk [… through] the gestures, the symbols, that arise in consciousness” (Mead, 1912: 406, emphasis added). Based on such a conception, the “I” is configured as the transitive element of the “stream of consciousness” that links different objective experiences and gives them a singularizing touch, a particular inward coloring that confers to the individual a sense of existential continuity (James, 1955 [1890]: 159). Therefore, the “I” is responsible for the subjective synthesis between an individual’s reflections and feelings by generating a sense of unity and sameness that supports its personal identity (James, 1955 [1890]: 214-216). The “me”, in its turn, emerges as the objective aspect of the self, which delimits, within this field of experience, the elements that can be (re)constructed as objects to the individuals’ action through its assumption of the attitudes of others with reference to oneself. Briefly, the “I” is the activity, the “actual response”, which is provided by the self to a problem caused by the disruption of an object (Mead, 1967 [1934]: 277); the “me” is the objectivity of experience introduced to the self when it assumes the attitudes of others (Mead, 1967 [1934]: 175, also see Markell, 2007: 125-127).\nIt is important to distinguish Markell’s distancing from the hegemonic interpretation of the internal structure of Mead’s self from the approach offered by Lewis (1979). Like Markell, Lewis also opposes the assumption that the “I” is an organically composed portion of the self with entity-like properties and, conversely, treats it as the self’s 4 Based on the Meadian vocabulary, the word “phase” does not necessarily regard a stage belonging to some sequential teleological order. Its use is not different from that of the word “aspect” (Silva, 2008: 90-91).\nform of response in communication. However, seeking what he calls a “social behaviorist” approach of the self, Lewis points out that the “I” is the predominantly overt response, the “[…] observable activity which is attended to by both the self and the other.” (Lewis, 1979: 269). He then offers an objectivist version of the “I” by basically excluding its presence in thought and by wiping out the subjective core of intimacy envisioned by Mead’s early writings from its response.\nWith traces of Dewey, one of the main effects of this counter-hegemonic understanding about the inner structure of the self lies on the fact that only the roles played by “I” and “me” can be respectively identified through exclusively individual and social properties; their content, however, is interchangeable (Markell, 2007: 128; Cook, 2013: 121- 124). As suggested by Markell (2007: 128), Mead’s assertion that the reconstructive activity of a present “I” ends up, retrospectively, integrating the objectivity of a future “me” (Mead, 1913: 374, 1967 [1934]: 174) also works in reverse. From this reasoning we conclude that the adoption of the attitude of the other by the individual as its response derives from a form of exercise, rather than necessarily from a drawback, of its individuality. The very act of responding, whether with or against society, is a manifestation of the “I”. Consequently, the same image or representation crossing one of the components of the “I”-“me” pair may come to attend the other. The only variation in those elements will be observed in the type of their functional participation in this reconstructive inner move, whether stimulus or response.\nThis approach is essential for us to understand the material dimension of the self. In order to advance in this direction, it must be specified that, due to the social treatment Mead gives to ontogenetic development, he sees the initial contact with the material world as the consolidation of the intersubjective cognitive mechanism in the individual. The physical object is the abstraction of the social object (Mead, 1972 [1938]: 190). Therefore, the physical thing always enters the experience of a person through the resistance awakened by the friction between that thing and the person’s physical organism. This resistance allows the identification of something substantial in the object, which is not necessarily a personality, but an interior, an “inside” that gives physical responses (thickness, roughness, rigidity…) to the frictional stimulus that, in its turn, is transported to the self and assumed by it through the objectivity of the “me” (Mead, 1972 [1938]: 109-110, 143-144, 152, 186-187, 191-196, 212- 213, 429-431). Devoid of communicative capacity, the resistance provided by the physical object to the human body is the equivalent to its voice in the Meadian interactive structure, so that we talk with things through their ledges, crests, and folds. Resistance also implies cooperation (Mead, 1972 [1938]: pp.108-110). Therefore, by drawing upon a vocabulary influenced by contemporary pragmatic sociology, I can state that, in affinity with Mead, the self is not only buttressed by conventional supports of action (Dodier, 1993), but also by material supports that are brought to its inner realm in the course of its interactions in a world full of physical objects.\nOnce inside the individual’s inner constitution, sensations caused by material supports interact with the universe of language and stir up representations and images stocked in a repertoire of memories built from past experiences: “The image, functionally defined, is then a content that, in terms of past experience, has served as a solution of the problem set in the form of the sensation” (Mead, 1904: 605, also see 1912). By standing before the ecological composition of the problem it faces and the updated version of its self (which is likely the carrier of a new, previously absent, memory), the individual’s response (which exercises the singularity of its “I”) can give rise to new images, i.e., new symbolic interpretations of those materially experienced sensations. My point in here does not lie on the precedence of materiality’s magnitude in comparison to the symbolic dimension of Mead’s pragmatism. I rather shine light on the way Mead is sensible to the reciprocity between the material and the symbolic. Significant symbols and physical resistances meet each other through the communicative work of thought, so that symbols find ballast in material supports and physical resistances acquire meaning from conventional references.\nThe discussion indicates that creative action benefits, on the one hand, from the situational variability set by the flux of experiences and, on the other, from the reconstructive work of the “I”-response, which expresses the individual’s volitions and goals in the space between an old reality that became obsolete, and a new reality yet to be defined (Mead, 1972 [1938]: 34-35, 115). By associating the “I” and the “me” with the creativity found in the resolution of problems set by interactions between people and things, we get to the vertex between the theories of self and the act.\nA few systematic words about the act are relevant at this point. Its substantial elaboration is found on The Philosophy of the Act, which is a posthumous compilation composed of writings where Mead was under the advanced influence of Alfred North Whitehead’s objective relativism. The act is an activity of practical ontology wherein human beings socially set the sense of reality by means of the convergence between their signifying abilities and the material properties of the natural world throughout a spatiotemporal axis.\nMead analytically distinguishes the act into four phases: 1) impulse, when sensations experienced by the individual start the first levels of the construction of a response that lasts the whole trajectory of the act; 2) perception, when, at distance, the object occupying the center of the act starts to be outlined after being associated with that initial sensation; 3) manipulation, when distance gives way to contact and a conscious analysis is exerted over the object; 4) consummation, when the construction of response is concluded and brings along a qualification cast upon the object (Mead, 1972 [1938]: ch.1).\nThe different stages of the act encompass the previously mentioned concepts of problem and inquiry. By drawing upon Dewey’s idea about the disintegration of the object, Mead (1972 [1938]: p.6) defines the problem as the “[…] lack of adjustment between the individual and his world”. It occurs in the context of the act due to the development of the incompatibility between the response provided by the individual and the demands it deals with after receiving a given stimulus. This situational mismatch breaks the flow of the act.\nThe reconstructive work that starts at this point follows the inquiry form, which experimentally analyzes data about the problematic situation in order to reduce incongruous or ambiguous information, to formulate new hypotheses for the solution of the problem, and to test such hypotheses by checking whether the paused act has been restored, or not (Mead, 1972 [1938]: 82-83; also see Cook, 1993: 177).\nA displacement occurs within two gradients throughout this inquiry. The first gradient is related to spatiotemporal proximity, as the examination of an object, whose initial stimuli are always felt at distance, depends on direct contact with the inquirer for effective experimentation. The second one concerns cognitive formality, as individuals move from a spontaneous relationship with the world around them, which Meads calls immediate experience, to the rationalized attitude of a reflected analysis, when conscience is already oriented towards the manipulation phase in order to experimentally test the components of the problem at hand (Mead, 1932: 133-139, 1972 [1938]: 13-16).\nThese two movements influence the inner configuration of the inquirer’s self as it goes through different situations. The objective stimulation (“me”) and the response (“I”) are gradually defined throughout the double displacement caused by the inquiry in the course of the act, from its initial stage (when immediate experience prevails) to the full establishment of reflected analysis (which takes place in manipulation). When reflected analysis is accessed, self-consciousness and awareness about objects adjacent to the self, which are based on a rationalized form of problem appreciation, are quite well-focused. At phylogenetic level, obtainment of rational problem solving does not result from the rupture with a state prior to conscience, but unfolds from it, in a dependent fashion, following the emergence of the significant symbol (Mead, 1922: 160, 1925: 271, 1967 [1934]: 68-82; Silva, 2008: 121-122). When it comes to the individual level, the theory of the act suggests that, as soon as the basis of one’s self is formed, the expression of the analytical reflection about an object in the field of experiences is situational and progressive, so that there is no interruption in thought, but continuity between rationality and the most intuitive forms of engaging in the world. Thus, we observe that the reconstruction of external data sets the “I” and the “me” in motion, and that this process will reflect on the interior domain of the self.\nThe self as inquirer also reconstructs its own inner constitution through its relations with the objects around it.\n2.2. Perspectives and prehensions In the transactions with the world sketched above the individual only has access to the common ground of reality through its own perspective. The idea of perspective has noteworthy presence in the work developed by Mead in the last decade of his life. Its mobilization represents Mead’s attempt to combine his pragmatist naturalism to the relational metaphysics of Whitehead (Mead, 1925: 259-260, 1932: 161-163). In a quite concise fashion, a perspective can be defined as the product of perception spatiotemporally originated from a percipient event that finds itself in relation to a consentient set, i.e., an environment comprising relevant objects concerning the existence of that perceiving entity (Mead, 1925: 256, 1932: 161-175, 1972 [1938]: 100ff). Different perspectives developed throughout the act are concentrated either in a prospective unity, as the promise of a future trajectory, or in a retrospective manner, in the consummation phase, when the act acquires evaluative character (Mead, 1934: 162, 1972 [1938]: 134). After all, reality is the product of a relational organization of perspectives, and individual human subjectivity is part of nature’s objectivity because it is a concrete datum produced within the interchange of organism and environment (Mead, 1972 [1938]: 163).\nMead’s borrowing of the concept of perspective is essential for the present articulation of his theories of self and act. As we know, the philosopher points out that the self benefits from inquiries conducted by the individual on its own inner affairs and problems, which are intersubjectively developed throughout relations with the external environment (Mead, 1913: 378-379, 1967 [1934]: 38, 97-100, 119-124, 177, 188, 216, 254, 274-281, 308, 376, 1972 [1938]: ch.1, 5). Conversations internal to the self sustain thought as a reconstructive activity enabling the individual to set up the self-perspective that defines its singularity (Mead, 1967 [1934]: 254, 308). Thus, Mead (1925: 259-260) understands that “[…] each individual has a world that differs in some degree from that of any other member of the same community, [and] that he slices the events of the community life that are common to all from a different angle from that of any other individual.”. The angles provided by the perspectives of each percipient event produce a stratified reality that comprises nature itself (Mead, 1932: 171).\nBy taking part in continuous processes of relational entanglement of viewpoints that comprise nature, the self has to deal with the material dimension of perspectives from a whole set of entities it interacts with in space and time. The articulation between the concepts of perspective and prehension in Whitehead’s philosophy helps us better understanding materiality’s relevance for the internal construction of individuality in Mead’s work.\nAccording to Whitehead (2011 [1925]): 86, 1978: 18ff), prehension is a mode of perception that takes shape through apprehension, whether cognitive or not, of a given actual entity over another. We do not find in it a simple extension of a being over another, or even an aggregate formed by the sum of two, or more, entities. In the formation of a prehensive unity, Whitehead (2011 [1925]): 81) sees the transperspective complexity of reality with the interpenetration of aspects among all beings composing a totality. Yet, due to its “vector character” (Whitehead, 1978: 19-20), prehension is the form through which an entity can extend itself to others, involve and be involved by them and express its singularity to the external environment. In short, there is no individuality without interdependence between the different perspectives observed in the same universe.\nIn Mead’s work, aside brief mentions in The Philosophy of the Act (1972 [1938]: 147, 202), there is a relevant reference to the concept of prehension in his essay The Objective Reality of Perspectives, published originally in 1926 and later compiled in The Philosophy of the Present. In such reference, Mead makes it clear that, from his view, the way how individuals deal with the common environment cannot be separated from the perspectives they built over themselves within their inner scopes: The consentient set is determined by its relation to a percipient event or organism. The percipient event establishes a lasting character of here and there, of now and then, and is itself an enduring pattern. The pattern repeats itself in the passage of events.\nThese recurrent patterns are grasped together or prehended into a unity, which must have as great a temporal spread as the organism requires to be what it is, whether this period is found in the revolutions of the electrons in an iron atom or in the specious present of a human being. Such a percipient event or organism establishes a consentient set of patterns of events that endure in the relations of here and there, of now and then, through such periods or essential epochs, constituting thus slabs of nature, and differentiating space from time. This perspective of the organism is then there in nature. (Mead, 1932: 162, emphasis added) Because it is a perceptual apprehension that is not reduced to cognitive intercourses between entities, prehension immediately refers us to processes of contact present in the flow of Mead’s act, from the impulse phase to the consummation phase. However, the excerpt above indicates that, according to Mead, by apprehending objects through such a process, a subject is simultaneously setting in motion the prehensive unit of its own self. This unity is built through the interaction of the individual with its consentient set, as different response patterns (elaborated in the interaction between “I” and “me” and later translated into a new mnemonically reconfigured “me”) are temporally accumulated and “grasped together or prehended” as the continuity of its being. This takes us back to James’ influence upon Mead’s initial phase, in particular to the proposition of personal identity as the subjective synthesis of experiences. By dialoguing with this reference it is possible to see in the context of interior problematic situations the “I” and the “me” engaging in a process of inner prehension, in which each of the two elements strives to seize the other from their own perspective, the result of this transaction being the personal configuration of the self. This means that the self derives from the crossing of perspectives between subjectivity and objectivity in the context of mind, where the “I” and the “me” seek to grasp one another 5.\nBy looking at this topic through such lenses, excerpts where Mead states that “The active individual [the “I”] finds in this object individual [the “me”] and its world the conditions under which its action may take place” (2011 [n.d.]: 31, emphasis added) can be interpreted as indicating the possibility that material supports from the field of experiences contribute to the consolidation of the posture of the “I”-response in the temporal flow, not 5 The conception of “I” and “me” as perspectives is also present in Bolton (1981). However, while I follow Whitehead’s definition of the concept, Bolton (1981: 249) suggests a simplified version of perspective as “[…] a symbolically organized mode of orienting oneself toward a situation […]”.\nonly to the configuration of a “me” an organic and naturally individual “I” presents itself to.\nIf, as suggested by Markell, the subjective self encompasses in its transitivity the generalized social attitudes brought along by the objective self, it does the same thing with the material impressions left by contact with physical objects. Matter is not simply an input that passively receives directions from the individuality of the self; it effectively acts upon this individuality, by influencing it through the game played between resistance and cooperation, which is especially observed in manipulation. The transitive state of the stream of consciousness composing the “I” can be supported either by the representational, imagistic and normative conventions of social relations or by the physical contours of the world in order to give its touch of singularity to the self. We seek and take hold of the perspective of an object, prehending its “inside”, just as we seek and take hold of the other in social conduct during the making of our own behavior. The ledges of things are as important for the definition of the response of the “I” in the subjective conformation of our actions as the social expectations of our human peers: “By acting as the object will act […]” says Mead, “[…] we realize the hardness of the object and do not run our heads against it.” (1972 [1938]: 107). We conclude that matter takes part not only in the formation of an individual’s corporal self-image, as Joas points out, but also in the entire introspective process of problem solving that feeds its self- understanding. As Mead himself has stated (1926: 382), that object we lay our hands over is turned into a material to build the world of our heart’s desire and dreams.\nThe interpretation built throughout this section made Markell’s rescue of the pioneer version of “I” and “me” meet Mead’s Whiteheadian reflections, and from there extracted the newly proposed approach of the material supports of the self. In important points, it contrasts with the view defended by Rosenthal and Bourgeois (1991). These authors have accessed Mead’s work by making the effort to make him closer to Merleau- Ponty (Rosenthal and Bourgeois, 1991: 103ff). In their theoretical convergence, they do not adhere to the counter-hegemonic definition of the “I” and “me” concepts, and it leads them to two important mistakes. Firstly, according to Rosenthal and Bourgeois, “I” and “me” do not fully take part in the reconstructive process of the problematic experience, because the disintegration of the object would also cause the transitory disintegration of the relationship between these two components of the self. During the first moments of reconstruction, the individual would only count on the fundamental subjectivity of the “concrete subject” and on its “lived body” (Rosenthal and Bourgeois, 1991: 106), notions taken by the pair of authors from Merleau-Ponty as sources of bodily intelligence. Secondly, because Rosenthal and Bourgeois do not assume the “I” as intrinsically associated with the response activity, they do not see the complex, continuous and incremental relationship between its role in the structure of the self and the material supports of action. According to them, “I” and “me” only return to the scene after the establishment of conscious reflection, and in there they are added to the dynamics of the concrete subject, which lasts and mediates the interactions of the self with the environment. The continuity of the concrete subject within the self is what would guarantee its exchange with the physical world in a process taking place through a non-thematic internal dialogue wherein the “I” would be experienced, felt as the background of mind, but not made explicit as an object of knowledge (Rosenthal and Bourgeois, 1991:113, 115).\nThis last proposition about a non-rationalized instance in thought actively contributes to the procedural treatment of the Meadian self, which has been designed throughout this paper. Nevertheless, it is worth inquiring: is the deviation through Merleau- Ponty necessary in order to achieve it? My answer is no, and its elaboration helps correcting the two aforementioned problems regarding Rosenthal and Bourgeois’ approach. If we recall the image of the self moving along a gradient of cognitive formality, we observe that the “I” and the “me” are involved in the reconstructive process from its very beginning, when immediate experience prevails. It is at that very moment that both elements express themselves in a non-thematic (following Rosenthal and Bougeois’ denomination), non- symbolic (Blumer, 1969: 8) way or, yet, from another viewpoint, in the manner of what Giddens (1984: 44-45) has called practical conscience, which is found in “[…] circumstances in which people pay attention to events going on around them in such a way as to relate their activity to those events” without, however, “thinking” about what they are doing. In reflective analysis, however, our relationship with the objects grows towards transparency and although still not turned into a theme in direct experience, the “I” finds itself in such circumstances able to support more refined ways of response. We can extract from this reasoning that what Rosenthal and Burgeois attempted to describe by resorting to the external notion of concrete subject can be reached within Mead’s own conceptual universe through the articulation between his theories of the self and the act. Therefore, we understand that, similarly to the symbolic dimension, the material dimension of experience is also part of the prehension of human subjectivity in its different degrees of rationality and intentional clarity, and that it is found both in the objectivity of the “me” and in the reconstructive activity of the “I”.\n\nThe self, pragmatic sociology and the new mastery of nature Different currents of contemporary social theory have recently converged to the appreciation of the ontological dimension of interactive partnerships between humans and other beings. References to an ontological politics (Mol, 1999) or to new materialisms (Coole and Frost, 2010), although quite different from each other, share as common orientation the understanding that definitions of reality are productions traversed by conflicts, disputes and effective transformations. The current section argues that Mead’s pragmatism, mainly his theory of the self as herein reconstituted, offers relevant contribution to the discussion about the ontological twist in the forms of power in contemporary modernity. Furthermore, as announced in the introduction, the theoretical exercise developed throughout this article is aimed at an empirically grounded sociological concern which finds fertile soil for research and reflection in discussions about ontological power. Therefore, in addition to discussing the issue through a Meadian outlook, I will also seize the opportunity to explore in the following pages a new sociological alternative to be integrated into Mead’s conceptual perspective.\n\nMy starting point to deal with these ontological issues is the study by Pellizzoni (2015) about recent reconfigurations in the neoliberal mode of mastery over nature, where he expands previous reflections by Cooper (2008) about the entanglement of knowledge, biotechnology and financial capital6. Pellizzoni describes a paradigmatic shift in the political and economic discourses of capitalism beginning in the 1970s. At that time, the sense of a natural limit to growth was progressively replaced by the proposition of the inexhaustibility of opportunities provided by nature. This new discourse appropriates diagnostics about the complexity of the biophysical world resulting from different sectors of the scientific community and from ecological movements to highlight certain features of environmental processes, such as indetermination and instability. It then generalizes these features in positive manner and depicts the unpredictability of environmental systems as a whole set of possibilities, rather than interdictions, for the fulfillment of human designs. The principle of precaution is then neutralized by the ontological reach of purposeful action, since the attitude to be taken towards risk is not its reduction, but the refinement of interventions in the 6 See Pellizzoni (2015: ch.1) for a comprehensive critical appraisal of post-constructivist/anti-humanist approaches to ontological politics, which are not the focus of the current article.\nbiophysical world. The investment in the figure of indetermination in this new form of mastery over nature reinforces the imaginary of plasticity of reality (Papadopoulos, 2011), which is taken to its last consequences by technological fronts such as geoengineering and biotechnology.\nPellizzoni dialogues, at important aspects, with Boltanski and Chiapello’s (1999) idea about a new moral foundation rising from the establishment of neoliberalism. These two authors suggest that capitalism has overcome the crisis of its industrial period by reconfiguring itself through the cooptation of an artistic critique. Present in several political and cultural movements at the late 1960s, this critical modality used to substantiate demands for mobility, adaptability and, most of all, for flexibility. Once the principle of flexibility was integrated as resource in the entrepreneurial world, the critique that used to call for it was disarmed to a large extent. Pellizzoni (2015: 66) himself points out his affinity with this argument; however, I herein further explore this link by assuming his idea of a new mastery of nature as part of the new spirit of capitalism proposed by Boltanski and Chiapello. Thus, the definition of matter as undetermined source of possibilities, broadly flexible and responsive to human projects, seems to result from a surreptitious response from capitalism to critiques coming from both complexity theorists and ecological movements that, since the 1960s, have drawn attention to the irreducibility of nature to the economic, political and epistemological ventures of that regime. Hence, it can be stated that the capitalist reconfiguration promoted by neoliberalism relied not only on moral supports, as Boltanski and Chiapello have suggested. We find in it the articulation between conventional and material supports in the reformulation of a normativity about the relation between human activity and nature.\nThe ideological reorganization that has promoted this flexibilization of nature in the wake of the formation of a new spirit of capitalism brought to light a new object to human experience. As shown by Mead, this is not sustainable without concrete supports. The neutralization of ecological critique did not occur despite the complexity of nature claimed by scientists and activists, but it precisely resulted from its recognition, since it contributed to the perception about the limitations of the typically industrial form of exploration in face of environmental resistances imposed to human manipulation. The adherence to complexity in the neoliberal layout had the double effect of sophistication of economic interference in nature, on the one hand, and the political emptying of critique (at least to some degree) on the other. Therefore, the development of the new technologies mentioned by Pellizzoni, which also include the ones related to carbon markets and human enhancement, did not happen simply throughout projections of pre-elaborated business models over the biophysical world.\nTheir designers engaged in inquiries that sought analytical contact with the profusion of attributes composing the materials in the center of their attention. By manipulating these objects, they intended to reach their interiors, assume their perspectives and, thus, access the complexity of their constitutions. This means that they understood the ideas by authors such as Morin (2008: 5), about the relationship between knowledge and the environment, but they actively sought to neutralize the critical inclination of such theories in favor of elaborating more creative and efficient forms of extracting economic value from nature. In other words, they relied upon the manifold material supports of nature in order to master it.\nAccordingly, material resistance has acted incisively in the perspectives either of critiques of the industrial mastery of nature and of its reformers. However, materiality does not express itself alone in symbolic mediated social relationships. The concept of complexity was the consummatory, representational form with which this resistance was consolidated as object. But, as we have seen, power relations have marked this adjustment of perspectives between the material world and human agencies. Clear asymmetry is established between these perspectives, because, even if the critical interpretation of complexity keeps on operating, its reformulated version as inexhaustible basis of economic exploitation has all the systemic, institutional and moral support of the new spirit of capitalism.\nBefore I tackle the problem of asymmetries, I shall draw new, pragmatist bases for Pellizzoni’s critique to the new mastery of nature. Based on Heidegger, Pellizzoni (2015: 156-157) defends a fundamental split between being and “thinking”, ontology and epistemology, as the source of the singularity of human existence. Consequently, the new technologies approached by his reflection would be worrying not so much due to the results of their activities, but mainly because they would push the leveling between matter and knowledge. From this viewpoint the corruption of the essence of the human as resident of the world is strengthened, and it leads up to an “[…] instrumentalization of everything [natural] as standing-reserve, governed by relations of efficient causality […]” (Pellizzoni, 2015: 153).\nThrough pragmatist lenses, this line of reasoning is not satisfactory. In the first place because, as seen in the discussion about the symbolic and the material in Mead, for pragmatism both knowledge and matter belong to the domain of practice: thinking is itself a way of acting upon the world (Frega, 2006: 39). Secondly, because it reverses the order of construction of critique (MacGilvray, 2004: 104; Frega, 2006), since its justification is based on the non-contemplation of a principle, in this case, the anthropological proposition of discontinuity between humanity and nature. In order to repel this form of idealism, Dewey- inspired pragmatism, to which Mead was affiliated, emphasizes the need for critique to be experimentally constructed. Critical endeavor should be based on assessments of the consequences of a problem, since the very meaning of the critique’s object is dependent upon such consequences for its process of signification (Frega, 2006: 62-65).\nThe consequences of the new technologies must therefore be the aim of critiques directed to the new mastery of nature. Critical constructions should not aim from the beginning at one-size-fits-all considerations (such as Pellizzoni’s), but instead should proceed modestly in a path guided by inquiry work (Chateauraynaud, 2018). The literature on biotechnology and geoengeneering points out some outcomes of such technologies which are relevant for a critical exercise that sticks to practical consequences as the starting point of judgment. Authors from different, albeit critical, theoretical affiliations (Cooper, 2008; Szerszynski et al, 2013; Demeulenaere, 2014; Pellizzoni, 2015), indicate that the progressive transfer of ontological control from ordinary entities (human or not) to the benefit of power systems that create and administer these technologies is one of the most prominent developments set in motion by both strands of innovation. Inspired by Mead and his Whiteheadian moment, by ontological control I mean the capacity an entity has to apprehend its own constitution as a being in relation to its consentient set and, in the case of humans, to actively inquiry and evaluate objects, including one’s self. Intrinsically linked to the regeneration of the market that has emerged after the global crises of the 1970’s, the new mastery of nature propels a gradual colonization of experience by the economy at “[…] the genetic, microbial, and cellular level, so that life becomes, literally, annexed within capitalist processes of accumulation.” (Cooper, 2008: 19).\nHowever, if Mead did not fully disregard the subject of power, it is true that his liberal normativity has limited his view to dialogical forms of conflict resolution (Silva, 2008: ch.15). Regarding this problem, it is essential extending to Mead the observation by MacGilvray (2004: ch.5) about the Hegelian “extrapragmatic roots” of Dewey’s political theory. Similarly to Dewey, Mead understands that the democratic dynamics of collective life is organized by the teleological harmonization of individual orientations, and that it takes place through communicative processes that integrate the multiple selves into their communities. There is insufficient room in his work to the discussion about inequality, violence and domination, which comes about the reduction of autonomous space for the production of perspectives in favor of hegemonic apprehensions.\nThis characteristic of Mead’s thinking emphasizes the difference between his social philosophy and an empirically oriented sociological approach and casts light upon the value of endeavors made by the authors present in the first section of the paper in order to remold the pragmatist’s conceptual force with sociological design7. As we have seen, however, those theoretical constructions suffer from problems which inhibit a satisfactory account of the self according to the ecological view guiding the present study. A final step in the reconstruction of Mead put forward by this article then lies in the task of finding a new base to synthetically house his perspective in the sociological discipline. After ruling out the most prominent options I suggest that a particular approach within contemporary pragmatic sociology, the one advanced by Francis Chataeauraynaud, presents itself as a promising candidate. In addition to his participation in pragmatic sociology’s active claim of classical pragmatism’s legacy in the beginning of the 2000’s (Chateauraynaud, 2004), Chateauraynaud’s theoretical work stands out for highlighting the intertwining between discursivity and materiality in the conduction of inquiries of both ordinary and expert profile.\nIn order to fill the Meadian gap on violence and domination, I shall introduce the concept of ascendancy (emprise) as understood by Chateauraynaud (2015, Chateauraynaud and Debaz, 2017), in the context of his approach to Foucauldian bio-power from the standpoint of pragmatic sociology. What Chateauraynaud defines as ascendancy is an intense form of asymmetry, non-hierarchical, diffused through networks, based on legitimacy and realized by the way of the biasing of actors’ perceptions (Chateauraynaud and Debaz, 2017: 235). An actor gains ascendancy over others by indirectly influencing their behavior, by conquering their “territories of experiences” (Chateauraynaud, 2015: 9), and, finally, by managing the conformation of problems that are elaborated there, as well as the flow of inquiries conducted to solve them. This discussion is substantiated by the concept of grasps (prises) observed throughout Chateauraynaud’s work. By drawing upon it, the author explores the ontoformative power of convergences between representations and material 7 Mead’s image as an armchair philosopher is not accurate, for he was not entirely distant from empirical practice (Huebner, 2014: ch.2-3). However, he never devoted himself to the elaboration of a specific methodology for empirical social research.\nperception (Bessy and Chateauraynaud, 1995; Chateauraynaud and Debaz, 2017: 606-607).\nGrasps are products of human agency in its attempt to elaborate definitions over objects and processes in a universe that is as material as hermeneutical.\nIt is relevant to point out the proximity between the concepts of grasp and prehension, as well as the scarce presence of Whitehead in the work by Chateauraynaud, which also holds true regarding Mead (Mello, 2019: 173)8. In the present article I address the confluence among Mead, Whitehead and Chateauraynaud in order to propose that the processes encompassed by the concept of prehension must be incorporated by the concept of grasp. This is, accordingly, the centerpiece of the synthetical movement bringing together Mead and Chateauraynaud. At this point of the article, I must introduce an analytical distinction between inner and outer grasps9. The basic difference between them is determined by the object of each one: in the former, internal affairs experienced by an actor are the main object, while in the latter the object lies outside the actor’s innerscape. In empirical reality a clear distinction between inner and outer grasps is not possible. We may think of them as interchangeable and communicable analytical perspectives, one directed to the study of problems and inquiries within the courts of the self, the other focused on social and environmental problems which different selves take part in.\nWhen it comes to human reflexivity, outer grasps are processes of ontological characterization of objects the actors interact with in their environments. Their existence implies the operation of inner grasps, because the same interaction promotes, at a greater or lesser degree, the reorganization of the self through the “me” and the “I”, which are responsible for conducting into interiority the material and conventional supports at stake in the resolution of the experienced problem and for the manifestation of the active element responsible for the personal mark in the subject’s response, respectively.\nInner grasps are in motion when the individual presents itself as its own object, when its own self occupies the center of the problems and inquiries it experiences at a given moment. On such occasions, the greatest test put to the self lies on coping with the problem rising within the “enduring pattern” shaping the individual, to grasp issues affecting its 8 Indeed, this similarity is suggested by the long excerpt from Mead quoted above. We may elaborate from it an image of prehension as the gripping movement of a hand that tactfully affords a sense of continuity between what is sensed in one of its regions and what lies in its opposite area.\n9 See Mello (2017) for the initial definition of inner and outer grasps regarding collective subjectivities.\nBesides concentrating on individual subjectivity, the present article dives much deeper in Mead’s work in order to substantiate the pair of concepts.\ninmost sphere by the “lasting character of here and there, of now and then” built along its biographical trajectory. Referring back to the Jamesian Mead (1903; James, 1955 [1890]: 213ff), we may state that, by holding an inner grasp, a person is apprehending its scope of memories, expectations, ideas, emotions, perceptions, and actions, whether they are informed by material or conventional supports, in a specific perspectival conformity that maintains its sense of intimacy and inner correspondence along an ever-changing relational existence with itself and the environment. Not only grasps over external objects, i.e. outer grasps, are compromised in contexts of ascendancy. Inner grasps are loosened, one’s ontological control over its own self is weakened, and an asymmetry is installed to favor other parties. Chateauraynaud’s sociology benefits from this procedure by accessing stronger terrain in order to deal with transactions between subjectivities and externalities sustaining generative existential processes. By taking this step we enable the concept of grasp to work as the existential pillar of a pragmatic sociology of interiority10.\nTwo important topics must be addressed regarding this Meadian-inspired formulation of the inner grasp. The first one is related to the compatibility between synthesis and disruption in the work of the “I”. The “I” may act as a disruptive force as the individual sees itself from a new angle during the self-inquiry engaged by it in the context of a problematic experience. However, a synthetical movement still guides it, as it seeks to leave behind the existential discomfort set in place once a problem has been established. Thus, disruption has to do with the contrast between the contents mobilized in the course of self- inquiry and the initial frame of the problem one is experiencing11.\nThe second topic complements the first and resumes the issue of the tension between the “I” and the “me” as approached towards the end of the previous section. As stated at that moment, both phases strive to grasp each other in the context of inner problematic situations. Chateauraynaud’s pragmatic sociology brings substance to this 10 In sociology, Thomas and Znaniecki (1918-21) were pioneers in developing a biographical analysis of the individual “life-organization” inspired by the legacy of pragmatism. Strauss (1959), in his turn, clearly borrowed the pragmatist conceptions of problem and inquiry (although without explicit reference to them) for analyzing self-identity through his discussion of “self-appraisals”. Corrêa (2021) has similarly followed this path recently, also proposing a dialogue between classical pragmatism and contemporary pragmatic sociology.\n11 Some complementary observations on this topic: 1) By “existential discomfort” I mean a form of dissatisfaction untied to any specific state of emotion. In light of this, peace, stillness and joy may be sources of existential discomfort just as unrest, suffering or misery; 2) given 1, by mentioning a movement away from such discomfort I evidently do not rely on the structural-functional argument of a constant human necessity of stability and social conformation, as conformation itself may be the cause of discomfort in the first place; 3) the synthetical movement set forth by a problem is not rectilinear or predictable; 4) because of 3, the exercise of a synthetic movement does not guarantee at all that a reconstruction will come to term, since a person may found itself in a continuous process of self-search without ever achieving a stationary solution.\ndiscussion. With his version of the concept of tests (épreuves), pervasive in pragmatic sociology, Chateauraynaud (2004: 169) invites us to think that the disintegration caused by a problem can not make disappear entirely the material and symbolic properties of beings involved in it. This reasoning is fully in line with Mead’s theory of the act. We may then assert that in order to conduct reconstruction and (re)gain an inner grasp, the “I” must deal with both cooperation and resistance offered by elements in the objective phase of the self.\nIn order to grasp oneself, a person must go through tests whose content is linked to the configuration of the problematic experience12. It is the result of these tests, in which the “I” and the “me” communicate more or less contentiously, which will determine the amount of permanence or transformation of the self. Like outer grasps on collective problems, inner grasps are also constantly put to the test by what one experiences in social situations.\nBased on such an articulation, we have observed that the bias caused by asymmetric ascendancy produces its effects on the relations of the self with its own internal province and with its environment; its effects stretch down to the self’s very sense of reality developed in its interactions with the other selves and the world. The ontological politics found in the new mastery of nature projects itself over the territories of experience of different strata of the world population, not just as a new grammar of relations with the environment, but, equally, as an existential prescription that naturalizes flexibility as a principle for the orientation of the self. The dynamics between the “I” and the “me” pointed out in the second part of this text is fully connected to this process.\nThe internal components of the self are also coveted by this form of existential ascendancy, since its goal is to influence the behavior of social actors. In order to further assess this assertion, I must take the case of climatic change policies mentioned by Pellizzoni (2015: 4): according to him, the new approach towards nature becomes normative when, among other factors, it boosts the overlapping of the principle of adaptation to that of mitigation in these regulations. This process leads to the normalization of uncertainty and spreads the imperative of flexibility to adapt to new situations as a form of individual responsibility in face of risks. The emphasis on the concept of adaptation, as it was molded and disseminated by multi-lateral actors, such as the United Nations Framework Convention on Climate Change (UNFCCC), shifts the focus of measures regarding risks from a paradigm of stability to that of adequacy to environmental instabilities (Jennings, 2011: 12 Périlleux (2001) speaks of “self-tests” (épreuves du soi) in an approach closely linked to that of Boltanski and Chiapello (1999).\n240). According to Grove (2014: 204), the adaptation discourse in contemporary climate- change and disaster policies heads towards the production of forms of life “appropriate” to contexts under risk, which are responsive to them and capable of forging their actions based on signs of threat. Just as assessed by Jennings (2011), the study by Grove suggests that, oftentimes, one of the consequences of implementing adaptation policies is the establishment of asymmetric relations between government and local populations that atomizes social responsibility for risks by transferring it from the state to the individual level. Once exposed to educational and qualification programs and to awareness initiatives, individuals are expected to engage in reviews of their own attitudes in order to make themselves pliable to the contingency of milieus (Grove, 2014: 203ff). An adaptable self is then vaunted, flexible enough to adequate to, and even to profit from, the unavoidable indeterminacy of nature and to be responsible enough to know that its fortune in this risky setting depends mainly on its individual behavior.\nIt is worth highlighting that such a critical consideration about the concept of adaptation refers to its hegemonic, contemporary version, which is consolidated in the official circles of the United Nations and national governments. The term presents a polysemic spectrum, and pragmatism itself houses a conception of adaptation related to its ecological interpretation of agency. The first generation of critical theory clung to a troublesome reduction of such an interpretation as a form of political conformism, when, by talking about adaptation, pragmatists actually “[…] never meant routine and loss of subjectivity but practical innovation, creative solutions to real problems.” (Joas, 1985 [1980]: 83, emphasis in original)13. Based on such logic, and besides the pragmatist difficult relation with conflict that I have herein tried to compensate, adaptation can represent either a way of accommodating to the status quo or to fully transform it. The current hegemonic conception of adaptation can nonetheless be interpreted as a feature to prevent transformation, especially if it is oriented towards a radical revision of risk production in capitalism. Many times, the non-publicized implication of a discourse that advocates for the promotion of empowerment of vulnerable communities, so they can develop their own ways of adaptation, is, in fact, the exclusion of anti-systemic alternatives of response.\nThe flexibilization of life as imperative linked to the new spirit of capitalism brings along a configuration where dealing with risks implies the continuous availability of 13 See Dewey’s (2013 [1934]: 14-15) differentiation between accommodation, adjustment and adaptation and the sociological account of adaptation in contexts of social change in Thomas and Znaniecki (1918-21).\ncognitive and affective arrangements between people and environments. If the new mastery of nature sets a guideline that can lead local actors to lose their grasps over the milieu, it may also promote a forced malleability of life projects, desires and dreams at the inner domains of their selves, which is justified by the need of adequacy to an always mobile horizon of hazards. Based on the conceptual articulation I have addressed earlier, I can talk about the chances of a varying loss not only of outer, but also inner grasps when individuals find themselves under the ascendancy of the hegemonic agenda of contemporary risk policies.\nBy replicating what happens in other neoliberal institutional coordinates (Boltanski and Chiapello, 1999), to the extent that legitimate powers are successful in diffusing the principles of adaptation and flexibilization, it is possible that a tendency for the reduction of autonomous determination of the perspectives of local actors may develop. This is due mainly to the interference in their selves’ inquiry space. The “I” lies in the center of this dynamics of ascendancy, since it is necessary to encapsulate its singularizing activity within a behavioral program ruled by the ethos of flexibility and adaptability. However, due to the striking contingency of the “I”, the logic of adaptation opts for an indirect form of control. It reaches the objective phases (“me”) of its target audience, provides them with justifications for an individualized responsibility towards risk and diminishes the room for autonomous responses of the “I”. This “culture of safety” (Grove, 2014: 205) espoused by many risk reduction official managers, is entangled with the perspective of the ontological instability of the environment, result of material manipulations upon nature’s properties. As a result,, the tests biasing these audiences’ inner grasps towards adaptable versions of their selves are sustained by both conventional and material supports. In the end, we observe that the depoliticizing outer grasps laid by the new mastery of nature upon its resistance to typical industrial exploration are mirrored by the exaltation of a flexibilizing model of inner grasp with the purpose of ascendancy.\nConclusion The discussion about the contemporary ontological politics based on Mead’s philosophy stands out due to the sensibility of his naturalist pragmatism to the entanglement of the natural and the social. With the aid of his perspective we observe that new forms of political coordination of nature derive from reciprocal modifications in perspectives between human communities and the biogeophysical world. With that in view, the integration of subjective processes of the self within a critical appreciation of society cannot dispense with the disclosure of the engines of mesological ascendancy that entertain human relations. Thus, the reassessment of risks as opportunities favors an asymmetric form of ontological flexibilization that affects life from its molecular level to the symbolic exchanges at social plan.\nThroughout the article, Markell’s rescue of James and Dewey’s influence on Mead’s initial definition of the concepts of “I” and “me” have worked as the basis for the reinterpretation of the relationship between materiality and subjectivity in the final, Whiteheadian phase of his work, and it enabled a new outlook over the role of materiality in the composition of the self. This was the background for the articulation between Mead’s pragmatism and Chateauraynaud’s sociology, which proposed the former’s concept of self as the fundament for the pragmatics of interiority envisaged by the latter, rendering it a Meadian twist. By bringing together these two authors, I sought to contribute with an alternative to the hegemonic interpretation of the internal dynamics of the Meadian self in sociology, more sensible to the material contours of subjectivity. What has been developed in this article lays the foundations for this endeavor, which shall be further explored both theoretically and empirically in future occasions. The idea of self-inquiries as one’s attempt to grasp itself may be unfolded both internally, through the access of other regions in the works of its two central authors, or externally, by bringing into its synthesis other references converging to the general conception of self sketched throughout the text.",
    "crumbs": [
      "General",
      "On the material supports of subjectivity"
    ]
  },
  {
    "objectID": "extracted/On_the_material_supports_of_subjectivity.html#references",
    "href": "extracted/On_the_material_supports_of_subjectivity.html#references",
    "title": "On the material supports of subjectivity",
    "section": "References",
    "text": "References\nBESSY C and CHATEAURAYNAUD F (1995) Experts et faussaires. Pour une sociologie de la perception. Paris: Métailié.\nBOLTANSKI L and CHIAPELLO E (1999) Le nouvel esprit du capitalisme. Paris: Gallimard.\nBOLTON CB (1981) Some consequences of the Meadian self. Symbolic Interaction, 4(2): 245-259.\nBLUMER H (1969) Symbolic interactionism: Perspective and method. Englewood Cliffs: Prentice-Hall.\nBLUMER H (2004) George Herbert Mead and human conduct. Walnut Creek: Altamira.\nBREWSTER BH and PUDDEPHATT AJ (2013) George Herbert Mead as a socio- environmental thinker. In: JOAS H and HUEBNER DR (eds) The timeliness of George Herbert Mead. Chicago: The University of Chicago Press.\nCEFAÏ D (2001) Le naturalisme dans la sociologie américaine au tournant du siècle: La genèse de la perspective de l’École de Chicago. Revue du MAUSS, 1(17): 261-274.\nCHATEAURAYNAUD F (2004) L’épreuve du tangible: Expériences de l’enquête et surgissements de la preuve. In: KARSENTI B and QUÉRÉ L (eds) La croyance et l’enquête: Aux sources du pragmatisme. Paris: EHESS.\nCHATEAURAYNAUD F (2015) L’emprise comme expérience: Enquêtes pragmatiques et théories du pouvoir. SociologieS, Dossier “Pragmatismes et Sciences Sociales” (on-line).\nAvailable at: http://sociologies.revues.org/4931, (accessed 23 February 2015).\nCHATEAURAYNAUD F (2018) De la criticité des causes environnementales. In: CARLINO V and STEIN M (eds) Les paroles militants dans les controverses environnementales. Nancy: Editions Universitaires de Lorraine.\nCHATEAURAYNAUD F and DEBAZ J (2017) Aux bords de l’irréversible: Sociologie pragmatique des transformations. Paris: Petra.\nCOOK GA (1993) George Herbert Mead: The making of a social pragmatist. Urbana and Chicago: University of Illinois Press.\nCOOK GA (2013) Mending Mead’s “I” and “me” distinction. In: LOW J and BOWDEN G (eds) The Chicago School diaspora: Epistemology and substance. Montreal and Kingston: McGill-Queen’s University Press.\nCOOLE D and FROST S (2010) Introducing the new materialisms. In: COOLE D and FROST S (eds) New materialisms: Ontology, agency, and politics. Durham and London: Duke University Press.\nCOOPER M (2008) Life as surplus: Biotechnology and capitalism in the neoliberal era.\nSeattle and London: University of Washington Press.\nCORRÊA DS (2021) Esboço de uma sociologia dos problemas íntimos. Sociologia & Antropologia 11(2): 415-444.\nDEMEULENAERE E (2014) A political ontology of seeds: The transformative frictions of a farmer’s movement in Europe. Focaal – Journal of Global and Historical Anthropology 69: 45-61.\nDEWEY J (1896) The reflex arc concept in psychology. The Psychological Review, III(4): 357-370.\nDEWEY J (2013 [1934]) A common faith. New Haven and London: Yale University Press.\nDEWEY J, HOOK S and NAGEL E (1945) Are naturalists materialists? The Journal of Philosophy 42(19): 515-530.\nDODIER N (1993) Les appuis conventionnels de l’action: Eléments de pragmatique sociologique. Réseaux 11(62):63-85.\nFREGA R (2006) John Dewey et la philosophie comme épistémologie de la pratique. Paris: L’Harmattan.\nGIDDENS A (1984) The constitution of society. Cambridge: Polity.\nGROVE K (2014) Biopolitics and adaptation: Governing socio-ecological contingency through climate change and disaster studies. Geography Compass 8(3): 198-210.\nHABERMAS J (1987 [1985]) The theory of communicative action, vol. 2. Boston: Beacon.\nHABERMAS J (1992) Postmetaphysical thinking: Philosophical essays. Cambridge, MA: The MIT Press.\nHONNETH A (1995 [1992]) The struggle for recognition. Cambridge: Polity.\nHONNETH A (2002) Grounding recognition: A rejoinder to critical questions. Inquiry: An Interdisciplinary Journal of Philosophy 45(4):499-520.\nHUEBNER, DR (2014) Becoming Mead: The social process of academic knowledge.\nChicago: The University of Chicago Press.\nJAMES W (1955 [1890]) Principles of psychology. Chicago: The University of Chicago Press/Encyclopaedia Britannica.\nJENNINGS T (2011) Transcending the adaptation/mitigation climate change science policy debate: Unmasking assumptions about adaptation and resilience. Weather, Climate, and Society 3(4): 238-248.\nJOAS H (1985 [1980]) G.H. Mead: A contemporary re-examination of his thought.\nCambridge, MA: The MIT Press.\nJOAS H (1993) Pragmatism and social theory. Chicago: The University of Chicago Press.\nJOAS H (1996) The creativity of action. Chicago: The University of Chicago Press.\nLEWIS JD (1979) A social behaviorist interpretation of the Meadian “I”. American Journal of Sociology (85)2: 261-287.\nMacGILVRAY E (2004) Reconstructing public reason. Cambridge, MA: Harvard University Press.\nMARKELL P (2007) The potential and the actual: Mead, Honneth, and the “I”. In: VAN DEN BRINK, B and OWEN, D (eds) Recognition and power: Axel Honneth and the tradition of critical social theory. Cambridge: Cambridge University Press.\nMEAD GH (1903) The definition of the psychical. Decennial publications of the University of Chicago, 1º series, Vol. III. Chicago: The University of Chicago Press.\nMEAD GH (1904) Image or sensation. Journal of Philosophy, Psychology and Scientific Methods 1(22): 604-607.\nMEAD GH (1910) What social objects must psychology presuppose? Journal of Philosophy, Psychology and Scientific Methods 7(7): 174-180.\nMEAD GH (1912) The mechanism of social consciousness. Journal of Philosophy, Psychology and Scientific Methods 9(15): 401-406.\nMEAD GH (1913) The social self. Journal of Philosophy, Psychology and Scientific Methods 10(14): 374-380.\nMEAD GH (1922) A behavioristic account of the significant symbol. The Journal of Philosophy 19(6): 157-163.\nMEAD GH (1925) The genesis of the self and social control. International Journal of Ethics 35(3): 251-277.\nMEAD GH (1926) The nature of aesthetic experience. International Journal of Ethics 36(4): 382-393.\nMEAD GH (1932) The philosophy of the present. LaSalle, IL: Open Court.\nMEAD GH (1967 [1934]) Mind, self & society. Chicago: The University of Chicago Press.\nMEAD GH (1972 [1938]) The philosophy of the act. Chicago: The University of Chicago Press.\nMEAD GH (2011 [n.d.]) On the self and teleological behavior. In: SILVA, FC (ed) G.H.\nMead: A reader. London and New York: Routledge.\nMELLO, FC (2017) Assimetria e Contestação: Uma sociologia pragmatista das subjetividades coletivas. PhD thesis, State University of Rio de Janeiro, Brazil.\nMELLO, FC (2019) As transformações de Francis Chateauraynaud: Percepção e reflexividade na segunda onda da sociologia pragmática francesa. Sociologia & Antropologia 9(1): 159-184.\nMOL A (1999) Ontological Politics: A word and some questions. The Sociological Review 47(S1): 74-89.\nMORIN E (2008) On complexity. Cresskill: Hampton Press.\nPAPADOPOULOS D (2011) The imaginary of plasticity: neural embodiment, epigenetics, and ecomorphs. The Sociological Review (59)3: 432-456.\nPELLIZZONI L (2015) Ontological politics in a disposable world: The new mastery of nature. Farnham: Ashgate.\nPÉRILLEUX, T (2001) Les tensions de la flexibilité: L’épreuve du travail contemporain.\nParis: Desclée de Brouwer.\nROSENTHAL SB and BOURGEOIS PL (1991) Mead and Merleau-Ponty: Toward a common vision. Albany: State University of New York Press.\nSILVA FC (2007) G.H. Mead: A critical introduction. Cambridge: Polity.\nSILVA FC (2008) Mead and modernity: Science, selfhood, and democratic politics. Lanham: Lexington Books.\nSTRAUSS A (1959) Mirrors and masks: The search for identity. Glencoe, IL: Free Press.\nSZERSZYNSKI B, KEARNES M, MACNAGHTEN P, OWEN R and STILGOE J (2013) Why solar radiation management geoengeneering and democracy won’t mix. Environment and Planning A 45: 2809-2816.\nTHOMAS WI and ZNANIECKI F (1918-21) The Polish peasant in Europe and America: Monograph of an immigrant group, 4 vols. Boston: The Gorham Press.\nWHITEHEAD AN (2011 [1925]) Science and the modern world. Cambridge: Cambridge University Press.\nWHITEHEAD AN (1978) Process and reality. New York: Free Press.",
    "crumbs": [
      "General",
      "On the material supports of subjectivity"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html",
    "href": "extracted/Counterfactuals and Causal Inference.html",
    "title": "Counterfaturals and Causal Inference",
    "section": "",
    "text": "SecondEdition\nIn this completely revised and expanded second edition of Counterfactuals and Causal Inference, the essential features of the counterfactual approach to observational data analy- sisarepresentedwithexamplesfromthesocial,demographic,andhealthsciences.Alternative estimationtechniquesarefirstintroducedusingboththepotentialoutcomemodelandcausal graphs;afterwhichconditioningtechniques,suchasmatchingandregression, arepresented fromapotentialoutcomesperspective. Forresearch scenarios inwhichimportant determi- nantsofcausalexposureareunobserved,alternativetechniques,suchasinstrumentalvariable estimators,longitudinalmethods,andestimationviacausalmechanisms,arethenpresented.\nTheimportanceofcausaleffectheterogeneityisstressed throughoutthebook,andtheneed fordeepcausalexplanationviamechanismsisdiscussed.\nStephenL.MorganistheBloombergDistinguishedProfessorofSociologyandEducationat JohnsHopkinsUniversity.HewaspreviouslytheJanRockZubrow’77ProfessorintheSocial SciencesandthedirectoroftheCenterfortheStudyofInequalityatCornellUniversity. His currentareasofinterestincludesocialstratification, thesociologyofeducation,andquanti- tativemethodology. HehaspublishedOntheEdge ofCommitment: EducationalAttainment andRaceintheUnitedStates(2005)and,aseditor,theHandbookofCausalAnalysisforSocial Research(2013).\nChristopherWinshipistheDiker-TishmanProfessorofSociologyandamemberofthesenior facultyofHarvard’sKennedySchoolofGovernment. PriortocomingtoHarvardin1992,he wasProfessorofSociologyandStatisticsandbycourtesyEconomicsatNorthwesternUniver- sity.Hisresearchfocusesonstatisticalmodelsforcausalinference,mostrecentlymechanisms and endogenous selection; how black clergy in Boston have worked with police to reduce youthviolence;theeffectsofeducationonmentalability;pragmatismasthebasisforatheory ofaction;theimplicationsofadvancesincognitivepsychologyforsociology;andsociological approachestohowindividualsunderstandjustice.Since1995hehasbeeneditorofSociological MethodsandResearch.\nAnalytical Methods for Social Research AnalyticalMethodsforSocialResearchpresentstextsonempiricalandformalmethodsforthe socialsciences. Volumesintheseriesaddressboththetheoreticalunderpinningsofanalyti- caltechniquesaswellastheirapplicationinsocialresearch. Someseriesvolumesarebroadin scope,cuttingacrossanumberofdisciplines.Othersfocusmainlyonmethodologicalapplica- tionswithinspecificfieldssuchaspoliticalscience,sociology,demography,andpublichealth.\nTheseriesservesamixofstudentsandresearchersinthesocialsciencesandstatistics.\nSeriesEditors: R.MichaelAlvarez,CaliforniaInstituteofTechnology NathanielL.Beck,NewYorkUniversity LawrenceL.Wu,NewYorkUniversity OtherTitlesintheSeries: TimeSeriesAnalysis fortheSocialSciences, byJanet M.Box-Steffensmeier, JohnR.Freeman, MatthewPerryHitt,andJonC.W.Pevehouse EventHistoryModeling:AGuideforSocialScientists,byJanetM.Box-Steffensmeierand BradfordS.Jones EcologicalInference: NewMethodologicalStrategies,editedbyGaryKing,OriRosen,and MartinA.Tanner SpatialModelsofParliamentaryVoting,byKeithT.Poole EssentialMathematicsforPoliticalandSocialResearch,byJeffGill PoliticalGameTheory:AnIntroduction,byNolanMcCartyandAdamMeirowitz Data Analysis Using Regression and Multilevel/Hierarchical Models, by Andrew Gelman and JenniferHill # Counterfactuals and Causal Inference: Methods and Principles for Social Research\nSecondEdition\nSTEPHEN L. MORGAN JohnsHopkinsUniversity CHRISTOPHER WINSHIP HarvardUniversity 32AvenueoftheAmericas,NewYork,NY10013-2473,USA CambridgeUniversityPressispartoftheUniversityofCambridge.\nItfurtherstheUniversity’smissionbydisseminatingknowledgeinthepursuitof education,learning,andresearchatthehighestinternationallevelsofexcellence.\nwww.cambridge.org Informationonthistitle:www.cambridge.org/9781107065079 (cid:2)c StephenL.MorganandChristopherWinship2007,2015 Thispublicationisincopyright.Subjecttostatutoryexception andtotheprovisionsofrelevantcollectivelicensingagreements, noreproductionofanypartmaytakeplacewithoutthewritten permissionofCambridgeUniversityPress.\nFirstpublished2007 Secondedition2015 PrintedintheUnitedStatesofAmerica AcatalogrecordforthispublicationisavailablefromtheBritishLibrary.\nLibraryofCongressCataloginginPublicationData Morgan,StephenL.(StephenLawrence),1971– Counterfactualsandcausalinference:methodsandprinciplesforsocialresearch/ StephenL.Morgan,ChristopherWinship.\npages cm.–(Analyticalmethodsforsocialresearch) Revisededitionoftheauthors’Counterfactualsandcausalinference,publishedin2007.\nIncludesbibliographicalreferencesandindex.\nISBN978-1-107-06507-9(hardback)–ISBN978-1-107-69416-3(paperback) 1. Socialsciences–Research. 2. Socialsciences–Methodology.\nH62.M6462015 300.72–dc23 2014033205 ISBN978-1-107-06507-9Hardback ISBN978-1-107-69416-3Paperback CambridgeUniversityPresshasnoresponsibilityforthepersistenceoraccuracyof URLsforexternalorthird-partyInternetWebsitesreferredtointhispublication anddoesnotguaranteethatanycontentonsuchWebsitesis,orwillremain, accurateorappropriate.\nTomywife,Sydney,myson,Vinny,andmydaughter,Beatrix –SteveMorgan Tomywife,Nancy,andmysons,DavidandMichael –ChrisWinship ## Contents\nListofFigures page xiii\nListofTables xvii AcknowledgmentsforFirstEdition xxi AcknowledgmentsforSecondEdition xxiii I CausalityandEmpiricalResearchintheSocialSciences 1 Introduction 3 1.1 ThePotentialOutcomeModelofCausalInference 4 1.2 CausalAnalysisandObservationalSocialScience 6 1.3 ExamplesUsedThroughouttheBook 14 1.4 ObservationalDataandRandom-SampleSurveys 27 1.5 CausalGraphsasanIntroductiontotheRemainderoftheBook 29 II Counterfactuals,PotentialOutcomes,andCausalGraphs 2 CounterfactualsandthePotentialOutcomeModel 37 2.1 DefiningtheCausalStates 37 2.2 PotentialOutcomesandIndividual-LevelTreatmentEffects 43 2.3 TreatmentGroupsandObservedOutcomes 44 2.4 TheAverageTreatmentEffect 46 2.5 TheStableUnitTreatmentValueAssumption 48 2.6 TreatmentAssignmentandObservationalStudies 53 2.7 AverageCausalEffectsandNaiveEstimation 54 2.8 Over-TimePotentialOutcomesandCausalEffects 62 2.9 ThePotentialOutcomeModelforMany-ValuedTreatments 70 2.10 Conclusions 73 2.11 AppendixtoChapter2:PopulationandDataGenerationModels 74 3 CausalGraphs 77 3.1 Identification 78 3.2 BasicElementsofCausalGraphs 79 3.3 GraphsandStructuralEquations 84 3.4 CausalGraphsandthePotentialOutcomeModel 90 ix 3.5 Conclusions 94 3.6 AppendixtoChapter3:Graphs,Interventions,andPotentialOutcomes 95 III EstimatingCausalEffectsbyConditioningonObservedVariablestoBlock Back-DoorPaths 4 ModelsofCausalExposureandIdentificationCriteria forConditioningEstimators 105 4.1 ConditioningandDirectedGraphs 105 4.2 TheBack-DoorCriterion 109 4.3 ModelsofCausalExposureandPointIdentificationBasedonthePotential OutcomeModel 118 4.4 ConditioningtoBalanceandConditioningtoAdjust 128 4.5 Conclusions 130 4.6 AppendixtoChapter4:TheBack-DoorandAdjustmentCriteria, Descendants,andCollidersUnderMagnification 130 5 MatchingEstimatorsofCausalEffects 140 5.1 OriginsofandMotivationsforMatching 141 5.2 MatchingasConditioningviaStratification 143 5.3 MatchingasWeighting 150 5.4 MatchingasaDataAnalysisAlgorithm 158 5.5 RemainingPracticalIssuesinMatchingAnalysis 181 5.6 Conclusions 187 6 RegressionEstimatorsofCausalEffects 188 6.1 RegressionasaDescriptiveTool 188 6.2 RegressionAdjustmentasaStrategytoEstimateCausalEffects 194 6.3 RegressionasConditional-Variance-WeightedMatching 206 6.4 RegressionasanImplementationofaPerfectStratification 214 6.5 RegressionasSupplementalAdjustmentWhenMatching 215 6.6 ExtensionsandOtherPerspectives 217 6.7 Conclusions 224 7 WeightedRegressionEstimatorsofCausalEffects 226 7.1 WeightedRegressionEstimatorsoftheATE 227 7.2 WeightedRegressionEstimatorsoftheATTandtheATC 231 7.3 DoublyRobustWeightedRegressionEstimators 234 7.4 RemainingPracticalIssuesinWeightedRegressionAnalysis 238 7.5 AnExtendedExample 243 7.6 Conclusions 262 IV EstimatingCausalEffectsWhenBack-DoorConditioningIsIneffective 8 Self-Selection,Heterogeneity,andCausalGraphs 267 8.1 NonignorabilityandSelectionontheUnobservablesRevisited 268 8.2 SelectionontheUnobservablesandtheUtilityofAdditional PosttreatmentMeasuresoftheOutcome 269 8.3 CausalGraphsforComplexPatternsofSelf-Selection andHeterogeneity 278 8.4 Conclusions 290 9 InstrumentalVariableEstimatorsofCausalEffects 291 9.1 CausalEffectEstimationwithaBinaryIV 291 9.2 TraditionalIVEstimators 296 9.3 InstrumentalVariableEstimatorsinthePresenceofIndividual-Level Heterogeneity 305 9.4 Conclusions 324 10 MechanismsandCausalExplanation 325 10.1 TheDangersofInsufficientlyDeepExplanations 326 10.2 TheFront-DoorCriterionandIdentificationofCausalEffectsby Mechanisms 330 10.3 TheAppealforGenerativeMechanisms 338 10.4 ThePursuitofExplanationwithMechanismsThatBottomOut 346 10.5 Conclusions 352 11 RepeatedObservationsandtheEstimationofCausalEffects 354 11.1 InterruptedTimeSeriesModels 355 11.2 RegressionDiscontinuityDesigns 360 11.3 PanelData 363 11.4 Conclusions 392 11.5 AppendixtoChapter11:Time-VaryingTreatmentRegimes 392 V EstimationWhenCausalEffectsAreNotPoint-IdentifiedbyObservables 12 DistributionalAssumptions,SetIdentification,andSensitivityAnalysis 419 12.1 DistributionalAssumptionsandLatentVariableSelection-BiasModels 420 12.2 SetIdentificationwithMinimalAssumptions 422 12.3 SensitivityAnalysisforProvisionalCausalEffectEstimates 429 12.4 Conclusions 434 VI Conclusions 13 CounterfactualsandtheFutureofEmpiricalResearchinObservational SocialScience 437 13.1 ObjectionstoAdoptionoftheCounterfactualApproach 438 13.2 ModesofCausalInquiryintheSocialSciences 446 References 451 Index 497 ## Figures\n1.1 Acausalgraphinwhichback-doorpathsfromDtoY canbeblockedby\nobservablevariablesandinwhichCisaninstrumentalvariableforD page 30 1.2 AcausalgraphinwhichCisnolongeraninstrumentalvariableforD 32 1.3 AcausaldiagraminwhichM andN representanisolatedandexhaustive mechanismforthecausaleffectofDonY 32 2.1 CrudebirthratesinJapan,1951–1980 65 3.1 Adirectedgraphthatincludesacycle 80 3.2 TworepresentationsofthejointdependenceofAandBonunobserved commoncauses 81 3.3 Basicpatternsofcausalrelationshipsforthreevariables 82 3.4 TwographsinwhichthecausaleffectofDonY isconfoundedbyC 83 3.5 Acausalgraphinwhichtheeffectofeducation(E)onearnings(Y)is confoundedbyobservedvariables(C)andbyunobservedability(A) 84 3.6 Atraditionallinearadditivepathdiagramfortheeffectsofparental background(P),charterschools(D),andneighborhoods(N)ontestscores(Y) 86 3.7 Equivalentdirectedgraphrepresentationsoftheeffectsofparentalbackground (P),charterschools(D),andneighborhoods(N)ontestscores(Y) 88 3.8 Twoalternativerepresentationsofassumedinterventionsincausalgraphs wheretheeffectofDonY isconfoundedbyC 96 3.9 Alternativegraphsforthejointdependenceofatwo-valuedcausalvariablefor education(E)andpotentialoutcomesforearnings(Y0andY1)onobserved confounders(C)andonanunobservedconfounderforability(A) 101 4.1 AgraphinwhichthecausaleffectofDonY isconfoundedbytheback-door pathD ←C →O →Y 106 4.2 Simulationofconditionaldependencewithinvaluesofacollidervariable 108 4.3 AcausaldiagraminwhichYt−1isacollideralongaback-doorpath 111 4.4 AcausaldiagraminwhichAisacollideronaback-doorpath 112 4.5 AcausaldiagraminwhichYt−2isacollideronaback-doorpathandYt−1is itsdescendant 114 4.6 Aconfoundedcausaleffectexpressedasanindirecteffectandanetdirecteffect 114 4.7 AgraphwheretheeffectofDonY isnotidentifiedbyconditioningonOand BbecauseOisadescendantofD 115 4.8 Causaldiagramsinwhichtreatmentassignmentis(a)nonignorableand (b)ignorable 121 xiii 4.9 Causaldiagramsfortheterminologyfromeconometricmodelingoftreatment selection 125 4.10 Acausaldiagraminwhichsufficientconditioningcanbeperformedwith respecttoSorX 129 4.11 Acausalgraphwithaconfoundedcausaleffectandwherethevariablesalong theback-doorpathareviewedundermagnification 131 4.12 AdiagramwherethecausaleffectofDonY isnotconfoundedandwherethe observedvariableOontheback-doorpathisadescendantofboth DandY 133 4.13 AgraphwheretheeffectofDonY isnotidentifiedbyconditioningonOand BbecauseOisadescendantofD 135 4.14 Adirectedgraphthatrevealsthedifferencesbetweentheback-doorcriterion andtheadjustmentcriterion 137 5.1 ThepropensityscorespecificationforMatchingDemonstration3 154 5.2 Thedirectedgraphimpliedbytheunderlyingdatagenerationmodelfor MatchingDemonstration4 174 6.1 GraphsforaregressionequationofthecausaleffectofDonY 196 6.2 AcausalgraphforaregressionequationinwhichthecausaleffectofDonY is identifiedbyconditioningonX 201 7.1 Kerneldensityestimatesoftheestimatedpropensityscore,calculated separatelyforpublicschoolstudents(blacksolidline)andCatholicschool students(graydashedline) 249 8.1 Coleman’sstrategyfortheidentificationofthecausaleffectofCatholic schoolingonachievement 269 8.2 CriticismofColeman’sestimatesoftheeffectofCatholicschoolingonlearning 272 8.3 Separatecausalgraphsfortwogroupsofindividuals(G=1andG=2) wheretheeffectsofparentalbackground(P)andcharterschools(D)ontest scores(Y)maydifferforthetwogroups 279 8.4 Agraphwheregroupsarerepresentedbyanunobservedlatentclassvariable (G)inasinglegraph 281 8.5 Twographswhereselectionintocharterschools(D)isdeterminedbygroup (G)andwhereselectionrenderstheeffectofDonY unidentifiedaslongasG remainsunobserved 282 8.6 Twographswhereselectionontheunobservablesisgivenanexplicit representationasself-selectiononsubjectiveexpectationsofvariationinthe causaleffectofDonY.Forpanel(b),theseexpectationsaredeterminedby information(I)thatisdifferentiallyavailabletofamilieswithparticular parentalbackgrounds(P) 283 8.7 Agraphwhereself-selectiononthecausaleffectofcharterschoolingalso triggersself-selectionintoconsequentialandinteractiveneighborhood contexts(N) 285 9.1 TwographsinwhichZisapotentialinstrumentalvariable 292 9.2 TwographsinwhichZisavalidIV 298 9.3 Agraphwithanunblockedback-doorpathandavalidIV 302 9.4 Instrumentalvariableidentificationofthecausaleffectofcharterschools(D) ontestscores(Y),whereZ istheinstrument 318 9.5 Instrumentalvariableidentificationofthecausaleffectofcharterschools(D) ontestscores(Y),whereseparategraphsaredrawnforcompliersand noncompliers 320 9.6 AcombinedgraphforFigures9.5(a)–(b),whereZ istheinstrumentand complianceisrepresentedasanunobservedlatentclassvariable(C) 321 9.7 IdentificationoftheLATEusinganinstrument(Z)forthecharterschool graphpresentedearlierinFigure8.7.TheunobservedvariableV isa compositeforthecausalchainthatgeneratesself-selectioninFigure8.7 throughinformationaccessandselectiononthesubjectiveevaluationofthe individual-levelcausaleffect 322 10.1 AdirectedgraphforcomplierswithquarterofbirthasanIVfor yearsofschooling 327 10.2 AdirectedgraphforcomplierswiththeVietnamdraftlotteryas anIVformilitaryservice 328 10.3 AdirectedgraphinwhichM andN representanexhaustiveandisolated identifyingmechanismforthecausaleffectofDonY 332 10.4 AdirectedgraphinwhichM isnotanisolatedmechanismforthecausaleffect ofDonY 335 10.5 Directedgraphsinwhichonepathwayinanexhaustiveandisolated mechanismisunobserved 336 11.1 Trajectoriesoftheobservedoutcomeaswellasthetrueandassumed counterfactualoutcomesforafaultyITSmodel 357 11.2 MonthlyyouthhomicideratesinBoston,1991–1999 358 11.3 ForeseeabilityofalayoffasanexampleofanRDdesign 361 11.4 AnexampleofafuzzyRDdesign 362 11.5 AdirectedgraphfortheeffectofCatholicschoolingontenthgrade achievementwhenameasureofeighthgradeachievementisalsoavailable 367 11.6 ExamplesofpossibletrajectoriesforE[Y0]forthetreatmentgroup(theupper it lineofeachpair)andthecontrolgroup(thelowerlineofeachpair)wherethe correctadjustmentfavor,α,varies 377 11.7 Depictionsofpossibletrajectories,asspecifiedbythemodelsinTable11.3,for EY0|D∗ =1andEY0|D∗ =0 382 11.8 Amodelofendogenoustreatmentassignmentinwhichselectionisonthe pretreatmentoutcome,Yt−1 383 11.9 Amodelofendogenoustreatmentassignmentinwhichselectionisonafixed effectthatalsodeterminestheoutcome 384 11.10 TheCatholicschooleffectinthetenthandtwelfthgradesasadynamic treatmentregime 395 11.11 AnillustrativedirectedgraphforG-computation 408 11.12 Adirectedgraphforapseudo-populationproducedusinginverseprobability oftreatmentweighting 412 12.1 AgraphinwhichthecausaleffectofDonY isconfoundedbyanobserved variableCandanunobservedvariableU 431 ## Tables\n2.1 TheFundamentalProblemofCausalInference page 46\n2.2 AHypotheticalExampleinWhichSUTVAIsViolated 49 2.3 AnExampleofInconsistencyandBiasoftheNaiveEstimatorWhentheATEIs theCausalEffectofInterest 60 2.4 TheFundamentalProblemofCausalInferenceforMany-ValuedTreatments 71 2.5 TheObservabilityTableforEstimatingHowEducationIncreases Earnings 72 5.1 TheJointProbabilityDistributionandConditionalPopulationExpectations forMatchingDemonstration1 146 5.2 EstimatedConditionalExpectationsandProbabilitiesforMatching Demonstration1 146 5.3 TheJointProbabilityDistributionandConditionalPopulationExpectations forMatchingDemonstration2 149 5.4 EstimatedConditionalExpectationsandProbabilitiesforMatching Demonstration2 149 5.5 MonteCarloMeansandStandardDeviationsofTrueandEstimatedTreatment EffectsforMatchingDemonstration3 155 5.6 MatchingEstimatesoftheATT,CatholicSchoolingonAchievementforOne SimulatedDataset 176 5.7 BiasforMatchingEstimatesoftheATT,CatholicSchoolingonAchievement Across10SimulatedDatasets 178 6.1 TheJointProbabilityDistributionandConditionalPopulationExpectations forRegressionDemonstration1 190 6.2 ExamplesoftheTwoBasicFormsofBiasforLeastSquaresRegression 198 6.3 Two-PersonExamplesinWhichLeastSquaresRegressionEstimatesAre Unbiased 200 6.4 TwoSix-PersonExamplesinWhichRegressionAdjustmentIs DifferentiallyEffective 203 6.5 ARearrangementoftheExampleinTable6.4ThatShowsHowRegression AdjustmentIsDifferentiallyEffective 204 6.6 TheJointProbabilityDistributionforTwoVariantsoftheStratifyingand TreatmentVariablesinPriorRegressionDemonstration1 210 6.7 TheJointProbabilityDistributionandConditionalPopulationExpectations forRegressionDemonstration3 213 xvii 6.8 AverageBiasComparisonsforSelectedMatchingEstimatesoftheATTfrom MatchingDemonstration4,WithandWithoutSupplementalRegression AdjustmentfortheAssumedDeterminantsofTreatmentAssignment 216 7.1 WeightedRegressionEstimatesoftheATE,UsingandExtendingtheData SetupforMatchingDemonstration3 230 7.2 WeightedRegressionEstimatesoftheATTandATC,UsingandExtendingthe DataSetupforMatchingDemonstration3 233 7.3 BiasforWeightedRegressionEstimatesoftheATT,CatholicSchoolingon AchievementAcross10SimulatedDatasetsUtilizedforMatching Demonstration4andRegressionDemonstration4 237 7.4 MeansandStandardDeviationsofthePrimaryVariablesUsedinthe Demonstration 245 7.5 CatholicSchoolCoefficientsfromBaselineRegressionModelsPredicting TenthGradeMathTestScores,TwelfthGradeMathTestScores,andMath TestGains 246 7.6 MeansandStandardDeviationsofPrimaryVariables,WeightedbytheATT WeightfromtheFinalEstimationoftheTreatmentAssignmentModel 250 7.7 MeansandStandardDeviationsofPrimaryVariables,WeightedbytheATC WeightfromtheFinalEstimationoftheTreatmentAssignmentModel 251 7.8 CatholicSchoolCoefficientsfromATT-WeightedandATC-Weighted RegressionModelsPredictingTenthGradeMathTestScores,TwelfthGrade MathTestScores,andMathTestGains 253 7.9 CatholicSchoolCoefficientsfromWeightedRegressionModelsRestrictedto theRegionofOverlapintheEstimatedPropensityScores 254 7.10 CatholicSchoolCoefficientsfromDoublyRobustWeightedRegression Models 255 7.11 CatholicSchoolCoefficientsfromWeightedRegressionModels,Including AdditionalCovariates 257 8.1 SimulatedResultsfortheIdentificationApproachAdoptedbyColemanand Colleagues 276 9.1 TheDistributionofVoucherWinnersbySchoolSectorfor IVDemonstration1 295 9.2 TheJointProbabilityDistributionandConditionalExpectationsoftheTest ScoreforVoucherWinnerbySchoolSectorforIVDemonstrations1and2 310 9.3 TheDistributionofNeverTakers,Compliers,andAlwaysTakersforIV Demonstration2 311 11.1 ChangeScoreandAnalysisofCovarianceEstimatesoftheCatholicSchool EffectintheTenthGrade 370 11.2 EstimatedAverageTreatmentEffectsforDifferentCombinationsofCorrect andAssumedAdjustmentFactors,WheretheTrueEffectIsEqualto1 379 11.3 AlternativeTrajectoriesoftheOutcomeUndertheControlStateforDifferent AssumptionsAboutItsDynamicStructure 381 11.4 SpecificationTestsfromtheAnalysisofHeckmanandHotz(1989)oftheEffect oftheNationalSupportedWorkProgramontheEarningsofHighSchool Dropouts 391 11.5 ExpectedValuesfortheEndogenousVariablesintheDirectedGraphin Figure11.10 399 11.6 IdentificationStatusoftheTotalCausalEffectsinFigure11.10 400 11.7 Pseudo-PopulationProportionsfortheDirectedGraphinFigure11.12 414 12.1 AHypotheticalExampleoftheCalculationofBoundsfortheATE 423 ## AcknowledgmentsforFirstEdition\nWithoutyetknowingit,webegantowritethisbookin1997whencollaboratingonapaper\nforthe1999volumeoftheAnnualReviewofSociology,titled“TheEstimationofCausalEffects fromObservationalData.” Webenefitedfrommanyhelpfulcommentsinthepreparationof thatmanuscript,andwewerepleasedthatmanyofourcolleaguesfoundittobeausefulintro- ductiontoaliteraturethatwewere,atthetime,stillworkingtounderstandourselves. Since then,considerableprogressinthepotentialoutcomesandcounterfactualmodelingliterature hasbeenachieved,whichledusintolongdiscussionsoftheutilityofwritingamorecompre- hensiveintroduction. Intheend,ourmotivationtolearnevenmoreoftheliteraturewasthe decisivefactor.\nWe thank Richard Berk, Felix Elwert, George Farkas, Glenn Firebaugh, Jeremy Freese, Andrew Gelman, Gary King, Trond Petersen, David Weakliem, and Kim Weeden for read- ingsomeorallofthepenultimatedraftofthebook. Wealsothanktheanonymousreviewer recruited by Cambridge University Press. The insightful comments of all of these readers helped tremendously. We also thank our students at Cornell and Harvard, from whom we havelearnedmuchinthecourseoflearningandthenpresentingthismaterialtothem. Their commentsandquestionsweremorevaluablethantheyareprobablyaware.\nFinally, we thank Kelly Andronicos and Jenny Todd at Cornell University for assistance with the preparation of the manuscript, as well as Larry Wu and Ed Parsons at Cambridge UniversityPress,ProjectManagerPeterKatsirubasatAptara,Inc.,andVictoriaDanahyatIn OtherWords.\nxxi ## AcknowledgmentsforSecondEdition\nWethankallofthestudentsinourclassesatCornellandatHarvard,aswellasthosewhohave\nattendedpresentationsofthenewmaterial inthissecondeditionatotheruniversities. Your excellentquestionsovertheyearshaveshapedthisbookmorethanyoumayrealize.\nFortheirgenerosityandwillingnesstoreadandcommentonsubstantialportionsofthis secondedition,wethankWeihuaAn,NealBeck,RichardBerk,DavidBills,KenBollen(and hisstudents),AndyCherlin,TomDiPrete,FelixElwert,MarkusGangl,GuangleiHong,Mike Hout,TimLiao,ScottLynch,IsaacReed,MattSalganik,JasjeetSekhon,PeterSteiner,Jessica Su,SteveVaisey,TylerVanderWeele,DavidWeakliem,andHuiZheng. Inaddition,wethank JohnCawleyandDanLichterforpointing ustorelevantliteratureinhealtheconomicsand demography.\nWealsothankCornellUniversityandHarvardUniversityforthesabbaticalsupportthat allowedustobeginthewritingofthissecondedition. MorganthanksCollegioCarloAlberto forprovidingarestfulandstimulatingenvironmentforworkfromJanuarythroughJune2013.\nxxiii # Part I: Causality and Empirical Research in the Social Sciences",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#causal-analysis-and-observational-social-science",
    "href": "extracted/Counterfactuals and Causal Inference.html#causal-analysis-and-observational-social-science",
    "title": "Counterfaturals and Causal Inference",
    "section": "1.2 Causal Analysis and Observational Social Science",
    "text": "1.2 Causal Analysis and Observational Social Science\nThechallengesofusingobservationaldatatojustify causalclaimsareconsiderable.In\nthissection,wepresentaselectivehistoryoftheliteratureonthesechallenges,focusing on the varied usage of experimental language in observational social science. We will also consider the growth of survey research and the shift toward outcome-equation- based motivations of causal analysis that led to the widespread usage of regression estimators.Many useful discussions of these developments exist, andour presentation here is not meant to be complete.4 We review only the literature that is relevant for explaining the connections between the counterfactual approach and other traditions of quantitatively oriented analysis that are of interest to us here.\n1.2.1 Experimental Language in Observational Social Science Althoughthecommondefinitionofthewordexperimentisbroad,inthesocialsciences itismostcloselyassociatedwithrandomizedexperimentaldesigns,suchasthedouble- blind clinical trials that have revolutionized the biomedical sciences and the routine small-scale experiments that psychology professors perform on their own students.5 philosophy on counterfactuals and causation, see Collins, Hall, and Paul (2004). For a penetrating examination of thecounterfactual model inphilosophyand itsrivals,seePaul andHall (2013). The counterfactual model that weconsider inthis book isclose to what Paul and Hall label the “causal model”approachtocausation, whichtheyconsideroneoffourvariantsofcounterfactual modeling.\n4Togainamorecompleteappreciationoftheexpansiveliteratureoncausalityinthesocialsciences, see, for sociology, Barringer, Leahey, and Eliason (2013), Berk (1988, 2004, 2008), Blossfeld (2009), Bollen (1989), Bollen and Pearl (2013), Firebaugh (2008), Fox (2008), Gangl (2010), Goldthorpe (2007), Harding and Seefeldt (2013), Lieberson (1985), Marini and Singer (1988), Morgan (2013), Rohwer (2010), Singer and Marini (1987), Smith (1990, 2003, 2013), Sobel (1995, 1996, 2000), and Treiman (2009). For economics, see Angrist and Krueger (1999), Angrist and Pischke (2009, 2010), Heckman(2000,2005,2008b,2010),ImbensandWooldridge(2009),Keane(2010),Lee(2005),Manski (1994, 1995, 2003), Moffitt (2003), Pratt and Schlaifer (1984), and Rosenzweig and Wolpin (2000).\nForpoliticalscience,seeBradyandCollier(2010),Druckman,Kuklinski,andLupia(2011),Dunning (2012), GerberandGreen(2012), Gerring(2007), GoertzandMahoney(2012), King,Keohane, and Verba (1994), Morton and Williams (2010), and Sekhon (2009). For applied evaluation and policy analysis,seeShadish,Cook,andCampbell(2001),andespeciallyforeducationresearch,seeMurnane andWillett(2011) 5The Oxford English Dictionary provides the scientific definition of experiment: “An action or operation undertaken in order to discover something unknown, to test a hypothesis, or establish or illustratesomeknowntruth”andalsoprovidessourcereferencesfromasearlyas1362.\nRandomizedexperimentshavetheiroriginsintheworkofstatisticianRonaldA.Fisher duringthe1920s,whichthendiffusedthroughoutvariousresearchcommunitiesviahis widely read 1935 book, The Design of Experiments.\nStatisticians David Cox and Nancy Reid (2000) offer a definition of an experi- ment that focuses on the investigator’s deliberate control and that allows for a clear juxtaposition with an observational study: The wordexperiment isusedina quiteprecisesenseto meananinvestiga- tionwherethe systemunderstudy is underthe controlofthe investigator.\nThis means that the individuals or material investigated, the nature of the treatments or manipulations under study and the measurement pro- cedures used are all selected, in their important features at least, by the investigator.\nBy contrast in an observational study some of these features, and in particular the allocation of individuals to treatment groups, are outside the investigator’s control. (Cox and Reid 2000:1) We will maintain this basic distinction throughout this book. We will argue in this sectionthatthepotentialoutcomemodelofcausalitythatweintroducedinthelastsec- tionisvaluablepreciselybecauseithelpsresearcherstostipulateassumptions,evaluate alternative data analysis techniques, and think carefully about the process of causal exposure. Its success is a direct result of the language of potential outcomes, which permitstheanalysttoconceptualizeobservationalstudiesasiftheywereexperimental designs controlledby someone other than the researcher– quite often, the subjects of the research. In this section, we offer a brief discussion of other important attempts to use experimental language in observational social science and that succeeded to varying degrees.\nSamuel A. Stouffer, the sociologist and pioneering public opinion survey analyst, argued that “the progress of social science depends on the development of limited theories – of considerable but still limited generality – from which prediction can be made to new concrete instances” (Stouffer 1962[1948]:5). Stouffer argued that, when testing alternative ideas, “it is essential that we always keep in mind the model of a controlledexperiment,evenifinpracticewemayhavetodeviatefromanidealmodel” (Stouffer1950:356).Hefollowedthispracticeoverhiscareer,fromhis1930dissertation thatcomparedexperimentalwithcasestudymethodsofinvestigatingattitudes,tohis leadershipofthe teamthatproducedThe American Soldier duringWorldWarII (see Stouffer 1949), and in his 1955 classic Communism, Conformity, and Civil Liberties.\nOn his death, and in celebration of a posthumous collection of his essays, Stouffer was praised for his career of survey research and attendant explanatory success. The demographerPhilipHausernotedthatStouffer“hadahandinmajordevelopmentsin virtuallyeveryaspectofthe samplesurvey–samplingprocedures,problemdefinition, questionnaire design, field and operating procedures, and analytic methods” (Hauser 1962:333).ArnoldRose(1962:720)declared,“Probablynosociologistwassoingenious in manipulating data statistically to determine whether one hypothesis or another could be considered as verified.” And Herbert Hyman portrayed Stouffer’s method of tabular analysis in charming detail: While the vitality with which he attacked a table had to be observed in action, the characteristic strategy he employed was so calculating that one can sense it from reading the many printed examples….Multivariate analysis for him was almost a way of life. Starting with a simple cross- tabulation, the relationship observed was elaborated by the introduction of a third variable or test factor, leading to a clarification of the original relationship….But there was a special flavor to the way Sam handled it.\nWithhim,theloveofatablewasundying.Threevariablesweren’tenough.\nFour,five,six,evensevenvariableswereintroduced,untilthatsimplething of beauty, that original little table, became one of those monstrous crea- tures at the first sight of which a timid student would fall out of love with our profession forever. (Hyman 1962:324–25) Stouffer’s method was to conceive of the experiment that he wished he could have conducted and then to work backwards by stratifying a sample of the population of interest into subgroups until he felt comfortable that the remaining differences in the outcome could no longer be easily attributed to systematic differences within the subgroups. He never lost sight of the population of interest, and he appears to have always regarded his straightforwardconclusions as the best among plausible answers.\nThus,ashesaid,“Thoughwecannotalwaysdesignneatexperimentswhenwewantto, wecanatleastkeeptheexperimentalmodelinfrontofoureyesandbehavecautiously” (Stouffer 1950:359).\nNot all attempts to incorporate experimental language into observational social science were as well received. Most notably in sociology,F. Stuart Chapin had earlier arguedexplicitly for an experimental orientationto nearly all of sociologicalresearch, but while turning the definition of an experiment in a direction that agitated others.\nForChapin,avalidexperimentdidnotrequirethatthe researcherobtaincontrolover the treatmentto be evaluated,only that observationof a causalprocess be conducted in controlled conditions (see Chapin 1932, 1947). He thus considered what he called “expostfactoexperiments”tobe thesolutiontotheinferentialproblemsofthesocial sciences, and he advocated matching designs to select subsets of seemingly equivalent individuals from those who were and were not exposed to the treatment of interest.\nInsodoing,however,he proposedtoignorethe incomparable,unmatchedindividuals, thereby losing sight of the population that Stouffer, the survey analyst, always kept in the foreground.\nChapin thereby ran afoul of emergent techniques of statistical inference, and he sufferedattacks fromhis naturalallies in quantitative analysis.The statisticianOscar Kempthorne, whose 1952 book The Design and Analysis of Experiments would later become a classic, dismissed Chapin’s work completely. In a review of Chapin’s 1947 book, Experimental Designs in Sociological Research, Kempthorne wrote: The usage of the word “experimental design” is well established by now to mean a plan for performing a comparative experiment. This implies that various treatments are actually applied by the investigator and are notjusttreatmentsthathappenedtohavebeenappliedtoparticularunits forsomereason,knownorunknown,beforethe“experiment”wasplanned.\nThisconditionrulesoutpracticallyalloftheexperimentsandexperimental designs discussed by the author. (Kempthorne 1948:491) Chapin’scolleaguesinsociologyanddemographywereoftenjustasunforgiving.Nathan Keyfitz(1948:260),forexample,chastisedChapinforignoringthepopulationofinter- estandaccusedhim ofusingterms suchas“experimentaldesign”merelyto “lendthe support of their prestige.” In spite of the backlashagainstChapin, in the end he has a recognizable legacy in observationaldataanalysis.Thematchingtechniquesheadvocatedwillbediscussedin Chapter5.Theyhavebeenreborninthenewliterature,inpartbecausethepopulation of interest has been brought back to the foreground.But there is an even more direct legacy. Many of Chapin’s so-called experiments were soon taken up, elaborated, and analyzedby the psychologistDonaldT. Campbell andhiscolleaguesunder the milder and more general name of “quasi-experiments.”6 The first widely read presentation of Campbell’s perspective emerged in 1963 (see Campbell and Stanley 1966[1963]), in which quasi-experiments were discussed along- side randomized and fully controlled experimental trials, with an evaluation of their relative strengths and weaknesses in alternative settings. In the subsequent decade, Campbell’s work with his colleagues moved closer toward observational research, cul- minatinginthevolumebyCookandCampbell(1979),Quasi-Experimentation:Design & Analysis Issues for Field Settings, wherein a whole menu of quasi-experiments was described and analyzed: from the sort of ex post case-control matching studies advo- catedbyChapin(butrelabeledmoregenerallyasnonequivalentgroupdesigns)tonovel proposals for regression discontinuity and interrupted time series designs (which we will discussinChapter11). For CookandCampbell, the termquasi-experimentrefers to “experiments that have treatments, outcome measures, and experimental units, but do not use random assignment to create the comparisons from which treatment- caused change is inferred” (Cook and Campbell 1979:6).7 And, rather than advocate for a reorientation of a whole discipline as Chapin had, they pitched the approach as a guide for field studies, especially program evaluation studies of controlled interven- tions. Nonetheless, the ideas were widely influential throughoutthe social sciences, as they succeededin bringinga tamedexperimental languageto the foregroundina way thatpermittedbroadassessmentsofthestrengthsandweaknessesofalternativestudy designs and data analysis techniques.\n1.2.2 “The Age of Regression” Even though the quasi-experiment tradition swept through the program evaluation community and gained many readers elsewhere, it lost out in the core social science disciplines to regression-equation-based motivations of observational data analysis, 6In his first publication on quasi-experiments, Campbell (1957) aligned himself with Stouffer’s perspective on the utility of experimental language, and in particular Stouffer (1950). Chapin is treated roughly by Campbell and Stanley (1966[1963]:70), even though his ex post facto design is identifiedas“oneofthemostextended effortstowardquasi-experimentaldesign.” 7NoticethatCookandCampbell’sdefinitionofquasi-experimentshereis,infact,consistentwith the definition of an experiment laid out by Cox and Reid, which we cited earlier in this section.\nForthat definitionofanexperiment, controlisessentialbutrandomizationisnot. ThetextofCook and Campbell (1979) equivocates somewhat on these issues, but it is clear that their intent was to discuss controlled experiments for which randomization is infeasible and which they then label quasi-experiments.\nunder the influence at first of researchers who promoted regression modeling from a path-modeling orientation. In sociology, Hubert Blalock and Otis Dudley Duncan are usually credited with introducing the techniques, first via Blalock’s 1964[1961] book Causal Inferences in Nonexperimental Research and then later via Duncan’s 1966article, “PathAnalysis:SociologicalExamples,”whichwaspublished asthe lead article in that year’s American Journal of Sociology.8 In both presentations, caution was stressed. Blalock discussed carefully the differences between randomized experi- mentsandobservationalsurveyresearch.Duncanstatedexplicitlyinhisabstractthat “path analysis focuses on the problem of interpretation and does not purport to be a method for discovering causes,” and he concluded his article with a long quotation from Sewall Wright attesting to the same point.\nA confluence of developments then pushed path models toward widespread usage and then basic regressionmodeling toward near complete dominance of observational research in some areas of social science.9 In sociology, the most important impetus was the immediate substantive payoff to the techniques. The American Occupational Structure, which Duncan cowrote with Peter Blau and published in 1967, offered new decompositions of the putative causal effects of parental background and individuals’ own characteristics on later educational and occupational attainment. By pushing socialstratificationresearchintonewterrain,theirbooktransformedacoresubfieldof thedisciplineofsociology,leadingtomajortheoreticalandmethodologicalredirections of many existing lines of scholarship.10 Researchers seemed to then ignore many of the cautionary statements of Blalock, Duncan, and others. In their defense, it should be noted that Blalock’s guidance was confusing at times. When introducing regressionequations in his 1961 book, specified as Yi=a+bXi+ei, where X is the causal variable of interest and Y is the outcome variable of interest, Blalock stated the matter correctly and clearly: What if there existed a major determinant of Y, not explicitly contained in the regression equation, which was in fact correlated with some of the 8Goldberger(1972)andHeckman(2000)offerahistoryofusageineconomics,whichbeginsbefore the history we offer for sociology. The biologist Sewall Wright (1925, 1934) deserves credit for the earliestdevelopments (seeBollenandPearl2013;Pearl2009).\n9Regression estimation of systems of linear causal models with observed variables should be regardedasarestrictedformofthemoregeneralstructuralequationmodelingapproachthatBlalock, Duncan,andothersintroducedintosociology(seeBollenandPearl2013foranexplanation,especially their debunking of the myth“SEM andRegressionAreEssentiallyEquivalent”). In these earlyand veryinfluentialpieces,BlalockandDuncanconsideredonlylinearcausalmodelswithobservedvari- ables. Duncan(1966:7) clarified:“Asastatistical technique, therefore, neither pathanalysis northe Blalock-Simonprocedureadds anything toconventional regressionanalysis asappliedrecursivelyto generateasystemofequations.Asapatternofinterpretation,however,pathanalysisisinvaluablein makingexplicittherationaleforasetofregressioncalculations.”Theliteraturemovedquicklyfrom the late 1960s to consider overidentified models (see Duncan, Haller, and Portes 1968; Hauser and Goldberger1971),afterwhichagenerallatentvariablestructuralequationmodelwasdeveloped(see Bollen 1989). Nonetheless, the pattern of practice that elevated regressionto its dominant position, we maintain, was shaped by these early pieces, as well as later work on interpreting the regression coefficients estimated for basic linear path models with observed variables (e.g., Alwin and Hauser 1975).\n10Forexample,comparethemethods(andsubstantivemotivations)inSewell(1964),withitsnon- parametrictablestandardizationtechniques,toSewell,Haller,andPortes(1969),withitspathmodel oftheentirestratificationprocess.\nindependent variables Xi? Clearly, it would be contributing to the error term in a manner so as to make the errors systematically related to these particular Xi. If we were in a position to bring this unknown variable into the regressionequation, we would find that at least some of the regression coefficients (slopes) would be changed. This is obviously an unsatisfactory state of affairs, making it nearly impossible to state accurate scientific generalizations. (Blalock 1964[1961]:47) At other points in his book, however, Blalock characterized the same issue in ways that encouragedmore permissive practice. He wrote at several points that the goal of causal inference should not be too easily sacrificed: Sinceitwillalwaysbepossiblethatsomeunknownforcesmaybeoperating todisturbagivencausalrelationship,ortoleadustobelieveacausalrela- tionship exists when in fact it does not, the only way we can make causal inferences at all is to make simplifying assumptions about such disturbing influences. (Blalock 1964[1961]:13) We shall assume that error terms are uncorrelated with each other and with any of the independent variables in a given equation….In non- experimental studies involving nonisolated systems, this kind of assump- tion is likely to be unrealistic. This means that disturbing influences must be explicitly brought into the model. But at some point one must stop and make the simplifying assumption that variables left out do not pro- duceconfoundinginfluences.Otherwise,causalinferencescannotbe made.\n(Blalock 1964[1961]:176) And,eventhoughBlalockwasclearthatregressioncoefficientsareestimatedquantities (and more fundamentally that the causal models that give regression equations their specifications are subject to simplifying assumptions that may be unrealistic), he still wrote about the resulting coefficients and equations in ways that would surely have excited readers interested in powerful new ways to gain insight from observational data: It is the regression coefficients which give us the laws of science. (Blalock 1964[1961]:51) In causal analyses our aim is to focus on causal laws as represented by regressionequations and their coefficients. (Blalock 1964[1961]:177)11 Finally, in the concluding section of his book, he suggested, The method for making causal inferences may be applied to models based on a priori reasoning,or it may be used in exploratoryfashion to arriveat models which give closer and closer approximations to the data. (Blalock 1964[1961]:179) 11Whenusingthislanguageofcausallaws,Blalockwasarguingforthecomparativevalueofmetric regression coefficients, in contrast to standardized regression coefficients, and probably using this causallawlanguagewithimplicitreferencetothecoveringlawmodelofexplanationthatwasdominant inphilosophyofscienceatthetime.Hewasnotclaimingthatregressionisamethodforthediscovery of causal laws. We maintain, nonetheless, that this sort of language had the potential to mislead readers.\nGiven this type of guidance, it is not hard to imagine practitioners offering up exploration-enhanced causal models, enabled by unrealistic simplifying assumptions, and then writing about their regression coefficients as if causal laws had been uncov- ered.\nDuncan never failed to mention that assumptions about causal relationships must begroundedintheoryandcannotberevealedbydata.Yet,asAbbott(2001[1998]:115) notes, “Duncan was explicit in [The American Occupational Structure] … about the extreme assumptions necessary for the analysis, but repeatedly urged the reader to bear with him while he tried something out to see what could be learned.” What Duncan learned transformed the field, and it was thus hard to ignore the potential power of the techniques to move the literature.\nDuncan’s 1975 methodological text, Introduction to Structural Equation Models, is appropriately restrained, with many fine discussions that echo the caution in the abstract of his 1966 article. Yet he also encouraged widespread application of regres- sion techniques to estimate causal effects, and at times he gave the impression that researchersshould just get onwith it, as he did in The American Occupational Struc- ture. For example, in his chapter 8, titled “Specification Error,” Duncan noted that “it would require no elaborate sophistry to show that we will never have the ‘right’ model in any absolute sense” (Duncan 1975:101). But he then continued: As the term will be used here, analysis of specification error relates to a rhetoricalstrategy in which we suggest a model as the “true” one for sake of argument, determine how our working model [the model that has been estimated] differs from it and what the consequences of the difference(s) are, and thereby get some sense of how important the mistakes we will inevitablymakemaybe.Sometimesitispossibletosecuregenuinecomfort by this route. (Duncan 1975:101–2) Asiswidelyknown,Duncanlatercriticizedthewidespreadusageofregressionanalysis, both in his 1984 book Notes on Social Measurement: Historical and Critical and in private communication,in which he reminded many inside and outside of sociologyof his long-standing cautionary perspective (see Xie 2007).\nFinally, the emergent ease with which regression models could be estimated with newcomputingpowerwasimportantaswell.NolongerwouldStoufferhaveneededto concentrate on a seven-way cross-tabulation. Researchers could instead estimate and then interpret only a few estimated regression slopes, rather than attempt to make sense of the hundred or so cells that Stouffer often generated by subdivision of the sample.Aage Sørensenhas giventhe most memorableindictment of the consequences of this revolution in computing power: With the adventof the high-speed computer,we certainly could study the relationships among many more variables than before. More importantly, we could compute precise quantitative measures of the strength of these relationships. The revolution in quantitative sociology was a revolution in statistical productivity. Social scientists could now calculate almost every- thing with little manual labor and in very short periods of time. Unfor- tunately, the sociological workers involved in this revolution lost control of their ability to see the relationship between theory and evidence. Soci- ologists became alienated from their sociological species being. (Sørensen 1998:241) As this quotation intimates, enthusiasm for regression approaches to causal inference had declined dramatically by the mid-1990s. Naive usage of regression modeling was blamed for nearly all the ills of sociology, everything from stripping temporality and context from the mainstream (see Abbott 2001 for a collections of essays), the sup- pression of attention to explanatory mechanisms (see Goldthorpe 2001 and Hedstrm 2005), the denial of causal complexity (see Ragin 1987, 2008), and the destruction of mathematical sociology (Sørensen 1998).\nIt is unfair to lay so much at the feet of least squares formulas, and we will argue laterthatregressioncanbeputtoworkquitesensiblyinthepursuitofcausalquestions.\nHowever, the critique of regression-based practice was largely on target. For causal analysis, the rise of regression led to a focus on estimated equations for outcomes, rather than careful thinking about how the data in hand differ from what would have been generated by the ideal experiments one might wish to have conducted.\nThis sacrifice of attention to experimental thinking might have been reasonable if the outcome-equationtraditionhadledresearcherstospecifyandthencarefullyinvestigate the plausibility of alternative explanatory mechanisms that generate the outcomes of theequations.But,instead,itseemsthatresearchersalltoooftenchosenottodevelop fully articulated mechanisms that generate outcomes and chose to simply act as if estimated regression equations somehow mimic appreciably well (by a process not amenable to much analysis) the experiments that researchers might otherwise have wished to undertake.\nLargely independent of these critiques, the potential outcome model for observa- tionaldata analysishas achievedsuccessinthe pasttwodecades inthe socialsciences because it brings experimental language back into observational data analysis. But it does soin the waythat Stouffer used it: asa frameworkin whichto ask carefully con- structed what-if questions that lay bare the limitations of observational data and the need to clearly articulate assumptions that are believable because they are grounded in theory that is defendable.\nConsider the motivating questions in the opening paragraph of this book, which weposedto drawinreaderswho arenotyetutilizing the counterfactualmodel.These questions are stated in the traditional style of Does X cause Y? If X causes Y, how large is the effect of X on Y? Thecounterfactualmodelencouragesthe formulationofmoreprecisecausalquestions with clear counterfactual contrasts, such as If individuals with X=x(cid:2) had instead had X=x(cid:2)(cid:2), how much would their value for Y have changed? Forexample,ratherthanaskthequestion“Doesobtainingacollegedegreeincreasean individual’slabormarketearnings?,”the counterfactualmodelencouragesresearchers to ask two questions: 1.Ifhighschoolgraduateshadinsteadobtainedcollegedegrees,howmuch would their labor market earnings have changed? 2. If college graduates had only obtained high school diplomas, how much would their labor market earnings have changed? For these two particular questions, the empirical literature suggests that the answers differ in magnitude, suggesting that important heterogeneity exists in the individual- level causal effects that underlie them. Such differences are of theoretical interest to researchers and of practical value to policymakers, and they are obscured by gen- eral cause-and-effect questions without clear and specific counterfactual states. This book is grounded on the position that social scientists ought to use a conceptual and methodological framework that encourages the asking and answering of rigorously posed questions such as these.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#examples-used-throughout-the-book",
    "href": "extracted/Counterfactuals and Causal Inference.html#examples-used-throughout-the-book",
    "title": "Counterfaturals and Causal Inference",
    "section": "1.3 Examples Used Throughout the Book",
    "text": "1.3 Examples Used Throughout the Book\nIn this section, we offer background on the main substantive examples that we will\ndraw on throughout the book when discussing the methods and approach abstractly andthenwhendemonstratingparticularempiricalanalysisstrategies.Wefirstpresent five broad foundational examples that have guided empirical research in the social, demographic,andhealthsciencesfordecades.Wethenpresenteightnarrowerexamples that are at the frontier of current research, all of which can be addressed using the counterfactual model.\n1.3.1 Broad Examples from the Social, Demographic, and Health Sciences We first outline three prominent classic examples that, in spite of their distinct disci- plinaryorigins,arerelatedtoeachother:(1)thecausaleffectsoffamilybackgroundand mental ability on educational attainment, (2) the causal effects of educational attain- ment and mental ability on earnings, and (3) the causal effects of family background, educational attainment, and earnings on political participation. These examples are classic and wide-ranging, having been developed, respectively, in the formative years of observational data analysis in sociology, economics, and political science. We then presenttwobroadexamplesfromtheinterdisciplinarysocial,demographic,andhealth sciences: (4) the causal effects of family backgroundand life course events on fertility patterns and (5) the causal effects of socioeconomic status on health and mortality.\nThe Causal Effects of Family Background and Intelligence on Educational Attainment In the status attainment tradition in sociology, as pioneered by Blau and Duncan (1967), family background and mental ability are considered to be ultimate causes of educationalattainment.Thisclaimisgroundedonthepurportedexistenceofaspecific causalmechanismthat relates individuals’expectations and aspirationsfor the future to the social contexts that generate them. This particular explanation is most often identified with the Wisconsin model of status attainment, which was based on early analyses of the Wisconsin Longitudinal Survey (see Sewell, Haller, and Portes 1969; Sewell, Haller, and Ohlendorf 1970).\nAccording to the original Wisconsin model, the joint effects of high school stu- dents’ family backgrounds and mental abilities on their eventual educational attain- ments can be completely explained by the expectations that others hold of them. In particular,significantothers–parents,teachers,andpeers–defineexpectationsbased on students’ family backgroundand observable academic performance. Students then internalize the expectations crafted by their significant others. In the process, the expectations become individuals’ own aspirations, which then compel achievement motivation.\nThe implicit theory of the Wisconsin model maintains that students are com- pelled to follow their own aspirations. Accordingly, the model is powerfully simple, as it implies that significant others can increase high school students’ future educa- tional attainments merely by increasing their own expectations of them.12 Critics of thisstatusattainmentperspectivearguedthatstructuralconstraintsembeddedinthe opportunity structure of society should be at the center of all models of educational attainment, and hence that concepts such as aspirations and expectations offer little or no explanatory power. Pierre Bourdieu (1973) dismissed all work that asserts that associations between aspirations and attainments are causal. Rather, for Bourdieu, the unequal opportunity structures of society “determine aspirations by determining the extent to which they can be satisfied” (Bourdieu 1973:83). And, as such, aspi- rations have no autonomous explanatory power because they are nothing other than alternative indicators of structural opportunities and resulting attainment.\nResearch on the relationships between family background and educational attain- ment is now vast, especially in economics and sociology (see Ehrenberg 2004; Morgan 2005; Stevens, Armstrong, and Arum 2008). Scholars disagree on the effects of the resource constraints imposed by disadvantaged family backgrounds, the role of indi- vidual choices in response to incentives, the importance of beliefs about the oppor- tunity structure, and features of the institutions that must be navigated (see Breen and Johnson 2005; Heckman 2008a; Holmlund, Lindahl, and Plug 2011; Hoxby 2004; Jackson2013; Morgan, Leenman, Todd, and Weeden 2013).\nThe Causal Effects of Educational Attainment and Mental Ability on Earnings The economic theory of human capital maintains that education has a causal effect on the subsequent labor market earnings of individuals. The theory presupposes that educationaltrainingprovidesskillsthatincreasethepotentialproductivityofworkers.\nBecause productivity is prized in the labor market, firms are willing to pay educated workers more.\nTheseclaimsarelargelyacceptedwithineconomics,butconsiderabledebateremains over the size of the causal effect of education. In reflecting on the first edition of his 12See Hauser, Warren, Huang, and Carter (2000) for the latest update of the original model and Sewell,Hauser,Warren,andHauser(2004) forareviewoftheentireresearchtradition.\nbookHuman Capital, whichwaspublishedin1964,GaryBeckerwrotenearly30years later: Educationandtrainingarethemostimportantinvestmentsinhumancap- ital.Mybookshowed,andsohavemanyotherstudiessincethen,thathigh school and college education in the United States greatly raise a person’s income, even after netting out direct and indirect costs of schooling, and after adjusting for the better family backgrounds and greater abilities of moreeducatedpeople.Similarevidenceisnowavailableformanypointsin timefromoveronehundredcountrieswithdifferentculturesandeconomic systems. (Becker 1993[1964]:17) The complication, hinted at in this quotation, is that economists also accept that mental ability enhances productivity. Thus, because those with relatively high ability areassumedtobemorelikelytoobtainhighereducationaldegrees,thehighlyeducated are presumed to have higher innate ability and higher natural rates of productivity.\nAs a result, some portion of the purported causal effect of education on earnings may instead reflect innate ability rather than any productivity-enhancing skills provided by educational institutions (see Willis and Rosen 1979).\nThe degreeof “ability bias” in standardestimates of the causal effect of education on earnings has remained one of the largest causal controversiesin the social sciences since the 1970s (see Card 1999). Scholars continue to disagree on the magnitude of biases in traditional estimates, and debate has also developed on the variability of returns that may be related to underlying cognitive ability and other individual char- acteristics (see Cunha and Heckman 2007; Brand and Xie 2010; Carneiro, Heckman, and Vytlacil 2011; Hout 2012).\nThe Causal Effects of Family Background, Educational Attainment, and Earnings on Political Participation Thesocioeconomicstatusmodelofpoliticalparticipationassertsthateducation,occu- pational attainment, and income predict strongly most measures of political partici- pation (see Verba and Nie 1972). Critics of this model maintain instead that political interests and engagement determine political participation, and these are merely cor- relatedwiththemaindimensionsofsocioeconomicstatus.13 Inotherwords,thosewho have a predilection to participate in politics are likely to show commitment to other institutions, such as the educational system.\nVerba, Schlozman, and Brady (1995) later elaborated the socioeconomic status model, focusing on the contingent causal processes that they argue generate patterns ofparticipationthroughtheresourcesconferredbysocioeconomicposition.Theyclaim that interest, information, efficacy, and partisan intensity provide the desire, knowledge, and self-assurance that impel people to be engaged by poli- tics. But time, money, and skills provide the wherewithal without which 13Thisinterestmodelofparticipationhasanequallylonglineage.Lazarsfeld,Berelson,andGaudet (1955[1948]:157) write that, in their local sample, “the difference in deliberate non-voting between peoplewithmoreorlesseducation canbecompletelyaccounted forbythenotionofinterest.” engagementismeaningless.Itisnotsufficienttoknowandcareaboutpoli- tics.Ifwisheswereresources,thenbeggarswouldparticipate.(Verbaetal.\n1995:355–56) They reachthis conclusionthrough a series of regressionmodels that predict political participation. They use temporal order to specify causal order, and they then claim to eliminate alternativetheories that emphasize political interests andengagementby showing that these variables have relatively weak predictive power in their models.\nMoreover, they identify education as the single strongest cause of political par- ticipation. Beyond generating the crucial resources of time, money, and civic skills, educationshapes preadultexperiences andtransmits differences infamily background (see Verba et al. 1995, figure 15.1). Education emerges as the most powerful cause of engagement because it has the largest net association with measures of political participation.\nNie, Junn, and Stehlik-Barry (1996) then built on the models of Verba and his colleagues, specifying in detail the causal pathways linking education to political par- ticipation. For this work, the effects of education, family income, and occupational prominence (again, the three basic dimensions of socioeconomic status) on voting frequency are mediated by verbal proficiency, organizational membership, and social network centrality.Nie et al. (1996:76)note that these variables “almostfully explain the original bivariate relationship between education and frequency of voting.” Currentresearchcontinuestoinvestigatetheserelationships,especiallytheeffectof educationon participation.Some studies havefocused attention on relativeeducation (e.g., Tenn 2005), while others have questioned whether the effect is genuine at all (Berinsky and Lenz 2011; Highton 2009; Kam and Palmer 2008, 2011). As often hap- pens in causal controversies, the latter research prompted additional effort to restore theoriginalclaim(HendersonandChatfield2011;Mayer2011;SondheimerandGreen 2010).14 The Causal Effects of Family Background and Life Course Events on Fertility Patterns Through the analysis of population trends in the nineteenth and early twentieth cen- turies, demographers developed the concept of a “demographic transition,” during which countries move in comparativelyshort periods of time from population regimes ofhighfertility andhighmortalitytowardthoseoflowfertility andlowmortality(see Davis1945;Thompson1949;Notestein1950).RonaldLeecharacterizestheworldwide march of country-specific transitions as “Three Centuries of Fundamental Change”: Before the start of the demographic transition, life was short, births were many, growth was slow and the population was young. During the transi- tion, first mortality and then fertility declined, causing population growth 14Perhapsthemostwidelyknownrecentpoliticalparticipationstudiesarethosethatdonotfocuson theeffectsofstablebackgroundcharacteristicsofindividuals.Researchon“GetOuttheVote”oper- ations shows, for example, that social pressureissurprisinglyeffective (Gerber, Green, and Larimer 2008;Davenport,Gerber,Greenetal.2010),whileattackadvertisementsbroadcastontelevisionare lesseffectivethanmanyhaveassumed(KrasnoandGreen2008).\nrates first to accelerate and then to slow again, moving toward low fertil- ity,longlifeandanoldpopulation.Thetransitionbeganaround1800with declining mortality in Europe. It has now spread to all parts of the world and is projected to be completed by 2100. (Lee 2003:167) Althoughthesetrendshaveinspiredmanystrandsofliteratureindemography,wewill use as our broad example the interconnected causes that are typically examined for differences in fertility rates, both over time and across groups, focusing mostly on the literature on fertility in the first group of industrializing countries to experience the demographic transition.15 Early studies document differences in fertility rates by immigrant status, geo- graphicregion,urban–rurallocation,andsocialclass(seeDinkel1952;Karpinos1938; Notestein 1933; Rose 1942; Thompson 1948; Whelpton 1932), often using causal lan- guage, for example, “the birth rate for married couples not separating during the migration was higher after they came to the United States than it would have been hadthey remainedinItaly”(Rose1942:621).Mostofthis literatureisconcernedwith how fertility differences varywith family background,typically acrosssocialclassesas measured by the occupations of husbands. Analyzing trends during a time when the eugenics movement had not yet fully receded, Notestein (1933:22)concludes: At present the white collar classes are not reproducing rapidly enough to maintainequalpermanentreplacement,buttheunskilledlaborerclassand the agricultural populationappear to be reproducing more rapidly than is required to maintain their numbers. (Notestein 1933:33) Notesteinoffersempiricalmodelstosupportthepositionthatsomeofthesedifferences can be attributed to the effects of age at marriage, but he also notes the possibility that “in the young marriages of the professional class fertility was purposefully and effectively controlled even prior to 1910” (Notestein 1933:25).\nAlthough this early literature considers the timing of marriage and the possibility of differential patterns of overt birth control, it does not consider the full range of gender-related mechanisms that with hindsight were obviously at play. After correc- tives were offered in subsequent literature, newly available individual-level data have allowed demographers to model the consequences of changing rates of female labor force participation (see Brewster and Rindfuss 2000 for a review), changes in birth controlpractices(WestoffandBumpass1973;GoldinandKatz2002),andsomeofthe deeper contingencies of related life course events, such as how age and marital status at first birth structure later fertility (Bumpass, Rindfuss, and Janosik 1978; see also Morgan and Rindfuss 1999).\nStudiesthatexaminefamilybackgrounddifferencesinfertility,asindexedbysocial class, are less common in current research, having been supplanted by the study of therelationshipbetweeneducationalattainmentandfertility,asconditionedbyfamily 15Although there is considerable debate on the role of causal analysis in demographic research (see Duncan 2008; Engelhardt, Kohler,and Prskawetz 2009; Moffitt2005; N´ıBhrolcha´inandDyson 2007; Smith1989, 2009, 2013; Xie2011), wedonotseedemographyas inherentlydifferentthanthe other domains of observational research considered in this book. However, it may be the case that demography has a special additional burden of documenting social and demographic patterns that donotdependonanyparticularcausal assumptions.\nbackground of origin (see Brand and Davis 2011; Musick, England, Edgington, and Kangas 2009). This more contemporary literature also takes full account of the dis- tinct patterns of marital and nonmarital fertility (see Musick 2002; Musick, England, Edgington, and Kangas 2009; Seltzer, Bachrach, Bianchi et al. 2005; Wu 1996, 2008; Wu and Wolfe 2001).\nThe Causal Effects of Socioeconomic Status on Health and Mortality In reaction to the traditional focus of epidemiology on the proximate direct causes of disease and mortality, a group of social epidemiologists has advanced the case that socioeconomic status should be considered a fundamental cause of health disparities across the life course, generating robust and recurrent associations between socioeco- nomic status and both health and mortality (Link and Phelan 1995; Phelan, Link, Diez-Rouxet al.2004;Phelan,Link, andTehranifar2010).Here,the three traditional dimensionsofsocioeconomicstatus–education,income,andoccupation–areallcon- sideredtobe active(see AdlerandNewman2002).Lutfey andFreesecharacterizethe nature of the posited causal relationship: If an explanatory variable is a fundamental cause of an outcome, then the associationcannot be successfully reduced to a set of more proximate, intervening causes because the association persists even while the relative influence of various proximate mechanisms changes. (Lutfey and Freese 2005:1328) Socioeconomic status is therefore a fundamental cause, according to this perspective, because it is a paramount distal determinant of health that activates alternative and replaceable causal pathways, such as those that arise through differential access to quality health care, knowledge about health innovations, and propensity to engage in risky health behaviors (see Cawley and Ruhm 2012; Fiscella, Franks, Gold, and Clancy 2000; Pampel, Krueger, and Denney 2010). Thus, while health may improve on average for all, socioeconomic disparities may persist, or even grow, because those who are disadvantaged by low education, low income, or lack of employment are less able to take advantage of improvements in health care.\nEachofthese fivebroadexamples,asnotedearlier,isconcernedwithrelationships that unfold over the life course of the majority of individuals in most industrialized societies. As such, these examples encompass some of the most important early sub- stantive scholarship in sociology, economics, and political science as well as the latest frontiers of research at the interdisciplinary nexus of social, demographic, and health science.Atthe sametime, however,theseexamplesposesomefundamentalchallenges forcausalanalysis:measurementcomplicationsandpotentialnonmanipulabilityofthe causes of interest. Each of these deserves some comment before the narrowerand less complicated examples that follow are introduced.\nFirst, the purported causal and outcome variables in these models are sometimes highly abstract and internally differentiated. Consider the political science example.\nPolitical participation takes many forms, from volunteer work to financial giving and voting. Each of these, in turn, is itself heterogeneous, given that individuals can con- tribute episodically and vote in only some elections. Furthermore, family background andsocioeconomicstatusincludeatleastthreeunderlyingdimensions:family income, parental education, and occupational position. But other dimensions of advantage, such as wealth and family structure, must also be considered, as these are thought to be determinantsofbothanindividual’seducationalattainmentandalsothe resources that supposedly enable political participation.16 Scholars who pursue analysis of these causal effects must therefore devote sub- stantial energy to the development of measurement scales. Although very important to consider, in this book we will not discuss measurement issues so that we can focus closelyoncausaleffectestimationstrategies.But,ofcourse,itshouldalwaysberemem- bered that, in the absence of agreement on issues of how to measure causes and their outcomes,fewcausalcontroversiescanberesolved,nomatterwhatestimationstrategy seems best to adopt.\nSecond,mostoftheseexamplesexaminecausaleffectsforindividualcharacteristics that are not easily manipulable through external intervention. Or, more to the point, evenwhentheyaremanipulable,anysuchinducedvariationmaydifferfundamentally fromthe naturallyoccurring(orsociallydetermined)variationwithwhichthe models aremostdirectlyconcerned.Forexample,familybackgroundcouldbemanipulatedby somehow convincing a sample of middle-class and working-class parents to exchange their children at particular well-chosen ages, but the subsequent outcomes of this induced variation may not correspond to the family background differences that the original models attempt to use as explanatory differences.\nAswe will discusslater,whethernonmanipulability ofa causepresentsa challenge to an observationaldata analystis a topic of continuing debate in the methodological andphilosophicalliterature.We will discussthis complicationatseveralpoints inthis book,including a section inthe concluding Chapter 13(see pages439–441), where we arguethatcriticshaveoveremphasizedthis concern.But,giventhatthe measurement andmanipulability concernsofthese broadexamplespresentchallengesatsome level, wealsodrawonmorenarrowexamplesthroughoutthebook,aswediscussinthenext section. For these examples, measurement is generally less controversialand potential manipulability is more plausible (and in some cases is completely straightforward).\n1.3.2 Narrow and Specific Examples In this section, we present additional examples that we will use at multiple points throughoutthebook:thecausaleffectsofneighborhoodofresidenceandfatherabsence on child development, educational performance, and deviance in adolescence; the causal effects of Catholic schooling, school vouchers, and charter schools on learn- ing; the causal effect of worker training on earnings; the causal effects of risky health behaviors and peer relationships on obesity and mortality; and the causal effects of alternative voting technology on valid voting and election outcomes.These additional 16Moreover,education asacauseissomewhatungainlyaswell.Foreconomists whowishtostudy the effects of learned skills on labor market earnings, simple variables measuring years of education obtainedareoversimplifiedrepresentations ofhumancapital.\nexamplesaremorespecific, andoftenmorerecent,versionsofthe fivebroadexamples presented in the last section.\nThe Causal Effects of Neighborhood of Residence on Educational Performance, Deviance, and Youth Development Working within the broad tradition of research on educational attainment and the transitionto adulthood, social scientists have investigatedthe effects of neighborhood of residence since at least the 1980s (see Jencks and Mayer 1990 for a review of the early research). Reflecting on his four decades of research on neighborhoods, William Julius Wilson writes of one such possible effect: [O]ne of the significant arguments in When Work Disappears is that a neighborhood in which people are poor and working is significantly dif- ferent from a neighborhood in which people are poor and jobless. Jobless neighborhoods create special problems, exacerbating conditions that rein- force racial stereotypes and prejudices. High rates of joblessness trigger other problems in the neighborhood ranging from crime, gang violence, and drug trafficking to family breakups and other disruptions in the orga- nization of family life. (Wilson 2011:10) Theeffectsofneighborhoodshaveprovenpersistentlydifficulttoestimate.Individuals make systematic but constrained residential choices, and analysts rarely have suffi- cient information to model their choices effectively. Furthermore, neighborhoods have many characteristics,and individuals living within them can be influenced to varying degrees by circumstances only partly under their own control. For young residents of neighborhoods, these effects may be even more complex: Neighborhoods are not static features of a child’s life; instead, neighbor- hoodschangeovertimeaschildrenmovethroughdifferentperiodsofdevel- opment, providing unique risks and opportunities at each stage. It follows that neighborhoods have the potential to alter developmentaltrajectories, and that their influence may be laggedor cumulative. (Sampson, Sharkey, and Raudenbush 2008:851–52) Researchers have considered the effects of neighborhoods on a range of outcomes for children and adolescents (see Harding, Gennetian, Winship et al. 2011 for a review).\nThe ensuing debates have not been settled by first-rate observational data analysis (e.g., Harding 2003; Sharkey and Elwert 2011; Sampson 2012) or by large-scale social experimentation(seeGennetian,Sanbonmatsu,Katzetal.2012;Kling,Liebman,Katz 2007; Kling, Ludwig, and Katz 2005; Sampson 2008).\nThe Causal Effects of Father Absence on Child and Adolescent Development Bridging work on family background effects with work in family demography, social scientistshaveconsideredtheconsequencesoffamilystructureforchildandadolescent development (see McLanahan 2004, 2009; McLanahan and Percheski 2008; Wu and Wolfe 2001). The most prominent strand of this research began as an effort to assess the effect of growing up as the child of a single parent (McLanahan and Sandefur 1994), during a period when single parenthood was on the rise and the subject of intense political debate.\nRecently,the literature has come to focus more specifically on father absence.In a review of the latest research, McLanahan and her colleagues conclude: We find strong evidence that father absence negatively affects children’s social-emotional development, particularly by increasing externalizing behavior. These effects may be more pronounced if father absence occurs duringearlychildhoodthanmiddle childhood, andthey maybe morepro- nounced for boys than for girls. There is weaker evidence of an effect of father absence on children’s cognitive ability.\nEffects on social-emotional development persist into adolescence, for which we find strong evidence that father absence increases adolescents’ risky behavior, such as smoking or early childbearing. The evidence of an effect on adolescent cognitive ability continues to be weaker, but we do find strong and consistent negative effects of father absence on high school graduation. The latter finding suggests that the effects on educa- tional attainment operate by increasing problem behaviors rather than by impairing cognitive ability. (McLanahan, Tach, and Schneider 2013:422) A rich array of models has been used to generate estimates of these effects, and yet some controversy remains over how substantial these effects are and whether they should instead be attributed to unmeasured environmental characteristics of families, schools, and neighborhoods, including the complexity of events that often co-occur with father absence.\nThe Causal Effect of Catholic Schooling on Learning James S. Coleman and his colleagues presented evidence that Catholic schools are more effective than public schools in teaching mathematics and reading to equivalent high school students (see Coleman and Hoffer 1987; Coleman, Hoffer, and Kilgore 1982; Hoffer, Greeley, and Coleman 1985). Their findings were challenged vigorously by other researchers, who argued that public school students and Catholic school students are insufficiently comparable, even after adjustments for family background and measured motivation to learn (see Alexander and Pallas 1983, 1985; Murnane, Newstead, andOlsen1985;Noell 1982;Willms 1985;see Bryk,Lee,and Holland1993 for a summary of the debate). Although the challenges were wide ranging, the most compellingargumentraised(andthatwasforeseenbyColemanandhiscolleagues)was that students who are most likely to benefit from Catholic schooling are more likely to enroll in Catholic schools net of all observable characteristics. Thus, self-selection on the causal effect itself may generate a mistakenly large apparent Catholic school effect.IfstudentsinsteadwereassignedrandomlytoCatholicandpublicschools,both types of schools would be shown to be equally effective on average.\nTo address the possibility that self-selection dynamics create an illusory Catholic school effect, a later wave of studies then assessedwhether or not naturally occurring experimentswereavailablethatcouldbeusedtomoreeffectivelyestimatetheCatholic school effect. Using a variety of variables that predict Catholic school attendance (e.g., share of the local population that is Catholic) and putting forth arguments for whythese variablesdonotdirectlydetermineachievement,EvansandSchwab(1995), Hoxby(1996),andNeal(1997)generatedsupportforColeman’soriginalconclusions.17 More recent research has considered whether the Catholic school effect still exists inthe twenty-firstcentury,generatingsimilarresultswithalternativeandmorerecent data sources (see Carbonaro and Covay 2010; Morgan and Todd 2008; West and Woessmann 2010). Similar recent research demonstrates that the case for a Catholic schooleffect at the primary and middle school levels is considerably weaker (Hallinan and Kubitschek 2012; Jepsen 2003; Reardon, Cheadle, and Robinson 2009).\nThe Causal Effect of School Vouchers on Learning InresponsetoaperceivedcrisisinpubliceducationintheUnitedStates,policymakers haveintroduced publicly funded schoolchoice programsinto some metropolitan areas inanefforttoincreasecompetitionamongschoolsontheassumptionthatcompetition will improve school performance and resulting student achievement (see Chubb and Moe 1990; see also Fuller and Elmore 1996). Although these school choice programs differbyschooldistrict,theprototypicaldesignisthefollowing.Asetnumberof$3,000 tuitionvouchersredeemable atprivate schoolsaremade availabletostudents resident in the public school district, and all parents are encouraged to apply for one of these vouchers.The vouchersare then randomlyassignedamong those who apply. Students who receive a voucher remain eligible to enroll in the public school to which their residence status entitles them. But they can choose to enroll in a private school. If they choose to do so, they hand over their $3,000 voucher but may then be required to pay top-up tuition and fees.\nThecausaleffectsofinterestresultingfromtheseprogramsarenumerous.Typically, evaluators are interested in the achievement differences between those who attend privateschoolsusingvouchersandothersuitablecomparisongroups.Mostcommonly, thecomparisongroupisthegroupofvoucherapplicantswholostoutinthelotteryand endedupinpublicschools(seeHowellandPeterson2002;Hoxby2003;Ladd2002;Neal 2002).And,eventhoughthesesortsofcomparisonsmayseementirelystraightforward, the published literature shows that considerable controversy surrounds how best to estimate these effects, especially given the real-world complexity that confronts the implementationofrandomizationschemes(seeJin,Barnard,andRubin2010;Krueger and Zhu 2004; Peterson and Howell 2004).\nFor this example, other effects are of interest as well. A researcher might wish to know how the achievement of students who applied for vouchers but did not receive them changed in comparison with those who never applied for vouchers in the first place(asthiswouldbecrucialforunderstandinghowtheself-selectinggroupofvoucher applicants may differ from other public school students). More broadly, a researcher mightwishtoknowtheexpectedachievementgainthatwouldbeobservedforapublic 17See Cohen-Zada and Elder (2009) for a similar instrumental variable approach that is less sup- portiveofColemanandcolleagues’ resultsfortestscores.SeealsoAltonji,Elder,andTaber(2005a, 2005b).\nschool student who was randomly assigned a voucher irrespective of the application process. This goal would necessitate altering the voucher assignment mechanism, and thusithasnotbeenanobjectofresearch.Finally,themarketcompetitionjustification forcreatingtheseschoolchoicepoliciesimpliesthattheachievementdifferencesofpri- mary interest are those among public school students who attend voucher-threatened public schools (i.e., public schools that feel as if they are in competition with private schoolsbutthatdidnotfeel asifthey wereincompetitionwith privateschoolsbefore the voucher program was introduced).\nThe Causal Effect of Charter Schools on Learning Complementing the school voucher example, we will also consider as an additional example the contentious research on charter schooling in the United States. In an excellent book on recent academic and public debates on the effectiveness of charter schools, Henig (2008:2) introduces and defines charter schools in the following way: Justa little morethanfifteen yearssince the firstcharterschoolopenedin Minnesota,therearenownearly4,000nationwide,servinganestimated1.1 million students….The laws governing charter schools differ – sometimes substantially–fromstatetostate,ofcourse,butsomegeneralcharacteris- tics haveemerged.Charterschoolsreceivepublic funding onaper-student basis, are often responsible for achieving educational outcomes defined by their government chartering entity, and are subject to at least nominal public oversight. They typically are barred from charging tuition on top of the public per-pupil allocation, but are free to pursue other forms of supplementary support from donors, foundations, or corporate sponsors.\nAlthough they must observe certain baseline regulations, such as prohibi- tions on discrimination and the provision of safe environments, they are exempt from many of the rules and regulations that bind regular pub- lic schools to specific standards and procedures. This hybrid status…has made charter schools a special focus of attention and helped draw them into ideological whirlpools that raise the stakes surrounding the research into their actual form and consequences.\nAt their core,the centralresearchquestions inthe charterschooldebate aresimple to state(andidenticalinstructuretothoseoftheothertwoschoolingexamplespresented above): Do students who attend charter schools perform better on standardized tests than they would have performed if they had instead attended regular public schools? Wouldstudentswhoattendregularpublicschoolsperformbetteronstandardizedtests if they had instead attended charter schools? The contentious research that has addressed these questions is distinguished in many respects (see Abdulkadiroglu, Angrist, Dynarski et al. 2011; Angrist, Dynarski, Kaneetal.2010;CenterforResearchonEducationalOutcomes2009;Hoxby,Murarka, and Kang 2009; Tuttle, Gill, Gleason et al. 2013). Not only are some of its combat- ants leading researchers at the nation’s top universities, many of them are unusually ideological (as Henig shows brilliantly in his book). Their scholarly energy and policy advocacyis amplifiedby the public attentionthat hasbeen paidto charterschoolsby the national press, which is related to the support that charter schools have received from celebrity donors and from recent presidential aspirants. At the same time, the researchthatinforms the debate is cutting-edge inthe bestsense.Carefulattentionis paidtodetailsofmeasurement,andtheresearchdesignsthathavebeenadoptedarea healthy mixture of basic comparisonsofachievementlevels as well as daring attempts to leverage quasi-experimental variation from the ways in which charter school pro- gramsareadministered(e.g.,usinglotteried-outstudentsforcomparisongroups,when such groups exist).\nWhat makes estimating the effects of charter schools complex, perhaps even more so than for the Catholic schooleffect and the school voucherseffect, is the underlying heterogeneityoftherealworld.Theprocessbywhichsomestudentsbecomeenrolledin charterschoolsisonlypartlyobserved.Atthesametime,charterschoolsdiffergreatly from each other, such that the effect of charter schooling must surely vary because of qualitydifferences,aswellasthe matchbetweeneachstudentandthe unique features of each charter school.\nThe Causal Effect of Worker Training on Earnings The United States federal government has supported worker training programs for economicallydisadvantagedcitizens fordecades (see LaLonde1995).Througha series oflegislative renewals, these programshave evolvedsubstantially, and programevalu- ations have become an important areaof applied work in labor and public economics.\nThe services provided to trainees differ and include classroom-based vocational edu- cation, remedial high school instruction leading to a general equivalency degree, and on-the-job training (or retraining) for those program participants who have substan- tial prior work experience. The types of individuals served by these programs are heterogeneous,including ex-felons,welfarerecipients,andworkersdisplacedfromjobs by foreign competition. Accordingly, the causal effects of interest are heterogeneous, varying with individual characteristics and the particular form of training provided.\nEvenso, some common challengeshave emergedacrossmost programevaluations.\nAshenfelter (1978) discovered what has become known as “Ashenfelter’s dip,” con- cluding after his analysis of training-programdata that all of the trainee groups suffered unpredicted earnings declines in the year prior to training….This suggests that simple before and after compar- isonsoftraineeearningsmaybeseriouslymisleadingevidence.(Ashenfelter 1978:55) Because trainees tend to have experienced a downward spiral in earnings just before receivingtraining,the wagesoftraineeswouldrisetosomedegreeeveninthe absence ofanytraining.AshenfelterandCard(1985)thenpursuedmodelsofthese“meanrever- sion”dynamics,demonstratingthatthesizeoftreatmenteffectestimatesisafunction ofalternativeassumptionsaboutpre-trainingearningstrajectories.Theycalledforthe construction of randomized field trials to improve programevaluation.\nLaLonde (1986) then used results from program outcomes for the National Sup- ported Work (NSW) Demonstration, a program from the mid-1970s that randomly assigned subjects to alternative treatment conditions. LaLonde argued that most of the econometric techniques used for similar program evaluations failed to match the experimental estimates generated by the NSW data. Since LaLonde’s 1986 paper, economists and statisticians have continued to refine procedures for evaluating both experimental and nonexperimentaldata from training programs,focusing in detail on how to model the training selection mechanism (see Frumento, Mealli, Pacini, and Rubin 2012; Heckman, LaLonde, and Smith 1999; Heckman and Vytlacil 2005, 2007; Smith and Todd 2005; Zhang, Rubin, and Mealli 2008, 2009).\nThe Causal Effects of Risky Health Behaviors and Peer Relationships on Obesity and Mortality Health scientists are increasingly concerned with the worldwide increase in obesity rates (see Swinburn, Sacks, Hall et al. 2011). In the United States, social scientists havedevotedconsiderableenergytounderstandingtheinterrelationshipsbetweenrisky healthbehaviorsthataresometimesreferredtoasmodifiableriskfactorsformortality (see Cawley and Ruhm 2012; Pampel, Krueger,and Denney 2010). Although declines inmostriskybehaviorsareevidentsince the 1970s,especially inratesofsmoking,the gains to health from these trends have been mitigated by a concomitant increase in obesity over the same time period (see Stewart, Cutler, and Rosen 2009).\nMany causal controversies exist in efforts to assess the causes and consequences of obesity (see Cawley 2011), but the most vigorously debated has been the claim that obesity is contagious. In a large study of a networked community over 32 years, Christakis and Fowler conclude: Our study suggests that obesity may spread in social networks in a quan- tifiable and discernable pattern that depends on the nature of social ties.\nMoreover, social distance appears to be more important than geographic distance within these networks. Although connected persons might share an exposure to common environmental factors, the experience of simulta- neous events, or other common features (e.g., genes) that cause them to gain or lose weight simultaneously, our observations suggest an important role for a process involving the induction and person-to-person spread of obesity….Obesity in alters might influence obesity in egosby diverse psy- chosocialmeans,suchas changingthe ego’snorms about the acceptability of being overweight, more directly influencing the ego’s behaviors (e.g., affecting food consumption), or both. Other mechanisms are alsopossible.\n(Christakis and Fowler 2007:377) Many other scholars have objected to these claims (e.g., Shalizi and Thomas 2011), andtheirobjectionshavebeenaddressedbycounterargumentsandadditionalanalyses (e.g., Christakis and Fowler 2013; VanderWeele 2011b).\nThe Causal Effect of Voting Technology on Valid Voting and Election Outcomes For specific causal effects embedded in the larger political participation debates, we could focus on particular decision points – the effect of education on campaign con- tributions, net of income, and so on. However, the politics literature is appealing in another respect: outcomes in the form of actual votes cast and subsequent election victories. These generate finely articulated counterfactual scenarios.\nAlthoughrecentresearchhasconsideredabroadrangeofvotingtechnologyeffects (see Card and Moretti 2007; Hanmer, Park, Traugott et al. 2010), the most famous example remains the contested 2000 presidential election in the United States, where considerable attention was focused on the effect of voting technology on the election outcome in Florida. Wand, Shotts, Sekhon et al. (2001) published a refined version of their analysis that spread like wildfire on the Internet in the week following the presidential election. They asserted that the butterfly ballot used in PalmBeachCounty, Florida,in the 2000pres- idential election caused more than 2,000 Democratic voters to vote by mistakeforReformcandidatePatBuchanan,anumberlargerthanGeorge W. Bush’s certified margin of victory in Florida. (Wand et al. 2001:793) Reflecting on efforts to recount votes undertakenby various media outlets, Wand and his colleagues identify the crucial contribution of their analysis: Ouranalysisanswersacounterfactualquestionaboutvoterintentionsthat such investigations [by media outlets of votes cast] cannot resolve. The inspections may clarify the number of voters who marked their ballot in support of the various candidates, but the inspections cannot tell us how many voters marked their ballot for a candidate they did not intend to choose. (Wand et al. 2001:804) Herron and Sekhon (2003) then examined invalid votes that resulted from overvotes (i.e., voting for more than one candidate), arguing that such overvotes further hurt Gore’s vote tally in two crucial Florida counties. Finally, Mebane (2004) then consid- eredstatewidevotingpatterns,arguingthatifvoters’intentionshadnotbeenthwarted by technology,Gore wouldhave wonthe Florida presidentialelectionby 30,000votes.\nOne particularly interesting feature of this example is that the precise causal effect of voting technology on votes is not of interest, only the extent to which such causal effects aggregate to produce an election outcome inconsistent with the preferences of those who voted (see also Yamamoto 2012 for a related point).",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#observational-data-and-random-sample-surveys",
    "href": "extracted/Counterfactuals and Causal Inference.html#observational-data-and-random-sample-surveys",
    "title": "Counterfaturals and Causal Inference",
    "section": "1.4 Observational Data and Random-Sample Surveys",
    "text": "1.4 Observational Data and Random-Sample Surveys\nWhenwediscussmethodsandexamplesthroughoutthisbook,wewillusuallyassume\nthatthedatahavebeengeneratedbyarelativelylargerandom-samplesurveyofawell- definedpopulation.Wewillalsoassumethattheproportionandpatternofindividuals whoareexposedtothecausearefixedinthepopulationbywhateverprocessgenerates causal exposure.\nWe rely on the random-sample perspective because we feel it is the most natural framing of these methods for the typical social scientist, even though many of the classic applications and early methodological pieces in this literature do not reference random-sample surveys. For the examples just summarized, the first three have been examined primarily with random-sample survey data, but many of the others have not. Some, such as the worker training example, depart substantially from this sort of setup, as the study subjects for the treatment in that example are a heterogeneous collection of welfare recipients, displaced workers, and others.18 Pinning downthe exactconsequences of the data generationand sampling scheme of each application is important for developing estimates of the expected variability of a causal effect estimate. We will therefore sometimes modify the random-sampling backgroundwhendiscussingwhatisknownabouttheexpectedvariabilityofthealter- native estimators we will present. Nonetheless, our primary focus in this book is on strategies to estimate parameters that can be interpreted as warranted causal effects, andaccordinglywewillgivefarlessattentiontoproceduresforestimatingthestandard errors of these parameter estimates. In fact, as the reader will notice in subsequent chapters, we will often assume that the sample is infinite. This preposterous assump- tion is useful for presentation purposes because it simplifies matters greatly; we can thenassumethatsamplingerroriszeroandassert,forexample,thatthesamplemean ofanobservedvariableisequaltothepopulationexpectationofthatvariable.Butthis assumption also signals a critical note of caution: It is meant to appear preposterous and unreasonable in order to reinforce the point that the consequences of sampling error must always be considered in any empirical analysis.19 Our assumption is that our readersknow how to estimate and utilize standarderrorsfor many analysissitua- tions, and so we will discuss these issues only when additional guidance is needed for the particular estimators presented in this book.\nMoreover, we will also assume for our presentation that the variables in the data are measured without error. This perfect measurement assumption is, of course, also entirely unreasonable. But it is commonly invoked in discussions of causality and in many, if not most, other methodological pieces. We will indicate in various places throughout the book when random measurement error is especially problematic for themethodsthatwepresent.Weleaveitasself-evidentthatnonrandommeasurement error can be debilitating for all methods.\n18Partly for this reason, some of the literature (e.g., Imbens 2004) has made careful distinctions between the sample average treatment effect (SATE) and the population average treatment effect (PATE). In this book, we will focus most of our attention on the PATE (and other conditional PATEs). We will generally assume that a well-defined population exists (usually a superpopulation withexplicitcharacteristics) andthat theavailabledata arearandomsamplefromthis population.\nHowever,muchofourtreatmentofthesetopicscouldberewrittenwithoutthelargerandom-sample perspective and focusing only on the average treatment effect within the sample in hand. Many articlesinthistraditionofanalysisadoptthisalternativestartingpoint(especiallythoserelevantfor small-scale studies in epidemiology and biostatistics for which the “sample” is generated in such a way that aformal connection to a well-defined population is impossible). We discuss these issues in substantial detailinChapter2,especiallyinitsappendixonalternativepopulationmodels.\n19Becausewewillassumeinthesecasesthatthesampleisinfinite,wemustthenalsoassumethat thepopulationisinfinite.Thisassumptionentailsadoptionofthesuperpopulation perspectivefrom statistics(whereinthefinitepopulationfromwhichthesampleisdrawnisregardedasonerealization ofastochasticsuperpopulation).Evenso,andaswewillexplaininChapter2,wewillnotclutterthe text of the book by making fine distinctions between the observable finite population and its more encompassingsuperpopulation.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#causal-graphs-as-an-introduction-to-the-remainder-of-the-book",
    "href": "extracted/Counterfactuals and Causal Inference.html#causal-graphs-as-an-introduction-to-the-remainder-of-the-book",
    "title": "Counterfaturals and Causal Inference",
    "section": "1.5 Causal Graphs as an Introduction to the Remainder of the Book",
    "text": "1.5 Causal Graphs as an Introduction to the Remainder of the Book\nIn Chapters 2 and 3, we will introduce what we regard as the two main pieces of the\ncounterfactualapproachtocausalanalysisforobservationalsocialscience–thepoten- tial outcome model and the directed graph approach to causal analysis. In Chapter 4, we will present the basic conditioning strategy for the estimation of causal effects, afterwhichwewillthenexplain–inChapters5through7–whymatching,regression, and weighted regression estimators are complementary implementations of the more general conditioning strategy.\nWe will then make the transition from “easy” to “hard” instances of causal effect estimation, for which simple conditioning will not suffice because relevant variables that are related to causal exposure are not observed. After presenting the general predicament in Chapter 8, we will then offer Chapters 9 through 11 on instrumental variable techniques, mechanism-based estimation of causal effects, and the usage of over-time data to estimate causal effects. Finally, we will consider in Chapter 12 how toproceedwhennoestimatorsareavailabletoofferwarrantedpointestimatesofcausal effects, considering both the literature on set identification and sensitivity analysis.\nIn conclusion, in Chapter 13 we will provide a summary of some of the objections thatothershavedevelopedagainstthecounterfactualmodel.Wewillalsoofferabroad discussion of the complementary modes of causal inquiry that comprise causal effect estimation in observationalsocial science.\nInpartbecauseourdetailedTableofContentsalreadygivesanaccurateaccounting of the material that we will present in the remaining chapters, we will not provide a set of detailed chapter summaries here. Instead, we will conclude this introductory chapter with three causal diagrams and the causal effect estimation strategies that they suggest. These graphs allow us to foreshadow some of the specific causal effect estimation strategies that we will present later.\nBecause the remainder of the material in this chapter will be reintroduced and more fully explained later (primarily in Chapters 3, 4, 8, and 10), it can be skipped now without consequence. However, our experience in teaching this material suggests that many readers may benefit from a quick graphical introduction to the basic esti- mation techniques before considering the details of the counterfactual framework for observationaldata analysis.\nGraphical Representations of Causal Relationships JudeaPearl(2000,2009)andothershavedevelopedageneralsetofrulesforrepresent- ing causal relationships with graphs.20 We will provide a more complete introduction to directed graph representations of causal effects in Chapter 3, and for now we use the most intuitive pieces of Pearl’s graphical apparatus with only minimal discussion of technical details.\n20Thesegraphs canbeinterpreted as the mostrecent incarnation ofthe path diagramsdeveloped bySewallWright(1925, 1934;seeBollenandPearl2013).\nG A F B D Y C Figure1.1 A causal graphin which back-doorpaths from D to Y can be blocked by observable variables and in which C is an instrumental variable for D.\nConsider the causal relationships depicted in the graph in Figure 1.1 and suppose that these relationships are derived from a set of theoretical propositions that have achievedconsensusintherelevantscholarlycommunity.Forthisgraph,eachnoderep- resents an observable random variable. Each directed edge (i.e., single-headed arrow) from one node to another signifies that the variable at the origin of the directed edge causesthe variableatthe terminusofthe directededge.Eachcurvedanddashedbidi- rected edge (i.e., double-headed arrow) signifies the existence of common unobserved nodesthatcausebothterminalnodes.Bidirectededgesrepresentcommoncausesonly, not mere correlations with unknown sources and not relationships of direct causation between the two variables that they connect.\nNow,suppose that the causalvariableof primaryinterestis D andthat the causal effect thatwe wishto estimate is the effect ofD onY. The questionto consideris the following: Given the structure of causal relationships represented in the graph, which variables must we observeand then use in a data analysis routine to estimate the size of the causal effect of D on Y? Three Strategies to Estimate Causal Effects Althoughwewillconsidermanystrategiesforestimatingcausaleffectsinthisbook,we will give our most sustained attention to the following three strategies. First, one can condition on variables (with procedures such as stratification, matching, and regres- sion) to eliminate the noncausal portion of an association between a causal variable andanoutcomevariable.This strategyisoftenreferredto asconditioningto blockall “back-door”pathsfromthecausalvariabletotheoutcomevariable,whereaback-door pathisdefinedasanypathbetweenthe causalvariableandthe outcomevariablethat beginswithanarrowthatpointstothecausalvariable.Second,onecanuseexogenous variation in an appropriate instrumental variable to isolate covariation in the causal andoutcomevariables.Third,onecanestablishanexhaustiveandisolatedmechanism that relates the causal variable to the outcome variable and then calculate the causal effect as it propagates through the mechanism.\nConsider the graph in Figure 1.1 and the opportunities it presents to estimate the causal effect of D on Y with the conditioning estimation strategy. First note that there are two back-door paths from D to Y in the graph that generate a sup- plemental noncausal association between D and Y: (1) D ←A(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)F →Y and (2) D←B(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)A(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)F →Y.21 Both of these back-door paths can be blocked in order to eliminate the supplemental noncausal association between D and Y by observing and then conditioning on A and B or by observing and then conditioning on F. These two conditioning strategies are general in the sense that they will suc- ceed in producing consistent estimates of the causal effect of D on Y under a variety of conditioning techniques and in the presence of nonlinear effects. They are mini- mally sufficient in the sense that one can observe and then condition on any subset of the observed variables in {A,B,C,F,G} as long as the subset includes either {A,B} or {F}.22 Now, consider the second estimation strategy, which is to use an instrumental variable for D to estimate the effect of D on Y. This strategy is completely different from the conditioning strategy just summarized. The goal is not to block back-door paths from the causal variable to the outcome variable but rather to use a localized exogenous shock to both the causal variable and the outcome variable in order to estimate indirectly the relationship between the two. For the graph in Figure 1.1, the variableC is a valid instrumentfor D because it causesD but does nothavean effect on Y except through its effect on D. As a result, one can estimate consistently the causal effect of D on Y by taking the ratio of the relationship between C and Y and between C and D.23 For this estimation strategy, A, B, F, and G do not need to be observed if the only interest of a researcher is the causal effect of D on Y.\nTo further considerthe differences betweenthese firsttwo strategies,now consider the alternative graph presented in Figure 1.2. There are five possible strategies for estimating the causal effect of D on Y for this graph, and they differ from those 21As we note later in Chapter 4 when more formally defining back-door paths, the two paths labeled “back-door paths” in the main text here may represent many back-door paths because the bidirected edges may represent more than one common cause of the variables they point to. Even so, the conclusions stated in the main text are unaffected by this possibility because the minimally sufficientconditioningstrategiesapplytoallsuchadditionalback-doorpaths aswell.\n22For the graph in Figure 1.1, one cannot effectively estimate the effect of D on Y by simply conditioning only on A. We explain this more completely in Chapters 3 and 4, where we introduce theconcept ofa collidervariable. Thebasic ideaisthat conditioning onlyon A,whichis acollider, createsdependencebetweenBandF withinthestrataofA.Asaresult,conditioningonlyonAdoes noteliminatethenoncausal associationbetween D andY.\n23Although all other claims in this section hold for all distributions of the random variables and all types of nonlinearity of causal relationships, one must assume for instrumental variable (IV) estimation what Pearl labels a linearity assumption. What this assumption means depends on the assumeddistributionofthevariables.ItwouldbesatisfiedifthecausaleffectofC onDislinearand thecausaleffectofDonY islinear.Bothofthesewouldbetrue,forexample,ifbothC andDwere binaryvariablesandY wereaninterval-scaledvariable,andthisisthemostcommonscenariowewill considerinthisbook.\nG A F B D Y C H Figure 1.2 A causal graph in which C is no longer an instrumental variable for D.\nG A F M B D Y N C Figure1.3 AcausaldiagraminwhichM andN representanisolatedandexhaustive mechanism for the causal effect of D on Y.\nfor the set of causal relationships in Figure 1.1 because a third back-door path is now present: D←C→H→Y. For the first four strategies, all back-door paths can be blocked by conditioning on {A,B,C}, {A,B,H}, {F,C}, or {F,H}. For the fifth strategy,the causaleffect canbe estimatedby conditioningonH andthenusing C as an instrumental variable for D.\nFinally,toseehowthethirdmechanisticestimationstrategycanbeusedeffectively, consider the alternative graph presented in Figure 1.3. For this graph, four feasible strategies are available as well. The same three strategies proposed for the graph in Figure 1.1 can be used. But, because the variables M and N completely account for the causal effect of D on Y, and because M and N are not determined by anything other than D, the causal effect of D on Y can also be calculated by estimation of the causal effect of D on M and N and then subsequently the causal effects of M and N on Y. And, because this strategy is available, if the goal is to obtain the causal effect of D on Y, then the variables A, B, C, F, and G can be ignored.24 In an ideal scenario, all three of these forms of causal effect estimation could be used to obtain estimates, and all three would generate equivalent estimates (subject to the expected variation produced by a finite sample from a population). If a causal effect estimate generated by conditioning on variables that block all back-door paths is similar to a causal effect estimate generated by a valid instrumental variable esti- mator,theneachestimateisbolstered.Betteryet,ifamechanism-basedstrategythen generates a third equivalent estimate, all three causal effect estimates would be even moreconvincing.And, in this case,anelaboratedexplanationofhow the causaleffect comesaboutisalsoavailable,asaresearchercouldthendescribehowthecausaleffect is propagated through the intermediate mechanistic variables M and N.\nImplications The foregoing skeletalpresentation of causal effect estimation is, of course,inherently misleading.Rarelydoesastateofknowledgeprevailinafieldthatallowsaresearcherto specifycausesascleanlyasinthegraphsinthesefigures.Writingdownafullgraphthat representsaconsensusposition,orasetofgraphsthatrepresentalternativepositions, can be very difficult, especially if the arguments put forward in alternative pieces of researchare open to multiple interpretations. Yet, little progresson estimating causal effects is possible until such graphs are drawn, or at least some framework consistent with them is brought to bear on the questions of central interest.\nBeyondintroducing the basic estimation strategies,these graphs convey two addi- tional points that are relevant for the material that follows. First, there is often more than one way to estimate a causal effect, and simple rules such as “control for all other causes of the outcome variable” can be poor guides for practice. For example, forFigure1.1,therearetwocompletelydifferentandplausibleconditioningstrategies: either condition on F or on A and B. The strategy to “control for all other causes of the outcome variable” is misleading because (1) it suggests that one should condition on G as well, which is unnecessary if all one wants to obtain is the causal effect of D on Y, and (2) it does not suggest that one can estimate the causal effect of D on Y by conditioning on a subset of the variables that cause the causal variable of interest.\nIn this case, one can estimate the causal effect of D on Y without conditioning on any of the other direct causes of Y, but instead by conditioning on the variables that cause D. Even so, this last conditioning strategy should not be taken too far. One 24Note that, for the graph in Figure 1.3, both M and N must be observed. If, instead, only M were observed, then this mechanistic estimation strategy would not allow for estimation of the full causaleffectofDonY.However,ifM andN areisolatedfromeachother,astheyareinFigure1.3, thentheportionofthecausal effectthat passesthroughM orN canbeeffectively estimatedinthe absenceofobservationoftheother.WediscusstheseissuesindetailinChapter 10.\nneed not condition on C when also conditioning on both A and B. Not only is this unnecessary (just as for G with the other conditioning strategy), but in doing so one failstouseC inits(possibly)mostusefulway:asaninstrumentalvariablethatcanbe used to consistently estimate the causal effect of D on Y, ignoring completely A, B, F, and G.\nSecond, the methods we will present, as we believe is the case with all estimation strategiesinthesocialsciences,arebestsuitedtothetargetedestimationoftheeffects of focal causes. As we will discuss at severalpoints throughoutthe book, especially in Chapters 6 and 13, the counterfactual approach can also be used to pursue the more ambitiousgoalofestimatingtheeffectsofall causesofanoutcomeofinterest.Evenso, thismoreambitiousgoalisrarelypursuedbecauseofhowdifficultitistoachieve.The way in which we have presented these graphs is telling on this point. Consider again the questionthatweposedafterintroducingFigure1.1.We askedasimplerversionof thefollowingquestion:GiventhestructureofcausalrelationshipsthatrelateA,B,C, D, F, G, and Y to each other (represented by presupposed edges that signify causal effects of unknown magnitude), which variables must we observe and then use in a data analysis routine to estimate the size of the causal effect of D on Y? This sort of constrainedquestion(i.e.,beginningwiththeconditional“given”clause)isquiteabit differentfromseekingtoanswerthemoregeneralquestions:Whatareallofthecauses ofY, andhowlargearetheir effects relativeto eachother? The methods that wewill present in this book are not irrelevantto this broaderquestion, but they are designed to first answer more targeted questions about the effects of subsets of all causes of an outcome.\nThe limited nature of the methods that we will present implies two important features of causal effect estimation from the perspective of counterfactual modeling.\nToofferapreciseanddefendablecausaleffectestimate,awell-specifiedtheoryisneeded to justify assumptions about underlying causal relationships. And, if theory is poorly specified, or divergenttheories exist in the relevantscholarlycommunity that support alternativeassumptionsaboutunderlyingcausalrelationships,thenalternativecausal effect estimates may be considered valid conditional on the validity of alternative maintained assumptions. We discuss these issues in depth across the chapters of the book, while presenting the framework and the methods that generate estimates that must then be placed in their proper context.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#defining-the-causal-states",
    "href": "extracted/Counterfactuals and Causal Inference.html#defining-the-causal-states",
    "title": "Counterfaturals and Causal Inference",
    "section": "2.1 Defining the Causal States",
    "text": "2.1 Defining the Causal States\nThe counterfactual framework for observational data analysis presupposes the exis-\ntence of well-defined causal states to which all members of the population of interest couldbe exposed.1 As we willshow in the next section,causaleffects are then defined based on comparisons of outcomes that would result from exposure to alternative causal states. For a binary cause, the two states are usually labeled treatment and control.Whenamany-valuedcauseisanalyzed,the conventionistorefertothe alter- native states as alternative treatments.\nAlthough these labels are simple, the assumed underlying states must be very carefully defined so that the contribution of an empirical analysis based upon them is clear. Some of the relevant issues can only be discussed as we introduce additional 1Wejustifytheimportanceofcarefullydefiningtheboundariesofthepopulationofinterestwhen presenting average causal effects later inthis chapter. We also provide an appendix to this chapter, in which we explain the general superpopulation model that we will adopt when the boundaries of the population can be clearlydefined and when wehave the good fortuneof having a largerandom samplefromthepopulation.\n37 piecesofthefull counterfactualframeworkinthischapterandthenext–movingfrom the definition of individual-level causal effects, through average causal effects, and then to causal graphs and the underlying structural equations that they represent.\nNonetheless, some initial clarificationof core definitional issues for these causalstates is essential.\nFineArticulation.Toappreciatethevalueoffinelyarticulatedcausalstates,con- siderthe examplesintroducedinSection 1.3. The workertrainingexampleis straight- forward, and the two states are “entered a training program” (the treatment state) and“didnotenteratrainingprogram”(thecontrolstate).Thecharterschoolexample issimilar.Here,thealternativestatesare“enrolledinacharterschool”(thetreatment state) and “enrolled in a regular public school” (the control state, although possibly referred to as an alternative treatment state). One possible complication with these examples is the possibility of inherent differences across training programs, charter schools, and regular public schools. If any such treatment-site heterogeneity exists, then stratified analyses may be necessary, perhaps by regions of the country, size of the program or school, or whatever other dimension suggests that variability of the causal states deserves explicit modeling.2 Otherexamples,atleastasexecutedintheextantresearch,havecausalstatesthat are not finely articulated. Consider the classic political participation line of inquiry.\nFor the relationship between socioeconomic status and political participation, there are many underlying causal effects, such as the effect of having obtained at least a college degree on the frequency of voting in local elections and the effect of having a family income greater than some cutoff value on the amount of money donated to political campaigns. Well-defined causal states exist for these narrow causal effects, but it is not clear at all that well-defined causal states exist for the internally dif- ferentiated concept of socioeconomic status, which social scientists have created for their own analytic purposes. It is therefore unsurprising that some of the most recent literature (e.g., Henderson and Chatfield 2011; Kam and Palmer 2008) has specified more finely articulatedcausalstates for this line of research,suchas “enteredcollege” (the treatment state) in comparison to “did not enter college” (the control state).\nThefatherabsenceexampleisanintermediatecase.Theoriginalresearchattempted toestimatethebroadeffectsofsingleparenthoodontheoutcomesofchildrenandado- lescents (see McLanahan and Sandefur 1994; Wu and Wolfe 2001). The more recent literaturehasfocusedonthe narrowlydefinedtreatmentstateoffatherabsence.Even so, much variationremains in both the definition of this treatment state and the rele- vant comparison(or control) state, as noted in a review piece: Studies in this field measured father absence in several ways, which the readershouldkeepinmindwheninterpretingandcomparingresultsacross studies. Some studies compared children of divorced parents with children of stably married parents; others compared children whose parents mar- riedafter their childs birth with those parents who never married….More recently, researchers have started to use even more nuanced categories to 2For example, Hong and Raudenbush (2006) provide a careful analysis of retention policies in primaryeducation,implementingthistypeoftreatment-sitestratificationbasedontheaveragelevel ofretentionindifferentpublicschools.Wewilldiscussthesetypes ofstudiesinSection2.5.\nmeasure family structure – including married biological-parent families, cohabiting biological-parent families, married stepparent families, cohab- iting stepparent families, and single parents by divorce and nonmarital birth – reflecting the growing diversity of family forms in society….We did not identify any studies that used causal methods to study the effects of same-sex unions. (McLanahan et al. 2013:408) In general, research that takes account of heterogeneity by splitting treatment states into mutually exclusive component states will break new ground if sufficient data are available to estimate the more narrowly defined treatment effects.\nNominal States from Constitutive Features.Wetakeapragmaticbutprinci- pled positionon the characteristicsof causalstates, and in this subsectionwe wantto clarifyourpositionforreaderswhoareinterestedindebatesonthenatureofcausation in philosophy and how those debates are relevant for social science research. Readers whoareuninterestedinthesedebatesmaywishtoskimthis subsectionnowandreen- gageit afterreadingChapter 10oncausalmechanisms andSection13.1onobjections tothecounterfactualapproachtoobservationaldataanalysis(pages438–446).Infact, most scholars who work with counterfactual models in social science research do not take any positions on the issues that we raise in this subsection, and their research shows that much useful work can proceed by taking and using the causal states as measured,withoutconsideringthefeaturesthatgivethemtheircapacitiestogenerate effects.\nHaving offered these warnings, we will now explain why we take the position that each state of each treatment should be regarded as a nominal state with constitutive features (e.g., entities, activities, and relations) that are jointly capable of producing the outcome of interest. Consider the Catholic school example, where the nominal states are “enrolledin a Catholic school” and “enrolledin a public school”and where the outcome is “learning.” Each type of school has teachers, classrooms, curricula, administrators, normative environments, affiliated institutions, and networks of peers and parents. The literature on the differences between Catholic schools and public schoolssuggeststhattheseconstitutive featuresoftheschoolsareinterrelatedinways that differ by type of school. Accordingly, while Catholic schools and public schools bothproducestudentlearning,the particularwaysinwhichthey dosoarethoughtto differ meaningfully acrosstype of school, and in ways that have notbeen documented comprehensivelywithavailabledata.Nonetheless,wecanstillconceiveofeachstudent in the populationof interest being exposedto eachtype ofschool,and we can assume that each student would then experience the learning generated in toto by the joint capacities of the constituent features of each type of school.\nTakingthisposition,whileatthesametimeembracingcounterfactualdependence, implies thatwe seevalue inmounting causalanalysisinthe socialsciences ontopofa foundation that conjoins a metaphysics of causal powers with a metaphysics of coun- terfactual dependence (see Collins, Hall, and Paul 2004; Mumford and Anjum 2011).\nThe price for such an inclusive pragmatism is an elaborate metaphysics, which most philosophers would likely regard as insufficiently elegant and insufficiently reductive.\nWith reference to Hume’s example of billiard balls (Hume 1977[1772]), our position requiresthatweadoptthefollowingspecific(butperhapspainfullyelaborate)account ofthe natureofcausation:The cue ballcausesthe secondbilliardballtorollapartic- ular observeddistance because billiard balls are spheres and because the cue ball was struckbytheplayer’spoolcueinsuchawaythatitthenstruckthesecondbilliardball at a particular angle and with a particular force. Furthermore, the cue ball would not have caused the second billiard ball to roll the same observed distance if the billiard ballshadinsteadnotbeenspheresorifthecueballhadnotbeenstruckbytheplayer’s pool cue in the exact same way. Thus, the causal effect of the cue ball on the second billiard ball is a joint product of the spherical feature of the billiard balls as well as the external intervention of the pool player.3 For the sorts of social science examples we consider in this book, we will express the effects of causal states using contrasts between observed exposure to one state and what-if counterfactual exposure to another state. However, we will also take the position that any such claims about the effects of exposure to alternative states are incompleteuntilthoseclaimsareaccompaniedbyaccountsoftheconstitutivefeatures ofthecausalstatesandhowthosefeaturesarethoughttograntthestatesthepowerto generate outcomes.4 The most complete accounts point to evidence that mechanisms exist that are capable of generating the outcomes of interest (and, better yet, that it is reasonable to believe that these mechanisms will be able to explain why exposure to alternative causal states generates differences).\nConsideranexamplewheremanyoftheseissuesaresettled.FortheCatholicschool effect, analysis can proceed within a guiding framework shaped by a rich background literature. The historical events that generated public schools and Catholic schools as coherentinstitutions suggeststhatthey canbe meaningfullycomparedwhenstudying student achievement because they each aim to produce learning for core academic subjects, even though they each pursue additional distinct goals (see Tyack 1974 for one of the most widely read accounts). In addition, each type of school has a rich set of literature that has examined the mechanisms that generate learning. For Catholic 3With the goal of reducing the complexity of such an account, philosophers seem inclined to take positions on whether the spherical characteristic of the cue ball (its “causal power”) is more fundamental than the striking(i.e.,the “counterfactual dependence” induced by the intervention of theplayer), whether “striking”canbedefined intheabsence ofanintervening poolplayer,whether avalidexplanationcansimplybededucedfromlawsofmotioninspaceandtime,whetheranything is transferredbetween the two billiardballs at the moment of impact, and so on. We see no reason totakeapositiononthesematters inthisbook, andwethereforequiteconsciouslyviolaterule4of PaulandHall(2013:40), “Thoushallnotbeanontological wimp.” 4We see little value in placing restrictions on what types of origination accounts are admissible andshouldbereliedupon.Forsomecausalclaims,historicalnarrativesareappropriate,totheextent that they focus on especially salient institutional histories while pushing into the background the multitudeofspecificdecisionsofallindividualsthathavegivenshapetotheconstitutive features of thealternative states (seeReed2011 forexamples ofsuch“forming”narratives). Inother cases,the origins of the states can be explained as contrasting values for built concepts, based on underlying analyticdimensionsdrawnfromtheextantsocialscienceliterature,wheretheseunderlyingdimensions have been chosen precisely because background evidence exists that they are sources of productive causalpowerofthenominalcausalstatesofinterest(seeGoertz2006forexamples).However,wesee onecomplicationforthissecondtypeofaccount,asforeshadowedbyourdiscussionofsocioeconomic status above. Causal states drawn from values for a built concept may be real only in the minds of researchers. As a result, explanations based upon them may appear nonsensical to individuals who arepurportedtobeproducingtheeffects ofinterest.Whether suchbehind-the-backaccounts areto be regarded as powerful or not is almost certainly a domain-specific consideration, which will also varywiththegoalsofastudy.\nschools, several complementary narratives exist that provide arguments that suggest whyCatholicschoolshavethecapacitytobemoreeffectivethanpublicschools.These narratives include those that emphasize the relations embedded in parental network structurealongsideanappropriatedideologyoftheCatholicchurch(seeColemanand Hoffer1987),those thatemphasize the extentto whichCatholic schoolsare especially responsive to parental feedback and the threat of exit (Chubb and Moe 1990), and those that emphasize the trusting relationships between teachers and administrators that flow from a shared purpose (Bryk, Lee, and Holland 1993).\nOf course, the existence of such lower-level claims about the specific mechanis- tic capacities of features of Catholic schools begs the question: When is it advis- able to decompose nominal causal states into component causal states with their own capacitiesforproducingtheoutcomeofinterest?Weseetheanswertothisquestionas subject- and domain-specific. Accordingly, we see little value in making general argu- ments about when such decomposition is feasible because of the inherent separability oftheproductivecapacitiesattachedtoparticularconstitutivefeaturesorisinfeasible becauseofthedeeplyentangledcomplementaritiesamongthem.And,aswewillargue later in Chapter 10, it is generallyimpossible to take a position onthese issues in any given study without first stipulating the causal structure of the mechanisms that are presumed to produce the outcome. Fortunately, as we will demonstrate in the inter- veningchapters,causaleffectsdefinedonlybynominalcausalstatescanbesufficiently precise so that their estimation is itself feasible and very much worthwhile.\nLocal and Reasonable. Consider the literature on socioeconomic status as a fundamental cause of health and mortality, which takes as its defining feature the argument that it is only occasionally useful to identify causal states for the mea- surable dimensions underneath the fundamental cause of socioeconomic status (see page 19). For these scholars, it is the abundant causal pathways that link socioe- conomic status with health and mortality that are most noteworthy because of the robust, total associations that they generate. Isolating a particular causal effect that is attributable to a contrast defined by two clearly defined underlying causal states embedded within socioeconomic status could still be useful, such as for the estima- tion of a health disparity attributable to a family income difference of $25,000. The claim of this literature is that this narrow exercise could become counterproductive if it detracted from the broader claim of fundamental causality, as would be the case if the analyst were to imply that any such narrow effect is as robust as the total causal effect that socioeconomic status exerts on health and mortality.\nA fundamental-cause orientation may be useful in challenging the status quo in research areas that have become too narrowly focused on only a few relevant causal pathways, but widespread adoption of the fundamental-cause orientation to causal analysis would not be productive. In many areas of research, it would not be hard to takecollectionsofnarrowlyandcarefullydefinedcausalcontrasts,lumpthemtogether into latent constructs, and then assert that, over sufficiently long intervals, the latent construct is a fundamental cause because the mechanisms that are activated by com- ponent causes switch on and off over time. Indeed, considering our other examples in Section1.3,onecouldarguequiteeasilythatthesocioeconomicstatusofone’sparents is a fundamental cause of educational attainment, subsequent labor market earnings, political participation,and fertility decisions. We doubt many scholarswoulddisagree with such broad claims, and most would likely interpret them as consistent with con- clusions drawn by scholars working with comparatively coarse data more than six decadesago.Moreimportantly,wethink itunlikelythat the reassertionofsuchbroad claims would encourage researchers to move in productive new directions. Instead, we see the counterfactual perspective, and the potential outcome model in particu- lar, as enabling the pursuit of a more ambitious goal: the careful delineation of the relevant causal states that lie within any purported fundamental causes and then the estimation of the specific effects generated by contrasts between them. Should there be reason to expect that any such effects vary in time, then their estimation across time demands empiricalanalysis,not simply the assertionthat sucheffects,by nature of their variability in time, can only be regarded as specialized instantiations of more fundamental causes.\nFor a related reasonableness concern, consider a specific political participation example. To what extent do restrictions on who can vote determine who wins elec- tions?Ahighlypublicizedvariantofthisquestionisthis:Whatistheeffectonelection outcomes of laws that forbid individuals with felony convictions from voting?5 Uggen and Manza (2002) make the straightforward claim that the 2000 presidential elec- tion would have gone in favor of Al Gore if felons and ex-felons had been permitted to vote: Although the outcome of the extraordinarily close 2000 presidential elec- tion could have been altered by a largenumber of factors, it would almost certainly have been reversed had voting rights been extended to any cate- gory of disenfranchised felons. (Uggen and Manza 2002:792) Uggen and Manza (2002) then note an important limitation of their conclusion: ourcounterfactualexamplesrely upona ceterisparibusassumption– that nothingelseaboutthecandidatesorelectionwouldchangesavethevoting rights of felons and ex-felons. (Uggen and Manza 2002:795) When thinking about this important qualification, one might surmise that a possible world in which felons had the right to vote would probably also be a world in which the issues(andprobablycandidates)ofthe electionwouldbe verydifferent.Thus,the mostchallenging definitional issue here is not who counts as a felon orwhether or not an individual is disenfranchised, but rather how well the alternative causal states can be characterized.\nA relevant criterion, although necessarily subjective, is whether it “stretches the mind”toomuchtoimagineconceivablealternativeworldsinwhichallelseremainsthe same, except for the instantiation of the alternative causal states. For this particular example,the“toomuch”criterionwasnotlikelycrossed.Scholarsinpoliticalsociology and criminology supported publication through blind peer review in the discipline’s highestprestigejournal,theAmerican Sociological Review.Reviewerspresumablysaw this particular line of research as an important contribution to our knowledge on howchanginglawstoallowfelonsandex-felonsto votecouldhavepotentialeffects on 5Behrens,Uggen, andManza(2003), ManzaandUggen(2004), andUggen, Behrens,andManza (2005) givehistoricalperspectiveonthisquestion.\nelectionoutcomes,andtheymusthaveconcludedthattherewasvalueinunderstanding sucheffectsinhypotheticalisolationfromotherchangesthatwouldalsolikelyco-occur in the real world along with the contemplated legislative changes.\nThemoregeneralpoint,however,isthatitisimportantthatthe“whatwouldhave been” nature of the conditionals that define the causal states of interest be carefully considered. When a facile ceteris paribus assumption is invoked to relieve the analyst from having to discuss other contrasts that are nearly certain to occur at the same time,thepositedcausalstatesmaybeopentothechargethattheyaretooimprobable or ill-defined to justify the pursuit of a causal analysis based on them.6 ## 2.2 Potential Outcomes and Individual-Level Treatment Effects\nGiventheexistenceofwell-definedcausalstates,causalinferenceinthecounterfactual\ntraditionproceeds by stipulating the existence of potential outcome randomvariables that are defined over all individuals in the population of interest. For a binary cause, we will denote potential outcome random variables as Y1 and Y0.\nWewillalsoadoptthenotationalconventionfromstatisticsinwhichrealizedvalues for randomvariables aredenoted by lowercaseletters. Accordingly, y1 is the potential i outcome in the treatment state for individual i, and y0 is the potential outcome in i the control state for individual i.7 The individual-level causal effect of the treatment 6ThephilosopherNancyCartwright(2007a,2007b)wouldrefertoananalysisthatdefinespotential outcomes (see next section) in terms of ill-conceived causal states as generating “impostor counter- factuals.”She stresses the need for fullcausal models of all interrelated causes of outcomes, so that theeffects ofcausesarenottoonarrowlyassessed.Shewrites: Toevaluatecounterfactuals…weneedacausalmodel;andthecausalmodelmustcon- tain all the information relevant to the consequent about all the changes presumed in theantecedent. Thereisnoother reasonablemethodonoffertoassesscounterfactuals.\nWe may not always produce a model explicitly, but for any grounded evaluation there must be a causal model implicit; and our degree of certainty about our counterfactual judgmentscanbenohigherthanourdegreeofcertaintythatourcausalmodeliscorrect.\n(Cartwright2007a:193) We agree with the value of having a causal model, as will become clear in subsequent chapters.\nHowever, Cartwright takes this position to an extreme that is counterproductive for practice; see Pearl(2009:362–65).\n7Thereisawidevarietyofnotationinthepotentialoutcomeandcounterfactualsliterature,andwe haveadoptedthenotationthatwefeelistheeasiesttograsp.However,weshouldnotethatEquation (2.1)anditselementsareoftenwrittenasoneofthefollowingalternatives, Δi=Y 1i−Y 0i, δ i=Y it−Y ic, τ i=y i(1)−y i(0), and variants thereof. We use the right-hand superscript to denote the potential treatment state of the corresponding potential outcome variable, but other authors use the right-hand subscript or parentheticalnotation.Wealsousenumericalvaluestorefertothetreatmentstates,butotherauthors (includingus,seeMorgan2001,WinshipandMorgan1999,andWinshipandSobel2004)usevalues suchastandcforthetreatmentandcontrolstates,respectively.Thereisalsovariationintheusage ofuppercaseandlowercaseletters.Wedonotclaimthateveryonewillagreethatournotationisthe easiest to grasp, and it is certainly not as general as, for example, the parenthetic notation. But it is then defined as δi=y i1−y i0. (2.1) Before proceeding, two caveats on this definition of individual-level causal effects should be noted. First, the individual-level causal effect can be defined in ways other thanasthelineardifferencebetweenthetworelevantpotentialoutcomes.8Oneobvious possibility is the ratio of one individual-level potential outcome to another, y1/y0. In i i someresearchareas,alternativedefinitionsattheindividuallevelmayhaveadvantages.\nThe mostprominentcaseisepidemiology,wherethe goalofestimatingriskfactorsfor health outcomes continuesto dominate practice andleads to a frequentpreference for ratio-based rather than difference-based comparisons. Nonetheless, the overwhelming majorityoftheliteraturerepresentsindividual-levelcausaleffectsaslineardifferences, as in Equation (2.1).\nSecond,theindividual-levelcausaleffectcouldbedefinedasthedifferencebetween the expectations of individual-specific random variables, as in E[Y1]−E[Y0], where i i E[.]istheexpectationoperatorfromprobabilitytheory(see,foraclearexampleofthis alternative setup, King et al. 1994:76–82).In thinking about individuals self-selecting intoalternativetreatmentstates,itcanbeusefultosetupthetreatmenteffectsinthis way.Inmanyapplications,individualsarethoughttoconsiderpotentialoutcomeswith somerecognitionoftheinherentuncertaintyoftheirbeliefs,whichmayproperlyreflect true variability in their individual-level potential outcomes. But, with data for which a potential outcome is necessarily observed for any individual as a scalar value (via an observed outcome variable, defined later), this individual-level, random-variable definition is largely redundant. Accordingly, we will denote individual-level potential outcomes as values such as y1 and y0, regarding these as realizations of population- i i levelrandomvariablesY1 andY0 whilerecognizing,atleastimplicitly,thattheycould also be regardedas realizations of individual-specific random variables Y1 and Y0.\ni i ## 2.3 Treatment Groups and Observed Outcomes\nFor a binary cause with two causal states and associated potential outcome variables\nY1 and Y0, a corresponding causal exposure variable, D, is specified that takes on two values: D is equal to 1 for members of the population who are exposed to the treatment state and equal to 0 for members of the population who are exposed to the control state. Exposure to the alternative causal states is determined by a particular process, typically an individual’s decision to enter one state or another, an outside actor’s decision to allocate individuals to one state or another, a planned random allocation carried out by an investigator,or some combination of these alternatives.\nByconvention,thosewho areexposedto the treatmentstate arereferredto asthe treatmentgroup,whereasthosewhoareexposedtothecontrolstatearereferredtoas thecontrolgroup.BecauseD isdefinedasapopulation-levelrandomvariable(atleast doesseem tohaveprovenitselfinourownclasses,offeringtherightbalancebetween specificityand compactness.\n8Rubin(2005,figure1)usesthegeneralnotation“v.”for“versus”todepictindividual-leveleffects intheirmostgeneralform.\nin most cases in observational data analysis), the treatment group and control group existinthepopulationaswellastheobserveddata.Throughoutthisbook,wewilluse this standard terminology, referring to treatment and control groups when discussing those who areexposedto alternative states ofa binary cause.If more thantwo causal states areofinterest, then we will shift to the semantics ofalternativetreatments and correspondingtreatmentgroups,therebydiscardingthebaselinelabelsofcontrolstate and control group.\nDespite our adoptionof this convention,we could rewrite all that follows referring tomembersofthe populationaswhatthey are–those whoareexposedtoalternative causalstates–andnotusethewordstreatmentandcontrolatall.Indeed,werecognize thatforsomereaderstheusageoftreatmentandcontrollanguagemayfeelsufficiently heterodox relative to the semantics of the areas in which they work that avoidance of these terms seems prudent. If so, it is perfectly acceptable to adopt parallel language without using the words treatment and control.\nWhen we refer to individuals in the observed treatment and control groups, we will again adopt the notational convention from statistics in which realized values for random variables are denoted by lowercase letters. Accordingly, the random variable D takes on values of di=1 for each individual i who is an observed member of the treatment group and di=0 for each individual i who is an observed member of the control group.\nGiven these definitions of Y1, Y0, and D (as well as their realizations y i1, y i0, di), we cannowdefine the observedoutcomevariableY interms ofthem. We canobserve valuesforavariableY asyi=y i1forindividualswithdi=1andasyi=y i0forindividuals with di=0. The observable outcome variable Y is therefore defined as Y =Y1 if D=1, Y =Y0 if D=0.\nThis paired definition is often written compactly as Y =DY1+(1−D)Y0. (2.2) Equation(2.2)impliesthatonecanneverobservethepotentialoutcomeunderthe treatmentstate for those observedin the control state, and one can never observe the potential outcome under the control state for those observed in the treatment state.\nThis impossibility implies that one can never calculate individual-level causal effects.\nHolland(1986)describesthischallengeasthefundamentalproblemofcausalinfer- ence in his widely readintroduction to the potential outcome model of counterfactual causality. Table 2.1 depicts the “problem,” which one might alternatively refer to as the “fundamental reality of causal analysis.” Causal effects are defined by contrasts within rows, which refer to groups of individuals observed in the treatment state or in the control state. However, only the diagonal of the table is observable, thereby rendering impossible the direct calculation of individual-level causal effects merely by means of observation and then subtraction.9 9AsTable2.1shows,wearemorecomfortablethansomewritersinusingthelabel“counterfactual” whendiscussingpotentialoutcomes.Rubin(2005),forexample,avoidsthetermcounterfactual,under the argument that potential outcomes become counterfactual only after treatment assignment has occurred.Thus,nopotentialoutcomeiseverexantecounterfactual.Weagree,ofcourse.But,because Table 2.1 The Fundamental Problem of Causal Inference Group Y1 Y0 Treatment group (D=1) Observableas Y Counterfactual Control group (D=0) Counterfactual Observableas Y As shown clearly in Equation (2.2), the outcome variable Y, even if we could enu- merate all of its individual-level values yi in the population, reveals only half of the information containedin the underlying potential outcome variables.Individuals con- tributeoutcomeinformationonlyfromthetreatmentstateinwhichtheyareobserved.\nThis is another way of thinking about Holland’s fundamental problem of causalinfer- ence. The outcome variables we must analyze – labor market earnings, test scores, and so on – contain only a portion of the information that would allow us to directly calculate causal effects for all individuals.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#the-average-treatment-effect",
    "href": "extracted/Counterfactuals and Causal Inference.html#the-average-treatment-effect",
    "title": "Counterfaturals and Causal Inference",
    "section": "2.4 The Average Treatment Effect",
    "text": "2.4 The Average Treatment Effect\nBecauseitistypicallyimpossibletocalculateindividual-levelcausaleffects,weusually\nfocus attention on the estimation of carefully defined aggregate causal effects. When weadoptthelineardifferenceinpotentialoutcomesasthedefinitionoftheindividual- level causal effect, we typically define aggregate causal effects as averages of these individual-level effects. These average causal effects can de defined for any subset of the population, and throughout this book we will consider many different average effects. In this section, we introduce the broadest possible average effect, which is the average treatment effect (ATE) in the population as a whole.\nWith E[.] denoting the expectation operator from probability theory, the average treatment effect in the population is E[δ]=E[Y1−Y0] (2.3) =E[Y1]−E[Y0].\nThesecondlineofEquation(2.3)followsfromthelinearityoftheexpectationoperator: The expectation of a difference is equal to the difference of the two expectations.10 For Equation (2.3), the expectation is defined with reference to the population of interest. For the fertility pattern example introduced in Section 1.3, the population wouldbe one or more birth cohortsof womenina particularcountry. For the election outcome examples, the population would be “all eligible voters”or “all eligible voters in Florida.” For other examples, such as the worker training example, the population ourfocus isonobservational dataanalysis,wefindthecounterfactual labelusefulforcharacterizing potential outcomes that are rendered unobservable ex post to the treatment assignment/selection mechanism.\n10However,atadeeperlevel,italsofollowsfromtheassumptionthatthecausaleffectisdefinedas alineardifferenceattheindividuallevel,whichallowstheapplicationofexpectations inthissimple waytocharacterize population-levelaverageeffects.\nwould be “all adults eligible for training,” and eligibility would need to be defined carefully. Thus, to define average causal effects and then interpret estimates of them, it is crucial that researchersclearly define the characteristics of the individuals in the assumed population of interest.11 Note also that the subscripting on i for the individual-level causal effect, δi, has been dropped for Equation (2.3). Even so, the definition of the ATE should not be interpreted to suggest that we now must assume that the treatment effect is constant in the population in any fundamental sense. Rather, we can drop the subscript i in Equation (2.3) because the expected causal effect of a randomly selected individual from the population is equal to the average causal effect across individuals in the population.Wewillattimesthroughoutthisbookreintroduceredundantsubscripting on i in order to reinforce the inherent individual-level heterogeneity of the potential outcomes and the causal effects they define.12 To see all of these pieces put together, consider the Catholic school example.\nThe potential outcome under the treatment, y1, is the what-if achievement outcome i of individual i if he or she were enrolled in a Catholic school. The potential out- come under the control, y0, is the what-if achievement outcome of individual i if i he or she were enrolled in a public school. Accordingly, the individual-level causal effect, δi, is the what-if difference in achievement that could be calculated if we could simultaneouslyeducateindividualiinbothaCatholicschoolandapublicschool.The ATE, E[δ], is then the average value among all students in the population of these what-if differences in test scores. The ATE is also equal to the expected value of the what-if difference in test scores for a randomly selected student from the population.\nAnalternativegroup-levelcausaleffectthatwewillnotconsidermuchinthisbook is the causal risk ratio, Pr[Y1=1] , (2.4) Pr[Y0=1] wherenowtheoutcomesY1 andY0 areindicatorvariablesequalto1iftheoutcomeof interest is present and 0 if not. This group-leveleffect is the analog to the individual- level ratio of potential outcomes, y1/y0, noted earlier in Section 2.2. The causal risk i i ratio is most frequently analyzedin epidemiology and the health sciences, where risk- factor analysis remains dominant and the outcomes are typically onset of a disease or a troubling symptom thereof (see Herna´n and Robins 2006a). For our purposes, most outcomesmodeledas causalrisk ratioscanbe translatedto averagetreatmenteffects, interpreting E[Y1]−E[Y0] as Pr(Y1 =1)−Pr(Y0 =1). Expectations of indicator variables are equivalent to probabilities of indicator variables, and an interval metric 11And,regardlessofthecharacterizationofthefeaturesofthepopulation,wewillassumethrough- out this book that the population is a realization of an infinite superpopulation. We discuss our decision to adopt this underlying population model in an appendix to this chapter. Although not essentialtounderstandingmostofthematerialinthisbook,somereadersmayfindithelpfultoread that appendix now in order to understand how these definitional issues are typically settled in this literature.\n12For example, at many times in the book, we willstress that quantities such as the ATE should not be assumed to be equal to the individual-level causal effect for any individual i, which we will expressasδ i(cid:2)=E[δ i]=E[δ]foralli.Inwords,whenindividual-levelheterogeneity ofcausaleffectsis present,individual-levelcausaleffects,δ i,willnotallbeequaltotheaverageoftheseindividual-level causaleffects,E[δ i],whichis,bythedefinitionoftheexpectation operator,equal toE[δ].\nisatleastassensibleasaratiometricforalloftheexampleswewillconsider.(Theratio metric might be preferable if we were attempting to make effect comparisons across outcomes with very different base rates, such as the effect of the same treatment on pancreatic cancer and hypertension.) ## 2.5 The Stable Unit Treatment Value Assumption\nIn most applications,the potential outcome model retains its tractability throughthe\nmaintenanceofastrongassumptionknownasthestableunittreatmentvalueassump- tion or SUTVA (see Rubin 1980b, 1986). In economics, a version of this assumption is sometimes referred to as a no-macro-effect or partial equilibrium assumption (see Garfinkel, Manski, and Michalopoulos 1992, Heckman 2000, 2005, for the history of these ideas, and Manski and Garfinkel 1992 for examples).13 SUTVA, as implied by its name, is a basic assumption of causal effect stability that requires that the potential outcomes of individuals be unaffected by changes in the treatment exposures of all other individuals. In the words of Rubin (1986:961), who developed the term, SUTVA is simply the a priori assumption that the value of Y for unit u when exposed to treatment t will be the same no matter what mechanism is used to assigntreatment t to unit u andno matter what treatments the other units receive.\nConsider the idealized example in Table 2.2, in which SUTVA is violated because the treatmenteffectvarieswithtreatmentassignmentpatterns.Fortheidealizedexample, therearethreerandomlydrawnsubjectsfromapopulationofinterest,andthestudyis designedsuchthatat leastone ofthe three study subjects mustreceivethe treatment and at least one must receive the control. The first column of the table gives the six possible treatmentassignmentpatterns.14 The firstrowofTable 2.2presents allthree ways to assign one individual to the treatment and the other two to the control, as well as the potential outcomes for each of the three subjects. Subtraction within the last column shows that the individual-level causal effect is 2 for all three individuals.\nThe second row of Table 2.2 presents all three ways to assign two individuals to the treatment and one to the control. As shown in the last column of the row, the individual-level causal effects implied by the potential outcomes are now 1 instead of 2. Thus, for this idealized example, the underlying causal effects are a function of the treatment assignment patterns, such that the treatment is less effective when more individuals areassignedtoit. ForSUTVA to hold, the potential outcomeswouldneed to be identical for both rows of the table.\n13SUTVAisamuchmalignedacronym,andmanyothersusedifferentlabels.Manski(2013a:S1),for example,hasrecentlylabeledthesameassumptionthe“individualistictreatmentresponse”assump- tioninorder“tomarkitasanassumptionthatrestrictstheformoftreatment responsefunctions.” 14Forthisexample,assumethatthevaluesofy1andy0foreachindividualiareeitherdeterministic i i potentialoutcomesorexactlyequaltoE[Y1]andE[Y0]foreachindividuali.Also,assumethatthese i i threesubjects compriseaperfectlyrepresentativesampleofthepopulation.\nTable 2.2 A Hypothetical ExampleinWhich SUTVAIs Violated Treatment assignment patterns Potential outcomes ⎡ ⎤ ⎡ ⎤ ⎡ ⎤ y1=3 y0=1 d =1 d =0 d =0 1 1 1 1 1 ⎣ d 2=0 ⎦ or ⎣ d 2=1 ⎦ or ⎣ d 2=0 ⎦ y 21=3 y 20=1 d =0 d =0 d =1 3 3 3 y1=3 y0=1 3 3 ⎡ ⎤ ⎡ ⎤ ⎡ ⎤ y1=2 y0=1 d =1 d =0 d =1 1 1 1 1 1 ⎣ d 2=1 ⎦ or ⎣ d 2=1 ⎦ or ⎣ d 2=0 ⎦ y 21=2 y 20=1 d =0 d =1 d =1 3 3 3 y1=2 y0=1 3 3 This type of treatment effect dilution is only one way in which SUTVA can be violated. More generally, suppose that d is an N × 1 vector of treatment indicator variablesforN individuals(analogoustothe treatmentassignmentvectorsinthe first column of Table 2.2), and define potential outcomes of each individual as functions acrossallpotentialconfigurationsoftheelementsofvectord.Accordingly,theoutcome for individual i under the treatment is y1(d), and the outcome for individual i under i the control is y0(d). The treatment effect for each individual i is then i δi(d)=y i1(d)−y i0(d). (2.5) With this more general setup, individual-level treatment effects could be different for every possible pattern of treatment exposure.\nSUTVA is what allows us to declare y1(d)=y1 and y0(d)=y0 and, as a result, i i i i assert that individual-level causal effects δi exist that are independent of the overall configurationofcausalexposure.IfSUTVA cannotbe maintained,thenthe simplified definitioninEquation(2.1)isinvalid,andtheindividual-leveltreatmenteffectmustbe writteninitsmostgeneralforminEquation(2.5),withallensuinganalysisproceeding conditional on alternative vectors d.\nSometimes it is argued that SUTVA is so restrictive that we need an alternative conception of causality for the social sciences. Our position is that SUTVA reveals the limitations of social science data and the perils of immodest causal modeling ratherthanthelimitationsofthepotentialoutcomemodelitself.Ratherthanconsider SUTVA as overly restrictive, researchers should always reflect on the plausibility of SUTVAineachapplicationandusesuchreflectiontomotivateacleardiscussionofthe meaning and scope of all causal effect estimates offered. Such reflection may lead one to determine that only the more general case of the potential outcome frameworkcan be justified, and this may necessitate building the analysis on top of the individual- level treatment effect defined in Equation (2.5) rather than the SUTVA-simplified variant in Equation (2.1). In some cases, however, analysis can proceed assuming SUTVA, as long as all resulting estimates are given restricted interpretations, as we now explain.\nTypical SUTVA violations share two interrelated features: (1) influence patterns that result from contact across individuals in social or physical space and (2) dilu- tion/concentration patterns that one can assume would result from changes in the prevalence of the treatment. Neither feature is entirely distinct from the other, andin manycasesdilution/concentrationeffects arisebecauseinfluence patternsarepresent.\nYet, ifthe violationcanbeinterpretedasadilution/concentrationpattern,evenwhen generatedinpartby anunderlyinginfluence pattern, then the analystcanproceedby scalingbacktheassertedrelevanceofanyestimatestosituationswheretheprevalence of the treatment is not substantially different.\nFor a simple example, consider the worker training example. Here, the plausibil- ity of SUTVA may depend on the particular training program. For small training programs situated in large labor markets, the structure of wage offers to retrained workers may be entirely unaffected by the existence of the training program. How- ever, for a sizable training program in a small labor market, it is possible that the wages on offer to retrained workers would be a function of the way in which the price of labor in the local labor market responds to the movement of trainees in and out of the program (as might be the case in a small company town after the company has just gone out of business and a training program is established). As a result, SUTVA may be reasonable only for a subset of the training sites for which data have been collected.\nFor an example of where influence patterns are more of a threat to SUTVA, con- sider the example of the Catholic school effect. For SUTVA to hold, the effectiveness of Catholic schooling cannot be a function of the number (and/or composition) of students who enter the Catholic school sector. For a variety of reasons – endogenous peer effects, capacity constraints, and so on – most school effects researchers would probablyexpect that the Catholic schooleffect wouldchangeif largenumbers ofpub- lic school students entered the Catholic school sector. As a result, because there are goodtheoreticalreasonstobelievethatthepatternofeffects wouldchangeifCatholic schoolenrollmentsballooned,itmaybethatresearcherscanestimatethecausaleffect of Catholic schooling only for those who would typically choose to attend Catholic schools, but also subject to the constraint that the proportion of students educated in Catholic schools remains constant. Accordingly, it may be impossible to determine from any data that could be collected what the Catholic school effect on achievement would be under a new distribution of students across school sectors that would result froma largeandeffective policy intervention.As a result, the implications of research on the Catholic school effect for research on school voucher programs may be quite limited, and this has not been clearly enough recognized by some (see Howell and Peterson 2002, chapter 6). A similar argument applies to research on charter school effects.\nConsider a SUTVA violationfor a related example: the evaluationof the effective- ness of mandatory school desegregationplans in the 1970son the subsequent achieve- ment of black students. Gathering together the results of a decade of research, Crain andMahard(1983)conductedameta-analysisof93studiesofthedesegregationeffect on achievement. They argued that the evidence suggests an increase of .3 standard deviations in the test scores of black students across all studies.15 It seems undeni- able that SUTVA is violatedfor this example, as the effect of moving fromone school to another must be a function of relative shifts in racial composition across schools.\nBreakingthe analysisintosubsetsofcitieswherethe compositionalshiftsweresimilar could yield conditional average treatment effect estimates that can be more clearly interpreted. In this case, SUTVA would be abandoned in the collection of all deseg- regation events, but it could then be maintained for some groups (perhaps in cities where the compositional shift was comparatively small).\nIn general, if SUTVA is maintained but there is some doubt about its validity because dilution or concentration patterns would emerge under shifts in treatment prevalence,thencertaintypesofmarginaleffectestimatescanusuallystillbedefended.\nThe idea here is to state that the estimates of average causal effects hold only for what-if movements of relatively small numbers of individuals from one hypothetical treatment state to another.\nIf,however,influencepatternsareinherenttothecausalprocessofinterest,andthe SUTVA violation cannot be considered as a type of dilution or concentration, then it will generally not be possible to circumvent the SUTVA violation by proceeding with thesameanalysisandonlyofferingcautiousandconditionalinterpretations.Themost well-developed literature on situations such as these is the literature on the effects of vaccine programs (see Hudgens and Halloran 2008). Here, additional causal effects of interest using the potential outcome framework have been defined, conditional on the overallpattern of treatment assignment: The indirect effect of a vaccination program or strategy on an individual is the difference between what the outcome is in the individual not being vaccinated in a community with the vaccination program and what the outcome would have been in the individual, again not being vaccinated, but in a comparable community with no vaccination program. It is, then, the effect of the vaccination program on an individual who was not vacci- nated. The combined total effect in an individual of being vaccinated and the vaccination program in the community is the difference between the outcomeintheindividualbeingvaccinatedinacommunitywiththevacci- nationprogramand whatthe outcomewouldbe if the individual werenot vaccinatedand the community did not havethe vaccinationprogram.The total effect, then, is the effect of the vaccination program combined with theeffectofthepersonhavingbeenvaccinated.Theoverall effect ofavac- cination programis the difference in the outcome in an averageindividual 15As reviewed by Schofield (1995) and noted in Clotfelter (2004), most scholars now accept that the evidence suggests that black students who were bused to predominantly white schools experi- encedsmallpositivereadinggainsbutnosubstantialmathematicsgains.CookandEvans(2000:792) conclude that “it is unlikely that efforts at integrating schools have been an important part of the convergenceinacademicperformance[betweenwhitesandblacks],atleastsincetheearly1970s”(see also Armor 1995; Rossell, Armor, and Walberg 2002). Even so, others have argued that the focus ontest scoregains hasobscured someofthe trueeffectiveness ofdesegregation. Inareview ofthese longer-termeffects,WellsandCrain(1994:552) concludethat“interracialcontactinelementaryand secondaryschoolcanhelpblacksovercomeperpetualsegregation.” inacommunitywiththevaccinationprogramcomparedtoanaverageindi- vidualinacomparablepopulationwithnovaccinationprogram.(Halloran, Longini, and Struchiner 2010:272;italics in the original) Effectively estimating these types of effects generally requires a nested randomization structure, wherein (1) vaccine programs are randomly assigned to a subset of par- ticipating groups and then (2) vaccinations are randomly given to individuals within groups enrolled in vaccine programs. These particular study designs are not possible for most social science applications, but the basic interpretive framework has been adopted to clarify what can be learned from social experiments, in particular, the Moving to Opportunity neighborhood experiment (see Sobel 2006).16 Much observational researchon social influence patterns proceeds without consid- erationofthese sortsofcomplications.Considerthe contentiousliteratureonwhether peer effects have accelerated the obesity epidemic, as presented in Section 1.3 (see page 26). As we noted there, the basic claim of Christakis and Fowler (2007) is that having a friend who becomes obese increases one’s own odds of becoming obese. Yet, theirfullsetofclaimsissubstantiallymoredetailed,suggestingthatthesepeereffects travelacrossnetwork paths of length three before dying out. In particular,one’s odds of becoming obese also increase if friends of friends become obese and if friends of friends of friends become obese. The sizes of these three effects diminish with the length of friendship distance.\nNow consider whether SUTVA is reasonable for such a schedule of effects across network ties. Holding the social network structure fixed, if obesity increases in the population,then,onaverage,individualshavemoreobesefriends,moreobesefriendsof friends,andmoreobesefriendsoffriendsoffriends.Mosttheoreticalpredictionswould suggest that the effects on one’s own odds of becoming obese that result from having friends of friends of friends who become obese should decline with the proportion of one’s own friends who are already obese or who have just become obese.17 Effects that cascade in these conditional ways, because they are defined across a pattern of interpersonal contact between units, nearly always violate SUTVA.18 16Suitablemodelsforobservationaldataareanactivefrontierofresearch(seeHongandRaudenbush 2013; Manski 2013a). Tchetgen Tchetgen and VanderWeele (2010) show that some estimators may be effective for applications withobservational data if allrelevant patterns of treatment assignment (i.e.,d)canbeattributed tomeasuredtreatment-level variables.\n17Thismeansthat,eveniftheissuesraisedbycriticsontheseverityofhomophilybiasareinvalid (seeVanderWeele2011bforaconvincingcasethattheyhavebeenexaggerated),thepatternofeffects only holds under the prevalence of obesity in the data analyzed, which is the pattern of obesity in Framingham, Massachusetts, among adults bornin1948 forwhom data wascollected between 1971 and 1999 (and for a social network structure elicited by an unconventional name generator). The overall pattern of declining effects may be valid, but the relation of the various lagged regression coefficients offeredtowell-definedcausaleffects ofgeneralinterestmayberatherthin.\n18Whenwehaveconveyedthispointtonetworkanalysisresearchers,acommonreactionisthatthe potential outcome model must not, therefore, be suitable for studying causal effects that propagate across networks. The logic of this position eludes us for two reasons. First, the potential outcome model cannot bedeemed inappropriatebecause itmakes clearhow harditistodefine andestimate theeffects that analysts claimthatthey wishtoestimate. Second, thepotential outcome model can accommodate SUTVA violations, although not without considerable additional effort. Weihua An (2013) demonstrates the value of counterfactual thinking for modeling peer effects, fully embedded withinasocialnetworkperspective(seealsoVanderWeeleandAn2013).",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#treatment-assignment-and-observational-studies",
    "href": "extracted/Counterfactuals and Causal Inference.html#treatment-assignment-and-observational-studies",
    "title": "Counterfaturals and Causal Inference",
    "section": "2.6 Treatment Assignment and Observational Studies",
    "text": "2.6 Treatment Assignment and Observational Studies\nA researcher who wishes to estimate the effect of a treatment that he or she can con-\ntrol on an outcome of interest typically designs an experiment in which subjects are randomly assignedto alternativetreatment and controlgroups.Other types of exper- iments are possible, as we described in Chapter 1, but randomized experiments are the most common research design when researchers have control over the assignment of the treatment.\nAfter randomizationofthe treatment,the experimentis run,andthe values ofthe observed outcome, yi, are recorded for those in the treatment group and for those in thecontrolgroup.Themeandifferenceintheobservedoutcomesacrossthetwogroups is then anointed the estimated average causal effect, and discussion (and any ensuing debate)then movesonto the particularfeatures of the experimentalprotocoland the degree to which the pool of study participants reflects the population of interest for which one would wish to know the average treatment effect.\nConsiderthisrandomizationresearchdesignwithreferencetotheunderlyingpoten- tial outcomes defined earlier. For randomized experiments, the treatment indicator variable D is forced by design to be independent of the potential outcome variables Y1 and Y0. (However, for any single experiment with a finite set of subjects, the values of di will be related to the values of y i1 and y i0 because of chance variability.) Knowingwhether ornotasubjectis assignedto the treatmentgroupin arandomized experimentyieldsnoinformationwhatsoeveraboutasubject’swhat-ifoutcomeunder the treatment state, y1, or, equivalently, about a subject’s what-if outcome under the i controlstate,y0.Treatmentstatusisthereforeindependentofthepotentialoutcomes, i andthetreatmentassignmentmechanismissaidtobeignorable.19 Thisindependence assumption is usually written as (Y0,Y1)⊥⊥ D, (2.6) where the symbol ⊥⊥ denotes independence and where the parentheses enclosing Y0 and Y1 stipulate that D must be jointly independent of all functions of the potential outcomes (such as δ). For a properly run randomized experiment, learning the treat- ment to which a subject has been exposedgives no informationwhatsoever about the size of the treatment effect.\nThis way of thinking about randomized experiments and potential outcomes can be confusing to social scientists who work primarily with observational data. The independence relationships represented by Equation (2.6) seem to imply that even a well-designed randomized experiment cannot tell us about the causal effect of the treatment on the outcome of interest. But, of course, this is not so, because Equation (2.6) does not imply that D is independent of Y.Equation ( 2.6) implies only that in the full population, ex ante to any patternoftreatmentassignment,D is independent ofY0, Y1, andany causaleffects defined fromthem. Only after a study is undertaken 19Aswewilldiscussindetailinlaterchapters,theword“ignorability”hasaveryspecificmeaning thatisbroaderthanimpliedinthisparagraph.Inshort,ignorabilityalsoholdsintheweakersituation in which S is a set of observed variables that characterize treatment assignment patterns and in which(Y0,Y1)⊥⊥ D | S.Thus, treatment assignment is ignorablewhen the potential outcomes are independentofD,conditionalonS.\ndo values for Y emerge, from Y =DY1+(1−D)Y0 in Equation (2.2). If individuals are randomly assigned to both the treatment and the control states, and individual causal effects are nonzero, then Y and D will be dependent because the averagevalue of DY1 will not be equal to the average value of (1−D)Y0.\nNowconsidertheadditionalchallengesposedbyobservationaldataanalysis.These challenges to causal inference are the defining features of an observational study, according to Rosenbaum (2002:vii): An observational study is an empiric investigation of treatments, policies, or exposures and the effects they cause, but it differs from an experiment in that the investigator cannot control the assignment of treatments to subjects.20 (Italics in the original) Observational data analysis in the counterfactual tradition is thus defined by a lack of control over the treatment – and often more narrowly by the infeasibility of ran- domizationdesignsthatallowforthestraightforwardmaintenanceoftheindependence assumptioninEquation(2.6).Anobservationalresearcher,hopingtoestimateacausal {yi,di}N effect, begins with observed data in the form of values for an observed out- i comevariable,Y,andatreatmentstatusvariable,D.Todeterminethecausalofeffect ofDonY,thefirststepinanalysisistoinvestigatethetreatmentselectionmechanism.\nNoticetheswitchinlanguagefromassignmenttoselection.Becauseobservationaldata analysisisdefinedasempiricalinquiryinwhichtheresearcherdoesnothavethecapac- itytoassignindividualstotreatments(or,asRosenbaumstatesequivalently,toassign treatments to individuals), researchers must instead investigate how individuals are selected into alternative treatment states.\nAnd herein lies the challenge of much scholarship in the social sciences. Although someoftheprocessbywhichindividualsselectalternativetreatmentscanbeexamined empirically, a full accounting of treatment selection is sometimes impossible (e.g., if subjects are motivated to select on the causal effect itself and a researcher does not have a valid measure of the expectations that determine their choices). As much as this challenge may be depressing to a dispassionate policy designer/evaluator, this predicamentshould not be depressingfor social scientists in general.On the contrary, our existential justification rests on the pervasive need to deduce theoretically from a setofbasicprinciplesorinferfromexperienceandknowledgeofrelatedstudiestheset of defendable assumptions about the missing components of the treatment selection mechanism. Only through such effort can it be determined whether causal analysis can proceed or whether further data collection and preliminary theoretical analysis are necessary.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#average-causal-effects-and-naive-estimation",
    "href": "extracted/Counterfactuals and Causal Inference.html#average-causal-effects-and-naive-estimation",
    "title": "Counterfaturals and Causal Inference",
    "section": "2.7 Average Causal Effects and Naive Estimation",
    "text": "2.7 Average Causal Effects and Naive Estimation\nThefundamentalproblemofcausalinferencerequiresthatwefocusonnon–individual-\nlevel causal effects, maintaining assumptions about treatment assignment and treat- mentstabilitythatwillallowustogivecausalinterpretationstodifferencesinaverage 20NotethatRosenbaum’sdefinitionisconsistentwiththeCoxandReiddefinitionquotedinChapter 1(seepage7).\nvaluesofobservedoutcomes.Intheremainderofthischapter,wedefineaveragetreat- ment effects of varying sorts and then lay out the complications of estimating them.\nInparticular,we considerhow averagetreatmenteffects varyacrossthose whoreceive the treatment and those who do not.\n2.7.1 Conditional Average Treatment Effects The unconditional average treatment effect, which is typically labeled the ATE in the counterfactual tradition, wasdefined in Equation(2.3) as E[δ]=E[Y1−Y0]. This averageeffectisthemostcommonsubjectofinvestigationinthesocialsciences,andit is the causaleffect thatis closestto the sortsof effects investigatedinthe broadfoun- dationalexamplesintroducedinSection1.3.1,suchastheeffectsoffamilybackground and mental ability on educational attainment, the effects of educational attainment and mental ability on earnings, and the effects of socioeconomic status on political participation. More narrowly defined average causal effects are of interest as well in virtually all of the other examples introduced in Chapter 1.\nTwo conditional average treatment effects are of particular interest. The average treatment effect for those who typically take the treatment is E[δ|D=1]=E[Y1−Y0|D=1] (2.7) =E[Y1|D=1]−E[Y0|D=1], and the average treatment effect for those who typically do not take the treatment is E[δ|D=0]=E[Y1−Y0|D=0] (2.8) =E[Y1|D=0]−E[Y0|D=0], where, as for the ATE in Equation (2.3), the second line of each definition follows from the linearity of the expectation operator. These two conditional average causal effectsareoftenreferredtoby theacronymsATT andATC,whichsignifythe average treatment effect for the treated and the average treatment effect for the controls, respectively.\nConsider the examples again. For the Catholic school example, the ATT is the average effect of Catholic schooling on the achievement of those who typically attend Catholicschoolsratherthanacrossallstudents who couldpotentially attendCatholic schools. The difference between the ATE and the ATT can also be understood with reference to individuals. From this perspective, the average treatment effect in Equa- tion (2.3) is the expected what-if difference in achievement that would be observed if we could educate a randomly selected student in both a public school and a Catholic school. In contrast, the ATT in Equation (2.7) is the expected what-if difference in achievementthatwouldbe observedif we couldeducate a randomlyselected Catholic school student in both a public school and a Catholic school.\nFor this example, the ATT is a theoretically important quantity, for if there is no Catholic school effect for Catholic school students, then most reasonable theoretical arguments would maintain that it is unlikely that there would be a Catholic school effect for students who typically attend public schools (at least after adjustments for observable differences between Catholic and public school students). And, if policy interest were focused on whether or not Catholic schooling is beneficial for Catholic schoolstudents(andthuswhetherpublicsupportoftransportationtoCatholicschools is a benevolent government expenditure, etc.), then the Catholic school effect for Catholic school students is the only quantity we would want to estimate. The ATC would be of interestas well if the goalof analysis is ultimately to determine the effect of a potential policy intervention, such as a new school voucher program, designed to move more students out of public schools and into Catholic schools. In fact, an even narrower conditional average treatment effect might be of interest: E[δ|D=0, Cur- rentSchool = Struggling], where of course the definition of being currently educated in a struggling school would have to be clearly specified.\nThe worker training example is similar, in that the subject of first investigation is surely the ATT (as discussed in detail in Heckman et al. 1999). If a cost-benefit analysis of a program is desired, then a comparison of the aggregate net benefits for thetreatedtotheoverallcostsoftheprogramtothefundersisneeded.Thetreatment effect for other potential enrollees in the treatment program could be of interest as well, but this effect is secondary (and may be impossible to estimate for groups of individuals completely unlike those who have enrolled in the program in the past).\nThe butterfly ballot example is somewhat different. Here, the treatment effect of interest is bound by a narrow question that was shaped by media attention. The investigatorswereinterestedonly inwhatactually happenedinthe 2000election,and they focused very narrowly on whether the effect of having had a butterfly ballot rather than an optical scan ballot caused some individuals to miscast their votes.\nAnd, in fact, they were most interested in narrow subsets of the treated, for whom specific assumptions were more easily asserted and defended (e.g., those who voted for Democrats in all other races on the ballot but who voted for Pat Buchanan or Al Gore for president). In this case, the ATC, and hence the all-encompassingATE, was of little interest to the investigators (or to the contestants and the media).\nAs these examples demonstrate, more specific averagecausal effects (or more gen- eral properties of the distribution of causal effects) are often of greater interest than simply the average causal effect in the population. In this book, we will focus mostly on the three types of averagecausal effects representedby Equations (2.3), (2.7), and (2.8), as well as simple conditional variants of them. But, especially when presenting instrumental variable estimators later and discussing general heterogeneity issues, we willalsofocusonmorenarrowlydefinedcausaleffects.Heckman(2000),Manski(1995), andRosenbaum(2002)allgivefulldiscussionsofthevarietyofcausaleffectsthatmay be relevant for different types of applications, such as quantiles of the distribution of individual-levelcausaleffectsinsubpopulationsofinterestandtheprobabilitythatthe individual-levelcausaleffectisgreaterthanzeroamongthetreated(seealsoHeckman, Smith, and Clements 1997).\n2.7.2 Naive Estimation of Average Treatment Effects Suppose again that randomization of the treatment is infeasible and thus that only an observational study is possible. Instead, an autonomous fixed treatment selection regime prevails, where π is the proportion of the population of interest that takes the treatment instead of the control. In this scenario, the value of π is fixed in the populationbythebehaviorofindividuals,anditisunknown.Suppose furtherthatwe haveobservedsurvey data from a relativelylarge randomsample of the population of interest.\nBecausewearenowshifting fromthepopulationtodatageneratedfromarandom sample of the population, we must use appropriate notation to distinguish sample- based quantities from the population-based quantities that we have considered until now. For the sample expectation of a quantity in a sample of size N, we will use a subscript on the expectation operator, as in EN[.]. With this notation, EN[di] is the sample mean of the dummy treatment variable, EN[yi|di=1] is the sample mean of theoutcomeforthoseobservedinthetreatmentgroup,andEN[yi|di=0]isthesample mean of the outcome for those observed in the control group.21 The naive estimator is then defined as δˆ NAIVE≡EN[yi|di=1]−EN[yi|di=0], (2.9) which is simply the difference in the sample means of the observed outcome variable Y for the observed treatment and control groups.\nIn observational studies, the naive estimator rarely yields consistent or unbiased estimates of the ATE because it converges to a contrast, E[Y|D=1]−E[Y|D=0], that is not equivalent to (and usually not equal to) any of the average causal effects defined above. To see why, first decompose the ATE in Equation (2.3) as E[δ]={πE[Y1|D=1]+(1−π)E[Y1|D=0]} (2.10) −{πE[Y0|D=1]+(1−π)E[Y0|D=0]}.\nEquation(2.10)revealsthattheATEisafunctionoffiveunknowns:theproportionof the population that is assigned to (or self-selects into) the treatment along with four conditional expectations of the potential outcomes.\nWith observational data from a random sample of the population and without introducing additional assumptions, we can compute estimates that are consistent and unbiased for only three of the five unknowns on the right-hand side of Equation (2.10). Consider π first, which we have defined as equal to E[D], and which is the fixedproportionofthe populationthatwouldbe assignedto(orwouldselectinto)the treatment. The sample-mean estimator, EN[di], is consistent for π, which we write as p EN[di]−→π. (2.11) Equation(2.11)representstheclaimthat,asthesamplesizeN increasestoinfinity,the sample mean of the values for di convergesto the true value of π, which we assume is p afixedpopulationparameterequalexactlyto E[D].22 Thus,thenotation−→denotes convergencein probability for a sequence of estimates overa set of samples where the sample size N is increasing to infinity. (Estimators with this property are defined as 21In other words, the subscript N serves the same basic notational function as an overbar on y i, asiny¯i.Weusethissub-N notationbecauseitallowsforgreaterclarityinaligningsample-leveland population-levelconditional expectations forsubsequentexpressions.\n22Again,seeourappendixtothischapteronourassumedsuperpopulationmodel.Weareimplicitly assuming that these sequences are well defined because conditions are such that the law of large numbersisapplicable.\n“consistent” in the statistical literature on estimation. We can also state that EN[di] is unbiased for π because the expected value of EN[di] over repeated samples of size N from the same population is equal to π as well. However, in this book we focus primarily on the consistency of estimators.)23 We can offer similar claims for consistent estimators of two other unknowns in Equation (2.10): p EN[yi|di=1]−→E[Y1|D=1], (2.12) p EN[yi|di=0]−→E[Y0|D=0], (2.13) which indicate that the sample mean of the observedoutcome in the treatment group converges to the true average outcome under the treatment state for those in the treatment group (and analogously for the control group and control state).\nUnfortunately, however, there is no assumption-free way to compute consistent or unbiased estimates of the two remaining unknowns in Equation (2.10): E[Y1|D= 0] and E[Y0|D=1]. These are counterfactual conditional expectations: the average outcome under the treatment for those in the control group and the averageoutcome under the control for those in the treatment group. Without further assumptions, no estimatedquantitybasedonobserveddatafromarandomsampleofthepopulationof interestwouldconvergetothetruevaluesfortheseunknowncounterfactualconditional expectations. For the Catholic school example, these are the average achievement of public school students if they had instead been educated in Catholic schools and the average achievement of Catholic school students if they had instead been educated in public schools.\n2.7.3 The Typical Inconsistency and Bias of the Naive Estimator In the last section, we concluded that the naive estimator δˆ , which is defined NAIVE as EN[yi|di=1]−EN[yi|di=0], converges to a contrast, E[Y1|D=1]−E[Y0|D=0], that does not necessarily equal the ATE. In this section, we show why this contrast can be uninformative about the causal effect of interest in an observational study by analyzing the typical inconsistency and bias in the naive estimator as an esti- mator of the ATE.24 Consider the following rearrangement of the decomposition in 23Nonetheless, we willoften label estimators as “consistent and unbiased” when this is true, even though we will not state the case for unbiasedness. On the one hand, estimators of fixed, finite values in the population that are consistent are necessarily also asymptotically unbiased. On the otherhand,someconsistentestimatorsarenotunbiasedinfinitesamples(mostprominently,forthis book,theinstrumentalvariableestimatorsthatwewillpresentinChapter9).Aswiththestatistical literatureonpointestimation,wetypicallyinterpretunbiasednessasadesirablepropertyamongthe consistentestimatorsthatwewillpresent.Ifanestimatorisnotconsistent(i.e.,isinconsistent),then inpractice thereislittlereasontofurther considerit(as unbiased, etc.), especiallywheninvokinga superpopulationperspectiveandassumingthatadataset foralargerandomsampleisavailable.\n24Animportantpointofthisliteratureisthattheinconsistencyandbiasofanestimatorisafunction of the target parameter that has been selected for analysis. Because there are many causal effects that can be estimated, general statements about the inconsistency andbias of particular estimators arealwaysconditionalonaclearindicationofthecausaleffectofinterest.\nEquation (2.10): E[Y1|D=1]−E[Y0|D=0]=E[δ]+{E[Y0|D=1]−E[Y0|D=0]} (2.14) + (1−π){E[δ|D=1]−E[δ|D=0]}.\nThe naive estimator converges to the difference on the left-hand side of this equa- tion, and the right-hand side shows that this difference is equal to the true ATE, E[δ], plus the expectations of two potential sources of inconsistency and bias in the naive estimator.25 The first source, {E[Y0|D=1]−E[Y0|D=0]}, is a baseline bias equal to the difference in the expected outcome in the absence of the treat- ment between those in the treatment group and those in the control group. The sec- ond source, (1−π){E[δ|D=1]−E[δ|D=0]}, is a differential treatment effect bias equal to the expected difference in the treatment effect between those in the treat- ment group and those in the control group (multiplied by the proportion of the population under the fixed treatment selection regime that does not select into the treatment).\nToclarifythisdecomposition,considerasubstantiveexample–theeffectofeduca- tiononanindividual’smentalability.Assumethatthetreatmentiscollegeattendance.\nAfter administering a test to a group of young adults, we find that individuals who have attended college score higher than individuals who have not attended college.\nThere are three possible reasons that we might observe this finding. First, attending collegemightmakeindividualssmarteronaverage.ThiseffectistheATE,represented by E[δ] in Equations (2.3) and (2.14). Second, individuals who attend college might have been been smarter in the first place. This source of inconsistency and bias is the baseline difference represented by E[Y0|D=1]−E[Y0|D=0]. Third, the mental ability of those who attend college may increase more than would the mental abil- ity of those who did not attend college if they had instead attended college. This source of inconsistency and bias is the differential effect of the treatment represented by E[δ|D=1]−E[δ|D=0].\nTofurtherclarifythelastterminthedecomposition,considerthealternativehypo- thetical example depicted in Table 2.3. Suppose, for context, that the potential out- comesarenowsomeformoflabormarketoutcome,andthatthetreatmentiswhether ornotanindividualhasobtainedabachelor’sdegree.Suppose furtherthat30percent of the population obtains a bachelor’s degree, such that π is equal to .3. As shown on themaindiagonalofTable2.3,theaverage(orexpected)potentialoutcomeunderthe treatmentis10forthoseinthetreatmentgroup,andtheaverage(orexpected)poten- tial outcome under the control for those in the control group is 5. Now, consider the off-diagonalelementsofthetable,whichrepresentthecounterfactualaveragepotential outcomes. According to these values, those who have bachelor’s degrees would have done better in the labor marketthan those without bachelor’sdegrees in the counter- factual state in which they did not in fact obtain bachelor’s degrees (i.e., on average theywouldhavereceived6insteadof5).Likewise,thosewhodonotobtainbachelor’s 25The referenced rearrangement is simply a matter of algebra. Let E[δ]=e, E[Y1|D=1]=a, E[Y1|D=0]=b,E[Y0|D=1]=c,andE[Y0|D=0]=dsothatEquation(2.10)canbewrittenmore compactlyase={πa+(1−π)b}−{πc+(1−π)d}. Rearrangingthisexpressionasa−d=e+a−b− πa+πb+πc−πdthen simplifiesto a−d=e+{c−d}+{(1−π)[(a−c)−(b−d)]}.Substituting for a,b,c,d,andethenyieldsEquation(2.14).\nTable 2.3 An Example of Inconsistency and Bias of the Naive Estimator When the ATE Is the Causal Effect of Interest Group E[Y1|D] E[Y0|D] Treatment group (D=1) 10 6 Control group (D=0) 8 5 degreeswould not havedone as wellas those who did obtain bachelor’sdegreesin the counterfactual state in which they did in fact obtain bachelor’s degrees (i.e., on aver- age they would have received 8 rather than 10). Accordingly, the ATT is 4, whereas the ATC is only 3.26 Finally, if the proportionof the population that has a bachelor’s degree is .3, then the ATE is 3.3, which is equal to .3(10−6)+(1−.3)(8−5).\nConsider now the inconsistency and bias of the naive estimator. For this exam- ple, the naive estimator, as defined in Equation (2.9), would be equal to 5 for an infinite sample (or equal to 5, on average, across repeated samples). Thus, the naive estimator is inconsistent and upwardly biased for the ATE (i.e., yielding 5 rather than 3.3), the ATT (i.e., yielding 5 rather than 4), and the ATC (i.e., yielding 5 rather than 3). Equation (2.14) gives the components of the total expected bias of 1.7 for the naive estimator as an estimate of the ATE. The term {E[Y0|D=1]− E[Y0|D=0]},whichwe labeledthe expected baselinebias, is 6−5=1.The term(1− π){E[δ|D=1]−E[δ|D=0]},whichistheexpecteddifferentialtreatmenteffectbias,is (1−.3)(4−3)=.7.27 2.7.4 Estimating Causal Effects Under Maintained Assumptions About Potential Outcomes What assumptions suffice to enable consistent and unbiased estimation of the ATE withthe naiveestimator?Therearetwobasicclassesofassumptions:(1)assumptions about potential outcomes for subsets of the population defined by treatment status and (2) assumptions about the treatment assignment/selection process in relation to thepotentialoutcomes.Thesetwotypesofassumptionsarevariantsofeachother,and eachmayhaveaparticularadvantageinmotivatinganalysisinaparticularapplication.\nIn this section, we discuss only the first type of assumption, as it suffices for the presentexaminationofthefallibilityofthenaiveestimator.Andourpointinintroduc- ingtheseassumptionsissimplytoexplaininonefinalwaywhythenaiveestimatorwill fail in most social science applications to generate a consistent and unbiased estimate of the ATE when randomization of the treatment is infeasible.\n26Forthecausaleffectofeducationonearnings,thereisdebateintherecentliteratureonwhether theATTislargerthan theATC.CunhaandHeckman(2007) andCarneiro,Heckman, andVytlacil (2011) offer results in support of this pattern, but Brand and Xie (2010) offer results in opposition toit.\n27In general, the size of this expected differential treatment effect bias declines as more of the populationischaracterizedbytheATTthanbytheATC(i.e.,asπ approaches 1).\nConsider the following two assumptions: Assumption 1: E[Y1|D=1]=E[Y1|D=0], (2.15) Assumption 2: E[Y0|D=1]=E[Y0|D=0]. (2.16) Ifone assertsthese twoequalities andthensubstitutes intoEquation(2.10), the num- ber of unknowns is reduced from the original five parameters to the three parameters that we know from Equations (2.11)–(2.13) can be consistently estimated with data generated from a random sample of the population. If both Assumptions 1 and 2 are maintained, then the ATE, ATT, and ATC in Equations (2.3), (2.7), and (2.8), respectively, are all equal. And the naive estimator is consistent and unbiased for all of them.\nWhen would Assumptions 1 and 2 in Equations (2.15) and (2.16) be reasonable? Clearly, if the independence of potential outcomes, as expressed in Equation (2.6), is valid because the treatment has been randomly assigned, then Assumptions 1 and 2 in Equations (2.15) and (2.16) are implied. But, for observational data analysis, for which random assignment is infeasible, these assumptions would rarely be justified.\nConsidertheCatholicschoolexample.Ifonewerewillingtoassumethatthosewho choosetoattendCatholicschoolsdosoforcompletelyrandomreasons,thenthesetwo assumptions could be asserted. We know from the applied literature that this char- acterization of treatment selection is false. Nonetheless, one might be able to assert insteadaweakernarrativetowarrantthesetwoassumptions.Onecouldmaintainthat studentsandtheir parentsmakeenrollmentdecisionsbasedontastesforaneducation with a religious foundation and that this taste is unrelated to the two potential out- comes, such that those with a taste for education with a religious foundation would not be expected to score higher on math and reading tests if educated in Catholic schoolsratherthanpublicschools.Thispossibilityalsoseemsunlikely,inpartbecause it implies that those with a distaste for education with a religious foundation do not attendCatholicschools.It seemsreasonabletoassumethatthese students wouldper- form substantially worse in Catholic schools than the typical students who do attend Catholic schools.\nThus, at least for the Catholic school example, there seems no way to justify the naiveestimator as a consistentandunbiasedestimator of the ATE. We encouragethe readerto consider all of the examples presentedin Chapter 1, and we suspect that all will agree that Assumptions 1 and 2 in Equations (2.15) and (2.16) cannot both be sustained for any of them.\nFinally,itisimportanttorecognizethatassumptionssuchasthesecanbeevaluated separately. Consider the two relevant cases for Assumptions 1 and 2: 1. If Assumption 1 is true but Assumption 2 is not, then E[Y1|D=1]=E[Y1| D=0], whereas EY0|D=1=E[Y0|D=0]. In this case, the naive estimator remains inconsistent and biased for the ATE, but it is now consistent and unbi- ased for the ATC. This result is true because of the same sort of substitution we notedearlier.We know thatthe naiveestimatorEN[yi|di=1]−EN[yi|di=0] converges to E[Y1|D=1]−E[Y0|D=0]. If Assumption 1 is true, then one can substitute E[Y1|D=0]for E[Y1|D=1]. Then, one canstate thatthe naiveesti- mator convergesto the contrastE[Y1|D=0]−E[Y0|D=0]when Assumption 1 is true. This contrast is defined in Equation (2.8) as the ATC.\n\nIfAssumption2istruebutAssumption1isnot,thenE[Y0|D=1]=E[Y0|D=0], whereasEY1|D=1=E[Y1|D=0].Theoppositeresulttothepriorcasefollows.\n\nOne can substitute E[Y0|D=1] for E[Y0|D=0] in the contrast E[Y1|D=1]− E[Y0|D =0]. Then, one can state that the naive estimator converges to the contrastE[Y1|D=1]−E[Y0|D=1]whenAssumption 2is true. This contrastis defined in Equation (2.7) as the ATT.\nConsidering the validity of Assumptions 1 and 2 separately shows that the naive esti- mator may be inconsistent and biased for the ATE and yet may be consistent and unbiasedforeithertheATTortheATC.Thesepossibilitiescanbe importantinprac- tice. For some applications, it may be the case that we have good theoretical reason to believe that (1) Assumption 2 is validbecause those in the treatmentgroupwould, on average, do no better or no worse in the counterfactual control state than those in the control group, and (2) Assumption 1 is invalid because those in the control group would not do nearly as well in the counterfactual treatment state as those in the treatment group. Or, stated more simply, we may have goodtheoretical reasonto believe that the treatment is more effective for the treatment group than it would be forthecontrolgroup.Underthisscenario,the naiveestimatorwilldeliveraconsistent and unbiased estimate of the ATT, even though it is still inconsistent and biased for both the ATC and the unconditional ATE.\nNow,returntothecaseinwhichneitherAssumption1norAssumption2istrue.If the naive estimator is therefore inconsistent and biased for the typical average causal effects of interest, what can be done? The first recourse is to attempt to partition the sample into subgroups within whichassumptions suchas Assumptions 1 and/or2 canbe defended. This strategyamounts toconditioning ononeormore variablesthat identifysuchstrataandthenassertingthatthenaiveestimatorisconsistentandunbi- asedwithinthesestrataforoneoftheaveragetreatmenteffects.Onecanthenaverage estimates from these strata in a reasonable way to generate the average causal effect estimate of interest. We will explain this strategy in great detail in subsequent chap- ters.Next, weintroduceover-timepotentialoutcomesandthenextendthe framework to many-valued causes.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#over-time-potential-outcomes-and-causal-effects",
    "href": "extracted/Counterfactuals and Causal Inference.html#over-time-potential-outcomes-and-causal-effects",
    "title": "Counterfaturals and Causal Inference",
    "section": "2.8 Over-Time Potential Outcomes and Causal Effects",
    "text": "2.8 Over-Time Potential Outcomes and Causal Effects\nHaving shown in the last section that the cross-sectional naive estimator will rarely\ndeliver consistent and unbiased estimates of average causal effects of interest when analyzing observational data, it is natural to then wonder whether observing individ- uals across time and then estimating similar unconditional differences may be more promising. We will take the position in this book that the power of over-time obser- vationis considerablebut that it is also too oftenoversoldand misunderstood. Inthis section,welayoutthebasicpotentialoutcomemodelwhenobservationsoccurinmore than one time period, moving from the case of a single individual or unit to multiple individuals or units. We reserve our full treatment of the strengths and weaknesses of alternative estimators using repeated observations for Chapter 11.\n2.8.1 A Single Unit Over Time Consider the analysis of a single unit, observed during time intervals indexed by a discrete counter t that increases from 1 to T. The outcome variable is Yt, which has observed values {y 1,y 2,y 3,…,yT}. Suppose that we have a two-state causal variable, Dt, that is equal to 1 if the treatment is in place during a time period t and is equal to 0 otherwise.\nBecause we are considering only one unit of analysis – possibly an individual but morelikely aschool,organization,city,state,country,orotheraggregateunit –wedo not have either a control group or a treatment group. Instead, we have a single unit thatisexposedtothetreatmentstateandthecontrolstateatdifferentpointsintime.\nThe fundamental problem/reality of causal inference now is that we cannot observe the same unit at the same time in both the treatment state and the control state.\nFor an analysis of a single unit, it only makes sense to consider designs where we have at least some pretreatment data and where the unit under consideration spends at least one time period in the treatment state. In particular, we will label the time period in which the treatment is initiated as t∗, and our restriction to situations in which pretreatment data are available requires that 1&lt;t∗ ≤T. We will allow the treatment to persist for one or more time periods, from t∗ through t∗+k, where k≥0.Oncethe treatmentends, followingt∗+k, wewill notallowthe treatmentto be reintroduced before the full observation window terminates at T.\nWe can set up the potential outcome model in the following way to capture the basic features of before-and-after designs for a single unit of analysis: 1. Before the treatment is introduced (for t&lt;t∗):28 Dt=0 Yt=Y t0 2. While the treatment is in place (from t∗ through t∗+k): Dt=1 Yt=Y t1 Y0existsbutiscounterfactual t 28AlthoughintheorycounterfactualvaluesY t1 existinpretreatmenttimeperiods,thesevaluesare nottypicallyconsidered.Ifonewereinterestedinaskingwhatthetreatmenteffectwouldhavebeenif thetreatment hadbeenintroducedinanearliertimeperiod,thenthesecounterfactual values would needtobeintroducedintotheanalysis.\n\nAfter the treatment ends (for time periods t&gt;(t∗+k)):29 Dt=0 Yt=Y t1 Y0existsbutiscounterfactual.\n\nt For a single unit, the causal effect of the treatment is δt=Y t1−Y t0, (2.17) andtheseeffectsmayexistinmorethanonetimeperiodt,dependingonthedurationof thetreatmentandwhetherthetreatmentisassumedtobeareversibletreatmentstate orapermanentchangethatcannotbeundone.Studiesareoftenunclearonmaintained assumptionssuchasthese,aswellasonthedistinctionsbetweentimeperiodsoftypes 2 and 3. Our setup is very general and can accommodate many alternative types of studies withonly minormodifications,including thosefor whichtime periods oftypes 2 or 3 are unobserved.30 Because suchassumptions and designfeatures will alwaysbe application-specific, we offer a worked example next.\nThe Year of the Fire Horse Foraconcreteexamplethatrevealsthepossiblepowerofover-timeanalysisforasingle unit, consider a variant of the demography example on the determinants of fertility introduced in Section 1.3 (see page 17). In addition to the individual-level effects of family backgroundandother life course events onfertility decisions,the causaleffects ofreligion,values,andmoregeneralculturalbeliefshavebeenoflong-standinginterest aswell(seeMayerandMarx1957;WestoffandJones1979;HayfordandMorgan2008; Thornton, Binstock, Yount et al. 2012).\nSupposethattheunitofanalysisisthebirthrateinasinglecountry,estimatedfrom aggregate census data and vital statistics. The example we will consider is presented in Figure 2.1, which displays birth rates in Japan between 1951 and 1980. Following a post-war baby boom, birth rates in Japan were comparatively stable from the late 1950s through the early 1960s. However, in 1966, the birth rate fell precipitously, after whichit reboundedin1967andthenstabilized.Fromthe 1970sonward,Japan’s birth rate then resumed its decline, as its population aged and it continued with its demographic transition to a low mortality and low fertility country, as discussed in general in Chapter 1.31 29Below we will consider an example where k≤(T−t∗), but we do not mean to imply that the treatmentcannotremaininplaceaftertheobservationwindowendsatT.Infact,weplacenoupper boundonvaluesfork.If(t∗+k)&gt;T,thennoneofthetimeperiodsoftype3areobserved.\n30Insomeapplications,thetreatmentisstipulatedtooccurbetweenobservationintervals.Inthese cases,timeperiodsoftype2areassumedtobeunobserved.Typically,inthiscase Dt isassumedto be equal to 1 forat least the firsttimeperiodof type 3inorder to indicate that the treatment was initiatedintheunobservedtimeperiodsoftype2.Othersstudiesimplythatt∗+k=T,suchthatthe treatmentispresentthroughthefullposttreatmentobservationwindow.Inthesecases,timeperiods oftype3areunobserved.\n31For a comprehensive consideration of the post-1973 “baby bust” in Japan, see Retherford and Ogawa(2006).\nOne could ask many causal questions about the trend in Japan’s birth rate in Figure 2.1, but the natural first question is, What caused the dramatic decline in the birth rate in 1966? The demographic consensus is the following. Every 60 years, two cycles within the Asian zodiac calendar – one over twelve animals and one over five elements – generate a year of the “fire horse.” A folk belief exists that families who give birth to babies designated as fire horses will suffer untold miseries, particularly soifthe babyis a girl.Enoughcouples supposedlyheld this belief inthe yearsaround 1966 that they adjusted their fertility behavior accordingly (see Hodge and Ogawa 1991).\nIn their discussion of causal analysis in demography, N´ı Bhrolch´ain and Dyson (2007:8) consider this example and write that “demographers naturally interpret this event in a causal way, without worrying about the formalities of causal inference.” Although we agree that the assertion of a fire-horse causal effect on Japanese birth rates in 1966 does not require a formal treatment to convince most demographers, we will nonetheless use this example to demonstrate an over-time analysis of a causal effect for a single unit of analysis.\nThe first issue to consider is measurement of the outcome. The outcome for Figure 2.1 is known as the crude birth rate, which is the number of live births per 1,000 persons alive in the same year. A more refined outcome could be constructed, 26.0 25.3 24.0 23.4 )snosrep 22.0 21.5 000,1 20.0 19.4 20.0 rep( 19.4 18.6 19.2 19.319.4 etar 18.0 18.4 18.6 18.518.8 18.6 18.0 17.7 htriB 17.2 17.5 17.2 16.917.017.3 17.1 16.0 16.3 15.5 14.9 14.0 14.2 13.7 13.6 12.0 1951 1956 1961 1966 1971 1976 Year Figure2.1 Crude birth rates in Japan, 1951–1980.\nSource: Table 2-24, Live Births by Sex and Sex Ratio of Live Births, Bureau of Statistics of Japan.Accessedathttp://www.stat.go.jp/data/chouki/zuhyou/02-24.xls onMarch11,2013.\nstandardizing for cohort sizes of women of childbearing age. An analogous drop in standardized birth rates would still be present for 1966.32 What are the causal states that generate the seemingly obvious causal effect? At the individual level,the causalstates couldbe quite specific (“believing that having a fire-horse baby is less desirable than having a baby in another year”) or considerably more broad (“believing in the relevance of zodiac calendars”). For our purposes here, the particular individual-level causal states do not matter because the causal states are at the national levelfor this analysis.The states are “fire-horse year in the zodiac calendar” and “not,” and they are aligned, not with observed treatment and control groups,butwiththeobservedyears,D 1966=1versusDt(cid:4)=1966=0.Intheyear1966,the treatment generates two corresponding potential outcome variables, Y1 and Y0 , 1966 1966 which define the effect of interest for the birth rate in Japan in 1966: δ =y1 −y0 .\n1966 1966 1966 We can estimate this effect as δˆ =y −yˆ0 1966 1966 1966 =13.7−yˆ0 .\n1966 The estimate δˆ is the observed birth rate in 1966, 13.7, minus an estimate of the 1966 counterfactual birth rate, yˆ0 , that would have been observed if 1966 had not been 1966 the year of the fire horse.\nWhat is a reasonable estimated value for the true counterfactual outcome, y0 ? 1966 How about 18.6,which is the birth rate for 1965?N´ı Bhrolch´ainand Dyson (2007:30) reasonthat“somebirthsthatmighthavetakenplacein1966weretransferred–either infact,orviatheyearofoccurrencereportedbytheparentsatthetimeofregistration – to the adjacent years.” Such a possibility is evident in 1965, where the birth rate appears elevated in comparison to prior years. In fact, the birth rate appears to be slightlyhigherin1964aswell,relativetotheprevailingtrendintheearly1960s.What about the value for 1967, 19.4? Again, the birth rate appears to be higher here too, and possibly again in 1968. Following N´ı Bhrolcha´in and Dyson’s reasoning (and also Hodge and Ogawa 1991), these higher rates in 1964, 1965, 1967, and 1968 could be presentbecause parents wereespecially eagerto have childrenbefore or after the year of the fire horse and adjusted their behavior accordingly. Given the uncertainties of conception, at least some of these parents started their avoidance early or failed to conceive a child until after the year of the fire horse.\nInourexperiencediscussingthisexamplewithotherresearchers,mostwillsettleon theaverageofthe twovaluesfor1963and1969,(17.3+18.5)/2=17.9,asareasonable estimate of the counterfactualvalue,y0 . The resultof sucha choiceis anestimated 1966 causal effect, δˆ =13.7−17.9=−4.2, 1966 32At least some of the overall downward trend would disappear because the trend in Figure 2.1 is produced inpart by the aging of the population (which itself is a function of the return to peace following World War II and continuing declines in mortality). Hodge and Ogawa (1991) document thesetrendsandconsideralternativeadjustments forotherdemographictrajectories.\nthat implies a decline in the crude birth rate of 31 percent. At the individual level, and ignoring rates of twins and so on, this estimate suggests that nearly 1 out of 3 mothers who would have given birth in 1966 did not do so because 1966 was the year of the fire horse. Notice also that, in selecting the average of the birth rates in 1963 and 1969 as the most reasonable estimate of the counterfactual value, one is thereby assuming positive fire-horse-year effects in 1964, 1965, 1967, and 1968, which were non–fire-horse years. As a result, in order to estimate the overall effect of the year of the fire horse on the population structure of Japan, as determined by the year-by- year evolution of what is known as the total fertility rate, one would need to model andthenappropriatelycombinefiveyear-specificeffects,δ throughδ ,basedon 1964 1968 additional corresponding treatment states for the specific years.\nNowconsiderwhathasbeenlearnedandwhathasnot.VisualinspectionofFigure 2.1 is probably convincing on its own that something causal happened in 1966 that altered birth rates in Japan. However, the specific explanation that is accepted in demography is based on substantive knowledge of Asian zodiac calendars, as well as cultural beliefs based upon them that were sufficiently widespread in 1966. The over- time design did not generate this knowledge,even though it providedthe incentive to uncover it.\nHas anything deeper been learned from this effect? Certainly the effect supports themoregeneralconclusionthatculturalbeliefshavebeenacauseoffertilitydecisions in Japanin the past. This conclusionmay then further bolster the overallperspective in empirical demography that fertility decisions across the world are likely shaped by cultural beliefs and cannot be reduced to a cold rational calculus of the direct costs and psychic benefits of producing offspring.\nWith a little extra work, we have been able to generate the reasonable estimate that the effect in 1966 was a reduction of the birth rate of 31 percent, and we also took the position that there were very likely positive near-fire-horse-year effects in the two years on either side of 1966. Notwithstanding these successes, our analysis yields no information on which types of couples changed their fertility behavior. The relevance of the zodiac calendar surely varies across couples in nonrandom ways, and such patterns would be useful to know in order to develop additional perspective on the broader consequences of the effect. We have also not learned how many women, or which women, had fewer children or instead simply had children who were one or two yearsyounger or older than they would have been if their children had been born in 1966.\nWe will return to this type of example in Chapter 11, where we will consider the deeper modeling issues that accompany the estimation of these types of effects. Often referredtoasinterruptedtimeseries(ITS)designs,thereareformaltimeseriesanalysis procedures for generating best estimates of counterfactual values, and these may be easier to defend than our ad hoc choice of 17.9 as the most reasonable estimate of the crucial counterfactual value that determines the size of the casual effect. As we will discuss in detail in Chapter 11, the main weakness of these designs is their rarity.\nIn the observational social sciences, few examples are as clear-cut as the year of the firehorse.Morecommonly,the causalshocksto outcomesunfolding overtime areless dramatic, and, as a result, they are more difficult to separate from underlying trends.\nNotice also that we have chosen in this section an aggregateunit – a country – as our example of the analysis of a causal effect for a “single unit.” In part, this decision reflectsourpositiononwhatcanbelearnedbystudyingindividualsinisolation.Surely there are genuine individual-level causal effects, some of which can be discerned from examiningthelivesofparticularindividualsovertime.Thechallengeiswhatingeneral can be learned from documenting such apparent effects, and whether analyses can be strengthenedbyconsideringindividualsingroups,especiallyinrepresentativesamples.\nThis is the focus ofour nextsection,wherewe introducethe potentialoutcomemodel for many units over time.\n2.8.2 Many Units Over Time Suppose now that we have a collection of individuals observed at multiple points in time.Generallyreferredtoaspaneldataorlongitudinaldata,outcomesandcausesnow vary over both individuals and time. Consider two examples. First, researchers who study the charter school effect often have access to samples of students observed over multiplegradesinbothcharterschoolsandregularpublic schools.Second,researchers who study the effects of father absence that results from divorce typically have access to data from random samples of families. These data often include measures of child development outcomes before and after the divorce that triggers father absence.\nWewillnowextendthe potentialoutcomeframeworktoconsidertheestimationof causaleffects withsuchover-timedataonsamplesofindividuals.Inearliersections of this chapter, we dropped subscripting on i for brevity when discussing causal effects.\nFor this section, in which we must deal now with some quantities that vary only over individuals, others that vary only over time, and others that vary over both, we subscriptwithiforindividualsandwithtfortime.Foratwo-statecause,thepotential outcome variablesare Y i1 t, Y i0 t, and the observedvariablesare Dit and Yit.33 As in the last section, we will allow the observation window to run from t=1 to T. Unlike the last section, we will not utilize notation for a focal time interval, t∗, in which the treatment is introduced. Here, we want to preserve the possibility that the treatment is introduced at different times for different individuals.\nWe will also now distinguish between two different treatment indicator variables.\nDitisatime-varyingvariablethatindicateswhetherindividualireceivesthetreatment in time period t. In contrast, D∗ is a time-constant variable that indicates whether i individual i ever receives the treatment at any point in time during the observation window of the study (i.e., in any time period from t=1 to T). Dit is best thought of as a treatment exposure indicator, and D∗ is best thought of as a treatment group i indicator.\nThe setup for the potential outcome model with panel data follows directly from thesedefinitions.Formembersofthecontrolgroup,Yit=Y i0 foralltimeperiodst.For t members of the treatment group, Yit=Y i0 before treatment exposure, and Yit=Y i1 t t 33Insomecases,thesubscriptingisredundant.Forexample,inSections2.4and2.7,werepresented the causal effect as δ, recognizing that this effect can vary over individuals. In this section, we will represent the individual-level causal effect always as δ i, so that it is clear that in this form we are assumingthatitdoesnotvarywithtime.Foratime-varyingcausaleffect,wewouldinsteadneedto subscriptitasδ it.\nafter treatment exposure begins. Altogether, Yit is defined with reference to Dit, such that Yit=DitY i1 t+(1−Dit)Y i0 t, (2.18) where Dit remains equal to 0 over time for all members of the control group(D i∗=0) but varies between 0 and 1 for all members of the treatment group (D∗=1).\ni Consideraconcreteapplicationofthisnotationusingboththetreatmentexposure indicator and the treatment group indicator. If no one is exposed to the treatment in time period t=1 or t=2, then Di1=0, Di2=0, Yi1=Y i0 1, and Yi2=Y i0 for those in 2 the control group (D∗=0) and for those in the treatment group (D∗=1). But, if the i i treatment is then introduced to all members of the treatment group in time period t=3, then the values of Dit and Yit diverge across the treatment and control groups in time period 3. Now, for those in the control group (D i∗=0), Di3=0 and Yi3=Y i0 3.\nBut, for those in the treatment group (D i∗=1), Di3=1 and Yi3=Y i1 3.\nThedistinctionbetweenDit andD i∗ revealsthepotentialvalueofpaneldata.Fora cross-sectionalstudy inwhichall observationoccursinasingle time period,Dit=D i∗.\nHowever, a panel dataset over multiple time periods allows a researcher to consider how treatment exposure (Dit) can be separated from treatment group membership (D∗) and then exploitthis difference to estimate the causaleffect. Considertwo types i of analysis.\nFirst, when individuals receive the treatment at different times or do not receive the treatment at all, it is possible to observe how Y0 changes over time for some it individualsafter othershavereceivedthe treatment.Asa result,itmay be possibleto makereasonablepredictionsabouthowY0wouldhaveevolvedovertimeforindividuals it in the treatment group during the posttreatment time period. If predictions of these counterfactual trajectories are reasonable, inferences about the causal effect of the treatment,δit,intimeperiodt,canbemadebycomparisonoftheobservedYit intime period t for those who are treated (D∗=1) with predictions of their corresponding i counterfactualvalues ofY0 in time periodt. The crux ofthe matter,ofcourse,is how it to use observed values of Yit=Y i0 in time period t among those in the control group t (D∗=0)to makereasonablepredictionsabout posttreatmentcounterfactualvalues of i Y0 for those in the treatment group (D∗=1).\nit i Second, in situations where it is reasonable to assume that E[Y0] is evolving in it parallelfashionacrossthetreatmentandcontrolgroupsandthattreatmentassignment is unrelated to the values of the outcome prior to the treatment, it is possible to estimate the ATT by offering a model that (1) calculates the averagedifference in the outcome in the treatment group between the pretreatment and posttreatment time periods and (2) subtracts from this difference the average difference in the outcome for the control group between the same two time periods.34 In this case, the most important issue to consider is whether it is reasonable to assume parallel trajectories and that treatment assignment is unrelated to pretreatment values of the outcome.\nThe latter assumption would be unreasonable if individuals with comparatively low or comparatively high values of the pretreatment outcome, net of other determinants 34Moreover, if it is reasonable to assume that self-selection on the causal effect is absent, then the ATT is equal to the ATE and ATC. A consistent and unbiased estimate of the ATT from a difference-basedestimatoristhenalsoconsistentandunbiasedforboththeATEandATC.\nof the outcome, select into the treatment, either under the assumption that they are especially suited to the treatment because of their recent strong performance or that they areespeciallyinneedofthe treatmentbecauseoftheirrecentweakperformance.\nWe will discuss a variety ofpaneldata estimation strategiesinChapter 11, but we wanttoforeshadowtwobasicconclusionsheretotempertheoptimismthatmanymay feelafterconsideringourpriortwoparagraphs.First,paneldataestimatorsbasedonly onposttreatmentobservationsdonotusuallyimproveonthecross-sectionalestimators we will present in this book. In our experience, analysts are often too sanguine about the clarifying power of observing the evolution of outcome variables for those who arealwaysobservedunder exposureto the treatmentofinterest(e.g., students always enrolled in Catholic high schools relative to students always enrolled in public high schools,withnodataoneithergroupavailablepriortohighschool).Second,oneneeds data from multiple pretreatment time periods and/or very well-developed theory to justify required assumptions before the gains to panel data are clear, especially given the other ancillary patterns, such as panel attrition, that must also often be modeled.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#the-potential-outcome-model-for-many-valued-treatments",
    "href": "extracted/Counterfactuals and Causal Inference.html#the-potential-outcome-model-for-many-valued-treatments",
    "title": "Counterfaturals and Causal Inference",
    "section": "2.9 The Potential Outcome Model for Many-Valued Treatments",
    "text": "2.9 The Potential Outcome Model for Many-Valued Treatments\nSo far in this chapter, we have focused our presentation of the potential outcome\nmodel on binary causal variables, conceptualized as dichotomous variables that indi- cate whether individuals are observed in treatment and control states. As we show in this section, the counterfactual framework can be used to analyze causal variables with more than two categories.\nConsider the more general setup, in which we replace the two-valued causal expo- sure variable, D, and the two potential outcomes Y1 and Y0 with 1. a set of J treatment states, 2. a corresponding set of J causal exposure dummy variables, {Dj}J , and j=1 3. a corresponding set of J potential outcome random variables, {YDj}J .\nj=1 Each individual receives only one treatment, which we denote Dj(cid:2). Accordingly, the Dj(cid:2) observed outcome variable for individual i, yi, is then equal to y . For the other i J−1 treatments, the potential outcomes of individual i exist in theory as J−1 other potential outcomes yDj for j(cid:6)=j(cid:2), but they are counterfactual.\ni Consider the fundamental problemof causalinference for many-valuedtreatments presented in Table 2.4 (which is simply an expansion of Table 2.1 to many-valued treatments). Groups exposed to alternative treatments are represented by rows with, for example, those who take treatmentD2 in the secondrow.For a binary treatment, we showed earlier that the observed variable Y contains exactly half of the informa- tion contained in the underlying potential outcome random variables. In general, for a treatment with J values, Table 2.4 shows that the observed outcome variable Y contains only 1/J of the total amount of information contained in the underlying Table 2.4 The Fundamental Problem of Causal Inference for Many-Valued Treatments Group YD1 YD2 ··· YDJ Takes D1 Observableas Y Counterfactual ··· Counterfactual Takes D2 Counterfactual Observableas Y ··· Counterfactual . . . . . . . . . . . . . . .\nTakes DJ Counterfactual Counterfactual ··· Observableas Y potentialoutcome randomvariables.Thus,the proportionofunknownandinherently unobservable information increases as the number of treatment values, J, increases.\nForanexperimentalist,thisdeclineintherelativeamountofinformationinY isrel- atively unproblematic. Consider anexample in which a researcherwishes to know the relative effectiveness of three pain relievers for curing headaches. The four treatments are “Take nothing,” “Take aspirin,” “Take ibuprofen,” and “Take acetaminophen.” Suppose that the researcherrules out an observationalstudy, in part because individ- ualshaveconstrainedchoices(i.e.,pregnantwomenmaytakeacetaminophenbutmay not take ibuprofen; many individuals take a daily aspirin for general health reasons).\nInstead, she gains access to a large pool of subjects not currently taking any medi- cation and not prevented from taking any of the three medicines.35 She divides the poolrandomlyintofourgroups,andthedrugtrialisrun.Assumingallindividualsfol- low the experimental protocol, at the end of the data-collection period the researcher calculates the mean length and severity of headaches for each of the four groups.\nEven though three quarters of the cells in a 4× 4 observability table analogous to Table 2.4 are counterfactual, she can easily estimate the relative effectiveness of each of the drugs in comparison with each other and in comparison with the take-nothing control group. Subject to random error, contrasts such as EN[yi|Take aspirin]−EN[yi|Take ibuprofen] reveal all of the average treatment effects of inter- est. The experimental design allows her to ignore the counterfactual cells in the observability table by assumption. In other words, she can assume that the aver- age counterfactual value of YAspirin for those who took nothing, took ibuprofen, and took acetaminophen (i.e., E[YAspirin|Take nothing], E[YAspirin|Take ibuprofen], and E[YAspirin|Takeacetaminophen])canallbeassumedtobeequaltotheaverageobserv- able value of Y for those who take the treatment aspirin, E[Y|Take aspirin]. She can thereforecomparesampleanalogsoftheexpectationsinthecellsofthediagonalofthe observability table, and she does not have to build contrasts within its rows. Accord- ingly, for this type ofexample, comparingthe effects ofmultiple treatments with each otherisnomorecomplicatedthanthebivariatecase,exceptinsofarasonenonetheless has more treatments to assign and resulting causal effect estimates to calculate.\n35Notethat,inselectingthisgroup,shehasadoptedadefinitionofthepopulationofinterestthat does not include those who (1) take one of these pain relievers regularlyfor another reason and (2) do not have a reason to refuse to take one of the pain relievers. We will discuss the importance of consideringsuchgroupsof“alwaystakers”and“nevertakers”whenwepresentinstrumentalvariable estimatorsinChapter9.\nTable 2.5 The Observability Table for Estimating How Education Increases Earnings Education YHS YAA YBA YMA Obtains HS Observableas Y Counterfactual Counterfactual Counterfactual Obtains AA Counterfactual Observable as Y Counterfactual Counterfactual Obtains BA Counterfactual Counterfactual Observableas Y Counterfactual Obtains MA Counterfactual Counterfactual Counterfactual Observableas Y Nowconsideravariantontheeducation-earningsexample.Supposethataresearcher hopes to estimate the causal effect of different educational degrees on labor market earnings, and further that only four degrees are under consideration: a high school diploma (HS), an associate’s degree (AA), a bachelor’s degree (BA), and a master’s degree (MA). For this problem, we therefore have four dummy treatment variables corresponding to each of the treatment states: HS, AA, BA, and MA. Table 2.5 has the samestructure as Table 2.4. Unlike the pain relieverexample, randomassignment to the four treatments is impossible. Consider the most important causal effect of interest for policy purposes, E[YBA−YHS], which is the average effect of obtaining a bachelor’s degree instead of a high school diploma.\nSuppose that an analyst has survey data on a set of middle-aged individuals for whomearningsatthemostrecentjobandhighesteducationaldegreearerecorded.To estimate this effect without asserting any further assumptions, the researcher would need to be able to consistently estimate population-level analogs to the expectations of allof the cells ofTable 2.5 in columns 1 and3, including six counterfactualcells off of the diagonal of the table. The goal would be to formulate consistent estimates of E[YBA−YHS] for all four groupsof differentially educatedadults. To obtaina consis- tent estimate of E[YBA−YHS], the researcher would need to be able to consistently estimate E[YBA−YHS|HS=1], E[YBA−YHS|AA=1], E[YBA−YHS|BA=1], and E[YBA−YHS|MA=1], after which these estimates would be averagedacrossthe dis- tributionofeducationalattainment.Noticethatthisrequirestheconsistentestimation ofsomedoublycounterfactualcontrasts,suchastheeffectonearningsofshiftingfrom ahighschooldiplomatoabachelor’sdegreeforthosewhoareobservedwithamaster’s degree.The researchermightboldly assertthatthe wagesofall highschoolgraduates are,onaverage,equalto whatallindividuals wouldobtainin the labor marketifthey instead had high school diplomas. But this is very likely to be a mistaken assumption if it is the case that those who carryon to higher levels of education would have been judgedmoreproductiveworkersbyemployerseveniftheyhadnotattainedmorethan high school diplomas.\nAs this example shows, a many-valued treatment creates substantial additional burden on an analyst when randomization is infeasible. For any two-treatment com- parison, one must find some way to estimate a corresponding 2(J−1) counterfactual conditionalexpectations,becausetreatmentcontrastsexistforindividualsinthepopu- lationwhoseobservedtreatmentsplacethemfarfromthediagonaloftheobservability table.\nIf estimating all of these counterfactual average outcomes is impossible, analysis can still proceed in a more limited fashion. One might simply define the parameter of interestverynarrowly,suchasthe averagecausaleffect ofa bachelor’sdegreeonly for those who typically attain high school diplomas: E[YBA−YHS|HS=1]. In this case, thecausaleffectofattainingabachelor’sdegreeforthosewhotypicallyattaindegrees other than a high school diploma are of no interest for the analyst.\nAlternatively, there may be reasonable assumptions that one can invoke to sim- plify the complications of estimating all possible counterfactualexpectations. For this example, many theories of the relationship between education and earnings suggest that, for each individual i, yHS≤yAA≤yBA≤yMA. In other words, earnings never i i i i decrease as one obtains a higher educational degree. Asserting this assumption (i.e., taking a theoretical position that implies it) may allowone to ignore some cells of the observabilitytablethatarefarthestfromthedirectcomparisononehopestoestimate.\nWe will discuss these sorts of assumptions in Chapter 12.\nAside from the expansion of the number of causal states, potential outcomes, and treatmenteffects, all other features of the potential outcome model remainessentially the same. SUTVA is typically still maintained, and, if it is unreasonable, then more general methods must again be used to model treatment effects that may vary with patterns of treatment assignment. Modeling treatment selection remains the same, eventhough the added complexity of havingto model movementinto andout of mul- tiple potential treatment states can be taxing. And the same sources of inconsistency and bias in standard estimators must be considered, only here again the complexity can be considerable when there are multiple states beneath each contrast of interest.\nTo avoidall of this complexity, one temptation is to assume that treatment effects are linear additive in an ordered set of treatment states. For the effect of education onearnings,a researchermight insteadchooseto move forwardunder the assumption that the effect of education on earnings is linear additive in the years of education attained. For this example, the empirical literature has demonstrated that this is a particularly poor idea. For the years in which educational degrees are typically con- ferred, individuals appear to receive an extra boost in earnings. When discussing the estimation of treatment effects using linear regression for many-valued treatments in Section 6.6.1, we will consider a piece by Angrist and Krueger(1999)that shows very clearly how far off the mark these methods can be when motivated by unreasonable linearity and additivity assumptions.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#conclusions",
    "href": "extracted/Counterfactuals and Causal Inference.html#conclusions",
    "title": "Counterfaturals and Causal Inference",
    "section": "2.10 Conclusions",
    "text": "2.10 Conclusions\nIn this chapter, we have introduced the main components of the potential outcome\nmodel,whichisafoundationalpieceofthecounterfactualmodelofcausalityforobser- vationalresearch.Wedefinedindividual-levelcausaleffectsasthewhat-ifdifferencesin potential outcomes that would result from being exposed to alternative causal states.\nWe then presented the assumption of causal effect stability – the stable unit treat- ment value assumption – that is frequently relied on when estimating effects defined by potential outcomes. We defined averagecausal effects at the population level, con- sidered how ineffective the simple mean-difference estimator is for estimating average causaleffects with observationaldata, and concluded with extensions of the potential outcomemodelforeffectsobservedovertimeandforeffectsdefinedacrossmanyvalues of the cause. In the next chapter, we introduce the directed graph approachto causal analysis,whichwe see as the secondfoundationalpiece ofthe counterfactualmodel of causality for observationalresearch.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#appendix-to-chapter-2-population-and-data-generation-models",
    "href": "extracted/Counterfactuals and Causal Inference.html#appendix-to-chapter-2-population-and-data-generation-models",
    "title": "Counterfaturals and Causal Inference",
    "section": "2.11 Appendix to Chapter 2: Population and Data Generation Models",
    "text": "2.11 Appendix to Chapter 2: Population and Data Generation Models\nInthecounterfactualtradition,nosingleagreed-onwaytodefinethepopulationexists.\nInarecentpiece,forexample,Rubin(2005:323)introducestheprimaryelementsofthe potential outcome model without taking any particular position on the nature of the population, writing that “‘summary’ causal effects can also be defined at the level of collectionsofunits,suchasthe meanunit-levelcausaleffectforallunits.”As aresult, avarietyofpossiblepopulation-based(and“collection”-based)definitionsofpotential outcomes,treatmentassignmentpatterns,andobservedoutcomescanbe used.Inthis appendix, we explain the choice of population model that we will use throughout the book (and implicitly, unless otherwise specified).\nBecauseweintroducepopulations,samples,andconvergenceclaimsinthischapter, we have placed this appendix here. Nonetheless, because we have not yet introduced modelsofcausalexposure,someofthe finepointsinthe followingdiscussionmaywell appear confusing (notably, how “nature” performs randomized experiments behind our backs). For readers who wish to have a full understanding of the implicit super- population model we will adopt, we recommend a quick reading of this appendix now and then a second more careful reading after completing Chapters 5 through 7.\nOur Implicit Superpopulation Model. The most expedient population and data generation model to adopt is one in which the population is regarded as a real- izationofaninfinitesuperpopulation.Thissetupisthestandardperspectiveinmathe- maticalstatistics,inwhichrandomvariablesareassumedtoexistwithfixedmoments for an uncountable and unspecified universe of events. For example, a coin can be flipped an infinite number of times, but it is always a Bernoulli distributed random variableforwhichthe expectationofa faircoinis equalto .5 forbothheads andtails.\nFor this example, the universe of events is infinite because the coin can be flipped forever.\nMany presentations of the potential outcome framework adopt this basic setup, followingRubin(1977)andRosenbaumandRubin(1983b,1985a).Forabinarycause, potentialoutcomesY1 andY0 areimplicitly assumedtohaveexpectationsE[Y1] and E[Y0] in an infinite superpopulation. Individual realizations of Y1 and Y0 are then denoted y1 and y0. These realizations are usually regarded as fixed characteristics of i i each individual i.\nThisperspectiveistantamounttoassumingapopulationmachinethatspawnsindi- viduals forever(i.e., the analogto a coin that can be flipped forever).Eachindividual is born as a set of random draws from the distributions of Y1, Y0, and additional variables collectively denoted by S. These realized values y1, y0, and s are then given individual identifiers i, which then become y i1, y i0, and si.\nThe challenge of causal inference is that nature also performs randomized exper- iments in the superpopulation. In particular, nature randomizes a causal variable D within strata defined by the values of S and then sets the value of Y as yi equal to y i1 or y0, depending on the treatment state that is assigned to each individual. If nature i assigns an individual to the state D=1, nature then sets yi equal to y i1. If nature assignsan individual to the state D=0, nature then sets yi equal to y i0. The differen- tial probability of being assigned to D=1 instead of D=0 may be a function in S, depending onthe experiment that nature has decided to conduct (see Chapters 4 and 5). Most important, nature then deceives us by throwing away y1 and y0 and giving i i us only yi.\nIn our examples, a researcherwith good fortune obtains data froma randomsam- {yi,di,si}N ple of size N from a population, which is in the form of a dataset i=1. The sample that generates these data is drawn from a finite population that is itself only onerealizationofatheoreticalsuperpopulation.Basedonthis set-up,the jointproba- bilitydistributioninthe samplePrN(Y,D,S) mustconvergeinprobabilitytothe true joint probability distribution in the superpopulation Pr(Y,D,S) as the sample size approachesinfinity.Themaintaskforanalysisistomodelthe relationshipbetweenD and S that nature has generated in order use observed data on Y to estimate causal effects defined by Y1 and Y0. [Many researchers do not have such good fortune and instead must analyze a dataset with measures of only a subset of the variables in S, whichwewilltypicallylabelX.Theseresearchershaveaccesstoadataset{yi,di,xi}N i=1 and model PrN(Y,D,X), which does not converge to Pr(Y,D,S).] Becauseofitsexpediency,wewillusuallywritewiththissuperpopulationmodelin thebackground,eventhoughthenotionsofinfinitesuperpopulationsandsequencesof sample sizes approaching infinity are manifestly unrealistic. We leave the population and data generation model largely in the background in the main text, so as not to distract the reader from the central goals of our book.\nAlternative Perspectives. There are two main alternative models of the pop- ulation that we could adopt. The first, which is consistent with the most common starting point of the survey sampling literature (e.g., Kish 1965), is one in which the finite population is recognized as such but treated as so large that it is convenient to regard it as infinite. Here, values of a sample statistic (such as a sample mean) are said to equal population values in expectation, but now the expectation is taken over repeated samples from the population (see Thompson 2002 for an up-to-date accounting of this perspective). Were we to adopt this perspective, rather than our superpopulationmodel, muchofwhatwe writewouldbe the same.However,this per- spective tends to restrict attention to large survey populations (such as all members of a country’s population older than 18) and makes it cumbersome to discuss some of the estimators we will consider (e.g., in Chapter 5, where we will sometimes define causal effects only across the common support of some random variables, thereby necessitating a redefinition of the target population).\nThe second alternative is almost certainly much less familiar to many empirical social scientists but is a common approach within the counterfactual causality litera- ture. It is used often when no clearly defined population exists from which the data can be said to be a random sample (such as when a collection of data of some form is availableandananalystwishestoestimatethecausaleffectforthoseappearinginthe data).Inthissituation,adatasetexistsasacollectionofindividuals,andtheobserved individuals are assumed to have fixed potential outcomes y1 and y0. The fixed poten- i i tial outcomes have average values for those in the study, but these averagevalues are not typically defined with reference to a population-level expectation. Instead, analy- sis proceeds by comparison of the average values of yi for those in the treatment and control groups with all other possible average values that could have emerged under all possible permutations of treatment assignment. This perspective then leads to a form of randomization inference, which has connections to exact statistical tests of null hypotheses most commonly associated with Fisher (1935).As Rosenbaum (2002) shows,manyofthe resultswepresentinthis book canbe expressedinthis framework (see also Rubin 1990, 1991). But the combinatoric apparatus required for doing so canbe cumbersome(andoftenrequiresconstraints,suchashomogeneityoftreatment effects, that are too restrictive). Nonetheless, because the randomization inference perspective has some distinct advantages in some situations, we will refer to it at sev- eral points throughout the book. And we strongly recommend that readers consult Rosenbaum (2002, 2010) if the data under consideration arise from a sample that hasnostraightforwardandsystematicconnectiontoawell-definedpopulation.Inthis case,sampleaveragetreatmenteffectsmaybetheonlywell-definedcausaleffects,and, if so, then the randomization inference tradition is a clear choice.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#identification",
    "href": "extracted/Counterfactuals and Causal Inference.html#identification",
    "title": "Counterfaturals and Causal Inference",
    "section": "3.1 Identification",
    "text": "3.1 Identification\nTo set the stage for our introduction to directed graph representations of causal rela-\ntionships, it is helpful to define the concept of identification. In Chapter2, we defined causaleffectsascontrastsbetweenwell-definedpotentialoutcomesandthenproceeded to consider some of the conditions under which consistent and unbiased estimators of average causal effects are available. A complementary approach, and the one which motivates the usage of the directed graphs that we will present in this chapter, is to performanidentification analysis.Here,thechallengestoinferencethatarisefromthe finitenatureoftheavailablesampleareheldasidewhiletheanalystconsiderswhether acausaleffectcouldbecomputedifdataonthefullpopulationwereinsteadavailable.\nIn his 1995 book Identification Problems in the Social Sciences, Manski writes, itisusefultoseparatetheinferentialproblemintostatisticalandidentifica- tion components. Studies of identification seek to characterize the conclu- sions that could be drawn if one could use the sampling process to obtain an unlimited number of observations. (Manski 1995:4) He continues, Empirical research must, of course, contend with statistical issues as well as with identification problems. Nevertheless, the two types of inferen- tial difficulties are sufficiently distinct for it to be fruitful to study them separately.The study of identification logically comes first. Negative iden- tification findings imply that statistical inference is fruitless: it makes no sense to try to use a sample of finite size to infer something thatcouldnot be learned even if a sample of infinite size were available. Positive iden- tification findings imply that one should go on to study the feasibility of statistical inference. (Manski 1995:5) The two most crucial ingredients for an identification analysis are these: 1. The set of assumptions about causal relationships that the analyst is willing to assertbased on theory and past research,including assumptions about relation- shipsbetweenvariablesthathavenotbeenobservedbutthatarerelatedtoboth the cause and the outcome of interest.\n\nThe pattern of information that one can assume would be contained in the joint distribution of the variables in the observed dataset if all members of the population had been included in the sample that generated the dataset.\n\nAs we will begin to explain in this chapter, causal graphs can represent these ingre- dients effectively and efficiently and are therefore valuable tools for conducting iden- tification analyses.2 We will use the concept of identification frequently in this book, and we will expand upon this brief introduction as we introduce additional strategies for analysis.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#basic-elements-of-causal-graphs",
    "href": "extracted/Counterfactuals and Causal Inference.html#basic-elements-of-causal-graphs",
    "title": "Counterfaturals and Causal Inference",
    "section": "3.2 Basic Elements of Causal Graphs",
    "text": "3.2 Basic Elements of Causal Graphs\n3.2.1 Nodes, Edges, Paths, and Cycles\nThe primary goal when drawing a causal system as a directed graph is to represent explicitly all causes of the outcome of interest, based on past empirical research and assumptions groundedin theory. As we discussedin Section 1.5, eachnode of a graph represents a random variable and is labeled by a letter, such as A, B, or C. Nodes that are represented by a solid circle • are observed random variables, whereas nodes that are represented by a hollow circle ◦ are unobserved random variables.\nCausaleffectsarerepresentedbydirectededges→(i.e.,single-headedarrows),such that an edge from one node to another signifies that the variable at the origin of the 2Nonetheless, an identification analysis can be conducted, and typically is within the economet- ric tradition, without utilizing directed graphs. Consider our discussion of the naive estimator in Chapter2.TheequalitiesacrosstheexpectedvaluesofpotentialoutcomesthatwestatedasAssump- tions 1 and 2 in Equations (2.15) and (2.16) are identification assumptions. Maintenance of these particular assumptions would allow an analyst to assert that the naive estimator in Equation (2.9) is consistent and unbiased for the true average treatment effect in Equation (2.3), as explained by the decompositions offered there. As such, the average treatment effect is “identified” or is “iden- tifiable” when these assumptions can be maintained, even though an estimate from a finite sample may, because of sampling error, depart substantially from the true average treatment effect in the population. The value of causal graphs, as we will show in this chapter and the next, is that they allow for an efficient representation of full systems of causal relationships, which can be helpful for determiningwhetheridentification assumptionsarereasonable.\nA B C Figure3.1 A directed graph that includes a cycle.\ndirected edge causes the variable at the terminus.3 These “directed” edges are what givegraphscomposedofnodesandsingle-headedarrowsthegenerallabelof“directed graphs.” Apath isanysequenceofedgespointinginanydirectionthatconnectsonevariable to another. A directed path is a path in which all edges point in the same direction.\nA variable is a descendant of another variable if it can be reached by a directed path.\nAll kinship terms are then duly appropriated. Most importantly, for directed paths of length one, as inA→B, the variableA is the parent while the variable B is the child.\nIn this book, we will consider only a subset of directed graphs known as directed acyclic graphs or DAGs. For these graphs,no directed paths emanating from a causal variable also terminate at the same causal variable. In other words, no variable can be its own descendant. Figure 3.1 presents a graph that includes a directed path that forms a cycle, and as a result it is not a DAG (even though it is a directed graph because it includes only directed edges). Unlike some graphical models from the past, the prohibition of cycles in DAGs rules out representations of simultaneous causation andfeedbackloops.4Allofourstatementsaboutgraphsfromthispointonwardassume that only acyclic graphs are under consideration.\nUnder some circumstances it is useful to use a curved and dashed bidirected edge (as in Figures 1.1–1.3) as a shorthand device to indicate that two variables are mutu- allydependent onone ormoreunobservedcommoncauses.Inthis shorthand,the two graphspresentedinFigures3.2(a)and(b)areequivalent.Suchshorthandcanbehelp- ful in suppressinga complex setof backgroundcausalrelationships thatare irrelevant 3InPearl’sframework,eachrandomvariableisassumedtohaveanimplicitprobabilitydistribution netofthecausaleffectsrepresentedbythedirectededgesthatpointtoit.Thispositionisequivalent toassumingthatbackgroundcausesofeachvariableexistthatareindependentofthecausesexplicitly representedinthegraphbydirectededges.WewilldiscussthisassumptioninmoredetailinSection 3.3.2,whereweintroducethestructuralequations thatcorrespondtodirectedgraphs.\n4AsshowninWhiteandChalak(2009),abroaderframeworkthataccommodatescyclesispossible (a position acknowledged by Pearl and colleagues for some time, and which has its origins in the interest in reconciling recursive and nonrecursive models since the 1960s). However, the additional detailsofthebroadersetupcanbedaunting,andwerecommendthatinterestedreadersfirstcarefully consider how much their research questions reallydo requirethe full specification of feedback loops thatgeneratecycles.Inourexperience,mostsuchpurportedlynecessaryloopsresultfromamisplaced unwillingnesstoconsidermoretractableempiricalresearchquestionsthatcanbeconfinedtoshorter spans of analytic time. We do not mean to imply, however, that theory should not attend to such feedbackloops,onlythatmostempiricalprojectscanbenefit fromrecursionpragmatism.\nU A B A B (a) (b) Figure3.2 Two representations of the joint dependence of A and B on unobserved common causes.\nto the empirical analysis at hand. Nonetheless, these bidirected edges should not be interpreted in any way other than as we have just stated. They are not indicators of mereassociationsorcorrelationsbetweenthevariablesthattheyconnect,andtheydo notsignifythateitherofthetwovariableshasadirectcauseontheotherone.Rather, they represent an unspecified set of unobserved common causes of the two variables that they connect.\n3.2.2 Causal Graphs for Three Variables Figure 3.3 presents the three basic patterns of causal relationships that would be observedforanythreevariablesthatareconnectedtoeachotherby onlytwodirected edges: a chain of mediation, a fork of mutual dependence, and an inverted fork of mutualcausation.Pearl’sanalysisofthefirsttwotypesofrelationshipisconventional.\nFor the graph in panel (a), A affects B through A’s causal effect on C and C’s causal effect on B. This type of a causal chain renders the variables A and B uncondition- ally associated. For the graph in panel (b), A and B are both caused by C. Here, A and B are also unconditionally associated, but now it is because they mutually depend on C.5 For the third graph in panel (c), A and B are again connected by a path through C.ButnowAandB arebothcausesofC.PearllabelsC acollider variable. Formally, a variable is a collider along a particular path if it has two arrowspointing directly at it. Figuratively,the causal effects of A and B “collide” with each other at C. Collider variablesarecommoninsocialscienceapplications:Anyendogenousvariablethathas two or more causes is a collider along some path.\nA path that is connected by a collider variable does notgenerate anunconditional association between the variables that cause the collider variable. For the mutual causationgraphinpanel (c) ofFigure3.3, the path betweenA andB throughC does not generate an unconditional associationbetween A and B. As a result, if nothing is knownaboutthe valuethatC takeson,thenknowingthevaluethatAtakesonyields noinformationaboutthevaluethat B takeson.Pearl’slanguageisquitehelpful here.\n5The unconditional associations between A and B for both graphs mean that knowing the value that A takes ongives one some informationonthe likelyvalue that B takes on. Thisunconditional associationbetweenAandB,however,iscompletelyindirect,asneitherAnorB hasadirectcausal effectoneachother.\nA C B (a) Mediation C A B (b) Mutual dependence A B C (c) Mutual causation Figure 3.3 Basic patterns of causal relationships for three variables.\nThe pathA→ C ←B does not generateanassociationbetween A andB because the collider variable C “blocks” the possible causal effects of A and B on each other.\nEventhough collider variables do not generateunconditional associationsbetween the variables that determine them, we will show in the next chapter that incautious handling of colliders can create conditional dependence that can sabotage a causal analysis. The importance of considering collider variables is a key insight of Pearl’s framework,and it is closely relatedto the familiar concernsof selecting onthe depen- dent variable and conditioning on an endogenous variable (see Elwert and Winship 2014). Before turning to these issues in detail in Chapter 4, we first need to continue ourpresentationofthebasicfeaturesofthedirectedgraphapproachtocausalanalysis.\n3.2.3 A First Look at Confounding and Conditioning The most common concern of a researcher seeking to estimate a causal effect with observational data is that a causal variable D and an outcome variable Y are deter- mined,inpart,byathirdvariable,C.Thiscommonbutsimplescenarioisrepresented by the two graphs in Figure 3.4, where for panel (a) the variable C is observed and for panel (b) it is not.\nForboth graphsin Figure 3.4,the totalassociationbetween D andY is composed of two pieces: (1) the genuine causal effect of D on Y, representedby D→Y, and (2) the common dependence of D and Y on C, represented by both C→D and C→Y.\nC C D Y D Y (a) (b) Figure3.4 Two graphs in which the causal effect of D on Y is confounded by C.\nIn such cases, it is often said that the causal effect of D on Y is “confounded” by C or, even more simply, that C is a “confounder.” Regardless of the label given to C, the causal effects C→D and C→Y render the total association between D and Y unequal to the causal effect D→Y.\nThe frequency of basic confounding has established subgroup analysis as perhaps the most common modeling strategy to prosecute causal questions in social science research. Whether referred to as subclassification, stratification, tabular decomposi- tion, or simply adjustment for a third variable, the data are analyzed after “condi- tioning”onmembershipingroupsdefinedby valuesofthe confoundervariable.Usage of the word “conditioning” is a reference to the “ | ” operator, already used exten- sivelyinChapter2, todefine conditionalexpectations(see,inparticular,Section2.7).\nFromagraphicalperspective,thismodelingstrategyisanalogoustodisconnectingthe conditioning variable from all other variables that it points to in the original graph, rewriting the graph without the edges from the conditioning variable for each value for the conditioning variable, analyzing the data that apply to each of these graphs separately, and then combining the results across graphs to form an overall estimate.\nFor Figure 3.4(a), but not for Figure 3.4(b), consistentand unbiased estimators of the causal effect of D on Y are available (with a large enough dataset generated by a suitably random sample) because the analyst can condition on the observed variable C and eliminate the portion of the association between D and Y that is generated by their common dependence on C. We will explain this claim more formally and more generally in Chapter 4, where we introduce Pearl’s back-door criterion for the identification of a causal effect.\nFornow,considertheessentialoperationaldataanalysisroutine.ForFigure3.4(a), the effectofD onY canbe estimatedbyconditioning onC intwosteps: (1)calculate the association between D and Y for each subgroup with C equal to c and then (2) average these c-specific associations over the distribution of the values c that the variable C takes on in the sample (which we assume is, again, a large random sample from the population of interest). The resulting weighted average is a consistent and unbiasedestimatorofthecausaleffectofDonY inPearl’sframework,whichwouldbe labeledtheaveragetreatmenteffect(ATE)inthepotentialoutcomemodelintroduced in Chapter 2. For Figure 3.4(b), no such data analysis routine is feasible because the analyst has no observed variable C with which to begin.\nTo make this example more concrete, and to begin to build connections to the examples utilized for Chapter 2, consider the graph in Figure 3.5, where we revisit C A E Y Figure3.5 A causal graph in which the effect of education (E) on earnings (Y) is confounded by observed variables (C) and by unobserved ability (A).\nthe research question on ability bias in estimates of the earning returns attributable to completed years of education. Here, education, E, is a cause of earnings, Y, but this causal effect is confounded by two sources: (1) observed variables, C, such as demographic characteristics and family background, and (2) an unobserved variable forability,A.6 ForFigure3.5,wehavemovedonestepbeyondtheanalysisofthenaive estimator in Chapter 2 (see Tables 2.3 and 2.5), because now we are considering the moretypicalscenarioinwhichtheanalystincludesinthedirectedgraphsomeobserved variablesinC thatpastresearchhasestablishedalmostcertainlyhavecausaleffectson both yearsof completed educationand subsequent labor marketearnings. The ability bias literature asserts that, even if we were to condition on a rich parameterizationof allvaluesofthevariablesinC, westillwouldnotbeabletoeliminatetheconfounding generated by A.\nNotice also that we have not asserted that the education variable, E, in Figure 3.5 is a two-valued cause, as was the case for the discussion of Table 2.3. Unless specified otherwise, graphs of this type do not place restrictions on the numbers of values taken on by any of their variables. This particular graph, for example, would apply to either the two-valued education variable discussed in Section 2.7.3 or the four-valued education variable introduced in Section 2.9.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#graphs-and-structural-equations",
    "href": "extracted/Counterfactuals and Causal Inference.html#graphs-and-structural-equations",
    "title": "Counterfaturals and Causal Inference",
    "section": "3.3 Graphs and Structural Equations",
    "text": "3.3 Graphs and Structural Equations\nHaving introduced the basic elements of directed graphs, the next step is to intro-\nduce the structural equations that lie beneath them. As noted in the introduction to thischapter,directedgraphsencodecausalrelationshipsthatarecompletelynonpara- metric and fully interactive. This generality allows for a model of causality without assumptions about functional form, which is a major advantage over traditional path diagrams. An appreciation for this advantage requires first understanding the con- straints imposed by the parametric assumptions that were common in the equations associated with these path diagrams and why many researchers had good reason to object to them.\n6Inthelaboreconomicsliterature,itwouldgenerallybeassumedthatbothC andAdependona commonunobservedcauseU thatgeneratesanunconditionalassociationbetweenCandA.Weleave out this dependence in this diagram for simplicity. Its inclusion would not change the fact that the effectofD onY isnotidentified.\n3.3.1 The Appeal and Critique of Traditional Path Diagrams To explainboth the appeal andsubsequentcritique of traditionallinear additive path models, we will use the charter schools example introduced in Section 1.3.2.7 Con- sider the path diagram presented in Figure 3.6, and suppose that we have data on all sixth graders in a large metropolitan area. For this path diagram, Y is a stan- dardized test taken at the end of the sixth grade, and D indicates whether or not a student attended a charter school for the past year. The variable P represents an omnibus parentalbackgroundmeasure that captures differences in economic standing and other basic dimensions of resources that predict both charter school attendance andschoolperformance. The variable N is neighborhoodof residence, and we assume that there are meaningful differences in the extent to which neighborhood environ- ments are conducive to engagement with schooling. Thus, D is the cause of primary interest,P representsindividualdeterminantsofD thatalsohavedirectcausesonthe outcome Y, and N is a measure of the social context in which the effect of D on Y occurs.8 ThepathdiagrampresentedinFigure3.6isassociatedwithtwoimplicitstructural equations for the two endogenous variables: D=aD+bPP+eD, (3.1) Y =aY +bDD+bPP+bNN+eY. (3.2) These structural equations are linear and additive in the variables P, D, and N, and each equation has terms, eD and eY, that are represented in the path diagram as all other determinants of D and Y other than P, D, and N.9 The structure of the path diagramanditsequationsimplythattheproperempiricalregressionspecificationforY is the same as Equation (3.2). Under the implicit assumption that eY is uncorrelated with D, P, and N, the path-model interpretation of least squares estimates of the coefficients bD, bP, and bN is that they are consistent and unbiased estimates of the genuine causal effects of P, D, and N on Y.10 How would such a path diagram have been presented and then discussed in a typicalresearchmethods classinthe 1970s(assumingthatthe charterschoolresearch questionwasunderdiscussion)?Followinganintroductiontographicalrepresentations of causal relationships via path diagrams, at least one student would invariably ask the instructor: 7ThissectiondrawsonmaterialpreviouslypublishedinMorganandWinship(2012).\n8Mostpathmodelsassumedtheexistenceofunexplainedcorrelationsbetweenall“predetermined” or“exogenous”variables,whichareP andN forFigure3.6.Inmanypathdiagrams,curveddouble- headed arrows wouldbe drawn to represent such correlations. To avoid confusion with our usage of bidirectededgesthroughoutthisbook,wehavenotaddedsuchadouble-headedarrowtoFigure3.6.\n9Thestandardapproachintheearlydaysofpathmodelinginthesocialscienceswouldhavebeen to assume that e D is uncorrelated with P and that e Y is uncorrelated with P, D, and N. More complete approaches, asexemplified byDuncan (1975), wouldnot necessarilyhave maintainedsuch assumptions.\n10The estimated effects are presumed to be constant across individuals, as specified in Equation (3.2).However,mostanalystsregardedtheestimatesassimpleaverageeffectsacrossindividuals.We will return to this issue in detail when we discuss how regression models do not in general deliver simple average effect estimates (see Chapter 6) and when we then introduce explicit heterogeneity intocausalgraphs(seeChapter 8).\ne D D N e Y P Y Figure3.6 Atraditionallinearadditivepathdiagramfortheeffectsofparentalback- ground (P), charter schools (D), and neighborhoods (N) on test scores (Y).\nCan the effect of D on Y vary across P? That seems reasonable, since it wouldseemthattheeffectofacharterschoolwoulddependonfamilyback- ground.Parentswithcollegedegreesprobablyhelptheir kidsgetmoreout of school. Actually, now that I think about it, since N captures neighbor- hood characteristics, don’t we think that there are better schools in some neighborhoods?Infact,charterschoolsaremorelikelytobeestablishedin areas with troubled neighborhood-basedschools. And neighborhoods with weaker schools also tend to have stronger deviant subcultures with gangs and such. So the effect of charter schooling probably also depends on the neighborhood in which one lives. How do we represent such variation in effects in the path model?11 Inresponse,aninstructorwouldtypicallyexplainthatonecanthink ofsucheffects as supplemental arrowsfromavariableinto the middle ofanotherarrowinthe pathdia- gram,suchthatthevariableitselfmodifiesthearrowunderdiscussion.Yet,sincethese sorts of arrows are not formally justified in traditional path diagrams, the instructor wouldalmostsurelyhavethenrecommendedashifttowardamorecomplexregression specification, such as Y =aY +bCC+bPP+bC×P(C×P)+bNN+bC×N(C×N)+eY. (3.3) Inthiscase,thepathdiagramceasestorepresentanunderlyingsetofstructuralcausal relationships and is instead best interpreted as only a simplified reflection of a more specific regressionmodel. After all, the interaction between the effects of D and P on Y (as well as the interaction between the effects of D and N on Y) can be estimated withlittletrouble.Oneneedonlycalculateeffectsofinterest,forexample,byplugging in values for ˆbCC+ˆbPP +ˆbC×P(C×P), after producing standard regression output fromestimation ofEquation(3.3). The differences then producedcanbe imbued with causal interpretations based on the same justification as for Equation (3.2), assuming that no other variables that are common causes of P and Y, D and Y, or N and Y have been mistakenly omitted from Equation (3.3).\nWe see two related outcomes of the rise and then demise of traditional linear path models conceived and estimated in this fashion in the social sciences. First, when it became clear that there was no agreed upon way to represent within path diagrams 11Werethisexchangeoccurringinthesubstanceoftheday,apathmodelfromthestatusattainment traditionwouldbethefocusoftheexchange.TheoutcomevariableY wouldbecareersuccess,andD wouldbeeducation. Allofthesameinteractions notedforthe charter schoolcase wouldthen apply inthiscase,althoughbasedondifferentnarrativesofcausation.\nthe interactions that could be specified in regression equations to capture variability and context, path diagrams came to seem much less useful.12 Researchers interested in such variability and context may have continued to draw path diagrams on yellow pads in their offices, but rarely did their drawings turn up in published articles.13 Estimation and reporting became a word and number affair, often with too much of each.\nSecond, and far more troubling, many scholars apparently chose to retain a linear additive orientation, even while no longer using path diagrams. For some, empirical research could be fruitfully advanced by ignoring the genuine interactive nonlinearity of the real world, in pursuit of a first-approximation, linear pragmatism. This stance might have been an acceptable form of pragmatism if the approximation spirit had carriedovertomodelinterpretation.Toofrequentlyitdidnot,andmanycausalasser- tions can be found in the literature based on linear additive models that are overly reductionist.\nOverall, the traditional path-modeling literature, and then the more general “age of regression” that we described in Section 1.2.2, opened up quantitative research to theclaimsofcriticsthattoomanypractitionershadfallenpreytothebeliefthatlinear regression modeling reveals strong causal laws in which variability and context play minor roles. A particularly cogent presentation of this criticism is Abbott’s oft-cited “Transcending General Linear Reality” (Abbott 1988). Although its straw-man style is irksome to methodologists who knew of these problems all along, and who urged better practice, it was a reasonable critique of much practice at the time.14 3.3.2 The Shift to Nonparametric Structural Equations ForthesamesubstantiveexampledepictedinthepathdiagraminFigure3.6,consider now its representation by a directed graph in the new causal graph tradition. Two variants are offered in Figure 3.7. The standard representation that is depicted in panel (a) is then shown again under “magnification” in panel (b).15 For the latter, each variable is seen, under close examination, to have its own structural “error” or “disturbance”term:eP, eD, eN, andeY. Analogousterms are implicitly presentinall directedgraphs,but they aretypicallysuppressedin their standardrepresentation,as in panel (a), for visual simplicity.\n12Wedonotmeantoimplythat methodologists havenotproposed solutions.Bollen(1995) offers the elegant proposal of including functions of other variables as separate entities in diagrams and using sawtooth arrows, (cid:5), in order to represent functional assignment relations. For example, an interactiveeffectofC andP onY canberepresentedaltogether bythreepathsC→Y,P→Y,and (C×P)→Y.Theentity(C×P)isnotanewsourceofvariationwithanexogenous component but rather isadeterministicfunction defined inC andP.This functional dependence issignifiedinthe diagrambyincludingbothC(cid:5)(C×P)andP(cid:5)(C×P).\n13FreeseandKevern(2013:27) labelsuchcausal doodlingas“arrowsalad.” 14For similar critiques in sociology in the same time period, see also Lieberson (1985) and Ragin (1987). Abbott (2001), Lieberson and Lynn (2002), and Ragin (2008) offer updates on these earlier critiques.Leamer (1983) isthe analogineconomics, although writteninacompletely differentstyle andwithalternativesuggested remedies.\n15SeePearl(2009:339)forusageoftheword“magnification”torevealthedisturbance/errorterms thatareimplicitinalldirectedgraphs.\ne D e N D N e D N e P Y P Y P Y (a) Standard representation (b) Under magnification Figure3.7 Equivalent directed graph representations of the effects of parental back- ground (P), charter schools (D), and neighborhoods (N) on test scores (Y).\nWhat are these terms, eP, eD, eN, and eY? Pearl(2009:27)states that such terms “representerrors(or‘disturbances’)duetoomittedfactors”andarealwaysassumedto beindependentofeachotherandofallothervariablesinthegraph.ForFigure3.7(b), the terms eP, eD, eN, and eY represent all causes of P, D, N, and Y, respectively, that can be regarded as “idiosyncratic” causes of each variable. They are assumed to be independentofeachotherandofP,D,N, andY. Assuch,they canbesuppressed in the standard representationof a directed graph, as in Figure 3.7(a).16 In general,all directed graphs in the new causal graphtradition must be drawnin sufficientdetailsothatanysuchdisturbancetermscanbepushedintothebackground.\nPearl cautions, The disturbance terms represent independent backgroundfactors that the investigator chooses not to include in the analysis. If any of these fac- tors is judged to be influencing two or more variables (thus violating the independence assumption), then that factor must enter the analysis as an unmeasured (or latent) variable and be represented in the causal graph as a hollow node. (Pearl 2009:68) In other words, one must be able to assume that these structural error terms are mutually independent of each other and of all of the other variables in the graph, such that no pair is mutually dependent on a common third variable that has been mistakenly omitted from the graph. If this assumption is dubious, then one must re- drawthegraphincludinghollownodesforanymistakenlyomittedunobservedcommon causes. These unobserved variables must then be given directed edges that point to thevariablesthattheycause.Thenewerrortermsforthere-drawngraphcanthenbe redefined so that they can be pushed into the background (but still rendered visible under magnification).\n16Thereisconsiderabledebateovertheontologicalstatusoftheseidiosyncraticcauses.Theirexis- tence implies to some scholars that causality is fundamentally probabilistic. By our reading, Pearl wouldmaintain,forexample,thatthevariablesembeddedine P aresimplyimplicitstructuralcauses of P.Under this interpretation, causalitycan stillbeconsidered astructural, deterministicrelation.\nFreedman(2010,esp.chapter15)discussessomeofthedrawbacksforstatisticalinferenceofassuming determinismofthisform.Althoughconvincingtosomedegree,hiscritiquedoesnotaltertheutility ofthesesortsofcausalgraphsforclarifyingwhencausaleffectsareidentified,whichisPearl’sprimary contribution.\nIn fact, for the graphs in Figure 3.7, the existing literature on the charter school effect suggests that these graphs are incomplete. Most importantly, it is almost cer- tainly the case that the terms eD and eY in Figure 3.7(b) are mutually dependent on a common cause that has been mistakenly omitted from the graph, analogous to the unobserved ability confounder, A, in Figure 3.5. We will therefore extend this graph in Chapter 8, bringing it more into line with assumptions that analysts have been willingtomaintaininexistingempiricalresearch.Fornow,weproceedasifthegraphs in Figure 3.7 represent the true causal model, accepted hypothetically (but counter- factually!) by a clear consensus of researchers who have studied the charter school effect.\nMindful ofthis specificdefinitionofthedisturbance/errortermindirectedgraphs, and supposing for now that the two causal graphs in Figure 3.7 represent a valid and accepted causal model for the charter school effect, the corresponding structural equationscannowbeintroduced.Unlikepathdiagramsintraditionalform,wherethe structuralequationsarelinearandadditiveandcorrespondonlytothetheendogenous variables in the diagram (e.g., D and Y in Figure 3.6), for the new directed graph traditionthestructuralequationsarewrittenforallvariablesandinunrestrictedform (i.e.,possiblynonlinearandinteractive,asexplainedbelow).ThetwographsinFigure 3.7 have the same set of structural equations: P =fP(eP), (3.4) D=fD(P,eD), (3.5) N=fN(eN), (3.6) Y =fY(P,D,N,eY). (3.7) Reading from left to right in the graphs and top to bottom in these equations, P is generated as an unspecified function, fP(.), with eP as its sole argument. The next three equations then represent analogous unrestricted functions with inputs that rep- resent all causes of the variables on the left-hand sides of the equations. The last is the most elaborate, in that Y is a function of the three observed variables P, D, and N, as well as eY, all of which transmit their effects on Y via the function fY(.).\nWhenwesaythatfP(.),fD(.),fN(.),orfY(.)areunrestrictedandhavenoassumed functional form, we mean that a value is produced for the outcome variable of each equation for every combination of the values in the corresponding function on the right-hand sides of these equations. For example, Y takes on a distinct value for each combination of values, P =p, D=d, and N =n (typically then with the assump- tion that values of eY are drawn at random from some common distribution that is presumed to have finite moments; see Freedman 2010, chapter 15 for discussion of alternative approaches).17 An implication of this flexibility deserves particular emphasis, and preexisting knowledge of traditional path models and their implicit linear additive structural 17Restrictionsarenottypicallyplacedonhowthedrawnvalueofthedisturbance/errortermisthen transmitted by f(.) to the outcome. However, because these terms are independent (by definition) of all other inputs in f(.), their realization in the outcome variable does not typically require any assumption,atleastwhenidentificationisthefocus.\nequations can hinder full recognition of its importance. Consider the nonparamet- ric structuralequationfor Y in Equation(3.7). All interactions between the effects of P,D, andN onY areimplicitly permitted bythe lackofrestrictionsplacedonfY(.).\nImportantly, this property of the structural equations means that the causal graphs in Figure 3.7 are consistent with all such interactions because the directed edges only signifyinclusioninthefunctionssuchasfY(.).Nonewarrows,noranynotationofany kind, are needed to represent interactions for more specific parameterizations where, for example, the effect of D on Y varies with the level of P or N.\nAsaresult,eventhoughitmayfeelnaturaltowantto“see”aspecificarrowpresent in the causal graph to represent an interaction effect that corresponds to a cross- product term in a regression equation, one must learn to suppress such a desire. The key point, in considering an analysis that utilizes causal graphs, is to drop regression modelsfromone’smindwhenthinkingaboutidentificationissues.Instead,ifonemust useadataanalyticmachinetoconceptualizehowtoperformanappropriateempirical analysis of the puzzle under consideration, one should default to simple conditioning, as introduced in the last section.\nAs we will explain in far greater detail in the next part of the book, if the graphs in Figure 3.7 were the true causal system that generates the effects of charter schools on test scores, the effect of D on Y would be confounded by the observed parental background variables in P. In addition, the effect of D on Y may vary across the contexts defined by neighborhoods. With a dataset of sufficient size, the analyst can estimatetheeffectofDonY foreverycombinationofthevaluesinP andN,adopting a conditioning strategy for identification and estimation. These within-P-and-within- N differences are not confounded and represent average causal effects for students within strata defined by P and N (again, under the assumption that the directed graphisacompleterepresentationofthetruecausalsystem).Toobtainaveragecausal effects for largergroupsof individuals, suchas those living within a particulartype of neighborhood defined by N, the analyst can combine the strata-specific estimates by forming a weighted average where the weights are proportional to the sample sizes of all strata that correspond to the type of neighborhood chosen.\nIn this way, causal analysis guided by the specification of directed graphs is an inherently flexible enterprise. Losing sight of the lack of functional form assumed for causal analysis with unrestricted structural equations may still lead one to fail to transcend “general linear reality.” If so, the fault lies with the analyst, not the graph or the possibly highly nonlinear structural equations that it represents.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#causal-graphs-and-the-potential-outcome-model",
    "href": "extracted/Counterfactuals and Causal Inference.html#causal-graphs-and-the-potential-outcome-model",
    "title": "Counterfaturals and Causal Inference",
    "section": "3.4 Causal Graphs and the Potential Outcome Model",
    "text": "3.4 Causal Graphs and the Potential Outcome Model\nWhatarethe connectionsbetweenthe directedgraphapproachto causalanalysisand\nthe potential outcome model introduced in Chapter 2? In short, they are intimately related but very distinct frameworks for considering the same issues, each of which offersuniqueinsightinparticularsituations.We willreturntothis basicpointrepeat- edly throughout this book. In this section, we begin to explain their complementary value and then offer a brief examination of the most important formal connection between the two frameworks: how each encodes (potentially counterfactual) causal states.\n3.4.1 Complementary Value We already have shown through our presentation in Chapter 2 that the potential outcome model can be understood and utilized without reference to causal graphs.\nIndividual-levelpotentialoutcomesallowonetothinkindependentlyabouttheobserved data as well as what data would have been observed if individuals had experienced alternative causal states. From these simple pieces, the model allows for transparent definitions of causal effects and encourages the analyst to consider individual-level heterogeneity as a first principle.\nWealsodemonstratedinChapter2howpotentialoutcomerandomvariablesenable clear definitions of conditional average causal effects and provide ways to usefully decomposesourcesofinconsistencyandbiasinestimators–intounaccounted-forbase- line differences between individuals and the differential responsiveness of individuals to the cause of interest. Many other advantages of thinking through causal analysis with potential outcomes will be demonstrated in the remaining chapters of this book.\nHowever,wealsobegantoshowinChapter2thatthetransparencyofthepotential outcome model begins to cloud overwhen more than two causal states are considered andwhenimportantassumptions,suchas the stable unittreatmentvalue assumption (SUTVA) (see Section 2.5), are asserted without considerable reflection. The latter is a specific instance of the complications of maintaining the full notational framework of the potential outcome model when many other causal variables of interest begin to enter the scientific problem.\nIn this chapter, we have shown that the basic elements of causal graphs do not includepotentialoutcomerandomvariables,suchY1 andY0.Theremainingchapters of the book will demonstrate how useful causal graphs can be for empirical research.\nAs we will begin to show in the next chapter, graphs offer a disciplined framework for expressing causal assumptions for entire systems of causal relationships. In many cases, their economy of presentation cannot be matched by potential-outcome-based presentations of the same material, even though equivalent expressions are available.\nThisadvantageisespeciallyapparentwhentheanalystmustconsiderthemanycausal pathways that may be present in the real applications of observational research. Yet, aswewillthenalsodetaillater,thepricepaidforsucheconomyofpresentationisthen that individuals, and individual-level causal effects, which are so usefully revealed in thepotentialoutcomemodel,canbecoveredoverbycausalgraphs,eveniftheproblem is not the causal graphs per se but the shallow interpretations that analysts can too easily attach to them.\nHavingstatedourpositionontheusefulcomplementarityofthesetwoframeworks, we now lay out the most important point of connection between them. In the next section, we show how each framework encodes causal states in analogous fashion, thereby defining causal effects using counterfactuals.\n3.4.2 Potential Outcomes and the do(.) Operator InChapter2,weintroducedpotentialoutcomesafterfirstdiscussingtheneedtoclearly define the states of the causal variables of primary interest. We then moved directly to the definition of potential outcomes defined by the instantiation of particular well- defined causal states, focusing for the most part on the canonical potential outcomes Y1 and Y0 for a two-valuedcause.Only thereafter did we back out a definition of the corresponding observed variable Y, and only by way of Equation (2.2), Y =DY1+ (1−D)Y0.\nWhen we then introduced directed graphs in this chapter, we skipped right over causal states and potential outcomes. We moved straight from the representation of observed random variables A, B, and C to discussions of causal effects invoking the same observed variables utilized earlier in Chapter 2, the observed variables D and Y. Corresponding potential outcomes, Y1 and Y0, were not incorporated into our presentation.Todemonstratetheconnectionsbetweenpotentialoutcomesanddirected graphs, we need to introduce how causal states are represented in Pearl’s variant of causal analysis.\nPearl introduces causal states in a different way, using the semantics of an ideal experimentalinterventionandwhathelabelsthedo(.)operator.Recallthebasicstruc- ture of the directed graph in Figure 3.4(a). For this graph, the causal effect of D on Y is represented by D→Y, and the directed edge indicates that D is an input in the function, fY(.). The do(.) operator, which we present in this section, is what pro- vides the bridge to quantities such as the ATE, E[δ]=E[Y1−Y0], defined earlier in Equation (2.3).\nFor Figure 3.4(a), consider the case where D takes on two values, 0 and 1. For Pearl,therearetworegimesbywhichD takesonvaluesof0or1:pre-interventionand under-intervention. In the pre-intervention regime, the value that D takes on for any given unit in the population is determined by the structural equation D=fD(C,eD).\nIn the under-intervention regime, the value that D takes on is set by what Pearl sometimescallsan“idealexperiment”(e.g.,Pearl2009:358)andatothertimescallsan “atomicintervention”(e.g.,Pearl2009:70).Notationally,thisinterventionisdo(D=1) or do(D=0).18 For Pearl, all causal quantities are defined by under-intervention distributions, not pre-intervention distributions (Pearl 2009, definitions 3.2.1 and 7.1.2-5). For D and Y in Figure 3.4(a), the two probability distributions that define causal effects are Pr[Y|do(D=1)]andPr[Y|do(D=0)],notPr[Y|D=1]andPr[Y|D=0].Inparticular, theaveragecausaleffectisE[Y|do(D=1)]−E[Y|do(D=0)],undertheassumptionthat 18As we will explain in more detail in the appendix to this chapter, Pearl typically also assumes “modularity,” which is the assumption that an intervention on a variable can be carried out with- out simultaneously altering anything else about the causal relationships encoded in the graph. The atomic intervention is assumed not to generate other interventions onother variables or to open up new causal pathways inconsistent withthe structure ofthe pre-intervention graph. Althoughmodu- larityistypicallyassumed,compoundinterventionsareeasilyaccommodated.Moredifficult,butnot impossible, are cases where the assumed intervention generates initially unforeseen counterfactuals.\nInthiscase,thepre-interventioncausalgraphmustberedrawntorepresentallpatternsofunfolding counterfactuals thatmayfollowfrompriorevents.\nthe individual-level causal effect is defined by the individual-level difference induced by the hypothetical intervention, [yi|do(di=1)]−[yi|do(di=0)]).19 Under this setup, observable associational quantities, based on Pr[Y|D], do not necessarilyequalcausalquantities,basedonPr[Y|do(D)].Mostimportantly,forgraphs such as Figure 3.4(a), the associational difference E[Y|D=1]−E[Y|D=0] does not equal the average causal effect defined by the atomic intervention on D, E[Y|do (D=1)]−E[Y|do(D=0)]. The confounding from C generates additional dependence between D and Y that enters into the average associational difference, E[Y| D=1]−E[Y|D=0], but not the average causal difference, E[Y|do(D=1)]−E[Y|do (D=0)]. The reason that C does not enter the under-intervention difference is that D is determined by a hypothetical ideal experiment in this regime. In contrast,in the pre-intervention regime, D is determined by the structural equation D=fD(C,eD) that has C as one of its inputs.\nConsider now the connection with potential outcomes. The do(.) operator is the exact analog to the superscripts given to potential outcomes in order to designate the underlying causal states that define them. In particular, Pearl states that the do(.) operator “is a mathematical device that helps us specify explicitly and formally what is held constant, and what is free to vary” (Pearl2009:358).The semantics that accompany the do(.) operator – “ideal experiment” and “atomic intervention” – are Pearl’schosenwaytoexpresstheideathatallunitsinthepopulationcouldbeassigned to the causal states in which they are observed (the “factual” ones) or to the causal states in which they are not observed (the “counterfactual” ones) and that causal effects are defined by differences attributable to movement between these alternative states. In this sense, E[Y1]−E[Y0] is equivalent to E[Y|do(D=1)]−E[Y|do(D=0)] for the graph in Figure 3.4(a), differing only in how the causal states are signified.20 Even though the do(.) operator is a crucial piece of Pearl’s variant of the directed graph approach to causal analysis, we introduced and discussed causal graphs in this chapterwithoutanyreferencetoit.Infact,weassertedthatadirectededgesignifiesa causaleffect,andthatrepresentationssuchasA→B areequivalenttotheassumption that A is a cause of B. Yet, only here, at the end of this chapter, do we note that it is the do(.) operatorthat defines the causaleffects that are signified by these directed edges.\nAslongasonemaintainsthatitisthedo(.)operatorthatdefinescausaleffects,not associational contrasts such as E[Y|D=1]−E[Y|D=0], the do(.) operator does not needtoberepresentedinthecausalgraphinanyexplicitway.Theprimarypurposeof thegraphistoencodethefullsetofcausalrelationshipsthatoneassumescharacterize a causaleffect ofinterest, so that those causal relationshipscan be consideredin both the pre-intervention regime and the under-intervention regime. The do(.) operator is 19Othercausalquantities,basedoncomparisonsofPr[Y|do(D=1)]andPr[Y|do(D=0)]couldalso bedefined,analogoustochoosingsomethingotherthanthesimpledifferencetodefineindividual-level causal effects in the potential outcome model or selecting something other than the comparison of populationexpectationsofindividual-levelpotentialoutcomes.Infact,Pearlpreferstoavoidselecting any particular comparison, emphasizing that all such comparisons are less general than focusing on thefullunder-interventiondistribution,Pr[Y|do(D)].\n20Whenweintroducedourchosennotationforthepotentialoutcomes,wealsonotedthatevenfor thepotential outcomemodelthereisawidevarietyofnotation adopted tosignifycausalstates (see footnote7onpage43).\ntherefore a piece of the underlying structure of the graphical approach, such as the error terms of nonparametric structural equations, which can be brought into the foreground when necessary to explain an identification result.21 And, even though we have not done so, the do(.) operator can be represented in graphical fashion. For each causal graph of the type presented in this chapter, two types of graphs can be drawn to show the associated under-intervention regime. For “mutilated” graphs, the directed edges that point to the causal variable of interest are deleted, leaving a causal variable with no parents because it is set by the atomic intervention. For “augmented” graphs, the original pre-intervention graph is drawn with an additional “forcing” variable that represents the atomic intervention.\nFor readers who wish to have an introduction to these additional types of graphs, as well as a slightly more formal presentationofthe do(.) operator(and its associated modularity condition within an overall definition of a Markovian causal graph), the appendix to this chapter offers an introduction to the primary literature where com- plete explanations can be found. The appendix also explains why potential outcome variablesarerarelydepictedindirectedgraphs.Readerswhoareuninterestedinthese details can skip the appendix and will be able to understand all of the material that follows.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#conclusions-1",
    "href": "extracted/Counterfactuals and Causal Inference.html#conclusions-1",
    "title": "Counterfaturals and Causal Inference",
    "section": "3.5 Conclusions",
    "text": "3.5 Conclusions\nInthischapter,wehaveintroducedthedirectedgraphapproachtocausalanalysis.We\nfirst introduced the basic elements of causal graphs and then presented the canonical causal graph for a confounded causal effect. We explained the nonparametric nature of these graphs, as represented by the structural equations that assume no functional form for the effects of causes on outcomes. We concluded by noting the equivalence between causal effects defined by directed edges in a causal graph and causal effects definedbypotentialoutcomes,demonstratingthattheequivalenceliesintheircommon invocation of what-if causal states grounded in counterfactual reasoning.\nAlong the way, we have noted that one goal of writing down a causal graph is to represent the set of causal relationships implied by past research and maintained theories. In all remaining parts of this book, we will enrich our discussion of this first goal, when, for example, we discuss whether simple graphs – such as Figure 3.7(a) for the charter school effect – are sufficiently rich to adequately represent the causal relationships that generate effects in real applications.\nAnothergoalofwritingdownacausalgraphistoassessthefeasibilityofalternative estimationstrategiesinlightofthedatathathavebeenobserved.Followinguponthis second goal, in the next part of the book we offer a full presentation of the rationale for conditioning as a causal effect estimation strategy. We then present three related methods for enacting conditioning estimators – matching, regression, and weighted regression– in three separate chapters.\n21This is similar to the implementation of particular estimation strategies that are motivated by the potential outcome model. In this case, the researcher analyzes data using observed variables Y andD.Potentialoutcomes,Y1 andY0,arebroughtout,typicallyatthebeginningofananalysis,to definethecausal effects ofinterestandtheassumptionsthatwillbemaintainedtoestimatethem.\nInsubsequentpartsofthe book,wethen furtherdemonstratehow directedgraphs canbeusedtorepresentheterogeneityandselectiononunobservedvariablesinorderto considerhowoneshouldanalyzecausaleffectswhenconditioningonobservedvariables does not identify the causal effect. We will consider mechanistic and instrumental variable approaches and conclude with estimators that use both pretreatment and posttreatment observations on the outcome variable.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#appendix-to-chapter-3-graphs-interventions-and-potential-outcomes",
    "href": "extracted/Counterfactuals and Causal Inference.html#appendix-to-chapter-3-graphs-interventions-and-potential-outcomes",
    "title": "Counterfaturals and Causal Inference",
    "section": "3.6 Appendix to Chapter 3: Graphs, Interventions, and Potential Outcomes",
    "text": "3.6 Appendix to Chapter 3: Graphs, Interventions, and Potential Outcomes\nIn this appendix, we first explain the intervention foundation of Pearl’s variant of\ncausalgraph methodology, and we then explain why potential outcomes are not com- monly depicted as outcome variables in causal graphs. This appendix is written for curious readers who wish to have an introduction to formal details before consulting the primary literature for more complete explanations.\nGraphs ThatRepresentAtomicInterventions.AsnotedinSection 3.4.2,the key linkage between the potential outcome model and the directed graph approachto causalanalysisisPearl’sconceptofanatomicintervention,asrepresentedbythedo(.) operator.Althoughthedo(.)operatorisnotvisibleinthestandardrepresentationofa causal graph, additional related graphs can be offered to demonstrate the connection more explicitly.\nThegraphinFigure3.8(a)isknownasan“augmented”graphbecauseitisthepre- intervention causal graph from Figure 3.4(a), augmented with a representationof the atomic intervention on D.22 The augmentation takes the from of a special “forcing” variable, FD, which is placed within (cid:6) to denote its special status as an assumed outside force that can produce a hypothetical atomic intervention. Accordingly, this forcing variable takes on three values in this case: do(D=0), do(D=1), and idle.\nAugmented graphs have accompanying structural equations that represent both the pre-intervention and the under-intervention regimes for the setting of variables subject to the atomic intervention (see Pearl 2009, section 3.2.2). For this graph, the structural equation for Figure 3.4(a), D=fD(C,εD), is replaced with D=Int[fD(.),C,εD], where the Int[.] function is defined so that it reduces to 1 if FD=do(D=1), to 0 if FD=do(D=0), and to fD(C,εD) if FD=idle. In other words, the pre-intervention structural equation fD(C,εD) that generates D becomes the value of FD when the forcing variable is idle because the hypothetical atomic intervention has not been enacted.\nFigure 3.8(b) then shows how to think about the graph in Figure 3.8(a) when FD =do(D =0) and FD =do(D=1). The two graphs in Figure 3.8(b) are known as the mutilated graphs under an atomic intervention. The mutilation refers to the removal of all edges pointing to the variable that is intervened upon. In this case, the 22Little would be gained by adding forcing variables for either C or Y, since the former has no causes other than ε C and the latter causes nothing else specified in the graph. Even so, no formal rulespreventtheinclusionofbothF C andF Y inafullyaugmented graph.\nC F D D Y (a) Augmented casual graph with a “forcing” variable that represents an intervention C C do(D=0) Y do(D=1) Y (b) “Mutilated” graphs that demonstrate the do(.) operator for the two values of D Figure3.8 Twoalternativerepresentationsofassumedinterventionsincausalgraphs where the effect of D on Y is confounded by C.\nobserved variable for D, represented in Figure 3.4(a) by •, is replaced by (cid:7)’s in two separate graphs that correspond to the two values of do(D=0) and do(D=1) that are determined by the intervention. Because D is no longer determined by C, having been set by a hypothetical atomic intervention,there is no directed edge fromC to D in either graph in Figure 3.8(b).\nNow, compare the standard representation of the canonical confounding graph in Figure 3.4(a) with its augmented variant in Figure 3.8(a). The latter shows the inter- ventionexplicitly,andthe formerleavesit implicit.Dawid(2010:75)claimsthatPearl onceregardedtheinclusionofforcingvariablesascrucialcomponentsofcausalgraphs.\nDawid argues that “he [Pearl], and most of those following him, have [recently] been usingonlytheimplicitversion,inwhichtheinterventionvariablesFV arenotexplicitly included in the diagram,but (to comply with the Pearlianinterpretation)the DAG is neverthelesstobeinterpretedasiftheywere.”Dawidregardsthesuppressionofinter- vention variables as a “retrograde move” that entails a “loss of transparency.”23 For simple graphs,Dawidis surelycorrectthatforcingvariablesdoincreasetransparency.\nFormorecomplexdiagrams,forcingvariablescanbeavisualdistraction.Accordingly, in this book, we will generally follow Pearl and not offer such representations. As we explain in the next section, however, Pearl builds very precise definitions of causal graphs, which, when kept in mind while interpreting a causal graph in its standard representation,leavelittledoubtaboutthecrucialroleofatomicinterventionsandthe do(.) operator.\n23Dawidprefersamoregeneral influencediagramforcausal graphs,restingontopofthedecision theoreticapproachhehaslongchampioned(seeDawid2002,2012).\nCriteria for Causal Graphs. For the canonical confounding graph in Figure 3.4(a), only three observable variables are present: C, D, and Y. No reference to the do(.) operator that defines causal effects is visible in the graph. Yet, we wrote in this chapterthatthis directedgraphis alsoa“causalgraph.”Thecarefulreadermayhave noticed that we have presented other directed graphs in this chapter from which we have withheld the label “causal graph.” We now explain.\nPearlhas specific requirementsfor whenadirectedgraphcanbe anointedacausal graph(Pearl2009,definitions1.3.1-3,2.2.2,and7.1.1),basedonwhetherthecandidate graph and its implied joint probability distribution satisfy “Markovian” conditions (Pearl2009,theorem1.4.1).Thesecriteriaaredifficulttoconveyindirectformwithout introducing all aspects of Pearl’s approach. We offer the following simplified criteria and strongly encourage readers to consult Pearl (2009) for their more complete and original expression.24 Accordingly, and at the risk of too much oversimplification, a directed graph can be considered a causal graph by Pearl’s definitions if 1. All variables in the graph,{V},are observed(other than those variables implic- itly included in the error terms, {eV}, that are only revealed under magnifica- tion).\n\nAll variables in the graph, {V}, have errorterms, {eV}, that areindependent of allvariablesinthegraph,{V},andthataremutuallyindependentofeachother.\nIt is reasonable to assume that each variable in the graph, V, can be subjected to a hypothetical intervention, do(V =v), that\n\n\nreplaces the pre-intervention probability distribution of V, Pr(V), with a single intervention value v,\nremoves the directed edges in the graph that terminate at V, and\nchangesnothingelseinthegraph(eventhoughthe settingofV tov propa- gates through the probability distributions of the descendants of V via the directed paths that remain in the graph).\n\nCriteria 1 and 2 should be clear to those familiar with path models; they are stronger versions of the standard linear path model identifying assumptions that “all causal variables are uncorrelated with the error terms of all endogenous variables” and “all error terms on endogenous variables are uncorrelated with each other.” Criterion 3 is typically considered to be unique to Pearl’s framework, but Pearl himself makes the case that versions of criterion 3 were essential to early motivations of path-modeling techniques and were subsequently forgotten by their inheritors (see Bollen and Pearl 2013).25 24Wewillnot,forexample,discussthebasicrequirementthatthegraph,anditsassociatedstruc- turalequations,fullydeterminesthejointprobabilitydistributionacrossallvariablesdepictedinthe graph. Using our simplified notation, this criterion is “All variables in the graph, {V}, have proba- bilitydistributions,{Pr(V)},thataregeneratedbyassociatedstructuralequations{f V(.)}thatare functionsonlyin(a)thevariablesthatpointdirectlytotheminthegraph(i.e,their“parents”)and (b)theirownerrorterms,e V.” 25In the broader literature on causal graphs beyond Pearl’s work, criterion 3 is required only for the subset of the variables in the graph that are immediately relevant for identification of the focal causaleffect(seeDawid2002;Glymouretal.2001;RobinsandRichardson2010).\nBeforeaddressingcriterion3,weshouldclarifyoneaspectofcriteria1and2.Figure 3.4(a) can be anointed a causal graph because its meets criteria 1 and 2 and because we have implicitly assumed up until now that criterion 3 is met as well. If criterion 1 is not met, but criteria 2 and 3 are, then the directed graph is “semi-Markovian”and typically thought of as if it is a causal graph (because what is observable and what is unobservable is subject to change).\nNow consider criterion 3. The lead in – “It is reasonable to assume …” – is our own writing, but it is consistent with Pearl’s presentation of the same material. The key idea is that, by placing such a structure on the graph through a series of finely articulateddefinitionsthatareadoptedasassumptions,causaleffectscanberigorously defined. The payoffto adopting such structure is twofold. First, a directed graphthat is a causal graph does not require that forcing variables be displayed to represent the atomic interventions that define all of the causal effects in the graph. Second, if a directedgraphisacausalgraphthatsatisfiescriteria1,2,and3,thentheobserveddata canbe manipulatedto deliverestimatedcausalcontraststhatareequal to true causal contrastsdefined by the applicationofthe do(.) operatorseparatelyto allvariablesin the graph.26 (Weakervariantsofthisimplicationareavailable,andshouldbe obvious.\nEvenifthefullcausalgraphdoesnotmeetthesecriteria,itisoftenpossibletoidentify specific causal effects while other effects in the graph remain unidentified.) We will demonstrate more fully the second implication in the next chapter, where we introduce the back-door criterion for sufficient conditioning to identify a causal effect.27 To get a handle on this implication now, it may be helpful to consider it in reverse for the simplest estimators we have considered so far in this book. Whenever conditioning estimators, or simple naive estimators, can be used to recover all causal contrasts in a graph from observed associational contrasts, the directed graph is a causal graph. For example, for Figure 3.4(a) a conditioning estimator (described in brief in Section 3.2.3) can be used to generate a consistent estimate of the average causal effect of D on Y, defined as E[Y|do(D=1)]−E[Y|do(D=0)].28 This result is true because the graph in Figure 3.4(a) is a causal graph: All variables are observed; the error terms that are viewable under magnification are defined to be independent of all else in the graph; and we have no reason to believe that it is unreasonable to assumethat criterion3 applies (becausewe havenoreasonto believethat intervening on D would alter C, etc.).\nFor anotherexample that alsoservesas a substantive bridge to the finalsection of this appendix, recall the graph in Figure 3.5 that includes an unobservedconfounder, 26Writteninthisform,thisimplicationholdsonlyforaninfinitesample,soastorendersampling error unable to destroy the “equal to” within it. The estimates are therefore best interpreted as consistentestimates ofthetruecausaleffects.\n27More generally, Pearl (2009, section 3.4) presents three rules that can be applied to candidate directed graphs and their associated structural equations to assess whether all effects in the graph canbeidentified.Hecharacterizes suchassessmentastheapplicationof“docalculus”withthegoal of reducing do-defined probability distributions to equivalent probability distributions based only on observable variables (or, more specifically, the joint probability distribution of all variables, as structuredbythepre-interventionregimeencoded inthegraph).\n28In addition, because the effects of C on both D and Y are unconfounded, assuming criterion 2 holds,thenaiveestimator(orvariantsofitifChasmorethantwovalues)canbeusedtoconsistently estimatethesetwoeffects.\nA,fortheeffectofeducation,E,onearnings,Y.Assumingcriteria2and3aremet,this graphis stillnotfully Markovian,andhence notacausalgraph,becausecriterion1 is notmet. Accordingly,no conditioning estimatorcan be undertakenwith the observed datato generatevalues thatwouldcorrespondto E[Y|do(E=e)]for allvaluese ofE.\nConditioningonlyontheobservedconfounderC doesnoteliminatetheconfoundingby the unobserved variable A. However, for Pearl, this graph would be semi-Markovian because observation of A would then render it a fully Markovian causal graph, for which an effective conditioning estimator would then become available. Thus, if we can assume that criteria 2 and 3 are met, then we can state that Figure 3.5 would be a causal graph if A were observed.\nThe Absence of Potential Outcome Variables from Causal Graphs.Imag- ineagraphthatincludedarrowsbetweenDandY0 andbetweenDandY1,suggesting purported causal effects such as D→Y0 and D→Y1. Such causal relationships are inherentlynonsensicalbecauseY1 andY0 aredefinedinrelationtoeachother,asthey jointlydeterminetheobservedvariableY ininteractionwiththecausalstatesindexed by D.\nRecall the definition offered in Equation (2.2): Y =DY1+(1−D)Y0. (3.8) OnetrivialwaytoexplainwhycausaleffectssuchasD→Y1 arenonsensicalistotake Equation (3.8) and rewrite Y1 in individual realizations as y1=yi−(1−di)y i0 . (3.9) i di If we think of the supposed causaleffect D→Y1 as being the theoretical difference in y i1 that would result from the action of switching di from 0 to 1, we can alternatively substitute 0 and 1 into Equation (3.9) and generate the result that the supposed causal effect of di on y i1 is the difference between “undefined” and yi. Doing the same operationfor y i0 delivers a supposedcausaleffect of di ony i0 as the difference between yi and “undefined.” In other words, it does not make any sense to seek the causal effect of D on Y1 or of D on Y0, even though we have already offered examples where, empirically and theoretically,theremaybegoodreasontobelievethatwithinthepopulationofinterest there may be an association between values of D and Y1 and/or between D and Y0 because of the ways individuals enter into the observed causal states (see Section 2.7).Fromacausalgraphperspective,if such associationsexist,they areproducedby causalrelationsthatconnectDandY butthatdonottravelthroughD→Y.Theseare exactly the sorts of relationships that we earlier argued, with reference to Equation (2.14), generate inconsistency and bias in the the naive estimator. Individuals with di=1 may have higher values, on average,for y i0 and/or y i1 than those with di=0. If so, such average differences must arise because D and Y both mutually depend on a third variable, such as C in Figure 3.4(a).29 29Pearl(2009:342)wouldstatesuchdependenceas“{Y0,Y1}representsthesumtotalofallexoge- nousvariables,latent aswellasobserved, whichcaninfluenceY throughpathsthat avoidD”(with notation changes from the original to match our example). The only point which differs from our Can one represent the same basic insight using causal graphs? Pearl, in his own writing, has largely chosen not to do so (but see Pearl 2009, section 11.3.2).30 The broader literature in causal graph methodology shows that it is possible to express the same ideas using directed graphs, although these are not graphs that are to be used in the same way as other graphs in this book. (A recent usage similar to ours in this section can be found in de Luna, Waernbaum, and Richardson (2011). See their citations to precursors.) Recall Figure 3.5, which was used to bridge our first presentation of conditioning in causal graphs with our earlier presentation of the ability bias example used to introducethepotentialoutcomemodelinChapter2.Inthatgraph,conditioningonC will not generate a consistent and unbiased estimate of the effect of education, E, on earnings,Y,becauseofthepresenceoftheunobservedabilityconfounder,A.However, inChapter2wediscussedsuchconfoundingbyabilityinsteadasinconsistencyandbias inthenaiveestimator.InSection2.7.3,wedefinedtwotypesofinconsistencyandbias, aided by the potential outcome definitions. Baseline bias in the naive estimator was presentwhen EY0|D=1=E[Y0|D=0], and treatment effect bias was presentwhen Eδ|D=1=Eδ|D=0.\nFigure3.9presentspairsofdirectedgraphsthatexpressthe mutualdependence of potential outcomes and causal variables on exogenous confounders in three different scenarios.Notice first that none of the graphs in Figure3.9 include either nonsensical causal effects, such as E→Y0 or E→Y1, or the observedoutcome variable earnings, Y. Instead, these graphs are drawn solely to represent the mutual dependence of the potential outcomes for earnings, Y0 and Y1, and the focal causal variable, E, on observed confounders, C, and the unobserved ability confounder, A.\nRecall that for the representation in Figure 3.5, it was not necessary to stipulate that E took on any particular values because the graph holds under a many-valued version of E. For simplicity of representation, and to match our earlier discussion in Section 2.7.3, we will now consider the case where E takes on only two values: 0 for those who do not obtain a bachelor’s degree and 1 for those who do.\nFor Figure 3.9(a), confounding by C generates noncausal associations between E and both Y0 and Y1. Baseline confounding by ability, A, generates a noncausal asso- ciationbetweenonlyeducationandY0.Thisisthecase,notedearlierinSection2.7.3, where those who have college degrees would have higher earnings than those without explanationhereisthatPearlusesthe{.,.}notationtoemphasize,asinignorability,thattheexoge- nous variables can structure a function defined in Y1 and Y0, such as the difference between these two.Wemakethesamepointinthegraphsthatfollow.\n30Although Pearl has not devoted a great deal of attention to developing graphical models that includepotentialoutcomes,heandhiscolleagueshavedevotedconsiderableattentiontotherepresen- tation of counterfactuals in causal graphs. Shpitser and Pearl (2007) develop a powerful framework for counterfactual graphs, following on Pearl’s earlier work on twinned network graphs; see Pearl (2000:213–14) and citations therein to earlierwork; Shpitser (2012a, 2012b) offers particularlyclear expositionsofthesegraphs.Counterfactualgraphsarebeyondthescopeofthisbook,inpartbecause they requireamorethorough understanding ofPearl’sdocalculus and fullstructural causal models than we have space to provide and than is necessary to understand the relevance of his framework formostformsofobservationalresearchinthesocialsciences.\nA Y0 Y1 C E C E (a) Unobserved baseline confounding by A Y0 A Y1 C E C E (b) Unobserved effect confounding by A A Y0 A Y1 C E C E (c) Unobserved baseline and effect confounding by A Figure3.9 Alternative graphs for the joint dependence of a two-valued causal vari- able for education (E) and potential outcomes for earnings (Y0 and Y1) on observed confounders (C) and on an unobserved confounder for ability (A).\ncollege degrees in the counterfactualstate in which they did not in fact obtain college degrees(evenafter adjustment for C). Inother words,being “smarter”paysoffin the labor market, even if one does not carry on to earn a bachelor’s degree.\nIncontrast,forFigure 3.9(b), confoundingby ability generatesa noncausalassoci- ationbetween educationand Y1 but not between education and Y0. This is a formof treatment effect confounding, wherein those who do not obtain college degrees would nothaveearningsas highasthose whodo obtaincollegedegreesinthe counterfactual state in which they did in fact obtain college degrees (again, after adjustments for C). Here, being smarter helps one get more of an earnings payoff from obtaining a bachelor’sdegree,eventhough,contraryto Figure3.9(a),being smarterdoesnotlead to higher earnings in the absence of a college degree.\nForFigure3.9(c),bothtypesofconfoundingbyabilityarepresent,asinthepattern presentedearlierinSection2.7.3.Inthiscase,however,thereislittleadvantageinusing the pairedgraphrepresentationinsteadof the single directed graphin Figure 3.5. For Figures 3.9(a), (b), and (c), the separate graphs for Y0 and Y1 allow for distinct patterns of confounding, and such clarity may be useful in some situations.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#conditioning-and-directed-graphs",
    "href": "extracted/Counterfactuals and Causal Inference.html#conditioning-and-directed-graphs",
    "title": "Counterfaturals and Causal Inference",
    "section": "4.1 Conditioning and Directed Graphs",
    "text": "4.1 Conditioning and Directed Graphs\nInSection1.5,weintroducedthethreemostcommonapproachesfortheestimationof\ncausal effects, using language from the directed graph literature: (1) conditioning on variables that block all back-door paths from the causal variable to the outcome vari- able, (2) using exogenous variation in an appropriate instrumental variable to isolate covariation in the causal variable and the outcome variable, and (3) establishing the exhaustive and isolated mechanism that intercepts the effect of the causal variable on the outcome variable and then calculating the causal effect as it propagates through the mechanism. In this chapter, we consider the first of these strategies, which moti- vates the basic matching, regression, and weighted regression techniques that we will present in Chapters 5, 6, and 7.\n105 C O D Y Figure4.1 A graph in which the causal effect of D on Y is confounded by the back- door path D←C→O→Y.\nIn Chapter 3, we explained the motivation for and execution of very simple con- ditioning estimators (see Section 3.2.3). In this chapter, we provide a more complete explanation of when, why, and how conditioning estimators will succeed in delivering estimates that can be given causal interpretations. We first reintroduce conditioning in a way that will reorient our perspective away from the “confounder variable” per- spective ofChapter3to the more complete“back-doorpath”perspective thatwewill use in the remainder of this book.\n4.1.1 From Confounders to Back-Door Paths Consider Figure 4.1, which is an elaboration of the canonical confounding graph pre- sented earlier in Figure 3.4(a). For this figure, the intermediate observed variable, O, expands the single-edge causal effect C →Y in Figure 3.4(a) to the directed path C→O→Y in Figure 4.1. We noted in our prior discussion of Figure 3.4(a) that con- ditioning on C would allow us to generate a consistent and unbiased estimate of the causal effect of D on Y. This result holds for Figure 4.1 as well. However, for Figure 4.1, one could instead condition on O and achieve the same result. In fact, one could condition on both C and O as a third alternative.\nThe key goal of a conditioning strategy is not to adjust for any particular con- founder but rather to remove the portion of the total association between D and Y that is noncausal. For Figure 4.1, the strategy to adjust for C is often referred to as “balancingthe determinants oftreatmentassignment,”andit is the standardmotiva- tion for matching estimators of causal effects. The alternative strategy to adjust for O is often referred to as “adjusting for all other causes of the outcome,” and it is the standard motivation for regressionestimators of causal effects.\nPearlcharacterizesboth strategiesin a novelway,using the languageof back-door paths. As defined in Section 3.2.1, a path is any sequence of edges pointing in any direction that connects one variable to another. We now formally define a particular type of path that we have invoked informally already: A back-door path is a path between any causally ordered sequence of two variables that begins with a directed edge that points to the firstvariable.1 For the directed graphin Figure 4.1, two paths connect D and Y: D←C →O→Y and D→Y. The path D←C →O→Y is a 1“Causallyordered”meansthatthefirstvariablecausesthesecondvariablebyadirectedpathof some length. For the example discussed in this paragraph, D and Yare causally ordered because D causesY byD→Y.C andYarealsocausallyorderedbecauseC causesY byC→O→Y.D andO arenot causallyorderedbecausetheonlytwopathsthatconnectthem(D←C→OandD→Y ←O) arenotdirectedpaths.Bothofthesepathshaveedgespointingintwodirections.Recallalsothatwe back-door path because it begins with a directed edge pointing to D. Likewise, the path D→Y is not a back-door path because it does not begin with a directed edge pointing to D.2 In Pearl’s language, the observed association between D and Y does not identify the causal effect of D on Y in Figure 4.1 because the total association between D and Y is an unknown composite of the true causal effect D→Y and a noncausal associationbetween D and Y that is generated by the back-door path D←C→O→ Y. Fortunately, conditioning on C, O, or both C and O will block the back-door path, leaving within-stratum associations between D and Y that can be given causal interpretations (and can also be suitably averaged to obtain consistent and unbiased estimates of average causal effects of various types). The remainder of this chapter explains this result, as well as many others that are more complex.\n4.1.2 Conditioning and Collider Variables As a technique for estimating causal effects, conditioning is a very powerful and very general strategy. But, it is a much more complicated procedure in general than is suggested by our discussion of the simple directed graphs in Figures 3.4(a) and 4.1.\nMany of the complications arise when collider variables are present, and Pearl has explained systematically how to resolve these complications.\nRecallthatavariableis acollideralongaparticularpathifithastwoedgespoint- ing directly to it, suchas C in the path A→C←B in Figure 3.3(c). For conditioning estimators of causal effects, collider variables must be handled with caution. Condi- tioning on a collider variable that lies along a back-door path does not help to block the back-door path but instead creates new associations.\nThereasoninghereisnotintuitive,butitcanbeconveyedbyasimpleexamplewith the mutual causation graph in Figure 3.3(c). Suppose that the population of interest is a set of applicants to a particular selective college and that C indicates whether applicants are admitted or rejected (i.e., C=1 for admitted applicants and C=0 for rejected applicants). Admissions decisions at this hypothetical college are determined entirely by two characteristics of students that are known to be independent within the population of applicants: SAT scores and a general rating of motivation based on an interview. These two factors are represented by A and B in Figure 3.3(c). Even thoughSATscoresandmotivationareunrelatedamongapplicantsingeneral,theyare not unrelated when the population is divided into admitted and rejected applicants.\nAmongadmittedapplicants,themostmotivatedstudentswillhavelowerthanaverage SATscores,andtheleastmotivatedstudentswillhavehigherthanaverageSATscores.\nThus, the college’s sorting of applicants generates a pool of admitted students within which SAT scores and motivation are negatively related.3 stipulatedinChapter3thatwewillonlyconsideracyclicgraphsinthisbook.Withoutcycles,causal orderiseasilydiscernedbyinspectingthedirectedpaths inthegraph.\n2Recall that a directed path is a path in which all edges point in the same direction. Because all back-door paths have edges pointing in two directions, back-door paths are not directed paths.\nHowever,theycancontaindirectedpaths,suchasthedirectedpathC→O→Y thatisembeddedin theback-door pathD←C→O→Y.\n3Anegativecorrelationwillemergeforrejectedstudents aswellif(1)SATscoresandmotivation havesimilarlyshapeddistributionsand(2)bothcontributeequallytoadmissionsdecisions.Asthese noitavitoM SAT Applicants to a Hypothetical College Rejected Admitted Figure4.2 Simulation of conditional dependence within values of a collider variable.\nThis example is depicted in Figure 4.2 for 250 simulated applicants to this hypo- thetical college. For this set of applicants, SAT and motivation have a very small positive correlation of .035.4 Offers of admission are then determined by the sum of SAT and motivation and grantedto the top 15 percent of applicants (as shown in the upper right-handportion of Figure 4.2).5 Among admitted applicants, the correlation between SAT and motivation is −.641, whereas among rejected applicants the corre- lation between SAT and motivation is −.232. Thus, within values of the collider (the admissions decision), SAT and motivation are negatively related.\nAs Pearl documents comprehensively with a wide range of hypothetical examples, this is a very general feature of causal relationships and is present in many real-world applications.ElwertandWinship(2014)presentmanyexamplesfromthesocialscience literature. In the next section, we show that care must be taken when attempting to estimateacausaleffectbyconditioningbecauseconditioningonacollidervariablecan spoil an analysis.\nconditionsarealtered,otherpatternscanemergeforrejectedstudents,suchasifadmissionsdecisions areanonlinearfunctionofSATandmotivation.\n4Thevalues forSAT and motivation are250 independent drawsfromstandard normal variables.\nThedrawsresultinanSATvariablewithmeanof.007andastandarddeviationof1.01aswellasa motivation variable with mean of −.053 and a standard deviation of 1.02. Although the correlation betweenSATandmotivationisasmallpositivevalueforthissimulation,wecoulddrivethecorrelation arbitrarilycloseto0byincreasingthenumberofapplicants forthesimulation.\n5Admissionisoffered tothe37of250students (14.8percent) whosesum ofSATandmotivation isgreaterthanorequalto1.5.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#the-back-door-criterion",
    "href": "extracted/Counterfactuals and Causal Inference.html#the-back-door-criterion",
    "title": "Counterfaturals and Causal Inference",
    "section": "4.2 The Back-Door Criterion",
    "text": "4.2 The Back-Door Criterion\nWithhis languageofback-doorpaths, colliders,anddescendants,Pearlhasdeveloped\nwhat he labels the back-door criterion for determining whether or not conditioning on a given set of observed variables will identify the causal effect of interest.6 The overall goal of a conditioning strategy guided by the back-door criterion is to block all paths that generate noncausal associations between the causal variable and the outcome variable without inadvertently blocking any of the paths that generate the causal effect itself. In practice, a conditioning strategy that utilizes the back-door criterion is implemented in two steps: Step 1: Write down the back-door paths from the causal variable to the outcomevariable,determinewhichonesareunblocked,andthensearch foracandidateconditioningsetofobservedvariablesthatwillblockall unblocked back-door paths.\nStep 2: If a candidate conditioning set is found that blocks all back-door paths, inspect the patterns of descent in the graph in order to verify that the variables in the candidate conditioning set do not block or otherwise adjust away any portion of the causal effect of interest.\nThis two-step procedure is justified by the following reasoning, which constitutes Pearl’s back-door criterion: Back-Door Criterion If oneormore back-doorpaths connectthe causalvariableto the outcome variable, the causaleffect is identified by conditioning ona setof variables Z if Condition1.Allback-doorpathsbetweenthecausalvariableand the outcome variable areblockedafter conditioning onZ, which will always be the case if each back-door path (a)containsachainofmediationA→C→B,wherethe middle variable C is in Z, or (b) contains a fork of mutual dependence A←C→B, where the middle variable C is in Z, or (c) contains an inverted fork of mutual causation A→ C←B, where the middle variable C and all of C’s descendants are not in Z; 6The back-door criterion is meant to be used only when the causal effect of interest is specified asacomponentofagraphthatisaMarkoviancausalmodel,orwouldbeifallvariablesrepresented inthe graph were observed; see Pearl’s causal Markovcondition for the existence of a causal model (Pearl 2009, section 1.4.2, theorem 1.4.1), as well as our discussion in the appendix to Chapter 3.\nThisrequirementcanbeweakenedwhenthegraphisonlyalocallyMarkoviancausalmodel,aslong astheunderspecifiedcausalrelationsareirrelevanttoanevaluationoftheback-doorcriterionforthe particular causal effect under consideration. All of the examples we utilize in this book meet these conditions.\nand Condition 2. No variables in Z are descendants of the causal variable that lie on (or descend from other variables that lie on) any of the directed paths that begin at the causal variable and reach the outcome variable.7 To explainthe back-doorcriterion,wewillfirstconsiderConditions1(a),(b),and(c), using examples where Condition 2 is met by default because the only descendant of the causal variable D in the graph is the outcome variable Y (and where we assume that the analyst does not consider conditioning on Y itself).\nConditions 1(a) and 1(b) of the back-door criterion should be clear as stated.\nReturn one last time to the simple example in Figure 4.1. Here, there is a single back-door path, D←C →O→Y, which includes within it both a fork of mutual dependence (D←C→O) and a chain of mediation (C→O→Y). By the back-door criterion,conditioning onC blocksthe path D←C→O→Y because C is the middle variable in a fork of mutual dependence. Likewise, conditioning on O blocks the path D←C→O→Y becauseO isthe middle variableinachainofmediation.As aresult, the candidate conditioning set meets Pearl’s back-door criterion if Z is C, O, or both C and O.\nCondition1(c),however,isquitedifferentthanConditions1(a)and1(b)andisnot intuitive. It states instead that the set of candidate conditioning variables Z cannot includecollidervariablesthatlieonback-doorpaths.8 Considerthefollowingexample.\nAcommonbut poorlyjustifiedpracticeinthe socialsciencesis tosalvagearegression model from suspected omitted-variable bias by adjusting for an endogenous variable thatcanberepresentedasaproxyfortheomittedvariablethatisunobserved.Inmany cases, this strategy will fail because the endogenous variable is usually a collider.\nSuppose that an analyst is confronted with a directed graph similar to the one in Figure 3.4(b), in which the causal effect of D on Y is confounded by an unob- served variable, such as C. When in this situation, researchers often argue that the effectsoftheunobservedconfoundercanbedecomposedinprincipleintoalaggedpro- cess, using a prior variable for the outcome, Yt−1, and two separate unobserved vari- ables, U and V, as in Figure 4.3. For this graph, there are two back-door paths from D to Y: 1. D←V →Yt−1→Y and 2. D←V →Yt−1←U→Y.\n7Thisrepresentationoftheback-doorcriterionisacombinationofPearl’sdefinitionofd-separation (Pearl2009:16–17), hisoriginalspecificationoftheback-doorcriterion(Pearl2009:79), andthegen- eralization of the back-door criterionthat was developed and labeled the “adjustment criterion” by Shpitser, VanderWeele, and Robins (2010). In an appendix to this chapter, we clarify our specifi- cation of Condition 2, as incorporated from the adjustment criterion. In brief, for Pearl’s original back-door criterion, Condition 2 requires more simply (but overly strongly) that no variables in Z canbedescendants ofthecausalvariable.\n8Because the “or” in the Conditions 1(a), (b), and (c) of the back-door criterion is inclusive, one can condition on colliders and still satisfy the back-door criterion if the back-door paths along whichthecolliderslieareotherwiseblockedbecauseZsatisfiesCondition1(a)orCondition1(b)with respecttoanother variableonthesameback-doorpath.\nU Y t–1 V Y D Figure4.3 A causal diagram in which Yt−1 is a collider along a back-door path.\nThe lagged outcome variable Yt−1 lies on both of these back-door paths, but Yt−1 does not satisfy the back-door criterion. Notice first that Yt−1 blocks the first back- door path because, for this path, Yt−1 is the middle variable in a chain of mediation, V →Yt−1→Y. But, for the second path, D←V →Yt−1←U →Y, Yt−1 is a collider becauseitisthemiddlevariableinaninvertedforkofmutualcausation,V →Yt−1←U.\nAccordingly, conditioning on Yt−1 would eliminate part of the back-door association between D and Y because Yt−1 blocks the first back-door path D←V →Yt−1→Y.\nBut,atthesametime, conditioningonYt−1 wouldcreateanew back-doorassociation between D and Y because conditioning on Yt−1 unblocks the second back-door path D←V →Yt−1←U→Y.\nHowcanconditioningonacolliderunblockaback-doorpath?Toseetheanswerto thisquestion,recallthediscussionofconditioninginreferencetoFigure3.3(c)andthen asdemonstratedinFigure4.2. There,withthe exampleofSATandmotivationeffects on a hypothetical admissions decision to a college, we explained why conditioning on a collider variable induces an association between those variables that the collider is dependent on. That point applies here as well, when the causal effect of D on Y in Figure 4.3 is considered. Conditioning on a collider that lies along a back-door path unblockstheback-doorpathinthe sensethatitcreatesanassociationbetweenD and Y within at least one of the subgroups enumerated by the collider.\nConsiderthe slightlymorecomplexexamplethatis presentedinFigure4.4(which issimilarto Figure1.1, exceptthat the bidirectededgesthatsignifiedunspecifiedand unobservedcommoncauseshavebeenreplacedwithtwospecificunobservedvariables, U and V). Suppose, again, that we wish to estimate the causal effect of D on Y. For this directed graph, there are two back-door paths between D and Y: 1. D←A←V →F →Y and 2. D←B←U→A←V →F →Y.\nNotice that A is a collider variable in the second back-door path but not in the first back-doorpath.Asaresult,thefirstback-doorpathgeneratesanoncausalassociation betweenDandY,butthesecondback-doorpathdoesnot.Wethereforewanttoblock the first path without unblocking the second path.\nV G U A F B D Y C Figure 4.4 A causal diagram in which A is a collider on a back-door path.\nFor this example, there are two entirely different and effective conditioning strate- giesavailablethatwillidentifythe causaleffect(numbers1and3inthefollowinglist) and a third one that may appear to workbut that will fail (number 2 in the following list): 1. F isthemiddle variableinachainofmediation,V →F→Y,forbothback-door paths. As a result, F satisfies the back-door criterion, and conditioning on F identifies the causal effect of D on Y.\n\nAisamiddlevariableinachainofmediation,D←A←V,forthefirstback-door path. However, A is a collider variable for the second back-doorpath because it is the middle variable in a fork of mutual causation, U →A←V. As a result, A alone does not satisfy the back-door criterion. Conditioning on A does not identify the causal effect of D on Y, even though A lies along both back-door paths.ConditioningonAwouldunblockthe secondback-doorpathandthereby create a new, noncausal, back-door association between D and Y.\nA is a middle variable in a chain of mediation, D←A←V, for the first back- doorpath.Likewise,B isamiddlevariableinachainofmediation,D ←B←U, for the second back-door path. Thus, even though A blocks only the first back- doorpath(and, infact, conditioning onitunblocks the secondback-doorpath), conditioning on B blocks the second back-door path. As a result, A and B together (but not alone) satisfy the back-door criterion, and conditioning on them together identifies the causal effect of D on Y.\n\nIn sum, for this example the causal effect can be identified by conditioning in one of two minimally sufficient ways: either condition on F or condition on both A and B.9 Now, we need to consider the complications introduced by descendants, as stipu- lated in both Condition 1(c) and Condition 2. Notice that Condition 1(c) states that neither C nor the descendants of C can be in Z. In words, conditioning on a collider or the descendant of a collider that lies on a back-door path will unblock the back- door path. Consider an extension of our prior analysis of Figure 4.3. For the graph in Figure 4.5, there are again two back-door paths from D to Y: 1. D←V →Yt−2→Yt−1→Y and 2. D←V →Yt−2←U→Y.\nThe firstpathdoes not containany collidersandtherefore confounds the causaleffect of D on Y. The second back-door path, however, is blocked without any conditioning because Yt−2 is a collider on it. One might think, therefore, that conditioning on Yt−1 will block the first path without unblocking the second path. Condition 1(c) rules out this possibility because Yt−1 is a descendant of Yt−2, and the latter is a collider on an already blocked path. The reasoning here is straightforward. The descendant Yt−1 is simply a noisy version of Yt−2 because its structural equation is Yt−1=fYt−1(Yt−2,eYt−1), where the error term, eYt−1, is (as usual) assumed to be independent of all else in the graph. As a result, conditioning on Yt−1 has the same consequences for the second back-door path as conditioning on Yt−2.10 Having explained Conditions 1(a), (b), and (c) of the back-door criterion, we can now consider Condition 2, which states that none of the variables in the possible conditioning set Z can be descendants of the causal variable that block the causal effect of interest by lying on or descending from any of the directed paths that begin atthe causal variableandreachthe outcome variable.Recall that a directedpathis a path in which all edges point in the same direction. In all prior examples discussed in thissection,the onlydescendantofD hasbeenY,andthusCondition2hasbeenmet by default (under the assumptionthat the analysthas notconsideredconditioning on the outcome variable Y itself).\nWe now consider two examples where additional descendants of D are present.\nFigure4.6presentsagraphthatelaboratesFigure4.1,wherenowthetotaleffectofD onY isseparatedintoanindirectpathwaythroughamediatingvariable,D→N→Y, and a remaining direct effect, D→Y. We will discuss models with such mediating 9 One can of course condition in three additional ways that also satisfy the back-door criterion: F and A, F and B, and F, A, and B. These conditioning sets include unnecessary and redundant conditioning.\n10Hernn,Hernandez-Diaz, andRobins(2004) offeranexcellent discussionofexamples inepidemi- ology for which such descendants of colliders are a primary focus. For their types of examples, the outcomeis“death,”thecolliderontheback-doorpath(orelsewhereinthecausalgraph)is“getting sick enough to be admitted to a hospital for treatment,” and the variable that is conditioned on is “inahospital.”Conditioningon“inahospital”(byundertakingastudyofhospitalpatients)induces associationsbetweenthedeterminantsofsicknessthatcanspoilstandardanalyses.Elwert(2013)and Elwert and Winship (2014) cover many of the same issues from a social science perspective. In an appendixtothischapter, wealsoprovideadditionaldiscussionandexamples.\nU Y t–2 Y t–1 Y V D Figure4.5 AcausaldiagraminwhichYt−2 isacollideronaback-doorpathandYt−1 is its descendant.\nC O D Y N Figure4.6 Aconfoundedcausaleffectexpressedasanindirecteffectandanetdirect effect.\nmechanisms in substantial detail in Chapter 10, and for now we will use this graph only to introduce a discussion of Condition 2 of the back-door criterion.\nAswehavenotedinthissectionandelsewhere(and,assumingnow,withoutlossof generality that D is a two-valued treatment), conditioning on either C or O identifies thetotalaveragecausaleffectofDonY,whichwedefinedinSection3.4asE[Y|do(D= 1)]−E[Y|do(D=0)].Theback-doorcriterionstatesthatif,inadditiontoC and/orO, we also conditioned on N, the resulting estimate would no longer identify the casual effectofDonY.TheconditioningsetofC,O,andN violatesCondition2oftheback- doorcriterionbecauseN isadescendantofDthatliesonadirectedpath,D→N→Y, that reaches Y. As a result, the back-door criterion indicates that the analyst should not condition on N.\nWe suspect that this conclusion would be clear to readers without consulting the back-door criterion (by reasoning that adjustment for N would rob the total causal effect of D on Y of some of its magnitude, leaving only a partial direct effect that is not equal to E[Y|do(D=1)]−E[Y|do(D=0)]).11 Such reasoning is correct, and Condition 2 of the back-door criterion is, in part, a formalization of this intuition.\n11Inthissection,weareconsideringonlyhowtoapplytheback-doorcriterionwhenthegoalisto estimate the total effect of the cause D on the outcome Y. If, instead, the analyst is interested in estimatingthedirecteffectofDonY,netoftheindirecteffectofDonY throughN,thenadjustment for N is necessary. VanderWeele (in press) provides a comprehensive treatment of the identification andestimationofdirecteffects. WewillreturntotheseissuesinChapter10,wherewewillconsider howtoidentifycausaleffects usinggenerativemechanisms.\nC O M D Y N B U Figure4.7 A graph where the effect of D on Y is not identified by conditioning on O and B because O is a descendant of D.\nHowever,Condition2ismorefinelyarticulatedthanthisintuitionalone.Itinvalidates conditioningsets that adjustawayanyportionofthe causaleffectofinterest,notjust those portions that are carried by variables that mediate the causal effect. Just as conditioningonthedescendantofacolliderhasthesameconsequencesasconditioning onthe collider itself,conditioning ona descendantofa variablethatlies ona directed path from the causal variable to the outcome variable has the same consequences for identificationresultsasconditioningdirectlyonthevariablefromwhichitdescends.12 ConsiderFigure4.7,whereweareagaininterestedintheeffectofDonY andwhere wehavenowspecifiedtwomediatingvariables,M andN,thatcompletelycharacterize the total effect of D on Y. For this graph, three back-door paths connect D to Y: 1. D←C→O→Y, 2. D←C→O←M→Y, and 3. D←B→U→Y.\nInaddition,thevariablesC,M,andU areunobserved,andthustheyarenotavailable to use in a conditioning estimator.\nSuppose that one decides to condition on both O and B. First, note that these two variables do not satisfy Conditions 1(a), (b), and (c) of the back-door criterion.\n12Notice further that Condition 2 applies to descendants of the cause that lieon or descend from variablesondirectedpathsthatbeginatthecausalvariableand“reachtheoutcomevariable”rather than “end at the outcome variable.”The word “reach” has been chosen to allow for Condition 2 to invalidate conditioning sets that include descendants of the cause that are also descendants of the outcome.SupposethatanadditionalobservedvariableW isaddedtoFigure4.6alongwithadirected edgefromY toW,asinY →W.ThenewvariableW isadescendant ofbothD andY viathetwo directed paths D→Y →W and D→N→Y →W that begin at D and reach Y (and, in this case, carry on to W). There is, of course, no reason to condition on W in an attempt to estimate the causal effect of D and Y because W does not lie on a back-door path from D to Y that confounds thecausaleffectofinterest.Ifananalystdoesdoso,byaddingW toaconditioningsetthatincludes C and/or O, then Conditions 1(a), (b), and (c) of the back-door criterion are met but Condition 2 is not. The variable W is simply a noisy version of Y, and the causal effect of D on Y is therefore embeddedwithinit.Conditioningon W will,infact,mistakenlysuggestthatD hasnocasualeffect onY becausewithinstratadefinedbyW,DandY areindependent(assumingnomeasurementerror andaninfinitesamplethatenables fullynonparametricestimation).\nConditioningonOwillblockpath1,andconditioningonB willblockpath3.However, conditioning on O will unblock path 2 because it is a collider on an already blocked back-door path.\nWhatwewanttostressnowisthatthecandidateconditioningsetofO andB also does not satisfy Condition 2 of the back-door criterion. O is a descendant of D on a directed path, D→M →O→Y, that reaches Y. Furthermore, O is a descendant of M, via M→O, and M is a variable that lies on another directed path, D→M→Y, that begins at D and reaches Y.\nNoticealsothatthegraphinFigure4.7isrealisticandnotcontrived.Ifaresearcher follows the (sometimes wrong)conditioning strategy of “adjusting for all other causes of the outcome,” and the researcher has not drawn the full causal graph in Figure 4.7, then the researcherwould almost certainly condition on O (even if the researcher wisely decides not to condition on the clearly endogenous observed variable N but does decide to condition on the second-order cause B in place of the unobserved direct cause U). In practice, other causes of an outcome that are observed are hard to resist conditioning on, even though many of them are descendants of the cause along directed paths that reach the outcome and thereby violate Condition 2 of the back-doorcriterion.IfaresearcherdoesnotobserveamechanisticvariablelikeM,the analyst may not recognize the endogeneity of O with respect to D (especially if the analyst comes to believe that the only mechanistic variable has been observed as N and that the remaining effect of D on Y is an unmediated direct effect).\nCondition2ofthe back-doorcriterionisageneralrequirementforsufficientcondi- tioningsets,anditiseasytoapply.Oneneedonlyexamineeachcandidateconditioning variable to determine whether it lies on (or descends from a variable that lies on) the directed paths that begin at the causal variable and reach the outcome variable.\nAlthough Condition 2 is easy to apply, we discuss additional examples in an appendixtothischapterthataremorechallengingtoexplain.Inparticular,werecon- sider the graphs just presented, building toward a full reexamination of the graph in Figure 4.7, which is even more complex than our presentation here reveals. In the appendix, we show that a full assessment of the consequences of conditioning on descendantsofthecauseisenabledbydrawingthegraphsundermagnificationsothat itiseasiertorecognizeallsuchdescendantsascolliders.Althoughthesemorecomplex cases are interesting to examine, so as to understand the full range of identification challenges that graphical models help to explain, one need not fully understand them or absorb them to effectively adhere to conditioning strategies that are warranted by the back-door criterion.\nThetwokeypointsofthissectionarethefollowing.First,conditioningonvariables thatlieonback-doorpathscanbeaneffectivestrategytoidentifyacausaleffect.Ifall back-doorpathsbetweenthecausalvariableandtheoutcomevariableareblockedafter the conditioning isenacted,thenback-doorpaths donotcontributeto the association betweenthecausalvariableandtheoutcomevariable.However,itmustbekeptinmind that conditioning on a collider (or a descendant of a collider) has the opposite effect.\nAny such conditioning unblocks already blocked back-door paths. And thus, when a conditioning strategy is evaluated, each back-door path must be assessed carefully because a variable can be a collider on one back-door path but not a collider on another.\nSecond, if a set of conditioning variables blocks all back-door paths, the analyst mustthenverifythatnovariableswithintheconditioningsetblockthecausaleffectof interest or otherwise mistakenly adjust it away. If none of the candidate conditioning variables are also descendants of the cause that lie on or descend from directed paths thatbeginatthecausalvariableandreachtheoutcomevariable,thenthecausaleffect is identified and a conditioning estimator is consistent and unbiased for the average causal effect.\nPearl’sback-doorcriterionforevaluatingconditioningstrategiesisageneralization (and therefore a unification) of various traditions for how to solve problems that are frequently attributed to omitted-variable bias. From our perspective, Pearl’s frame- work is particularly helpful in two respects. First, it shows clearly that researchersdo not need to condition on all omitted direct causes of an outcome variable in order to solve an omitted-variable bias problem. This claim is not new, of course, but Pearl’s back-door criterion shows clearly why researchers need to condition on only a minimally sufficient set of variables that (a) renders all back-door paths blocked and (b) does not block the causal effect itself. Second, Pearl’s framework shows how to think clearly about the appropriateness of conditioning on endogenous variables.\nWritingdowneachback-doorpathandthen determiningwhether ornoteachendoge- nous variable is a collider along any of the back-door paths is a much simpler way to begin to consider the full complications of a conditioning strategy than other approaches.13 In the next section, we consider models of causal exposure that have been used in thecounterfactualtradition,startingfirstwiththestatisticsliteratureandcarryingon to the econometrics literature. We will showthat the assumptions often introduced in thesetwotraditionstojustifyconditioningestimationstrategies–namely,ignorability and selection on the observables – have close connections to the back-door criterion presented in this section.\n13Theback-doorcriterionisnottheonlyavailablegraphicalguidefortheselectionofconditioning variables.Elwert(2013:256–61) offersacrispsummaryofthealternatives.Amongthese, theadjust- mentcriterion isthemostgeneralandisguaranteedtoselectallpossiblesufficientconditioningsets.\nNonetheless, we make the case in the appendix to this chapter that the version of the back-door criterionthatwepresentinthemaintextofthischapterhasadvantagesrelativetothecompleteness oftheadjustmentcriterion.Amongtheothercriteria,thedisjunctivecausecriterion ofVanderWeele and Shpitser (2011) is also particularly useful because it can serve as a guide to conditioning when the analyst is unwilling to commit to a set of assumptions that enable a full directed graph to be drawn for the generation of the outcome. The disjunctive cause criterion instructs the analyst to adjustforallvariablesthatarecausesofthetreatmentortheoutcome, butnotthosevariablesthat arecauses neither of thetreatment nor ofthe outcome. Theanalyst thereforedoes notneedto con- structadirectedgraph,onlytakeapositiononwhether thecandidate conditioningvariablesshould beassumedtobecauses ofthe treatment, causes oftheoutcome, orneither.Ofcourse, thepriceto bepaidforthesimplicityofthedisjunctivecausecriterionisthatitwillnotnecessarilyidentifythe causal effect (because one cannot know about all sources of confounding ifone cannot draw the full directed graphforthe generation of the outcome) and can suggest redundant conditioning (because one does not need to condition on variables that lie on back-door paths that are already blocked bycolliders,variablesthat lieonback-door paths thatarealreadyblocked byconditioningonother variables, or variables that do not lie on any back-door paths). Nonetheless, the disjunctive cause criterion will prevent the analyst from inducing noncausal associations between the treatment and outcome that would result from conditioning on the relevant colliders that already block back-door paths.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#models-of-causal-exposure-and-point-identification-based-on-the-potential-outcome-model",
    "href": "extracted/Counterfactuals and Causal Inference.html#models-of-causal-exposure-and-point-identification-based-on-the-potential-outcome-model",
    "title": "Counterfaturals and Causal Inference",
    "section": "4.3 Models of Causal Exposure and Point Identification Based on the Potential Outcome Model",
    "text": "4.3 Models of Causal Exposure and Point Identification Based on the Potential Outcome Model\nWith this general presentation of the conditioning strategy in mind, return to the\nfamiliarcaseofabinarycauseD andanobservedoutcomevariableY.Asdiscussedin Chapter2,forthepotentialoutcomemodelweconsiderY tohavebeengeneratedbya switchingprocessbetweentwopotentialoutcomevariables,asinY =DY1+(1−D)Y0, where the causal variable D is the switch. To model variation in Y and relate it to the individual-level causal effects defined by the potential outcome variables Y1 and Y0, a model for the variation in D must be adopted. This is typically known in the statistics literature as “modeling the treatment assignment mechanism” and in the econometrics literature as “modeling the treatment selection mechanism.” In this section, we first consider the notation and language developed by statisti- cians, andwe then turn to the alternative notationand language developedby econo- metricians. Although both sets of ideas are equivalent, they each have some distinct conceptualadvantages.Inshowingboth,wehopetodeepentheunderstandingofeach.\n4.3.1 Treatment Assignment Modeling in Statistics The statistics literature on modeling the treatment assignment mechanism is an out- growthofexperimentalmethodologyandtheimplementationofrandomizationresearch designs. Accordingly, we begin by considering a randomized experiment for which the phrase “treatment assignment” remains entirely appropriate.\nAs discussed in Chapter 2, if treatment assignment is completely randomized by design,thenthetreatmentindicatorvariableDiscompletelyindependentofthepoten- tial outcomes Y0 and Y1 as well as any function of them, such as the distribution of δ; see the earlier discussion of Equation (2.6). In this case, the treatment assignment mechanismisknownbecauseitissetbytheresearcherwhoundertakestherandomiza- tion. If the researcherwants treatment and control groups of approximately the same size, then Pr[D=1] is set to .5. Individual realized values ofD for those in the study, denoteddi generically,arethen equalto1or0 andaredeterminedbythe flipofafair coin(orby acomputer thatruns Bernoullitrialsfor the randomvariableD with .5as the probability).\nTofacilitatethe transitionto designsforobservationalresearch,consideraslightly more elaborate design where study subjects are stratified first by gender and then assigned with disproportionate probability to the treatment group if female. In this case, the treatment assignment protocol would instead be represented by two condi- tional probabilities, such as Pr[D=1|Gender=Female]=.7, (4.1) Pr[D=1|Gender=Male]=.5. (4.2) These conditional probabilities are typically referred to as “propensity scores” in the literaturebecausetheyindicatethepropensitythatanindividualwithspecificcharac- teristics will be observed in the treatment group. Although labeled propensity scores intheliterature,theyarenonethelessnothingmorethanconditionalprobabilitiesthat lie within anintervalbounded by 0 and 1.For this example,the propensity score is .7 for female subjects and .5 for male subjects. The general point is that for randomized experiments, the propensity scores are known to the researcher.\nIncontrast,aresearcherwithobservationaldatadoesnotpossessaprioriknowledge of the exact propensity scores that apply to all individuals. However, the researcher may know all of the characteristics of individuals that systematically determine their propensityscores,eveniftheresearcherdoesnotknowthespecificvaluesofthepropen- sity scores.14 In this case, treatmentassignmentpatterns are representedby a general conditional probability distribution, Pr[D=1|S], (4.3) where S now denotes all variables that systematically determine all treatment assign- mentpatterns.CompleteobservationofS thenallowsaresearchertoassertthattreat- ment assignment is “ignorable” and then consistently estimate the averagetreatment effect (ATE), as we now explain.\nThe general idea here is that, within strata defined by S, the remaining variation in the treatment D is completely random and hence the process that generates this remaining variation is labeled “ignorable.” The core of the concept of ignorability is the independence assumption that was introduced in Equation (2.6), (Y0,Y1) ⊥⊥ D, where the symbol ⊥⊥ denotes independence. As defined by Rubin (1978), ignorability of treatment assignment holds when the potential outcomes are independent of the treatment dummy indicator variable, as in this case all variation in D is completely random. Ignorability also holds in the weaker case where (Y0,Y1) ⊥⊥ D | S (4.4) and all variables in S are observed.\nIn words, the treatment assignment mechanism is ignorable when the potential out- comes(andanyfunctionofthem,suchasδ)areindependentofthetreatmentvariable, D, within strata defined by all combinations of values on all variables, S, that sys- tematicallydetermine alltreatmentassignmentpatterns.IfsomecomponentsofS are unobserved, the conditional independence condition in Equation (4.4) may still hold, buttreatmentassignmentcannotbeconsideredignorablewithrespecttotheobserved data. In this case, treatment assignment must be regarded as nonignorable, even if it is known that it would be ignorable if all variables in S had instead been observed.15 14This would be the situation for the randomized experiment represented by Equations (4.1) and (4.2)ifthe experimentalistknew that the probabilityofbeingassigned tothe treatment differedby gender(andonlybygender)buthadforgottenthevalues of.7and.5.\n15Rosenbaum and Rubin (1983a) defined strong ignorability to develop the matching literature, which we will discuss later. To Rubin’s ignorability assumption, Rosenbaum and Rubin (1983a) required for strong ignorability that each subject have a nonzero probability of being assigned to both the treatment and the control groups. Despite these clear definitions, the term ignorability is In practice, in order to assertthat treatment assignment is ignorable for an obser- vational study, a researcher would 1. determinefromrelatedstudies andsupportableassumptionsgroundedintheory what the components of S are, 2. measure each of the component variables in S, and 3. collect enough data to be able to consistently estimate outcome differences on the observed variable Y within strata defined by S.\nThis thirdstepcanbe weakenedifthe dataaremerelysparse,aswe willdiscusswhen presenting models based on estimate propensity scores in Chapters 5 and 7. The key pointisthataresearcherdoesnotneedtoknowtheexactpropensityscores(i.e.,what Pr[D=1|S=s] is equal to for all s), only that the systematic features of treatment assignmentcanbeexhaustivelyaccountedforbythedatainhandonthecharacteristics of individuals. The naive estimator can then be calculated within strata defined by values of the variables in S, and a weighted average of these stratified estimates can be formed as a consistent estimate of the ATE.16 Consider the Catholic school example. It is well known that students whose par- ents self-identify as Catholic are more likely to be enrolled in Catholic schools than students whose parents self-identify as non-Catholic. Suppose that parents’ religious identity is the only characteristic of students that systematically determines whether they attend Catholic schools instead of public schools. In this case, a researcher can consistentlyestimatetheATEbycollectingdataontestscores,students’schoolsector attendance,andparent’sreligiousidentification.Aresearcherwouldthenestimatethe effect of Catholic schooling separately by using the naive estimator within groups of students defined by parents’ religious identification and then take a weighted average ofthese estimatesbasedonthe proportionofthe populationofinterestwhose parents self-identify as Catholic and as non-Catholic. In the words of the prior section, the researchercangenerateconsistentandunbiasedestimatesofthe ATE byconditioning on parents’ religious identification.\nAssumptions of ignorability have a close connection to the back-door criterion of Pearl, given the shared centrality of the conditioning operation. Even so, it is impor- tant to recognize some differences. Suppose that we are confronted with the graph in Figure 4.8(a), which includes the causal effect D→Y but also the bidirected edge D(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)Y. The most common solution is to build an explicit causal model that rep- resents the variables that generate the bidirected edge between D and Y in Figure 4.8(a). The simplest such model is presented in Figure 4.8(b), where D(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)Y has been replaced with the back-door path D← S→Y. If S is observed, then condition- ing on S will solve the causal inference problem, according to the back-door criterion oftendefinedindifferentwaysintheliterature.Wesuspectthatthisvariedhistoryofusageexplains why Rosenbaum (2002) rarely uses the term in his monograph on observational data analysis, even thoughheisgenerallycredited,alongwithRubin,withdevelopingtheignorabilitysemanticsinthis literature. And it also explains why some of the most recent econometrics literature uses the words unconfoundedness and exogeneity for the same set of independence and conditional-independence assumptions(seeImbens2004).\n16Again,weassumethatmeasurementerrordoesnotexist,whichrequiresthatstep2beundertaken withouterror.\nS D Y D Y (a) (b) Figure4.8 Causal diagrams in which treatment assignment is (a) nonignorable and (b) ignorable.\npresentedintheprevioussection.Inthestatisticsliterature,thesameresultisexplained by noting that treatment assignment is ignorable when S is observed, which is then written asEquation ( 4.4).\nWhen identification by back-door conditioning is feasible with the observed data, then treatment selection is ignorable with respect to the observed data. However, we do not mean to imply with this statement that the assertion of a valid ignorability assumptionwillleadtheresearchertoconditionontheexactsamevariablessuggested by the back-door criterion. Recall that the back-door criterion guides the researcher in selecting minimally sufficient conditioning sets. Ignorability can be asserted with respect to these sets or with respect to broader sets of conditioning variables. For an example, let S in Figure 4.8(b) be a set of variables. Suppose that, upon reflec- tion, a researcher decides that one of the variables in S, S(cid:2), has a direct effect on D but no direct effect on Y. Accordingly, it is appropriate to separate S(cid:2) from the other variables in S and assert that S(cid:2) is a cause of D that causes Y only indirectly throughD.17Inthiscase,S(cid:2)doesnotgenerateanyconfoundingbecauseS(cid:2)doesnotlie onaback-doorpathbetweenD andY.Theminimallysufficientconditioningsetsthat are judged admissible by the back-door criterion would not include S(cid:2), even though treatment assignment is ignorable with respect to S(cid:2) and the remaining variables in S.Thus,whenassertingignorabilitywith respectto the observeddata,the researcher maydecidetoconditiononS(cid:2),eventhoughsuchconditioningisunnecessary.Afterall, S(cid:2) does determine treatment assignment and, hence, does structure the true propen- sityscore.AnditispossiblethatthestrongassumptionthatS(cid:2) doesnothaveadirect effect on Y is incorrect.\nWe will begin to discuss specific techniques for conditioning estimators in Chapter5,wherewefirstpresentmatchingestimatorsofcausaleffects.Buttheimme- diate complications of undertaking a conditioning analysis strategy for the Catholic school example should be clear. How do we determine all of the factors that system- atically determine whether a student enrolls in a Catholic school instead of a public school? And can we obtain measures of all of these factors? Attendance at a Catholic school is determined by more than just parents’ religious self-identification, and some of these determinants are likely unmeasured. If this is the case, then the treatment assignment mechanism is likely to be nonignorable, as treatment selection is then a function of unobserved characteristics of students that generate confounding. These 17S(cid:3) isaninstrumentalvariable,aswewillexplaininfulldetailinChapter 9.\nissues are best approached by first drawing a directed graph. It may be that some of the unobserved determinants of treatment assignment do not generate confound- ing because (a) they do not lie on back-door paths, (b) they lie on back-door paths that are already blocked by colliders, or (c) they lie on back-door paths that can be blockedbyconditioning onothervariablesthatlie onthe sameback-doorpaths.Ifso, the researchermaybe able toassertanignorabilityassumptionwithrespecttoonly a subsetofthevariableswehavedesignatedasS forthissection.However,inmostcases, the opposite challenge will dominate: The directed graph will show clearly that only a subset of the variables in S that generate confounding are observed, and the con- founding that they generate cannot be eliminated by conditioning with the observed data. Treatment assignment is then nonignorable with respect to the observed data.\n4.3.2 Treatment Selection Modeling in Econometrics The econometrics literature also has a long tradition of analyzing causal effects, and this literature may be more familiar to social scientists. Whereas concepts such as ignorability are used somewhat infrequently in the social sciences, the language of selection bias is commonly used throughout the social sciences. This usage is due, in large part,to the energy that economists have devoted to exploring the complications of self-selection bias.\nThe selection-bias literature in econometrics is vast, but the most relevant piece thatwefocusonhereisJamesHeckman’sspecificationoftherandom-coefficientmodel for the treatment effects of training programs, which he attributes, despite the differ- enceinsubstance,toRoy(1951).Theclearestspecificationofthismodelwaspresented in aseries ofpapersthat Heckmanwrotewith RichardRobb (see Heckmanand Robb 1985, 1986, 1989), but Heckman worked out many of these ideas in the 1970s. Using the notation we have adopted in this book, take Equation (2.2), Y =DY1+(1−D)Y0, and then rearrangeand relabel terms as follows: Y =Y0+(Y1−Y0)D (4.5) =Y0+δD =μ0+δD+υ0, where μ0≡E[Y0] andυ0≡Y0−E[Y0].The standardoutcome modelfromthe econo- metrics of treatment evaluation simply reexpresses Equation (4.5) so that potential variability of δ across individuals in the treatment and control groups is relegated to the error term, as in Y =μ0+(μ1−μ0)D+{υ0+D(υ1−υ0)}, (4.6) where μ1≡E[Y1], υ1≡Y1−E[Y1], and all else is as defined for Equation (4.5).18 Note that, in evolving from Equation (2.2) to Equation (4.6), the definition of the 18The original notation is a bit different, but the ideas are the same. Without much usage of the languageofpotentialoutcomes,HeckmanandRobb(1985,section1.4)offeredthefollowingsetupfor therandomcoefficientmodeloftreatmenteffects toanalyzeposttreatment earningsdifferencesfora fictitious workertrainingexample.Foreachindividuali,theearningsofindividualiiftrainedare observed outcome variable Y has taken on the look and feel of a regression model.19 The firstμ0 termis akinto anintercept,eventhoughitis definedas E[Y0]. The term (μ1−μ0)thatprecedesthefirstappearanceofD isakintoacoefficientontheprimary causal variable of interest D, even though (μ1−μ0) is defined as the true ATE, E[δ].\nFinally,the terminbraces,{υ0+D(υ1−υ0)}, isakinto anerrorterm,eventhoughit represents both heterogeneity of the baseline no-treatment potential outcome and of the causal effect, δ, and even though it includes within it the observed variable D.20 Heckman and Robb use the specification of the treatment evaluation problem in Equation(4.6),andmanyotherssimilartoit,todemonstrateallofthemajorproblems createdbyselectionbiasinprogramevaluationcontextswhensimpleregressionestima- torsareused.HeckmanandRobbshowwhyaregressionofY onDdoesnotingeneral identifytheATE,inthiscase(μ1−μ0),whenD iscorrelatedwiththepopulation-level variant of the error term in braces in Equation (4.6), as would be the case when the size of the individual-leveltreatmenteffect, in this case (μ1−μ0)+{υ i0+di(υ i1−υ i0)}, differs among those who select the treatment and those who do not.\nThestandardregressionstrategythatprevailedintheliteratureatthetimewasto includeadditionalvariablesinaregressionmodeloftheformofEquation(4.6),hoping y i1=β1+U i1, andtheearningsofindividualiintheabsenceoftrainingare y i0=β0+U i0, (wherewehavesuppressedsubscriptingontfortimefromtheoriginalpresentationandalsoshifted thetreatmentstatedescriptorsfromsubscripttosuperscriptposition).Withobservedtrainingstatus representedbyabinaryvariable,d i,HeckmanandRobbthensubstitutetheright-handsidesofthese equationsintothedefinitionoftheobservedoutcomeinEquation(2.2)andrearrangetermstoobtain y i=β0+(β1−β0)d i+U i0+(U i1−U i0)d i, whichtheythencollapseinto y i=β0+α¯d i+{U i0+ε id i}, whereα¯≡β1−β0 andε i≡U i1−U i0 (see Heckman andRobb1985, equation 1.13). Asaresult, α¯ is the ATE, which we defined as E[δ] in Equation (2.3), and ε i is the individual-level departure of δ i fromtheATE,E[δ].AlthoughthenotationinthislastequationdiffersfromthenotationinEquation (4.6),thetwoequationsareequivalent.HeckmanandVytlacil(2005,2007)giveafullynonparametric versionofthistreatment selectionframework,whichwedrawonbelow.\n19Sometimes,Equation(4.6)iswrittenas Y =μ0+[(μ1−μ0)+(υ1−υ0)]D+υ0 in order to preserve its random-coefficient interpretation. This alternative representation is nothing otherthanamorefullyarticulatedversionofEquation(4.5).\n20Statisticianssometimesobjecttothespecificationof“errorterms”because,amongotherthings, they are said to represent a hidden assumption of linearity. In this case, however, the specification ofthis errorterm isnothing other than anexpression of the definition of the individual-levelcausal effectasthelineardifferencebetweeny1 andy0.\ni i to break the correlation between D and the error term.21 Heckman and Robb show that this strategy is generally ineffective with the data available on worker training programs because (1) some individuals are thought to enter the programs based on anticipation of the treatment effect itself and (2) none of the available data sources have measures of such anticipation. We will return to this case in detail in Chapter 6, where we discuss regression models.\nTo explain these complications, Heckman and Robb explore how effectively the dependence between D and the error term in Equation (4.6) can be broken. They proceed by proposing that treatment selection be modeled by specifying a latent con- tinuous variable D˜ as D˜=Zφ+U, (4.7) where Z represents all observed variables that determine treatment selection, φ is a coefficient (or a vector of coefficients if Z includes more than one variable), and U represents both systematic unobserved determinants of treatment selection and com- pletely random idiosyncratic determinants of treatment selection. The latent contin- uous variable D˜ in Equation (4.7) is then related to the treatment selection dummy, D, by D=1 if D˜≥0, D=0 if D˜&lt;0, wherethethreshold0isarbitrarybecausethetermU hasnoinherentmetric(because it is composed of unobserved and possibly unknown variables).\nTo see the connectionbetween this econometricspecificationandthe one fromthe statistics literature introduced in the last section, first recall that statisticians typi- cally specify the treatmentselectionmechanismas the generalconditional probability distribution Pr[D=1|S], where S is a vector of all systematic observed determinants oftreatmentselection.22 This is showninthe graphin Figure4.8(b). The correspond- ing causaldiagramforthe econometricselectionequationis presentedintwodifferent graphs in Figure 4.9, as there are two scenarios corresponding to whether or not all elements of S have been observed as Z.\nFor the case in which Z in Equation (4.7) is equivalent to the set of variables in S in Equation (4.3), treatment selection is ignorable, as defined in Equation (4.4), because conditioning on Z is exactly equivalent to conditioning on S. In the econo- metric tradition, this situation would not, however, be referred to as a case for which treatment assignment/selection is ignorable. Rather, treatment selection would be characterized as “selection on the observables” because all systematic determinants of treatment selection are included in the observed treatment selection variables Z.\nThis phrase is widely used by socialscientists because it conveysthe essential content 21Barnow,Cain,andGoldberger(1980:52) notedthat“themostcommonapproach”isto“simply assumeawaytheselectionbiasafteradiligentattempttoincludealargenumberofvariables”inthe regressionequation.\n22When more specific, the basic model is usually a Bernoulli trial, inwhich Pr[D=1|S=s] gives thespecificprobabilityofdrawinga1andthecomplementofdrawinga0forindividualswithSequal tos.\nZ Z D Y D Y U U (a) Selection on the observables (b) Selection on the unobservables Figure4.9 Causaldiagramsfor the terminologyfromeconometricmodeling oftreat- ment selection.\noftheignorabilityassumption:Allsystematicdeterminantsoftreatmentselectionhave been observed.23 The scenarioof selection on the observables is depicted in Figure 4.9(a). The vari- able S in Figure 4.8(b) is simply relabeled Z, and there are no back-door paths from D to Y other than the one that is blocked by Z. The remaining idiosyncratic random variation in D is attributed in the econometric tradition to a variable U, which is presented in Figure 4.9(a) as a cause of D that is conditionally independent of both Z and Y. This error term U represents nothing other than completely idiosyncratic determinantsoftreatmentselection.It couldthereforebe suppressedinFigure 4.9(a), which would render this graph the same as the one in Figure 4.8(b).24 Now consider the case in which the observed treatment selection variables in Z are only a subset of the variables in S. In this particular case, some components of S enter into the treatment selection latent variable D˜ through the error term, U, of Equation (4.7). In this case, treatment selection is nonignorable. In the words of econometricians, “selection is on the unobservables” (or, more completely, “selection is on the observables Z and the unobservables U”). The scenario of selection on the unobservablesis depicted in Figure 4.9(b), where there are now back-doorpaths from D to Y represented by D←U (cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)Y. Conditioning on Z for this graph does not block all back-door paths.\nIn spite of differences in language and notation, there is little that differentiates the statistics and econometrics models of treatment selection, especially now that the outcomeequationsusedbyeconomistsareoftencompletelygeneralnonparametricver- sionsofEquation(4.6)(seeHeckmanandVytlacil2005,whichwewilldiscussinafew differentplaceslaterinthebook,suchasChapters9and12).Fornow,thekeypointis that both the statistics and econometric specifications consider the treatment indica- tor variable, D, to be determined by a set of systematic treatment selection variables 23And,as withignorability, the variables inZ arenotnecessarily equivalent to those inthe mini- mallysufficientconditioningsetssuggestedbytheback-doorcriterion.Theadmissiblesetsaccording to the back-door criterion may be subsets of the variables in Z or even variables not in Z that are proximatedeterminantsofY andthat,whenconditionedon,blockallback-doorpathsgeneratedby thevariablesinZ.\n24The latent variable specification in the econometric tradition can be made equivalent to almost all particular specifications of the statement Pr[D=1|S] in the statistics tradition by the choice of an explicit probability distribution for U. The full nonparametric equivalence in the causal graph traditionwouldbeD=f D(S,e D)=f D(Z,U).\nin S. When all of these variables are observed, the treatment selection mechanism is ignorable and selection is on the observables only. When some of the variables in S areunobserved,the treatmentselectionmechanismisnonignorableandselectionison the unobservables.\nFinally,thequalificationswenotedinthepriorsectionaboutthedifferencesbetween ignorability assumptions and the back-door criterion apply in analogous fashion to assumptions of selection on the observables. Minimally sufficient conditioning sets suggested by the back-door criterion may be subsets of the variables in Z or entirely different variables that, when conditioned on, eliminate the confounding generatedby Z. Variables of the latter type would typically be proximate determinants of Y that intercept the effects of the variables in Z on Y, such as the variable F in Figure 4.4.\n4.3.3 Point Identification of Conditional Average Treatment Effects by Conditioning At the beginning of this chapter, we indicated that we would implicitly focus our pre- sentation of directed graphs and identification issues on the estimation of the uncon- ditional ATE. This narrow focus is entirely consistent with the graphical tradition, in which parameters such as the average treatment effect for the treated (ATT) in Equation (2.7) and the average treatment effect for the controls (ATC) in Equation (2.8) are given considerably less attention than in the potential outcome modeling traditioninbothstatisticsandeconometrics.Somecommentsonthe connectionsmay be helpful at this point to foreshadow some of the specific material on causal effect heterogeneity that we will present in the next three chapters.\nIdentification When the Unconditional ATE Is Identified Ifonecanidentify andconsistentlyestimatethe unconditionalATEwithconditioning techniques, then one can usually estimate some of the conditional average treatment effects that may be of interest as well. As we will show in the next three chapters, consistent estimates of conditional average treatment effects can usually be formed by specification of alternative weighted averages of the average treatment effects for subgroups defined by values of the conditioning variables. Thus, calculating average effects other than the unconditional ATE may be no more complicated than simply adding one step to the more general conditioning strategy we have presented in this chapter.\nConsideragainthegraphpresentedinFigure4.8(b).Theback-doorpathfromDto Y is blockedbyS. Asa result,aconsistentestimate ofthe ATE inEquation(2.3)can beobtainedbyconditioningonS.But,inaddition,consistentestimatesoftheATTin Equation(2.7) and the ATC in Equation(2.8) can be obtained by properly weighting conditional differences in the observed values of Y. In particular, first calculate the sample analogsto the differences E[Y|D=1,S=s]−E[Y|D=0,S=s] for allvalues s of S. Then, weight these differences by the conditional distributions Pr[S|D=1] and Pr[S|D=0] to calculate the ATT and the ATC, respectively.\nIdentification When the Unconditional ATE Is Not Identified Ifselectionisontheunobservables,conditioningstrategieswilltypicallyfailtoidentify unconditional ATEs. Nonetheless, weaker assumptions may still allow for the iden- tification and subsequent estimation by conditioning of various conditional average treatment effects. We will present these specific weaker assumptions in the course of explainingmatchingandregressiontechniquesin the nextthree chapters,butfor now we give a brief overviewof the identification issues in relationto the graphicalmodels presentedinthischapter.(SeealsothediscussioninSection2.7.4ofsimilarissueswith regardto the inconsistency and bias of the naive estimator.) Suppose,forexample,thatthegraphinFigure4.9(b)nowobtains,andhence that a back-door path from D to Y exists via unobserved determinants of the cause, U.\nIn this case, conditioning on Z will not identify the unconditional ATE. Nonetheless, conditioning on Z may still identify a conditionalaveragetreatment effect of interest, as narrower effects can be identified if weaker assumptions can be maintained even though unblocked back-door paths may still exist between D and Y.\nConsideracaseforwhichpartialignorabilityholds,suchthatY0 ⊥⊥D|S istruebut (Y0,Y1)⊥⊥D |S isnot.Here,conditioningonS generatesaconsistentestimateofthe ATTeventhoughS doesnotblocktheback-doorpathfromDtoY.Theoppositeis,of course,alsotrue.Ifpartialignorabilityholdsintheotherdirection,suchthatY1⊥⊥D|S holds but (Y0,Y1) ⊥⊥ D|S does not, then the ATC can be estimated consistently.25 Considerthefirstcase,inwhichonlyY0 ⊥⊥D |S holds.Evenafterconditioningon S, a back-door path remains between D and Y because Y1 still differs systematically betweenthoseinthetreatmentandcontrolgroupsandY isdeterminedinpartbyY1; seeEquation(2.2).Nonetheless,if,afterconditioningonS,theoutcomeundertheno- treatment-state, Y0, is independent of exposure to the treatment, then the ATT can be estimated consistently. The average values of Y, conditional on S, can be used to consistently estimate the averagewhat-if values for the treatedif they wereinstead in thecontrolstate.ThistypeofpartialignorabilityisakintoAssumption2inEquation (2.16), except that it is conditional on S. We will give a full explanation of the utility of such assumptions when discussing matching estimates of the ATT and the ATC in the next chapter.\nGraphs Do Not Clearly Reveal the Identification Possibilities for the ATT and ATC When the ATE Is Not Also Identified In the prior section, we noted in our presentations of ignorability and selection on the observables that graphs help guide researchers toward minimally sufficient con- ditioning sets that may differ from the conditioning sets suggested by the statistics andeconometricsliterature.Theback-doorcriterionisespeciallyhelpfulinthisregard because of its targeted focus on back-door paths that generate noncausal associations betweenthecausalvariableandtheoutcomevariable.However,itmustalsobestated, asimpliedbythissection,thatdirectedgraphswillnotclearlyrevealeffectiveanalysis 25And,aswewillshowinthenextchapter,therequiredassumptionsareevensimplerbecausethe entiredistributionsofY0 andY1 neednotbeconditionallyindependent ofD.Aslongasthestable unittreatmentvalueassumption(SUTVA)holds,onlymeanindependence mustbemaintained.\nstrategies to identify either the ATT or the ATC in situations where the ATE cannot also be identified by conditioning.\nThe overall implication of this point is that researchers should learn all three frameworks for approaching causal identification challenges. Graphs help immensely inselectingconditioningsetswhenthetargetparameteristheATE.WhentheATEis not identified by any feasible conditioning sets, the potential outcome model – either as deployed in statistics or econometrics – can still guide the researcher to identifica- tion strategies for narrower conditional average effects, most commonly the ATT or the ATC. Directed graphs remain a useful tool in these situations, as they help to organizeone’s thinking about the full systemofcausalrelationshipsthat arerelevant.\nBut, the identification strategy that is then selected to estimate either the ATT or the ATC is likely to emerge from thinking through the possibilities from within the potential outcome model.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#conditioning-to-balance-and-conditioning-to-adjust",
    "href": "extracted/Counterfactuals and Causal Inference.html#conditioning-to-balance-and-conditioning-to-adjust",
    "title": "Counterfaturals and Causal Inference",
    "section": "4.4 Conditioning to Balance and Conditioning to Adjust",
    "text": "4.4 Conditioning to Balance and Conditioning to Adjust\nWhen presenting Pearl’s back-door criterion for determining a sufficient set of condi-\ntioningvariables,wenotedthatforsomeapplicationsmorethanonesetofconditioning variables is sufficient. In this section, we return to this point as a bridge to the fol- lowing three chapters that present both matching and regression implementations of conditioning. Although we will show that matching and regression can be considered variants of each other, here we point to the different ways in which they are usually invoked in applied research. Matching is most often considered a technique to bal- ance the determinants of the causal variable, and regression is most often considered a technique to adjust for other causes of the outcome.\nTo frame this discussion, consider first the origins of the balancing approach in the randomized experiment tradition. Here, the most familiar approach is a random- ized experiment that ensures that treatment status is unassociated with all observed and unobservedvariables that determine the outcome (although only in expectation).\nWhen treatment status is unassociated with an observed set of variables W, the data are balanced with respect to W. More formally, the data are balanced if Pr[W|D=1]=Pr[W|D=0], (4.8) whichrequiresthattheprobabilitydistributionofW bethesamewithinthetreatment and control groups.\nNowconsiderthegraphpresentedinFigure4.10.Back-doorpathsarepresentfrom D to Y, representedby D←S(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)X→Y, whereS is the complete setofvariables that are direct causes of treatment assignment/selection, X is the complete set of variables other than D that are direct causes of Y, and the bidirected edge between S and X signifies that they are mutually caused by some set of common unobserved causes.26 26Forthisexample,wecouldhavemotivatedthesamesetofconclusionswithothertypesofcausal graphs.ThesamebasicconclusionswouldholdevenifX andSincludeseveralvariableswithinthem in which some members of X cause D directly and some members of S cause Y directly. In other S X D Y Figure4.10 Acausaldiagraminwhichsufficientconditioningcanbeperformedwith respect to S or X.\nBecause neither S nor X is a collider, all back-door paths in the graph can be blockedbyconditioningoneitherS orX (andwewrite“paths”becausetheremaybe many back-door paths through the bidirected edge between S and X). Conditioning on S is considered a balancing conditioning strategy, whereas conditioning on X is considered an adjustment-for-other-causes conditioning strategy. If one observes and then conditions on S, the variables in S and D are no longer associated within the subgroups defined by the conditioning. The treatment and control groups are thereby balanced with respect to the distribution of S. Alternatively, if one conditions on X, the resulting subgroup differences in Y across D within X can be attributed to D alone. Inthis case,the goalis notto balanceX but rather to partialoutits effects on Y in order to isolate the net effect of D on Y.\nThe distinction between balancing and adjustment for other causes is somewhat artificial (see Hansen 2008). For the graph in Figure 4.10, balancing X identifies the causal effect. Thus, it is technically valid to say that one can identify a causal effect by balancing a sufficient set of other causes of Y. Nonetheless, the graph in Figure 4.10 demonstrates why the distinction is important. The ultimate set of systematic causesthatgeneratesthe relationshipbetweenS andX isunobserved,asitoftenisin many applied research situations. Because one cannot condition on these unobserved variables, one must condition on either S or X in order to identify the causal effect.\nThese two alternatives may be quite different in their practical implementation.27 Should one balance the determinants of a cause, or should one adjust for other causesoftheoutcome?Theanswertothisquestionissituationspecific,anditdepends on the quality of our knowledge and measurement of the determinants of D and Y.\nwords, all that we need to make the distinction between balancing and adjustment for other direct causesistwosetsofvariablesthatarerelatedtoeachother,withatleastonevariableinonesetthat causesD butnotY andatleastonevariableintheothersetthatcauses Y butnotD.\n27Note also that the ingredients utilized to estimate the ATE (as well as the ATT and the ATC) willdifferbasedontheparticularconditioningroutine,andthiswillallowalternative expressionsof underlyingheterogeneity.IfSisobserved,thenconditionalaveragetreatmenteffectscanbecalculated forthosewhoaresubjecttothecausefordifferentreasons,basedonthevaluesofSthatdetermineD.\nIfX isobserved,thenconditionalaveragetreatmenteffectscanbecalculatedholdingothercausesof Y atchosenvaluesofX.Eachofthesesetsofconditionalaveragetreatmenteffectshasitsownappeal, with the relative appeal of each depending on the application. In the potential outcome tradition, average treatment effects conditional on S would likely be of more interest than average treatment effectsconditionalonX.Butforthosewhoareaccustomedtoworkingwithinanall-causeregression tradition,thenaveragetreatments effects conditional onX mightbemoreappealing.\nOne answer is that the researcher should do both.28 Nonetheless, there is a specific advantageofbalancingthatmaytipthescalesinitsfavorifbothstrategiesarefeasible: Balancing diminishes the inferential problems that can be induced by data-driven specification searches, as we will explain in Chapter 6.29 ## 4.5 Conclusions\nIn this chapter, we have used the causal graphs introduced in Chapter 3 to explain\nthe rationale for conditioning estimators of causal effects, focusing on the back-door criterion for selecting sufficient sets of conditioning variables that identify the ATE.\nWe then introduced models of treatment assignment and treatment selection from statistics and econometrics that are used to assert similar claims about conditioning estimators, focusing also on the ATT and ATC.\nIn the next three chapters, we present details and connections between the three main types ofconditioning estimation strategiesutilized in the socialsciences:match- ing, regression, and weighted regression. We show how they typically succeed when selection is on the observables and fail when selection is on the unobservables. We lay out the specific assumptions that allow for the identification of unconditional average treatment effects, as well as the weaker assumptions that allow for the identification of narrowerconditionalaveragetreatment effects, suchas the ATT and ATC. In later chapters, we then present additional methods for identifying and estimating causal effects when conditioning methods do not suffice because crucial variables on back- door paths are unobserved.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#appendix-to-chapter-4-the-back-door-and-adjustment-criteria-descendants-and-colliders-under-magnification",
    "href": "extracted/Counterfactuals and Causal Inference.html#appendix-to-chapter-4-the-back-door-and-adjustment-criteria-descendants-and-colliders-under-magnification",
    "title": "Counterfaturals and Causal Inference",
    "section": "4.6 Appendix to Chapter 4: The Back-Door and Adjustment Criteria, Descendants, and Colliders Under Magnification",
    "text": "4.6 Appendix to Chapter 4: The Back-Door and Adjustment Criteria, Descendants, and Colliders Under Magnification\nIn order to properly utilize the back-door criterion when evaluating alternative con-\nditioning sets, an analyst does not need to understand all details of all scenarios in which its violation will prevent a conditioning estimator from generating consistent and unbiased estimates of causal effects of interest. However, a deeper examination of additionalscenariosprovides insightinto commonmethodologicalchallenges,while also demonstrating the powerful contribution that graphical methods are likely to make to social science research in the coming decades.\nIn this appendix, we offer additional examples where colliders and descendants must be carefully considered in order to understand the fine points of why the back- door criterion warrants causal inference. We show how Condition 2 of the back-door 28As we discuss in later chapters, many scholars have argued for conditioning on both S and X.\nRobins,forexample,arguesforthisoptionasadoubleprotectionstrategythatofferstwochancesto effectivelyblocktheback-door pathsbetween D andY (seeRobinsandRotnitzky2001).\n29We phrase this guidance with “may” because it must be evaluated alongside another concern.\nBalancingallvariablesthatdetermineD,includingthosethatdonotgenerateconfounding,isunnec- essaryandinefficient.Asaresult,itmayrenderconditioninginfeasibleindatasetsofthesizetypically availabletosocialscientists.\ne e c o C O D Y Figure4.11 A causal graph with a confounded causal effect and where the variables along the back-door path are viewed under magnification.\ncriterion, which appears only to prevent the analyst from inadvertently conditioning onvariablesthat adjustawaythe causaleffectofinterest, alsoplaysa rolein blocking hidden as-if back-door paths that also result from conditioning on endogenous vari- ables.Weshowthatthisresultcanonlybeseenwhenendogenousvariablesareviewed under magnification, so that it becomes clear that these variables are also colliders.\nWe conclude with an examination of the connections between Pearl’s original back- doorcriterion,itsgeneralizationastheadjustmentcriterionofShpitser,VanderWeele, and Robins (2010), and our blended alternative, which retains the targeted spirit and inherent practicality of Pearl’s original back-door criterion while also incorporating some of the insight furnished by the admirably broad adjustment criterion.\nLike the appendix to Chapter 3, nothing in this appendix is necessary for under- standing the next three chapters thatfollow.We offer it for curiousreaderswho crave a deeper understanding of the back-door criterionand who wish to dive into the orig- inal literature after reading this book. We also offer it to explain to the community of causalgraphmethodologistswhywehavechosentheversionoftheback-doorcriterion that we have.\nThe Back-Door Criterion Explained with Causal Graphs Viewed Under Selective Magnification. The first step in fully considering why violations of the back-door criterion prevent conditioning estimators from delivering consistent and unbiasedestimatesistorepeatsomeofthematerialfromthemainbodyofthechapter, after redrawing the causal graphs under magnification. As we introduced in Section 3.3.2 using Figure 3.7, under magnification the unobserved structural error terms of the associated structural equations are brought into view. For Figure 4.11, we have redrawnFigure 4.1 under what we will call “selective magnification.” In this case, we magnify the nodes ofall variablesthat we might considerconditioning on,leaving the errortermsonthe causalvariableandthe outcome variablehiddenasin the standard representation for visual simplicity. Accordingly, Figure 4.11 shows two additional causal effects, eC→C and eO→O, that were only implicit in Figure 4.1.\nNow,reconsiderourexplanationoftheback-doorcriterionforthisgraph.Wewrote earlierthatconditioningonC and/orOwouldidentifythecausaleffect.Asatransition totheadditionalexamplesinthisappendix,wewillnowpresentthesameexplanation considering how the inclusion of eC →C and eO→O in the graph does not change this claim.\nIn the directed graph tradition, C is a “root” variable because it has no causes other than those embedded in its structural error term. Root variables do not need to be considered in any other way when viewed under magnification because their structural error terms are nothing more than the source of the variation observed for these variables. Accordingly, it is still the case that conditioning on C blocks the sole back-door path D←C→O→Y because C is the middle variable of a fork of mutual dependence that lies within the path. Because C is also not a descendant of D, it satisfies the back-door criterion.\nFor O, an additional complication should be clear. Under magnification, it is revealed that O is a collider variable because C→O is now accompanied by eO→O.\nIn general, all variables in a causal graph that are not root variables will appear as colliders when viewed under magnification. We have urged caution when handling colliders, and yet only now do we reveal that all variables such as O are, in fact, col- liders as well. Accordingly, conditioning on O will induce an association between C and eO. Fortunately, this conditioning does not invalidate the back-door criterion by unblocking an already blocked back-door path, as we will now explain.\nRecall our prior discussions of colliders in Sections 3.2.2 and 4.1.2. We have said that for a blockedpath, A→C←B, where C is the collider, conditioning onC opens upthispath.Wenowintroduceapieceofnotationtoconveythisresult:aconditioning “button,” (cid:10), that can be deployed to show the genesis of a new induced association, ···(cid:10)···.30 Forexample,forthe blockedpathA→C←B, conditioningonC generates a new association, A···(cid:10)···B, where the conditioning action itself, (cid:10), generates the association between A and B. For our hypothetical college admissions example in 4.1.2,the notationrepresentsthe followingaction:Abuttonispushedfor“admissions decisions,” and the population of applicants is then divided into those admitted and those rejected. Within both groups, A and B are now associated, as shown in Figure 4.2. The only way to eliminate the induced association is to undo the conditioning that generates it (i.e., release the conditioning button).\nReturn to Figure 4.11 so that we can demonstrate this new notation when consid- ering the conclusions suggested by an evaluation of the back-door criterion. Suppose again that O is our candidate conditioning variable, and we know that conditioning on O will block the back-door path D ←C →O →Y. When seen under magnifi- cation, it should be clear that now conditioning on O also generates a new associ- ation, C···(cid:10)···eO. In fact, conditioning on O also generates a second association, eC···(cid:10)···eO.31 Pearl (2009:339) explains, for examples such as this one, that these induced associations create two as-if back-door paths: 1. D←C···(cid:10)···eO→O→Y and 2. D←C←eC···(cid:10)···eO→O→Y.\n30Pearl and other authors often use alternative notation to convey the same associations, most commonlyA—B.Wepreferourmoreactive“button,”whichcanalsobedirectlyextendedtoactual operator status, asin···(cid:8)(.)···. Ifone wanted toshow conditioning onmorethanone variable,we wouldhave···(cid:8)(C,O)···,etc.\n31Conditioningonacollider,oradescendantofacollider,inducesassociationsbetweenallancestors ofthecollideronseparatedirectedpaths thatreachthecollider.\neC eO C O D Y Figure4.12 A diagram where the causal effect of D on Y is not confounded and where the observed variable O on the back-door path is a descendant of both D and Y.\nFortunately,bothoftheseas-ifback-doorpathsarealsoblockedwhenOisconditioned on because O is the middle variable in a chain of mediation, eO→O→Y, for both of them. Thus, O satisfies the back-doorcriterionbecause O is not a descendant of D and because conditioning on O eliminates all back-door associations between D and Y, including two associations created by as-if back-door paths that are only revealed under magnification.\nOfcourse,wealreadyknewthatOsatisfiedtheback-doorcriterionfromourconsid- erationofFigure4.1.Viewingthe graphunderselectivemagnificationhasforcedusto reckonwith the unobserved structural error terms, and little insight has been gained.\nWe will now consider two additional examples where consideration of the structural errorterms leadsto additionalinsightthatwill convincethe readerofhowsimple and effective the back-door criterion is.\nConsider Figure 4.12, where again we have four variables, and where all variables but D and Y are displayed under magnification. The only back-door path between D and Y, which is D←C→O←Y, is blocked by the collider O. Although it may seem awkward to refer to D←C→O←Y as a back-door path between D and Y (because it does not end with →Y), it satisfies our definition because it is a path betweentwo causallyorderedvariablesD andY thatbegins with D←. As a result, it isstillaback-doorpath,eventhoughitdoesnotterminatewith →Y (unlikeall other back-doorpaths displayed so far in our examples).32 Because the sole back-door path between D and Y does not generate a noncausal association between D and Y, there is no need to adjust for any variables in order to generate a consistent and unbiased estimate of the causal effect of D on Y.\nIn fact, all that one can do is make the situation worse. Suppose that an analyst believesmistakenlythatthepathD←C→O←Y isanunblockedback-doorpaththat must be blocked in order to generate a consistent and unbiased estimate of the effect of D on Y. Because C is unobserved, suppose that the analyst decides to condition onO instead, under the rationalethat it is the only observedvariable that lies on the back-door path.\n32We could bring this graph in line with prior ones by replacing Y →O with O←U→Y. The explanationwouldthenchangeabitbecauseOwouldnolongerbeadescendantofD viaadirected path,buttheanalysiswithrespecttoCondition1oftheback-doorcriterionwouldbethesame.\nThe variable O violates both conditions of the back-door criterion. Consider Con- dition 1 first. Because O is a collider variable, conditioning on O generates many new associations,includingC···(cid:10)···Y,eC···(cid:10)···Y,C···(cid:10)···eO,andeO···(cid:10)···Y.These induced associations generate three as-if back-door paths: 1. D←C···(cid:10)···Y, 2. D←C←eC···(cid:10)···Y, and 3. D←C···(cid:10)···eO···(cid:10)···Y.\nBecause C is unobserved, these as-if back-door paths remain unblocked after condi- tioning on O, and therefore O does not satisfy Condition 1 of the back-doorcriterion.\nNow consider Condition 2, and notice that O lies on a directed path, D→Y →O, that begins at D and reaches Y. As we noted earlier, we chose to specify Condition 2 of the back-door criterion with the words “reaches the outcome variable” rather than “ends at at the outcome variable” in order to capture cases such as this one. In this case, O lies on the directed path that represents the causal effect of interest, even though O does notmediate the casualeffect itself. The intuition ofCondition 2 ofthe back-doorcriterionshouldnonetheless still be clear. Becausethe causaleffect ofD on Y isfullyembeddedwithinthevariationinO,adjustingforO wouldexplainawaythe causal effect itself.33 Overall,then, conditioning on O in this graph would make the situation consider- ablyworse.Nounblockedback-doorpathsneededto be blockedinthe firstplace,and conditioning on O would generate as-if back-door paths that induce new noncausal associations between D and Y while at the same time robbing the causal effect of (possibly all) of its magnitude.\nTonow transitionto amore complicatedcase,pause to considerhowourlanguage in this appendix differs from the language used in the main body of the chapter. Up until now, we have expressed similar results to those for Figure 4.12 on the perils of conditioning on colliders using more brief language. For this graph, the simpler language would be the following: ConditioningonthecollidervariableO unblocksthealreadyblockedback- door path, D←C→O←Y.\nThis explanatorysyntax is concise andcorrect.Evenso,it should now be clear that a more laborious way to understand this result is the following: ConditioningonthevariableOthatisacolliderontheback-doorpathD← C → O ← Y creates additional as-if back-door paths such as D←C···(cid:10)···Y, D←C←eC···(cid:10)···Y, and D←C···(cid:10)···eO···(cid:10)···Y.\nThese as-if back-door paths are unblocked when conditioning on O.\n33Inaninfinitesample,whereinonecouldstratifythe dataonallvalues ofO,D andY wouldbe independent within the strata of O. In a finite sample, possibly necessitating the use of a different type of conditioning estimator, the conditional association between D and Y might not equal zero butwouldstillnotbeaconsistentestimateofthecausaleffect.\neC eO C O M eN D Y eM N B U eB eU Figure4.13 A graph where the effect of D on Y is not identified by conditioning on O and B because O is a descendant of D.\nForthegraphsconsideredinthemainbodyofthischapter,thismoretorturedlanguage would not have been helpful and therefore was not used. However, for this particular graph, the more tortured language may offer a clearer explanation. The brief expla- nation does not make clear why conditioning on O generates a back-door association by unblocking D←C →O←Y, given that this back-door path does not end with →Y. The more tortured language, which uses the conditioning button, does provide the proper imagery because the as-if back-door path, D←C···(cid:10)···Y, does not end with ←Y.\nFor an additional example, which draws many of these issues together, consider Figure 4.13. This graph is a redrawn version Figure 4.7, but now with all variables other than D and Y displayed under magnification. As noted earlier for Figure 4.7, there are three back-door paths from D to Y: 1. D←C→O→Y, 2. D←C→O←M→Y, and 3. D←B→U→Y.\nAgain, suppose that one decides to condition on both O and B. Using the condi- tioning button to reveal all of the associations generated by the conditioning action itself wouldgeneratemany new as-ifback-doorpaths. Considerjust two ofthese. The inducedassociationC···(cid:10)···M createstheas-ifback-doorpathD←C···(cid:10)···M→Y that remains unblocked after conditioning on O and B. This as-if back-door path is similar to those considered for Figure 4.12. But now consider how the induced associ- ationD···(cid:10)···eM createsthe as-ifback-doorpathD···(cid:10)···eM→M→Y. This path is also unblocked after conditioning on O and B. But, most importantly, this as-if back-door path only comes to the foreground when the causal graph is viewed under magnification. Except under magnification, it is all too easy to fail to recognize that M is a collider andthat conditioning ona descendantofM will induce anassociation between D and eM. For all but the most experienced causal graph practitioners, this as-if back-door path would be hidden by the standard representation of the graph.\nAs a result, the conditioning set of O and B does not satisfy Conditions 1(a), (b), and (c) of the back-door criterion. As we used this graph to show in the main body of the chapter, this graph also does not satisfy Condition 2 of the back-door criterion either. This result does not need to be explained in any different fashion whenthe graphis viewedunder selectivemagnification.Overall,the adjustedeffect of D on Y, which results from conditioning on O and B, would steal some of the total effect of D on Y. Yet, as we show here, the conditioning action also generates new back-door associations, one through the unobserved mediating variable M. This last as-if back-door path is completely hidden from view in the standard representation of a causal graph. Fortunately, all such hidden as-if back-door paths that emerge underconditioningwillnevercreepintoanempiricalanalysisaslongasthe back-door criterion is properly evaluated.\nAndthisisthekeypointofthislastexample:Condition2oftheback-doorcriterion must be heeded for two reasons. First, as was also presented in the main body of the chapter,conditioningondescendantsofthecausethatlieon(ordescendfrom)directed paths that begin at D and that reach Y will always mistakenly adjust away some of thecausaleffectthe analystisinterestedinestimating.Second,aswehavenowshown in this appendix, conditioning on the descendants of the cause (such as O) that are also descendants of unobserved colliders that are are themselves descendants of the cause (such as M) will always generate unblocked back-door associations that spoil the analysis. Fortunately, if one uses to the back-door criterion to select conditioning sets, then the threat of such hidden unblockedback-doorassociationscan be avoided.\nThe Back-Door and Adjustment Criteria Considered.As we noted earlier, ourversionoftheback-doorcriterionincorporatesinsightgainedfromthemorerecent developmentoftheadjustment criterion byShpitseretal.(2010).Figure4.14presents a graph that reveals the differences between Pearl’s original back-door criterion and the morerecentgeneralizationthatis the adjustmentcriterion.Wewilluse this graph to explain why we havemodified Pearl’soriginalback-doorcriterionto a small degree but also why we have not adopted the adjustment criterion as a whole.\nAs we have specifiedit in the mainbody of this chapter,the back-doorcriterionis evaluatedinthefollowingtwosteps.Thefirststepistowritedowntheback-doorpaths from D to Y, determine which ones are unblocked, andthen searchfor a conditioning set that will block all unblocked back-door paths. For Figure 4.14, the two back-door paths are 1. D←A→B←C→Y and 2. D←E→Y.\nPath 1 is already blocked by the collider B, and so only path 2 must be blocked by conditioning. Here, the solution is simple: Condition on E because it is the middle variable of a fork of mutual dependence.\nThe second step is to verify that the variables in the candidate conditioning set are not descendants of the causal variable that lie along, or descend from, all directed paths from the causal variable that reach the outcome variable. For Figure 4.14, it A B C E M N D Y O Q P R S T Figure4.14 A directed graphthat reveals the differences between the back-doorcri- terion and the adjustment criterion.\nis easy to see that E is a root variable and as such is not a descendant of any other variable in the graph.\nHowever,to understandthe differencesbetweenthe back-doorcriterioninits orig- inal form and the adjustment criterion, we need to consider this step in more detail.\nFor more elaborate causal graphs, in order to evaluate Condition 2 of the back-door criteriononeneedstoascendthefamilytreebylooking“upstream”throughthearrows thatpointtoeachcandidateconditioningvariable(i.e.,fromtheparent,tothegrand- parent,to the greatgrandparent,andso on)to determine whether the causalvariable is a direct ancestor of any of the candidate conditioning variables. If the causal vari- able is not found to be an ancestor of any of the candidate conditioning variables in the set under consideration, then by definition none of the candidate conditioning variableslies onordescends fromdirectedpaths that beginatthe causalvariableand that reach the outcome variable. In this case, a conditioning estimator that uses the variables under consideration will generate consistent and unbiased estimates of the causal effect of interest.\nIfthe causalvariableisdiscoveredto be anancestorofanyofthe candidate condi- tioning variables in the set under consideration, then for our versionof the back-door criterion(which incorporatesinsightfrom the adjustment criterion), one has to deter- mine whether the directed paths from the causal variable that establish the descent of the conditioning variable(s) also reach the outcome variable. If not, then one can still condition on any such variables and generate consistent and unbiased estimates.\nIf, instead, any of the candidate conditioning variables are descendants of the causal variable and lie on or descend from directed paths that begin at the causal variable and reach the outcome variable, then the conditioning set will block or adjust away someofthecausaleffect.Inthiscase,the conditioningsetwillnotgenerateconsistent and unbiased estimates of the causal effect of interest.\nTo now transition to a parallel considerationof the adjustment criterion, and why we have not adopted it in whole, return to the case of Figure 4.14 and consider how the back-doorcriterionmightbe utilized inpractice by anexperiencedanalyst.As we notedaboveinthisappendix,conditioningonE alonesatisfiestheback-doorcriterion.\nNotice,however,that,inadditiontoE,onecouldalsoconditiononA,onC,onAand B, on B and C, or on A, B, and C. The back-door criterion does not rule out these possibilities, but it does not encourage the analyst to consider A and C as members ofthe candidateconditioning setbecausethe back-doorpathonwhichthese variables lie is already blocked in the absence of any conditioning by B. Instead, the back-door criterion guides the analystto the essentialinformation: (1) path 1 is already blocked by B and can be left alone; (2) path 2 must be blocked by conditioning on E.\nNonetheless, an experienced analyst might reason that, although one should not condition only on B, one could condition on B as long as either A or C is also condi- tionedon. The experiencedanalystmightthenchooseto offer twoestimates, onethat conditions only on E and one that conditions on B and C as well (perhaps because a fair critic has a theory says that the B←C in Figure 4.14 should instead be B→C).\nThe experienced analystmight reachthis positioneven thoughshe regardscondition- ing on B and C as unnecessary and inefficient, given that she truly does believe that her theoretical assumptions represented by the original graph are beyond reproach.\nNevertheless, she might reason that it is prudent to show a fair critic that even if his alternativeassumptions arecorrect,the mainresults ofthe ensuing empiricalanalysis remain the same.\nOnce one begins to allow supplementary but unnecessary conditioning variables intotheconditioningset,aquestionarisesastowhethertheback-doorcriterioncovers all cases. This is the inspiration for the adjustment criterion, developed by Shpitser etal.(2010).Itisdesignedtoallowthe analysttoidentify allpermissibleconditioning sets, including those that include unnecessary andredundant conditioning,as we now explain.\nTheadjustmentcriterionalsohastwosteps.Forthefirststep,theanalystconsiders all paths in the graph that begin at the causal variable and then categorizesall paths into(1)“causalpaths,”whicharedefinedasalldirectedpathsfromthecausalvariable totheoutcomevariable,and(2)“noncausalpaths,”whicharedefinedasallpathsfrom the causal variable that are not causal paths. For Figure 4.14, one would enumerate the following paths, categorizing them as follows: 1. D←A→B←C→D (noncausal), 2. D←E→Y (noncausal), 3. D→M→Y (causal), 4. D→N→Y (causal), 5. D→N→O (noncausal), 6. D→P (noncausal), 7. D→Q←Y (noncausal), 8. D→R←S→T ←Y (noncausal).\nNotice that paths 1 and 2 are back-door paths for the back-door criterion but, for the adjustment criterion, are classified as members of the more encompassing set of noncausal paths. The first step of the adjustment criterion then requires that the analyst search for variables that, when conditioned on, will ensure that all noncausal paths betweenD andY areblocked. This is analogousto the back-doorcriterion,but nowallnoncausalpaths,notjustback-doorpaths,mustbeconsidered.ForFigure4.14, thispartofthefirststeprequiresthe analysttosearchforallpermissibleconditioning setsthatwillblockthenoncausalpaths1,2,5,6,7,and8.ForthecaseofFigure4.14, moresetsthanwewishtoenumeratewouldbeselected.Inbrief,allsetswouldinclude E and exclude Q. Yet, these sets would include many combinations of additional unnecessary conditioning variables, including appropriate combinations of A, B, C, N, O, P, R, S, and T, such as the maximal blocking set {A,B,C,E,N,O,P,R,S,T}.\nFor the second step of the adjustment criterion, one then implements the same secondstepastheversionoftheback-doorcriterionwehavespecifiedinthemainbody ofthe chapter.For Figure4.14,this steprequiresthat the candidateconditioning sets notinclude the variablesM,N,orO. PresumablyM wouldnothavebeenconsidered as a conditioning variable in the first place because it is not a variable that lies on any of the noncausal paths that the analyst is attempting to block. Nonetheless, the analystmustalsostrikeallconditioningsetsthatincludeN andO,andthisconclusion has to be discerned from the graph, not the list of the paths that does not reveal full patterns of descent. (This is also the case for the back-door criterion.) Theadvantageoftheadjustmentcriteriaisthatitwillrevealallpermissiblecondi- tioning sets, such as the maximal permissible conditioning set {A,B,C,E,P,R,S,T}, assuming that the analyst devotes the necessary energy to delineating all patterns of permissible conditioning. The disadvantage is that, for graphs such as the one in Fig- ure4.14,the adjustmentcriterionis laboriousandis likelyto leadone to conditionon more variables than is necessary to identify the causal effect.\nWe have therefore chosen to stick with the back-door criterion in the main body of the chapter, with only one substantial modification to Pearl’s originalspecification in deference to the completeness of the adjustment criterion. As we noted earlier in our footnote on Condition 2 of our version of the back-door criterion, Pearl’s original back-door criterion requires more simply (but overly strongly) that no variables in the conditioning set Z can be descendants of the causal variable. For our version of the back-door criterion, we weaken Pearl’s original no-descendants condition to allow conditioning on variables, such as P in Figure 4.14, that are descendants of the cause D but that do not lie on or descend from directed paths that begin at D and reach Y. We doubt an analyst would think to condition on P when evaluating the back- door criterion for this graph (because the back-door criterion focuses attention more narrowlyonback-doorpaths,ratherthanallnoncausalpaths).Still,this modification oftheback-doorcriterionallowsittoidentifymoreofthepermissibleconditioningsets thatareidentifiedbythemorelaboriousbutadmirablycompleteadjustmentcriterion.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#origins-of-and-motivations-for-matching",
    "href": "extracted/Counterfactuals and Causal Inference.html#origins-of-and-motivations-for-matching",
    "title": "Counterfaturals and Causal Inference",
    "section": "5.1 Origins of and Motivations for Matching",
    "text": "5.1 Origins of and Motivations for Matching\nMatchingtechniqueshaveoriginsinexperimentalworkfromthe firsthalfofthe twen-\ntieth century. Relatively sophisticated discussions of matching as a research design can be found in early methodological texts in the social sciences (e.g., Greenwood 1945) and also in attempts to adjudicate between competing explanatory accounts in applieddemography(Freedman andHawley 1949).This early workcontinued in soci- ology (e.g., Althauser and Rubin 1970, 1971; Yinger, Ikeda, and Laycock 1967) right up to the key foundational literature in statistics (Rubin 1973a, 1973b, 1976, 1977, 1979, 1980a) that provided the conceptual foundation for the new wave of matching techniques that we will present in this chapter.\nIntheearly1980s,matchingtechniques,asweconceiveofthemnow,wereadvanced in a set of papers by Rosenbaum and Rubin (1983a, 1984, 1985a, 1985b) that offered solutions to a variety of practical problems that had limited matching techniques to very simple applications in the past.3 Variants of these new techniques found some use immediately in sociology (Berk and Newton 1985; Berk, Newton, and Berk 1986; Hoffer,Greeley,and Coleman1985),continuing with work by Smith (1997).Since the late 1990s, economists and political scientists have contributed to the development of new matching techniques (e.g., Heckman et al. 1999; Heckman, Ichimura, Smith, andTodd 1998;Heckman,Ichimura,andTodd1997,1998in economicsandHo, Imai, King, and Stuart 2007 and Diamond and Sekhon 2013in political science). Given the growth of this literature, and the applications that are accumulating, we expect that matching will complement other types of modeling in the social sciences with greater frequency in the future.\nIn the methodological literature, matching is usually introduced in one of two ways: (1) as a method to form quasi-experimental contrasts by sampling comparable treatment and control cases from among two larger pools of such cases or (2) as a nonparametric method of adjustment for treatment assignment patterns when it is feared that ostensibly simple parametric regression estimators cannot be trusted.\nFor the first motivation, the archetypical example is an observational biomedical studyinwhicharesearcheriscalledontoassesswhatcanbelearnedaboutaparticular treatment.Theinvestigatorisgivenaccesstotwosetsofdata,oneforindividualswho have been treated and one for individuals who have not. Each dataset includes a measurement of current symptoms, Y, and a set of characteristicsof individuals, as a vector of variables X, that are drawn from demographic profiles and health histories.\n3See Rubin (2006) for a compendium. See Guo and Fraser (2010), Sekhon (2009), and Stuart (2010)forreviewsthatconnecttheearlyliteraturetothecurrentstateofpractice,butwithdifferent pointsofemphasisthanweofferinthischapter.\nTypically, the treatment cases are not drawn from a population by means of any known sampling scheme. Instead, they emerge as a result of the distribution of initial symptoms, patterns of access to the health clinic, and then decisions to take the treatment. The control cases, however, may represent a subsample of health histories from some known dataset. Often, the treatment is scarce, and the control dataset is much larger than the treatment dataset.\nInthisscenario,matchingisamethodofstrategicsubsamplingfromamongtreated and control cases. The investigator selects a nontreated control case for each treated casebasedonthecharacteristicsobservedasxi.Alltreatedcasesandmatchedcontrol cases are retained, and all nonmatched control cases are discarded. Differences in the observed yi are then calculated for treated and matched cases, with the average difference serving as the treatment effect estimate for the group of individuals given the treatment.4 The second motivation has no archetypical substantive example, as it is similar in form to any attempt to use regression to estimate causal effects with survey data.\nSuppose, for a general example, that an investigator is interested in the causal effect of an observed dummy variable, D, on an observed outcome, Y. For this example, it is assumed that a simple bivariate regression, Y =α+δD+ε, will yield an esti- mated coefficient δˆthat is an inconsistent and biased estimate of the causal effect of interestbecausethecausalvariableDisassociatedwithvariablesincludedintheerror term,ε.Foraparticularexample,ifDisthereceiptofacollegedegreeandY isamea- sureofeconomicsuccess,thentheestimateofinterestisthecausaleffectofobtaininga college degree on subsequent economic success. However, family backgroundvariables are present in ε that are correlated with D, and this relationship produces omitted- variable bias for a college-degree coefficient estimated from a bivariate ordinary least squares (OLS) regressionof Y on D.\nIn comparison with the biomedical example just presented, this motivation differs intwoways:(1)inmostapplicationsofthistype,thedatarepresentarandomsample from a well-defined population and (2) the common practice in the applied literature is to use regression to estimate effects. For the education example, a set of family backgroundvariables in X is assumedto predictboth D andY. The standardregres- sion solution is to estimate an expanded regression equation: Y =α+δD+Xβ+ε∗.\nWith this strategy (which we will discuss in detail in the next chapter), the goal is to estimate simultaneously the causal effects of X and D on the outcome, Y.\nIn contrast, a matching estimator nonparametrically balances the variables in X acrossDsolelyintheserviceofobtainingthebestpossibleestimateofthecausaleffect of D on Y. The most popular technique is to estimate the probability of D for each individualiasafunctionofX andthentoselectforfurtheranalysisonlymatchedsets oftreatmentandcontrolcasesthatcontainindividualswithequivalentvaluesforthese predicted probabilities. This procedure results in a subsampling of cases, comparable with the matching procedure described for the biomedical example, but for a single 4Avirtueofmatching, as developed inthistradition,iscost-effectiveness forprospectivestudies.\nIfthegoalofastudyistomeasuretheevolutionofacausaleffectovertimebymeasuringsymptoms at several points in the future, then discarding nontreated cases unlike any treated cases can cut expenses without substantially affecting the quality of causal inferences that a study can yield. See StuartandIalongo(2010).\ndimensionthatis a function ofthe variablesinX. Inessence, the matching procedure throws away information from the joint distribution of X and Y that is unrelated to variationinthetreatmentvariableDuntiltheremainingdistributionofX isequivalent for both the treatment and control cases.When this equivalence is achieved, the data aresaidtobebalancedwithrespecttoX.5 Underspecificassumptions,theremaining differences inthe observedoutcome betweenthe treatmentandmatchedcontrolcases can then be regarded as attributable solely to the effect of the treatment.6 Atmostpoints inthe remainderofthis chapter,wewilladoptthis secondscenario because research designs in which data are drawn from random-sample surveys are much more common in the social sciences.7 Thus, we will assume that the data in hand were generated by a relatively large random-sample survey (in some cases an infinite sample to entirely remove sampling error from consideration), in which the proportion and pattern of individuals who are exposed to the cause are fixed in the population by whatever process generates causal exposure.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#matching-as-conditioning-via-stratification",
    "href": "extracted/Counterfactuals and Causal Inference.html#matching-as-conditioning-via-stratification",
    "title": "Counterfaturals and Causal Inference",
    "section": "5.2 Matching as Conditioning via Stratification",
    "text": "5.2 Matching as Conditioning via Stratification\nInthissectionweintroducematchingestimatorsinidealizedresearchconditions,draw-\ning connections with the broad perspective on conditioning introduced in Chapter 4.\nThereafter, we proceed to a discussion of matching in more realistic scenarios, which iswhere we explainthe developmentsofmatching techniquesthat havebeenachieved in the past three decades.\n5.2.1 Estimating Causal Effects by Stratification Supposethatthosewhotakethetreatmentandthosewhodonotareverymuchunlike eachother,andyetthe waysinwhichthey differarecapturedexhaustivelybya setof observed treatment assignment/selection variables S. For the language we will adopt in this chapter, knowledge and observation of S allow for a “perfect stratification”of the data. By “perfect,”we mean precisely that individuals within groups defined by values on the variables in S are entirely indistinguishable from each other in all ways exceptfor (1) observedtreatment status and (2) differences in the potential outcomes that are independent of treatment status. Under such a perfect stratification of the data, even though we would not be able to assert Assumptions 1 and 2 in Equations 5As we will discuss later, in many applications balance can be hard to achieve without some subsampling from among the treatment cases. In this case, the causal parameter that is identified is narrower even than the ATT (and is usually a type of marginal treatment effect pinned to the commonsupportoftreatment andcontrolcases).\n6A third motivation, which is due to Ho et al. (2007; see also Iacus and King 2012), has now emerged. Matching can be used as a data preprocessor that prepares a dataset for further causal modeling with a parametric model. We discuss this perspective along with others when we intro- duceparticularmatchingtechniques thatarecurrentlyinuseintheappliedliterature,includingthe “coarsenedexactmatching”ofIacus, King,andPorro(2011, 2012a).\n7SeeourearlierdiscussioninSection1.4ofthisrandom-samplesetup.\n(2.15)and(2.16),wewouldbeabletoassertconditionalvariantsofthoseassumptions: Assumption 1-S: E[Y1|D=1,S]=E[Y1|D=0,S], (5.1) Assumption 2-S: E[Y0|D=1,S]=E[Y0|D=0,S]. (5.2) These assumptions would suffice to enable consistent and unbiased estimation of the average treatment effect (ATE) because the treatment can be considered randomly assigned within groups defined by values on the variables in S.\nWheninthissituation,researchersoftenassertthatthenaiveestimatorinEquation (2.9) is subject to bias (either generic omitted-variable bias or individually generated selection bias). But, because a perfect stratification of the data can be formulated, treatment assignment is ignorable – see the earlier discussion of Equation (4.3) – or treatment selection is on the observable variables only – see the earlier discussion of Equation(4.7). Thisis abitimprecise,however,becauseAssumptions 1-Sand2-Sare implied by ignorabilityandselectiononthe observables(assuming S is observed).For ignorability and selection on the observables to hold more generally, the full distribu- tionsofY1 andY0 (andanyfunctions ofthem)mustbe independentofD conditional on S; see the discussion of Equation (4.4). Thus Assumptions 1-S and 2-S are weaker than assumptions of ignorability and selection on the observables, but they are suffi- cient to identify the three averagecausal effects of primary interest.\nRecallthedirectedgraphinFigure4.8(b),whereS liesontheonlyback-doorpath fromD to Y. Asdiscussedthere,conditioningonS allowsforconsistentandunbiased estimation of the unconditional ATE, as well as the average treatment effect for the treated (ATT) and the average treatment effect for the controls (ATC). Although we gave a conceptual discussion in Chapter 4 of why conditioning works in this scenario, we will now explain more specifically with a demonstration. First note why every- thing works out so cleanly when a set of perfect stratifying variables is available. If Assumption 1-S is valid, then E[δ|D=0,S]=E[Y1−Y0|D=0,S] =E[Y1|D=0,S]−E[Y0|D=0,S] (5.3) =E[Y1|D=1,S]−E[Y0|D=0,S] =E[Y|D=1,S]−E[Y|D=0,S].\nIf Assumption 2-S is valid, then E[δ|D=1,S]=E[Y1−Y0|D=1,S] =E[Y1|D=1,S]−E[Y0|D=1,S] (5.4) =E[Y1|D=1,S]−E[Y0|D=0,S] =E[Y|D=1,S]−E[Y|D=0,S].\nThelastlineofEquation(5.3)isidenticaltothelastlineofEquation(5.4),andneither lineincludescounterfactualconditionalexpectations.Accordingly,onecanconsistently estimate the difference in the last line of Equation (5.3) and the last line of Equation (5.4) for each value of S. To then form consistent estimates of alternative average treatment effects, one simply averagesthe stratified estimates over the distribution of S, as we show in the following demonstration.\nMatching Demonstration 1 Consider a completely hypothetical example in which Assumptions 1 and 2 in Equa- tions(2.15)and(2.16)cannotbeassertedbecausepositiveselectionensuresthatthose whoareobservedinthetreatmentgrouparemorelikelytobenefitfromthetreatment than those who are not. But assume that a three-categoryperfect stratifying variable S is available that allows one to assert Assumptions 1-S and 2-S in Equations (5.1) and(5.2). Moreover,suppose for simplicity of expositionthat our sample is infinite so that sampling error is zero. In this case, we can assume that the sample moments in our data equal the population moments (i.e., EN[yi|di=1]=E[Y|D=1] and so on).\nIf it is helpful, think of Y as a measure of an individual’s economic success at age 40,Dasanindicatorofreceiptofacollegedegree,andS asamixedfamily-background and preparedness-for-collegevariable that completely accounts for the pattern of self- selectionintocollegethatisrelevantforlifetimeeconomicsuccess.Note,however,that no one has ever discoveredsuch a variable as S for this particular causal effect.\nSuppose that, for our infinite sample, the sample mean of the outcome for those observedin the treatment groupis 10.2, whereas the sample mean of the outcome for those observed in the control group is 4.4. In other words, we have data that yield EN[yi|di=1]=10.2 and EN[yi|di=0]=4.4, and for which the naive estimator would yield a value of 5.8 (i.e., 10.2−4.4).\nConsider, now, an underlying set of potential outcome variables and treatment assignmentpatterns that could give rise to a naive estimate of 5.8. Table 5.1 presents the joint probability distribution of the treatment variable D and the stratifying vari- able S in its first panel as well as expectations, conditional on S, of the potential outcomes under the treatment and control states. The joint distribution in the first panel shows that individuals with S equal to 1 are more likely to be observed in the control group, individuals with S equal to 2 are equally likely to be observed in the control group and the treatment group, and individuals with S equal to 3 are more likely to be observed in the treatment group.\nAs shown in the second panel of Table 5.1, the average potential outcomes condi- tional on S and D imply that the average causal effect is 2 for those with S equal to 1 or S equal to 2, but 4 for those with S equal to 3 (see the last column). Moreover, as shown in the last row of the table, where the potential outcomes are averagedover the within-D distributionofS,E[Y|D=0]=4.4andE[Y|D=1]=10.2,matching the initial setup of the example based on a naive estimate of 5.8 from an infinite sample.\nTable 5.2 shows what can be calculated from the data, assuming that S offers a perfect stratification of the data. The first panel presents the sample expectations of the observedoutcome variable conditionalon D andS. The secondpanel of Table 5.2 presentscorrespondingsample estimatesofthe conditionalprobabilitiesofS givenD.\nTheexistenceofaperfectstratification(andthesupposedavailabilityofdatafrom an infinite sample) ensures that the estimated conditional expectations in the first panel of Table 5.2 equal the population-level conditional expectations of the second panel of Table 5.1. When stratifying by S, the average observed outcome for those in the control/treatment group with a particular value of S is equal to the average potential outcome under the control/treatmentstate for those with a particular value Table 5.1 The Joint Probability Distribution and Conditional Population Expectations for Matching Demonstration 1 Joint probability distribution of S and D D=0 D=1 S=1 Pr[S=1,D=0]=.36 Pr[S=1,D=1]=.08 Pr[S=1]=.44 S=2 Pr[S=2,D=0]=.12 Pr[S=2,D=1]=.12 Pr[S=2]=.24 S=3 Pr[S=3,D=0]=.12 Pr[S=3,D=1]=.2 Pr[S=3]=.32 Pr[D=0]=.6 Pr[D=1]=.4 Potential outcomes Underthecontrol state Underthetreatment state S=1 E[Y0|S=1]=2 E[Y1|S=1]=4 E[Y1−Y0|S=1]=2 S=2 E[Y0|S=2]=6 E[Y1|S=2]=8 E[Y1−Y0|S=2]=2 S=3 E[Y0|S=3]=10 E[Y1|S=3]=14 E[Y1−Y0|S=3]=4 E[Y0|D=0] E[Y1|D=1] =.36(2)+.12(6) =.08(4)+.12(8) .6 .6 .4 .4 +.12(10) +.2(14) .6 .4 =4.4 =10.2 Table 5.2 Estimated Conditional Expectations and Probabilities for Matching Demonstration 1 Estimated mean observed outcome conditional on si and di Control group Treatment group si=1 EN[y i|s i=1,d i=0]=2 EN[y i|s i=1,d i=1]=4 si=2 EN[y i|s i=2,d i=0]=6 EN[y i|s i=2,d i=1]=8 si=3 EN[y i|s i=3,d i=0]=10 EN[y i|s i=3,d i=1]=14 Estimated probability of S conditional on D si=1 PrN[s i=1|d i=0]=.6 PrN[s i=1|d i=1]=.2 si=2 PrN[s i=2|d i=0]=.2 PrN[s i=2|d i=1]=.3 si=3 PrN[s i=3|d i=0]=.2 PrN[s i=3|d i=1]=.5 ofS.Conversely,ifS werenotaperfectstratifyingvariable,thenthesamplemeansin thefirstpanelofTable5.2wouldnotequalthe expectationsofthepotentialoutcomes in the secondpanel of Table 5.1. The sample means would be based onheterogeneous groups of individuals who differ systematically within the strata defined by S in ways that are related with individual-level treatment effects.\nIf S offers a perfect stratification of the data, then one can estimate from the numbers in the cells of the two panels of Table 5.2 both the ATT as (4−2)(.2)+(8−6)(.3)+(14−10)(.5)=3 and the ATC as (4−2)(.6)+(8−6)(.2)+(14−10)(.2)=2.4.\nFinally, if one calculates the appropriate marginal distributions of S and D (using sampleanalogsforthemarginaldistributionfromthefirstpanelofTable5.1),onecan estimate the unconditional ATE either as (4−2)(.44)+(8−6)(.24)+(14−10)(.32)=2.64 or as 3(.4)+2.4(.6)=2.64.\nThus, for this hypothetical example, the naive estimator would be inconsistent and (asymptotically)upwardlybiasedfor the ATT, ATC, andthe ATE. But, by appropri- ately weighting stratified estimates of the treatment effect, one can obtain consistent and unbiased estimates of all three of these average treatment effects.\nIn general, if a stratifying variable S completely accounts for all systematic differ- ences between those who take the treatment and those who do not, then conditional- on-S estimatorsyieldconsistentandunbiasedestimatesoftheaveragetreatmenteffect conditional on a particular value s of S: {EN[yi|di=1,si=s]−EN[yi|di=0,si=s]} (5.5) p −→E[Y1−Y0|S=s]=E[δ|S=s].\nWeighted sums of these stratified estimates can then be taken, such as for the uncon- ditional ATE: (cid:6) p {EN[yi|di=1,si=s]−EN[yi|di=0,si=s]}PrN[si=s]−→E[δ]. (5.6) s Substituting into this last expression the distributions of S conditional on the two possible values of D (i.e., PrN[si=s|di=1] or PrN[si=s|di=0]), one can obtain consistent and unbiased estimates of the ATT and ATC.\nThe key to using stratification to solve the causal inference problem for all three causal effects of primary interest is twofold: finding the stratifying variable and then obtaining the marginal probability distribution Pr[S] as well as the conditional prob- ability distribution Pr[S|D]. Once these steps are accomplished, obtaining consistent andunbiasedestimatesofthewithin-stratatreatmenteffectsisstraightforward.There- after,estimatesofotheraveragetreatmenteffectscanbeformedbytakingappropriate weighted averages of the stratified estimates.\nThis simple example shows all of the basic principles of matching estimators that wewillpresentingreaterdetailintheremainderofthischapter.Treatmentandcontrol subjects arematchedtogetherinthe sensethat they aregroupedtogetherinto strata.\nThen,anaveragedifferencebetweentheoutcomesoftreatmentandcontrolsubjectsis estimated, based on a weighting of the strata (and thus the individuals within them) by a common distribution.\n5.2.2 Overlap Conditions for Estimation of the ATE Suppose again that a perfect stratification of the data is available, such that within values of a stratifying variable S individuals are indistinguishable from each other as defined in the lastsection. But now suppose that there is a stratum of the population (andhence ofthe observeddata)inwhichnomember ofthe stratumeverreceivesthe treatment. In this case, the ATE is ill-defined, and the analyst will only be able to generate a consistent and unbiased estimate of the ATT, as we show in the following demonstration.8 Matching Demonstration 2 For the example depicted in Tables 5.3 and 5.4, S again offers a perfect stratification of the data. The setup of these two tables is exactly equivalent to that of the prior Tables 5.1 and 5.2 for Matching Demonstration 1. We again assume that the data are generated by a random sample of a well-defined population, and for simplicity of exposition that the sample is infinite. The major difference is evident in the joint distribution ofS andD presentedinthe first panel of Table 5.3. As shownin the first cell of the second column, no individual in the population with S equal to 1 would ever be observed in the treatment group of a dataset of any size because the joint probability of S equal to 1 and D equal to 1 is zero. Corresponding to this structural zero in the joint distribution of S and D, the second panel of Table 5.3 shows that there is no corresponding conditional expectation of the potential outcome under the treatment state for those with S=1. And, thus, as shown in the last column of the second panel, no average causal effect is presented for individuals with S=1 because this particular average causal effect is ill-defined.9 Adopting the same framing as for the college-degree example used in Matching Demonstration 1, this hypothetical example asserts that there is a subpopulation of individuals from suchdisadvantagedbackgroundsthat no individuals with S=1 have ever graduated from college. For this group of individuals, we assume in this example thatthereissimplynojustificationforusingthewagesofthosefrommoreadvantaged social backgrounds to extrapolate to the what-if wages of the most disadvantaged individuals if they had somehow overcome the obstacles that prevented them from obtaining college degrees.\n8In this section, we focus on the lack of overlap that may exist in a population (or super- population). Fornow, weignorethelackofoverlapthatcanemergeinobserved datasolelybecause ofthefinitesizeofadataset. Weturntotheseissuesinthenextsection,wherewediscusssolutions tosparseness.\n9By “ill-defined,” we mean the following. No information about E[Y|S=1,D=1] or E[Y1|S= 1,D=1]existsinthepopulation(and,asaresult,thedatawillnevergiveusavalueforE N[y i|s i= 1,d i=1]becausenoindividualsinthedatawilleverhaveboths i=1andd i=1).\nTable 5.3 The Joint Probability Distribution and Conditional Population Expectations for Matching Demonstration 2 Joint probability distribution of S and D D=0 D=1 S=1 Pr[S=1,D=0]=.4 Pr[S=1,D=1]=0 Pr[S=1]=.4 S=2 Pr[S=2,D=0]=.1 Pr[S=2,D=1]=.13 Pr[S=2]=.23 S=3 Pr[S=3,D=0]=.1 Pr[S=3,D=1]=.27 Pr[S=3]=.37 Pr[D=0]=.6 Pr[D=1]=.4 Potential outcomes Underthe control state Underthetreatment state S=1 E[Y0|S=1]=2 S=2 E[Y0|S=2]=6 E[Y1|S=2]=8 E[Y1−Y0|S=2]=2 S=3 E[Y0|S=3]=10 E[Y1|S=3]=14 E[Y1−Y0|S=3]=4 E[Y0|D=0] E[Y1|D=1] =.4(2)+.1(6) =.13(8)+.27(14) .6 .6 .4 .4 +.1(10) .6 =4 =12.05 Table 5.4 Estimated Conditional Expectations and Probabilities for Matching Demonstration 2 Estimated mean observed outcome conditional on si and di Control group Treatment group si=1 EN[y i|s i=1,d i=0]=2 si=2 EN[y i|s i=2,d i=0]=6 EN[y i|s i=2,d i=1]=8 si=3 EN[y i|s i=3,d i=0]=10 EN[y i|s i=3,d i=1]=14 Estimated probability of S conditional on D si=1 PrN[s i=1|d i=0]=.667 PrN[s i=1|d i=1]=0 si=2 PrN[s i=2|d i=0]=.167 PrN[s i=2|d i=1]=.325 si=3 PrN[s i=3|d i=0]=.167 PrN[s i=3|d i=1]=.675 Table 5.4showswhatcanbe estimatedconsistently forthis example. Eventhough S offers a perfect stratification of the data, the fact that Pr[S=1,D=1]=0 prevents theanalystfromusingthe dataforthe stratumwith S=1toestimateastratum-level causal effect. No value exists for EN[yi|si=1,di=1].\nFortunately, the analyst can consistently estimate the average effect of the treat- mentseparately for the two stratawith S=2and S=3.And, because all members of the treatment groupbelong to these two strata,the analystcantherefore consistently estimate the ATT as (8−6)(.325)+(14−10)(.675)=3.35.\nStill, no consistent and unbiased estimates of the ATC or the ATE are available.10 Areexamples suchasthis one everfoundin practice?For anexample thatis more realistic than the causal effect of a college degree on economic success, consider the evaluation of a generic program in which there is an eligibility rule. The benefits of enrolling in the program for those who are ineligible cannot be estimated from the data, even though, if some of those individuals were enrolled in the program, they would likely be affected by the treatment in some way. Developing such estimates would require going well beyond the data, introducing assumptions that allow for extrapolation off of the joint distribution of S and D.\nMore generally, even in best-case data availability scenarios where the sample size is infinite, it may not be possible to consistently estimate all average causal effects of theoretical or practical interest because the distribution of the treatment across all segments of the population is incomplete. However, at other times, the data may appear to suggest that no causal inference is possible for some group of individuals even though the problem is simply a small sample size. There is a clever solution to sparsenessofdataforthislattertypeofsituation,whichwediscussinthenextsection.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#matching-as-weighting",
    "href": "extracted/Counterfactuals and Causal Inference.html#matching-as-weighting",
    "title": "Counterfaturals and Causal Inference",
    "section": "5.3 Matching as Weighting",
    "text": "5.3 Matching as Weighting\nAs shown in the last section, if all of the variables in S have been observed such that\na perfect stratification of the data would be possible with an infinitely large random sample from the population, then a consistent and unbiased estimator is available in theory for each of the average causal effects of interest defined in Equations (2.3), (2.7), and (2.8) as the ATE, ATT, and ATC, respectively. Unfortunately, in many (if not most) datasets of finite size, it may not be possible to use the simple estimation methods of the last section to generate consistent and unbiased estimates. Treatment and control cases may be missing at random within some of the strata defined by S, such that some strata contain only treatment or only control cases. In this situation, some within-stratum causal effect estimates cannot be calculated with the available data.Wenowintroduceasetofweightingestimatorsthatrelyonestimatedpropensity scores to solve the sparseness problems that afflict samples of finite size.\n10The naive estimate can be calculated for this example, and it would equal 8.05 for an infinite sample because [8(.325)+14(.675)]−[2(.667)+6(.167)+10(.167)] is equal to 8.05. See the last row of Table 5.3 for the population analogs to the two pieces of the naive estimator. This means that, withoutdeterminingthelackofoverlapbystratifyingthedata,anincautiousanalystmightofferthe naiveestimateandthendiscussitsrelationshiptotheATE,whichisitselfatargetparameterthatis ill-defined.\n5.3.1 The Utility of Known Propensity Scores An estimated propensity score is the estimated probability of taking the treatment as a function of variables that predict treatment assignment. Before the attraction of estimated propensity scores is explained, there is value in understanding why known propensityscoreswouldbeusefulinanidealizedcontextsuchasaperfectstratification of the data. (See also our prior discussion of propensity scores in Section 4.3.1.) Within a perfect stratification, the true propensity score is nothing other than the within-stratum probability of receiving the treatment, or Pr[D=1|S]. For the hypothetical example in Matching Demonstration 1, the propensity scores are .08 Pr[D=1|S=1]= =.182, .44 .12 Pr[D=1|S=2]= =.5, .24 .2 Pr[D=1|S=3]= =.625.\n.32 Why is the propensity score useful? As shown earlier for Matching Demonstration 1, ifa perfect stratificationofthe data is available,then the finalingredientfor calculat- ing estimates of the ATT and ATC is the conditional distribution Pr[S|D]. One can recoverPr[S|D]fromthepropensityscoresbyapplyingBayes’ruleusingthemarginal distributions of D and S. For example, for the first stratum, Pr[D=1|S=1]Pr[S=1] (.182)(.44) Pr[S=1|D=1]= = =.2.\nPr[D=1] (.4) Thus,thetruepropensityscoresencodeallofthenecessaryinformationaboutthejoint dependence ofS andD that isneeded toestimate andthencombine conditional-on-S treatmenteffectestimatesintoestimatesofthe ATTandthe ATC.Knownpropensity scores are thus useful for unpacking the inherent heterogeneity of causal effects and then averagingover such heterogeneity to calculate average treatment effects.\nOfcourse,knownpropensityscoresarealmostneveravailableto researcherswork- ingwithobservationalratherthanexperimentaldata.Thus,theliteratureonmatching more often recognizes the utility of propensity scores for addressing an entirely dif- ferent concern: solving comparison problems created by the sparseness of data in any finite sample. These methods rely on estimated propensity scores, as we discuss next.\n5.3.2 Weighting with Estimated Propensity Scores to Address Sparseness Supposeagainthataperfectstratificationofthe dataexists andis known.Inparticu- lar,Assumptions1-Sand2-SinEquations(5.1)and(5.2)arevalid,andS isobserved.\nBut, suppose now that (1) there are multiple variables in S, (2) some of the variables in S take on many values, and (3) the true propensity score is greater than 0 and less than 1 for every stratum defined by S. In this scenario, there may be many strata in the available data from a finite sample in which no treatment and/or no control casesareobserved,eventhoughthe true propensityscoreis between0and1forevery stratum in the population (i.e., every population-level stratum includes individuals in both the treatment and control states).\nCan average treatment effects be consistently estimated in this scenario? RosenbaumandRubin(1983a)answerthisquestionaffirmatively.Theessentialpoints of their argument are the following (see the original article for a formal proof): First, the sparseness that results from the finiteness of a sample is random, conditional on thejointdistributionofS andD.Asaresult,withineachstratumforaperfectstratifi- cationofthe data,the probabilityofhavingazerocellinthe treatmentorthe control state is solely a function of the propensity score. Because such sparseness is condi- tionallyrandom,stratawithidenticalpropensityscores(i.e.,differentcombinationsof values for the variables in S but the same within-stratum probability of treatment) can be combined into more coarse strata. Over repeated samples from the same pop- ulation, zero cells would emerge with equal frequency across all strata within these coarse propensity-score-definedstrata.\nBecause sparseness emerges in this predictable fashion, stratifying on the propen- sity score itself (rather than more finely on all values of the variables in S) solves the sparseness problem because the propensity score can be treated as a single stratify- ing variable. In fact, as we show in the next hypothetical example, one can obtain consistent estimates of treatment effects by weighting the individual-level data by an appropriately chosen function of the estimated propensity score, without ever having to compute any stratum-specific causal effect estimates.\nButhowdoesoneobtainthepropensityscoresfordatafromarandomsampleofthe populationofinterest?RosenbaumandRubin (1983a)arguethat, if onehas observed thevariablesinS,thenthepropensityscorecanbeestimatedusingstandardmethods, such as logit modeling. That is, one can estimate the propensity score, assuming a logistic distribution, exp(Sφ) Pr[D=1|S]= , (5.7) 1+exp(Sφ) and invoke maximum likelihood to estimate a vector of coefficientsφˆ. One can then stratify on the index of the estimated propensity score, e(si)=siφˆ, or appropriately weight the data, and all of the results established for known propensity scores then obtain.11Considerthefollowinghypotheticalexample,inwhichweightingisperformed only with respect to the estimated propensity score, resulting in consistent and unbi- asedestimatesofaveragetreatmenteffectseventhoughsparsenessproblemsaresevere.\n11AsRosenbaum(1987)laterclarified(seealsoRubinandThomas1996),theestimatedpropensity scoresdoabetterjobofbalancingtheobservedvariablesinS thanthetruepropensityscoreswould inanyactual application,becausetheestimatedpropensityscorescorrectforthechance imbalances in S that characterize any finite sample. This insight has led to a growing literature that seeks to balancetheobservedvariablesinSbyvariouscomputationallyintensivebutpowerfulnonparametric techniques(e.g.,DiamondandSekhon2013;Lee,Lessler,andStuart2009;McCaffrey,Ridgeway,and Morral 2004). We discuss this literature later, and for now we use only parametric models for the estimationofpropensityscores,astheydominatethefoundational literatureonmatching.\nMatching Demonstration 3 Consider the following Monte Carlo simulation, which is an expanded version of the hypothetical example in Matching Demonstration 1 in two respects. First, for this example, there are two stratifying variables,A and B, each of which has 100 separate values.AsforMatchingDemonstration1,thesetwovariablesrepresentaperfectstrat- ification of the data and, as such, represent all of the variables in the set of perfect stratifying variables, defined earlier as S. Second, to demonstrate the properties of alternativeestimators,this example utilizes 50,000samplesofdata,eachofwhichis a randomrealizationof the same set of definitions for the constructedvariables and the stipulated joint distributions between them.\nGeneration of the 50,000 Datasets. For the simulation, we gave the variables A andB valuesof.01,.02,.03,andupwardto1.Wethencross-classifiedthetwovariables to form a 100×100grid and stipulated a propensity score, as displayed in Figure 5.1, that is a positive, nonlinear function in both A and B.12 We then populated the resulting 20,000 constructed cells (100×100 for the A×B grid multiplied by the two values of D) using a Poisson random-number generator with the relevant propensity score as the Poisson parameter for the 10,000 cells for the treatment group and one minusthepropensityscoreasthePoissonparameterforthe10,000cellsforthecontrol group. This sampling scheme generates (on average across simulated datasets) the equivalentof10,000sample members,assignedtothe treatmentinsteadofthe control as a function of the probabilities plotted in Figure 5.1.\nAcrossthe 50,000simulateddatasets,onaverage7,728ofthe 10,000possible com- binationsofvaluesforbothAandB hadnoindividualsassignedtothetreatment,and 4,813hadnoindividualsassignedtothecontrol.Nomattertheactualrealizedpattern of sparseness for each simulated dataset, all of the 50,000 datasets are afflicted, such that a perfect stratification on all values for the variables A and B would result in manystratawithineachdatasetforwhichonlytreatmentorcontrolcasesarepresent.\nTo define treatment effects for each dataset, two potential outcomes were defined as linear functions of individual values for A and B: y i0=100+3ai+2bi+υ i0, (5.8) y i1=102+6ai+4bi+υ i1, (5.9) where both υ0 and υ1 are independent random draws from a normal distribution i i with expectation 0 and standard deviation of 5. Then, as in Equation (2.2), individ- uals from the treatment group were given an observed yi equal to their simulated y i1, and individuals from the control group were given an observed yi equal to their simulated y0.\ni With this setup, the simulation makes available 50,000 datasets for which the individual treatment effects can be calculated exactly (because true values of y1 and i 12Theparameterizationofthepropensityscoreisaconstrainedtensorproductsplineregressionfor theindexfunctionofalogit.SeeRuppert,Wand,andCarroll(2003)forexamplesofsuchparameter- izations.Here,SφinEquation(5.7)isequal to−2+3(A)−3(A−.1)+2(A−.3)−2(A−.5)+4(A− .7)−4(A−.9)+1(B)−1(B−.1)+2(B−.7)−2(B−.9)+3(A−.5)(B−.5)−3(A−.7)(B−.7).\n00..88 00..66 eerrooccSS yyttiissnneeppoorrPP 00..44 00..22 00 11 00..88 11 00..66 00..88 00..44 00..66 00..44 00..22 00..22 BB 00 00 AA Figure5.1 The propensity score specification for Matching Demonstration 3.\ny0 are available for all simulated individuals). As a result, the true ATE, ATT, and i ATC areknownforeachsimulateddataset, andthese knownaverageeffects canserve as baselines against which alternative estimators that use data only on yi, di, ai, and bi can be compared.\nThefirstrowofTable5.5presentstrueMonteCarlomeansandstandarddeviations ofthethreeaveragetreatmentseffects,calculatedacrossthe50,000simulateddatasets.\nThe mean of the true ATE acrossall datasets is 4.525,whereas the means of the true ATT and ATC are 4.892 and 4.395, respectively. Similar to the hypothetical example in Matching Demonstration 1, this example represents a form of positive selection, in whichthosewhoaremostlikelytobeinthetreatmentgrouparealsothosemostlikely to benefit from the treatment. Accordingly, the ATT is larger than the ATC.\nMethods for Treatment Effect Estimation. The last three rows of Table 5.5 present results for three propensity-score-based weighting estimators. For the esti- mates in the second row, it is (incorrectly) assumed that the propensity score can be estimatedconsistentlywithalogitmodelwithlineartermsforAandB (i.e.,assuming that, for Equation (5.7), a logit with Sφ specified as α+φAA+φBB will yield con- sistent estimates of the propensity score surface plotted in Figure5.1). After the logit model was estimated for each of the 50,000 datasets with the wrong specification, the Table 5.5 Monte Carlo Means and Standard Deviations of True and Estimated Treatment Effects for Matching Demonstration 3 ATE ATT ATC True treatment effects 4.525 4.892 4.395 (.071) (.139) (.083) Propensity-score-based weighting estimators: Misspecified propensity 4.456 4.913 4.293 score estimates (.122) (.119) (.128) Perfectly specified 4.526 4.892 4.396 propensity score estimates (.120) (.127) (.125) True propensity scores 4.527 4.892 4.396 (.127) (.127) (.132) estimated propensity score for each individual was then calculated, exp(αˆ+φˆ Aai+φˆ Bbi) pˆi= , (5.10) 1+exp(αˆ+φˆ Aai+φˆ Bbi) along with the estimated odds of the propensity of being assigned to the treatment pˆi rˆi= 1−pˆi, (5.11) where pˆi is as constructed in Equation (5.10).\nTo estimate the ATT, we then implemented a weighting estimator by calculating the average outcome for the treated and subtracting from this average outcome a counterfactualaverageoutcome using weighted data on those from the controlgroup: ⎛ (cid:12) ⎞ (cid:7) (cid:8) rˆiyi (cid:6) δˆ ATT,weight≡ n1 yi −⎜ ⎝i:di(cid:12)=0 ⎟ ⎠, (5.12) 1 rˆi i:di=1 i:di=0 where n1 is the number of individuals in the treatment group and rˆi is the estimated odds for each individual i of being in the treatment group instead of in the control group, as constructed in Equations (5.10) and (5.11). The weighting operation in the second term gives more weight to control group individuals equivalent to those in the treatmentgroup;seeRosenbaum(1987,2002);seealsoImbens(2004)andHainmueller (2012).13 To estimate the ATC, we then implemented a weighting estimator that is 13AswewilldescribeinChapter 7whendiscussingtheconnections betweenmatchingandregres- sion,theweightingestimatorinEquation(5.12)canbewrittenasaweightedregressionestimator.\nthe mirror image of the one in Equation (5.12): ⎛ (cid:12) ⎞ (cid:7) (cid:8) yi/rˆi (cid:6) δˆ ATC,weight≡⎜ ⎝i:(cid:12)di=1 n1/rˆi⎟ ⎠− n1 yi , (5.13) 0 i:di=0 i:di=1 where n0 is the number of individuals in the controlgroup.Finally, the corresponding estimator of the unconditional ATE is (cid:7) (cid:8) (cid:18)(cid:7) (cid:8)(cid:19) (cid:6) (cid:16) (cid:17) (cid:6) (cid:16) (cid:17) 1 1 δˆ ATE,weight≡ di δˆ ATT,weight + 1− di δˆ ATC,weight , (5.14) n n i i whereδˆ ATT,weight andδˆ ATC,weight areasdefinedinEquations(5.12)and(5.13),respec- tively.\nThe same basic weighting scheme is implemented for the third row of Table 5.5, buttheestimatedpropensityscoresutilizedtodefinetheestimatedoddsoftreatment, rˆi, are instead based on results from a flawlessly estimated propensity score equation (i.e., one that uses the exact same specification that was fed to the random-number generator that assigned individuals to the treatment; see footnote on page 153 for the specification). Finally, for the last row of Table 5.5, the same weighting scheme is implemented, but, in this case, the estimated odds of treatment, rˆi, are replaced with the true odds of treatment, ri, as calculated with reference to the exact function that generated the propensity score for Figure 5.1.\nMonte Carlo Results. On average across all 50,000 simulated datasets, the naive estimator yields a value of 5.388, which is substantially larger than all three of the average values for the true ATE, ATT, and ATC presented in the first row of Table 5.5. The reason is simple. The two variables A and B mutually cause both D and Y (in a structure analogous to Figure 3.5). The two back-door paths, D←A→Y and D←B→Y, generate noncausal associations between D and Y. These paths must be blocked, and this is the motivation for the weighting estimators.\nThe second row of the table presents three estimates from the weighting estima- tors in Equations (5.12), (5.13), and (5.14), using weights based on the misspecified logit described above. These estimates are closer to the true average values presented in the first row (and much closer than the average value of the naive estimate), but the misspecification of the propensity-score-estimating equation appears to generate systematicbiasintheestimates,suggestingthattheyareunlikelytobeconsistentesti- mates. The third row of the table presents another three weighting estimates, using a perfect specification of the propensity-score-estimating equation, and now the esti- matesappeartobe consistentandunbiasedforthe ATE,ATT,andATC.Finally,the lastrowpresents weightingestimatesthat utilize the true propensity scores,whichwe know by construction are consistent and asymptotically unbiased (but, as shown by Rosenbaum 1987,more variable than those based on the flawlessly estimated propen- sity score; see also Hahn 1998; Hirano, Imbens, and Ridder 2003; Rosenbaum 2002).\nThe last two rows demonstrate the most important claim of the literature: If one can obtain consistent estimates of the true propensity scores, one can solve the problems created by sparseness of data.\nThis example shows the potential power of propensity-score-based modeling. If treatmentassignmentcanbemodeledperfectly,onecansolvethesparsenessproblems that afflict finite datasets.At the same time, this simulation also develops two impor- tantqualificationsofthispotentialpower.First,thissolutiononlyholdsinexpectation overrepeatedsamples(orinthe limitasthe samplesizeincreasestoinfinity).Forany single dataset, any resulting point estimate of a treatment effect will differ from the true target parameter to some degree because of sampling variability.\nSecond, without a perfect specification of the propensity-score-estimating equa- tion, one cannotrest assuredthat consistentand unbiased estimates can be obtained.\nBecause propensity scores achieve their success by “undoing” the treatment assign- ment patterns, analogous to weighting a stratified sample so that it is representative of the population, systematically incorrect estimated propensity scores can generate systematicallyincorrectweightingschemesthatyieldinconsistentandbiasedestimates of treatment effects.\nThere are two common sources of inconsistency and bias that can be considered separately. As discussed at length in Chapter 4, if the conditioning set leaves one or more back-door paths unblocked, then Assumption 1-S and/or Assumption 2-S in Equations (5.1) and (5.2) are/is invalid. We avoided this problem in Matching Demonstration 3 because we used A and B to estimate the propensity scores, and we know by construction that S is defined as the set {A,B}. Had we mistakenly used only A or only B, then we would not have conditioned fully on S, thereby leaving a back-door path unblocked. We will have much more to say about this source of inconsistency and bias in the remainder of this chapter.\nThesecondsourceofinconsistencyandbiasismisspecificationoftheequationthat estimatesthepropensityscores,andthisisespeciallyimportanttoconsiderforthesort ofpropensity-score-basedweightingestimatorsutilizedforMatchingDemonstration3.\nFor the results reported in the second row of Table 5.5, we included both A and B in the propensity-scoreestimating equation. But, we did not do so while also choosing a flexible enough parameterizationof A and B that would allow the data to generate a sufficiently accurate set of estimated propensity scores (which, in expectation, would match the shape of the surface in Figure 5.1, when plotted in three dimensions). As a result,the estimated effects in the Monte Carlo simulationwere systematically biased when the weights based on these estimated propensity scores were used. Only when the correct specification was used to generate the weights were we able to generate unbiased estimates of the ATE, ATT, and ATC.\nThese possible weaknesses aside, one concluding question should be answered: In what sense are the individual-level weighting estimators of the hypothetical example in Matching Demonstration 3 equivalent to matching estimators? For the hypothet- ical examples in Matching Demonstrations 1 and 2, we explained how stratification estimatorshaveastraightforwardconnectiontomatching.The stratathatareformed represent matched sets, and a weighting procedure is then used to average stratified treatment effect estimates in order to obtain the average treatment effects of inter- est. The propensity-score weighting estimators presented in this section have a less straightforwardconnection.Here,thedataare,ineffect,stratifiedcoarselybytheesti- mation of the propensity score, and then the weighting is performed directly across individuals instead of across the strata. This individual-level weighting is made nec- essary by sparseness, since some of the fine strata for which propensity scores are estimated necessarily contain only treatment or control cases, thereby preventing the direct calculation of stratified treatment effect estimates.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#matching-as-a-data-analysis-algorithm",
    "href": "extracted/Counterfactuals and Causal Inference.html#matching-as-a-data-analysis-algorithm",
    "title": "Counterfaturals and Causal Inference",
    "section": "5.4 Matching as a Data Analysis Algorithm",
    "text": "5.4 Matching as a Data Analysis Algorithm\nAlgorithmic matching estimators differ primarily in (1) the number of matched cases\ndesignatedforeachto-be-matchedtargetcaseand(2)howmultiple matchedcasesare weighted if more than one is utilized for each target case. In this section, we describe the four main types of matching estimators as well as recent extensions to them.\nHeckman, Ichimura, and Todd (1997, 1998) and Smith and Todd (2005) outline a general framework for representing alternative matching estimators, and we follow their lead.With ourvariantoftheir notation,allmatchingestimatorsofthe ATT can be expressed as some variation of ⎡ ⎤ (cid:6) (cid:6) δˆ ATT,match= n1 ⎣ (yi|di=1)− ωi,j(yj|dj=0)⎦ , (5.15) 1 i j wheren1 isthenumberoftreatmentcases,iistheindexovertreatmentcases,j isthe index over control cases, and ωi,j represents a set of scaled weights that measure the distance between eachcontrolcase and the targettreatment case.In Equation(5.15), the weights are entirely unspecified. For the ATC, an opposite expressionis available, with alternative weights ωj,i instead attached to the control cases (cid:18) (cid:19) (cid:6) (cid:6) 1 δˆ ATC,match= (yj|dj=0)− ωj,i(yi|di=1) , (5.16) n0 j i and where n0 is the number of control cases.\nAlternative matching estimators can be represented as different procedures for deriving the weights represented by ωi,j and ωj,i in these two expressions. As we will describe next, the weights can take on many values, indeed as many n1×n0 different values, because alternative weights can be used when constructing the counterfactual value for each target case. The difference in the propensity score between the target case and each potential matched case is the most common distance measure used to construct weights. Other measures of distance are available, including the estimated oddsofthepropensityscore,theindexofanestimatedlogit,probit,orotherparametric binary outcome model, and the Mahalanobis metric.14 Beforedescribingthefourmaintypesofmatchingalgorithms,andtheirextensions, we note three important points. First, for simplicity of presentation, in the remainder ofthis sectionwe willfocus onmatching estimatorsofthe ATT.Eachofthe following matching algorithms could be described in reverse, explaining how treatment cases canbe matched to control casesin orderto constructanestimate ofthe ATC, relying on Equation (5.16) rather than Equation (5.15). We mention this, in part, because it 14The Mahalanobis metric is (S i−S j)(cid:3)Σ−1(S i−S j), where Σ is the covariance matrix of the variablesinS(usuallycalculatedforthetargetcasesonly).Thereisalongtraditioninthisliterature ofusingMahalanobismatching,sometimesincombinationwithpropensity-scorematching.\nis sometimes implied in the applied literature that the matching techniques that we areaboutto summarizeareuseful forestimating onlythe ATT. This isfalse. If(1)all variables in S are known and observed, such that a perfect stratification of the data could be formed with a suitably large dataset because both Assumptions 1-S and 2-S in Equations (5.1) and (5.2) are valid and (2) the ranges of all of the variables in S are the same for the treatment group and the control group, then simple variants of the matching estimators that we will present in this section can be formed that are consistent for both the ATT and ATC (and, as a result, for the ATE as a weighted average).\nSecond,ifitisthecasethatoneonlywantstoestimatetheATT,onedoesnotneed toassumefull ignorabilityoftreatmentassignmentorthatbothAssumptions 1-Sand 2-SinEquations(5.1)and(5.2)arevalid.Instead,onlyAssumption2-S(i.e.,E[Y0|D= 1,S]=E[Y0|D=0,S])must hold. In other words,to estimate the ATT, it is sufficient to assume that, conditional on S, the average level of the outcome under the control for those in the treatment is equal, on average, to the average level of the outcome under the control for those in the control group.15 This assumption is still rather stringent, in that it asserts that those in the control group do not disproportionately gainfromexposuretothe controlstatemorethanwouldthoseinthe treatmentgroup ifthey wereinsteadin the controlgroup.Butit is surelyweakerthanhavingto assert Assumptions 1-S and 2-S together.16 Third, the matching algorithms we summarize next are data analysis procedures that can be used more generally when ignorability, or related assumptions, cannot be assumed to hold because some of the variables in the perfect stratification set S are unobserved. Matching routines are still useful, according to Rosenbaum (2002) and others, as techniques that generate provisional estimates that can then be subjected to further analysis in pursuit of warrantedcausal inferences.\n5.4.1 Basic Variants of Matching Algorithms Exact Matching Exact matching for the ATT constructs the counterfactual for each treatment case usingthecontrolcaseswithidenticalvaluesonallofthevariablesinS.Inthenotation ofEquation(5.15), exactmatching uses weightsequal to 1/ki forthe matchedcontrol cases, where ki is the number of exact matches identified for each target treatment case i. Weights of 0 are given to all unmatched control cases. If only one exact match is chosen at random from among available exact matches, then ωi,j is set to 1 for the randomly selected match and to 0 for all other control cases.\n15Thereis anignorabilityvariant of this mean-independence assumption: D isindependent of Y0 conditional on S.One would always prefer a study design inwhichthis moreencompassing formof independenceholds.Resultingcausalestimateswouldthenholdundertransformationsofthepotential outcomes.ThiswouldbeparticularlyhelpfulifthedirectlymappedY –definedasDY1+(1−D)Y0– isnotobservedbutsomemonotonictransformationofY isobserved(ascouldperhapsbegenerated byafeatureofmeasurement).\n16Andthisisagainweakerthanhavingtoassertanassumptionofignorabilityoftreatmentassign- ment.\nIfS includesmorethanoneortwovariablesand/orthesamplesizeoftheavailable dataislimited,thenexactmatchingistypicallyinfeasible,sincemanytreatmentcases will remain unmatched. As a result, exact matching is rarely used on its own and is instead most commonly used in combination with one of the other matching methods describedinthefollowingsections.Theanalystperformsanexactmatchononeortwo of the variables in S and then utilizes another matching algorithm for the remaining variables in S.\nNearest-Neighbor, Caliper, and Radius Matching Nearest-neighbor matching for the ATT constructs the counterfactual for each treat- ment case using the control cases that are closest to the treatment case on a unidi- mensional distance measure constructed from the variables in S, most commonly an estimated propensity score (see Althauser and Rubin 1970;Cochran and Rubin 1973; RosenbaumandRubin1983a,1985a,1985b;Rubin1973a,1973b,1976,1980a,1980b).\nAs noted in our discussion of Equation (5.15), other distance metrics are sometimes used.\nThetraditionalalgorithmrandomlyordersthetreatmentcasesandthenselectsfor each treatment case the single control case with the smallest distance on the chosen metric. The algorithm can be run with or without replacement. With replacement, a controlcaseisreturnedtothepoolafteramatchandcanbematchedlatertoanother treatment case. Without replacement, a control case is taken out of the pool once it is matched.\nOne weakness of the traditional algorithm when used without replacement is that the estimate will vary depending on the order in which the the treatment cases are passed to the matching algorithm. Moreover, any single estimate may not be based on the minimum aggregate distance between all treatment cases and their matched controlcases.Aformofoptimalmatching,whichwediscussbelow,hasbeendeveloped to remedy these weakness in the traditional algorithm by selecting the best overall match of the data from among all of those that are possible.\nAn analyst can also match on a fixed number of multiple nearest neighbors for each target treatment case, such as 5 nearest neighbors for each target treatment case. The decision of whether to set the algorithm to select more than one nearest neighbor represents a subtle trade-off.Matching more controlcases to each treatment case results in lower expected variance of the treatment effect estimate but also tends to increase bias because the probability of making more poor matches increases with the number of matches.\nIfonlyonenearestneighborisselectedforeachtreatmentcase,asinthetraditional algorithm, then ωi,j is set equal to 1 for the matched control case. If multiple nearest neighbors are selected, the weights ωi,j are set equal to 1/ki for each matchednearest neighbor, whereki is the number of matches selectedfor eachtargettreatmentcase i.\nAs with exact matching, the weights are set to 0 for all unmatched control cases.\nA danger with nearest-neighbor matching, especially when the algorithm is forced to find a fixed multiple of matches such as 5, is that it may result in some very poor matches for some treatment cases. A version of nearest-neighbor matching, known as caliper matching, is designed to remedy this drawback by restricting matches to a chosen maximum distance, such as .25 standard deviations of the distance metric whencalculatedonlyforthetreatmentcases.Thisdistancerestrictionthenalsoallows for variable numbers of multiple nearest neighbors (e.g., ≤5 nearest neighbors within thecaliperforeachtargettreatmentcase).However,withthis typeofmatching,some treatment cases may not receive matches, since for some of these cases no control cases will fall within their caliper. If this occurs, the resulting effect estimate then applies only to the subset of the treatment cases that have received matches (even if ignorability holds and there is simply sparseness in the data). Because such a data- inducedshiftoffocus inthe targetparametermaybe undesirable,acommonstrategy is to then use a hybrid approach, where in a second step all treatment cases without any caliper-based matches are then matched to a single nearest neighbor outside of the caliper.\nFinally,forradiusmatching,thereisvariationinterminologyanddefinitionsinthe literature.Mostcommonly,allcontrolcaseswithinaparticulardistanceofeachtarget treatment case are matched, and as a result the “radius” is functionally equivalent to thecaliperincalipermatching.And,again,theweightsωi,j aresetequalto1/kiforthe matchednearestneighbors,whereki isthe numberofmatchesselectedforeachtarget treatment case i. The difference from caliper matching is simply that all potential matcheswithinthecaliperofeachtreatmentcaseareanointedasmatchesforthetarget treatment case, which means that the matching is performed with replacement.17 As with caliper matching, supplemental single nearest-neighbormatching may be needed if the analystwishes to keep all treatment cases in the analysis.For some researchers, such additional forced matching is an essential component of radius matching, unlike caliper matching.\nInterval Matching Intervalmatching(alsoreferredtoassubclassificationandstratificationmatching)for the ATT sorts the treatment and controlcases into segments of a unidimensional dis- tance metric, usually the estimated propensity score (see Cochran 1968; Rosenbaum and Rubin 1983a, 1984; Rubin 1977). For the traditional estimator of the ATT, the intervalsaredefinedby cutpoints onthe distancemetric thatsubdivide the treatment casesintoa chosennumber ofequal-sizedsubgroups(e.g.,the intervalsthatsubdivide 1,000treatment casesinto five groupsof 200). Morerecentvariants ofinterval match- ing, sometimes referred to as full matching, use an optimization step to first generate intervals of variable size that minimize the within-subgroup average difference in the distance metric.\nNo matter how defined, for each interval a variant of the matching estimator in Equation(5.15)isthenestimatedseparately.Theweightsωi,j aresettogivethe same amount of weight to the treatment cases and control cases within each interval. The ATTisthencalculatedasthe meanofthe interval-specifictreatmenteffects,weighted by the number of treatment cases in each interval.\n17In contrast, caliper matching can be performed without replacement, although it is most com- monlyperformedwithreplacement.\nKernel Matching Kernel matching for the ATT constructs the counterfactual for each treatment case using all control cases but weights each control case based on its distance from the treatment case (see Heckman, Ichimura, and Todd 1997, 1998). The weights repre- sented by ωi,j in Equation (5.15) are calculated with a kernel function, G(.), that transforms the distance between the selected target treatment case and all control cases in the study. When the estimated propensity score is used to measure the dis- tance, kernel-matching estimators define the weight as G(pˆj−pˆi) ωi,j=(cid:12) G(a pˆn j−pˆi), (5.17) j an wherean isabandwidthparameterthatscalesthe differenceintheestimatedpropen- sity scores based on the sample size and pˆ is the estimated propensity score.18 The numerator of this expression yields a transformed distance between each control case and the target treatment case. The denominator is a scaling factor equal to the sum of all the transformed distances across control cases, which is needed so that the sum of ωi,j is equal to 1 across all control cases when matched to each target treatment case.\nAlthough kernel-matching estimators appear complex, they are a natural exten- sion of nearest-neighbor caliper and radius matching: All control cases are matched to each treatment case but weighted so that those closest to the treatment case are given the greatest weight. Smith and Todd (2005) offer an excellent intuitive discus- sionofkernelmatchingalongwith generalizationstolocallinearmatching (Heckman, Ichimura,Smith,andTodd1998)andlocalquadraticmatching(Ham,Li,andReagan 2011).\n5.4.2 Recent Matching Routines That Seek Optimal Balance In the description of the matching algorithms above, we have given no indication of which algorithm will work best. We will defer this question until after we offer a demonstration of a variety of matching techniques below. Instead, in this section we will shift the motivation of matching slightly in order to present the most recent matching estimators that we will discuss in this section.\nConsider our order of presentation of the main issues so far in this chapter. We offered Matching Demonstrations 1 and 2 to explain the basic conditioning strategy thatunderliesmatchingandtoclarifywhyconsistentestimatesoftheATT,ATC,and ATE are all available when the set of perfect stratifying variables S is observed. We then turnedto MatchingDemonstration3 to explainhow estimatedpropensityscores can address the problems posed by finite sample sizes, under the recognition that a full stratification of the data on all of the variables in S will rarely be feasible if S includes many variables and/or those variables take on many values.\nThe recentmethodologicalliteratureonmatching assumes thatthe readeralready knows these points and instead moves directly to the consideration of an omnibus 18Increasing the bandwidth increases bias but lowers variance. Smith and Todd (2005) find that estimates arefairlyinsensitivetothesizeofthebandwidth.\nperformance criterion that motivates most recent matching routines: the capacity of matchingestimatorstobalancethevariablesthathavebeenmatchedon.Wetherefore need to explain the concept of balance in more detail, first in an abstract sense and theninrelationtotheparticularmatchingestimatorsconsideredsofarinthischapter.\n(See also our earlier brief discussion of balance in Section 4.4.) Consider a case where we have many variables in the perfect stratification set S, whereallofthesevariablesareobserved,butwherewehaveafinitesampleafflictedby rampant sparseness. In such a dataset, many combinations of values on the variables inS willnotbe present,eventhoughindividuals with thesepatterns ofvaluesexistin thepopulation.Tocapturethispointformally,letPrN[si]representtheobservedjoint distribution acrossthe realizedvalues s of all variables in S for a particular sample of size N. For a dataset with substantial sparseness, the joint distribution PrN[si] will not in general be equal to the population distribution of S, denoted Pr[S]. Generic sampling variation will lead to over-representation and under-representation of most combinations of values on the variables in S, and many of the rarest combinations in the population will not be present in the sample.\nTo now consider within-sample balance with respect to a treatment effect param- eter, we must consider the observed joint distribution of S conditional on member- ship in the observed treatment and control groups, PrN[si|di=1] and PrN[si|di=0], respectively. For all examples considered so far in this chapter, the observed data are imbalanced with respect to treatment effect estimates for D because PrNsi|di=1=PrN[si|di=0]. (5.18) Inwords,thejointdistributionsfortheobservedversionsofthevariablesintheperfect stratification set S are not the same in the treatment and control groups.\nThe underlying goal of all matching estimators is to transform the data in such a way that they can be analyzed as if they are balanced with respect to the treatment effect of interest, which will be the case if PrN[si|di=1]=PrN[si|di=0] (5.19) inthematcheddataset.IftheATTistheparameterofinterest,thenthedatawillonly be balanced when matching has yielded a set of matched control cases that have the same joint distribution for the observed variables in S that the treatment cases have in the originalobserveddataset. If the ATC and ATE are also parameters of interest, then the data will only be balanced with respect to these additional parametersif the same routine also yields a set of matched treatment cases that have the same joint distribution for the observed variables in S that the control cases have in the original observed dataset.\nConsider classic exact matching in a scenario where all treatment cases have one available exact match among the control cases, and where by exact we mean again that the resulting matched pairs have the same values on all of the variables in S.\nIn this case, optimal balance is achieved for estimation of the ATT. In particular, all unmatched cases are tossed out of the dataset, and the remaining treatment and control cases have the exact same observedjoint distribution acrossall variablesin S.\nThese data are not, however,balanced with respect to either the ATC or the ATE.19 For a closely related example, where the data are balanced with respect to the ATT, ATC, and ATE, consider our hypothetical stratification example in Matching Demonstration1.Forthatexample,weassumedaninfinitesamplewherethedistribu- tionofS (see Table5.1)differsacrossthetreatmentandcontrolgroups,suchthatthe populationandsamplehavetreatmentgroupswithdisproportionatelylownumbersof individualswithsi=1anddisproportionatelyhighnumbersofindividualswithsi=3.\nAccordingly, the observeddata are imbalanced. However,when the data are analyzed within the strata of S, the average values for the outcome Y are generated from bal- ancedcomparisonswithrespecttoS because,withineachstratum,allindividualshave the samevalue for S.20 Togenerateestimates ofthe ATT, ATC,andATE,a common distributionofS is thenpassedbacktothe estimatoras stratum-levelweights.Inthis sense,astratificationestimator,ifavailable,isageneralizationofexactmatchingthat allows one to optimally balance the data for all average treatment effects that can be defined as functions in the underlying strata, including the ATT, ATC, and ATE.\nAs we noted above, finite datasets generallyrender exact matching and full strati- fication infeasible. Indeed, this was the impetus for the developmentof matching esti- mators, such as propensity-score matching, that utilize distance metrics for matching that are lower-dimensionalthan the full joint distribution of the perfect stratification set S. In these cases, perfect balance is generally impossible to achieve, as we now explain.\nConsiderourhypotheticalexampleinMatchingDemonstration3.Fortheassumed data there, the distributions of A and B (which jointly represent the perfect strat- ification set S) differ across the treatment and control groups, such that the 50,000 simulated samples, on average, have treatment groups with disproportionately high values for A and B. Similar to Matching Demonstration 1, individuals are grouped into strata, but now only implicitly by estimation of the propensity score and only coarsely (i.e., not based on the full stratification defined by the full joint distribu- tion of A and B). Individuals are then weightedwithin these propensity-score-defined strata, although indirectly by individual-level weights, in order to ensure that the expected distribution of S is the same within the treatment and controlcases that are then used to estimate the ATT, ATC, and ATE.\nNotice the inclusion of the word “expected” in the last sentence. Unlike exact matching and our full stratification example in Matching Demonstration 1, the data 19They wouldbe balanced withrespect to the ATC andATE ifthe unmatched control cases also had the same observed joint distribution for S as the treatment cases. This would be the case if (1)alltreatmentcaseshavetwoexactmatchesamongthecontrolcases,(2)therearenoothercontrol cases that are exact matches, and (3) for each treatment case the exact match that is chosen from amongtheavailabletwoisdeterminedbythetoss offaircoin.Weimplicitlyassumethatthisisnot the case for this example because, if itwere, then the original dataset would have been balanced in thefirstplaceandnomatchingwouldhavebeenperformed.\n20In other words, the stratification match allows the unbalanced data to be analyzed in a trans- formed fashion (i.e., within strata) where the data are balanced. In particular, the probability dis- tribution of S collapses to a single value and becomes degenerate within each stratum, at which point stratum-level effects are calculated. The distribution of S is then reanimated with stratum- levelweightsthatgenerateaveragetreatmentseffectsweightedbyadistributionofS commontothe treatmentandcontrolcases.\nfor this example are only balanced in expectation. For any single sample among the 50,000 samples in the simulation, imbalance in the observed joint distribution of A and B will almost certainly exist within some of the coarse strata defined by the estimated propensity scores. Any imbalance that resides within these coarse strata then cumulates to the sample level.21 Now, consider the traditional matching algorithms presented in the last section.\nBecause nearest-neighbor, caliper, radius, interval, and kernel matching also utilize a unidimensional distance metric to form matches, they have the same basic features as the weighting estimators for Matching Demonstration 3. For a single dataset, a setof perfect matches onthe estimated propensity score,or any other unidimensional metric, does not guarantee balance on the observed joint distribution of S. In fact, if such optimal balance were possible, then exact matching or a full stratification of the datacouldhavebeen usedinthe firstplace.Althoughthe appliedmatching literature isrepletewithmisleadingclaimsthatpropensity-scorematchingisacompleteremedy forcovariateimbalanceinasinglesample(and,evenmoredistressing,evenforselection onthe unobservables!),the coremethodologicalliterature is clear onthese points (see Rubin 2006).\nThe most recent literature has focused on developing estimators that optimize within-sample balance, typically by more closely tying the estimation steps to bal- ance assessment. Ongoing research on matching methods can be grouped into four non-mutually exclusive streams: new methods for balance assessment, more flexible estimationofthedistancemetric onwhichmatchingis performed,optimizationofthe matching step that follows the estimation of the distance metric, and coarsening the stratification variables before matching is performed.\nEnhancing Routines for Balance Assessment Assessing the balance of the variables on which the cases have been matched can be difficult for two reasons.First, if exact matching or full stratificationare not possible, thenitwillnotingeneralbepossibletoachieveperfectbalance.Yet,therearenoclear standards,noranysensethattheremustbecommonstandardsacrossallapplications, in what features of balance can be traded off against others. Surely it is correct that one should attempt to match the mean values of variables that strongly predict both the treatment and the outcome, as opposed to the mean values of variables that only strongly predict one or the other. But, beyond this obvious point, there is no clear consensus on the relative importance of alternative components of overall balance.\nSecond,theuseofanyhypothesistestofsimilarityforthefeaturesoftwodistributions has two inherent associated dangers: (a) with small samples, a null hypothesis of no difference may be accepted when in fact the data are far from balanced; (b) with very large samples, almost any difference, however small, is likely to be statistically significant,leadingto the possibilitythatnoamountofbalancewouldeverbe deemed 21More formally, the foundational propensity-score literature claims only that the observed data will be balanced after propensity-score matching on average over repeated sampling from the same population. For any single finite sample, either Equation (5.18) or( 5.19) could be true. And, unfor- tunately,exceptforthesimpleststratificationsetsS,itisfarmorelikelythattheobserveddatawill remainunbalancedtosomedegree.\nacceptable. As such, hypothesis tests are generally less useful for assessing balance than measures that focus on differences in magnitude.22 Against the backdrop of these acknowledged challenges, substantial attention has been devoted to the creation of new methods for balance assessment. The favorite measureofbalance,followingthe soleconsensuspositionjustoutlined, isthatbalance should first be assessed based on the standardized difference in sample means, |EN[xi|di=1]−EN[xi|di=0]| (cid:20) , (5.20) 1VarN[xi|di=1]+1VarN[xi|di=0] 2 2 which is calculated twice for every variable X that is matched on: (1) before any matching is performed in order to establish the baseline level of imbalance in the originaldataand(2)acrossthematchedtreatmentandcontrolcasestodeterminehow muchofthe initial imbalancehas beenremovedby matching. Becausethis measureof balance is a scaled absolute difference in the means of each X across treatment and control cases, variable-specific measures can be compared between alternative Xs. In addition, one can take the mean of these standardized differences across all variables that have been matched on, and this single value then summarizes the quality of the balance in means across all variables.\nEquation (5.20) is but the tip of the iceberg among all possible balance measures that one could construct. Most of the matching software in use has improved tremen- douslyinthepastdecade,offeringresearchersmorewaystoexaminehowmuchbalance has been achieved by particular matching routines, based on analogs to standardized differencesforhighermomentsofthedistributionsofthematchingvariables,aswellas indices based on differences between full distributions and between quantile-quantile plots (see Austin 2009a;Hansen and Bowers 2008; Iacus et al. 2011; Imai et al. 2008; Sekhon 2007).\nWith these new tools for balance assessmentin hand, ananalystcanoptimize bal- ance by pursuing two different strategies: reestimating the distance metric on which matching is performed and optimizing the matching algorithm that uses these dis- tances.Insomeofthemostrecentmatchingroutines,thesetwostepsareblended,but for clarity we present them next with some artificial separation.\nReestimating the Distance Metric If the covariates remain substantially imbalanced after a particular matching routine has been performed, the first recourse is to return to the model that estimates the distances between the treatment and control cases. Typically, this involves respecify- ing the propensity-score-estimatingequationprogressivelyin pursuitofimprovements in balance (which, of course, can only be measured after the analyst then passes the reestimated distance metric through to the matching algorithm of choice). The ana- lyst can try adding interaction terms, quadratic terms, and other higher-order terms, 22Forafulldiscussionoftheseissues,andsomewhatdifferentconclusions,seeHansenandBowers (2008),Heller,Rosenbaum,andSmall(2010),Iacusetal.(2011),Imai,King,andStuart(2008),and RubinandThomas(1992, 1996).\nguidedbythebalanceindicesthatarenowonoffer.23 Suchrespecificationcanbelabor intensive and frustrating because alternative respecifications can improve balance in some variables while simultaneously eroding balance in others. In the end, there is no guarantee that through such a respecification loop the analyst will find the specifica- tion that will deliver the best possible balance for the single sample under analysis.\nFor this reason, some of the most recent literature has moved toward more flexible ways of estimating the difference metric, attempting to remove the analyst from the initialspecification,andthenanyresultingrespecificationloop,byharnessingavailable computational power through data mining protocols. We will discuss this literature next.\nAsecond,notmutuallyexclusive,optionistoassesswhetherbalanceimprovement may result from the relaxation or alteration of the parametric assumptions one may have implicitly adopted in estimating the unidimensional distance metric. Estimated propensityscoresareonlyonedistance metricthatcanbe adoptedbefore matchingis performed,andfromitsoriginsthematchingliteraturehasbeenespeciallyenamoredof onealternative,theMahalanobismetric,whichreducesthe datainadifferentfashion, preserving more of the multidimensional content of the matching variables (but in a way that makes verbal description difficult; see the note on page 158). Even for the propensity score, the preference for a default logit specification is rarely justified in any formal sense and rather is typically adopted because the literature suggests that it has worked well enough in the past.\nRecently,multiplearticleshavetestedforthesensitivityofthelogitfunctionalform in simulationstudies andwith realdata (e.g., Harder,Stuart, andAnthony 2010;Hill et al. 2011). Our reading of this literature is that logit specifications have performed moderately well. Still, in some head-to-head competitions, nonparametric estimation has performed comparatively well (e.g., Harder et al. 2010), and these results may portendthat the future of propensity scoreestimation lies in regressiontree modeling (e.g, McCaffrey et al. 2004).24 Such a trajectory may be appealing because a case can be made that the whole businessofassertinga parametricmodel andthensearchingfora balance-maximizing specificationby trying out one after another is the sortof error-pronesausagemaking thatitwouldbebesttoavoid.JasjeetSekhon’spositioniscommon,evenifinfrequently expressed in writing: The literature on matching, particularly the debate over the LaLonde (1986)data,makescleartheneedtofindalgorithmswhichproducematched datasets with high levels of covariate balance. The fact that so many tal- ented researchers over several years failed to produce a propensity score 23Because this type ofrespecification does not involve examiningthe effects of the matching vari- ablesontheoutcomeofinterest,itisnotconsideredoneoftheperniciousformsofdatamining(e.g., wherefalseeffectsareclaimedwhenvariablessneakthroughspecificationscreensasafunctionsolely ofsamplingerror;seeourdiscussionlaterinSection6.6.2).\n24As we willshow in a later demonstration, the maindanger to effect estimates is still unblocked back-door paths that exist because some variables in S have either been left out of the estimating equation or unobserved. This position has been reinforced by a related set of evaluations, this time witha“yokedexperiment,”wheremodeofdataanalysiswasfarlessimportantthattheselectionof the variables with which to balance or adjust the data (see Cook, Steiner, and Pohl 2009; Steiner, Cook,Shadish,andClark2010).\nmodel which had a high degree of covariate balance is a cautionary tale.\nIn situations like these, machine learning can come to the rescue. There is little reason for a human to try all of the multitude of models possible to achieve balance when a computer can do this more systematically and much faster. Even talented and well trained researchersneed aid. (Sekhon 2007:8) From this orientation, Diamond and Sekhon (2013) have proposed a general multi- variate matching method that uses a genetic algorithm to search for the match that achieves the best possible balance. Although their algorithm can be used to carry out matching after the estimation of a propensity score, their technique is more general and can almost entirely remove the analyst from having to make any specification choices other than designating the matching variables. Diamond and Sekhon (2013) show that their matching algorithms provide superior balance in both Monte Carlo simulations and a test with genuine data.25 Imai and Ratkovic (2014) offer a related approach, but it is one that integrates covariate balancing into the estimation of the propensity score.\nOptimizing the Matching Algorithm Suppose that an analyst eschews methods such as those proposed by Diamond and Sekhon (2013) and instead decides to preserve the traditional two-step estimation strategy.Evenwith a distance metric in handfromaniterativefirststep that delivers the bestobservedbalance(ascertainedbyrunningcandidatedistancemetricsthrough the intended matching algorithm), there is no guarantee that the chosen matching algorithm will then optimize the balance that the distance metric may be able to deliver.\nFor example, as we noted above, nearest-neighbor matching without replacement cangeneratesuboptimalmatchingpatternsbecauseofordereffectsthatemergeinthe matching process. Although these problems are not large when the pool of available control cases includes many good matches for each treatment case, they can be sub- stantial for even moderate-sized datasets and/or when the number of control cases is comparatively small. Considerationof these effects has led to the more generalrecog- nitionthatanyserialmatchingofpairsthatpassesoverthetargetcasesonlyoncewill notnecessarilyguaranteethattheoverallaveragedistanceontheunidimensionalmet- ric within matched pairs is minimized. If this averagedistance is not minimized, then there is little chance that the underlying joint distribution of the matching variables will be balanced as completely as the distance metric may allow.\nTo address the weaknesses of nearest-neighbor matching, and other related algo- rithms, Rosenbaum(1989)began a literature on optimal matching that has now fully matured.The keyadvancesareto (1)considerthe closenessofamatchpatternacross all treatment and control cases using a global metric that is a function in all pairwise differencesinthechosenunidimensionaldistancemetricand(2)useacomputationally 25Anaturalend-stateofthisorientationisthefullnonparametricestimationoftheeffects,dispens- ingwiththeintermediateestimationofapropensityscore(seeHill2011; Hilletal.2011).\nrich algorithm to search through possible matching patterns for the one that delivers the smallest averagewithin-pair distance.\nAlthough optimal matching algorithms vary and allow the user to specify many additional constraints on the match patterns searched (see Hansen 2004; Rosenbaum 2002, 2010; Zubizarreta 2012), optimal matching routines are based on the idea of minimizing the average distance between the estimated propensity scores (or some other unidimensional distance metric) for the cases that are matched together. The most recent literature combines optimal pair matching with attempts to achieve near exact matching on the variables deemed most crucial to balance (see Yang, Small, Silber, and Rosenbaum 2012;Rosenbaum 2012; Zubizarreta 2012).\nDirect Coarsening of the Stratification Variables One way to improve balance is to ask less of the matching variables, while invoking a theoretical justification for doing so. Consider a political participation example. If one seeks to estimate the average effect of receiving a college degree on participation (according to some index of participatory acts; see Section 1.3.1, page 16), theory may suggest that one can block all back-door paths by conditioning on five variables: self-reported racial-ethnic identity, gender, state of residence, household income, and marital status.26 For datasets of finite size, it may be difficult to balance these five variables if they are measured in full detail. Accordingly, an analyst might consider conditioningonacoarserepresentationofstateofresidence(reliableredstate,reliable blue state, and swing state), marital status (collapsing widows and widowers with those currently married, but leaving never married and formerly married as separate categories),self-reportedrace(collapsingHispanicethnicityintotwocategories,Cuban and non-Cuban), and household income (using quintiles of household income rather than the full interval scale). One suspects that researchers have been making such decisionsfordecades,usingreasonedtheoreticaljudgmentandbackgroundknowledge for doing so.\nIacus et al. (2012a; see also Iacus and King 2012) have refined this approach into a new matching strategy that they label “coarsened exact matching.” As suggested by the label, the key idea is to perform only exact matching, but after the matching variableshavebeencoarsenedinsomeprincipledfashion.Theysituatethisnewmethod within a broader class of “monotone imbalance bounding” (MIB) matching methods that they propose (see Iacus et al. 2011), all of which have the attractive property of allowing the analyst to avoid setbacks in variable-specific balance when respecifying the routine by altering the specifications for other variables.27 The primary trade-off of using exact matching, even with coarsened data, is that cases will typically be dropped from both the treatment and control groups in the observed data. Such a narrowing of the dataset shifts the target parameter to some- thing narrowerthan the population-basedATT, ATC, andATE thatwe havefocused 26For a recent debate on these issues for this particular example, see the discussionof alternative matching estimates in Henderson and Chatfield (2011), Kam and Palmer (2008, 2011), and Mayer (2011).\n27Becausethematchingisexact, nopropensityscoreisestimated.Rather,heretherespecification involves coarsening thematching variablesinalternative ways, whichmaythen alsoshiftthe target parameter,aswediscussinthemaintext.\noninthisbook.Iacusetal.(2012a:5)implythatthemostcommontargetparameterof coarsened exact matching is the local sample average treatment effect for the treated (localSATT),whichtheydefineas“thetreatmenteffectaveragedoveronlythesubset oftreatedunitsforwhichgoodmatchesexistamongavailablecontrols.”Thisisawell- defined parameter in theory, but in practice it moves with each coarsening decision because these decisions recalibrate what counts as a good match.28 When are such methods likely to lead to improvements in estimation relative to other matching methods? Iacus et al. (2012a:1) write that “the key goal of matching is to prune observationsfromthe data sothatthe remainingdatahavebetter balance betweenthetreatedandcontrolgroup.”Assuch,coarsenedexactmatchingisanatural endpoint forthe datapreprocessingperspective onmatching methods introducedinto the literature by Ho et al. (2007). Overall, coarsened exact matching is likely to work quite well for analysts who can accept that the key goal of matching is to “prune” the data in pursuit of an estimate of a local SATT. And this will often be a very reasonable position when there is no clear correspondence between the data and a well-defined population, such as for non-random collections of individuals who have received a treatment in a biomedical study or for collections of aggregate units that are defined by social processes, such as nation states or congressional districts.\nThis book reflects our tastes for target parameters anchored in well-defined pop- ulations and random samples of them, and our tastes are grounded in the tradition ofrandom-samplesurveyanalysisthatdominates sociologyanddemography.Yet, the overallmatchingliterature,especiallythestreamsthathavealwaysseenmatchingasa type of practical sampling in the service of best estimates of hard-to-estimateaverage treatment effects, is closer to the motivation of coarsened exact matching than is our treatment of matching in this book.29 5.4.3 Which of These Matching Algorithms Works Best? Very little specific guidance exists in the literature on which of these matching algo- rithms works best. We have givensome indication of the relative strengths and weak- nessesinourintroductionofeachtechnique,butthe strengthsandweaknessesofeach will necessarily vary in their relevance for alternative applications.\nWe do not mean to imply that no one advocates for the superiority of particu- lar matching estimators. On the contrary, the strongest advocates for any particular estimators would appear to be those who have had a hand in developing them. Heck- man,Ichimura,andTodd(1997,1998),forexample,arguefortheadvantagesofkernel matching. Diamond and Sekhon (2013)prefer genetic matching for similar situations.\nRosenbaum (2010) defends optimal matching, and now Iacus et al. (2011) advocate for coarsened exact matching. We could continue.\n28Inparticular,ascoarseningproceedsvariablebyvariable,moreofthecasesareexactlymatched, untilthelocalSATTbecomestheSATT.Atthesametime,theabilitytodefendtheexactmatching estimateasunbiasedfortheSATTdeclinesascoarseningispursued.\n29FromtheperspectiveofIacus etal.(2012a), wearewillingtoaccept somemodeldependence in finalestimates,soastopreservethecorrespondencebetweensampleandpopulation-basedquantities.\nOurorientationwillbecomeclearoverthenexttwochapters,whereweendorsemodelingstrategies, suchas weighted regression,that blendmatching methods withmoretraditional formsof regression analysis.\nThesescholarsareverylikelycorrectthatthematchingestimatorstheyhavedevel- oped are the best for the applications they have been developed to model. This does not mean that it is easy to choose from among the alternatives, as we showed in the first edition of this book, and as others have since also documented (e.g., Austin 2009b; Harder et al. 2010; Hill et al. 2011). Because there is no clear guidance on which of these matching estimators is “best,” we offer a fourth hypothetical example to give a sense of how often alternative matching estimators yield appreciably similar estimates.\nMatching Demonstration 4 The debate overthe size ofthe causaleffect ofCatholic schoolingonthe testscoresof highschoolstudentshasspannedmorethanthreedecades(seeSection1.3.2,page22).\nThe example we offer here is basedon Morgan(2001),althoughwe will use simulated data for which we have defined the potential outcomes and treatment assignment patterns so that we can explore (a) the relative performance of alternative matching estimators and (b) the consequences of conditioning on only a subset of the variables in the set of perfect stratification variables S. Similar to Matching Demonstration 3, wewillrepeatthe simulationfor multiple samples,but formany fewerofthemfor the reasons we explain below.\nGeneration of the Data. The simulated datasets that we constructed mimic the real dataset from the National Education Longitudinal Study (NELS) analyzed by Morgan(2001).Forthatapplication,regressionandmatchingestimatorswereusedto estimatethe effectofCatholicschoolingonthe achievementofhighschoolstudents in theUnitedStates.Foroursimulationhere,wegenerateddatasetsof10,000individuals with values for baseline variables that resemble closely the joint distribution of the similar variables in Morgan (2001). The variables for respondents include variables for race, region, urbanicity, whether they have their own bedrooms, whether they live withtwoparents,anordinalvariablefornumberofsiblings,andacontinuousvariable for socioeconomic status. Departing from Morgan (2001), we also created a cognitive skill variable, assumed to reflect innate and acquired skills in unknown proportions, that we assume was measured just prior to the decision of whether or not to enroll in a Catholic school.30 30To be precise, each sample, with a fixed N of 10,000, was generated using a multinomial dis- tribution with parameters calibrated by a 40-cell cross-tabulation of race (five categories of white, Asian, Hispanic, black, and Native American), region (four categories), and urbanicity (two cate- gories),basedonthedata inMorgan(2001). Values forsocioeconomic status werethendrawnfrom normal distributions with means and standard deviations estimated separately for each of the race- by-region-by-urbanicitycellsusingtheNELSdatawithrespecttosocioeconomic status. Thereafter, allothervariablesweregeneratedfromsocioeconomicstatus,usingparametervaluesforsuitableran- dom distributions basedon auxiliaryestimates fromthe NELSdata. Because wereliedonstandard parametric distributions, and did not build interactions between these additional variables into the simulationroutine,thedatafortheseadditionalvariablesaresmootherthantheoriginalNELSdata.\nBut,becausethesamplingcross-tabulationhas40cells,forwhichsocioeconomicstatusisthenparam- eterized differently for each, the simulation is initiated as a mixture distribution for socioeconomic status that is itself rather lumpy, given the pronounced differences insocioeconomic status between racialgroupsandacrossgeographicspaceinthereferentNELSdata.\nWe definedpotentialoutcomesforall10,000individuals ofeachdataset,assuming that the observed outcome of interest is a standardized test taken at the end of high school. For the potential outcome under the control (i.e., a public school education), we generated what-if test scores as y i0=100+2(Asiani)−3(Hispanici)−4(Blacki) −5(NativeAmericani)−1(Urbani)+.5(Northeasti) +.5(NorthCentrali)−.5(Southi)+.02(NumberofSiblingsi) (5.21) +.05(OwnBedroomi)+1(TwoParentHouseholdi) +2(SocioeconomicStatusi)+4(CognitiveSkillsi)+υ i0, where the values for υ0 are independent random draws from a normal distribution i with expectation 0 and standard deviation of 12.31 We then assumedthat the what-if testscoresunder the treatment(i.e., a Catholic school education) would be equal to the outcome under the control plus a boosted outcome under the treatment that is a function in race, region, and cognitive skills (under the assumption, based on the dominant position in the extant literature, that blackandHispanicrespondentsfromthenorth,aswellasallstudentswithhighpreex- isting cognitive skills, are disproportionatelylikely to benefit fromCatholic secondary schooling). Accordingly, we generated the potential outcomes under the treatment as y1=y0+δ(cid:2) +δ(cid:2)(cid:2) , (5.22) i i i i where the values for δ(cid:2) are independent random draws from a normal distribution i with expectation 6 and standard deviation of 0.5. To this common but stochastic individual-leveltreatmenteffect,weaddedasecondcomponentwithvaluesforδ(cid:2)(cid:2) that i vary systematically over individuals. These values were constructed as draws from a normal distribution with expectation equal to 0+1(Hispanici×Northeasti)+.5(Hispanici×NorthCentrali) +1.5(Blacki×Northeasti)+.75(Blacki×NorthCentrali) (5.23) +.5(CognitiveSkillsi) and with a standard deviation of 2, after which we subtracted the mean of all drawn values in the simulated sample (in order to center the draws for δ(cid:2)(cid:2) on 0). Taken i together, the values of δ(cid:2) and δ(cid:2)(cid:2) for each individual represent two additive compo- i i nents of their individual-level treatment effects, as is clear from a rearrangement of Equation(5.22),withreferencetothedefinitionoftheindividual-leveltreatmenteffect in Equation (2.1), as δi=y i1−y i0=δ i(cid:2)+δ i(cid:2)(cid:2).\nWe then defined the probability of attending a Catholic school using a logistic distribution, exp(Siφ) Pr[Di=1|Si]= , (5.24) 1+exp(Siφ) 31Across simulated datasets, the standard deviations of socioeconomic status and cognitive skills variedbutweretypicallycloseto1.\nwhere Siφ=−4.6−.69(Asiani)+.23(Hispanici)−.76(Blacki) −.46(NativeAmericani)+2.7(Urbani)+1.5(Northeasti) +1.3(NorthCentrali)+.35(Southi)−.02(NumberofSiblingsi) −.018(OwnBedroomi)+.31(TwoParentHouseholdi) +.39(SocioeconomicStatusi)+.33(CognitiveSkillsi) −.032(SocioeconomicStatus2)−.32(CognitiveSkills2) i i (5.25) −.084(SocioeconomicStatusi×CognitiveSkillsi) −.37(TwoParentHouseholdi×Blacki) +1.6(Northeasti×Blacki)−.38(NorthCentrali×Blacki) +.72(Southi×Blacki)+.23(TwoParentHouseholdi×Hispanic) −.74(Northeasti×Hispanici)−1.3(NorthCentrali×Hispanici) −1.3(Southi×Hispanici)+.25δ i(cid:2)(cid:2) .\nThe specification for Equation (5.25) is based on the results of Morgan (2001), along with an additional assumed self-selection dynamic in which individuals are slightly more likely to select the treatment as a function of the relative size of the systematic component of the individual-specific shock to their treatment effect, δ(cid:2)(cid:2).\ni The probabilities defined by Equation (5.24) were then specified as the parameter for random draws from a binomial distribution, generating a treatment variable di for each simulated student. Finally, following Equation (2.2), simulated students in Catholic schools were given observed values for yi equal to their simulated y i1, while all others were given an observed values for yi equal to their simulated y i0.\nThe ATT as the Target Parameter. The presence of the self-selection term, δ(cid:2)(cid:2), i inbothEquation(5.22)andEquation(5.25)createsanearlyinsurmountablechallenge fortheestimationofthe ATE.We willconsidercasessuchasthisoneindetailinlater chapters, but for now we will explain briefly why the only target parameter that can be estimated with any degree of confidence is the ATT.\nConsider the directed graph presented in Figure 5.2, and consider why this graph indicates that the ATE cannotbe estimated with the availabledata. Equations (5.21) and (5.25) imply that all of variables whose names are written out in this figure are mutual causes of both D and Y. All of these variables are on the right-hand sides of both of these equations, and the nonparametric nature of the directed graph also represents the variety of higher-order and cross-productterms embedded in Equation (5.25). If we observe and then condition on all of these variables, we will be able to block many back-door paths that would otherwise confound the causal effect of D on Y. Unfortunately, there is an additional back-door path, represented by the bidi- rectededgeD(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)Y,thatwillremainunblockedaftersuchconditioning.Thisisthe noncausalback-doorassociationthatisgeneratedbythe presenceofδ(cid:2)(cid:2) inbothEqua- i tion(5.22)andEquation(5.25).Aswithmanyreal-worldapplications,thissimulation assumes that individuals (in this case students, although surely informed by parents andothers)select fromamongalternativetreatments basedonaccurateexpectations, Race, Urbancity, Region, Number of Siblings, Have Own Cognitive Bedroom, Have Two Parents, Skills Socioeconomic Status D Y Figure5.2 The directed graph implied by the underlying data generation model for Matching Demonstration 4.\nunavailableasmeasurestoresearchers,oftheirlikelygainsfromalternativetreatment regimes. Accordingly, prospective Catholic school students with comparatively high values of δ(cid:2)(cid:2) are more likely to be in Catholic schools, according to Equation (5.25), i and are also more likely to benefit from Catholic schooling, according to Equations (5.22)and(5.23).This patternisthe mostcommontype ofselectiononthe unobserv- ables in the social sciences.\nThe directed graph reveals clearly why the ATE is not identified, and yet it does not at all suggest that the ATT is, in fact, still identified in cases such as this one.\nHere,itishelpful toconsultthe equationsagain.Thesetofvariablesthatwasusedto generate y0 in Equation (5.21) does not include the individual-specific shock, δ(cid:2)(cid:2). We i i thereforedo notneedto observeδ(cid:2)(cid:2) in orderestimate reasonablecounterfactualvalues i fory0 amongsimulatedstudentsenrolledinCatholicschools.Asdiscussedearlier–see i Equations (2.16) and (5.2) – these are the only counterfactual values that are needed in order to effectively estimate the ATT.32 The problem for the ATE is that the ATC is not identified. Because of the way in which the generation of y i1 and di are entangled by their joint dependence on δ i(cid:2)(cid:2), we cannotestimate reasonablecounterfactualvalues fory1 amongthose who areenrolled i in public schools. Net of all of the other observed variables, the students most likely to benefit from Catholic schooling are in Catholic schools, and they therefore have values for yi=y i1 that are too positive, even net of the observables, to enable effective estimation of the counterfactual values of y1 for public school students.\ni (Although the directed graphs we have introduced so far do not make the identifi- cation of the ATT particularly clear when the ATE is not also identified, in Chapter 8 we will offer elaborated directed graphs, which use latent classes and variables for individuals’ own expectations, to communicate results such as these. Still, it is often the case that targeted identification results are best conveyed by equations, whether 32Notice that we did not specify self-selection on the causal effect in both directions. If we had, the ATT would not be identified either. We have builtthis simulationassuming that public schools serveasabaselinestate,outofwhichstudentsmayexitinordertocaptureadditionallearninggains thatmaybeavailabletothemfromCatholicschooling.Themorecomplicatedscenariowouldbeone where Equation 5.21 alsoincluded δ(cid:3)(cid:3) but with a negative coefficient (such that, net of observables, i those who areleast likely to do well inCatholic schooling are those most likely to do well inpublic schools).\ntheseareequationsfurnishedbythepotentialoutcomemodelorbasedonthenonpara- metric structural equations that underlie all directed graphs. We will consider these issues in substantial detail in the next part of the book.) Methods for Treatment Effect Estimation. In Tables 5.6 and 5.7, we offer 19 separate matching estimates of the ATT, where we match the simulated controlcases to the simulated treatment cases. These estimates are produced by routines written for R and Stata by others (see the notes to Table 5.6 for citations to the software), and the row labels we have chosen for the tables map onto the terminology that we used to present the matching estimators in Sections 5.4.1 and 5.4.2.\nWe estimate all matching estimators under two basic scenarios. First, we offer a set of estimates based on an incomplete specification of treatment assignment, where we omit the cognitive skills variable. In addition, for routines that utilize estimated propensityscores,wealsoomittedthehigher-orderandcross-productinteractionterms presentinEquation(5.25).Theexclusionofthecognitiveskillsvariableisparticularly important because it has correlations of 0.4 with the outcome variable and 0.2 with the treatment variable, on average across the simulated datasets. For the second sce- nario, which we label the complete specification scenario, we included the cognitive skills variable, and, for those routines that utilize propensity scores, the higher-order andcross-productinteractiontermspresentinEquation(5.25).Bothscenarioslackan adjustment for the self-selection dynamic, in which individuals select into the treat- ment partly as a function of an accurate expectation of their own individual-specific treatment effect. In this sense, the complete specification is only complete enough to deliveraconsistentandasymptoticallyunbiasedestimateoftheATT,notofthe ATC or the ATE as explained above.\nRegardingthespecificsettingsforthealternativematchingestimators,welistsome relevant information in the row labels for each (i.e., caliper size, kernel specification).\nBeyond these settings, we generally accepted the default options for all estimators as specified in the relevant software, on the argument that this “horse race” between estimators ought to be fair. As we will note below, each of the estimates we offer could be tailored to this specific application more so than for the analysis that we present, and perhaps some estimators could therefore get closer on average to the target parameter and be shown to outperform all others. We have made the datasets available,onthebook’sWebsite(www.cambridge.org/9781107065079),foranyreaders whowishtotry.Weencourageinstructorsusingthisbooktosharethesedatasetswith theirstudentsandtousethemtotryoutadditionalmatchingestimatorsbeyondthose we have presented here, including any matching routines developed after publication of this edition of the book.\nWe will not provideestimated standarderrorsin the tables, althoughwe will indi- cate their range in the text. As we describe following the demonstration (see Section 5.5), there is no common methodology that allows the estimation of standard errors in analogous ways across all estimators, which makes informative comparisons across estimators difficult (in terms of relative efficiency or expected mean-squared error).\nNonetheless, the literature agrees that estimators that use more of the data, such as interval matching and kernel matching, have smaller estimated standard errors than Table 5.6 Matching Estimates of the ATT, Catholic Schooling on Achievement for One Simulated Dataset Specification of treatment assignment variables: Numberof treatment cases retained for the Method Incomplete Complete estimate of the ATT Nearest-neighbor match: 1 without replacement (ps2) 7.37 7.03 1052 1 without replacement (MI) 7.55 7.09 1052 1 with replacement (ps2/psc) 7.77 7.17 1052 1 with replacement (MI) 7.96 7.38 1052 1 with replacement and caliper = .05 SD (ps2) 7.77 7.15 1051 1 with replacement and caliper = .05 SD (MI) 7.27 6.43 1051 5 with replacement (ps2) 7.51 6.42 1052 5 with replacement (MI) 8.06 7.29 1052 5 with replacement and caliper = .05 SD (ps2) 7.55 6.37 1051 5 with replacement and caliper = .05 SD (MI) 8.00 7.12 1051 Radius match: Caliper = .05 SD (ps2) 7.61 6.36 1051 Caliper = .05 SD (psc) 8.23 7.84 1051 Intervalmatch: 10 fixed blocks (MI) 8.71 8.71 1052 Variable blocks (ps2) 7.50 6.60 1052 Kernel match: Epanechnikov(ps2/psc) 7.57 6.58 1052 Gaussian (ps2/psc) 7.70 6.82 1052 Optimal match (MI-opt) 6.84 6.78 1052 Genetic match (MI-gen) 7.80 6.46 1052 Coarsened exact match (cem) 7.54 6.59 1015/973 Notes:Thesoftwareutilizedisdenoted “ps2”forLeuvenandSianesi(2012), “MI”for Hoetal.(2011), “psc”forBeckerandIchino(2005), “opt”forHansen,Fredrickson,andBuckner (2013), “gen”forSekhon(2013), and“cem”forIacus etal.(2012b).\nthosethatdiscardmoreofthedata,suchasnearest-neighbormatching.Thelatterhave a claim to lower bias, since bad matches are thrown away, and yet also have greater sampling variability. In this sense, comparisons of matching estimators represent a classic trade-off between bias and variance.\nResults. Table 5.6 presents matching estimates of the ATT for a single dataset, as wouldbethecaseinnearlyallapplicationsofthemethodologypresentedinthisbook.\nHowever, one important difference from the typical scenario is that we know for this simulated dataset that the true ATT is equal to 6.92. And, even though we will not estimate them here, we also know that the true ATE and ATC are equal to 6.00 and 5.90,respectively.Byconstruction,theATTislargerthantheATCbecausethosewho aremost likely to benefit from Catholic schoolingare more likely to enrollin Catholic schooling, both as a function of observed variables that lie on the back-door paths in Figure 5.2 and because of the self-selection on the individual-level treatment effect itself.\nEstimates based on the incomplete specification are reported in the first column ofTable 5.6. As expected, the estimates aregenerallymuch largerthan the true value of the ATT, which is 6.92 (although the optimal match estimate yields a surprisingly close value of 6.84 for this single dataset). Most of the positive bias of these estimates is due to the mistaken exclusion of the variable for cognitive skills from the model for treatment assignment.\nEstimates based on the complete specification are then reported in the second column of Table 5.6. On the whole, this second set of estimates is considerably closer to the true ATT, oscillating on either side of the true value of 6.92 (i.e., 10 have negativebiasforthe ATT,and9havepositivebiasforthe ATT). Thestandarderrors fortheseestimates,whichallsoftwareroutinesprovide,fallwithinarangebetween.43 and .66, although using different estimation techniques. The point values reported in the second column are consistent with what one would expect for variation produced by sampling error alone. However, the variation across the point estimates does not arise from sampling error, since all estimators use the same sample, but rather from the different ways in which the estimators use the data. As such, it is unclear how comforting is the claim that this level of variation is consistent with what would be produced by sampling error alone.\nNotice also that the third column reports the number of treatment cases retained for the estimate of the ATT. For estimators that do not impose a nearness crite- rion (i.e., a caliper or radius), all 1,052 treatment cases were retained for the esti- mate. Even when quite narrow calipers are selected, only one treatment case is dis- carded for the relevant estimates for this single dataset. This pattern indicates that these data are therefore well suited for matching estimators that force the utiliza- tion of all treatment cases, such as traditional nearest-neighbor matching without a caliper, because there are many suitable control cases on the support of the match- ing variables for the treatment cases. This will not always be the case for datasets with more extreme patterns of treatment assignment and/or a more limited sample size.\nMuch more could be said about each pair of estimates, but we will note only a few additionalpatterns.First, insome casessoftwareprogramsthat utilized the same routineyieldedestimatesthatwerequitedifferent.Thereasonsforthesedifferencesare notobvious,buttheytendtooccurforestimatorsthatprocessthematchingalgorithm in ways that could vary or that utilize difference calculations across propensity scores within calipers that can be sensitive to rounding error. Second, although it may be tempting to conclude that the optimal match is superior to all others, we will show Table 5.7 Bias for Matching Estimates of the ATT, Catholic Schooling on Achievement Across 10 Simulated Datasets Specification of treatment assignment variables: Incompletespecification Complete specification Method Min, Max Average Min, Max Average Nearest-neighbor match: 1 without replacement (ps2) −.37, 2.17 .79 −1.17, 0.68 −.04 1 without replacement (MI) −.23, 2.08 .75 −1.11, 0.56 .00 1 with replacement (ps2/psc) −.35, 2.00 .77 −1.18, 0.40 −.13 1 with replacement (MI) −.25, 2.22 .95 −.70, 0.84 .19 1 with replacement and caliper = .05 SD (ps2) −.32, 2.04 .78 −1.21, 0.35 −.13 1 with replacement and caliper = .05 SD (MI) −.16, 1.89 .98 −.99, 1.16 .07 5 with replacement (ps2) −.01, 1.77 .79 −.79, 0.83 −.04 5 with replacement (MI) .43, 2.29 1.17 −.44, 1.34 .50 5 with replacement and caliper = .05 SD (ps2) −.01, 1.71 .77 −.81, 0.75 −.04 5 with replacement and caliper = .05 SD (MI) .15, 2.43 1.19 −.49, 1.18 .39 Radiusmatch: Caliper = .05 SD (ps2) −.18, 2.07 .81 −.82, 1.02 −.08 Caliper = .05 SD (psc) .36, 2.42 1.17 .10, 2.03 .89 Intervalmatch: 10 fixed blocks (MI) .84, 3.02 1.68 .84, 3.02 1.68 Variable blocks (ps2) .03, 2.18 .88 −.85, 1.12 −.03 Kernelmatch: Epanechnikov(ps2/psc) .08, 2.25 .89 −.76, 1.25 .01 Gaussian (ps2/psc) .08, 2.34 1.00 −.59, 1.44 .19 Optimal match (MI-opt) .45, 2.89 1.28 −.36, 1.53 .54 Genetic match (MI-gen) .09, 1.66 .96 −.89, 1.55 .23 Coarsened exact match (cem) .58, 2.66 1.28 −.43, 1.59 .35 Notes:seenotes toTable 5.6forsoftwaredetails.\nbelow that this is partly a chance result for this single sample (even though optimal matching is designed to outperform traditional estimators and can be expected to do so). Third, the interval match with fixed blocks does not improve for the complete specification because the inclusion of the variable for cognitive skills does not have consequencesfortheorderingofthedata,andhenceitdoesnotmovecasesinbetween the 10 intervals that are used. For the alternative interval matching estimator that uses variable blocks, selected in order to maximize within-interval mean balance on the propensity score, the utilization of the variable for cognitive skills does improve the estimate.\nThe only estimates that require more detailed explanation are those based on coarsenedexact matching. For this estimator,we could have coarsenedthe data more in order to retain all treatment cases. Or we could have coarsened the data less and retained fewer cases. We chose a strategy that kept most of the treatment cases so that the assumed local SATT is not too far from the target parameter for all other matching estimators, the true ATT.\nIn particular, for the incomplete specification, we made coarsening decisions that, collectively, defined 868 strata that contained either treatment or control cases, of which244hadbothtreatmentandcontrolcasespresent.Overall,37of1,052treatment cases fell into strata without any control cases and were therefore discarded from the analysis. The specific coarsening decisions were to coarsen the variable for number of siblings into three categories (0, 1 or 2, and 3 or more) and socioeconomic status into five categories as equal-sized quintiles. No other variables were coarsened.\nFor the complete specification, we then included the variable for cognitive skills, whichwe alsocoarsenedinto quintiles.This additionalvariableincreasedto 1,540the number of strata that contained either treatment or control cases, of which 316 had both treatment and control cases present. Because of the increasingly specific strata, 79 treatment cases fell into strata without any control cases and were discarded from theanalysis.Intheend,thelocalSATT forthe completespecificationisestimatedfor 973 of the 1,052 treatment cases (or 92.5 percent). It is unclear, therefore, whether it is sensible to compare the resulting estimate to the true ATT for this example, as we dohere.Yet,itcouldalsobe unfairtocompareittoitsownimpliedtargetparameter, the true local SATT, without similarly doing so for caliper and radius estimators, for example, that also discard some treatment cases.\nIn sum, when we consider a single sample, and when we know the true value for the ATT, it is clear that omitting a crucial variable, such as the variable for cognitive skills in this application, will prevent matching estimators from effectively estimating the ATT. When the complete specification is adopted, matching appears to perform quitewell,althoughtheparticularmatchingestimatorsgivepointvalueestimatesthat oscillate around the true target parameter.\nHowgeneralaretheseresults?Inonesense,theyareverygeneral.Weknowfroma richexistingliteraturethatmatchingestimatorscanbeaneffectivetoolforestimating causaleffectsinthesesituations.Andwecould,therefore,withsuitablecomputational power and investigator patience, perform a Monte Carlo version of this simulation across50,000simulateddatasets,asforMatchingDemonstration3.33 Alessambitious multiple-sample simulation will suffice to reveal the general results.\nTable5.7presentsresultsfrom10simulatedsamples,ofwhichonewasusedforthe estimates reported already in Table 5.6.34 Across all 10 samples, the true values for the ATT vary only slightly, from a low of 6.87 to a high of 6.98. Rather than present 33Doing so for 50,000 datasets would require substantial time, since some estimators, such as the geneticmatchingestimatorofSekhon(2013),takefarmoretimetoestimatethanthesimpleweighted averagesanalyzedforMatchingDemonstration3.\n34Infact, for the estimates reported inTable 5.6, wechose the samplefromamong these 10 that, onaverageoverallestimators,deliveredestimates thatwereclosesttotheirrespectivetrueATT.In thespecificpointestimatesoftheATTforall10samples(i.e.,anadditional9versions ofTable 5.6),we instead offerthe minimum, maximum,and averagebias acrossall10 estimates of the true ATT for each matching estimator.\nAs shown in the first two columns, for the incomplete specification the average bias of all estimators was positive and substantial, from a low of .75 to a high of 1.68.\nMoreover, the minimum amount of bias was positive for many estimators, and the maximum amount of bias was never less than 1.66. When the complete specification was used, the average amount of bias was considerably smaller, and the minima and maxima for each estimator were typically negative and positive, respectively.\nIfweweretorepeatthisexercisefor50,000simulateddatasets,wewouldhavemore confidence that the average values for the bias inform us of how well these matching estimators perform for this particular pattern of simulated data. We do not do so, in part, because this could give a misleading impression that one of these estimators should be more generally preferred, even for applications very much unlike this one.\nInstead,wehopetohaveconvincedthereaderofamorebasicpoint.Evenforexamples suchasthis one,wherethis is considerableoverlapbetweenthe treatmentandcontrol groups, such that even the traditional estimators that have been around for decades can be used with some confidence, the specific point values generated by matching estimators can differ considerably. It is possible that some of the variability of these estimates canbe reducedby routine-specificrespecificationsofthe matching variables afterassessingthe achievedbalanceofeachestimator.Itisunlikelythatallvariability can be eliminated, and therefore researchers who wish to use a matching strategy should make sure that their conclusions hold across a reasonable range of matching estimators.\nWe have demonstrated three general points with this example. First, the sort of self-selection dynamic built into this example – in which individuals choose Catholic schooling as a function of their expected gains from Catholic schooling – does not prevent one from consistently estimating the ATT (because Assumption 2-S may still hold),eventhoughitmakesestimationofboththeATCandATEimpossible(because Assumption 1-S does not hold). If all variables in S other than anticipation of the individual-level causal effects are observed, then the ATT can be estimated consis- tently.35 Second, even when the ATT is formally identified by conditioning on S while maintaining Assumption 2-S, matching estimators cannot compensate for a decision to mistakenly exclude an observedcovariate in S. Failure to condition on the variable contrast,Table5.7showsthatitwilloftenbethecasethatmatchingestimatorsperformsubstantially worse.\n35At the same time, this example shows that even our definition of a “perfect stratification” is somewhat underspecified. According to the definition stated above, if self-selection on the causal effectoccurs,aperfectstratificationisavailableonlyifvariablesthataccuratelymeasureanticipation of the causal effect for each individual are also available and duly included in S. Thus, perhaps it would be preferable to refer to three types of perfect stratification: ATC-perfect stratification for whichAssumption1-Sisvalid(whichenablesestimationoftheATC),ATT-perfectstratificationfor which Assumption 2-S is valid (which enables estimation of the average treatment for the treated), and our unconditionally perfect stratification for which both are valid, enabling estimation of the ATT,ATC,andATE.\nfor cognitive skills in this example would invalidate Assumption 2-S (in addition to Assumption 1-S that is already invalidated by the self-section on the causal effect itself). The matching routines will still attempt balance the matching variables, but theresultingestimateswillremaininconsistentandbiasedfortheATT,ATC,andthe ATE.\nThird, in cases such as this one, where a researcherattempts to estimate the ATT andwherethereisalargereservoirofsuitablecontrolcasestomatchtothetreatment cases, many alternative specific matching estimators can be used. They will all tend to offer slightly different point estimates, and there is no clear guidance for which ones should be preferred. We therefore recommend that, in these situations, many point estimates be offered and that conclusions not be selected that depend on only a subset of all permissible estimates. However, for applications that depart from the featuresofthisexample,someofthemorerecentlydevelopedmatchingestimatorsmay have a clear advantage, particularly optimal matching when the sample size is small, geneticmatchingwhenthereisverylittlepriorresearchtohelpestablishaspecification for a propensity score, and coarsened exact matching when one wishes to eliminate incomparable cases in a principled way and when one is comfortable narrowing the analysis to a subset of the treatment cases.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#remaining-practical-issues-in-matching-analysis",
    "href": "extracted/Counterfactuals and Causal Inference.html#remaining-practical-issues-in-matching-analysis",
    "title": "Counterfaturals and Causal Inference",
    "section": "5.5 Remaining Practical Issues in Matching Analysis",
    "text": "5.5 Remaining Practical Issues in Matching Analysis\nIn this section, we discuss the remaining practical issues that analysts who consider\nusing matching estimators must confront. We first discuss the possibility of using matching to estimate parameters when the ATE, ATT, and ATC are not identified.\nWe then consider the literature on when, why, and how an analyst may want to estimate effects only after restricting the analysis to the rangeof common support for the matching variables. We then discuss what is known about the sampling variance of alternativematching estimators,and we conclude with some guidance on matching estimators for causal variables with more than two values.\n5.5.1 Matching When Treatment Assignment Is Nonignorable WhatifneitherAssumption1-SnorAssumption2-Sisvalidbecauseweobserveonlya subsetofthe variablesinS,whichwe willnowdenote byX?We canstillmatchon X usingthetechniquesjustsummarized,aswedidfortheincompletespecificationinthe hypotheticalexampleforMatchingDemonstration4.Inthatexample,weshowedthat if the complete specification is available, one should of course use it. Yet, in practice this will often not be possible, and yet matching can still be used as a data analysis technique with substantial payoff, assuming that the results are properly interpreted.\nConsider, for example, the paper of Sekhon (2004), in which a matching algo- rithmis used to balancevarious predictorsofvotingat the county levelinanattempt to determine whether or not John Kerry lost votes in the 2004 presidential election campaign because optical scan voting machines were used instead of direct electronic voting machines in many counties (see Section 1.3.2, page 26, on voting technology effects in Florida for the 2000 election). Sekhon shows that it is unlikely that voting technologycausedJohnKerrytolosevotes.Inhisanalysis,ignorabilityisnotasserted in strict form, as it is quite clear that unobserved features of the counties may well have been related to both the distribution of votes and voting technology decisions.\nNonetheless,theanalysisisconvincingbecausethepredictorsoftreatmentassignment are quite rich, and Sekhon is cautious in his interpretations.\nWhen in this position, however, it is important to concentrate on estimating only one type of treatment effect (usually the ATT, although perhaps the ATE). Because a crucial step must be added to the project – assessing the level of inconsistency and bias that may arise from possible nonignorability of treatment – focusing on a very specific treatment effect of primary interest helps to ground a discussion of an estimate’s limitations. Then, after using one of the matching estimators of the last section, one should use the data to minimize bias in the estimates and, if possible, proceedthereaftertoasensitivityanalysis(whichwewill discusslaterinChapter12).\nWewillreturntothisissueindepthinChapter7,wherewewillpresenttechniquesthat combine matching and regressionestimators, often for examples wherein assumptions of ignorability are knowingly suspect.\n5.5.2 Matching Only on the Region of Common Support Treatment cases may have no counterparts among the control cases in the observed data because they are saidto be “off the support” of S, and vice versa for the control cases.36 Typically, researchers will notice this situation when the distributions of the estimated propensity scores for the treatment and control cases have substantially different minimum and maximum values, and that is the situation we will consider in this section.\nIn some cases, the lack of observed overlap in estimated propensity scores may reflectgenericsparsenessbecauseunusualtreatmentandcontrolcaseswilloftenfailto besampledforfinitedatasets.Inothercases,thereisgoodreasontobelievethatsome ofthelackofobservedoverlapmayhaveemergedfromsystematicsources,oftenrelated tothechoicebehaviorofindividuals.Inthesesituations,itisnotasparsenessproblem.\nInstead, a more fundamental mismatch between the observed treatment and control cases exists in the population, as in our earlier hypothetical example in Matching Demonstration 2. In still other situations, unlike those that we focus on in this book, the data exist for a collection of units that is either not drawn at random from a well-defined population (as in many biomedical examples) or where the population is not well-defined (as in many social science examples when administrative units, or other socially defined units, are analyzed). In these cases, the treatment and control cases may be off of the support of each other, and matching is invoked precisely to takeaccountofthispredicament,usingavariantofthedatapreprocessingperspective proposedby Ho et al. (2007)to define a useful comparisonthat canmovethe relevant literature forward.\n36Support is often given slightly different definitions depending on the context, although most definitionsareconsistentwithastatement suchasthisone:Supportistheunionofallintervalsofa probabilitydistributionthathavetruenonzeroprobabilitymass.\nWhen in any of these situations, applied researcherswho use matching techniques to estimate treatment effects may choose to estimate narrower treatment effects. For example,analysismaybeconfinedonlytotreatmentcaseswhoseestimatedpropensity scores fall between the minimum and maximum estimated propensity scores of the control cases. Resulting estimates are then interpreted as estimates of a treatment effectthatisnarrowereventhantheATTandistypicallylabeledthecommon-support ATT (see Heckman, Ichimura, and Todd 1997, 1998; see also Crump, Hotz, Imbens, and Mitnik 2009). Although using the estimated propensity score to find the region of overlap may not capture all dimensions of the common support (as there may be interiorspacesinthejointdistributiondefinedbythe matchingvariables),subsequent matching is then expected to finish the job of eliminating incomparable cases.\nSometimesmatchingontheregionofcommonsupporthelpstoclarifyandsharpen the contribution of a study. Even if imposing a common-support condition results in throwing awaysome of the treatment cases,this can be considered an important sub- stantive finding for some applications. Any resulting estimate is a conditional average treatment effect that is informative only about those in the treatment and control groupswhoaresubstantiallyequivalentwithrespecttoobservedtreatmentassignment andselectionvariables.Insomeapplications,thisispreciselytheestimateneeded,such as when evaluating whether a programshould be expanded in size in order to accom- modatemoretreatmentcasesbutwithoutchangingeligibilitycriteria.(Wewilldiscuss these marginal treatment effects in Chapter 9.) Theliteratureonthesecommon-supportstrategiesisnowwelldeveloped.Heckman, Ichimura, and Todd (1998; see also Smith and Todd 2005) recommend trimming the region of common support to eliminate cases in regions of the common support with extremelylowdensity(andnotjustwithrespecttotheestimatedpropensityscorebut for the full distribution of the matching variables). This involvesselecting a minimum density (labeled the “trimming level”) that is greater than zero. Heckman and his colleagues have found that estimates are sensitive to the level of trimming in small samples, with greater bias when the trimming level is lower. More recently, Crump et al. (2009) have developed optimal weighting estimators that are more general but designedtoachievethesamegoals.Coarsenedexactmatchingcanbeseenasmotivated bythesamebasicstrategy,guideddirectlybythematchingvariablesratherthantheir unidimensional reduction in the estimated propensity score. The common support ATT may coincide with the local SATT of coarsened exact matching, but the latter will always be at least as narrow if the underlying matching variables are the same at the outset before any coarsening is applied.\n5.5.3 The Expected Variance of Matching Estimates Aftercomputingamatchingestimateofsomeform,mostresearchersnaturallydesirea measureofitsexpectedvariabilityacrosssamplesofthesamesizefromthesamepopu- lation,eithertoconducthypothesistestsortoofferaninformedposteriordistribution forthecausaleffectthatcanguidesubsequentresearch.37 Wedidnot,however,report 37There is also a related set of randomization inference techniques, built up from consideration ofallofthepossiblepermutations oftreatment assignmentpatterns that couldtheoreticallyemerge fromalternativeenactmentsofthesametreatmentassignmentroutine(seeRosenbaum2002).These standarderrorsfor the treatmenteffect estimates reportedin Tables 5.6 or5.7 for the hypothetical example in Matching Demonstration 4 (although we did indicate in the text the range of the estimates that are provided by the relevant software routines).\nAlthoughmostoftheavailablesoftwareroutinesprovideestimatedstandarderrors, many rely on different methodologies for calculating them. Given their lack of agree- ment, we caution against too strong of a reliance on the standard error estimates producedbyanyonesoftwareroutine,atleastatpresent.Muchremainstobe worked out before commonly accepted standards for calculating standard errors for all types of matching estimators are available (see Abadie and Imbens 2009, 2012; Hill and Reiter2006;ImbensandWooldridge2009).Fornow,ouradviceistoreportarangeof standarderrorsproduced by alternativesoftwareroutines for correspondingmatching estimates.38 We recommend caution for the following reasons. In some simple cases, there is widespread agreementon how to properly estimate standard errorsfor matching esti- mators. For example, if a perfect stratificationof the data can be found, the data can be analyzed as if they are a stratified random sample with the treatment randomly assignedwithin eachstratum.In this case,the varianceestimates fromstratifiedsam- plingapply.Butrarelyisaperfectstratificationavailableinpracticewithoutsubstan- tial sparseness in the data at hand. Once stratification is performed with reference to an estimated propensity score, the independence that is assumed within strata for standard error estimates from stratified sampling methodology is no longer present.\nAnd, if one adopts a Bayesian perspective, the model uncertainty of the propensity- score-estimatingequationmustberepresentedintheposterior(seeAbadieandImbens 2009; An 2010).\nEven so, there is now also widespread agreement that convergence results from nonparametricstatistics canbe usedtojustify standarderrorestimates forlargesam- ples. A variety of scholarshavebegun to workout alternative methods for calculating such asymptotic standard errors for matching estimators, after first rewriting match- ing estimators as forms of nonparametric regression (see Abadie and Imbens 2006, 2011; Hahn 1998; Heckman, Ichimura, and Todd 1998; Hirano et al. 2003; Imbens 2004;Imbens andWooldridge2009).Forthese large-sampleapproaches,however,it is permutationideasgenerateformulasforevaluatingspecificnullhypotheses,which,fromourperspec- tive,arelargelyuncontroversial.Theyareespeciallyreasonablewhentheanalysthasdeepknowledge of a relatively simpletreatment assignment regime and has reason to believe that treatment effects areconstantinthepopulation.AlthoughRosenbaumprovideslarge-sampleapproximationsforthese permutation-based tests, the connections to the recent econometrics literature that draws on non- parametricconvergence resultshavenotyetbeenestablished.\n38Many matching software routines allow one to calculate bootstrapped standard errors. This is presumablybecausetheseeasy-to-implementmethodswereoncethoughttoprovideageneralframe- workforestimatingthestandarderrorsofalternativematchingestimatorsandhencewereafairand quite general way to compare the relative efficiency of alternative matching estimators (see Tu and Zhou2002).Unfortunately,AbadieandImbens(2008)showthatconventionalbootstrappingwillnot workfornearestneighbormatchingandrelatedestimators.Inessence,thesematchingestimatorsare atypeoftwo-stagesamplinginwhichasetoftreatmentandcontrolcasesaresampledfirstandthen the possible matching cases are subsampled again based on nearness to the target cases. Yet, there istoomuchdependence between thefirstandsecondsamplingstages inthesingleobservedsample, such that resampling within the first stage using the observed sample of target cases does not then generatesuitablevariationamongmatchingcasesinthesecondstage.\ngenerallyassumed that matching is performed directly with regardto the variables in S, and the standard errors are appropriate only for large samples in which sparseness is vanishing. Accordingly, the whole idea of using propensity scores to solve rampant sparsenessproblemsisalmostentirelydispensedwith,andestimatedpropensityscores thenservemerelytocleanupwhateverchancevariabilityinthedistributionofSacross treatment and control cases remains in a finite sample.\nGiventhattheliteratureonmethodstoestimatestandarderrorsformatchingesti- mates is still developing, and that software developments lag the literature, it seems prudent to (1) report the standard errors offered by the relevant software routines in sufficient detail so that a reader can understand the method adopted but (2) avoid drawingconclusionsthatdepend onacceptinganyoneparticularmethodforcalculat- ing standard errors.\n5.5.4 Matching Estimators for Many-Valued Causes Given the prevalence of studies of many-valued causes, it is somewhat odd to place thissectionunderthe moregeneralheadingofpracticalissues.Butthis isappropriate because most of the complications of estimating many-valued treatment effects are essentially practical, even though very challenging in some cases.\nRecall the setup for many-valued causes from Section 2.9, where we have a set of J treatment states, a set of J causal exposure dummy variables, {Dj}J , and a j=1 correspondingsetofJ potentialoutcomerandomvariables,{YDj}J .Thetreatment j=1 received by each individual is Dj(cid:2), and the outcome variable for individual i, yi, is then equal to yDj(cid:2) . For j(cid:6)=j(cid:2), the potential outcomes of individual i exist as J−1 i Dj counterfactual outcomes y .\ni There are two basic approaches to matching with many-valued treatments (see Rosenbaum 2002, section 10.2.4). The most straightforward and general approach is to form a series of two-way comparisons between the multiple treatments, estimating a separatepropensity scorefor eachcontrastbetweeneachpair oftreatments.39 After theestimatedpropensityscoresareobtained,treatmenteffectestimatesarecalculated pairwisebetweentreatments.Caremustbetaken,however,tomatchappropriatelyon the correct estimated propensity scores. The observed outcomes for individuals with equivalent values on alternative propensity scores cannot be meaningfully compared (see Imbens 2000, section 5).\nFor example, for three treatments with J equal to 1, 2, and 3, one would first estimate three separate propensity scores, corresponding to three contrasts for the threecorrespondingdummyvariables:D1versusD2,D1versusD3,andD2versusD3.\n39Somesimplificationofthepropensityscoreestimationispossible.Ratherthanestimatepropensity scores separately for each pairwisecomparison, one can use multinomial probit and logit models to estimate the set of propensity scores (see Lechner 2002a, 2002b; see also Hirano and Imbens 2004; ImaiandvanDyk2004;Imbens2000;Zhao,vanDyk,andImai2012).Onemuststill,however,extract the right contrasts from such a model in order to obtain an exhaustive set of estimated propensity scores.\nOnewouldobtainthreeestimatedpropensityscores:PrN[d1i=1|d1i=1ord2i=1,si], PrN[d1i=1|d1i=1ord3i=1,si],andPrN[d2i=1|d2i=1ord3i=1,si].Onewouldthen matchseparatelyforeachofthethreecontrastsleaving,forexample,thosewithd3i=1 unused and unmatched when matching on the propensity score for the comparison of treatment1versustreatment2.Atnopointwouldonematchtogetherindividualswith equivalent values for alternative estimated propensity scores.For example, there is no meaningfulcausalcomparisonbetweentwoindividuals,inwhichforthefirstindividual d2i=1andPrN[d1i=1|d1i=1ord2i=1,si]=.6andforthesecondindividuald3i=1 and PrN[d1i=1|d1i=1 or d3i=1,si]=.6.\nWhen the number of treatments is of modest size, such as only four or five alter- natives,thereismuchtorecommendinthis generalapproach.However,ifthe number of treatments is considerably larger, then this fully general approach may be infeasi- ble. One might then choose to simply consider only a subset of causal contrasts for analysis, thereby reducing the aim of the causal analysis.\nIf the number of treatments can be ordered, then a second approachdeveloped by Joffe and Rosenbaum (1999) and implemented in Lu, Zanutto, Hornik, and Rosen- baum (2001) is possible. These models generally go by the name of dose-response models because they are used to estimate the effects of many different dose sizes of the same treatment, often in comparison with a base dosage of 0 that signifies no treatment.\nRather than estimate separate propensity scores for each pairwise comparison, an ordinal probability model is estimated and the propensity score is defined as a single dimension of the predictors of the model (i.e., ignoring the discrete shifts in the odds of increasing from one dosage level to the next that are parameterized by the estimated cut-point parameters for each dosage level). Thereafter, one typically performs a slightly different form of matching in which optimal matched sets are formed by two criteria, which Lu et al. (2001:1249) refer to as “close on covariates; far apart on doses.” The idea here is to form optimal contrasts between selected sets of comparableindividuals to generate estimates of counterfactually defined responses.\nThe goal is to be able to offer a predicted response to any shift in a dosage level from any k(cid:2) to k(cid:2)(cid:2), where both k(cid:2) and k(cid:2)(cid:2) are between the smallest and largest dosage valuesobserved.Again,however,these methodsassumethatthe treatmentvaluescan be ordered, and further that the propensity scores can be smoothed across dose sizes after partialing out piecewise shifts. Even so, these assumptions are no more severe than what is typically invoked implicitly in standard parametric regression modeling approaches to causality, as we discuss in later chapters.\nSome work has continued to examine how the rationale for propensity scores can beusefullygeneralizedwithoutnecessarilyadoptingthefullstructureofdose-response models. Ordered and nonordered multinomial probability models for modeling treat- ment assignment are again the foundations of these models (see Hirano and Imbens 2004; Imai and van Dyk 2004; and Zhao et al. 2012 for further details). This litera- ture has progressedslowly because analogs to balance checking across many values of a treatment have not been developed, placing these particular approaches outside of the balance-optimizing agenda that has driven the most recent research on matching methods, as discussed in Section 5.4.2.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#conclusions-2",
    "href": "extracted/Counterfactuals and Causal Inference.html#conclusions-2",
    "title": "Counterfaturals and Causal Inference",
    "section": "5.6 Conclusions",
    "text": "5.6 Conclusions\nWe conclude this chapter by discussing the strengths and weaknesses of matching as\na method for causal inference from observational data. Some of the advantages of matching methods are not inherent or unique to matching itself but rather are the result of the analytical framework in which most matching analyses are conducted.\nMatching focuses attention on the heterogeneity of the causal effect, and it suggests clearly why thinking separately about the ATT, ATC, and ATE is crucial. Matching also forces the analyst to examine the alternative distributions of covariates across those exposed to different levels of the causal variable, and it may suggest that for someapplicationstheonlyestimatesworthinterpretationarethosethatarerestricted to the regionof common support. Matching, as will become clear in the next chapter, iscomparativelyconservativeinamodelingsensebecauseitdoesnotimplicitlyinvoke the interpolation and extrapolation that characterize parametric regression models.\nAlthoughthesearetheadvantagesofmatching,itisimportantthatwenotoversell the potential power of the techniques. In much of the applied literature on matching, the propensity score is presented as a single predictive dimension that can be used to balance the distribution of important covariates across treatment and control cases, therebywarrantingcausalinference.Ifonedoesnotobserveandutilize variablesthat, inaninfinitesample,wouldyieldaperfectstratification,thensimplypredictingtreat- ment status from a more limited set of observed variables with a logit model and then matching on the estimated propensity score does not solve the causal inference problem.Theestimatedpropensityscoreswillbalancethosevariables(inexpectation) across the treatment and control cases. But the study will remain open to the sort of “hidden bias” explored by Rosenbaum (2002), which is often labeled selection on the unobservables in the social sciences. Matching is thus a statistical method for analyz- ingavailabledata,whichmayhavesomeadvantagesinsomesituations.Theregression estimators that we will present in the next two chapters are complementary, and our understanding of them has been enrichedby the matching literature presented in this chapter.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#regression-as-a-descriptive-tool",
    "href": "extracted/Counterfactuals and Causal Inference.html#regression-as-a-descriptive-tool",
    "title": "Counterfaturals and Causal Inference",
    "section": "6.1 Regression as a Descriptive Tool",
    "text": "6.1 Regression as a Descriptive Tool\nLeast squares regressioncan be justified without reference to causality because it can\nbe considered nothing more than a method for obtaining a best-fitting descriptive 188 model under entailed linearity constraints. Goldberger (1991),for example, motivates least squares regressionas a technique to estimate a best-fitting linear approximation to a conditional expectation function that may be nonlinear in the population.\nConsider this descriptive motivation of regression a bit more formally. If X is a collectionof variablesthat are thought to be associatedwith Y in some way,then the conditional expectation function of Y, viewed as a function in X, is denoted E[Y|X].\nEach particular value of the conditional expectation for a specific realization x of X is then denoted E[Y|X=x].\nLeast squares regressionyields a predicted surface Yˆ =Xβˆ, where βˆ is a vector of estimatedcoefficientsfromtheregressionoftherealizedvaluesyi onxi.Thepredicted surface, Xβˆ, does not necessarily run through the specific points of the conditional expectation function, even for an infinite sample, because (1) the conditional expec- tation function may be a nonlinear function in one or more of the variables in X and (2) a regression model can be fit without parameterizing all nonlinearities in X. An estimated regression surface simply represents a best-fitting linear approximation of E[Y|X]under whateverlinearity constraintsareentailed by the chosenparameteriza- tion of the estimated model.1 The following demonstration of this usage of regression is simple. Most readers know this material well and can skip ahead to the next section. But, even so, it may be worthwhile to read the demonstration quickly because we will build directly on it when shifting to the consideration of regression as a causal effect estimator.\nRegression Demonstration 1 Recall the stratificationexample presented as Matching Demonstration1 (see Section 5.2.1, page 145). Suppose that the same data are being analyzed, as generated by the distributions presented in Tables 5.1 and 5.2; features of these distributions are reproduced in Table 6.1 in more compact form. As before, assume that well-defined causalstatescontinuetoexistandthatS servesasaperfectstratificationofthedata.2 Accordingly,theconditionalexpectationsinthelastthreepanelsofTable6.1areequal as shown.\nBut, for this demonstration of regression as a descriptive tool, suppose that a cautious researcher does not wish to rush ahead and attempt to estimate the specific underlying causal effect of D on Y, either averaged across all individuals or averaged across particular subsets of the population. Instead, the researcher is cautious and is willing to assert only that the variables S, D, and Y constitute some portion of a largersystemofcausalrelationships.Inparticular,theresearcherisunwillingtoassert anything about the existence or nonexistence of other variables that may also lie on the directed paths that reach D and Y. This is tantamount to doubting the claim that S offers a perfect stratification of the data, even though that claim is true by construction for this example.\n1Onecanfitalargevarietyofnonlinearsurfaceswithregressionbyartfulparameterizationsofthe variablesinX,butthesesurfacesarealwaysgeneratedbyalinearcombinationofacoefficientvector andvaluesonsomewell-definedcodingofthevariablesinX.\n2For this section, we will also stipulate that the conditional variances of the potential outcomes areconstant acrossbothofthepotential outcomes andacrosslevelsofS.\nTable 6.1 The Joint Probability Distribution and Conditional Population Expectations for Regression Demonstration 1 Joint probability distribution of S and D Control group: D=0 Treatment group: D=1 S=1 Pr[S=1,D=0]=.36 Pr[S=1,D=1]=.08 S=2 Pr[S=2,D=0]=.12 Pr[S=2,D=1]=.12 S=3 Pr[S=3,D=0]=.12 Pr[S=3,D=1]=.2 Potential outcomes underthecontrol state S=1 E[Y0|S=1,D=0]=2 E[Y0|S=1,D=1]=2 S=2 E[Y0|S=2,D=0]=6 E[Y0|S=2,D=1]=6 S=3 E[Y0|S=3,D=0]=10 E[Y0|S=3,D=1]=10 Potential outcomes underthe treatment state S=1 E[Y1|S=1,D=0]=4 E[Y1|S=1,D=1]=4 S=2 E[Y1|S=2,D=0]=8 E[Y1|S=2,D=1]=8 S=3 E[Y1|S=3,D=0]=14 E[Y1|S=3,D=1]=14 Observed outcomes S=1 E[Y|S=1,D=0]=2 E[Y|S=1,D=1]=4 S=2 E[Y|S=2,D=0]=6 E[Y|S=2,D=1]=8 S=3 E[Y|S=3,D=0]=10 E[Y|S=3,D=1]=14 Inthissituation,supposethattheresearchersimplywishestoestimatethebestlin- earapproximationtotheconditionalexpectationE[Y|D,S]anddoesnotwishtothen give a causal interpretation to any of the coefficients that define the linear approx- imation. The six true values of E[Y|D,S] are given in the last panel of Table 6.1.\nNotice that the linearity of E[Y|D,S] in D and S is present only when S≤2. The value of14for E[Y|D=1,S=3]makesE[Y|D,S] nonlinearinD andS overtheir full distributions.\nNow consider the predicted surfaces that would result from the estimation of two alternativeleastsquaresregressionmodels with data froma sample ofinfinite size (to render sampling errorzero).A regressionof Y on D and S that treats D as a dummy variable and S as an interval-scaled variable would yield a predictive surface of Yˆ =−2.71+2.69(D)+4.45(S). (6.1) This model constrains the partial association between Y and S to be linear. It rep- resents a sensible predicted regression surface because it is a best-fitting, linear-in- the-parameters model of the association between Y and the two variables D and S, where “best” is defined as minimizing the average squared differences between the fitted values and the true values of the conditional expectation function.\nFor this example, one can offer a better descriptive fit at little interpretive costby usinga more flexible parameterizationofS. An alternativeregressionthattreats S as a discrete variable represented in the estimation routine by dummy variables S2 and S3(for S equalto 2 andS equal to 3, respectively)wouldyieldapredictive surfaceof Yˆ =1.86+2.75(D)+3.76(S2)+8.92(S3). (6.2) Like the predicted surface for the model in Equation (6.1), this model is also a best linear approximation to the six values of the true conditional expectation E[Y|D,S].\nThe specific estimated values are D=0,S=1: Yˆ =1.86, D=0,S=2: Yˆ =5.62, D=0,S=3: Yˆ =10.78, D=1,S=1: Yˆ =4.61, D=1,S=2: Yˆ =8.37, D=1,S=3: Yˆ =13.53.\nIncontrasttothemodelinEquation(6.1),forthismodelthevariableS isgivenafully flexiblecoding.As aresult,parametersarefitthatuniquely representallvaluesof S.3 The predicted change in Y for a shift in S from 1 to 2 is 3.76 (i.e., 5.62−1.86=3.76 3The difference between a model in which a variable is given a fully flexible coding and one in whichitisgivenamoreconstrainedcodingisclearerforasimplerconditional expectation function.\nForE[Y|S],considerthevaluesinthecellsofTable6.1.ThethreevaluesofE[Y|S]canbeobtained fromthefirstandfourthpanelsofTable6.1asfollows: .36 .08 E[Y|S=1]= (2)+ (4)=2.36, (.36+.08) (.36+.08) .12 .12 E[Y|S=2]= (6)+ (8)=7, (.12+.12) (.12+.12) .12 .2 E[Y|S=3]= (10)+ (14)=12.5.\n(.12+.2) (.12+.2) NoticethatthesethreevaluesofE[Y|S]donotfallonastraightline;themiddlevalueof7iscloser to2.36thanitisto12.5.\nFor E[Y|S],a least squares regression of Y on S, treating S as an interval-scaled variable, would yieldapredictivesurfaceof Yˆ=−2.78+5.05(S).\nThethreevaluesofthisestimatedregressionsurfacelieonastraightline−2.27,7.32,and12.37–and theydonotmatchthecorrespondingtruevaluesof2.36,7,and12.5.AregressionofY onS,treating SasadiscretevariablewithdummyvariablesS2andS3,wouldyieldanalternativepredictivesurface of Yˆ=2.36+4.64(S2)+10.14(S3).\nThis second model uses a fully flexible coding of S, and each value of the conditional expectation function is a unique function of the parameters in the model (that is, 2.36=2.36, 4.64+2.36=7, and 10.14+2.36=12.5). Thus, in this case, the regression model would, in a suitably large sample, estimatethethreevaluesofE[Y|S]exactly.\nand 8.37−4.61=3.76), whereas the predicted change in Y for a shift in S from 2 to 3 is 5.16 (i.e., 10.78−5.62=5.16 and 13.53−8.37=5.16).\nEven so, the model in Equation (6.2) constrains the parameter for D to be the same without regard to the value of S. And, because the level of Y depends on the interaction of S and D, specifying more than one parameter for the three values of S does not bring the predicted regression surface into alignment with the six values of E[Y|D,S] presented in the last panel of Table 6.1. Thus, even when S is given a fully flexible coding (and evenfor aninfinitely largesample), the fitted values do not equal the true values of E[Y|D,S].4 As we discuss later, a model that is saturated fully in both S and D – that is, one that adds two additional parameters for the interactions between D and both S2 and S3 – would yield predicted values that would exactly match the six true values of E[Y|D,S] in a dataset of sufficient size.\nRecallthe moregeneralstatement ofthe descriptivemotivationofregressionanal- ysis presented above, in which the predicted surface Yˆ =Xβˆ is estimated for the sole purposeofobtainingabest-fitting linearapproximationtothetrueconditionalexpec- tation function E[Y|X]. When the purposes of regression are so narrowly restricted, the outcomevariableofinterest,Y, isnotgenerallythoughttobeafunctionofpoten- tial outcomes associated with well-defined causal states. Consequently, it would be inappropriate to give a causal interpretation to any of the estimated coefficients in βˆ.\nThis perspective implies that if one were to add more variables to the predictors, embedding X in a more encompassing set of variables W, then a new set of least squares estimates γˆ could be obtained by regressing Y on W. The estimated surface Wγˆ then represents a best-fitting, linear-in-the-parameters, descriptive fit to a more encompassing conditional expectation function, E[Y|W]. Whether one then prefers Wγˆ to Xβˆ as a description of the variation in Y depends on whether one finds it more useful to approximate E[Y|W] than E[Y|X]. The former regressionapproxima- tion is often referred to as the long regression, with the latter representing the short regression.These labels are aptly chosen, when regressionis considered nothing more than a descriptive tool, because there is no inherent reasonto prefer a short to a long regression if neither is meant to be interpreted as anything other than a best-fitting linear approximation to its respective true conditional expectation function.\nIn many applied regression textbooks, the descriptive motivation of regression receives no direct explication. And, in fact, many textbooks state that the only cor- rect specification of a regression model is one that includes all explanatory variables.\nGoldberger (1991) admonishes such textbook writers, countering their claims: 4Why would one ever prefer a constrained regression model of this sort? Consider a conditional expectation function,E[Y|X],whereY isearningsandX isyearsofeducation(with21valuesfrom 0to20).AfullyflexiblecodingofX wouldfit20dummyvariablesforthe21valuesofX.Thiswould allow the predicted surface to change only modestly between some years (such as between 7 and 8 andbetween12and13)andmoredramaticallybetweenotheryears(suchasbetween11and12and between 15 and 16). However, one might wish to treat X as an interval-scaled variable, smoothing these increases from year to year by constraining them to a best-fitting line parameterized only by anintercept andaconstant slope.Thisconstrained modelwouldnot fittheconditional expectation functionascloselyasthemodelwith20dummyvariables,butitmightbepreferredinsomesituations because it is easier to present and uses fewer degrees of freedom, which could be important if the modelisestimatedwithasmallsample.\nAn alternative position is less stringent and is free of causal language.\nNothinginthe CR[classicalregression]modelitselfrequiresanexhaustive list of explanatory variables, nor any assumption about the direction of causality. (Goldberger 1991:173) Goldberger is surely correct, but his perspective nonetheless begs an important ques- tionontheultimateutilityofdescriptivelymotivatedregression.Clearly,ifonewishes to know only predicted values of the outcome Y for those not originally studied but whose variables in X are known, then being able to form the surface Xβˆ is a good firststep (andperhaps a goodlaststep). And, if one wishes to build a moreelaborate regressionmodel, allowing for an additional variable in W or explicitly accounting for multilevel variability by modeling the nested structure of the data, then regression results will be useful if the aim is to generate descriptive reductions of the data. But, if one wishes to know the value of Y that would result for any individual in the pop- ulation if a variable in X were shifted from a value k to a value k(cid:2), then regression results may be uninformative.\nMany researchers (perhaps a clear majority) who use regression models in their research are very much interested in causal effects. Knowing the interests of their readers, many textbook authors offer presentations of regression that sidestep these issuesartfullyby,forexample,discussinghowbiasedregressioncoefficientsresultfrom the omissionofimportant explanatoryvariables but without introducing explicit, for- mal notions of causality into their presentations. Draper and Smith (1998:236), for example,write of the bias that enters into estimated regressioncoefficients when only a subset of the variables in the “true response relationship” are included in the fit- ted model. Similarly, Greene (2000:334) writes of the same form of bias that results from estimating coefficients for a subset of the variables from the “correctly specified regressionmodel.”5 And, in his presentation of regressionmodels for social scientists, Stolzenberg (2004:188)equivocates: Philosophical arguments about the nature of causation notwithstanding (see Holland, 1986), in most social science uses of regression, the effect of anindependentvariableonadependentvariableistherate atwhichdiffer- encesintheindependentvariableareassociatedwith(orcause)differences or changes in the dependent variable. (italics in the original) Weassumethatthereadersofourbookareinterestedincausaleffectestimators.And thus,althoughwerecognizetheclassicalregressiontradition,perhapsbestdefendedby Goldberger(1991)asinterpretablemerelyasadescriptivedatareductiontool,wewill considerregressionasacausaleffectestimatorintheremainingsectionsofthischapter.\nAnd we further note that, in spite of our reference to Goldberger (1991), in other writingGoldbergerhasmadeitabsolutelyclearthathetoowasverymuchinterestedin theproperusageofregressionmodelstoofferwarrantedcausalclaims.Thisisperhaps most clear in work in which he criticized what he regarded as unwarranted causal claims generated by others using regression techniques, such as in his robust critique ofColeman’sCatholicschoolsresearch(seeGoldbergerandCain1982).Wewillreturn 5Thereare,ofcourse,othertextbooksthatdopresentamorecompleteperspective,suchasAngrist andPischke(2009), Berk(2004), Freedman(2005), andGelmanandHill(2007).\ntoadiscussionofthe notionofacorrectspecificationofaregressionmodelinthefinal section of the chapter, where we discuss the connections between theoretical models and regressions as all-cause perfect specifications. Until then, however, we return to the same basic scenario considered in our presentation of matching in Chapter 5: the estimation of a single causal effect that may be confounded by other variables.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#regression-adjustment-as-a-strategy-to-estimate-causal-effects",
    "href": "extracted/Counterfactuals and Causal Inference.html#regression-adjustment-as-a-strategy-to-estimate-causal-effects",
    "title": "Counterfaturals and Causal Inference",
    "section": "6.2 Regression Adjustment as a Strategy to Estimate Causal Effects",
    "text": "6.2 Regression Adjustment as a Strategy to Estimate Causal Effects\nIn this section, we consider the estimation of causal effects in which least squares\nregressionisusedto adjustfor variablesthoughtto be relatedto boththe causalvari- ableandtheoutcomevariable.Wefirstconsiderthetextbooktreatmentoftheconcept ofomitted-variablebias,withwhichmostreadersareprobablywellacquainted.There- after,weconsiderthesamesetofideasafterspecifyingthepotentialoutcomevariables that the counterfactual tradition assumes lie beneath the observed data.\n6.2.1 Regression Models and Omitted-Variable Bias Suppose that one is interested in estimating the causal effect of a binary variable D on an observed outcome Y. This goal can be motivated as an attempt to obtain a consistent and unbiased estimate of a coefficient δ in a generic bivariate regression equation, Y =α+δD+ε, (6.3) where α is an intercept and ε is a summary random variable that represents all other causes of Y (some of which may be related to the causal variable of interest, D).\nWhen Equation (6.3) is used to represent the causal effect of D on Y without any reference to individual-varying potential outcomes, the parameter δ is implicitly cast as an invariant, structural causal effect that applies to all members of the population of interest.6 The OLS estimator of this bivariate regression coefficient is then CovN(yi,di) δˆ OLS,bivariate≡ , (6.4) VarN(di) whereCovN(.) andVarN(.)areconsistentandunbiased,sample-basedestimates from a sample of size N of the population-level covariance and variance of the variables that are their arguments.7 Because D is a binary variable, δˆ OLS,bivariate is exactly equivalentto the naive estimator,EN[yi|di=1]−EN[yi|di=0],presentedin Equation 6Althoughthisisgenerallythecase,thereareofcourseintroductionstoregressionthatexplicitly define δ as the mean effect of D on Y across units in the population of interest or, as was noted in thelastsection, withoutregardtocausalityatall.\n7Notice that we are again focusing on the essential features of the methods. When we present least squares regression estimators in this chapter, we will maintain three implicit assumptions to simplifyinferencecomplications inordertofocus onidentification issues.First,weignoredegree-of- freedom adjustments because weassumethat the availablesampleis verylarge. Tobemoreprecise in justifying unbiasedness for a finite sample, we would want to indicate that the sample variance of D does not equal the population-level variance of D in the absence of such a degree-of-freedom (2.9) (i.e., the sample mean of yi for those in the treatment group minus the sample mean of yi for those in the control group). Our analysis thus follows quite closely the discussion of the naive estimator in Section 2.7.3. The difference is that here we will develop the same basic claims with reference to the relationship between D and ε rather than the general implications of heterogeneity of the causal effect.\nConsider first a case in which D is randomly assigned, as when individuals are randomly assigned to the treatment and control groups. In this case, D would be uncorrelatedwith ε in Equation(6.3), even though there may be a chance correlation betweenDandεinanyfinitesetofstudysubjects.8Theliteratureonregression,when presented as a causal effect estimator, maintains that, in this case, (1) the estimator δˆ OLS,bivariate is consistent and unbiased for δ in Equation (6.3) and (2) δ can be interpreted as the causal effect of D on Y.\nTo understand this claim, it is best to consider a counterexample in which D is correlated with ε in the population because D is correlated with other causes of Y that are implicitly embedded in ε. For a familiar example, consider again the effect of education on earnings. Individuals are not randomly assigned to the treatment “completed a bachelor’s degree.” It is generally thought that those who complete college would be more likely to have had high levels of earnings in the absence of a collegeeducation.Ifthisistrue,D andthepopulation-levelerrortermεarecorrelated because those who have a 1 on D are more likely to have high values rather than low values for ε. For this example, the least squares regression estimator δˆ OLS,bivariate in Equation (6.4) would not yield an estimate of δ that can be regardedas consistent or unbiased for the causal effect of D on Y. Instead, δˆ OLS,bivariate must be interpreted as inconsistent and upwardly biased. In the substance of the college-degree example, δˆ OLS,bivariate would be a poor estimate of the causal effect of a college degree on adjustment,andsoon.WemerelylabelVarN(.)assignifyingsuchaconsistentandunbiasedestimate ofthe population-level-variance of that whichisits argument. Thus,VarN(.)implicitlyincludes the properdegree-of-freedomadjustment,whichwouldbeN/(N−1)andwhichwouldthenbemultiplied bytheaverageofsquareddeviationsfromthesamplemean.Second,wewillassumethatthesampling- errorcomponents oftheregressionerrortermshave“zeroconditional mean”; seeWooldridge(2010, equation4.3);seealsothe“strictexogeneity”assumptionofHayashi(2000,equation1.1.7).Underthis assumption,thefinitesamplebiasoftheOLSestimatorofeachcoefficienthasexpectationequalto0, eventhoughweallowthepredictorstoberandomvariablesratherthanafixedfeatureofthedesign.\nAs will become clear, we will have a lot to say about assumptions regarding regression error terms inthischapter, and fornow weinvokethis assumptiononlyinthe limitedsensethatitallowsusto eliminatefinitesamplebiasfromourconsideration.Third,ourperfectmeasurementassumptionrules out measurement error in predictors, which eliminates attenuation bias in all regression coefficient estimates.\n8WewillfrequentlyrefertoDandεasbeinguncorrelatedforthistypeofassumption,asthisisthe semanticsthatmostsocialscientistsseemtouseandunderstandwhendiscussingtheseissues.Most textbook presentations ofregressiondiscussveryspecificexogeneity assumptionsforD thatimplya correlationof 0between D and ε.Usually,inthe social sciences the assumptionis defined either by meanindependenceofDandεorasanassumedcovarianceof0betweenDandε.Bothoftheseimply acorrelationbetweenDandεof0.Instatistics,oneoftenfindsastrongerassumption:Dandεmust becompletelyindependentofeachother.Theargumentinfavorofthisstrongerassumption,whichis convincingtostatisticians,isthataninferenceisstrongestwhenitholdsunderanytransformationof Y (andthusanytransformationofε).WhenfullindependenceofDandεholds,meanindependence ofD andε,acovarianceof0betweenD andε,anda0correlationbetweenD andεareallimplied.\nε D Y D Y (a) A graph in which the (b) An equivalent regression casual effect is not identified representation of the same graph Figure 6.1 Graphs for a regressionequation of the causal effect of D on Y.\nearningsbecauseitwouldsuggestthatthe effectofobtainingacollegedegreeislarger than it really is.9 Figure 6.1(a) presents a graph where D and Y are connected by two types of paths, the direct causal effect D→Y and an unspecified number of back-door paths representedby D(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)Y. (Recall that bidirectededges(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)representan unspec- ified number of common causes of the two variables that they connect.) For Figure 6.1(a),the causaleffectofD onY isnotidentifiedbecausenoobservablevariablesare available to block the back-door paths represented by D(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)Y.\nFigure 6.1(b) is the regression analog to the graph in Figure 6.1(a). It contains three edges: D→Y, ε→Y, and D(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)ε, where the node for ε is represented by a hollow circle ◦ rather than a solidcircle • in orderto indicate that ε is an unobserved variable.Theunblockedback-doorpathsfromD toY nowrunthroughtheerrorterm ε, and the dependence represented by the bidirected edge confounds the causal effect of D on Y. Bivariate regression results, when interpreted as warranted causal effect estimates, assume that there are no such unblocked back-door paths from the causal variable to the outcome variable.\nFor many applications in the social sciences, a correlation between D and ε is conceptualized as a problem of omitted variables. For the example in this section, a bivariate OLS estimate of the effect of a college degree on labor market earnings would be said to be biased because intelligence is unobserved but is correlated with both education and earnings. Its omission from Equation (6.3) leads the estimate of the effectofacollegedegreeonearningsfromthatequationtobe largerthanitwould have been if a variable for intelligence were instead included in the equation.\nThisperspective,however,hasledtomuchconfusion,especiallyincasesinwhicha correlationbetweenDandεemergesbecausesubjectschoosedifferentlevelsofDbased on their expectations about the variability of Y, and hence their own expectations of the causal effect itself. For example, those who attend college may be more likely to benefit from college than those who do not, even independent of the unobserved ability factor. Although this latent form of anticipation can be labeled an omitted 9Consider for one last time the alternative and permissible descriptive interpretation: The least squares regression estimator δˆ OLS,bivariate in Equation (6.4) could be interpreted as consistent and unbiased for δ, where the regression surface generated by the estimation of δ in Equation (6.3) is considered only a descriptively motivated, best linear prediction of the conditional expectation function, E[Y|D] (i.e., where αˆ is a consistent and unbiased for E[Y|D=0] and αˆ+δˆis consistent andunbiasedforE[Y|D=1]).Inthesubstanceofthecollege-degreeexample,theestimatecouldbe regarded as an estimate of the mean difference between the earnings of those who have obtained a collegedegreeandthosewhohavenot,withoutrequiringorwarrantinganycausalinterpretation.\nvariable, it is generally not. Instead, the language of research shifts toward notions suchas self-selectionbias, and this is less comfortable territoryfor the typicalapplied researcher.\nTo clarify the connections between omitted-variable bias and self-selection bias within a more general presentation, we utilize the potential outcome model in the nextsection.WebreaktheerrorterminEquation(6.3)intocomponentpiecesdefined by underlying potential outcome variables and allow for the more general forms of causaleffectheterogeneitythatareimplicitlyruledoutbyconstant-coefficientmodels.\n6.2.2 Potential Outcomes and Omitted-Variable Bias Considerthe same set of ideas but now use the potentialoutcome model to define the observedvariables.Here,wewillbuilddirectlyonthevariantofthepotentialoutcome modelpresentedinSection4.3.2.Fromthatpresentation,recallEquation(4.6),which we reintroduce here as Y =μ0+(μ1−μ0)D+{υ0+D(υ1−υ0)}, (6.5) whereμ0≡E[Y0],μ1≡E[Y1],υ0≡Y0−E[Y0],andυ1≡Y1−E[Y1].Wecouldrewrite this equation to bring it into closer alignment with Equation (6.3) by stipulating that α=μ0, δ=(μ1−μ0), and ε= υ0+D(υ1−υ0). But note that these equalities would redefine what is typically meant by the terms α, δ, and ε in Equation (6.3). The parametersα and δ in Equation(6.3) are usually not consideredto be equal to E[Y0] or E[δ] for two reasons: (1) models are usually asserted in the regression tradition (e.g., in Draper and Smith 1998) without any reference to underlying causal states tied to potential outcomes and (2) the parameters α and δ are usually implicitly held to be constant structural effects that do not vary over individuals in the population.\nSimilarly,theerrorterm,ε,inEquation(6.3)isalmostneverseparatedintotwopieces as a function of the definition of potential outcomes and their relationship to D. For thesereasons,Equation(6.5)isquitedifferentfromthetraditionalbivariateregression in Equation (6.3), in the sense that it is more finely articulated but also irretrievably tied to a particular formalization of a causal effect that is allowed to vary across individuals.\nSuppose that we are interested in estimating the average treatment effect (ATE), denoted(μ1−μ0)here.ThecausalvariableDcouldbecorrelatedwiththepopulation- levelvariantoftheerrortermυ0+D(υ1−υ0)inEquation(6.5)intwoways.First,sup- posethatthere is anetbaselinedifference inthe hypotheticalno-treatmentstate that is correlated with membership in the treatment group, but the size of the individual- leveltreatment effect does notdiffer on averagebetweenthose inthe treatmentgroup andthoseinthecontrolgroup.Inthiscase,υ0 wouldbecorrelatedwithD,generating a correlation between {υ0+D(υ1−υ0)} and D, even though the D(υ1−υ0) term in {υ0+D(υ1−υ0)} would be equal to zero on average because υ1−υ0 does not vary with D. Second, suppose there is a net treatment effect difference that is correlated withmembershipinthe treatmentgroup,butthereisnonetbaselinedifferenceinthe absence of treatment. Now, D(υ1−υ0) would be correlated with D, even though υ0 is not, because the average difference in υ1−υ0 varies across those in the treatment Table 6.2 Examples of the Two Basic Forms of Bias for Least Squares Regression Differential baseline bias only y i1 y i0 υ i1 υ i0 yi di υ i0+di(υ1 i−υ0 i) In treatment group 20 10 0 5 20 1 0 In control group 20 0 0 −5 0 0 −5 Differential treatment effect bias only y i1 y i0 υ i1 υ i0 yi di υ i0+di(υ1 i−υ0 i) In treatment group 20 10 2.5 0 20 1 2.5 In control group 15 10 −2.5 0 10 0 0 Both typesof bias y i1 y i0 υ i1 υ i0 yi di υ i0+di(υ1 i−υ0 i) In treatment group 25 5 5 −2.5 25 1 5 In control group 15 10 −5 2.5 10 0 2.5 groupandthose in the controlgroup.In either case,anOLSregressionofthe realized values of Y on D would yield an inconsistent and biased estimate of (μ1−μ0).\nItmaybehelpfultoseepreciselyhowthesesortsofbiascomeaboutwithreference to the potential outcomes of individuals. Table 6.2 presents three simple two-person examples in which the least squares bivariate regression estimator δˆ OLS,bivariate in Equation (6.4) is biased. Each panel presents the potential outcome values for two individuals and then the implied observed data and error term in the braces from Equation(6.5).Assumeforconveniencethatthereareonlytwotypesofindividualsin the population, both of which are homogeneous with respect to the outcomes under study and both of which comprise one half of the population. For the three examples in Table 6.2, we have sampled one of each of these two types of individuals for study.\nFor the example in the first panel, the true ATE is 15, because for the individual in the treatment group δi is 10, whereas for the individual in the control group δi is 20. The values of υ1 and υ0 are deviations of the values of y1 and y0 from E[Y1] and i i i i E[Y0],respectively.Becausetheseexpectationsareequalto 20and5,the values ofυ1 i are both equal to 0 because each individual’s value of y1 is equal to 20. In contrast, i the valuesofυ0 areequalto 5and−5fortheindividuals inthetreatmentandcontrol i groups, respectively, because their two values of y0 are 10 and 0.\ni As noted earlier, the bivariate regression estimate of the coefficient on D is equal to the naive estimator, EN[yi|di=1]−EN[yi|di=0]. Accordingly, a regression of the values for yi on di would yield a value of 0 for the intercept and a value of 20 for the coefficientonD.Thisestimatedvalueof20is anupwardlybiasedestimateforthe true average causal effect because the values of di are positively correlated with the values of the error term υ i0+di(υ i1−υ i0). In this case, the individual with a value of 1 for di has a value of 0 for the error term, whereas the individual with a value of 0 for di has a value of −5 for the error term.\nFortheexampleinthesecondpanel,therelevantdifferencebetweentheindividual in the treatment group and the individual in the control group is in the value of y1 i rather than y0. In this variant, both individuals would have had the same outcome if i they were both in the control state, but the individual in the treatment group would benefit relatively more from being in the treatment state. Consequently, the values of di are correlated with the values of the error term in the last column because the true treatment effect is larger for the individual in the treatment group than for the individual in the control group. A bivariate regression would yield an estimate of 10 for the ATE, even though the true ATE is only 7.5 in this case.10 Finally, in the third panel of the table, both forms of baseline and net treatment effect bias are present, and in opposite directions. In combination, however, they still generate a positive correlationbetween the values of di and the error term in the last column.Thispatternresultsinabivariateregressionestimateof15,whichisupwardly biased for the true ATE of 12.5.\nForsymmetry,andsomeadditionalinsight,nowconsidertwoadditionaltwo-person examples in which regression gives an unbiased estimate of the average causal effect.\nFor the first panel of Table 6.3, the potential outcomes are independent of D, and as a result a bivariate regressionof the values yi on di would yield an unbiased estimate of 10 for the true ATE. But the example in the second panel is quite different. Here, the values of υ i1 and υ i0 are each correlated with the values of di, but they cancel each other out when they jointly constitute the error term in the final column. Thus, a bivariate regression yields an unbiased estimate of 0 for the true ATE of 0. And, yet, with knowledge of the values for y1 and y0, it is clear that these results mask i i important heterogeneity of the causal effect. Even though the average causal effect is indeed0,the individual-levelcausaleffectsareequalto10and−10fortheindividuals inthetreatmentgroupandcontrolgroup,respectively.Thus,regressiongivestheright answer,butithidestheunderlyingheterogeneitythatonewouldalmostcertainlywish to know.11 Having considered these examples, we are now in a position to answer, with refer- ence to the potential outcome model, the question that so often challenges students whenfirstintroducedtoregressionasacausaleffectestimator:Whatistheerrorterm ofaregressionequation?Comparethethirdandfourthcolumnswiththefinalcolumn in Tables 6.2 and 6.3. The regression error term, υ0+D(υ1−υ0), is equal to υ0 for those in the control group and υ1 for those in the treatment group. This can be seen without reference to the examples in the tables. Simply rearrange υ0+D(υ1−υ0) as 10Note,however,that10isthetrueaveragetreatmenteffectforthetreated(ATT),orinthiscase the treatment effect for the treated for the sole individual inthe treatment group. This is the same essentialpatternasforMatchingDemonstration4,wheretheATTisidentifiedbecause,inthiscase, Assumption2inEquation(2.16)wouldholdbecause(y i0|d i=1)=(y i0|d i=0)=10.\n11Assumptions1and2inEquations(2.15)and(2.16)arethereforesufficientbutnotnecessaryfor thenaiveestimatorandbivariateOLSregressionestimatortoconsistentlyestimatetheATE.Wehave notmentionedthisqualificationuntilnowbecausewedonotbelievethatperfectcancellationoccursin socialscienceapplications.Thisassumptionissometimeslabeled“faithfulness”inthecounterfactuals literature.\nTable 6.3 Two-PersonExamples in Which Least Squares Regression Estimates Are Unbiased Independenceof (Y1,Y0) from D y i1 y i0 υ i1 υ i0 yi di υ i0+di(υ1 i−υ0 i) In treatment group 20 10 0 0 20 1 0 In control group 20 10 0 0 10 0 0 Offsetting dependenceof Y1and Y0 on D y i1 y i0 υ i1 υ i0 yi di υ i0+di(υ1 i−υ0 i) In treatment group 20 10 5 −5 20 1 5 In control group 10 20 −5 5 20 0 5 Dυ1+(1−D)υ0 and then rewrite Equation (6.5) as Y =μ0+(μ1−μ0)D+{Dυ1+(1−D)υ0}. (6.6) It should be clear that the error term now appears very much like the definition of Y presentedearlierasDY1+(1−D)Y0inEquation(2.2).JustasY switchesbetweenY1 andY0asafunctionofD,theerrortermswitchesbetweenυ1andυ0asafunctionofD.\nGiventhatυ1andυ0canbeinterpretedasY1andY0centeredaroundtheirrespective population-level expectations E[Y1] and E[Y0], this should not be surprising.\nEven so, few presentations of regression characterize the error term of a bivariate regression in this way. Some notable exceptions do exist. The connection is made to the counterfactual tradition by specifying Equation (6.3) as Y =α+δD+ε (D), (6.7) where the error term ε (D) is considered to be an entirely different random variable for each value of D (see Pratt and Schlaifer 1988). Consequently, the error term ε in Equation(6.3)switchesbetweenε andε inEquation(6.7)depending onwhether (1) (0) D is equal to 1 or 0.12 6.2.3 Regression as Adjustment for Otherwise Omitted Variables The basic strategy behind regressionanalysis as an adjustment technique to estimate acausaleffectistoaddasufficientsetof“controlvariables”tothebivariateregression in Equation (6.3). The goal is to break a correlation between the treatment variable 12This is the same approach taken by Freedman (see Berk 2004; Freedman 2005), and he refers to Equation (6.7) as a response schedule. See also the discussion of Sobel (1995). For a continuous variable,Garen(1984)notesthattherewouldbeaninfinitenumberoferrorterms(seehisdiscussion ofhisequation10).\nε∗ X D Y Figure6.2 A causal graph for a regression equation in which the causal effect of D on Y is identified by conditioning on X.\nD and the error term ε, as in ∗ Y =α+δD+Xβ+ε , (6.8) where X represents one or more variables, β is a coefficient (or a conformable vector of coefficients if X represents more than one variable), ε∗ is a residualized version of the original error term ε from Equation (6.3), and all else is as defined for Equation (6.3).\nForthemultipleregressionanalogtotheleastsquaresbivariateregressionestimator δˆ OLS,bivariate inEquation(6.4),theobserveddatavaluesdi andxi areembeddedinan all-encompassing Q matrix, which is N × K, where N is the number of respondents and K is the number of variables in X plus 2 (one for the constant and one for the treatment variable D). The OLS estimator for the parameters in Equation (6.8) is then written in matrix form as δˆ OLS,multiple≡(Q(cid:2) Q)−1Q(cid:2) y, (6.9) where y is an N × 1 vector for the observed outcomes yi. As all regressiontextbooks show, there is nothing magical about these least squares computations, even though the matrix representation may appear unfamiliar to some readers. OLS regression is equivalentto the followingthree-stepregressionprocedurewith referenceto Equation (6.8) – and without reference to the perhaps overly compact Equation (6.9): 1. Regress yi on xi and calculate y i∗=yi−yˆi; 2. Regress di on xi and calculate d∗ =di−dˆ i; i 3. Regress y∗ on d∗.\ni i Theregressioncoefficientond∗ yieldedbystep3isthe OLSestimate ofδ inEquation i (6.8), which is typically declaredconsistent and unbiased for the true value of δ if the correlation between D and ε∗ is assumed to be equal to zero. Thus, in this simple example, OLS regression is equivalent to estimating the relationship between residu- alized versions of Y and D from which their common dependence on other variables in X has been “subtracted out.” Even though the variables in X might be labeled control variables in a regression analysis of a causal effect, this label expresses the intent rather than the outcome of their utilization. The goalof such a regressionadjustment strategy is to find variables in X that can be used to redraw the graph in Figure 6.1(b) as the causal graph in Figure 6.2. If this can be done, then one can condition on X in order to consistently estimatethecausaleffectofDonY becauseX blockstheonlyback-doorpathbetween D and Y.\nIfDisuncorrelatedwithε∗ (i.e.,theerrortermnetofadjustmentforX),thenleast squares regression yields an estimate that is ostensibly freed of the bias generated by the correlation of the treatment D with the error term ε in Equation (6.3). However, even in this case some complications remain when one invokes the potential outcome model.\nFirst,if oneassumesthatδ is truly constantacrossindividuals (i.e.,that y1−y0 is i i equal to the same constant for all individuals i), then the OLS estimate is consistent andunbiasedforδ andfor(μ1−μ0).If,however,y1−y0 isnotconstant,thentheOLS i i estimate represents a conditional-variance-weightedestimate of the underlying causal effectsofindividuals,δi,inwhichtheweightsareafunctionoftheconditionalvariance of D (see Angrist 1998 and Angrist and Pischke 2009, as well as our explanation of thisresultinthe nextsection).Undertheseconditions,theOLSestimateisconsistent and unbiased and for this particular weighted average, which is usually not a causal parameter of primary interest.\nSecond,notethattheresidualizederrorterm,ε∗,inEquation(6.8)isnotequivalent to either ε fromEquation(6.3) or to the multiparterror term {υ0+D(υ1−υ0)} from Equation (6.5). Rather, it is defined by whatever adjustment occurs within Equation (6.8), as represented by the term Xβ. Consequently, the residualized error term ε∗ cannot be interpreted independently of decisions about how to specify the vector of adjustmentvariablesinX,andthiscanmakeitdifficulttodefinewhenanetcovariance between D and ε∗ can be assumed to be zero.\nWeexplainthesetwocomplicationsandtheirimportantimplicationsinthefollow- ingsectionsofthis chapterandthenext, whereweconsideravarietyofexamplesthat demonstrate the connections between matching and regression estimators of causal effects. Before developing these explanations, however, we conclude this section with two final small-N examples that demonstrate how the regressionadjustment strategy does and does not work.\nTable 6.4 presents two six-person examples. For both examples, a regression of Y on D yields a biased estimate of the true ATE. And, in fact, both examples yield the same biased estimate because the observedvalues yi and di are the same for both examples.Moreover,anadjustmentvariableX isalsoavailableforbothexamples,and its observed values xi have the same associations with the observed values yi and di forbothexamples.Buttheunderlyingpotentialoutcomesdiffersubstantiallybetween the two examples. These differences render regression adjustment by X effective for only the first example.\nFor the example in the first panel, a regressionof Y on D would yield an estimate of the coefficient for D of 11.67, which is an upwardly biased estimate of the true average causal effect of 10. The bias arises because the correlation between the error term in the last column and the realized values for di is not zero but is instead .33.\nFortheexampleinthesecondpanel,aregressionofY onDwouldyieldanestimate of the coefficient for D of 11.67 because the values for yi and di are exactly the same as for the example in the first panel. Moreover, this estimate is also upwardly biased because the error term in the last column is positively correlated with the realized Table 6.4 Two Six-PersonExamples in Which Regression Adjustment Is Differentially Effective Regression adjustment with X generates an unbiased estimate for D y i1 y i0 υ i1 υ i0 yi di xi υ i0+di(υ1 i−υ0 i) In treatment group 20 10 2.5 2.5 20 1 1 2.5 In treatment group 20 10 2.5 2.5 20 1 1 2.5 In treatment group 15 5 −2.5 −2.5 15 1 0 −2.5 In control group 20 10 2.5 2.5 10 0 1 2.5 In control group 15 5 −2.5 −2.5 5 0 0 −2.5 In control group 15 5 −2.5 −2.5 5 0 0 −2.5 Regression adjustment with X does not generate an unbiased estimate for D y i1 y i0 υ i1 υ i0 yi di xi υ i0+di(υ1 i−υ0 i) In treatment group 20 10 2.83 2.5 20 1 1 2.83 In treatment group 20 10 2.83 2.5 20 1 1 2.83 In treatment group 15 5 −2.17 −2.5 15 1 0 −2.17 In control group 18 10 .83 2.5 10 0 1 2.5 In control group 15 5 −2.17 −2.5 5 0 0 −2.5 In control group 15 5 −2.17 −2.5 5 0 0 −2.5 values of di. However, here the patterns are more complex. The underlying potential outcomes are different, and individual-level heterogeneity of the causal effect is now present. One member of the control group has an individual-level treatment effect of only 8, and as a result the true ATE is only 9.67. Consequently, the same bivariate regressioncoefficientof11.67hasalargerupwardbiasinthissecondexample,andthe correlation between the values of di and the error term in the last column is now .39 rather than .33.\nThis underlying difference in potential outcomes also has consequences for the capacity of regression adjustment to effectively generate unbiased estimates of the ATE. This is easiest to see by rearranging the rows in Table 6.4 for each of the two examples based on the values of X for each individual, as in Table 6.5. For the first example,thevaluesofdiareuncorrelatedwiththeerrortermwithinsubsetsofindivid- ualsdefinedbythetwovaluesofX.Incontrast,forthesecondexample,thevaluesofdi remain positively correlated with the error term within subsets of individuals defined by the two values of X. Thus, conditioning on X breaks the correlation between D and the error term in the first example but not in the second example. Because the observeddata are the same for both examples, this difference is entirely a function of the underlying potential outcomes that generate the data.\nTable 6.5 A Rearrangementof the Example in Table 6.4 That Shows How RegressionAdjustment Is Differentially Effective Regression adjustment with X generates an unbiased estimate for D y i1 y i0 υ i1 υ i0 yi di xi υ i0+di(υ1 i−υ0 i) For thosewith X=1 In treatment group 20 10 2.5 2.5 20 1 1 2.5 In treatment group 20 10 2.5 2.5 20 1 1 2.5 In control group 20 10 2.5 2.5 10 0 1 2.5 For thosewith X=0 In treatment group 15 5 −2.5 −2.5 15 1 0 −2.5 In control group 15 5 −2.5 −2.5 5 0 0 −2.5 In control group 15 5 −2.5 −2.5 5 0 0 −2.5 Regression adjustment with X does not generate an unbiased estimate for D y i1 y i0 υ i1 υ i0 yi di xi υ i0+di(υ1 i−υ0 i) For thosewith X=1 In treatment group 20 10 2.83 2.5 20 1 1 2.83 In treatment group 20 10 2.83 2.5 20 1 1 2.83 In control group 18 10 .83 2.5 10 0 1 2.5 For thosewith X=0 In treatment group 15 5 −2.17 −2.5 15 1 0 −2.17 In control group 15 5 −2.17 −2.5 5 0 0 −2.5 In control group 15 5 −2.17 −2.5 5 0 0 −2.5 This example demonstrates an important conceptual point. Recall that the basic strategy behind regressionanalysis as an adjustment technique is to estimate ∗ Y =α+δD+Xβ+ε , where X represents one or more control variables, β is a coefficient (or a conformable vector of coefficients if X represents more than one variable), and ε∗ is a residualized versionofthe originalerrortermεfromEquation(6.3); seeourearlierpresentationof Equation (6.8). The literature on regressionoften states that an estimated coefficient δˆfromthis regressionequationis consistentandunbiasedfor the averagecausaleffect if ε∗ is uncorrelated with D. But, because the specific definition of ε∗ is conditional on the specification of X, many researchersfind this requirementof a zero correlation difficult to interpret and hence difficult to evaluate.\nThe crux of the idea, however, can be understood without reference to the error term ε∗ but rather with reference to the simpler and (as we have argued in Section 6.2.2)more clearly defined errorterm υ0+D(υ1−υ0) fromEquation(6.5) or, equiva- lently,Dυ1+(1−D)υ0 fromEquation(6.6). RegressionadjustmentbyX inEquation (6.8) will yield a consistent and unbiased estimate of the ATE when 1. D is mean independent of (and therefore uncorrelatedwith) υ0+D(υ1−υ0) for each subset of respondents identified by distinct values on the variables in X, 2. the causal effect of D does not vary with X, and 3. a fully flexible parameterization of X is used.\nConsidertherelationshipbetweenthissetofconditionsandwhatwasdescribedinSec- tion4.3.1asanassumptionthattreatmentassignmentisignorable.Switchingnotation from S to X in Equation (4.4) results in (Y0,Y1) ⊥⊥ D | X, (6.10) where,again,thesymbol⊥⊥denotesindependence.Now,rewritetheassumption,devi- ating Y0 and Y1 from their population-level expectations: (υ0,υ1) ⊥⊥ D | X. (6.11) This switch from(Y0,Y1) to (υ0,υ1) does not changethe assumption,at leastinsofar as it is relevant here (because we have defined the individual-level causal effect as a linear difference, because the expectation operator is linear, and because E[Y0] and E[Y1] do not depend on who is in the treatment state and who is in the control state). Consequently, ignorability of treatment assignment can be defined only with respectto individual-leveldeparturesfromthe true averagepotential outcomesacross all members of the population under the assumptions already introduced.\nGiven that an assumption of ignorable treatment assignment can be written as Equation (6.11), the connections between this assumption and the set of conditions thatwehavesaidjustifyaregressionestimatorasconsistentandunbiasedfortheATE canbeexplored.Twoimportantpointsshouldbenoted.First,iftreatmentassignment is ignorable, as defined in Equation (6.11), then an estimator that conditions fully on allvaluesofX existsthatwillyieldaconsistentandunbiasedestimateoftheATE(and that can be implemented in practice if the sample size is large enough). For reasons we will explain in the next section, a regression estimator with dummy variables for all but one categories of X will only be the appropriate estimator if, in addition, our number 2 just above also holds: the causal effect of D does not vary with X. Second, ignorabilitystipulatesfullindependence.Instead,foroursetofconditions,υ0 andυ1 – aswellasfunctionsofthem,suchasυ0+D(υ1−υ0)–mustonlybemeanindependent of D conditional on X, not fully independent of D conditional on X.\nFinally, we shouldnote that our three conditions are not the only ones that would establishleastsquaresestimatorsasconsistentandunbiasedfortheATE,buttheyare the most common ones that would apply in most research situations.13 Our point in 13For example, the second condition can be dropped if the heterogeneity of the causal effect is modeled as a function of X (i.e., the parameterization is fully saturated in both D and X). In this case, however, regression then becomes a way of enacting a stratification of the data, as for the matchingtechniques presentedinChapter 5.\nlayingoutthese conditionsis notto providea rigidguideline applicableto alltypes of regressionmodels in all situations but instead to show why the earlier statement that “ε∗ must be uncorrelated with D” is insufficiently articulated from a counterfactual perspective.\nA larger point of this section, however, is that much of the received wisdom on regression modeling breaks down in the presence of individual-level heterogeneity of a causal effect, as would be present in general when causal effects are defined with reference to underlying potential outcomes tied to well-defined causal states. In the nextsection,webegintoexplainthesecomplicationsmoresystematically,startingfrom the assumption, as in prior chapters, that causal effects are inherently heterogeneous and likely to vary systematically between those in the treatment and control groups.\nBeginningwiththenextsectionandcontinuinginChapter7onweightedregression,we then present the connections among regression, matching, and stratification, building directly on our presentation of matching in Chapter 5.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#regression-as-conditional-variance-weighted-matching",
    "href": "extracted/Counterfactuals and Causal Inference.html#regression-as-conditional-variance-weighted-matching",
    "title": "Counterfaturals and Causal Inference",
    "section": "6.3 Regression as Conditional-Variance-Weighted Matching",
    "text": "6.3 Regression as Conditional-Variance-Weighted Matching\nInthissection,wereturntothedemonstrationsutilizedtoexplainmatchingestimators\nin Chapter 5. Our goal is to show why matching routines and least squares regression yield different results, even though a researcher is attempting to adjust for the same set of variables.\nWe first show why least squares regression can yield misleading causal effect esti- mates in the presence of individual-level heterogeneity of causal effects, even if the only variable that needs to be adjusted for is given a fully flexible coding (i.e., when the adjustment variable is parameterized with a dummy variable for each of its val- ues, save one for the reference category).14 In these cases, least squares estimators implicitly invokeconditional-varianceweighting ofindividual-level causal effects. This weighting scheme generates a conditional-variance-weighted estimate of the average causaleffect,whichisnotanaveragecausaleffectthatisoftenofanyinherentinterest to a researcher.15 Angrist (1998) provides a more formal explanation of the following results, which is then placed in the context of a larger class of models in Angrist and Krueger (1999) and Angrist and Pischke (2009).\n14Whenwewriteofafullyflexiblecodingofavariable,wearereferringtoadummyvariablecoding ofthatvariableonly(i.e.,onedummyforatwo-categoryvariable,twodummiesforathree-category variable, and so on). As we will discuss later, a saturated model entails a fully flexible coding of each variableas well as all interactions between the dummy variables of each them. For the models discussed in this section, a saturated model would include interactions between the causal variable D andeachdummyvariableforallbutoneofthevaluesofS.Foramodelwithonlyafullyflexible codingofS,theseinteractions areleftout.\n15Itcouldbeofinteresttoaresearcherwhoseeksaminimum-varianceestimateandwhohasreason tobelievethattheinconsistencyandbiasoftheregressionestimateismodest.Wediscussthispoint later, but we hope to show that most applied researchers have good reason to want consistent and unbiasedestimatesratherthanminimummean-squared-errorestimatesthatremaininconsistentand biased.\nRegression Demonstration 2 Reconsider Regression Demonstration 1 (see page 189), but now step back from the cautious mindset of the fictitious descriptively oriented researcher. Suppose that a causality-orientedresearcher had performed the same exercise and obtained the same results for the regressionmodel reported above in Equation (6.2): Yˆ =1.86+2.75(D)+3.76(S2)+8.92(S3). (6.12) WeknowfromMatchingDemonstration1(seepage145),onwhichRegressionDemon- stration1isbased,thatforthishypotheticalexamplethe ATTis3,the averagetreat- ment effect for the controls (ATC) is 2.4, and the unconditional ATE is 2.64. If the causality-orientedresearcherweretodeclarethatthe coefficienton D of2.75inEqua- tion(6.12)isagoodestimateofthecausaleffectofD onY,thentheresearcherwould be incautious but not appreciably incorrect. The value of 2.75 is indeed close to the true ATE of 2.64, and we know from the setup of Regression Demonstration 1 that the variable S continues to serve as a perfect stratifying variable, as defined earlier.16 Thus, if the researcher were to state that the regression model in Equation (6.12) statistically controls for the common effect of S on both D and Y, as in Equation (6.8), where S is specified as the sole element of X but as two dummy variables S2 andS3,thentheresearcheris nothorriblyoffthe mark.The researcherhasofferedan adjustment for S and gotten close to the true ATE.\nUnfortunately, the closeness of the estimate to the true ATE is not a general fea- ture of this type of a regression estimator. Under this particular specification of the regressionequation, the OLS estimator yields precisely the value of 2.75 in an infinite sample as the sum of sample analogs to three terms: Var[D|S=1]Pr[S=1] (cid:12) {E[Y|D=1,S=1]−E[Y|D=0,S=1]} (6.13) Var[D|S=s]Pr[S=s] S Var[D|S=2]Pr[S=2] + (cid:12) {E[Y|D=1,S=2]−E[Y|D=0,S=2]} Var[D|S=s]Pr[S=s] S Var[D|S=3]Pr[S=3] + (cid:12) {E[Y|D=1,S=3]−E[Y|D=0,S=3]}.\nVar[D|S=s]Pr[S=s] S Thesethreetermsarenotascomplicatedastheymayappear.First,notethatthe dif- ferences in the braces on the right-hand side of each term are simply the 16Moreover,S satisfiestheback-door criterionbyconstruction. However, thisdoesnotimplythat everyconditioningestimatorwilldeliverconsistentandunbiasedestimatesoftheATT,ATC,orATE thatcouldbecalculatednonparametricallyinasufficientlylargesample.Inthiscase,asweshowin thissection,theleastsquaresestimatorintroducesparametricconstraintsthatdeliveranalternative averagecausaleffect. Theback-doorcriteriongivesacorrectresult–acausalinferenceofsometype is indeed warranted by conditioning via a regression model on variables that satisfy the back-door criterion – but the causal effect estimate that is produced by the regression estimator is not one of theaveragecausaleffects thattheanalysttypicallywants.\nstratum-specific differences in the outcomes, which in this case are E[Y|D=1,S=1]−E[Y|D=0,S=1]=4−2, (6.14) E[Y|D=1,S=2]−E[Y|D=0,S=2]=8−6, (6.15) E[Y|D=1,S=3]−E[Y|D=0,S=3]=14−10. (6.16) The left-hand portion of each term is then just a weight, exactly analogous to the stratum-specific weights that were used for Matching Demonstration 1 to average the stratum-specific causal effect estimates in various ways to obtain consistent and unbiased estimates of the ATE, ATT, and ATC. But, rather than use the marginal distribution of S, Pr[S], or the two conditional distributions of S, Pr[S|D=1] and Pr[S|D=0], a different set of weights is implicitly invoked by the least squares oper- ation. In this case, the weights are composed of three pieces: (1) the variance of the treatment variable within each stratum, Var[D|S=s], (2) the marginal probability of S for eachstratum, Pr[S=s], and (3) a summation of the product of these two terms across S so that the three weights sum to 1.\nAccordingly, the only new piece of this estimator that was not introduced and examined for Matching Demonstration 1 is the conditional variance of the treatment, Var[D|S =s]. Recall that the treatment variable is distributed within each stratum solely as a function of the stratum-specific propensity score, Pr[D|S=s]. Thus, the treatmentvariableis aBernoullidistributed randomvariablewithineachstratum.As can be found in any handbook of statistics, the variance of a Bernoulli distributed randomvariableisp(1−p),wherepistheBernoulliprobabilityofsuccess(inthiscase D equal to 1) instead of failure (in this case D equal to 0). Accordingly, the expected varianceofthewithin-stratumtreatmentvariableDis(Pr[D|S=s])(1−Pr[D|S=s]).\nForthisexample,theconditionalvariances,Var[D|S=s],contributetothenumer- ator of each weight as follows: (cid:21)(cid:22) (cid:23)(cid:22) (cid:23)(cid:24) .08 .08 Var[D|S=1]Pr[S=1]= 1− (.08+.36), (6.17) .08+.36 .08+.36 (cid:21)(cid:22) (cid:23)(cid:22) (cid:23)(cid:24) .12 .12 Var[D|S=2]Pr[S=2]= 1− (.12+.12), (6.18) .12+.12 .12+.12 (cid:21)(cid:22) (cid:23)(cid:22) (cid:23)(cid:24) .2 .2 Var[D|S=3]Pr[S=3]= 1− (.2+.12). (6.19) .2+.12 .2+.12 Thetermsinbracketsontheright-handsidesofEquations(6.17)–(6.19)areVar[D|S= 1], Var[D|S=2], and Var[D|S=3]. The terms in the last set of parentheses on the right-hand sides of Equations (6.17)–(6.19) are the marginal probability of S for each stratum, Pr[S=1],(cid:25)(cid:16)Pr[S=2(cid:17)],(cid:16)and Pr[S=(cid:17)(cid:26)3]. For example, for the stratum with S= 1, Var[D|S =1]= .08 1− .08 and Pr[S =1]= (.08+.36). Finally, the .08+.36 .08+.36 denominator of each of the three stratum-specific weights in Equation (6.13) for this exampleisthe sumofEquations(6.17)–(6.19).Thedenominatoris constantacrossall three weights and scales the weights so that they sum to 1.\nWith an understanding of the implicit stratum-specific weights of least squares regression, the regression estimator can be seen clearly as an estimator for the ATE but with supplemental conditional-varianceweighting.Weighting is indeed performed withrespecttothemarginaldistributionofindividualsacrossstrata,asfortheATEin MatchingDemonstration1,butweightingisalso performedwithrespecttothecondi- tionalvariance ofthe treatment variable acrossstrataas well. Thus, net of the weight given to stratum-specific effects solely as a function of Pr[S], the conditional-variance terms give more weight to stratum-specific causal effects in strata with propensity scores close to .5 (where Var[D|S] approachesits maximum of .5×.5) and less weight to stratum-specific causaleffects in stratawith propensity scoresclose to either 0 or1 (where Var[D|S] approaches its minimum of 0×1 or 1×0).\nWhy would the OLS estimator implicitly invoke conditional-variance weighting as a supplement to weighting simply by the marginal distribution of S? OLS is a minimum-variance-based estimator of the parameter of interest. As a result, it gives more weight to stratum-specific effects with the lowest expected variance, and the expectedvarianceof eachstratum-specificeffect is aninversefunction ofthe stratum- specific variance of the treatment variable D. Thus, if the two pieces of the weight- ing scheme are not aligned (i.e., the propensity score is close to 0 or 1 for strata that have high total probability mass but close to .5 for strata with low probabil- ity mass), then a regression estimator of this form, even under a fully flexible cod- ing of S, can yield estimates that are far from the true ATE even in an infinite sample.\nTo see the effects that supplemental weighting by the conditional variance of the treatmentcanhaveonaregressionestimate,weconsideralternativejointdistributions for S and D, which we then impose on the setup for Matching Demonstration 1 and Regression Demonstration 1. In particular, the values of E[Y0|S,D], E[Y1|S,D], and E[Y|S,D] in the final three panels of Table 6.1 again obtain, such that S continues to offer a perfect stratification of the data. Now, however, we assume two different joint distributions of S and D in two variants reported in Table 6.6. For these two alternative joint distributions of S and D, the marginal distribution of S remains the sameas for Table 6.1: Pr[S=1]=.44,Pr[S=2]=.24,and Pr[S=3]=.32.As a result, the unconditional ATE is the same for both variants of the joint distribution of S and D depicted in Table 6.6, and it matches the unconditional ATE for the original demonstration represented fully in Table 6.1. In particular, the same distribution of stratum-specific causal effects results in an unconditional ATE of 2.64. The difference representedby each variant of the joint distributions in Table 6.6 is in the propensity score for each stratum of S, which generates an alternative marginal distribution for D and thus alternative true ATTs and ATCs (and, as we will soon see, alternative regressionestimates from the same specification).\nFor Variant I in Table 6.6, those with S equal to 1 or 2 are much less likely to be in the treatment group, and those with S equal to 3 are now only equally likely to be in the treatment group and the control group. As a result, the marginal distribution of D is now different, with Pr[D=0]=.76 and Pr[D=1]=.24. The ATT is now 3.33 whereas the ATC is 2.42. Both of these effects are larger than was the case for Table 6.1 because (1) a greater proportion of those in the control group have S =3 (i.e., .16 .12), &gt; (2) a greater proportion of those in the treatment group have S=3 (i.e., .76 .6 .16&gt;.2), and (3) those with S=3 gain the most from the treatment.\n.24 .4 Table 6.6 The Joint Probability Distribution for Two Variants of the Stratifying and Treatment Variables in Prior Regression Demonstration 1 Joint probability distribution of S and D Control group: D=0 Treatment group: D=1 Variant I S=1 Pr[S=1,D=0]=.40 Pr[S=1,D=1]=.04 S=2 Pr[S=2,D=0]=.20 Pr[S=2,D=1]=.04 S=3 Pr[S=3,D=0]=.16 Pr[S=3,D=1]=.16 Variant II S=1 Pr[S=1,D=0]=.40 Pr[S=1,D=1]=.04 S=2 Pr[S=2,D=0]=.12 Pr[S=2,D=1]=.12 S=3 Pr[S=3,D=0]=.03 Pr[S=3,D=1]=.29 ForVariantII,thosewithS equalto1arestillveryunlikelytobeinthetreatment group,butthosewithS equalto2areagainequallylikelytobeinthetreatmentgroup.\nIn addition, those with S equalto 3 are now very likely to be in the treatment group.\nAs aresult,the marginaldistributionof D isnowdifferentagain,withPr[D=0]=.55 andPr[D=1]=.45,andthe ATT isnow 3.29,whereasthe ATC is2.11.Bothofthese are smaller than for Variant I because a smaller proportion of both the treatment group and the control group have S=3.\nFor these two variants of the joint distribution of S and D, we have examples in whichtheunconditionalATEisthesameasitwasforRegressionDemonstration1,but the underlying ATT and ATC differ considerably. Does the reestimation of Equation (6.12) for these variants of the example still generate an estimate for the coefficient on D that is (1) relatively close to the true unconditional ATE and (2) closer to the unconditional ATE than either the ATT or the ATC? For Variant I, the regressionmodel yields Yˆ =1.90+3.07(D)+3.92(S2)+8.56(S3) (6.20) foraninfinite sample.Inthiscase,thecoefficientof3.07onD isnotparticularlyclose to the unconditionalATE of2.64,andinfactitis closertothe ATT of3.33(although still not particularly close). For Variant II, the regressionmodel yields Yˆ =1.96+2.44(D)+3.82(S2)+9.45(S3). (6.21) In this case, the coefficient of 2.44 on D is closer to the unconditional ATE of 2.64, but not as close as was the case for Equation(6.12) when applied to the original data specifiedforRegressionDemonstration1.ItisnowrelativelyclosertotheATC,which is 2.11 (although, again, still not particularly close).\nFor Variant I, the regression estimator is weighted more toward the stratum with S=3, for which the propensity score is .5. For this stratum, the causal effect is 4. For Variant II, the regression estimator is weighted more toward the stratum with S=2, for which the propensity score is .5. And, for this stratum, the causal effect is 2.17 What is the implication of these alternative setups of the same basic demonstra- tion?Giventhat the unconditional ATE is the same for all three joint distributions of S andD,itwouldbe unwisefortheincautiousresearchertobelievethatthis sortofa regressionspecificationwillprovideareliablycloseestimatetotheunconditionalATE, the ATT, or the ATC when there is reason to believe that these three average causal effects differ because of individual-level heterogeneity. The regressionestimate will be weightedtowardstratum-specificeffects forwhichthepropensityscoreisclosestto.5, net of all else.\nIn general, regression models do not offer consistent or unbiased estimates of the ATE when causal effect heterogeneity is present, even when a fully flexible coding is given to the only necessary adjustment variable(s). Regression estimators with fully flexible codings of the adjustment variables do provide consistent and unbiased esti- matesoftheATEifeither(1)thetruepropensityscoredoesnotdifferbystrataor(2) theaveragestratum-specificcausaleffectdoesnotvarybystrata.18Thefirstcondition would almost never be true (because, if it were, one would not even think to adjust for S because it is already independent of D). And the second condition is probably not true in most applications, because rarely are investigators willing to assert that all consequential heterogeneity of a causal effect has been explicitly modeled.\nInstead, for this type of a regressionspecification, in which all elements of a set of perfect stratifying variables S are given fully flexible codings (i.e., a dummy variable coding for all but one of the possible combinations of the values for the variables in S), the OLS estimator δˆ OLS,multiple in Equation (6.9) is equal to (cid:6) 1 VarN[di|si=s] PrN[si=s]{EN[yi|di=1,si=s]−EN[yi|di=0,si=s]} (6.22) c s in a sample of size N. Here, c is a scaling constant equal to the sum (over all combi- nations of values s of S) of the terms VarN[di|si=s]PrN[si=s].\nTherearetwoadditionalpointstoemphasize.First,theweightingschemeforstrat- ifiedestimatesinEquation(6.22)appliesonlywhenthefullyflexibleparameterization of S is specified. Under a constrained specification of S – e.g., in which some ele- ments of S are constrained to have linear effects, as in Equation (6.1) – the weighting scheme is more complex. The weights remain a function of the marginal distribution of S and the stratum-specific conditional variance of D, but the specific form of each of these components becomes conditional on the specification of the regression model 17Recallthat,becausebyconstructionthemarginaldistributionofS isthesameforallthreejoint distributionsofSandD,thePr[S=s]piecesoftheweightsremainthesameforallthreealternatives.\nThus, the differences between the regression estimates are produced entirely by differences in the Var[D|S=s]piecesoftheweights.\n18Asaby-productofeithercondition,theATEmustbeequaltotheATTandtheATC.Thus,the regressionestimatorwouldbeconsistentandunbiasedforbothoftheseaswell.\n(seesection2.3.1ofAngristandKrueger1999).Thebasicintuitionhereisthatalinear constraintona variablein S inaregressionmodelentailsanimplicit assumptionthat the underlying propensity scores are also linear in the values of S.19 Second,regressioncanmakeitalltooeasytooverlookthesamesortoffundamental overlap problems that were examined for Matching Demonstration 2 (see page 148).\nRegression will implicitly drop strata for which the propensity score is either 0 or 1 in the course of forming its weighted average by Equation (6.22). As a result, a researcherwhointerpretsaregressionresultasadecentestimateoftheATE,butwith supplemental conditional-variance weighting, may be entirely wrong. No meaningful averagecausal effect may exist in the population. This second point is best explained by the following demonstration.\n19For a binary causal variable D, a many-valued variable S that is treated as an interval-scaled variable,andaregressionequation Yˆ=αˆ+δˆ(D)+βˆ(S), theOLSestimatorδˆisequalto (cid:2) 1 V(cid:3) arN[dˆ i|s i=s]P(cid:4) rN[s i=s]{E N[y i|d i=1,s i=s]−E N[y i|d i=0,s i=s]} l s in a sample of size N, where l is a scaling constant equal to the sum of V(cid:3) arN[dˆ i|s i=s] P(cid:4) rN[s i=s] overallsofS.\nThe distinction between V(cid:3) arN[dˆ i|s i=s] P(cid:4) rN[s i=s] and VarN[d i|s i=s] PrN[s i=s] in the main text results from a constraint on the propensity score that is implicit in the regression equation. In specifyingS as aninterval-scaled variable, leastsquares implicitlyassumes that the true propensity scorePr[D|S]islinearinS.Asaresult,thefirstportionofthestratum-specificweightis V(cid:3) arN[dˆ i|s i=s]≡pˆs(1−pˆs), wherepˆs isequaltothepredictedstratum-specificpropensityscorefromalinearregressionofd i on s i: pˆs=ξˆ+φˆ ss.\nPerhapssomewhatlessclear,thetermP(cid:4) rN[s i=s]isalsoafunctionoftheconstraintonS.P(cid:4) rN[s i= s]isnotsimplythemarginaldistributionofS inthesample,asPrN[s i=s]is.Rather,onemustuse Bayes’ rule to determine the implied marginal distribution of S, given the assumed linearity of the propensityscoreacrosslevelsofS.Rearranging i]=Pr[s i|d i= Pr1 [s] iP ]r[d i=1] Pr[d i=1|s as Pr[s i]=Pr[s i P|d ri [d= i1 =]P 1|r s[d i]i=1] , andthensubstitutingpˆs forPr[d i=1|s i],wethenfindthat P(cid:4) rN[s i=s]=PrN[s i=s|d i p= ˆs1]PrN[d i=1] .\nThetermsPrN[s i=s|d i=1]andPrN[d i=1]are,however, unaffected bythe linearityconstrainton thepropensityscore.TheyaresimplythetrueconditionalprobabilityofS equaltosgivenD equal todaswellasthemarginalprobabilityofD equaltodforasampleofsizeN.\nNotethat, ifthetruepropensityscoreislinearinS,thenthe weightingschemehereisequivalent totheoneinthemaintext.\nRegression Demonstration 3 ReconsiderthehypotheticalexamplepresentedasMatchingDemonstration2(seepage 148), which is reproduced in Table 6.7. The assumed relationships that generate the hypotheticaldataforthisdemonstrationareverysimilartothosewehavejustconsid- ered.However,in this caseno individual for whomS is equalto 1in the populationis everexposedtothetreatmentbecausePr[S=1,D=1]=0andPr[S=1,D=0]=.4.As aresult,the population, andanysamplefromit, doesnotinclude anindividual inthe treatmentgroupwith si=1.20 Because ofthis structuralzeroin the joint distribution ofS andD,thethreeconditionalexpectations,E[Y0|S=1,D=0],E[Y1|S=1,D=0], andE[Y|S=1,D=0],areproperlyregardedasill-definedandhenceareomittedfrom the last three panels of Table 6.7.\nAsshownforMatchingDemonstration2,thenaiveestimatorcanstillbecalculated and will be equal to 8.05 in an infinite sample. Moreover, the ATT can be estimated Table 6.7 The Joint Probability Distribution and Conditional Population Expectations for Regression Demonstration 3 Joint probability distribution of S and D Control group: D=0 Treatment group: D=1 S=1 Pr[S=1,D=0]=.4 Pr[S=1,D=1]=0 S=2 Pr[S=2,D=0]=.1 Pr[S=2,D=1]=.13 S=3 Pr[S=3,D=0]=.1 Pr[S=3,D=1]=.27 Potential outcomes underthecontrol state S=1 E[Y0|S=1,D=0]=2 S=2 E[Y0|S=2,D=0]=6 E[Y0|S=2,D=1]=6 S=3 E[Y0|S=3,D=0]=10 E[Y0|S=3,D=1]=10 Potential outcomes underthetreatment state S=1 E[Y1|S=1,D=0]=4 S=2 E[Y1|S=2,D=0]=8 E[Y1|S=2,D=1]=8 S=3 E[Y1|S=3,D=0]=14 E[Y1|S=3,D=1]=14 Observed outcomes S=1 E[Y|S=1,D=0]=2 S=2 E[Y|S=2,D=0]=6 E[Y|S=2,D=1]=8 S=3 E[Y|S=3,D=0]=10 E[Y|S=3,D=1]=14 20Again, recall that we assume no measurement error in general in this book. In the presence of measurementerror,someindividualsmightbemisclassifiedandthereforemightshowupinthedata withs i=1andd i=1.\nconsistently as 3.35 by considering only the values for those with S equal to 2 and 3.\nButthereisnowaytoconsistentlyestimatetheATC,andhencenowaytoconsistently estimate the unconditional ATE.\nConsider now the estimated values that would be obtained with data arising from this joint distribution for a regression model specified equivalently as in Equations (6.12), (6.20), and (6.21): Yˆ =2.00+3.13(D)+3.36(S2)+8.64(S3). (6.23) Inthiscase,theOLSestimatorisstillequivalenttoEquation(6.22),whichinaninfinite samplewouldthenbeequaltoEquation(6.13).But,withreferencetoEquation(6.13), note that the weight for the first term, Var[D|S=1]Pr[S=1] (cid:12) , Var[D|S=s]Pr[S=s] S is equal to 0 because Var[D|S=1] is equal to 0 in the population by construction.\nAccordingly, the numerator of the stratum-specific weight is 0, and it enters into the summation of the denominator of the other two stratum-specific weights as 0. As a result, the regression estimator yields a coefficient on D that is 3.13, which is biased downward as an estimate of the ATT and has no relationship with the ill-defined ATE. If interpreted as an estimate of the ATT, but with supplemental conditional- varianceweighting,thenthe coefficientof3.13isinterpretable.Butitcannotbe inter- preted as a meaningful estimate of the ATE in the population once one commits to the potential outcome framework and allows for individual-level heterogeneity of the treatment effect.\nThe importance of this demonstration is only partly revealed in this way of pre- {yi,di,si}N senting the results. Imagine that a researcher simply observes and then i=1 estimates the model in Equation(6.23)withoutfirstconsideringthe jointdistribution ofS andD aspresentedinTable6.7. Itwouldbeentirelyuncleartosucharesearcher thattherearenoindividualsinthesample(orinthepopulation)whosevaluesforboth D and S are 1. Sucha researchermight therefore be led to believe that the coefficient estimate for D is a meaningful estimate of the causal effect of D for all members of the population.\nAlltoooften,regressionmodeling,atleastaspracticedinthesocialsciences,makes ittooeasyforananalysttooverlookfundamentalmismatchesbetweentreatmentand control cases. And, thus, one can obtain ATE estimates with regression techniques even when no meaningful ATE exists.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#regression-as-an-implementation-of-a-perfect-stratification",
    "href": "extracted/Counterfactuals and Causal Inference.html#regression-as-an-implementation-of-a-perfect-stratification",
    "title": "Counterfaturals and Causal Inference",
    "section": "6.4 Regression as an Implementation of a Perfect Stratification",
    "text": "6.4 Regression as an Implementation of a Perfect Stratification\nFor completeness, in this sectionwe make the (perhaps obvious)point that regression\ncanbe usedasatechniquetoexecute aperfectstratification.Ifallcellsofthe implicit full cross-tabulation of the adjustment variables and the causal variable are uniquely parameterized, using a saturated coding of all variables, regression can be used to carry out a perfect stratification of the data.\nConsiderhowtheestimatespresentedinMatchingDemonstration1(seepage145) could have been generated by standard regression routines using a saturated coding ofthe causalvariableandalladjustmentvariables.Alternatively,one couldeffectively estimate the ATE for Regression Demonstrations 1 and 2 (see pages 189 and 207, respectively)byenrichingtheparameterizationoftheregressionmodelthatweshowed earlier does not generate a consistent and unbiased estimate of the ATE.\nFor the data common to these demonstrations, an analyst could specify S as two dummy variables, D as one dummy variable, and include all two-way interactions between S and D. In so doing, the analyst has enacted the same perfect stratification of the data by fitting a model that is saturated in both S and D to all of the cells of the first panel of Table 5.2: Yˆ =2+2(D)+4(S2)+8(S3)+0(D×S2) +2(D×S3). (6.24) Thevaluesofeachofthesixcellsofthepanelareuniquefunctionsofthesixestimated coefficients from the regressionmodel.\nWiththesecoefficients,theanalystcouldthenformdifferenceswithinstratadefined by allvalues of S and then use the marginaldistribution ofS to generatea consistent and unbiased estimate of the ATE (or use the conditional distribution of S given D to obtain consistent and unbiased estimates of the ATT and ATC). Although this last stratum-averaging step is not typically seen as part of a regression estimation strategy,itisnonethelesscompatiblewithit(andnowquiteeasytoimplement,using, for example, the command margins after the command regress in Stata).\nNevertheless, for many applications, such a saturated model may not be possible, andinsomecasesthisimpossibilitymaybemisinterpreted.ForRegressionDemonstra- tion3(seepage213), justpresentedinthelastsection,ifoneweretofittheseemingly saturated model with the same six parameters as in Equation (6.24), the coefficient on D would be dropped by standard software routines. One might then attribute this to the size of the dataset and then instead use a more constrained parameterization, that is, either enter S as a simple linear term interacted with D or instead specify the model in Equation (6.23). These models must then be properly interpreted, and in no case could they be interpreted as yielding consistent and unbiased estimates of the ATE.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#regression-as-supplemental-adjustment-when-matching",
    "href": "extracted/Counterfactuals and Causal Inference.html#regression-as-supplemental-adjustment-when-matching",
    "title": "Counterfaturals and Causal Inference",
    "section": "6.5 Regression as Supplemental Adjustment When Matching",
    "text": "6.5 Regression as Supplemental Adjustment When Matching\nAlthough we have separated our presentation of matching and regression estimators\nacross two chapters for didactic purposes, we have been gradually working our way towardChapter7onweightedregressionwherewewillshowhowmatchingandregres- sion can be used together very effectively. It is appropriate at this point to note that the matching literature has long recognized the utility of parametric regression as a supplemental adjustment technique that can be applied to traditional matching esti- mators in attempts to eliminate remaining within-sample imbalance on the matching variables. In this section, we offer a demonstration of how standard regression tech- niques can be used to supplement matching estimators.\nRegression Demonstration 4 RecallMatchingDemonstration4(seepage171)andconsidernowhowregressioncan be used to supplement a matching algorithm. For Matching Demonstration4, we pre- sented matching estimates of the Catholic school effect on achievement for simulated data. We offered matching estimators under two basic scenarios, first using an incom- plete specification of treatment assignment and then using a complete specification thatincludesacognitiveskillsvariable.Becausebothscenarioslackanadjustmentfor the self-selection dynamic, in which individuals select into the treatment partly as a function of their expected treatment effect, we only attempted to estimate the ATT.\nIn the columns labeled “Unadjusted,” Table 6.8 redisplays the average bias for selectedmatchingestimatorsfromTable5.7,underbothspecificationsofthetreatment Table 6.8 Average Bias Comparisons for Selected Matching Estimates of the ATT from Matching Demonstration 4, With and Without Supplemental RegressionAdjustment for the Assumed Determinants of Treatment Assignment Specification of treatment assignment variables: Incompletespecification Complete specification Method Unadjusted Adjusted Unadjusted Adjusted Nearest-neighbor match: 1 without replacement (MI) 0.75 0.72 0.00 −0.10 1 with replacement (MI) 0.95 0.81 0.19 −0.12 1 with replacement and caliper = .05 SD (MI) 0.98 0.86 0.07 −0.11 5 with replacement (MI) 1.17 0.83 0.50 −0.05 5 with replacement and caliper = .05 SD (MI) 1.19 0.80 0.39 −0.13 Intervalmatch: 10 fixedblocks (MI) 1.68 0.84 1.68 −0.11 Optimal match (MI-opt) 1.28 0.80 0.54 0.07 Genetic match (MI-gen) 0.96 0.80 0.23 −0.07 Coarsened exact match (cem) 1.28 0.86 0.35 −0.08 Notes:SeenotestoTable 5.6forsoftwaredetails.\nassignment variables.21 For the two columns labeled “Adjusted,” the average bias is reportedforthesamematchingestimatorsacrossthesame10datasets,butnowusing a post-match regressionadjustment for the matching variables.\nOverall,Table6.8showsthatsupplementalregressionadjustmentreducestheaver- age bias for nearly all of the matching estimators, which is consistent with the litera- ture. The reductions occur for both the incomplete and complete specifications. This does not imply that for any single sample a supplemental regression adjustment will necessarily reduce bias, but on average such adjustments will reduce the bias that would remain if matching alone were utilized.\nThereasonforthereductionsinbiasshouldbeobvious.Anypost-matchimbalance that remains in the matching variables is likely to have a component that exists as differences in mean values of the matching variables across the treatment and con- trol cases. If we then use a parametric regression model to adjust for the matching variables in the matched datasets, the regression model yields a net estimate of the ATT after a linear adjustment for these lingering mean differences. The conditional- variance weighting property of least squares regression estimators remains, but the consequences of this property for estimates is greatly diminished when regression is usedinthis supplementaryway,after the data havealreadybeenalignedinpursuitof the ATT.\nWe will discuss in Chapter 7 a variety of perspectives that suggest when and why matching and regression should be pursued together. Moving beyond regression as a supplementary procedure, we will show how weighted regression can be used to implement matching estimators, picking up onthe weighting perspective on matching already introduced in Section 5.3.2.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#extensions-and-other-perspectives",
    "href": "extracted/Counterfactuals and Causal Inference.html#extensions-and-other-perspectives",
    "title": "Counterfaturals and Causal Inference",
    "section": "6.6 Extensions and Other Perspectives",
    "text": "6.6 Extensions and Other Perspectives\nInthis chapter,we havefocusedalmostexclusivelyonthe estimationofthe effectofa\nbinarycauseonaninterval-scaledoutcome,andwehaveconsideredonlyleastsquares adjustments. Before carrying on to discuss least squares estimation of the effects of many-valuedcauses,weofcoursemustconcedewhatthereaderissurelyawareof:We have considered only a tiny portion of what falls under the general topic of regression modeling. We have not considered categoricaloutcome variables, time series analysis, nested data structures, variance-component models, and so on. One can gain a full perspective of the types of regression modeling used in just sociology and economics by consulting Agresti(2002),Allison (2009),Arminger et al. (1995),Berk (2004),Fox (2008), Hamilton (1994), Hayashi (2000), Hendry (1995), Long (1997), Powers and Xie (2000), Raudenbush and Bryk (2002), Ruud (2000), Stock and Watson (2007), Treiman (2009), and Wooldridge (2010).\nIn this section, we consider only one modest extension: least squares regression models for many-valuedcauses.This presentationthen leads naturally to a discussion 21Weselected the subsetofthe matchingestimates fromTable5.7based onwhether the software allowedforsupplemental regressionadjustment.\nthat follows of what might be labeled the “all-cause correctspecification” tradition of regressionanalysis.Informedbythedemonstrationsofferedinthischapter,wediscuss the attractiveness of the promise of this alternative perspective but also the implau- sibility of the perspective as a general guide for either causal analysis or regression practice in the social sciences.\n6.6.1 Regression Estimators for Many-Valued Causes We suspect that the vast majority of published regression estimates of causal effects in the social sciences are for causes with more than two values. Accordingly, as in Section 5.5.4 on matching estimators for many-valued causes, we must discuss the additional complexities of analogous regression estimators. We will again, however, restrict attention to an interval-scaled outcome.\nFirst,againrecallthebasicsetupformany-valuedcausesfromSection2.9,inwhich we have a set of J treatment states, a corresponding set of J causalexposure dummy variables,{Dj}J , andacorrespondingsetofJ potentialoutcome randomvariables, j=1 {YDj}J . The treatment received by each individual is Dj(cid:2).\nj=1 How would one estimate the causal effect of such a J-valued cause with regression methods? The first answer should be clear from our presentation in the last section: Because regression can be seen as a form of matching, one can use the same basic strategies outlined for matching estimators of many-valued causes in Section 5.5.4.\nOne could form a series of two-way comparisons between the values of the cause and then model each pairwise causal effect.\nIf the number of causal states is relatively large, then this general strategy is infeasible. Some smoothing acrosspairwise comparisonswould be necessary,either by collapsingsomeoftheJ causalstatesorbyimposinganorderingonthedistributionof the causal effect across the J causal states. The most common parametric restriction would be to assume that the causal effect is linear in j for each individual i. For example, for a set of causal states (such as years of schooling) enumerated by values from1,2,3,toJ,thelinearityassumptionistheassumptionthaty iDj =y iD1+βi(j−1), yDj−yDj−1 which requires that the difference for each individual i be equal to a i i constant βi. In this case, the individual-level causal effect is then a slope βi, rather thanthesimpledifferenceinpotentialoutcomes,δi,specifiedearlierinEquation(2.1).\nThissetupisanalogoustothedose-responsemodelsformatchingestimatorsdiscussed in Section 5.5.4, but it explicitly leaves open the possibility that the dose-response relationship varies across individuals even though it remains linear.\nAngrist and Krueger (1999) show in a very clear example how both a linearity assumption on the individual-specific, dose-response relationship and a fully flexible coding of adjustment variables results in an OLS weighting scheme for the average value of βi in a sample that is even more complex than what we discussed earlier for simple binary causes (see Regression Demonstration 2). A form of conditional- variance weighting is present again, but now the weighting is in multiple dimensions because least squares must calculate average derivatives across the linearly ordered causalvariable(seeAngristandKrueger1999,equation34).Becauseonecannotintu- itively grasp how these weights balance out across all the dimensions of the implicit weighting scheme (at least we cannot do so), Angrist and Krueger help by offering a familiarexample:anOLSestimateofthe averagecausaleffectofanadditionalyearof schoolingonlabormarketearnings,assuminglinearityinyearsofschoolingandusinga fullyflexiblecodingofadjustmentvariablesforage,race,andresidencelocation.They show that, for this example, OLS implicitly gives more weight to the causal effect of shifting from 13 to 14 years of schooling and from 14 to 15 years of schooling than for much more common differences, such as the shift from 11 to 12 years of schooling (primarilybecausethenetconditionalunexplainedvarianceofschoolingisgreatestfor the contrasts between 13 and 14 years and between 14 and 15 years). They also show that,forthisexample,thepiecewiseincreasesinaverageearningshappentobelargest for the years of schooling that OLS systematically weights downward. The result is a least squares estimate under the linearity constraint of .094, which is smaller than the weightedaverageestimate of.144thatone cancalculate by droppingthe linearity constraintandthenaveragingyear-specificestimatesoverthemarginaldistributionof years of schooling.\nFor other examples, the weighting schemes may not generate sufficiently differ- ent estimates because the overall weighting is a complex function of the relationship betweentheunaccountedforvarianceofthecausalvariablewithinstrataoftheadjust- ment variables and the level of nonlinearity of the conditional expectation function.\nBut the general point is clear and should be sobering: Linearity constraints across causal states may lead OLS models to generate nonintuitive (and sometimes mislead- ing) averages of otherwise easily interpretable stratum-specific causal effects.\n6.6.2 The Challenge of Regression Specification In this section, we discuss the considerableappeal ofwhat can be calledthe all-cause, complete-specification tradition of regression analysis. We argue that this orientation is impractical for most of the social sciences, for which theory is too weak and the disciplines too contentious to furnish perfect specifications that can be agreed on. At the same time, we argue that inductive approaches to discovering flawless regression modelsthatrepresentallcausesaremostlyaformofself-deception,eventhoughsome software routines now exist that can prevent the worst forms of abuse.\nConsider first a scenario in which one has a theoretical model that one believes is true. It suggests all of the inputs that determine the outcome of interest, as a set of observable variables, and it is in the form of a specific function that relates all inputs to the outcome. In this case, one can claim to have the correct specification for a regression of the outcome on some function of the variables suggested by the theoretical model. The only remaining challenges are then measurement, sampling, and observation.\nThe weakness of this approach is that critics can claim that the model is not true andhencethattheentailedregressionspecificationiswrong.Fightingoffanysuchcrit- ics with empirical results can then be difficult, given that the regression specification used to generate the empirical results has been called into question.\nIn general, if members of a community of competing researchers assert their own true models and then offer up purportedly flawless regression models, the result may beawarofattritioninwhichnoscientificprogressispossible.Itisthereforenaturalto ask: Can the data generate an all-cause, complete-specification regression model that all competing researchers can jointly adopt? Thefirststepinansweringthisquestionistodeterminewhatanall-cause,complete specification would be, which is sometimes simply labeled a “correct specification.”22 Inhis1978bookSpecification Searches: Ad HocInference with Nonexperimental Data, Edward Leamer lays out the following components of what he labels “The Axiom of Correct Specification”: (a)Thesetofexplanatoryvariablesthatarethoughttodetermine(linearly) the dependent variable must be (1) unique, (2) complete, (3) small in number, and (4) observable.\n\nOther determinants of the dependent variable must have a probability distribution with at most a few unknown parameters.\nAll unknown parameters must be constant. (Leamer 1978:4) But Leamer then immediately undermines the axiom as it applies to observational data analysis in the social sciences: If this axiom were, in fact, accepted, we would find one equation esti- mated for every phenomenon, and we would have books that compiled these estimates published with the same scientific fanfare that accompa- nies estimates of the speed of light or the gravitational constant. Quite thecontrary,weareliterallydelugedwithregressionequations,alloffering to “explain” the same event, and instead of a book of findings we have volumes of competing estimates. (Leamer 1978:4) OnecanquibblewithLeamer’saxiom(e.g.,thatcomponent(a)(3)isnotessentialand so on), but the literature seems to provide abundant support for his conclusion. Few examples of flawless regression models suggested by true theoretical models can be found in the social science literature. One might hope for such success in the future, but the past 50 years of researchdo not give much reason for optimism.\n\nLeamerinsteadarguesthatmostregressionmodelsareproducedbywhathelabels a data-instigated specification search, which he characterizes as a Sherlock Holmes formofinferencewhereinonerefrainsfromdevelopingamodeloranyfirmhypotheses before first considering extensively all the facts of a case. Leamer argues that this approach to variable selection and specification is fraught with potential danger and invalidates traditional notions of inference.\nConsider the example of the Catholic school effect on learning, and in particular the researchof James Colemanand his colleagues. In seeking to estimate the effect of Catholicschoolingonachievement,Colemandidnotdrawacompletespecificationfor 22Theliteraturehasneverclearlysettledonadefinitionthathasachievedconsensus,butLeamer’s is as good as any. Part of the confusion arises from the recognition that a descriptively motivated regressionmodelcanalwaysbedeclaredcorrect,nomatterwhatitsspecificationhappens tobe.\nhisregressionmodelsfromaspecifictheoreticalmodelofhumanlearning.Thisdecision wasnotbecausenosuchmodelsexisted,norbecauseColemanhadnoappreciationfor the needforsuchmodels.He was,incontrast,wellawareofclassicbehavioristmodels of learning (see Bush and Mosteller 1955, 1959) that specified complex alternative mechanisms for sequences of responses to learning trials. Although he appreciated these models, he recognized (see Coleman 1964:38) that they could not be deployed effectively in the complex environments of secondary schooling in the United States, the context of which he had already studied extensively (see Coleman 1961).\nAs a result, Coleman did not specify a learning model that justified the regression modelsthathe andhiscolleaguespresented(seeSørensen1998;SørensenandMorgan 2000).23 Their basic specification strategy was instead to attempt to adjust for a sufficient subset of other causes of learning so that, net of these effects, it could be claimed that Catholic and public school students were sufficiently equivalent. The specific variables that Coleman and his colleagues chose to include in their models were based in part on Coleman’s deep knowledge of what predicts learning in high school(andonecouldarguethatColemanwasthemostknowledgeablesocialscientist on the topic in the world at the time). But he and his colleagues also adopted an empiricalapproach,asindicatedparentheticallyatthe endofthe followingaccountof their selection of adjustment variables: Inordertominimizetheeffectsofdifferencesininitialselectionmasquerad- ing as effects ofdifferences in the sectorsthemselves,achievementsubtests were regressed, by sector and grade, on a larger number of background variables that measure both objective and subjective differences in the home. Some of these subjective differences may not be prior to the stu- dent’s achievement, but may in part be consequences of it, so that there may be an overcompensationfor background differences. It was felt desir- able to do this so as to compensate for possible unmeasured differences in family background;but of course the results may be to artificially depress the resulting levels of background-controlled achievement in Catholic and other private schools. (A few additional background variables were ini- tially included; those that showed no effects beyond the ones listed in the following paragraph were eliminated from the analysis.) (Coleman et al.\n1982:147) Coleman and his colleagues then reported that the final list of variables included 10 they considered “clearly prior” to school sector – including family income, parents’ 23When the 1982 data on seniors became available to supplement the 1980 data on sophomores, Colemanandhiscolleaguesdidmovetowardastrongerfoundationfortheirspecifications,providing an underlying model for the lagged achievement gain regression model that was an outgrowth of Coleman’s early work on Markov chains and his proposals for longitudinal data analysis (Coleman 1964, 1981). InHoffer et al.(1985:89–91), he andhis colleagues showedthat (subject to restrictions on individual heterogeneity) the lagged test score model is a linearized reduced-form model of two underlying rates (learning and forgetting) for the movement between two states (know and don’t know)foreachitemonthecognitivetest.Althoughthemodelisplausible,itisclearlyconstrainedso thatitcanbeestimatedwithsimpleregressiontechniques(seeColeman1981:8–9foranexplanation of his modus operandi in such situations), and this is of course not the sort of constraint that one mustadoptifoneistrulyinterestedinlayingoutthecorrecttheoretical modeloflearning.\neducation, number of siblings, and number of rooms in the home – as well as 7 other variables that they considered “not clearly prior” to school sector – including more than 50 books in the home, owning a pocket calculator, and having a mother who thinks the student should go to college after high school.\nAs so often occurs in causal controversies of public importance, critics found this resulting list inadequate. From the perspective of their critics, Coleman and his col- leagueshadnotprovidedaclearenoughaccountingofwhysomestudentswereobserved in Catholic schools, whereas others were observed in public schools and why levels of learning shouldbe considereda linearfunction of backgroundandthe specific charac- teristics selected. After arguing that more would be known when follow-up data were collectedandtestscoregainsfromsophomoretosenioryearcouldbeanalyzed,Alexan- der and Pallas (1983) argued that Coleman and his colleagues should have searched harder for additional adjustment variables: Failing this [estimating models with pretest and posttest data], another possibilitywouldbetoscoutaboutforadditionalcontrolsthatmightserve as proxies for student input differences that remain after socioeconomic adjustments. One candidate is the student’s curriculum placement in high school. (Alexander and Pallas 1983:171) AlexanderandPallasthenlaidoutarationaleforthisproxyapproach,andtheyoffered modelsthatshowedthatthedifferencesbetweenpublicandprivateschoolsaresmaller after conditioning on type of curriculum.\nAsthisexampleshows,itisoftensimplyunclearhowoneshouldgoaboutselecting asufficientsetofconditioningvariablestoincludeinaregressionequationwhenadopt- ing the “adjustment for all other causes” approach to causal inference. Coleman and colleaguesclearlyincludedsomevariablesthattheybelievedthatperhapstheyshould not have included, and they presumably tossed out some variables that they thought they should perhaps include but that proved to be insufficiently powerful predictors oftestscores.Evenso,AlexanderandPallascriticizedColemanandhis colleaguesfor too little scouting.24 Leamer,asmentionedearlier,wouldcharacterizesuchscoutingasaSherlockHolmes– style, data-driven specification search. Leamer argues that this search strategy turns classical inference on its head: if theories are constructed after having studied the data, it is difficult to establishbyhowmuch,ifatall,thedatafavorthedata-instigatedhypoth- esis. For example, suppose I think that a certain coefficient ought to be positive, and my reaction to the anomalous result of a negative estimate is to find another variable to include in the equation so that the estimate is positive. Have I found evidence that the coefficient is positive? (Leamer 1983:40) 24ContrarytotheforecastsofColemanandhiscritics,afterthe1982datawerereleased,thespecifi- cationdebatedidnotend.Itsimplymovedontonewconcerns,primarilyhowtoadjustforsophomore testscores(withorwithoutafamilybackgroundadjustment,withorwithoutcurriculumdifferences, withonlyasubsetofsophomoretestscores,andwithorwithout adjustmentforattenuation thatis duetomeasurementerror).\nTakento its extreme, the Sherlock Holmes regressionapproachmay discoverrelation- ships between candidate independent variables andthe outcome variable that are due to sampling variability and nothing else. David Freedman showed this possibility in a simple simulation exercise, in which he sought to demonstrate that “in a world with a large number of unrelated variables and no clear a priori specifications, uncritical use of standard [regression] methods will lead to models that appear to have a lot of explanatorypower” (Freedman 1983:152).To show the plausibility of this conclusion, Freedmanconstructedanartificial datasetwith 100individuals, one outcome variable Y,and50othervariablesX throughX .The100valuesforeachofthese51variables 1 50 were then independent random draws from the standard normal distribution. Thus, thedatarepresentcompletenoisewithonlychancedependenciesbetweenthevariables that mimic what any real-world sampling procedure would produce. The data were then subjected to regressionanalysis, with Y regressedon X through X . For these 1 50 50variables,1variableyieldedacoefficientwithapvalueoflessthan.05andanother 14hadpvaluesoflessthan.25.FreedmanthenranasecondregressionofY onthe 15 variables that had p values of less than .25, and in this second pass, 14 of them again turned up with p values of less than .25. Most troubling, 6 of them now had p values ofless than.05,andthe model asa whole hadan R2 of.36. Frompure noise andsim- ulated sampling variability, Freedman produced a regressionmodel that looks similar to any number of those published in social science articles. It had six coefficients that passed conventional standards of statistical significance, and it explained a bit more than one third of the variance of the outcome variable.25 The dangerofdata-drivenspecificationsearchesisimportanttorecognize,butnot allproceduresaresimilarlyindanger,especiallygivendevelopmentssinceLeamerfirst presentedhiscritiqueinthe1970sand1980s.Thereisanewliteratureondatamining and statistical learning that has devised techniques to avoidthe problems highlighted by Freedman’s simulation (see Hastie et al. 2001). For a very clear overview of these methods, see Berk (2006, 2008). And, as we noted in Chapter 5, there are cases in whichadata-drivenspecificationsearchisbothpermissiveandpotentiallyquiteuseful.\nConsider again the causal graph in Figure 4.10 and suppose that one has a large number of variables that may be associated with both D and Y in one’s dataset and that one presumes may be members of either S or X. Accordingly, one has the choice of conditioning on two different types of variables that lie along the back-door path from D to Y: the variables in S that predict D or the variables in X that predict Y. Engagingin a data-drivenspecification searchfor variables that predict Y will fall preytoinferentialdifficulties aboutthecausaleffectofD onY forexactlythe reasons just discussed. But a data-drivenspecification searchfor variables that predict D will not fall prey to the same troubles, because in this search one does not use any direct information about the outcome Y.\nEvenso,data-instigatedspecificationsofregressionequationsremainaproblemin practice, because few applied social scientists use the fair and disciplined algorithms in the statistical learning literature. The Catholic school example is surely a case in 25Raftery (1995) repeated Freedman’s simulation experiment and obtained even more dramatic results.\nwhich scouting led to the inclusion of variables that may not have been selected by a statistical learning algorithm. But, nonetheless, none of the scholars in the debate dared to reason backwards from their regression models in order to declare that they hadinductivelyconstructedatruemodeloflearning.And,ingeneral,itishardtofind examplesofcompleteinductivemodelbuildinginthepublishedliterature;scholarsare usuallydrivenbysometheoreticalpredilections,andthe resultsofmistakeninduction are often fragile enough to be uncoveredin the peer review process.26 Milder forms of misspecification are surely pervasive.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#conclusions-3",
    "href": "extracted/Counterfactuals and Causal Inference.html#conclusions-3",
    "title": "Counterfaturals and Causal Inference",
    "section": "6.7 Conclusions",
    "text": "6.7 Conclusions\nRegressionmodels,intheirmanyforms,remainoneofthemostpopulartechniquesfor\ntheevaluationofalternativeexplanationsinthesocialsciences.Inthischapter,wehave restricted most of our attention to OLS regression of an interval-scaled variable on a binarycausalvariable.And,althoughwehaveconsideredhowregressionmodelingcan be used as a descriptive data reduction tool, we have focused mostly on regressionas a parametric adjustment technique for estimating causal effects, while also presenting someoftheconnectionsbetweenregressionandmatchingascomplementaryformsofa moregeneralconditioningestimationstrategy.We concludethischapterbydiscussing the strengths and weaknesses of regression as a method for causal inference from observational data.\nThe main strengths of regression analysis are clearly its computational simplic- ity, its myriad forms, its familiarity to a wide range of social scientists, and the ease with which one can induce computer software to generate point estimates and stan- dard errors. These are all distinct advantages over the matching techniques that we summarized in Chapter 5.\nBut, as we have shown in this chapter, regressionmodels have some serious weak- nesses. Their ease of estimation tends to suppress attention to features of the data that matching techniques force researchers to consider, such as the potential hetero- geneity of the causal effect and the alternative distributions of covariatesacross those exposed to different levels of the cause. Moreover,the traditional exogeneity assump- tion of regression (e.g., in the case of least squares regression that the independent variablesmustbe uncorrelatedwiththe regressionerrorterm)oftenbefuddles applied researchers who can otherwise easily grasp the stratification and conditioning per- spective that undergirds matching. As a result, regressionpractitioners can too easily accepttheirhopethatthespecificationofplausiblecontrolvariablesgeneratesanas-if randomized experiment.\nFocusing more narrowly on least squares models, we have shown through several demonstrations that they generate causal effect estimates that are both nonintuitive andinappropriatewhenconsequentialheterogeneityhasnotbeenfullyparameterized.\nIn this sense, the apparent simplicity of least squares regressionbelies the complexity 26However, predictions about the behavior of financial markets can come close. See Krueger and Kennedy (1990) for discussion and interpretation of the apparent effect of Super Bowl victories on thestockmarketindicesintheUnitedStates.\nof how the data are reduced to a minimum mean-squared-errorlinear prediction. For more complex regression models, the ways in which such heterogeneity is implicitly averagedarecurrentlyunknown.Butnooneseemstosuspectthatthecomplicationsof unparameterizedheterogeneityare less consequential for fancier maximum-likelihood- based regressionmodels in the general linear modeling tradition.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#weighted-regression-estimators-of-the-ate",
    "href": "extracted/Counterfactuals and Causal Inference.html#weighted-regression-estimators-of-the-ate",
    "title": "Counterfaturals and Causal Inference",
    "section": "7.1 Weighted Regression Estimators of the ATE",
    "text": "7.1 Weighted Regression Estimators of the ATE\nIn this section, we show how weighted regression estimators can be used to gener-\nate consistent and unbiased estimates of the ATE, as long as conditioning variables that satisfy the back-door criterion have been observed and properly utilized. These 1Fordetails,seeanyregressiontextbook, suchasDraperandSmith(1998)orGreene(2000).\nmethods have diverse and overlapping origins – inverse probability weighting in sur- vey statistics (see Kish 1965, 1987; Thompson 2002), missing data imputation and survey nonresponse adjustment via weighted complete-case analysis (see Little 1982; Little and Rubin 2002), weighting procedures in multiple regression analysis for data from stratified samples (see DuMouchel and Duncan 1983), propensity-score mod- els and general methods for modeling the probability of treatment assignment (see Rosenbaum and Rubin 1983b; Rubin 2006; Rubin and Thomas 2000), direct adjust- ment estimators (see Rosenbaum 1987, 2002), econometric evaluation estimators (Imbens 2004; Imbens and Wooldridge 2009), and inverse probability of treatment weighting in epidemiology (see Robins and Hernn 2009; Robins and Ritov 1997; van der Laan and Robins 2003).\nRecallfirstthe hypotheticalexampleinMatchingDemonstration3(seepage153), where matching was considered a method to weight the data in order to balance predictors of treatment assignment and thereby calculate contrasts that can be given causalinterpretations.Inthissectionandthenext,weshowthatthethreepropensity- score-weighting estimators presented there as Equations (5.12) through (5.14) can be specified as three weighted regressionestimators.\nTo estimate the ATE with weighted regression, one first must estimate the pre- dicted probability of treatment, pˆi, for units in the sample, which is again the esti- mated propensity score. All of the methods discussed so far can be used to obtain these estimated values. Once the values for pˆi are obtained, weights for the ATE are constructed as 1 For di=1: wi,ATE= , pˆi (7.1) 1 For di=0: wi,ATE= 1−pˆi.\nThese weights are equivalent in structure to survey weights that must be used to weightcomplexsamples so thatthey arerepresentativeof their respectivetargetpop- ulations. Here, the weights, wi,ATE, can be used to weight those in the treatment group and those in the control group so that both of these groups have the same weighted distribution on (observed) determinants of treatment assignment as the full population(where,inthis case,the full populationofinterestiscomposedofboththe population-level treatment group and the population-level control group).\nTo then estimate the ATE, a weighted bivariate regression model is estimated, whereyiarethevaluesfortheoutcome,di arethevaluesforthesolepredictorvariable, and wi,ATE are the weights. No specialized software is required, and the weights are treatedexactlyasiftheyaresurveyweights(eventhoughtheyarenotsurveyweights, but instead weights based on estimated propensity scores that are relevant only for the estimation of the ATE).\nFor those accustomed to matrix representations of regression estimates, note first that the naive estimator in Equation (2.9) can be written as an OLS estimator, (Q(cid:2)Q)−1Q(cid:2)y, where (1) Q is an n×2 matrix that contains a vector of 1s in its first column and a vector of the values of di for each individual in its second column and (2)yisann×1columnvectorcontainingvaluesofyi foreachindividual.Toestimate the ATE, a weighted regressionestimator is utilized, δˆ OLS,weighted≡(Q(cid:2) PQ)−1Q(cid:2) Py, (7.2) where P is an n × n diagonal matrix with the corresponding value of wi,ATE on the diagonalforeachindividualandzeroelsewhere.Considerthefollowingdemonstration, whichbuildsdirectlyonthepriorpresentationofmatchingasweightinginSection5.3.\nWeighted Regression Demonstration 1 For Matching Demonstration 3 (see page 153), consistent and unbiased estimates of the ATE were generated from averages of estimates of the ATT and the ATC. These estimates of the ATT and ATC were differences in weighted averages of the values of yi, constructed using weights defined by pˆi. In the demonstration we offer here, we will show how the same estimates of the ATE can be generated directly by weighted regression. We will dispense with the Monte Carlo setup from Matching Demonstra- tion 3, which offers little additional insight, and we will instead shift to the simpler scenariowe have used elsewhere in demonstrations, where we assume an infinite sam- ple. We will, however,vary the setup for the potential outcomes in order to show how weighted regressioncan easily handle nonlinearities in the relationships that generate the propensity scores and the potential outcomes.\nAsshownforMatchingDemonstration3inEquations(5.8)and(5.9),thepotential outcomes were specified as functions of individual values for A and B: y i1=102+6ai+4bi+υ i1, (7.3) y i0=100+3ai+2bi+υ i0, (7.4) whereA andB aredistributed asindependent uniformrandomvariableswith a mini- mum of .1 and a maximum of 1, and where υ1 and υ0 are independent randomdraws i i fromanormaldistributionwith expectation0andastandarddeviationof5.Foreach individual, yi is then equal to y i1(di)+(1−di)y i0, where the value of di is determined by a Bernoulli distribution with the probability of 1 rather than 0 as the nonlinear function in A and B that is presented in Figure 5.1 on page 154.\nThefirstpanelofTable7.1reproducesthetrueATEforthisexamplefromtheprior Table 5.5, whichis 4.53. The secondpanel of Table 7.1 introduces a secondvarianton the basic setup for Matching Demonstration 3. For this variant, Equations (7.3) and (7.4) are replaced with y i1=102+3ai+2bi+6(ai×bi)+υ i1, (7.5) y i0=100+2ai+1bi−2(ai×bi)+υ i0, (7.6) but everything else remains the same. These alternativepotential outcome definitions resultin a slightly more dramatic pattern for the averagetreatment effects (in partic- ular, for the ATT and ATC, as will be discussed in the next demonstration where we willestimatethesedirectly).Fornow,thissecondvariantgeneratesaslightlydifferent value for the true ATE, which is 5.05 rather than 4.53.\nFor each variant of this hypothetical example, we first offer three coefficients on D from unweighted OLS regression models using three different specifications: (1) Y Table 7.1 Weighted RegressionEstimates of the ATE, Using and Extending the Data Setup for Matching Demonstration 3 ATE Variant I:Y1and Y0 linear in A and B True treatment effect 4.53 OLS regression estimates: Yregressed on D 5.39 Yregressed on D and linear A and B 4.75 Yregressed on D and quadratic A and B 4.74 ATE-weighted regression of Yon D 4.53 Variant II:Y1and Y0 nonlinear in A and B True treatment effect 5.05 OLS regression estimates: Yregressed on D 5.88 Yregressed on D and linear A and B 5.47 Yregressed on D and quadratic A and B 5.44 ATE-weighted regression of Yon D 5.05 regressedonD, (2) Y regressedonD,A, andB,and(3) Y regressedonD, A,A2,B, andB2. NoneoftheseunweightedOLSestimates isparticularlycloseto itsrespective trueATEforeithervariant,andthequadraticspecificationsofAandB helponlyvery little. Unweighted regression has invoked the form of implicit weighting explained in Section 6.3, and as a result even in an infinite sample the estimated parameter would not equal to the true ATE, only a variant of it that invokes supplementary weighting by the conditional variances of A and B.\nForthelastrowofeachpanel,wethenimplementedtheweightedregressionmodels specified earlier in Equation(7.2). For these estimates, we take the estimated propen- sity scores from the row labeled “Perfectly specified propensity score estimates” in Table5.5,formwi,ATE,asinEquation(7.1),andestimateaweightedbivariateregres- sionmodel, where we implicitly assemble Pby declaringthe values for wi,ATE assur- vey weights in the weighted regression routine. Both resulting estimates land exactly on the target true ATE, as will always be the case in a sufficiently large dataset if the propensity scores are estimated flawlessly. No supplemental conditional-variance weightingis introducedinto the estimatorbecause the informationonA andB enters the model only through the values of pˆi that then structure the weights.\nSeveral caveats should be mentioned before we proceed. First, as with nearly all other estimatorswe haveconsideredsofar, these results holdonly inexpectationover repeatedsamplesorintheprobabilitylimitasasinglesampleincreasestoinfinity.Sec- ond,fortheresultstoemergeascleanlyasinthisdemonstration,thepropensityscores mustbeestimatedflawlessly.Misspecificationofthepropensity-score-estimatingequa- tionwillpushthepointestimateoffofthetargetATEparameter.Althoughthelitera- ture has not yet systematically exploredhow sensitive point estimates are to different types and degrees of misspecification, it is clear that a misspecified propensity-score- estimating equation will not generate weights that will balance the underlying deter- minantsoftreatmentassignmentforthesameargumentsdiscussedalreadyinChapter 5. Third, even if the weights are correct because the propensity scores are flawlessly estimated,thepointestimateswillbeimpreciseacrosshypotheticalrepeatedsampling for finite datasets if large weights result after estimated propensity scores are passed toEquation(7.1).2 Largevaluesforwi,ATE willbepresentiftheestimatedpropensity score, pˆi, is either very close to 0 or very close to 1, for treatment or control cases, respectively. Nonetheless, Imbens and Wooldridge (2009:35) offer the somewhat com- fortingpositionthat“theseconcernsarelessseriousthanthoseregarding[unweighted] regressionestimators because at least the…[weighted regression]estimates will accu- rately reflect uncertainty.” In Section 7.4 on practical issues that confront weighted regressionanalysis,wewilldiscussaliteraturethatconsiderstheconsequencesoflarge weights and that advocates truncation of the distribution of the weights in some situ- ations. Next, however, we will present equivalent estimators for the ATT and ATC.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#weighted-regression-estimators-of-the-att-and-the-atc",
    "href": "extracted/Counterfactuals and Causal Inference.html#weighted-regression-estimators-of-the-att-and-the-atc",
    "title": "Counterfaturals and Causal Inference",
    "section": "7.2 Weighted Regression Estimators of the ATT and the ATC",
    "text": "7.2 Weighted Regression Estimators of the ATT and the ATC\nToestimatethe ATTandATC, asimilarprocedurecanbeadoptedafterconstructing\nappropriate weights, which are again functions of the estimated propensity scores, pˆi.\nIn particular, two sets of weights wi,ATT and wi,ATC are formed as For di=1: wi,ATT=1, (7.7) pˆi For di=0: wi,ATT= 1−pˆi, and 1−pˆi For di=1: wi,ATC= , (7.8) pˆi For di=0: wi,ATC=1.\nAgain, these weights are analogs to survey weights, but the target population is no longer the total population comprising the population-level treatment and control groups together.3 Instead, when using the weight wi,ATT, the population-level treat- mentgroupbecomesthetargetpopulation.Accordingly,theweightleavesthesampled 2Inthiscase,theestimatescanstillberegardedasconsistentfortheATE.But,foranysinglefinite sample, the point estimate of the ATE may not be close to the true ATE because of consequential samplingvariabilityinthetailsofthedistributionofthepropensityscore.\n3However,theyarenotthesameanalogs.Theweightw i,ATEisanalogoustoasurveyweight,and inparticularthesurveyweightsknownasHorvitz-Thompson(HT)weights.HTweightsareequalto 1/π i,whereπ istheprobabilitythatindividualifromthepopulationwillbeincludedinthesample i treatmentgroupunaltered(becausewi,ATT=1forthoseinthetreatmentgroup),but it attempts to turn the control group into a representative sample of the population- 1−pˆi level treatment group (because wi,ATT= for those in the control group). More pˆi specifically, there are two distinct pieces of the weight that is applied to the control group. The denominator of wi,ATT, is the same as for wi,ATE, 1−pˆi, and it therefore weights the distribution of the control cases toward the full population, giving rela- tively more weight to cases with larger propensity scores. The numerator of wi,ATT, pˆi, then accentuates the relative weighting induced by the denominator so that the control cases are properly weighted toward the target treatment group, not the full population.4 The weight wi,ATC works in the opposite direction.\nAs with the ATE, to estimate point values for the ATT and ATC, one estimates a weightedbivariateregressionmodelofY onD,specifyingthecorrespondingweightfor the parameter of interest. The same weighted estimator in Equation (7.2) is utilized, but now the n × n diagonal matrix P is specified with either wi,ATT or wi,ATC on its diagonal, as we show now for a continuation of the same weighted regression demonstration.\nWeighted Regression Demonstration 1 (Continued) This demonstration is a continuation of Weighted Regression Demonstration 1 (see page229)becausethe samesetupisutilized, andthe modelsdifferonlyintheweights that are specified. However, the two variants of the data setup show their differences moreclearlyinthiscontinuation,becausetheyweredesignedtoyielddifferentpatterns of true values for the ATT and ATC.\nAs shown in the first panel of Table 7.2, the true ATT and ATC are 4.89 and 4.40,respectively,for VariantI. But, as shownin the secondpanel, the true ATT and ATC are 5.77 and 4.79 for Variant II. For this second variant, the opposite-signed parameters specified for the cross-product interactions of A and B in Equations (7.5) (alsoknownasthesamplingprobabilityforindividuali).FortheATEweightsinEquation(7.1),the values for pˆi and 1−pˆi are each treated as if they are the HT inclusion probabilities, and two HT weights are used to standardize the treatment and control groups to the full population (as if the treatment and control groups aresamples fromthe population based on different designs that must then be weighted in different ways to be representative of the same original target population). In contrast, the ATT and ATC weights, w i,ATT and w i,ATC in Equations (7.7) and (7.8), are either equal to 1 or are the odds of values that correspond to HT sampling probabilities. The latter align the treatment or control group with the group that receives uniform weights of 1 for each target parameter. As such, the analog for the odds embedded within the weights w i,ATT and w i,ATC are ratioadjustmentstobaseweights(eitherbaseweightsequalto1forsimplerandomsamplesorequalto HTsurveyweightsortheirgeneralizationsformorecomplexdesigns).Accordingly,itisquitenatural to multiply the weights w i,ATT and w i,ATC by any survey weights that adjust for an underlying surveydesign,aswewilldolaterinthischapterwhenanalyzingdatafromthe2002and2004waves oftheEducationLongitudinalStudy.Forthegeneralreasoningbehindthemultiplicationofweights, seeLevy,Lemeshow,Biemer,andChrist(2008)andValliant,Dever,andKreuter(2013,chapter13).\n4Inotherwords,foracontrolcasewithalowpropensityscore,thenumeratorfurtherdecreasesthe weightbecausethecaseisunlikelytoreflectthecharacteristicsofthetreatmentgroup.Forexample, forpˆi=.2,w i,ATE= 1−1 = 1−1 .2=1.25whilew i,ATT= 1−pˆi = 1−.2 .2=.25.Foracontrolcasewitha pˆi pˆi highpropensityscore,thenumeratorstilldecreases theweight,butitdoes sorelativelylessbecause the caseismorelikelytoreflect thecharacteristics ofthe treatment group. Forexample, forpˆi=.8, w i,ATE= 1−1 = 1−1 .8=5whilew i,ATT= 1−pˆi = 1−.8 .8=4.\npˆi pˆi Table 7.2 Weighted Regression Estimates of the ATT and ATC, Using and Extending the Data Setup for Matching Demonstration 3 ATT ATC Variant I: Y1and Y0 linear in A and B Truetreatment effects 4.89 4.40 OLSregression estimates: Yregressed on D 5.39 5.39 Yregressed on D and linear A and B 4.75 4.75 Yregressed on D and quadraticA and B 4.74 4.74 ATTor ATC weighted regression of Yon D 4.89 4.40 Variant II: Y1and Y0 nonlinear in A and B Truetreatment effects 5.77 4.79 OLSregression estimates: Yregressed on D 5.88 5.88 Yregressed on D and linear A and B 5.47 5.47 Yregressed on D and quadratic A and B 5.44 5.44 ATTor ATC weighted regression of Yon D 5.77 4.79 and (7.6) ensure that those with high levels of A and B together have much larger individual-level treatment effects than others. For Variant I, the differential sizes of thetreatmenteffects areseparableinto simplelinearpiecesthatcanbe independently attributed to A and B, as shown in Equations (7.3) and (7.4).\nFor each panel of Table 7.2, the same three unweighted OLS regression estimates alreadyreportedforTable7.1arereportedagain.Now,theyareplacedinbothcolumns because standard unweighted OLS regression estimators do not differentiate between the ATE, ATT, or the ATC. The estimator is the same for each target parameter becauseit is often regardedas anestimatorofanimplicit constantstructuraleffect of D onY,whichwouldrendertheATE,ATT,andATCequaliftheconstant-coefficient assumption were true.\nForthelastrowofeachpanel,wethenimplementedtheweightedregressionmodels specified earlier inEquation ( 7.2). For these estimates, we again took the estimated propensityscoresfromtherowlabeled“Perfectlyspecifiedpropensityscoreestimates” in Table 5.5, but now we formed the weights wi,ATT or wi,ATC in Equations (7.7) and (7.8). Unlike the unweighted regression estimates, the ATT-weighted and ATC- weighted regression estimates land exactly on their respective target parameters for eachvariant.Inaddition,theyeffectivelyundothecomplexpatternofnonlinearityfor VariantII,wherethe propensityscoresandthe potentialoutcomesarebothnonlinear in A and B.\nAs for the weighted regression estimates of the ATE, these results only hold over repeatedsamplesfromthesamepopulationorintheprobabilitylimitasasinglesam- ple approachesinfinity. And the same caveatsintroduced in Section 7.1 still obtain. If the equation that estimates the propensity scores is misspecified, then the estimates of the ATT and ATC will be inconsistent and biased because the weights will not fully balance the underlying determinants of treatment assignment. In addition, dis- proportionately small or large weights may still emerge even if the propensity scores are estimated flawlessly, and in these cases the estimates may be imprecise (i.e., still consistentbutnotnecessarilyclosetothetrueATTorATCinthesinglefinitesample under analysis).",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#doubly-robust-weighted-regression-estimators",
    "href": "extracted/Counterfactuals and Causal Inference.html#doubly-robust-weighted-regression-estimators",
    "title": "Counterfaturals and Causal Inference",
    "section": "7.3 Doubly Robust Weighted Regression Estimators",
    "text": "7.3 Doubly Robust Weighted Regression Estimators\nMany perspectives existon how matching andregressioncanbe combined. In Section\n6.5, we demonstrated how parametric regression can be used to provide supplemen- tal adjustment for matching estimators, following several decades of practice in the applied matching literature.The rationale for this type of adjustment is that the cho- sen matching routine has almost certainly not eliminated all of the imbalance in the observedtreatmentassignmentvariables,andapost-matchparametricregressionthat adjustsforthesamevariableswhilealsoestimatingthetreatmenteffectmayeliminate at least some of the lingering imbalance.\nAn alternative but related perspective has also been discussed at several points, and it has more recent origins. Rather than consider regression as a supplement to an imperfect matching routine, one can consider matching as a remedy to artifac- tual regression results that have been produced by incautious data mining. Ho et al.\n\nsuggest that the general procedure one should carry out in any multivariate analysis that aspires to generate causal inferences is to first balance one’s data as much as possible with a matching routine and then estimate a regression model on the matched data. From this perspective, matching is a preprocessor, which can be used to prepare the data for subsequent analysis with something such as a regression model.\n\nBoth of these perspectives are motivated by the goal of giving the analyst two chances to “get it right,” first with a matching routine and second with a parametric regressionmodel.Inthissection,wepresentthemostinfluentialversionofthisencom- passing strategy. For the estimators presented in Sections 7.1 and 7.2, the observed determinantsoftreatmentassignmentwereusedonlytoestimatethepropensityscores.\nIn this section, we present a related set of estimators that use these same variables a secondtime, aspartofthe regressionmodelthatgeneratesthepointestimates.Recall Equation (7.2), δˆ OLS,weighted≡(Q(cid:2) PQ)−1Q(cid:2) Py, wherewedefinedtheQmatrixascontainingacolumnof1sandacolumnofindividual- level values di for the treatment variable, along with a diagonal matrix P that represents a set of weights specific to the target parameter. For this estimator, as used up until this section, treatment assignment variables are presumed to have been used only in a first stage to estimate the values of pˆi, which then structure the appro- priate weights in P. The estimators that we present and demonstrate in this section usethesamevariablesasecondtimeassupplementaryadjustmentvariables.Theesti- mator in Equation (7.2) is still used, but these variables are included in additional columns in Q.\nThe idea is to offer what James Robins and his colleagues refer to as a “doubly robust”or“doublyprotected”estimator(seeBangandRobins2005;RobinsandRot- nitzky2001).RobinsandRotnitzkyreflectonthefallibilityofbothstandardregression methods, as presented in Chapter 6, as well as propensity-score-basedweighting esti- mators, as presented in Sections 7.1 and 7.2: There has been considerable debate as to which approach to confounder control is to be preferred, as the first is biased if the outcome regression model is misspecified while the second approachis biased if the treatment regression,i.e.,propensity,modelismisspecified.Thiscontroversycouldbe resolved if an estimator were available that was guaranteed to be consis- tent…whenever atleast one of the two models wascorrect….We refer to such combined methods as doubly-robust or doubly-protected as they can protectagainstmisspecificationofeither the outcome ortreatmentmodel, although not against simultaneous misspecification of both. (Robins and Rotnitzky 2001:922) Thebasicmotivationistogivetheanalysttwochancesto“getitright,”inhopesthat misspecifications of the propensity-score-estimating equation and the final regression equation will neutralize each other. And, although Robins is credited with developing the recentasymptotic justification for a variety ofspecific procedures(see Robins and Hernn 2009; Robins and Ritov 1997; Robins, Rotnitzky, and Zhao 1994; Scharfstein, Rotnitzky, and Robins 1999; and van der Laan and Robins 2003), the idea of using matching and regression together is quite general and has a long legacy in applied work, as we noted earlier in Section 6.5 (see Cochran and Rubin 1973; Gelman and King 1990; Heckman, Ichimura, and Todd 1998; Hirano and Imbens 2001; and Rubin and Thomas 1996,2000).\nBecause we used flawlessly estimated propensity scores for an infinite sample in Weighted Regression Demonstration 1, there would be no value in demonstrating the doublyrobustestimationstrategyforthesamesetup.Wedonotneedasecondchance to“getitright.”Instead,wenextofferademonstrationwithdoublyrobustestimators, where we use simulated data and vary our capacity to “get it right” when estimating the propensity scores.\nWeighted Regression Demonstration 2 Forthis demonstration,we revisitMatchingDemonstration4 andRegressionDemon- stration 4 (see pages 171 and 216, respectively). We will use the same 10 simulated datasets for the Catholic school effect on learning, modeled on the National Edu- cation Longitudinal Study (NELS) data analyzed in Morgan (2001). Recall that for this hypothetical substantive example, we have concluded that only the ATT can be estimated with any degree of confidence because we have not observed variables that wouldallowustodirectlymodelself-selectionontheindividual-leveleffectofCatholic schooling.\nWe already showed in Regression Demonstration 4 that matching performs well when the complete specification of treatment assignment is used, along with a sup- plementary regression adjustment. The reason for this result is precisely the double protection argument outlined above. The varying level of imbalance that remains for eachmatching estimatorcanbe seenas slightmisspecificationofthe matchingmodel, whichisproducedeitherbecausethepropensityscoremodelhasnotbeenrespecifiedto removeasmuchimbalanceaspossibleorbecausethe matchingalgorithmhasfeatures that render it suboptimal for the particular application. The supplemental regression adjustments,asshowninTable6.8,reducethe averagebiasinthe matchingestimates because they further adjust for remaining imbalance in the means of the matching variables. As such, the matching and supplementary adjustment are workingtogether to minimize bias in the estimates of the ATT, using the double protection reasoning introduced above.\nIn the demonstration we offer here, we will present doubly robust estimates from ATT-weighted regression models for the same 10 simulated datasets. As shown in Table 7.3, we again use estimated propensity scores from two scenarios, where for the incomplete specification we omit the crucial cognitive skills variable as well as additionalhigher-orderandinteractionterms.We thenestimate theATT,usingthese two sets of propensity scores in two ways, first as simple weighted ATT estimators as for Weighted Regression Demonstration 1 but also now as doubly robust estimators as defined in this section.\nFor the first row of Table 7.3, we report the minimum, maximum, and average bias of ATT-weighted regression estimates under both specifications of the models that generate the values of pˆi across all 10 simulated datasets. These bias values are directlycomparabletothoseofthe19matchingestimatorsreportedearlierinTable5.7 forMatchingDemonstration4.Asshownhere,thebiasissubstantialfortheweighted regression estimates that use the incomplete specification to estimate the propensity scores. This result is the same as for the matching estimators reported in Table 5.7, and the bias is produced mostly because of the exclusion of the variable for cognitive skills. In contrast, the average bias for the weighted regressionestimates that use the complete specification to estimate the propensity score is small. In fact, the average biasoftheATT-weightedregressionisinthemiddleofthedistributionofaveragebias of all 19 matching estimators reported in the final column of Table 5.7.\nFor the second row of Table 7.3, the equivalent bias values are reported for the doublyrobustestimators,wheretheassumedtreatmentassignment/selectionvariables are used a second time in the outcome regressionequations. Perhaps surprisingly, the double protection of supplementary regression adjustment does not narrow the aver- age bias further (and, in fact, may even increase it for these 10 samples). This result Table 7.3 Bias for Weighted Regression Estimates of the ATT, Catholic Schooling on Achievement Across 10 Simulated Datasets Utilized for Matching Demonstration 4 and RegressionDemonstration 4 Specification of treatment assignment variables: Incomplete specification Complete specification Method Min, Max Average Min, Max Average Weighted regression estimate of theATT −0.08, 2.17 0.82 −0.87, 1.11 −0.09 Doubly robust weighted regression estimate of the ATT −0.05, 2.19 0.83 −0.87, 1.08 −0.10 departsfromwhatweshowedinTable6.8forthesame10datasetswhensupplemental regressionwasusedtoeliminatesomeoftheremainingbias.There,asopposedtohere, one can see clear evidence of double protection.\nThereasonthatthebiasisrelativelyunchanged,forthisdemonstration,andhence littleevidenceofdoubleprotectionseemstoemerge,isthattheATTandATCweights arealreadyverywellestimatedinthesensethattheyleaveverylittleimbalanceinthe data on the observed values that generate them. In particular, the logit estimation of the propensity scores matches the assumed logistic distribution for the true propen- sity scores. As such, no unusual weights emerge because, on average, the parametric structureoftheestimatedlogitmodeldoesnotforceanunwarranteddistributiononto the values of pˆi.\nIsthisresulttypicalforweightedregressionestimators?Iftheweightsareestimated very well in the sense that they effectively represent all of the relevant information in the determinants of treatment assignmenton which they are based(as can usually be discernedbyanexaminationofbalance),thensupplementaryadjustmentbythetreat- mentassignment/selectionvariableswillhavelittle ornoeffectontheestimates.None ofthevirtuouseffectsofdoubleprotectionwouldbeevidentbecausethesupplemental adjustment is redundant. In many cases, especially for small datasets, these condi- tions will not be present, and the supplementary adjustment will offer clear double protection.\nAs this demonstrationand the last show, propensity scores can be used effectively withinaweightedregressionframeworktoestimateaveragecausaleffects.Thecaveats noted in Section 7.1 continue to apply, and in the next section we will discuss these.\nIn the section that follows the next, we will offer an extended and realistic example with genuine data, which demonstrates how effective weighted regressionestimates of the ATT and ATC can be, but also how carefully they must be interpreted, just like all other estimators considered in Chapters 5 through 7.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#remaining-practical-issues-in-weighted-regression-analysis",
    "href": "extracted/Counterfactuals and Causal Inference.html#remaining-practical-issues-in-weighted-regression-analysis",
    "title": "Counterfaturals and Causal Inference",
    "section": "7.4 Remaining Practical Issues in Weighted Regression Analysis",
    "text": "7.4 Remaining Practical Issues in Weighted Regression Analysis\nInthis section,we bridgethe simulatedresults forthis chapterwith a relatedbutreal\napplication.Wefirstdiscusstheneedtoconsidertheconsequencesofhavingestimated weights that may appear to be unreasonably large. We then discuss how and why weighted regression estimates have a distinct advantage over matching methods in their ability to handle survey data, which is rarely generated by a simple random sample. Finally, we consider alternatives for estimating standard errors.\nWe will not discuss here some issues that are common to both matching and weighted regression estimators. Our prior discussions of estimation when treatment assignment is nonignorable (Section 5.5.1), estimation on the region of common sup- port (Section 5.5.2), and estimation for many-valued treatments (Section 5.5.4) apply toweightedregressionestimatorsaswellinonlyslightlymodifiedwaysthatshouldbe obvious.\n7.4.1 The Concern Over Extreme Weights As we noted when introducing weighted regression estimators of the ATE, it is pos- sible to generate large weights if the estimated propensity score, pˆ, is close to 0 or 1.\nSimilarly,for the weightsusedto estimate the ATT andATC,valuesofpˆcloseto 0or 1 will generate either small or large weights. The literature on propensity-score-based weighting includes a number of decidedly skeptical pieces (e.g., Freedman and Berk 2008), some of which focus on the consequences of such weights (e.g., Lee, Lessler, and Stuart 2011). In some pieces, which we will not cite, manifestly poor weights have been used to demonstrate the obvious point that estimated propensity scores will not necessarily balance the data or warrant a causal inference. The more revela- tory work demonstrates why one should proceed with caution when the estimation of the propensityscoresgeneratesdisproportionatelylargeweights,whichmay thengive undue influence to only a very few members of a givensample. Yet, the literature has not determinedprecisely whensmall andlargeweightsshould be regardedas extreme or, more deeply, when extreme weights should be regarded as problematic.\nToapproachthe keyissues,firstconsiderthree scenariosinwhichextremeweights might emerge: 1. The weights are basedon an empirical model of treatment assignmentthat uses observed variables as predictors that do not collectively sustain the relevant ignorability assumption.\n\nThe weights are basedon an empirical model of treatment assignmentthat uses observedvariablesaspredictorsthatsustaintherelevantignorabilityassumption, but the model is nonetheless misspecified so that the estimated distribution of the propensity score departs systematically from the distribution of the true propensity score.\nThe weights are basedon an empirical model of treatment assignmentthat uses observedvariablesaspredictorsthatsustaintherelevantignorabilityassumption, and the model is thought to be well specified, after an inspection of covariate overlapandindicesofbalance.Asaresult,extremeweightsmustreflecteither(a) a strong treatment assignment/selection regime for which some true propensity scores are very close to either 0 or 1 and/or (b) very unusual cases sampled at random from the population.\n\nScenario1isaweakpositionfromwhichtoestimateacausaleffect,anditdoesnotrep- resent a unique threat to weighted regression estimators. Analogous to the discussion onmatchinginChapter5,forweightedregressionestimatorsinthissituationtheana- lystwillnecessarilypassonto the regressionroutine some poorlyconstructedweights andtherebygenerateestimatesthatareinconsistentandbiasedforthetruetreatment effects of interest. Although scenario 1 might generate extreme weights (especially if some of the misspecification issues we will discuss for the next scenario emerge), it has comparatively low probability of doing so. If back-door paths remain unblocked, it is more likely than not that the range of the estimated propensity score will be too narrow.\nScenarios 2 and 3, however, raise particular issues for weighted regression estima- tors.Forscenario2,themodelmay,forexample,“overfit”thedatainthespecificsense that the model has been too heavily parameterized so that cases appear artificially overdetermined. Imagine the extreme (but preposterous) scenario where a researcher includesoneormoreindividual-identifyingindicatorvariables(e.g.,adummyvariable for“individualnumber566inthedataset”basedonanassumptionthatthispersonis, forreasonsdeeplyfeltbytheinvestigator,perfectlypredisposedtobeinthetreatment group). Any such variable will lead to a perfect prediction for the relevant case, and mostsoftwarepackageswill happily deliver (if the relevantswitch is turned on) a pre- dictedprobabilityoftreatmentassignmentthatissetarbitrarilyclosetoeither0or1.\nMilder forms of overfitting can also generate estimated propensity scores that are too dispersed (see Hill et al. 2011).5 The solution here, however, is straightforward. One should not overfit, and the protection against overfitting is to (1) grounda condition- ing strategy in defendable assumptions about back-door paths and then (2) conduct balance checking while specifying the equation for propensity-score estimation.6 Forscenario3,everythinghasbeendonecorrectly.Instead,itissimplyanempirical fact, as best can be discerned, that the true propensity scores are either very large or very small for some members of the population (even though they are not structural 5Matchingestimatorsof sometypes mayescape fromsomeoftheconsequences ofover-dispersed estimatedpropensityscores.One-to-onenearest-neighbormatchingwithoutreplacement,forexample, pairsup treatment and control respondents andthen calculates mean differences, ignoringthe scale ofthepropensityscore.Allcasesarethengiventhesameweightintheanalysis.Ifcalipersareused, however,thencaseswithpropensityscoresverynearto0or1maybecastasideasunmatchable.The resulting matching estimator is then implicitly replacing unduly large weights with weights of zero, which could be deemed worthwhile under an appropriate consideration of expected mean-squared error.\n6Another remedy, following the double protection strategy, would be to estimate weights based on an incomplete propensity-score model, where the variable that generates the extreme weights is removed from the propensity-score-estimating equation. This variable would then be used in the weighted regressionmodel that estimates the effect. A downsideof this strategy isthat conditional- variance-basedweighting withrespecttothis variablecouldthenpushthe estimated effect offofits target parameter. Accordingly, this remedy should be avoided if one has reason to believe that the individual-leveleffectofinterestvariesinthelevelsofthevariableinquestion.\nconstants equal to 0 or 1, as for Matching Demonstration 2; see page 148). What are the consequences of such very large weights, and what can be done to mitigate any negative consequences? We noted above that the ATE, ATT, and ATC weights can be interpreted as analogs to survey weights. In the survey methodology literature, it is commonplace to evaluate the distribution of constructed survey weights and to consider procedures that may mitigate the consequences of using large weights. There are two common positions.\nFirst,onecanregardtheweightsascorrect,eventhoughextreme,andsimplycarry on (mindful that an appropriate variance estimator must, however, be utilized, as we discuss below). Levy et al. (2008) describe the distribution of weights constructed for the National Survey of Child and Adolescent Well-Being (NSCAW). These weights were constructed to adjust for the stratified sampling design and also patterns of nonresponse.TheyshowthattheconstructedweightsfortheNSCAWhadaminimum of 2 and a maximum of 8,175 and write: The distribution is highly skewed to the right, which is not atypical for unequalprobability sample designs.This is because the units in the popu- lationthathave higherprobabilities ofselection,andconsequently smaller base weights, will dominate the sample. Some units with very small selec- tion probabilities will still be selected in large samples…and the weights for these units can be quite large. (Levy et al. 2008:511) Inthissituation,analysiscanproceedeventhoughmostsamplemembershaveweights less than 50, but a few have weights greater than 4,000,with one at 8,175.\nSecond, one can trim the weights back so that one does not have to assume that the extreme weights are correct, as might be appropriate if one had a lack of confi- dence in the model that generates them. Valliant et al. (2013) consider the procedure that is used to trim the weights for the National Assessment of Educational Progress (NAEP). Here, estimated weights that are greater than 3.5 times the median weight are trimmed back to 3.5 times the median weight (and the aggregate trimmed-away weight is then redistributed equally across cases beneath the upper bound for trim- ming). This procedurewasadoptedby the data contractorswith the expectationthat thetrimmedweightswouldlikelyimpartsomebiastoestimatedparametersofinterest butwouldalsolowerthe expectedvarianceforeachofthem. Valliantetal.(2013:388) note that “these methods are ad hoc and largely theoretical,” suggesting that in gen- eral mean-squared-error calculations are less influential than “agency preference or historical precedence.”7 The same two positions are applicable to weights used to estimate the ATE,ATT, and ATC. First, an analyst who has confidence, perhaps after sufficient inspection of overlap and a specification produced by careful balance checking (as in the extended example we will offer below in Section 7.5), may choose to assertthat the weights are 7A third possibility would be to smooth the weights nonparametrically across strata defined by theinitialsetofestimated propensity scores,pullingintheextreme values inthetails andreducing thedependence ofallweightvaluesontheparticularspecificationofthepropensityscoreestimating equation. See Hong (2010, 2012) for a marginal mean weighting estimator that is based on such smoothedweights.\nindeedcorrectandworthusing,regardlessoftheirdistribution.Or,second,ananalyst can trim back the weights by truncating their distribution by progressively recoding themtointeriorpercentilesoftheinitialestimateddistribution(i.e.,perhapsfirstback to the 1st and 99th percentiles, then the 5th and 95th percentiles, and so on).\nFinally, a third option is also available,which is to focus the parameter of interest onasubsetofthepopulation.Oftenreferredtocolloquiallyas“movingthegoalposts,” one changes the parameter of interest to something for which the seemingly extreme weights are irrelevant. Rather than estimate the ATE, ATT, or ATC, one instead estimates an average effect over a specific range of the estimated propensity score.\nAlthough it would likely be hard to defend in a principled fashion, one could argue that the average treatment effect for those whose propensity scores are ≥.1 and ≤.9 is a well-defined parameter of interest. A more common strategy would be to restrict theanalysistothecommonsupportorregionofoverlapinthepropensityscoreacross the treatment and control groups (see Section 5.5.2 for a description of this strategy when offering matching estimates). In this case, one could, for example, still offer an estimate of the ATT that may still apply to most members of the treatment group and yet does not draw the cases with extreme weights into the analysis. The prudent approachmay be to take all three of these strategies and develop conclusions that do not depend on adopting only one or another.\n7.4.2 Survey Data Relatively few of the surveys that are routinely analyzed by social scientists have simple sample designs. As explained in survey methodology texts such as Thompson (2002), most survey samples have multistage, stratified designs that entail unequal probabilities of inclusion across members of the population. Accordingly, most of the datasetsfromthesesurveysthataredeliveredtothedesktopsofobservationalanalysts come with survey weights that have been constructed to account for their design features. Most also include weights that adjust for patterns of nonresponse, typically constructed in a series of nested steps (see Valliant et al. 2013).\nWeighted regressionestimators of the ATE, ATT, and ATC can incorporate these weightswithoutdifficulty.Incontrast,thereisnoconsensuspositiononhowmatching algorithmsshould be deployed for complex survey data. Most matching routines were designedfor the analysisofsimple randomsamples ornonsampledcollections of units that can be treated as equally representative pieces of information. For the weights used for regression estimation of the ATE, ATT, and ATC, all one needs to do is (1) weight the propensity-score-estimatingequation by the appropriate survey weight suggested by the data distributor and then (2) multiply the constructed weights for the ATE,ATT, and/orATC by the same surveyweight.Inso doing,the analystthen passes to the regressionroutine a model-based weight for the relevant parameter that ismodifiedbytheprobabilityofinclusionintheanalysissamplethatisbeingutilized.\nFor example, the ATE weights can be formed as 1 For di=1: wi,ATE,complex=surveyweight × , pˆi (7.9) 1 For di=0: wi,ATE,complex=surveyweight × 1−pˆi.\nThe survey weights will alter the distribution of the weights that are passed to the regression routine, but they will not necessarily inflate the variance of the weight.\nCases with relatively low or high estimated propensity scores may have probabilities of inclusion that place them near the mean of the constructed survey weights.8 7.4.3 Expected Sampling Variance and Estimated Standard Errors Forallweightedregressionestimatorsofthetypeconsideredhere,noconvincingratio- nale exists for assuming homoscedasticity when calculating standard errors. We rec- ommendthatresearchersroutinelyreportheteroscedasticity-consistentstandarderrors (e.g., the robust option in Stata, which will be called automatically if the weights are specified as pweights).9 These estimated standard errors are more likely to reflect the true expected sampling variability of weighted regression estimates, although the degreetowhichrobustvarianceestimationisfullyeffectiveinfinitesamples(especially small ones) has not been clearly established in the literature.\nInourownsimulationwork,wehavefoundthatheteroscedasticity-consistentstan- darderrorshaveperformedquite well forlargersamplesandthe estimationofparam- eters that are identified. Consider the following results. Following up on Weighted Regression Demonstration 2 (see page 235), we performed the following Monte Carlo simulation. Rather than analyze the 10 simulated datasets already produced for the priorsimulations(seetheexplanationoftheirgenerationintheintroductiontoMatch- ing Demonstration 4 on page 171), we generated 10,000 new datasets, each of which included 10,000 simulated individuals. On average across all of these datasets, 1,049 caseswereassignedtothetreatment,andtheaveragevalueforthetrueATTwas6.93.\nFor each dataset, we then estimated the weighted regression and doubly robust weighted regression estimates of the ATT, equivalent to those labeled as the “com- plete specification” for Table 7.3. Across all10,000datasets, the averagebias for each estimator was &lt;.01 (and we assume that the average bias of each would approach 0 in the limit if the number of simulated datasets was increased from 10,000 to infinity). The standard deviations of the distributions of these estimates were .47 and .46, respectively, across all 10,000 datasets. These two values of .47 and .46 are Monte Carlo benchmarks for the true standard errors of the corresponding weighted regressionestimates of the ATT.\nTo evaluate alternative methods for estimating standard errors for the point esti- mates of the ATT, we also calculated two estimated standard errors, a classical stan- darderrorthatassumeshomoscedasticityandaheteroscedasticity-consistentstandard error (the latter using the “sandwich” package for R; see Lumley and Zeileis 2013).10 8The rationale for ratio multipliers to base survey weights is very general, and an analyst can furthermultiplyATE,ATT,andATCweightsbymodel-basedweightsofanytype(suchasattrition- adjustment weights in a longitudinal model, as for the demonstration in the next section based on MorganandTodd2008).\n9TheseestimatedstandarderrorsarealsosometimesreferredtoasHuber-Whitestandarderrors, robuststandarderrors,sandwichstandarderrors,andothervariants;seeAngristandPischke(2009, chapter 8)aswellasLongandErvin(2000).\n10The sandwich routine for R calls a version of the estimator that is known as “HC3” and that corrects for finite sample bias in the estimated variance of the residuals (see Angrist and Pischke The classicalstandarderrorsweretoo small by a wide margin,at .26and.24 onaver- age,respectively.However,theheteroscedasticity-consistentstandarderrorswereclose to the simulated true standard errors, at .50 and .46 on average.\nAs with matching estimators, more work is needed to determine when heteroscedasticity-consistentstandarderrorsarevalid. However,weareconfidentthat they are more reasonable than the classical standard errors that are produced as defaults by most software packages. For all types of regressionmodeling, Angrist and Pischke (2009:307) recommend a conservative rule of thumb: For the parameter of interest,calculateboth classicalandheteroscedasticity-consistentstandarderrorsand then use whichever one is larger.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#an-extended-example",
    "href": "extracted/Counterfactuals and Causal Inference.html#an-extended-example",
    "title": "Counterfaturals and Causal Inference",
    "section": "7.5 An Extended Example",
    "text": "7.5 An Extended Example\nInthissection,weofferafullanalysisoftheestimationoftheATTandtheATCfrom\na weighted regression perspective, using real data where we do not know either the true treatment effects or the form of whatever underlying equation generates the true propensity scores. The substance of the demonstration is again the Catholic school effect on learning in high school.\nWeighted Regression Demonstration 3 Forthisdemonstration,wedrawonMorganandTodd(2008)andpresenttheanalysis in the steps in which it was undertaken. In particular, we will first model the effect of Catholic schooling on the math test scores of high school students in the tenth and twelfth grade in 2002 and 2004 using standard OLS regression models typical of the original researchon the Catholic school effect. We will then offer weighted regres- sion estimates of the ATT and ATC, under provisional acceptance of the identifying Assumptions 1-S and 2-S in Equations (5.1) and (5.2). However, we will conclude the demonstration with an extended set of interpretations that critically reevaluate these assumptions,whereinwewill arguethat, atbest, onlythe ATTisidentified. Nonethe- less, we aim to convince the reader that provisional estimation of the ATC helps to explain why neither the ATC nor the ATE is identified and promotes a substantive consideration of how best to interpret the estimate of the ATT.\nData and Measures. The data for this demonstration were drawn from the 2002 base-year and 2004 follow-up waves of the Education Longitudinal Study (ELS), col- lected by the National Center for Education Statistics (NCES) of the United States Department of Education. The ELS is a nationally representative sample of students in public and private high schools, based on a two-stage sampling design that first 2009,chapter8).AlthoughavailableinStataaswell,thedefaultthatStatacallswiththecommonly usedvce(robust)option(orthedefaultthatisautomaticallycalledinthebackgroundwhenpweights arespecified) is the original “HC0”that is biasedfor the variance of the residuals infinite samples.\nLong and Ervin (2000) offer a Monte Carlo simulation that suggests that for linear regression and samplesoflessthan500,theHC3formulaoutperformstheHC0formula.Fortheirlargesamplesize, thedifferences weretrivialinthesimulation,asweexpecttheywouldbeforoursimulationtoo.\ndraws a random sample of public and private high schools and then draws random within-school samples of tenth graders (typically aged 16). For the first follow-up in 2004,respondentsweretrackedtoalternativedestinations,andmostrespondentswere twelfth graders (typically aged 18).\nFrom among all base-year ELS participants, we restricted the analysis to respon- dents who were enrolled in either a Catholic school or a public school during the 2001–2002 academic school year. Table 7.4 presents means and standard deviations for the variables we will analyze on the 1,918 students who were enrolled in Catholic schools and the 12,025 students who were enrolled in public schools (for a total of 13,943 students).\nSeveral practical features of our subsequent analysis, which have their sources in the complex nature of the ELS survey data, require detailed explanation. Because these details are not essential for understanding the main contours of the demonstra- tion, we will provide this supplementary information in footnotes (and they are more completely specified in the appendix to Morgan and Todd 2008). Readers who are contemplating using these estimators for a project with a similar data structure – where a complex sampling design necessitates the use of a post-stratification weight that corrects for unit-level nonresponse and where some models are estimated with an adjustment for panel attrition – should consult this supplementary material for specificpracticaladvice.Inshort,theweightsweutilizefortheATTandATCestima- tors are multiplied by additional weights that account for design features of the data.\nIn addition, we use heteroscedasticity-consistent estimated standard errors, with an adjustment for clustering in schools, for both the ATT and ATC estimates reported below.\nStep 1: Estimate a Bivariate Regression Model. To initiate the analysis with naive estimators, we first estimate three bivariate regression equations with ordinary least squares, Y =αˆ+δˆ D+ε, (7.10) OLS,bivariate whereY isoneofthreeinterval-scaledoutcomevariablesandDisanindicatorvariable equal to 1 for those who attend Catholic high schools (and equal to 0 for those who attend public high schools). The estimated coefficient δˆ is the estimated OLS,bivariate effect of D on Y. If regardedas a structural constant, this coefficientis anestimate of the ATE, ATT, and ATC.\nThebivariateregressionestimatesfortheCatholicschooleffectonachievementare presented in the first row of each panel of Table 7.5. The three panels offer analogous resultsforthreerelatedoutcomevariables:tenthgrademathtestscores,twelfthgrade mathtestscores,andmathgainsbetweenthetenthandtwelfthgrades.Theestimates of δˆ in Equation (7.10) are 7.31, 8.45, and 2.00 for these three different OLS,bivariate outcome variables. Each of these estimates suggests that Catholic school students havehigher levelsofachievementonstandardizedtests andongrowthin achievement between the tenth and twelfth grades, matching results from research since the 1980s (see Section 1.3.2, page 22).\nTable 7.4 Means and Standard Deviations of the Primary Variables Used in the Demonstration Public Catholic Variable Mean SD Mean SD Math Test Scores IRTestimated numberright (10th grade) 41.68 13.97 48.99 12.02 IRTestimated numberright (12th grade) 47.64 15.05 56.08 12.80 Math gain (12th grade −10th grade) 4.66 6.49 6.66 6.06 Female .50 .48 Race(White is thereference category) Black .15 .06 Hispanic .17 .11 Asian .04 .04 Native American .01 &lt;.01 Multiracial .04 .04 Urbanicity (Suburbanis thereference category) Urban .28 .58 Rural .21 .01 Region (Midwest is the reference category) Northeast .18 .31 South .34 .23 West .23 .17 Family Background Mother’s education (in years) 13.46 2.32 14.77 2.22 Father’s education (in years) 13.59 2.59 15.25 2.57 SEI score of mother’s occupation 44.98 12.87 50.55 12.85 SEI score of father’s occupation 44.15 11.70 49.81 11.71 Family income (naturallog) 10.60 1.09 11.23 .90 Family income (naturallog) squared 113.61 19.83 126.99 17.04 Family income (naturallog) cubed 1225.64 295.46 1441.33 267.98 Two-parent family .75 .84 Past History (as reported by parent) Learning disability .13 .07 Ever held back .13 .05 Repeated 4th grade .01 &lt;.01 Years parents lived in current neighborhood 10.56 8.00 12.90 8.21 Source:EducationLongitudinal Study,2002and2004.\nStep 2: Estimate a Multiple Regression Model by Introducing Adjustment Variables. Wenextestimatethreemultipleregressionequationswithordinaryleast squares, Y =αˆ+δˆ D+Xβˆ+ε, (7.11) OLS,multiple Table 7.5 Catholic School Coefficients from Baseline Regression Models Predicting Tenth Grade Math Test Scores, Twelfth Grade Math Test Scores, and Math Test Gains Outcome Variable: Predictor Variables 10th Grade Math Test Score Model 1: Dummyfor Catholic school 7.31 (.66) Model 2: Model 1 + family background, 1.48 demographics, and past history (.52) Outcome Variable: 12th Grade Math Test Score Model 1: Dummyfor Catholic school 8.45 (.74) Model 2: Model 1 + family background, 2.13 demographics, and past history (.60) Outcome Variable: Math Gain (12th−10th) Model 1: Dummyfor Catholic school 2.00 (.23) Model 2: Model 1 + family background, 1.27 demographics, and past history (.26) Note:Heteroscedasticity-consistent standarderrorsinparentheses.\nwhere X represents observed variables thought to determine D and Y (because they lie on back-door paths from D to Y, as in Figure 5.2), δˆ is the estimated OLS,multiple causal effect of D on Y adjusted for X, and βˆ is a conformable vector of estimated coefficients that correspond to the variables in X.\nDescriptive statistics for the 23 variables specified as X in Equation (7.11) are presented above in Table 7.4. The variables in X represent the most common family background, demographic, and educational history variables utilized in school effects research. The multiple regression estimates for the Catholic school effect on achieve- ment are presented in the second row of each panel of Table 7.5. The coefficients for δˆ are 1.48,2.13,and1.27inthe three panels, eachof whichis considerably OLS,multiple smallerthanthecorrespondingvaluesofδˆ fromtheestimationofEquation OLS,bivariate (7.10). Nonetheless, the values of δˆ suggest that Catholic school students OLS,multiple outperformpublicschoolstudentsevenafteradjustmentsforthevariablesinX,again matching results of past research since the 1980s.\nStep 3: Estimate Propensity Scores and Form Weights to Estimate the ATT and ATC. In this step we iteratively estimate propensity scoresin pursuit of maximumachievablebalanceonthevariablesinX andthenformweightsbasedonthe final set of estimates. We first estimated a model of treatment selection/assignment using the variables in X as predictors, and using the same simple linear specification as for the multiple regressionmodels estimated for Table 7.5.\nIn particular, we estimated a logit model where the variables specified as X are thesame23variablesspecifiedasX forthemultipleregressionmodels.Theestimated logit model fit the data reasonably well and delivered a chi-squared test statistic of 404 with 23 degrees of freedom. Predicted values for the estimated propensity scores, pˆi, were then calculated. The estimated propensity scores had a mean of .0440 and a standard deviation of .0688. The distribution was heavily skewed with a minimum of .0000182but a maximum of .857.\nWe then took these estimated propensity scores and formed two sets of weights, wi,ATT and wi,ATC, using the expressions in Equations (7.7) and (7.8). We next checked how effective this first set of estimated weights was in balancing the data.\nAgain, perfect balance requires that all moments of the joint distributions of the vari- ables in X be exactly the same in the treatment and control groups.\nInthis case,the rawdataaresubstantiallyimbalanced,aswasshowninthemeans and standard deviations that were reported above in Table 7.4. In general, public school students are less advantaged and are more heterogeneous with respect to the characteristics measured as X. For example, the mean of mother’s education in years is 13.46 for those in public schools but 14.77 for those in Catholic schools. The mean of the log of family income is 10.60 for those in public schools but 11.23 for those in Catholic schools. Moreover,the dispersion of the log of family income is substantially different as well; its standard deviation is 1.09 for those in public schools but only .90 for those in Catholic schools.\nTo assess the degree of balance achievedby the weights formed in this first step, a balancecriteriamustbe chosen.The firstmetric weuseis the averageofstandardized mean differences across treatment and control groups (see Rubin 1973a, 1973b). The standardized difference of the mean for each variable in X is calculated as |EN[xi|di=1]−EN[xi|di=0]| (cid:20) , (7.12) 1VarN[xi|di=1]+1VarN[xi|di=0] 2 2 which we introduced earlier as Equation (5.20). Equation (7.12) yields a scaled abso- lutedifferenceinthe meanofavariableinX acrossthetreatmentandcontrolgroups.\nThesevaluescanbecombinedacrossallvariablesinX inordertoconstructanaverage standardizeddifferenceofmeans.Theaveragestandardizeddifferenceofmeanscanbe calculated under different weighting schemes in order to compare the relative perfor- manceofalternativeweightsinachievingbalancewithrespecttothetargetparameter (e.g., the balance of means on average for estimation of the ATT).\nBecause balance is not just a property of the means of variables but also of higher moments of the distributions, we used a second metric of balance for variables that are not two-valued indicator/dummy variables. For this metric, we change Equation (7.12) slightly, substituting standard deviations in the treatment and control groups for EN[xi|di =1] and EN[xi|di =0]. The modified version of Equation (7.12) then yields a scaled absolute difference in the standard deviation of a variable in X across thetreatmentandcontrolgroups.Becausethesevaluesarestandardized,theycanalso be combinedacrossalternativevariablesin X in orderto constructanestimate ofthe average standardized difference in standard deviations.11 To set a baseline against which to measure improvements in balance, we first cal- culated a baseline level of imbalance for the raw data by estimating the averagestan- dardized difference of means and standard deviations for the variables in X. The means of the variables (as well as the corresponding standard deviations for variables that take on more than two values) were already reported in Table 7.4, separately for those in Catholic and public schools. To assess how much imbalance the weights eliminate, wethen calculatedthe balanceafterusing the twoseparateweightswi,ATT and wi,ATC. The results showed that the weights succeeded in producing substantial balance, reducing the average standardized difference of means from .350 to .00634 when using wi,ATT and to .111 when using wi,ATC. The average standardized dif- ference of standard deviations also fell substantially from .0715 to .0391 when using wi,ATT and to .0287 when using wi,ATC. The increase in balance that results from employing wi,ATT and wi,ATC is substantial, but some minor imbalance remains.\nTheremainingimbalancesuggeststhatrespecifyingthemodeloftreatmentassign- mentmaybeworthwhile.Theinitialspecificationofthemodeloftreatmentassignment wasborrowedfromthesimpledefaultlinearspecificationoftheadjustmentvariablesin X forthemultipleregressionmodelsreportedinTable7.5,whichisbasedonthetypical specifications offered in the early literature. The goal is now to enrich the parameter- ization of the treatment assignment model in order to construct weights that further improve the balance on the variables in X when the weights are deployed. Accord- ingly, interactions between the variables in X not already included in the regression specification,aswellastransformationsoftheoriginalvariables,shouldbeconsidered.\nAlthough various data mining procedures can be wedded to balancing metrics in pursuitofabestpossiblemodel(seeSection5.4.2),wechosethetraditionalstrategyof controlled trial-and-error respecification of the propensity-score-estimating equation.\nWe usedaforwardselectionprocedurewhere interactionsthathavesomejustification in theory and past research were added progressively until improvements in balance ceasedto arise.We ignoredthe size andstatistical significanceoflogitcoefficients and only inspected improvements in balance using our chosen criteria.\nAs we explained just above, the original logit model fit the data reasonably well andalsoprovidedgoodbalanceby the standardsofthe matching literature.However, a better fit was available that also yielded weights that provided even better balance.\nWeadded75interactiontermstotheinitiallogitmodelthatpredictedCatholicschool attendance. The estimated propensity scores,pˆi, from this new model have a mean of .0440, a standard deviation of .0756, a minimum of 0, and a maximum of .892.12 11Inprinciple,andasdiscussedindetailinSection5.4.2,onecouldmoveontohighermomentsof thedistributions,assessingskewnessnextorbeginningtoconsiderinteractionsandother featuresof thejointdistributionofX.WestopatthesecondmomentofeachvariableinX.Note,however,that weconsiderthemeanandstandarddeviationoflogfamilyincome,itssquare,anditscube.Thus,for thisvariable,weattempttomatchfarmorethanjustitsexpectation andvariance.\n12The model was so predictive that a number of cases were completely determined. In particu- lar, 2,406 public school students were given predictive values arbitrarily close to 0 by the software (although no Catholic schools students were deemed completely determined and given values arbi- trarilycloseto1).Thesepublicschoolstudents weremostlylow-SESruralstudents.\n30 20 10 0 0 .2 .4 .6 .8 1 Figure7.1 Kernel density estimates of the estimated propensity score, calculated separately for public school students (black solid line) and Catholic school students (gray dashed line).\nFigure 7.1 presents kernel density estimates of these estimated propensity scores, separatelyforthoseinCatholicschoolsandpublicschools.Thereissubstantialoverlap in the estimated propensity scores, but there are no public school students with pˆi greater than .738 and no Catholic school students with pˆi less than .00115. If we focused in very closely on the cases within the tails of these densities, we would be able to see that there are 6 Catholic school students with .738&lt;pˆi ≤ .892 who have no counterparts among public school students as well as 2,739 public school students with 0≤pˆi &lt;.00115 who have no counterparts among Catholic school students.\nBy the common support standards that prevail in observational data analysis, these data would be regarded as characterized by sufficient overlap for analysis to be worthwhile,since 1,912ofthe 1,918treatmentcaseshavepˆi withinthe rangeofpˆi for the control cases. However, there is enough of a lack of overlap that some caution is in order, especially when making inferences about how public school students would fareiftheywereinsteadenrolledinCatholicschools.We willdiscusstheseconcernsin more detail later when offering estimates restricted to the region of overlap (i.e., the common support) where .00115≤pˆi ≤ .738.\nAsjustmentioned,therevisedweightsyieldedslightlybetterbalancewhenapplied to the data. In particular, the average standardized difference of means fell further to .00437 when using wi,ATT and to .0899 when using wi,ATC. Likewise, the average standardized difference of standard deviations also fell to .0166 when using wi,ATT and to .0229 when using wi,ATC.\nTo give a better sense of how well these weights have succeeded in producing bal- ance on a variable-by-variable basis (and for two different weighting schemes), we present the weighted means (and standard deviations where appropriate) of each of the variables in X for Catholic and public school students in Tables 7.6 and 7.7.\nTable 7.6 Means and Standard Deviations of Primary Variables, Weighted by the ATT Weight from the Final Estimation of the Treatment Assignment Model Public Catholic Variable Mean SD Mean SD Female .48 .48 Race (Whiteis thereference category) Black .06 .06 Hispanic .11 .11 Asian .04 .04 NativeAmerican &lt;.01 &lt;.01 Multiracial .04 .04 Urbanicity (Suburbanis thereference category) Urban .58 .58 Rural .01 .01 Region (Midwest is thereference category) Northeast .31 .31 South .23 .23 West .16 .17 Family Background Mother’s education (in years) 14.77 2.22 14.77 2.22 Father’s education (in years) 15.25 2.57 15.25 2.57 SEI score of mother’s occupation 50.56 12.77 50.55 12.85 SEI score of father’s occupation 49.67 11.68 49.81 11.71 Family income (natural log) 11.24 .84 11.23 .90 Family income (natural log) squared 127.07 16.50 126.99 17.04 Family income (natural log) cubed 1441.92 261.94 1441.33 267.98 Two-parent family .83 .84 Past History (as reported by parent) Learning disability .07 .07 Everheld back .05 .05 Repeated 4th grade &lt;.01 &lt;.01 Years parentslived in current neighborhood 12.93 8.96 12.90 8.21 The differences between the columns in each of these two tables can be directly com- paredtothe rawdifferencesreportedaboveinTable7.4.Forexample,the unbalanced raw difference in mother’s education between Catholic and public school students is 1.31 years (i.e., |14.77−13.46| from Table 7.4), whereas the difference is reduced to .00years(afterrounding)whenusingwi,ATT (i.e.,|14.77−14.77|fromTable7.6)and to .12 years when using wi,ATC (i.e., |13.58−13.46|from Table 7.7).\nBy our readings of applications of these sorts of models, the balance achieved by these weights is impressive. Some imbalance remains, and more so for the weights, wi,ATC,thataredesignedto enableestimationofthe ATC. Thevariablesthatproved Table 7.7 Means and Standard Deviations of Primary Variables, Weighted by the ATC Weight from the Final Estimation of the Treatment Assignment Model Public Catholic Variable Mean SD Mean SD Female .50 .53 Race(White is thereference category) Black .15 .20 Hispanic .17 .13 Asian .04 .06 Native American .01 .01 Multiracial .04 .05 Urbanicity (Suburbanis thereference category) Urban .28 .33 Rural .21 .05 Region (Midwest is the reference category) Northeast .18 .28 South .34 .29 West .23 .16 Family Background Mother’s education (in years) 13.46 2.32 13.58 2.35 Father’s education (in years) 13.59 2.59 13.80 2.68 SEI score of mother’s occupation 44.98 12.87 45.88 13.10 SEI score of father’s occupation 44.15 11.70 44.05 11.71 Family income (naturallog) 10.60 1.09 10.62 1.03 Family income (naturallog) squared 113.61 19.83 113.87 19.36 Family income (naturallog) cubed 1225.64 295.46 1228.94 292.93 Two-parent family .75 .71 Past History (as reported by parent) Learning disability .13 .14 Ever held back .13 .12 Repeated 4th grade .01 &lt;.01 Years parents lived in current neighborhood 10.56 8.00 10.72 6.89 most difficult to balance were some of the categorical variables, especially urbanicity and region because of the more limited geographic distribution of Catholic schools.\nAre there general standards for how good the balance must be for analysis to proceed? Of course, perfect balance for the full distribution of X is the standard for which an analyst should strive. Even with abundant data, as in this application, the standardcannotbe met. Rubin(2006)discussesthe generalpredicamentanalystswill encounter, and he concludes with this advice: Of course, at some point, this sort of [perfect balance] assessment must terminate, because no matter how large the samples, the investigator will almost certainly not be able to achieve this balance for all covariates and their interactions simultaneously,and higher order terms in prognostically minor covariates are clearly less important than prognostically important ones, and so scientific judgment must enter the process, just as it does when designing a randomized experiment. (Rubin 2006:462) As discussed already, remaining imbalance can be addressed by supplemental para- metric adjustment within a weighted regression framework, and we will offer such estimates later. And typically the weakness of an estimate arises not from lingering imbalance on observed variables, but rather the imbalance on unobserved variables thatmakesthemaintenanceofignorabilityassumptionsunreasonable.Wewilldiscuss this issue in detail later in this demonstration, when we interpretour estimates of the ATT and ATC.\nStep 4: Estimate Weighted Bivariate Regression Models Using the Weights fortheATTandATC. ATT-weightedandATC-weightedvariantsofδˆ OLS,bivariate are reported in the three panels of Table 7.8. Notice that for all three outcome vari- ables,thepointestimateoftheATC isconsiderablylargerthanthe pointestimatefor the ATT. Past research on the Catholic school effect has tended to show, by fitting interactionterms, that the estimated Catholic school effect is largestfor low-SESand non-white students (see Bryk, Lee, and Holland 1993; Hoffer, Greeley, and Coleman 1985; Neal 1997). The results presented in Table 7.8 are consistent with this pattern.\nIn particular, a comparisonof Tables 7.6 and 7.7 shows that Catholic school students whohavethe profileofthetreatmentgrouphavehigherlevelsofsocioeconomicstatus and are less likely to be black or Hispanic.\nHaving shown how to estimate the weights and produce point estimates for the ATT and ATC with the ELS data, we will not yet give a full interpretation to these estimates or to the common pattern of difference between the estimates of the ATT and ATC for all three outcome measures. We will save that discussion until after we havepresentedaseriesofmodelsthatassesswhetherthispatternofdifferenceisrobust to alternative analysis decisions.\nThe first issue we consider is whether allowing the models to use data off the common support of the treatment and control cases may have contributed to the difference between the estimates of the ATT and the ATC. For the estimation of the weighted regression models just reported, we used all sample members, recognizing, however, that with respect to pˆi, there are 6 Catholic school students who have no counterpartsamongpublicschoolstudentsand2,739publicschoolstudents whohave no counterparts among Catholic school students.\nTable7.9presentsallofthemodelsfromTable7.8again,butthistime theestima- tion sample is restricted to the region of overlap on the estimated propensity scores, .00115≤pˆi ≤ .738. For the tenth grade math test score models, the sample size is reduced from 13,943to 11,198.For the twelfth grade math test score and math gains models, the sample size is reduced from 10,502 to 8,469. A comparison of the results in Table 7.9 to those reported earlier in Table 7.8 shows that the point estimates of therespectiveaveragecausaleffectschangeslightly,withtheATCestimatescomingin Table 7.8 Catholic School Coefficients from ATT-Weighted and ATC-Weighted RegressionModels Predicting Tenth Grade Math Test Scores, Twelfth Grade Math Test Scores, and Math Test Gains Outcome Variable: 10th Grade Math Test Score Predictor Variables ATT Weight ATCWeight Model 1: Dummyfor Catholic school 1.08 2.44 (.77) (1.17) Outcome Variable: 12th Grade Math Test Score ATT Weight ATCWeight Model 1: Dummyfor Catholic school 1.42 3.29 (.89) (1.36) Outcome Variable: Math Gain (12th−10th) ATT Weight ATCWeight Model 1: Dummyfor Catholic school 1.02 1.98 (.31) (.37) a bit smaller. But, in general, the same pattern holds with ATT estimates remaining about the same and considerably smaller than the ATC estimates.\nStep5:EstimateDoublyRobustWeightedRegressionEstimates. Todemon- strate doubly robust weighted regression estimators, Table 7.10 presents weighted regression estimators analogous to those in Table 7.8 but with further regression adjustment for the 23 covariates used in Model 2 for Table 7.5. Beyond the weighted regressionmodels presented in Table 7.8, these models are designed to adjust for any remaining imbalance in X due to misspecification of the model that was used to esti- mate the weights. Again, acrossall three outcome variables,the point estimate of the ATC is considerably larger than the point estimate for the ATT.\nGiventheconsistencyofthepatternshownintheselastthreetables,the nextstep is to ask the simple statisticalquestion:Are the point estimates of the ATT and ATC sufficiently different that it makes sense to consider whether they support the claim that students who have the typical profile of public school students are more likely to benefit fromCatholic schooling thanstudents who have the typical profile of Catholic school students? To answer this question, we must consider some thorny issues in statistical infer- ence. Consider first the weighted multiple regression model for the Catholic school effect on the tenth grade math test. The estimated coefficient is 1.08 with a standard error of .56 when the wi,ATT weight is utilized. In contrast, when the wi,ATC weight Table 7.9 Catholic School Coefficients from Weighted Regression Models Restricted to the Region of Overlap in the Estimated Propensity Scores OutcomeVariable: 10th Grade Math Test Score Predictor Variables ATT Weight ATC Weight Model 1: Dummy for Catholic school 1.02 2.18 (.77) (1.17) OutcomeVariable: 12th Grade Math Test Score ATT Weight ATC Weight Model 1: Dummy for Catholic school 1.38 2.85 (.89) (1.36) OutcomeVariable: Math Gain (12th−10th) ATT Weight ATC Weight Model 1: Dummy for Catholic school 1.03 1.82 (.31) (.37) isutilized,thecoefficientincreasesto2.42withastandarderrorof.59.Aredifferences such as these large enough to be considered meaningful? A comparisonofthe 95 percent confidence intervals for eachestimate may suggest not. Consider the regression model for the Catholic school effect on the tenth grade mathtest.Here,the95-percentconfidenceintervalis(−.01,2.17)fortheestimateusing wi,ATT and(1.26,3.58)fortheestimateusingwi,ATC.Clearly,theseintervalsoverlap.\nScientific judgment, however,suggeststhat this overlapshouldnot leadresearchersto conclude that there are no substantive differences of importance, as we now explain.\nFirst, the difference betweenthe twopoint estimatesis substantivelylargeat1.34; this difference suggeststhat the averageeffect ofCatholic schoolingis 124%largerfor thosewhotypicallyattendpublicschoolsthanforthosewhotypicallyattendCatholic 2.42−1.08 schools (i.e., =1.24). The 95 percent confidence interval for the difference, 1.08 basedon a standarderrorof .81,is (−.26,2.92).This confidence interval is dominated by positiveprobabilitymassandsuggeststhat valuesforthe difference≥2.66arejust as likely as values ≤0.13 13Moreover, theestimated standard erroronwhichthis confidence interval isbased does not take into account that the two estimates were generated from the same sample. The confidence interval (−.26,2.92) is, in fact, a bit too wide (but not by much given the size of the available sample). In otherapplications,asame-samplecorrectionmaybemoreconsequential.\nTable 7.10 Catholic School Coefficients from Doubly Robust Weighted Regression Models OutcomeVariable: 10th Grade Math Test Score Predictor Variables ATT Weight ATC Weight Model 2: Model 1 + family background, 1.08 2.42 demographics, and past history (.56) (.59) OutcomeVariable: 12th Grade Math Test Score ATT Weight ATC Weight Model 2: Model 1 + family background, 1.60 4.01 demographics, and past history (.66) (.71) OutcomeVariable: Math Gain (12th−10th) ATT Weight ATC Weight Model 2: Model 1 + family background, 1.05 2.06 demographics, and past history (.29) (.45) Second,asnotedjustabove,thedifferenceof1.34isconsistentwithmuchpastwork on this substantive question. Evolving interpretive standards in statistical inference demand that such prior information be considered. If a full Bayesian posterior were generated, the lower end of the frequentist confidence interval, −.26, would be judged too negative as guidance for further research.\nForthese tworeasons,wejudge the differencebetweenthe doubly robustweighted regression estimates of the ATT and the ATC to be large enough to be meaningful.\nBefore attaching meaning to this difference, we need to consider assumptions about the extent to which the observed determinants of treatment assignment can sustain alternativetypesofignorability.Beforeofferingsuchinterpretations,wehaveonefinal type of analysis to perform, which will assess the extent to which the apparent differ- encesbetweenthe pointestimatesofthe ATTandtheATC arerobusteventofurther conditioning.\nStep 6: Further Assess the Robustness of the Difference Between the Esti- mates of the ATT and the ATC. In Step 4, we showed that the vast majority of the difference between the ATT-weighted and ATC-weighted regression estimates heldwhenthedatawererestrictedtotheregionofoverlapontheestimatedpropensity score.Thesameresultcouldalsobeshownforthedoublyrobustestimatesofthesame parameters.Fornow,weconsideradifferenttypeofrobustnesscheck:whetherthedif- ference between the point estimates continues to hold after additional supplemental parametric adjustment for variables that other researchers might instead regard as essential determinants of treatment assignment/selection.\nSome of the earliestliterature on the Catholic school effect consideredslightly dif- ferentvariablesforregressionadjustmentthanthe variablesthatweincludedinX for this demonstration. As we discussed in Section 6.6.2 (beginning on page 219), regres- sion adjustments were often performed with variables such as students’ educational expectations and parental involvement. The original researchers,James Coleman and his colleagues, recognized that these variables were not clearly “prior to” Catholic school attendance and thus were likely influenced by the posited causal effect itself.\nYet they wanted to show that, even adjusting for these variables, the apparenteffects of Catholic schooling persisted in their models.\nInourcase,wearenotprimarilyinterestedindetermininghowmuchtheestimated causal effects are reduced when additional adjustment variables are entered into the various regression models (although were they to change in unexpected ways, such as vanishing entirely, one of a number of reasonable interpretations would need to be advanced). Rather, we are most interested in determining whether the inclusion of additional adjustment variables in the doubly robust weighted regressions models would cause us to revisit our preliminary decision that the difference between the estimates of the ATT and ATC is robust and deserving of interpretation.\nWith this goal in mind, we consider additional variables for educational expec- tations and parental involvement in school. As shown in Morgan and Todd (2008), students attending Catholic schools are expected to obtain more years of postsec- ondary schooling (nearly a year in students’ own expectations and almost as much in parents’ expectations). In addition, more than half of all parents of Catholic school students volunteer at their schools, which is twice as high as the rate for the parents of public school students.\nTable 7.11 presents weighted regression models that utilize variables for expecta- tionsandparentalinvolvementassupplementaladjustmentvariables(i.e.,asvariables only in the outcome regressionequations, not as variablesalso in the propensity score estimating equation). The results in Table 7.11 show that these variables reduce the estimates of the ATT and ATC by a substantial amount. However, the coefficients remainpositiveandinthesamepattern.Moreover,therelativedifferencebetweenthe estimates ofthe ATT andthe ATC is largerfor Model 3 in Table 7.11than for Model 2 in Table 7.8.\nInsum,themainpatternofresultsissupportedbytheanalysesreportedinTables 7.9 through 7.11. Alternative decisions about overlap issues and supplemental regres- sion adjustment did not alter the relative sizes of the weighted regression estimates of the ATT and ATC. As a consequence, we conclude that there is compelling evi- dence that these estimates differ. The deeper question is whether this pattern can be interpreted as evidence that true ATT and ATC differ, which is the issue we consider next.14 14Another strategy that could be adopted to extend the analysis we report here is to attempt to modeltheunderlyingheterogeneityinamorefine-grainedway.Weseethecomparisonofestimatesof theATTandATCasonlyafirststep,andothermethodsmaybeausefulnextstep.Ifonebelieved Table 7.11 Catholic School Coefficients from Weighted Regression Models, Including Additional Covariates Outcome Variable: 10th Grade Math Test Score Predictor Variables ATT Weight ATC Weight Model 3: Model 2 + expectations .22 1.26 and parental involvement (.54) (.62) Outcome Variable: 12th Grade Math Test Score ATT Weight ATC Weight Model 3: Model 2 + expectations .82 2.77 and parental involvement (.63) (.74) Outcome Variable: Math Gain (12th−10th) ATT Weight ATC Weight Model 3: Model 2 + expectations .98 1.94 and parental involvement (.29) (.44) Interpretation of Results. We have generated estimates of the ATT and ATC usingatreatmentassignmentmodelthatincludes variableswehavelabeledX.Recall thatinthecounterfactualtradition,treatmentassignmentpatternsarerepresentedby the propensity score, Pr[D=1|S], where S denotes all variables that systematically determine treatment assignment. Complete observation of S allows a researcher to assertthat treatmentassignmentis ignorableandthen consistentlyestimate the ATT and ATC, and, as a result, the ATE or any other average treatment effect that can be formed by weighting across the marginal distribution of the observed variables in S (see Section 4.3).\nAre the ATT and ATC both identified? Thecrucialquestionforidentification iswhetherthevariableswehavedeclaredasX forourestimatorsinthisdemonstration are sufficiently complete to be regarded as equivalent to S, which we have previously labeled the perfect stratification set. To approach this question, it is useful to first reconsiderthe same substantive example modeled for our simulated data in Matching thattheestimatedpropensityscoreinaparticularapplicationhasaclearinterpretation(andhence ismorethanatoolforbalancingthedeterminantsoftreatmentassignment),thenonecouldanalyze directly the association between conditional average treatment effects and the estimated propensity score. Xie, Brand, and Jann (2012) and Brand and Thomas (2013) offer guidance for this sort of analysis,includingaStataadd-onprogram.Alternatively,onecouldmovetowarddirectexamination oftheseparateresponsesurfacesofthetreatmentandcontrolgroups,usingageneralnonparametric regression framework. Hill (2011) offers a compelling demonstration of the value of this alternative approach. Finally,as wewillexplaininChapters 9and 12,one couldattempt tomodel someofthe local average treatment effects and marginal treatment effects that constitute the ATT and ATC, althoughonlyifappropriateinstrumentalvariablesareavailable.\nDemonstration4,whereidentification ofthe ATT but notthe ATC is clearbecause it was guaranteed by construction.\nIn the subsection on identification for that demonstration(beginning on page 173; seeespeciallyFigure5.2),weexplainedwhyself-selectionontheindividual-levelcausal effect renders the ATC and ATE unidentified. In particular, with reference to the equations that defined the simulated data, we noted that we did not create observed variablesthatweresufficienttosustainanassumptionoffullignorability,asdefinedby Equation (4.4). However, we showed that we could nonetheless consistently estimate the ATT because we created observed variables that allowed us to assert what is labeled Assumption 2-S in Equation (5.2), E[Y0|D=1,S]=E[Y0|D=0,S].\nAssumption2-Sisimpliedbyastrongerassumptionofpartialignorabilitywithrespect to S, such that Y0⊥⊥D|S, (7.13) which we introduced in Section 4.3. The basic idea is that, on average within strata definedbyS,thevaluesofyiamongthoseinthecontrolgroupcanbeusedtoeffectively estimatethe counterfactualvaluesofy0 forthoseinthe treatmentgroup.Weknowby i the setup of Matching Demonstration 4 that this assumption holds for the simulated data,inparticularbecauseallofthevariablesontheright-handsideofEquation(5.21) were declared observed variables. For the remainder of that demonstration, we then explained why the ATC is not identified, which is the same explanation for why the ATE is not identified.\nNowreturnto the currentdemonstration.Becausewedid notsimulatethese data, we cannot assert that the ATT is identified with full confidence. We think it is rea- sonable to assert that Assumption 2-S is valid, treating X as equivalent to S for this assumption. However, it is possible that, for the cases observed in the ELS, those students most likely to benefit from public schools are those students who are least likely to attend Catholic schools, in which case Assumption 2-S does not obtain for the conditioning set X because E[Y0|D=1,X]&lt;E[Y0|D=0,X]. (7.14) ThiswouldhavebeenthecaseforMatchingDemonstration4ifwehadincludedaterm such as −.5(δ(cid:2)(cid:2)) on the right-hand side of of Equation (5.21). We do not know of any i research that suggests that the inequality in Equation (7.14) is true for the Catholic school effect, as would be the case if we had evidence that those who are most likely to do well in public schools are those with an aversion to educational institutions with religious foundations. On balance, it seems reasonable to assume that the ATT is identified in this demonstration.\nThe ATC is another matter entirely. Based on past research that maintains that self-selection is present, and the fact that we do not have any variables in the ELS that could plausibly measure students’ (and their parents’) own expectations for the benefits they might obtain from attending a Catholic school, we cannot accept what is labeled Assumption 1-S in Equation (5.1), E[Y1|D=1,S]=E[Y1|D=0,S], or the stronger assumption of partial ignorability, Y1⊥⊥D|S, (7.15) thatimpliesit.Inotherwords,wedonotbelievethatfortheATCthevariablesinX are equivalenttothemoreencompassingsetofvariablesinS thatdefinesthisassumption.\nOperationally, we do not believe that for the ELS data we can use the values of yi among those in the treatment group to effectively estimate the counterfactual values of y1 for those in the control group, on average within strata defined by X. Sufficient i evidence exists to suggest that some Catholic school students attend Catholic schools because they expect to gain from doing so. As such, we do not see any basis for regarding the ATC estimates as consistent or unbiased for the true ATC. Instead, these estimates are very likely too large because E[Y1|D=1,X]&gt;E[Y1|D=0,X]. (7.16) Although this reasoning is sufficient to convince us that the ATC is not identified, it also bears mentioning that the common support models show that 23 percent of public school students (i.e., 2,739 out of 12,025) have estimated propensity scores lower than the lowest estimated propensity score of any Catholic school student. Our comparison of the results in Tables 7.8 and 7.9 suggested that this lack of overlap is relatively inconsequential for the empirical results in this demonstration, and yet this provides only modest reassurance that the data can inform us at all about the likely benefit that students such as these 23 percent of public school students would obtain from attending a Catholic school.\nBasedonthisreasoning,theATCestimateislargerthantheATTestimatebecause theformerisinconsistentandupwardlybiasedwhilethelatteriseitherconsistentand unbiased, or still inconsistent but far less upwardly biased. Nonetheless, we cannot know for sure that this reasoning is correct because it is contingent on the validity of Equations (7.14) and (7.16), and these are assumptions that cannot be tested.\nWhy might the true ATC still be larger than the true ATT? Because the reasoning just offered could be wrong, we will conclude this section by considering alternative interpretations that would hold under the most plausible alternative pat- terning of results where (1) the true ATC is larger than the true ATT and (2) the estimates we have reported are sufficiently unbiased to convey this basic ordering of the underlying effects.\nBased on past research, there are two possible explanations for why one might expectthatthetrueATCwouldbe largerthanthetrueATTfortheeffectofCatholic schooling: 1. The common school explanation: Catholic schools distribute opportunities for learning,suchasadvancedcourse-taking,moreequitablythandopublicschools.\nThis explanation was stressed by Coleman and his colleagues in their initial research and was then more comprehensively developed by Bryk, Lee, and Hol- land (1993). It suggests that variables such as parental education and non- minority status have positive relationships with D but negative relationships with the variation in δ among Catholic schools students. The explanation is based on the implicit claim that E[Y1−Y0|D=1,CSE=1]&gt;E[Y1−Y0|D=1,CSE=0], (7.17) where CSE is a “common school effect” dummy variable that indicates which particular students receive a “boost” in their individual-level treatment effect becauseofthe comparativelyegalitariannature ofCatholicschooling.Low-SES, black, and Hispanic students are more likely to receive the CSE boost. Accord- ingly, when the average of individual-level treatment effects is weighted to the distributionofS thatcharacterizesthecontrolgroup,theresultingaveragetreat- menteffectislargerbecausethissyntheticgroupofCatholicschoolstudentshas moremembers with CSE=1. (The same is alsotrue whenthe weighting is per- formedonlywithrespecttotheobservedvariablesinX becausetherelationship betweenS andCSE isgeneratedbytherelationshipbetweenX andCSE,which does not depend in any way on the determinants of self-selection in S that are not among the observed variables in X.) 2. The better alternatives explanation: Catholic schooling is particularly beneficial tothosestudentswhohavepoorpublicschoolingalternatives,inparticularthose students from families who are not able to afford to live in school districts with thebestpublicschools.ThisexplanationwasfirstfullydevelopedbyNeal(1997), and it suggests that variables such as family income and wealth have positive relationships with D but negative relationships with the variation in δ among Catholic school students. The explanation is based on an implicit claim, of the same basic structure as Equation (7.17), that E[Y1−Y0|D=1,WAP =1]&gt;E[Y1−Y0|D=1,WAP =0], (7.18) where WAP is a “worse alternative public school” indicator variable equal to 1 for those Catholic school students who have particularly poor public schooling alternatives, and which is assumed for this explanation to be a function in S.\nHowever, here the claim is implicitly in two separable pieces, which makes it qualitatively different than the common school explanation. This explanation is composed of two assumptions, E[Y1|D=1,WAP =1]=E[Y1|D=1,WAP =0] and E[Y0|D=1,WAP =1]&lt;E[Y0|D=1,WAP =0], which together imply Equation (7.18).15 In this case, when the average of individual-leveltreatmenteffectsisweightedtothedistributionofS thatcharac- terizesthe controlgroup,the resultingaveragetreatmenteffectislargerbecause this synthetic group of Catholic school students has more members with WAP=1.\nIfeitherthe commonschoolexplanationorthe better alternativesexplanationis true, then the true ATC would be larger than the true ATT, and this might also be true for the estimated ATC and ATT if the bias in the estimates is small enough not to 15Weassumeforsimplicityofnotationthatthelinearityoftheexpectationsatthepopulationlevel applies also at the individual level. This assumption will hold for the third explanation introduced belowaswell.\nobscure the true difference between the target parameters (as usual, assuming that sampling error is zero).\nWefavoranalternativethirdexplanation,whichwethink ismorecompatiblewith theunderlyingclaimthattheestimatedATCislargerthantheestimatedATTinpart because self-selectionis very likely presentand cannotbe adjusted awaybecause X is only a subset of S: 3. Thebindingconstraint explanation:Differentialresponsivenessexiststoaccurate perceptions of students’ likely benefits from Catholic schooling. For low-income families for whom tuition at a Catholic school represents a genuine financial sacrifice, the students who enroll in Catholic schools are much more likely to be studentswhoarelikelytobenefitfromenrolling.Incontrast,amonghigh-income families for whom tuition is not a substantial financial sacrifice, even students who arenotlikely to benefitfromattending Catholic schoolinginsteadof public schoolingmayenrollinCatholicschools.ThisexplanationisdiscussedinMorgan (2001), and it is based on the assumption that it takes a larger individual-level value of δ to induce low-income students to enroll in Catholic schooling. As a result, variables that capture resource availability have positive relationships withD butnegativerelationshipswiththevariationinδ amongthosewhoenter Catholic schooling. The implicit claim here is that E[Y1−Y0|D=1,BC=1]&gt;E[Y1−Y0|D=1,BC=0], (7.19) where BC is an indicator variable equal to 1 for those students from families for whom Catholic school tuition is a genuine financial sacrifice, and which is therefore a function in S. Here, as with the better alternatives explanation, the claim is implicitly in two separable pieces, E[Y1|D=1,BC=1]&gt;E[Y1|D=1,BC=0] and E[Y0|D=1,BC=1]=E[Y0|D=1,BC=0], whichtogetherimplyEquation(7.19).Inthiscase,whentheaverageofindividual- leveltreatmenteffects is weightedto the distribution ofS that characterizesthe control group, the resulting average treatment effect is larger because this syn- thetic group of Catholic school students has more members with BC=1.\nHaving laidout these alternative explanations,there is no reasonto assume that only one of them holds. One reasonable blended explanation would combine the better alternatives and binding constraint explanations by asserting both E[Y1|D=1,BC=1]&gt;E[Y1|D=1,BC=0] and E[Y0|D=1,WAP =1]&lt;E[Y0|D=1,WAP =0], and then noting that there is likely to be a strong positive association between BC and WAP in the population, conditional on S (and its typical observed subset X).\nTheseassertionscouldthenbecombinedwiththeclaimthatthedifferencebetweenthe estimated ATC and the estimated ATT is further increased because these assertions also lend indirect support to the claim that the estimated ATC is inconsistent and upwardly biased for the true ATC because E[Y1|D=1,X]&gt;E[Y1|D=0,X].\nOther blended explanations are also possible, and we cannot rule out the possi- bility that Coleman and his colleagues had it correct all along: Catholic schools and public schools do have differences in their instructional practices, which at least for Coleman had deeper sources in alternative ideological beliefs about the capacities of children.Theseinstructionaldifferencesmaybeparticularlybeneficialtostudentswho are systematically disadvantaged in public schools.\nOverall,wasitworthofferingprovisionalestimatesoftheATC?Ofcourse,weknew from the outset which assumptions likely held, and it would have been reasonable to estimateandreportonlytheATT.Nonetheless,wethinkitisclearthatwhataremost likelyinconsistentandbiasedestimates ofthe ATC still giveusa valuableperspective on why the ATC is not identified, and hence enhance our explanationof why, at best, only the ATT is identified by conditioning on the observed data. In addition, the reasoning that was motivated by the need to interpret the estimated ATC may also explain why the common school explanation of Coleman and his colleagues also may reflect underlying heterogeneity that is produced by individual-level selection on the treatment effect.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#conclusions-4",
    "href": "extracted/Counterfactuals and Causal Inference.html#conclusions-4",
    "title": "Counterfaturals and Causal Inference",
    "section": "7.6 Conclusions",
    "text": "7.6 Conclusions\nIn this chapter, we have presented weighted regression estimators of the ATE, ATT,\nand ATC, and we have argued that they have enough comparative advantages that they arelikelyto continueto growinprominenceinthe comingyears.We haveshown how weightedregressionestimators allow the analyst to adopta matching orientation and thereby take advantage of the clarity that a matching perspective provides. We have also shown that weighted regression estimators require no specialized software and can be utilized when analyzing complex survey data of many types.\nTheseadvantagesnotwithstanding,itshouldalsobe clearthatweightedregression estimators are no panacea, especially if practitioners fall back too casually into stan- dard regression thinking. Instead, analysts must carefully consider the estimation of the propensityscoresthat generatethe weights,checkingbalance andthen examining theconsequencesoflargeweights.Onlythereaftershouldonecalculatepointestimates of the averagetreatment effects of interest.\nThe ultimate value of weighted regressionestimators in comparisonto other types of conditioning estimators has not yet been fully determined. As with the matching estimators presented Chapter 5, this is an area of active methodological scholarship, and it is not easy to predict the developments of the coming years. Our current pre- diction is that weightedregressionwill be at the center ofan emergentconsensus,but our prediction is accompanied by substantial uncertainty.\nWith this chapter,wehaveconcludedourpresentationoftechniquesthatestimate causal effects by conditioning on variables that block back-door paths. In the next section of the book, we present techniques that can be used effectively when simple conditioning will not identify causal effects because crucial variables that lie along back-door paths have not been observed. We will consider general strategies first, elaborating on the causal graphs we have used so far in this book. Thereafter, we will presentinstrumentalvariableestimators,front-doorconditioningestimatorsgrounded inassumptionsaboutcausalmechanisms,andapproachesthatutilizeover-timeobser- vations of the outcome variable.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#nonignorability-and-selection-on-the-unobservables-revisited",
    "href": "extracted/Counterfactuals and Causal Inference.html#nonignorability-and-selection-on-the-unobservables-revisited",
    "title": "Counterfaturals and Causal Inference",
    "section": "8.1 Nonignorability and Selection on the Unobservables Revisited",
    "text": "8.1 Nonignorability and Selection on the Unobservables Revisited\nAsdemonstratedinSections4.3.1and4.3.2,theconceptofignorabletreatmentassign-\nment is closely related to the concept of selection on the observables. In many cases, they can both be represented by the same directed graph. Recall Figure 4.8(a), in which there are two types of paths between D and Y: the causal effect of D on Y represented by D →Y and an unspecified set of back-door paths represented col- lectively by the bidirected edge in D(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)Y. If this graph can be elaborated, as in Figure 4.8(b), by replacing D (cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)Y with a fully articulated back-door path D← S→Y, then the graph becomes a full causal model. Observation of S ensures that the conditioning strategies of the prior three chapters can be used to generate consistentestimates ofthe causaleffectofD onY. Inthis scenario,selectionis onthe observables–thevariablesinS –andtheremainingtreatmentassignmentmechanism is composed only of random variation that is ignorable.\nIf,incontrast,asshowninFigure4.9(b)ratherthanFigure4.8(b),onlyasubsetZ of the variables in S is observed, then selection is on the unobservables because some components of S are now embedded in U. Conditioning on Z in this graph leaves unblocked back-door paths represented by D ←U (cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)Y untouched. And, as a result, any observed association between D and Y within strata defined by Z cannot be separated into the genuine causal effect of D on Y and the back-door noncausal association between D and Y that is generated by the unobserved determinants of selection, U.\nAs explained in Chapter 4, and then as shown in demonstrations in Chapters 5 through7,the concepts ofignorabilityandselectiononthe observablesarea bitmore subtle when potential outcomes are introduced. Weaker forms of conditionalindepen- dence can be asserted about the joint distribution of Y1, Y0, D, and S than can be easily conveyed as in Figures 4.8 and 4.9, in which the observable variable Y is depicted instead of the underlying potential outcome variables Y1 and Y0. For exam- ple, the average treatment effect for the treated (ATT) can be estimated consistently X X Y 10 O Y 10 O Y 12 U D U D (a) The identification puzzle (b) Coleman’s approach Figure8.1 Coleman’s strategy for the identification of the causal effect of Catholic schooling on achievement.\nbyassertingonlythatY0 isindependentofD conditionalonS,eventhoughfullignor- ability does not hold; see the discussion of Equation (4.4) and Section 4.3.3.1 These possibilitiesarenotfullyrevealedbyconventionaldirectedgraphs,giventhatforthese graphspotential outcome variablesaretypically notrepresented(seethe discussionof Figure 3.9).",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#selection-on-the-unobservables-and-the-utility-of-additional-posttreatment-measures-of-the-outcome",
    "href": "extracted/Counterfactuals and Causal Inference.html#selection-on-the-unobservables-and-the-utility-of-additional-posttreatment-measures-of-the-outcome",
    "title": "Counterfaturals and Causal Inference",
    "section": "8.2 Selection on the Unobservables and the Utility of Additional Posttreatment Measures of the Outcome",
    "text": "8.2 Selection on the Unobservables and the Utility of Additional Posttreatment Measures of the Outcome\nIn this section, we present the challenges of modeling causal effects when selection\nis on unobservables, using as an example the regression equations offered by James ColemanandhiscolleaguesfortheestimationofthecausaleffectofCatholicschooling on high school achievement. The basic estimation challenge that Coleman and his colleagues confronted is depicted in Figure 8.1(a). Although somewhat simplified, the graph represents the basic types of causal variables that Coleman and his colleagues contemplatedintheiroriginalanalysesand thenindebate withtheircritics(Coleman et al. 1982; see also our prior discussion in Section 6.6.2). For Figure 8.1(a), Y is an 10 observedscoreona standardizedachievementtestgiveninthe tenth gradeto second- year high school students. The variable D is again an observed dichotomous causal variable equal to 1 for those who attend Catholic schools and 0 for those who attend public schools. A primary goal of the original research was to estimate the causal effectofD onY ,conceptualizedasthe averagecausaleffect ofCatholicschoolingon 10 achievement.\nThe remaining variables in the graph represent the basic types of variables that Coleman and his colleagues decided should be specified as adjustment variables in 1Furthermore, as discussed inSection 5.2.1 inthe presentation of matching techniques, one need not assume full conditional independence of Y0 in order to offer consistent and unbiased estimates of the ATT. An equality of the two conditional expectations, E[Y0|D=1,S]=E[Y0|D=0,S], will suffice;seediscussionofAssumption2-SinEquation(5.2).\ntheir regression equations. The variables in X are determinants of achievement test scores that have no direct causal effects on school sector selection. The variables in O are ultimate background factors that determine all other variables in the graph (i.e., X, U, D, and Y ). Coleman and his colleagues designated many variables that 10 they believed were contained in O and X, although they were unsure of whether to consider them as members of O or X. Finally, the variables in U are the crucial variablesthatColemanandhiscolleaguesrecognizedwereprobablyunobserved.These variables–intrinsic motivationto learn,subtle featuresofthe homeenvironment,and anticipation of the causal effect itself – were thought to determine both school sector choiceandachievement.Becausethese variableswereassumedtobe unobserved,they are represented collectively in Figure 8.1(a) by the variable U with a node that is a hollow circle ◦.\nIn the initial research, the analysis strategy of Coleman and his colleagues was to conditionon observedvariablesin O and X in orderto attempt to removeas much of theconfoundingofD→Y aspossible.Reinterpretedwiththeaidofdirectedgraphs, 10 to identify the causal effect they needed to block five separate back-door paths from D to Y : 10 1. D←U→Y , 10 2. D←U←O→Y , 10 3. D←U←O→X→Y , 10 4. D←O→Y , and 10 5. D←O→X→Y .\n10 Accordingto the back-doorcriterion,conditioning onthe variablesin O andX would blockpaths2,3,4,and5butwouldleavepath1unblocked.Colemanandhiscolleagues recognized that the variables in U rendered the causal effect of D on Y formally unidentified,andtheycouldnotconvincetheircriticsthattheirestimatesfrommodels that conditioned only on O and X were sufficiently close to the ATE (or the ATT) to offer the conclusion that they did.\nTheirsolutiontothispredicamentispresentedinFigure8.1(b),whichbecamepos- sible when the secondroundof surveydata was releasedtwo yearslater (see Coleman and Hoffer 1987; Hoffer et al. 1985). Rather than focus on explaining variation in the tenth grade test score variable, Y , they reclassified it as a conditioning variable and 10 instead designated the new twelfth grade test score variable, Y , as the outcome of 12 interest.TheythenarguedthatY couldservetoscreenofftheeffectsofthevariables 10 inU onY . Inparticular,their strategywasequivalentto assertingthatconditioning 12 on O, X, and Y blocks all five of the back-door paths between D and Y in Figure 10 12 8.1(b): 1. D←U→Y →Y , 10 12 2. D←U←O→Y →Y , 10 12 3. D←U←O→X→Y →Y , 10 12 4. D←O→Y →Y , and 10 12 5. D←O→X→Y →Y .\n10 12 Indeed, all of these back-door paths are blocked by conditioning on Y , and four of 10 themareblockedbysupplemental butunnecessaryconditioningonO andX aswell.2 However, notice that Y does not satisfy Condition 2 of the back-door criterion.\n10 It lies on a directed path that begins at the causal variable and reaches the outcome variable, D→Y →Y . Conditioning on Y adjusts away some of the total causal 10 12 10 effectofCatholicschoolingonachievementmeasuredinthetwelfthgrade.Asaresult, by adopting this analysis strategy, Coleman and his colleagues changed the average causal effect of interest from the total effect of Catholic schooling on achievement to a net direct effect, D→Y . This effect is best thought of as the average gain in 12 achievement between the tenth and twelfth grades attributable to Catholic schooling, although the specific interpretation depends on the model that is estimated.\nHoldingasidethefundamentalissueofwhethernarrowingthefocustothisparticu- larnetdirecteffectishelpfulfortheresearchquestionsathand,considernowthegraph presentedinFigure8.2,whichsuggeststwomorebasiccriticismsofthisapproach.The first was seized on by their critics: the variables in U that confound the causal effect of D on Y are not effectively screened off by Y . More generally, Figure 8.2 should 12 10 be seen as more plausible than Figure 8.1(b) because it is unreasonable to rule out three direct effects: O→Y , X→Y , and U →Y (or, as Coleman and colleagues 12 12 12 asserted, that these effect are indirect and transmitted through Y →Y ). Because 10 12 O and X are observed, the claims that O→Y and X →Y should be included 12 12 in the graph can be accommodated in subsequent analysis. However, the inclusion of U →Y renders back-door adjustment with the observed variables ineffective. The 12 rationale for the inclusion of U →Y in the graph is the following. If the parents 12 of highly motivated students were more likely to pay tuition to enroll in Catholic schools, then enhanced motivation would contribute directly to learning in both the tenth grade and the twelfth grade. Similarly, it is unreasonable to assume that the motivation that is correlated with willingness to pay tuition would exert only a one- timeboostearlyintheCatholicschoolcareersofstudents,whichwouldthenstructure subsequentachievementonlybywayofatwelfthgradeknock-oneffectfromtheinitial boost in achievement in the tenth grade. Taken together, the critics argued, in effect, that Coleman and his colleagues mistakenly ignored a back-door path, D←U→Y , 12 that remains unblocked after conditioning on O, X, and Y because they failed to 10 acknowledge that U causes Y directly.\n12 The second criticism is more subtle. For Figure 8.2, we have omitted the effect Y →Y that Coleman and his colleagues seem to have asserted for their models, 10 12 andwhich we depicted in Figure8.1(b). Whether this effect shouldbe included in the graphdependsontherichnessofthevariablesinO,X,andU.Ifthesevariables,when combinedwithD,constitutefullmodelsofachievementforpublicandCatholicschool students, then no direct relationship between Y and Y needs to be represented in 10 12 2Coleman and his colleagues sometimes wrote as if they allowed for effects such as O→Y 12 and X→Y 12. The back-door paths generated by these additional direct effects would all be blocked by conditioningon O,X, andY 10.Thekey assumptionistheir implicitclaimthat U does not havean effectonY 12,exceptthroughY 10.\nX Y 10 E O Y 12 U D Figure8.2 Criticism of Coleman’s estimates of the effect of Catholic schooling on learning.\nthe graph. The critics did not take a position on this issue, but we suspect that they wouldnothavebeenwillingtomaintainthatthemeasuredvariablesinO andX were richenoughtoeliminatetheneedforincludingY →Y insuchagraph.Instead,they 10 12 would have likely allowed for such an effect so that the causes embedded in eY10 are allowedto contribute to Y via Y . The critics only emphasized the implausibility of 12 10 interpretingmodelsunderthefaultyassumptionthatD←U→Y doesnotexist,and 12 this point of criticism stands regardless of what position one takes on the plausibility of Y →Y .\n10 12 Yet, once one begins to think about the relationship between Y and Y , it may 10 12 seem implausible to assume that these variables are only associated because of their commondependenceonO,X,U,andD.Isitreasonabletoassumethatthestructural error terms eY10 and eY12, which are viewable only under magnification, are indepen- dent of each other? For Figure 8.1(b), they were assumed to be so. For Figure 8.2, instead it is assumed that they are only independent of each other after we allow for unobservedcommondirect causes of both Y and Y , which are representedby E in 10 12 Figure 8.2. Although the common cause relationship Y ←E→Y is quite general, 10 12 for now consider E to be an unobservedand completely random characteristic of stu- dents that measures their taste for tests. Independent of all else, some students enjoy takingtestsandperformwellonthem.3 IfsuchacommoncauseofY andY exists, 10 12 it creates four new back-door paths from D to Y through E: 12 1. D←U→Y ←E→Y , 10 12 2. D←O→Y ←E→Y , 10 12 3. D←U←O→X→Y ←E→Y , 10 12 4. D←O→X→Y ←E→Y .\n10 12 For these back-door paths, Y is a collider. In the absence of conditioning, all four of 10 these paths are blocked and do not create additional noncausal associations between D and Y . But, when O, X, and Y are used as adjustment variables, the first path 12 10 3Of course, if this particular variablein E exists, itis unlikelyto be independent of both O and X.Were weto addedges toalsospecifyO→E orX→E as additional causal effects inFigure8.2, all of what is written in the maintext would be the same. These additional back-door paths would beblockedbyconditioningonOandX,butthesameback-doorpath,D←U→Y 10←E→Y 12,that isunblockedafterconditioningonY 10 wouldremain.\nbecomesunblockedbecauseconditioningonY inducesanassociationbetweenU and 10 E (seeChapter4).Thesecondandthirdback-doorpathsremainblockedbythesimul- taneousconditioningontheobservedvariablesO andX,eventhoughconditioningon Y induces an association between O and E as well as between X and E. In short, 10 if Figure 8.2 is the appropriate representation of the causal system, Coleman and his colleagues unblocked an already blocked back-door path, thereby creating a new net association between D and Y . This induced noncausal association is then mixed in 12 with the noncausal association generated by D←U →Y , which critics argued had 12 been mistakenly assumed not to exist. The following demonstration, which considers thesimplestpossiblecausalmodelconsistentwithFigure8.2,explainsthesecomplica- tions together, while also leading into the explicit consideration of heterogeneity that we will take up in the section that follows it.\nPanel Data Demonstration 1 ForthissimulatedexampleoftheanalysisofCatholicschooleffectsbyColemanandhis colleagues,we will use the panel datanotationintroducedinSection 2.8.Nonetheless, because we will consider only posttreatment data on the outcome and because our other variables are fixed in time, we can suppress some of the subscripting and other fine distinctions introduced there.4 In order to focus on the essential identification issues,weconsideronlylinearspecificationsand,exceptwhennotedotherwise,restrict all causal effects to be constants or to vary across individuals in completely random ways independent of all else in the models. These conditions are consistent with the original research by Coleman and his colleagues, even though they are inconsistent withourextensivetreatmentofthisresearchquestionusingthemorerecentliterature (as shown in Chapters 5 through 7, where nonlinearities and heterogeneity of effects were both shown to be vital considerations when modeling the Catholic school effect on achievement).\nFor this demonstration, the potential outcome variables are Y1 and Y0, where t t t={10,11,12} for the three grades that occur during the observation window from the tenth grade through the twelfth grade. Because treatment selection occurs before t=10, we have observed data only for posttreatment time periods. The treatment indicator variable, D, is equal to 1 if a student is enrolled in a Catholic school and 0 if enrolled in a public school. (We again ignore other types of private schools.) The observed outcome variable, Yt, is defined as DY t1+(1−D)Y t0 for t={10,11,12}.\nFor simplicity, our other variables O, X, and U should be interpreted as indices of many underlying variables, which we will scale as normally distributed composite variables. Consistent with our discussion of Figures 8.1 and 8.2, X is a composite determinant of achievement test scores, Yt, that has no direct effect on whether stu- dents select Catholic schooling, D. U is a composite variable of unobserved factors thatdeterminesbothD andYt.AndO isacompositevariableofultimatebackground 4Most importantly, for this demonstration we do not need to make a distinction between D it (the treatment exposure indicator) and D∗ (the treatment group indicator). Because we have no i pretreatment observations and we ignore (as did Coleman and his colleagues) students who switch between public and Catholic schools between the tenth and twelfth grade, D it=D i∗ for all t. We thereforeuseourcustomaryD withoutsubscriptsforeitheriort.\nfactors that determines U, X, D, and Yt. To give these composite variables distribu- tions that are familiar, O is a standard normal random variable with mean of 0 and varianceof1.HavingdefinedO asanexogenousrootvariable,wethensetX=O+eX andU=O+eU, where eX andeU areindependent standardnormalrandomvariables with mean of 0 and variance of 1.\nWeconsiderfourdatasetupscenarios,definedasacross-classificationoftwobinary conditions:(1)thepresenceofself-selectiononaccurateexpectationsofindividual-level effectsofCatholicschoolingand(2)thepresenceofsupplementaldependencebetween the potential outcomes that is produced by an exogenous variable E (see Figure 8.2).\nForallscenarios,theprobabilityofCatholicschoolenrollmentis specifiedasalogistic distribution exp(−3.8+O+U) Pr[D=1|O,U]= , (8.1) 1+exp(−3.8+O+U) where O and U are as defined above. The probabilities defined by Equation (8.1) are then specified as the parameters for draws from a binomial distribution, yielding the indicator variable D for Catholic schooling defined above. As explained below, we introduce self-selection into two of the four scenarios by allowing U to structure the potential outcomes, such that those with higher values for U have higher average individual-level treatment effects. Because of the presence of U in Equation (8.1), students with highervalues forU arethen morelikely to enterCatholic schoolingand more likely to benefit from doing so.\nFor the scenarios without supplemental dependence on E, Y0 is defined as t Y0 =100+O+U+X+υ0 , 10 10 Y0 =101+O+U+X+υ0 , (8.2) 11 11 Y0 =102+O+U+X+υ0 , 12 12 where the υ0 are independent normal random variables with mean of 0. For the sce- t narios with supplemental dependence, Y0 is instead defined as t Y0 =100+O+U+X+E+υ0 , 10 10 Y0 =101+O+U+X+E+υ0 , (8.3) 11 11 Y0 =102+O+U+X+E+υ0 , 12 12 where E is also a normal random variable with mean of 0.5 On average, Y0 follows a t linear time path as determined by the intercept values of 100,101,and 102.However, the levels of these potential outcomes for individuals are set by the time-invariant values of O, U, X, and E as well as by time-specific shocks to their outcomes, υ0.\nt 5To yield a covariance structure similar to real test score data, for Equation (8.2) we specify υ t0 as time-period-specific standard normal random variables multiplied by 10. For Equation (8.3), we specify E as a standard normal random variable multiplied by 5 and υ t0 as time-period-specific standardnormalrandomvariablesmultipliedby8.6.\nTo specify a treatment effect that increases linearly in time, Y1 is defined as t Y1 =Y0 +δ(cid:2) +δ(cid:2)(cid:2) , 10 10 Y1 =Y0 +(1+δ(cid:2) )+δ(cid:2)(cid:2) , (8.4) 11 11 Y1 =Y0 +(2+δ(cid:2) )+δ(cid:2)(cid:2) , 12 12 where δ(cid:2) is a baseline individual-level causal effect, specified as a normal random variablewithmeanof10andvarianceof1.Theconstitutionofδ(cid:2)(cid:2) dependsonwhether self-selection is present. In the no-self-selection scenarios, δ(cid:2)(cid:2) is additional random individual-level variation, specified as a standard normal random variable with mean of 0 and variance of 1. In the self-selection scenarios, δ(cid:2)(cid:2) varies systematically over individuals. The values of δ(cid:2)(cid:2) are set as single draws from individual-specific standard normalrandomvariables with expectation equal to eachindividual’s realizedvalue ui of U.\nThe first panel of Table 8.1 presents the ATE, ATT, and ATC for the effect of Catholic schooling on test scores in the tenth and twelfth grades, as implied by the data setup just detailed. For the first two columns, students do not self-select into Catholic schooling based on accurate expectations of the individual-level gains from doingso.Accordingly,theATE,ATT,andATCareallthesame,andtheyallincrease from10.00 to 12.00 between the tenth and twelfth grades, as determined by Equation (8.4). For the last two columns, students self-select on the causal effect, as explained above.The ATT is largerthan the ATE andthe ATC. But, again,the averagegainis 2.00 for the ATE, ATT, and ATC.\nThe second panel of Table 8.1 presents estimates for the coefficient on D from a series of regression models, first for cross-sectional estimators that use outcome data from only one point in time and then, as in the research of Coleman and colleagues, for panel data models that use outcome data from two posttreatment points in time.\nTheselatterregressionmodels,aswewillexplaininChapter11,arelabeledpaneldata analysisof covariancemodels. We use generic ordinaryleast squares (OLS) regression estimation, as in the original research of Coleman and his colleagues, but we have givenOLSestimationabestcasedatasetupwherelinearspecificationsarereasonable and the pattern of individual-level heterogeneity is simple.\nConsiderfirsttheresultsfortheregressionmodelsintheno-self-selectionscenarios.\nFor the first column, we also do not assume that E is a common cause of both Y 10 and Y , which does not render Y a collider on any back-door paths from D to Y .\n12 10 12 For the second column, E is a common cause. This distinction for the data setup producesnodifferencesforthecross-sectionalregressionestimatesofthecoefficienton D because Y is not in the conditioning set for these models.\n10 For both sets of cross-sectional estimators in the no-self-selection scenarios, the same pattern of results is present for models that have Y as the outcome variable 10 and for models that have Y as the outcome variables. The naive estimator is too 12 large, and adjustment for O and X eliminates only some of the confounding.6 6Additional adjustment for U wouldyield estimates that areequal to the ATE, ATT,and ATC.\nThislastresultismerelyabenchmark, giventhat wehave assumedthat U isunobserved, asinthe researchofColemanandhiscolleagues.\nTable 8.1 Simulated Results for the Identification Approach Adopted by Coleman and Colleagues Setup conditions: Self-selection on the causal effect No No Yes Yes E is a common a cause of Y t0 No Yes No Yes True average treatment effects: ATE,tenth grade 10.00 10.00 10.00 10.00 ATT, tenthgrade 10.00 10.00 11.85 11.85 ATC, tenthgrade 10.00 10.00 9.81 9.81 ATE,twelfth grade 12.00 12.00 12.00 12.00 ATT, twelfth grade 12.00 12.00 13.85 13.85 ATC, twelfth grade 12.00 12.00 11.81 11.81 Estimated Coefficient on D Cross-sectional estimators: Regression of Y 10 on D 14.75 14.75 16.60 16.60 Regression of Y 10 on O, X, and D 10.80 10.80 12.58 12.58 Regression of Y 12 on D 16.75 16.75 18.60 18.60 Regression of Y 12 on O, X, and D 12.80 12.80 14.58 14.58 Panel data analysis of covariance estimators: Regression of Y 12 on Y 10, O, X, and D 12.68 9.98 14.41 11.27 For the analysis of covariance models with Y as the outcome variable, the coeffi- 12 cientestimatesonD donotequaltheATE,ATT,orATCforthetwelfthgrade,which are all 12.00. The coefficient estimate of 12.68 is too large when E is not a common cause because the unblocked back-doorpath throughU biases the coefficient upward.\nThe estimate is then too small when E is a common cause because the upward bias fromtheunblockedback-doorpaththroughU isthenjoinedbyalargerdownwardbias produced by conditioning on Y , which is a collider along the new back-door paths 10 through E (see the discussion that precedes the demonstration for an accounting of these back-door paths).\nAs shown in the third and fourth columns, the basic pattern for the estimated models changes only modestly when self-selection is present. The last two columns are analogous to the first two, after allowing the self-selection term, δ(cid:2)(cid:2), to vary with U, as explained above for Equation (8.4). For these last two scenarios, none of the cross-sectional estimators yield estimates equal to any of the average causal effects, eitherinthetenthgradeorthetwelfthgrade.7 Theanalysisofcovariancemodelshave 7Evenmodels thatadjustforU wouldnot suffice.Fortheself-selectionscenarios,theindividual- leveleffectofCatholicschoolingvarieswithU,suchthatthosewithhigheraveragevaluesofU have the same pattern as in the no-self-selectionscenarios.When E is not a common cause of Y and Y , the estimate is larger than the ATE, ATT, and ATC. When E is a 10 12 common cause, rendering Y a collider, the estimate is smaller than the ATE, ATT, 10 and ATC.\nFinally,noticealsothattheanalysisofcovarianceestimatesarenowhereneartothe average gain in achievement between the tenth and twelfth grades, which is equal to 2.00,and which by construction is equal for both Catholic and public school students and does not depend on whether self-selection is present. As such, under this setup, which is consistent with Figure 8.2, the analysis of covariancemodels do not estimate a net direct effect of Catholic schooling on achievement in the twelfth grade that can be given an interpretation as an estimate of an average gain in achievement.\nMany analysis puzzles and ensuing causal controversies in the social science lit- erature have the same basic features as this demonstration. The plausibility of the criticism in Figure 8.2 should serve as a caution because it demonstrates how addi- tional posttreatment observations of the outcome variable are unlikely to resolve the fundamental identification challenge created by selection on unobservables and non- ignorability of treatment assignment. We consider models of this type in detail in Chapter 11, including a more complete discussion of the sorts of processes that gen- erate over-time dependencies, such as the one produced by E in Figure 8.2. However, we also have some more encouragingresults to offer in Chapter 11. If, as was the case for this demonstration, the causal effect is evolving in time, such that the trajectory for the outcome in the absence of treatment has the same time path before and after treatment exposure, then it is possible to obtain consistent estimates of some average treatment effects of interest.\nBefore offering a full explanation of analysis strategies when data are available from pretreatment time periods, we will consider two other types of estimators – instrumental variable estimators in Chapter 9 and mechanism-based estimators in Chapter 10. To motivate our presentation of these methods in subsequent chapters, we conclude this chapter in the next section by enriching our presentation of directed graph methodology, explaining how graphs can be used to represent full patterns of self-selection and heterogeneity using latent class variables.\nlarger treatment effects. As a by-product, the individual-level causal effect also varies with O and X, given that these variables are positively associated with U because of the common-cause path U←O→X. The conditional-variance weighting that is implicit in OLS regression averages these heterogeneous individual-level effects, giving more weight to those whose implicit propensity scores are near to .5. Given the data setup, where only 9 percent of students end up enrolled in Catholic schools–becauseoftheinterceptof−3.8forthelogisticdistributioninEquation(8.1)–theimplicit weighting would move the estimated average effects toward the ATT relative to the ATC. Yet, the coefficientestimateswouldnotequaltheATT.AsexplainedinSection6.3,thesecoefficientsarebest interpretedasestimates oftheATEwithsupplemental conditional-variance-based weighting, which, for this demonstration, would push the estimates toward the ATT because of the distribution of D and the positive association between U and D. In practice, of course, the variable U would not be availableforanalysisinthefirstplace.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#causal-graphs-for-complex-patterns-of-self-selection-and-heterogeneity",
    "href": "extracted/Counterfactuals and Causal Inference.html#causal-graphs-for-complex-patterns-of-self-selection-and-heterogeneity",
    "title": "Counterfaturals and Causal Inference",
    "section": "8.3 Causal Graphs for Complex Patterns of Self-Selection and Heterogeneity",
    "text": "8.3 Causal Graphs for Complex Patterns of Self-Selection and Heterogeneity\nWeconcludethischapterwithapresentationofhowpatternsofself-selectionandhet-\nerogeneitycanberepresentedwithdirectedgraphs.8Wehavetwogoalsinthissection.\nFirst, we want to demonstrate and explain the generality of the graphical approach to the representationof causalrelationships,which we will utilize insubsequentchap- ters. Second, we want to make the following obvious (but frequently forgotten) point: The best solution to an unobserved variable problem is to develop and deploy addi- tional new measures. Too often, the literature implies that self-selection patterns are so complex that estimation in their presence will forever remain infeasible. We see more promise in developing methods to directly confront the limitations of available data thanthe literature often implies, andwe wantto make this caseexplicitly before offering explanations in the next three chapters of estimation strategies that may be feasible while the limitations of available data remain unaddressed.\nIn this section, we use the charter school effect on learning as the focal example, which we introduced in Section 1.3.2 (see page 24). This example shares some of the samecomplicationsastheexampleoftheCatholicschooleffectthatwehaveconsidered extensively already, but it offers some new complications as well (and serves as a bridge to the school voucher instrumental variable example that will be considered in Chapter 9). In the material that follows, we start with a simple latent class model of heterogeneity that allows families of different types to differ in their likelihood of choosing charter schools. We then build toward a full directed graph that shows the estimationchallengeclearly,atwhichpointwewillthenelaboratetheback-doorpaths inordertodiscussfeasibleestimationstrategiesthatwouldbepossibleifnewmeasures were constructed that would enable direct modeling of choice behavior. We conclude withagraph-aidedinterpretationofextantempiricalresearchoncharterschooleffects.\n8.3.1 A Starting Point: Separate Graphs for Separate Latent Classes Consider the two causal graphs in Figure 8.3, and suppose that the population is partitioned into two latent classes, each of which has its own graph in panel (a) or panel (b). Suppose that P is a family’s parental background, D is charter school attendance, and Y is a score on a standardized test given to all fifth graders in a large metropolitan school district. For these two graphs, the subscripts refer to latent classes, which are also indicated by a latent class membership variable G that takes on values of 1 and 2.9 Althoughsurelyagrossoversimplification,supposenonethelessthatthepopulation is composed of fifth graders who have been raised in two types of families. Families with G=1chooseschoolspredominantlyforlifestylereasons,suchasproximitytothe home and tastes for particular school cultures, assuming that all schools are similar 8ThissectiondrawsonmaterialpreviouslypublishedinMorganandWinship(2012).\n9Thelowercasevaluesx,d,andy forthetwocausalgraphs aremeanttoconnote that theseare realizedvaluesofX,D,andY thatmaydifferintheirdistributionsacrossthetwolatentclasses.\nd d 1 2 α δ α δ 1 1 2 2 p 1 β 1 y 1 p 2 β 2 y 2 (a) G = 1 (b) G = 2 Figure8.3 Separate causal graphs for two groups of individuals (G=1 and G=2) where the effects of parental background (P) and charter schools (D) on test scores (Y) may differ for the two groups.\nin instructional impact because achievement is largely a function of individual effort.\nFamilieswithG=2chooseelementaryschoolsfortheirchildrenbyselectingtheschool, subject to constraints, that they feel will maximize the achievement of their children, assumingthatschoolsdiffer inqualityandthattheir childrenmaylearnmoreinsome schools than in others. Accordingly, these families are attentive to the national press coverageofeducationalpolicy,inwhichmanypolicymakershavearguedforincreasing the number of charter schools in the country because some research has claimed that charter schools are more effective than traditional public schools. As a consequence, the second group of families is more likely to send their children to charter schools, such that the mean of D is higher for those families with G=2 than G=1.\nFinally,supposethatparentswithhigherlevelsofeducationaremorelikelytovalue distinctive forms of education, and as a result are more likely to send their children to charter schools (independent of whether or not highly educated parents are more likely to be found in the latent class for whom G=2, which we will discuss later).\nThey are also more likely to be able to support children in completing homework and otherwise making the most of the educational opportunities that are offered to their children. Accordingly, suppose that in both groups the causal effects P → D and P → Y are positive and substantial (i.e., that α , β , α , and β in Figure 8.3 are 1 1 2 2 positive and substantial).\nThe question for investigation is whether the effect of D on Y is positive for both groups and, if so, whether it is the same size for both groups. If one is willing to assume, assome ofthe literature suggests,that the secondgroupoffamilies is correct in the sense that school quality does matter for student learning, and further that charter schools are higher quality, then we should expect that both δ and δ are 1 2 more likely positive than not. And, if one believes that parents with G=2 have some sense that this is correct, then not only will more of them send their children to charterschools,theywillalsosorttheirchildrenmoreeffectivelyintocharterandnon- charterschools.Inotherwords,theywillalsobemorelikelytocontinuetoenrolltheir childreninregularpublicschoolsiftheyfeelthattheirchildrenwillnotbenefitfromthe distinctive characteristics of available charter schools (e.g., if the charter schools that have openings have instructional themes that their children find distasteful). Because both of these self-selection effects are reinforcing, is it likely that δ &gt;δ .10 2 1 10Thesetargetparameters,δ 2andδ 1,aredefinedimplicitlyastheaverageeffectofcharterschooling forallstudents fromfamilieswithG=2andG=1,respectively.\nIf this plausible scenario is true in reality, what would happen if a researcher ignored the latent classes (either by mistake or, more realistically, because the mem- bership variable G is unobserved) and simply assumed that a single graph prevailed? In this case, a researcher might estimate the effect of D on Y for each value of P and then average these effects over the distribution of P, yielding a population-level estimate δ. At best, this estimate would be uninformative about the underlying pat- tern of heterogeneity that suggests that δ &gt;δ . At worst, this estimate would be 2 1 completely wrong as an estimate of the average causal effect of D on Y, which we have referred to as the ATE in prior chapters. For example, if P predicts latent class membershipG,andGpredictsthesizeoftheeffectofDonY,thenP-stratum-specific effects mix together individual-level causal effects that vary with the conditional dis- tribution of G within the strata of P. Combining P-stratum-specific effects by cal- culating an average effect across only the distribution of P does not properly weight the G-stratum-specific effects that are embedded in differential patterns within the strata of P.\nIn order to consider these possibilities, we need to have a model of selection into D that is informed by a model of the traits of families that would cause them to be foundinunderlyinglatentclasses.Itismostnaturaltopursuesuchamodelinasingle causal graph that explicitly represents the latent classes by including the variable G as a node within it.\n8.3.2 A Single Graph That Represents All Latent Classes Consider Figure 8.4, which contains a standard causal triangle where D has an effect on Y but where both D and Y share a common cause P. To this triangle, the latent class membership variable G is introduced as an explicit cause of D. The variable G is given a hollow node, ◦, to indicate that it is unobserved.11 The arrowfromG to D is presentbecause there are alternativegroups offamilies, codedbythealternativevaluesoftheunobservedvariableG,thatapproachdifferently thedecisionofwhethertosendtheirchildrentocharterschools.Asaresult,Gpredicts charter school attendance, D. Although we will continue to write as if G only takes on two values that identify two latent classes, this restriction is no longer necessary.\nG may take on as many values as there are alternative groups of families who differ systematically in how they approach and enact the decision of whether to send their children to a charter school. (We considered only two values for G in Figure 8.3 to limit the number of G-specific graphs that needed to be drawn.) The corresponding structural equations for the graph in Figure 8.4 are then P =fP(eP), (8.5) G=fG(eG), (8.6) D=fD(P,G,eD), (8.7) Y =fY(P,D,eY). (8.8) 11Here, we followElwertand Winship (2010) and introduce alatent class variableG to represent effectheterogeneity.\nG D P Y Figure8.4 A graphwheregroupsarerepresentedby anunobservedlatentclassvari- able (G) in a single graph.\nThe latent class membership variable G only enters these structural equations in two places, on its own in Equation (8.6) and then as an input to fD(.) in Equation (8.7).\nRecall also that the unspecified structure of the functions such as fY(.) permits the sort of interactions discussed in the last subsection, where, for example, the effect of D depends on the level of P. (See Section 3.3.2 for a full discussion.) To accept Figure 8.4 as a full representationof the causalrelationships between G and the other variables P, D, and Y, we must be able to assume that G shares no commoncauseswithP,D,orY thathavebeenmistakenlysuppressed.Thenecessary assumptions are that students who have parents with higher levels of education are no more likely to know of the educational policy dialogue that claims that charter schools have advantages and also are no more likely to think that school quality has anyeffectsonachievement.Wemustalsobewillingtoassumethat,withinvaluesofP andD,GhasnocausaleffectonY,whichwithourexampleistantamounttoassuming thatthosewhoattempttomaximizethelearningoftheirchildrenbyselectingoptimal schools(1)donotmanagetodosowellenoughsothattheobtainedeffectisanylarger on average,conditional on other factors, for their own children than for those who do not attempt to select on the causaleffect of schooling and (2) do not do anything else that helps their children to benefit from the learning opportunities provided to them in schoolor in the home that is not alreadycapturedby the direct effect P →Y. This wouldrequirethattheimpulsetoselectintocharterschoolsbasedonbeliefsaboutthe size of the charter school effect for one’s own child is a completely ignorable process, since it does notresult in any actualselectionon the variationin the causaleffect nor generate any reinforcing behavior that might complement the charter school effect.\nNone of the literature on charterschooleffects supports such a dismissal of the power of self-selection.\nAccordingly, for Figures 8.5(a) and 8.5(b), we add an arrow from G to Y to the graph presented earlier in Figure 8.4. For Figure 8.5(a), which includes only this one additional arrow,the structural equations are P =fP(eP), (8.9) G=fG(eG), (8.10) D=fD(P,G,eD), (8.11) Y =fY(P,D,G,eY). (8.12) G G D D P Y P Y (a) (b) Figure8.5 Two graphs where selection into charter schools (D) is determined by group (G) and where selection renders the effect of D on Y unidentified as long as G remains unobserved.\nFor Figure 8.5(b), we drop the assumption that G is independent of P. This elabo- rated graph now includes an arrow from P to G. As a result, fG(eG) is no longer the appropriate function for G.Equation ( 8.10) must be replaced by G=fG(P,eG) (8.13) so that family background is an explicit cause of latent class membership. It is likely that parents with high socioeconomic status are more likely to select on the possible causal effect of charter schooling, which is how the latent classes were discussed for Figure 8.3. Still, how these latent classes emerge is not sufficiently transparent in Figure 8.5. A more explicit causal model that gives structure to the causal pathway from P to G may help to clarify the self-selection dynamic, as we show next.12 8.3.3 Self-Selection into the Latent Classes Suppose that the latentclass membershipvariableG is determined atleastin partby avariablethatmeasuresafamily’ssubjectiveexpectationoftheirchild’slikelybenefit from attending a charter school instead of a regular public school.Although we could enter this variable into a graph with a single letter, such as S or E, for Figure 8.6 we useafullmnemonicrepresentationasavariablelabeledExp(D→Y),whichrepresents “thefamily’ssubjectiveexpectationofthespecificeffectofD onY fortheirparticular child.” For Figure 8.6(a), which is a direct analog to Figure 8.5(a), this subjective 12Insomework,latent classmembershipvariables suchasGarenotregardedas causal variables.\nWeregardGasanominalcausalvariablebecausewecanconceiveofaninterventionthatcouldmove a family from one value of G to another. The goal of introducing G into this graph is to provide a representation of consequential individual-levelheterogeneity, and accordingly weallow G to have nominal causal effects on the outcome of interest through G→Y. We will explain later why a fully elaboratedgraphthatlocates thesourcesofallsuchheterogeneity instructural variablesthat lieon directed paths that reach G would thereby render G as a redundant carrier of these fully specified determinantsofheterogeneity. Inthiscase,Gcouldthenberemovedfromthegraph,astherewould be no need for a nominal causal variable to transmit the heterogeneity produced by its genuine determinants.\nExp(D Y) G Exp(D Y) G I D D P Y P Y (a) (b) Figure8.6 Two graphswhere selectiononthe unobservablesis givenanexplicit rep- resentationas self-selectionon subjective expectations ofvariationin the causal effect of D on Y. For panel (b), these expectations are determined by information (I) that is differentially available to families with particular parental backgrounds (P).\nexpectation is the sole determinant of G. The structural equations are then P =fP(eP), (8.14) Exp(D→Y)=f (e ), (8.15) Exp Exp G=fG[Exp(D→Y), eG], (8.16) D=fD(P,G,eD), (8.17) Y =fY(P,D,G,eY). (8.18) Note that Exp(D→Y) is determined solely by e in Equation (8.15). Thus, the Exp graph in Figure 8.6(a) would be an accurate representation of the system of causal relationshipsifsubjectiveexpectationswereeithercompletelyrandomorinsteadbased solely on characteristics of families that are independent of the family background variables in P.\nGiven what we have written about the likelihood that families with different pat- terns of P will end up in different latent classes represented by G, it seems clear that Figure 8.6(a) is not the proper representation for the research scenario we have alreadyspecified. Accordingly,in Figure 8.6(b), e is joined by an unspecified addi- Exp tional input I into the subjective expectation of the child-specific causal effect of D onY,whichisthenpresumedtobecaused,inpart,byfamilybackground.Asaresult, thereisnowapathfromP toGthroughI andExp(D→Y).Thestructuralequations are now augmented as P =fP(eP), (8.19) I=fI(P,eI), (8.20) Exp(D→Y)=f (I,e ), (8.21) Exp Exp G=fG[Exp(D→Y), eG], (8.22) D=fD(P,G,eD), (8.23) Y =fY(P,D,G,eY). (8.24) Insociology,thecausaleffectofP onExp(D→Y)viaI followsfromthepositionthat privilegedpositionsinsocialstructureareoccupiedbyadvantagedfamilies.Fromthese positions,individualsacquireinformationI thatallowsthemtorecognizebenefitsthat are available to them.13 The directed path P →I →Exp(D→Y)→G carries one important systematic source of self-selection through to the latent class variable G. However, this path is not the only directed path that is present, as could be seen under magnification.\nThe differences in information about the charter school effect that are independent of parental background have their effect on G through eI →I →Exp(D→Y)→G.\nLikewise, differences in expectation formation processes that are not based on infor- mation and are independent of parental background have their effects on G through e →Exp(D→Y)→G.\nExp By building the full graph progressively from Figures 8.4 through 8.6(b), we have explicitly elaboratedwhat is often presumedin models that incorporateself-selection.\nBackgroundvariablesinP arerelatedtothecauseDbywayofasetoflatentclassesin Gthatencodesubjectiveevaluationsoftheindividual-specificcausaleffectofD onY.\nThese expectations are functions, in part, of characteristics in P by way of the infor- mation I that is differentially available to families that differ on P. Yet, even though we now have an elaborate representation of self-selection, we still have not brought what some would label “contextual effects” into the model, such as neighborhood of residence. We consider this complication next, which is clearly important to consider when modeling the effects of charter schools on learning.\n8.3.4 Self-Selection into the Treatment and a Complementary Context How hard is the task of allowing for contextual effects? Consider Figure 8.7, which incorporates a contextual variable N into the causal graph in Figure 8.6(b). N repre- sentsallcausesofstudentachievementthatcanbeconceptualizedaseitherfeaturesof astudent’sresidentialneighborhoodorfeaturesofacharterschool’ssurroundingneigh- borhood. The component variables in N might be access to resources not measured by P or specific local cultures that may or may not promote student achievement.14 13In addition, it may be that there are also additional common causes of P and I, which could be represented by a bidirected edge between P and I in the graph. This would be reasonable if informational advantages that structure expectations for optimal school choices are determined by deeper structural factors that alsoconfer socioeconomic advantages onparents beforethey arriveat thedecisionpointofwhether ornottosendtheirchildrentocharter schools.Itisalsopossiblethat parental background determines expectation formationprocessestosomedegree,suchthat different familiesprocess informationdifferently, aswouldbecase ifthedirected pathP→Exp(D→Y)→G were added to the graph. We do not include these additional causal pathways in the graph because they would add additional back-door paths to the subsequent discussion without changing the core identificationresults.\n14If the latter are only diffuse cultural understandings that only weakly shape local norms about theappropriatenessofenactingtheroleofachievement-orientedstudent,thensuchvariablesmaybe difficulttoobserve.Inthiscase,N mightthenbecodedasaseriesofneighborhooddummyidentifier variables. Analysis of these effects would then only be possible if there were sufficient numbers of students to analyze from within each neighborhood studied. Without such variation, the potential effectsofN couldnotbeseparatedfromindividualcharacteristicsofstudentsandtheirfamilies.And, if modeled in this way, only the total effects of N would be identified, since the dummy variables for N would not contain any information on the underlying explanatory factors that structure the neighborhoodeffects thattheyidentify.\nExp(D Y) G N I D Y P Figure8.7 A graph where self-selection on the causal effect of charter schooling also triggers self-selection into consequential and interactive neighborhood contexts (N).\nWith the addition of N, the function for Y is now fY(P,D,G,N,eY). Recall, again, that N is not restricted by any functional form assumption for fY(.). As a result, the causal effect of N can modify or interact with the effects of G, D, and P on Y.15 Figure 8.7also allowsforevenmore powerfuleffects of self-selection.Suppose that self-selectionintothelatentclassesinGisassociatedwithself-selectionintoN aswell.\nWe see two separate and countervailing tendencies. Parents attuned to the potential benefitsofcharterschoolingarealsomorelikelytochooseneighborhoodcontextsthat bestallowthemtoencouragetheirchildrentostudyhardinschool.Atthesametime, after obtaining an attendance offer from a charter school, a family may also decide to move to an alternative neighborhood in the catchment area of a suboptimal regular public school, since attendance at such a school may no longer be a consideration in the family’s residential decision. If either effect is present, then the function for N is equal to fN(G,eN), and we then have seven structural equations as P =fP(eP), (8.25) I=fI(P,eI), (8.26) Exp(D→Y)=f (I,e ), (8.27) Exp Exp G=fG[Exp(D→Y), eG], (8.28) D=fD(P,G,eD), (8.29) N=fN(G,eN), (8.30) Y =fY(P,D,G,N,eY). (8.31) The nonparametric nature of these structural equations allows for fully interactive effects. Most importantly,the function for Y, fY(P,D,G,N,eY), allows for the effects of D and N to vary within each distinct combination of values between them, as wouldbe the caseif the charterschooleffectvariedbasedonthe neighborhoodwithin which students lived. We should also note that we could enrich the causal model further by drawing from the literature that posits deeper causal narratives for the joint determination of P and N, as well as other causal pathways that link P to N.\nWe see the graph in Figure 8.7 as sufficiently rich to motivate the discussion we have offered so far as well as for the analysis of the extant empirical research to which we turn next.\n15SeeVanderWeele(2009b)foranincisiveanalysisofthedifferencebetweenaninteractionandan effect modification. Our interest, conceptually at least, is in instances of genuine causal interaction, althoughmuchofwhatwewritewouldholdundersimplerstructuresofonlyeffect modification.\n8.3.5 A Graph-Aided Interpretation of Extant Empirical Models of Charter School Effects There are two basic goals of writing down a causal graph: (1) to represent the set of causal relationships implied by the available state of knowledge and (2) to assess thefeasibilityofalternativeestimationstrategies.Figure8.7representsacausalgraph that is a reasonable representation of the causal structure that generates the charter school effect. This is a matter of judgment, and one might contend, for example, that the claim that self-selection on the charter school effect generates movement between neighborhoods is overly complex.\nSupposethatonehasaccesstoobservationaldata,suchastheNationalAssessment ofEducationProgress(NAEP)dataanalyzedbyLubienskiandLubienski(2003),that provide information on standardized test scores, school type, and some family back- groundcharacteristics.Forthesakeofourexposition,supposefurtherthattheseNAEP datahadevenbettermeasuresoffamilybackgroundandneighborhoodcharacteristics, so that we could conclude that high-quality data are available for all of the variables in Figure 8.7 with solid nodes: Y, D, N, and P. Yet, no data are available for the variables with hollow nodes: I, Exp(D→Y), and G. The primary goal of analysis is to estimate the average causal effect of D on Y, as this effect interacts with the complementary causal effect of N on Y. Can one adjust for confounding in order to estimate these effects? The first question to consider is the following: Is there a set of observed variables inFigure 8.7thatsatisfies the back-doorcriterionwiththe respectthe causaleffect of D on Y and the causal effect of N on Y? The relevant back-door paths are, for D, 1. D←P →Y, 2. D←P →I→Exp(D→Y)→G→Y, 3. D←P →I→Exp(D→Y)→G→N→Y, 4. D←G→N→Y, 5. D←G→Y; and for N, 6. N←G→Y, 7. N←G→D→Y, 8. N←G←Exp(D→Y)←I←P →Y, 9. N←G←Exp(D→Y)←I←P →D→Y, 10. N←G←Exp(D→Y)←I←P →D←G→Y.\nHow many of these paths can be blocked by conditioning on the observed data? For models that estimate the effect of D on Y, paths 1 through 4 can be blocked by conditioning on P and N. However, path 5 remains unblocked. Likewise, paths 7 through 10 can be blocked by conditioning on P and D, but path 6 remains unblocked.Forthetwounblockedpaths,thesameproblematiceffectispresent:G→Y.\nThis effect transmits the effects of exogenous causal determinants of I and Exp(D→Y), which are eI and e Exp, through the directed path I →Exp(D→Y) →G→Y.Thus,ifthereisselectiononthecausaleffectitself,independentofparental background, then it enters the model through G and confounds the conditional asso- ciations between D and Y and between N and Y. This confounding cannot be elimi- nated by conditioning on the observeddata, and therefore back-door conditioning for the effects of D and N on Y is infeasible.\nThisconclusionishardlyrevelatoryforreaderswhoalreadyknowtheliteratureon self-selectionbiasand/ortheempiricalliteratureoncharterschooleffects.Nonetheless, we would argue that there is substantial didactic and communicative value in seeing this result expressed with a causal graph to which the back-door criterion is then applied.To effectively use back-doorconditioning to identify all averagecausal effects of primary interest – the ATC, ATT, and ATE – we would need to specify a more elaborate set of causes of G, which would generate G through and/or alongside the structuralequations that determine I andExp(D→Y). Itwouldbe sufficient to have a model for G, fG(.), where all inputs other than eG are observed and where these inputs are sufficiently rich such that eG can be regarded as a constant that applies to everyone.Equivalently, we would need a set of observedmeasures as variables that point to G in the graph that would allow us to declare that there are no more latent classesprecisely because G is a deterministic function of the observedvariables in the graph. In this case, all sources of the noncausal association between D and Y and between N and Y would be indexed by the observed variables that determine G, and we could safely remove G from the graph and allow those variables to point directly to D, N, and Y.\nWithout accessto suchobservedvariables,whichpreventus fromexplaining away the existence of the latent classes indexed by G, how can analysis proceed? There are twomainchoices.First,theanalystcanconcedethatself-selectiononthecausaleffect ispresent(because Gcannotbe eliminatedfromthe graph),whichmayevengenerate neighborhood-basedselectionasa by-product.Inthese circumstances,the presenceof the causal relationship G→Y rendersestimates of D andN on Y unidentified, either in interactive fashion or when averaging one over the other. In this case, analysis must then be scaled back, and we would recommend that set identification results be pursued, as we will explain later in Chapter 12. The new goal would be to estimate an interval within which the averagecausal effect of interest must fall.\nIn the actual empirical literature on the charter school effect, this humble option has not been pursued by any of the main combatants in the debates. Instead, this research is a good example of what Manski (2013b) has labeled “policy analysis with incredible certitude.” The desire to provide point estimates of causal effects has been too strong, even though it would seem clear to many outside readers that the debate over charter school effects persists simply because the point estimate of the ATE is unidentified. Consider the two dominant positions in the extant literature.\nOne group of researchers has used the lottery-induced structure of charter school enrollmentsinordertoestimateeffects.Incitieswherethenumberofcharterschoolsis insufficienttomeetdemand,mostschoolsarerequiredbytheircharteringauthoritiesto performrandomlotteriesandofferadmissionfirsttothosewhowintheirlotteries.This admissions mechanism delivers two comparable groups: lottery winners and lottery losers. If the lottery winners attend charter schools and the lottery losers do not, then observation of achievement trajectories following the lottery enables estimation of averagetreatment effects for those who participate in the lottery.16 The researchers who use this research design typically define the charter school effect of interest as solely the ATT: the effect of charter schooling among those who would self-select into charter schooling by applying for the lottery. This is entirely appropriate for the interpretation of lottery-based results. The problem is that these samescholarstoofrequentlyforgettheboundednatureoftheirconclusions.Forexam- ple, in their study of charter schools in New York City, Hoxby, Murarka, and Kang (2009:vii) introduce their results in their “Executive Summary” with three bullet points: • “Lottery-basedanalysis of charter schools’ effects on achievement is, by far, the mostreliablemethodofevaluation.Itistheonlymethodthatreliablyeliminates ‘selection biases’ which occur if students who apply to charter schools are more disadvantaged,moremotivated,ordifferentinanyotherwaythanstudents who do not apply.” • “On average, a student who attended a charter school for all of grades kinder- garten through eight would close about 86 percent of the ‘Scarsdale-Harlem achievement gap’ in math and 66 percent of the achievement gap in English. A studentwho attended fewer gradeswouldimproveby a commensuratelysmaller amount.” • “Onaverage,alotteried-outstudentwhostayedinthetraditionalpublicschools for allofgradeskindergartenthrougheightwould stayon gradelevelbut would notclosethe‘Scarsdale-Harlemachievementgap’bymuch.However,thelotteried- outstudents’ performance does improveandis better thanthe norminthe U.S.\nwhere, as a rule, disadvantaged students fall further behind as they age.” Nowhere in their “Executive Summary” is it stated that these comparisons across lotteried-inandlotteried-outstudentsareonlyinformativeaboutthosewhoself-select into the relevant charter school lottery. Selection bias is not eliminated, as claimed in the first bullet point; the lottery-generateddata simply provide a reasonable compar- ison among those who self-select into the charter school lottery.\nMore generally, it is not conceded that the results are uninformative about two first-order policy questions: 1. What is the expected charter school effect for a randomly chosen student from New York City, assuming the supply of charter schools is held constant? 2. What is the expected charter school effect for the subset of students in public schoolswhowouldbeinducedtoapplytocharterschoolsifapolicyintervention were implemented to expand the supply of charter schools? 16For simplicity, in this discussion we ignore non-comparability generated by random variation, initialcompliancewiththelottery,andselectiveattritionovertheobservation windowfollowingthe lottery. In most cases, the researchers who have modeled these effects have carefully adjusted their datatoneutralizethesethreats toinference.\nTo answer these questions, the authors would need a full model of the charter school effect for students who never applied to charter schools, and lottery-basedstudies use no data on these students. The ATT is the appropriate parameter to estimate only when addressing a second-order policy question that is not the focus of the debate: “Should charter schools in New York City continue to receive support because those students who have chosen to attend them have learned more than they would have if they had attended regular public schools?” The answer to this question appears to be yes, and yet Hoxby et al. (2009) chose not to limit their conclusions only to this supportable position, at least when putting forward their primary conclusions.\nIf this were nottroubling enough,the alternative is worse.One cansimply assume away the unblocked paths that include G→Y, which is tantamount to assuming that self-selection does not exist. The study of the Center for Research on Education Outcomes(2009)isclosertothisposition.Itsauthorsofferacomplexsetofconclusions based on national results where charter school students are matched to students from traditional public schools based on observed characteristics. Their overall conclusion isthatcharterschoolsaregenerallyineffective foramajorityofstudents,eventhough charter schools may be effective for a minority of students who are not well servedby regular public schools: In our nationally pooled sample, two subgroups fare better in charters than inthe traditional system: students inpovertyand ELL[EnglishLan- guage Learner] students….These findings are particularly heartening for the charter advocates who target the most challenging educational popu- lationsorstrivetoimproveeducationoptionsinthe mostdifficultcommu- nities. Charter schools that are organized around a mission to teach the mosteconomicallydisadvantagedstudentsinparticularseemtohavedevel- opedexpertiseinservingthesecommunities….Theflip-sideofthisinsight shouldnotbeignoredeither.Studentsnotinpovertyandstudentswhoare not English language learners on average do notably worse than the same students who remain in the traditional public school system. Additional workisneededtodeterminethereasonsunderlyingthisphenomenon.Per- haps these students are “off-mission” in the schools they attend. (Center for Research on Education Outcomes 2009:7) These conclusions are offered based on models that match students on observable characteristics, leaving unobserved selection on the causal effect unaccounted for and almost entirely ignored in the write-up of the results. The report is written as if variation in the average treatment effect for different types of students is the central interest, and that matching justifies estimation of all such conditional averageeffects.\nIt bears noting that the pattern presented in this study by CREO is consistent with the one that we favored for the extended example that concluded Chapter 7, whichweseemoregenerallyasthesignatureofanunderlyingpatternofself-selection.\nIn this case, students from families who are living in poverty but who make their way into charter schools are fleeing poor alternatives in their own neighborhood schools and,furthermore,haveextraamountsof motivationto succeedinschool.Atthe same time, it is likely that students from more advantaged families are more likely to be attending charter schools solely for lifestyle reasons. In fact, they may be trading off academic opportunities in high-quality schools that they have found distasteful for medium-quality charter schools with peer cultures or instructional programs that are more appealing.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#conclusions-5",
    "href": "extracted/Counterfactuals and Causal Inference.html#conclusions-5",
    "title": "Counterfaturals and Causal Inference",
    "section": "8.4 Conclusions",
    "text": "8.4 Conclusions\nInthischapter,wehavemadethetransitionfrom“easy”to“hard”instancesofcausal\neffect estimation. No longer does simple conditioning onthe observeddeterminants of the cause or all other direct causes of the outcome allow for identification and consis- tent estimation of the causal effect of interest. Instead, we have considered examples in which important variables that might have been used to mount an effective con- ditioning strategy are unobserved. Thus, selection of the treatment of interest is on unobserved characteristics of individuals that have unknown but suspected relation- ships to the outcome. We have also expanded our usage of directed graphs to show how patterns of self-selection and heterogeneity can be given explicit representations, andwehavemadetheimplicitcasethatomittedvariableproblemsarebestaddressed, in the long run, by developing and deploying new measures.\nWeturninthenextthreechapterstoapresentationofadditionalmethodstoiden- tify causaleffects withobservedvariableswhenonecannotmovebeyondthe available data: instrumental variable estimators in Chapter 9, causal mechanisms in Chapter 10, andpaneldata models that utilize pretreatmentmeasures ofthe outcome variable inChapter11.Wewillexplainthesestrategiesindetail,discussingtheirstrengthsand weaknesses along the way.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#causal-effect-estimation-with-a-binary-iv",
    "href": "extracted/Counterfactuals and Causal Inference.html#causal-effect-estimation-with-a-binary-iv",
    "title": "Counterfaturals and Causal Inference",
    "section": "9.1 Causal Effect Estimation with a Binary IV",
    "text": "9.1 Causal Effect Estimation with a Binary IV\nWebeginourpresentationwiththesimplestscenarioinwhichaninstrumentalvariable\ncan be used to effectively estimate a causal effect. Recall the causal regression setup in Equation (6.3): Y =α+δD+ε, (9.1) where Y is the outcome variable, D is a binary causal exposure variable, α is an intercept, δ is the causal effect of D on Y, and ε is a summary random variable 291 Z ε Z ε D Y D Y (a) Z is a valid instrumental (b) Z is not a valid instrumental variable for D variable for D Figure 9.1 Two graphs in which Z is a potential instrumental variable.\nthat represents all other causes of Y. As noted above, when Equation (9.1) is used to represent the causal effect of D on Y, the parameter δ is usually considered an invariant, structural causal effect that applies to all members of the population of interest. We will maintain this traditional assumption in this section.1 Suppose that the probability that D is equal to 1 rather than 0 is a function of a binaryvariableZ thattakesonvaluesof0and1.Figure9.1presentstwopossibleways in which the variable Z could be related to both D and Y. Note first that, for both graphs, the back-door paths represented by D(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)ε→Y prevent a least squares regression of Y on D from generating a consistent or unbiased estimate of the effect of D on Y. More generally, no conditioning estimator would effectively estimate the causal effect of D on Y for these graphs because no observed variables satisfy the back-door criterion.\nNow consider how Z, which we have labeled a “potential instrumental variable,” is related to the outcome variable Y according to the alternative structures of these two graphs. For both Figures 9.1(a) and 9.1(b), Z has an association with Y because of the directed path Z →D→Y. In addition, the paths collectively represented by Z→D(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)ε→Y do not contribute to the association between Z and Y because D is a collider variable along all of them. However, for Figure 9.1(b), the additional paths represented by Z(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)ε→Y contribute to the association between Z and Y because of the common causes that determine both Z and ε.2 This last difference is thereasonthatZ canbeusedtoestimatethecausaleffectofD onY forFigure9.1(a) but not for Figure 9.1(b), as we will now explain.\nIf we continue to maintain the assumption that the effect of D on Y is a constant structural effect δ, then it is not necessary to relate all of the variation in D to all of the variation in Y in order to obtain a consistent estimate of the causal effect. Under this assumption, if we can find a way of isolating the covariation in D and Y that is causal,thenwecanignorethe othercovariationinD andY thatisnoncausalbecause it is generated by the common causes of D and ε. For Figure 9.1(a), the variable Z represents an isolated source of variation across which the analyst can examine the covariation in D and Y that is causal. In this sense, Z is an “instrument” for 1InPearl’sframework,weareassumingthatf Y(D,e Y)isdefinedasthelinearfunctionα+δD+ε andwhereαandβ arescalarconstants.\n2We have drawn the two bidirected edges separately for Figure 9.1(b) for simplicity. The same reasoningholdswhensomeofthecommoncauses ofZ andεarealsocauses ofD (andsoon).\nexamining an isolated slice of the covariation in D and Y. For Figure 9.1(b), Z does notprovideanisolatedsourceofvariation.Theanalystcanstillexaminetheportionof the covariationin D and Y that can be calculated across levels of Z, but some of this covariation must be noncausal because D and Y are dependent on common causes embedded in the bidirected edge in the back-door paths collectively represented by D←Z(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)ε→Y.\nToseethisresultwithoutreferencetographs,takethepopulation-levelexpectation ofEquation(9.1),E[Y]=E[α+δD+ε]=α+δE[D]+E[ε],andrewriteitasadifference equation in Z: E[Y|Z=1]−E[Y|Z=0] (9.2) =δ(E[D|Z=1]−E[D|Z=0])+(E[ε|Z=1]−E[ε|Z=0]).\nEquation (9.2) is now focused narrowly on the variation in Y, D, and ε that exists across levels of Z.3 Now, take Equation (9.2) and divide both sides by E[D|Z =1] −E[D|Z=0], yielding E[Y|Z=1]−E[Y|Z=0] (9.3) E[D|Z=1]−E[D|Z=0] δ(E[D|Z=1]−E[D|Z=0])+(E[ε|Z=1]−E[ε|Z=0]) = .\nE[D|Z=1]−E[D|Z=0] If the data are generated by the set of causal relationships depicted in Figure 9.1(a), then Z has no linear associationwith ε, and E[ε|Z=1]−E[ε|Z=0] in Equation(9.3) is equal to 0. Consequently, the right-hand side of Equation (9.3) simplifies to δ: E[Y|Z=1]−E[Y|Z=0] =δ. (9.4) E[D|Z=1]−E[D|Z=0] Under these conditions, the ratio of the population-level linear association between Y and Z and between D and Z is equal to the causal effect of D on Y. This result suggests that, if Z is in fact associated with D but not associated with ε (or with Y, except through D), then the following sample-based estimator will equal δ in an infinite sample: δˆ IV,WALD≡ EE NN [[ dyi i| |z zi i= =1 1] ]− −E EN N[ [y di i| |z zi i= =0 0] ]. (9.5) As suggested by its subscript, this is the IV estimator, which is known as the Wald estimatorwhentheinstrumentisbinary.AlthoughtheWaldestimatorisconsistentfor δ in this scenario, the assumption that δ is an invariant structural effect is crucial for thisresult.4 Fromapotentialoutcomesperspective,inwhichwegenerallyassumethat 3Equation (9.2) is generated in the following way. First, write E[Y]=α+δE[D]+E[ε] con- ditional on the two values of Z, yielding E[Y|Z =1]=α+δE[D|Z=1]+E[ε|Z=1] and E[Y| Z=0]=α+δE[D|Z=0]+E[ε|Z=0]. Note that, because α and δ are considered constant struc- turaleffectsforthistraditionalmotivationofIVestimation,theydonotvarywithZ.Now,subtract E[Y|Z=0]=α+δE[D|Z=0]+E[ε|Z=0] from E[Y|Z=1]=α+δE[D|Z=1]+E[ε|Z=1]. The parameterαiseliminatedbythesubtraction,andδcanbefactoredoutofitstwoterms,resultingin Equation(9.2).\n4AsfortheoriginoftheWaldestimator,itiscustomarilytracedtoWald(1940)byauthorssuch asAngristand Krueger(1999). Aswediscuss later,theWaldestimator isnot generallyunbiasedin afinitesampleandinsteadisonlyconsistent.\ncausaleffectsvarymeaningfullyacrossindividuals,thisassumptionisverylimitingand quite likely unreasonable.Explainingwhenandhow this assumptioncanbe relaxedis one of the main goals of this chapter.\nForcompleteness,returntoconsiderationofFigure9.1(b),inwhichZ hasanonzero association with ε. In this case, E[ε|Z=1]−E[ε|Z=0] in Equations (9.2) and (9.3) cannot be equal to 0, and thus Equation (9.3) does not reduce further to Equation (9.4). Rather, it reduces only to E[Y|Z=1]−E[Y|Z=0] E[ε|Z=1]−E[ε|Z=0] =δ+ . (9.6) E[D|Z=1]−E[D|Z=0] E[D|Z=1]−E[D|Z=0] In this case, the ratio of the population-level linear association between Y and Z and between D and Z does not equal the causal effect of D on Y but rather the causal effectofD onY plusthelasttermontheright-handsideofEquation(9.6). TheWald estimator in Equation (9.5) is not consistent for δ in this case. Instead, it converges to the right-handside of Equation (9.6), which is equal to δ plus a bias term that is a function of the net association between Z and ε.\nMore generally, an IV estimator is a ratio that is a joint projection of Y and D onto a third dimension Z. In this sense, an IV estimator isolates a specific portion of the covariation in D and Y. For that selected covariation to be the basis of a valid causal inference for the effect of D on Y, it cannot be attributable to any extraneous commoncausesthatdeterminebothZ andY.And,tojustifythecausaleffectestimate generated by a subset of the covariation in D and Y as a consistent estimate of the population-level causal effect of D on Y, it is typically assumed in this tradition that δ isaconstantforallmembersofthepopulation.5 Considerthefollowinghypothetical demonstration, which is based on the school voucher example introduced in Section 1.3.2 (see page 23).\nIV Demonstration 1 Suppose that a state education department wishes to determine whether private high schools outperform public high schools in a given metropolitan area, as measured by the achievement of ninth graders on a standardized test. For context, suppose that a school voucher program is operating in the city and that the state is considering whether to introduce the program in other areas in order to shift students out of public schools and into private schools.\nTo answer this policy question, the state department of education uses a census of the population in the metropolitan area to select a random sample of 10,000 ninth graders.Theythengiveastandardizedtesttoeachsampledninthgraderattheendof theyear,andtheycollectdataas{yi,di}1 i=0, 1000,whereY isthescoreonthestandardized 5Thereisonetrivialwayaroundthisassumption.IfthenaiveestimatorofDonY isconsistentfor theaveragecausaleffect ofD onY,thenD isitsownIV.ThesubsetofthecovariationinD andY thatisprojectedontoZ isthenthefullsetofcovariationinDandY becauseZ isequaltoD.Inthis case,noextrapolationisneededandtheconstanttreatmenteffectassumptioncanbeavoided.Aswe willdiscusslater,thereareslightlylesstrivialwaystoavoidtheassumptionaswell.Onealternative is to assert that δ is a constant among the treated and then stipulate instead that the IV identifies only the ATT. Although plausible, there arebetter ways to handle heterogeneity, as we willdiscuss asthischapter unfolds.\nTable 9.1 The Distribution of Voucher Winners by School Sector for IV Demonstration 1 Public school Private school d i=0 d i=1 Voucherloser z i=0 8000 1000 Voucherwinner z i=1 800 200 test and D is equal to 1 for students who attend private high schools and equal to 0 for students who attend public high schools.\nAfter the data are collected, suppose that the values of yi are regressed on the values of di and that a predicted regressionsurface is obtained: Yˆ =50.0+9.67(D). (9.7) The state officials recognize that private school students typically have more highly educated parents and therefore are more likely to have higher test scores no matter what curriculum and school culture they have been exposed to. Accordingly, they surmise that 9.67 is likely a poor causal effect estimate, or at least not one that they would want to defend in public as equal to the ATE.\nThe state officials therefore decide to merge the data with administrative records onthe school voucherprogramin the area. For this program,all eighthgradersin the city (both in public and private schools) are entered into a random lottery for $3,000 schoolvouchersthat are redeemable at a private highschool. By mandate, 10 percent of all eligible students win the voucher lottery.\nAfter merging the data, the state officials cross-tabulate eighth grade lottery win- ners (where zi=1 for those who won the lottery and zi=0 for those who did not) by school sector attendance in the ninth grade, di. As shown in Table 9.1, 1,000 of the 10,000 sampled students were voucher lottery winners.6 Of these 1,000 students, 200 were observed in private schools in the ninth grade. In comparison, of the 9,000 sampled students who were not voucher lottery winners, only 1,000 were observed in private schools.\nTheresearchersassumethatthedummyvariableZ forwinningthevoucherlottery isavalidIVforDbecausetheybelievethat(1)therandomizationofthelotteryrenders Z independent of ε in the population-level causal regression equation Y =α+δD+ε and that (2) Z has a causal effect on Y only through Z.. They therefore estimate δˆ IV,WALD in Equation (9.5) as EN[yi|zi=1]−EN[yi|zi=0] 51.600−51.111 = =5.5, (9.8) EN[di|zi=1]−EN[di|zi=0] .200−.111 and conclude that the true causal effect of private schooling on ninth grade achieve- ment is 5.5 rather than 9.67. Operationally, the Wald estimator takes the average 6Forsimplicity,wehaveassumedthatthesamplepercentageoflotterywinnersisthesameasthe populationpercentage. Ofcourse,somerandomvariationwouldbeexpected inanysample.\ndifference in test scoresamongthose students who havewona voucherandthose who have not won a voucher and divides that difference by a corresponding difference in the proportion of high school students who attend private schools among those who have won a voucher and the proportion of high school students who attend private schools among those who have not won a voucher. The numerator of Equation (9.8) is equal to 51.600−51.111 by an assumed construction of the outcome Y, which we will present later when we repeat this demonstration in more detail in Section 9.3.1 (as IV Demonstration 2, beginning on page 309). The denominator, however, can be calculated directly from Table 9.1. In particular, EN[di=1|zi=1]=200/1000=.200, whereas EN[di=1|zi=0]=1000/9000=.111.\nFor this demonstration, Z is a valid instrument by the traditional assumptions maintained in this section of the chapter; it is randomly assigned to students and has no association with Y except for the one produced by the directed path Z→D→Y.\nThe resulting estimator yields a point estimate that can be given a traditional causal interpretation based on the position that the casual effect of interest is a constant structural effect. However, as we will show later in this chapter when we reintroduce this demonstration as IV Demonstration 2, the particular causal effect that this IV identifiesisquiteabitdifferentwhenindividual-levelcausaleffectheterogeneityisnot assumed away. The IV does not identify the ATE or the ATT. Instead, it identifies onlytheaveragecausaleffectforthesubsetofallstudentswhowouldattendaprivate school if given a voucher but who would not attend a private school in the absence of a voucher. This means, for example, that the IV estimate is uninformative about the average causal effect among those who would enroll in private high schools in the absence of a voucher. This group of students represents the vast majority of private school students (in this example 1,000/1,200 or 83 percent). The potential outcome literature has provided the insight that allows such a precise causal interpretation and clarifies what a valid IV estimate does not inform. Before presenting that newer material, we return to a more complete accounting of the traditional IV literature.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#traditional-iv-estimators",
    "href": "extracted/Counterfactuals and Causal Inference.html#traditional-iv-estimators",
    "title": "Counterfaturals and Causal Inference",
    "section": "9.2 Traditional IV Estimators",
    "text": "9.2 Traditional IV Estimators\nAs detailed by Goldberger (1972), Bowden and Turkington (1984), Heckman (2000),\nand Bollen (2012), IV estimators were developed first in the 1920s by biologists and economists analyzing equilibrium price determination in market exchange (see E.\nWorking 1927; H. Working 1925; and Wright 1921, 1925). After subsequent devel- opment in the 1930s and 1940s (e.g., Wright 1934; Schultz 1938; Reiersl 1941; and Haavelmo 1943), IV estimators were brought into widespread use in economics by researchers associated with the Cowles commission (see Hood and Koopmans 1953; Koopmans and Reiersl 1950).7 The structural equation tradition in sociology shares 7The canonical example for this early development was the estimation of price determination in markets.Foramarketinequilibrium,onlyonepriceandonequantity ofgoodssoldisobservableat any point intime. To makeprospective predictions about the potential effects of exogenous supply- and-demandshocksonpricesandquantitiesforanewmarketequilibrium,theshapeoflatentsupply- and-demand curves must be determined. To estimate points on such curves, separate variables are similaroriginstothatoftheIVliterature(seeDuncan1975).Themostfamiliardeploy- ment of IV estimation in the extant sociologicalresearch is as the order condition for identificationofasystemofstructuralequations(seeBollen1989,1995,1996a,1996b, 2001,2012; Fox 1984).\n9.2.1 The Linear Structural Equation IV Estimator Consider the same basic ideas presented earlier for the Wald estimator in Equation (9.5). Again, recall the causal regressionsetup in Equation (9.1): Y =α+δD+ε, (9.9) andagainassumethatweareinthetraditionalsetupwhereδisaninvariant,structural causal effect that applies to all members of the population of interest. The ordinary least squares (OLS) estimator of the regressioncoefficient on D is OLS,bivariate≡CovN(yi,di) δˆ , (9.10) VarN(di) where CovN(.) and VarN(.) denote unbiased, sample-based estimates from a sample of size N of the population-level covariance and variance.\nNow, again suppose that the back-door association between D and ε renders the leastsquaresestimatorbiasedandinconsistentfor δ inEquation(9.9).Ifleastsquares cannotbeusedtoeffectivelyestimateδ,analternativeIVestimatorcanbeattempted, with an IV Z, as in CovN(yi,zi) δˆ ≡ , (9.11) IV CovN(di,zi) where Z can now take on more than two values. If the instrument Z is linearly asso- ciated with D but unassociated with ε, then the IV estimator in Equation (9.11) is consistent for δ in Equation (9.9).8 One way to see why IV estimators yield consistent estimates is to again consider the population-level relationships between Y, D, and Z, as in Equations (9.1)–(9.4).\nManipulatingEquation(9.1)asbefore,thecovariancebetweentheoutcomeY andthe instrument Z can be written as Cov(Y,Z)=δCov(D,Z)+Cov(ε,Z), (9.12) againassumingthatδisaconstantstructuraleffect.DividingbyCov(D,Z)thenyields Cov(Y,Z) δCov(D,Z)+Cov(ε,Z) = , (9.13) Cov(D,Z) Cov(D,Z) needed that uniquely index separate supply-and-demand shocks. Usually based on data from a set of exchangeable markets or alternative well-chosen equilibria for the same market from past time periods, these IVs are then used to identify different points of intersection between a shifted linear supply/demandcurveandafixedlineardemand/supplycurve.\n8Notice that substituting d i for z i in Equation (9.11) results in the least squares regression esti- mator in Equation (9.10). Thus, the least squares regression estimator implicitly treats D as an instrumentforitself.\nW Z V ε Z ε∗ D Y D Y (a) Z is a valid surrogate (b) Z is a valid conditional instrumental variable instrumental variable Figure9.2 Two graphs in which Z is a valid IV.\nwhich is directly analogous to Equation (9.3). When Cov(ε,Z) is equal to 0 in the population, then the right-hand side of Equation (9.13) simplifies to δ. This suggests that CovN(yi,zi) −p →δ (9.14) CovN(di,zi) if Cov(ε,Z)=0 in the population and if Cov(D,Z)(cid:6)=0. This would be the case for the causal diagram in Figure 9.1(a). But here the claim is more general and holds for cases in which Z is many-valued (and, in fact, for cases in which D is many-valued as well, assuming that the linear, constant-coefficient specification in Equation (9.9) is appropriate).\nOur priorgraphicalpresentationwas alsomore restricted thanit needed to be. As we discussedabove,if Z is relatedto D andY as in Figure9.1(a),then IV estimation with Z is feasible.9 Figure 9.2(a) presents another graph in which Z can be used as a valid instrumental variable for the effect of D on Y. In this case, the instrument V is unobserved. What we have instead is a surrogate instrumental variable, Z, which is not a direct cause of D but which has an association with D because both Z and D mutually depend on the unobserved instrument V. A complication, which we will discussbelow,isthatthe associationbetweenZ andD maybeveryweakinthiscase, creating a particular set of statistical problems.10 Figure9.2(b)representsperhapsthemostcommonsetupinthetraditionalapplied literature. In this case, Z is not a “clean” instrument that has no association with Y other than the association that is generated by a directed path that begins at the instrument and ends at the outcome. Nonetheless, all of the additional associations between Z and Y are generated by back-door paths from the instrument Z to the outcome Y that can be blocked by simultaneous conditioning on observed variables, such as W in Figure 9.2(b). In this case, Z is sometimes referred to as a conditional 9TheonlydifferenceinthissectionisthatwearenowallowingZtotakeonmorethantwovalues.\nBecause of this relaxation, in order for the graph to be compatible with the traditional setup, we needtomakethefurtherassumptionthatZ hasalinearcausaleffectonD,whichneithervariesover individualsnorinanypiecewisefashionacrossthelevelsofZ.\n10As elsewhereup until this point inthe chapter, inorder to stay withinthe traditional setup we must now assume that linearity holds throughout, so that the effect of V on Z generates a linear relationshipbetweenZ andD.\ninstrumentalvariable,andestimationmustproceedwithaconditionalversionofEqua- tion (9.11), usually the two-stage least squares estimator that we will discuss below.\nConsider the following examples of IV estimation from the applied literature.\n9.2.2 Examples of IV Estimation Amongsocialscientists,demographic,andhealthresearchers,economistsarethemost prone to the adoption of IV estimation.11 Consider the causal effect of education on labor market earnings, as introduced earlier in Section 1.3.1 and as used as a focal example inpriorchapters.As reviewedinpieces suchas Card(1999)andAngristand Krueger(2001),thecausaleffectofyearsofschoolingonsubsequentearningshasbeen estimated with a variety of IVs, including proximity to college, regionaland temporal variation in school construction, tuition at local colleges, temporal variation in the minimumschool-leavingage,andquarterofbirth.Theargumentintheseapplications is that the IVs predict educational attainment but have no direct effects on earnings.\nFor the quarter-of-birth instrument, which is one of the most widely discussed IVs in the literature, Angrist and Krueger (1991:981–82)reason: If the fraction of students who desire to leave school before they reachthe legaldropoutageisconstantacrossbirthdays,astudent’s birthday should be expected to influence his or her ultimate educational attainment. This relationship would be expected because, in the absence of rolling admis- sions to school, students born in different months of the year start school atdifferentages.Thisfact,inconjunctionwithcompulsoryschoolinglaws, which require students to attend school until they reach a specified birth- day,producesacorrelationbetweendateofbirthandyearsofschooling….\nStudents who are born early in the calendar year are typically older when they enter school than children born late in the year…. Hence, if a fixed fractionofstudentsisconstrainedbythecompulsoryattendancelaw,those borninthe beginning ofthe yearwill haveless schooling,onaverage,than those born near the end of the year.\nThe results of Angrist and Krueger (1991) were sufficiently persuasive that many additionalresearchershavesincebeenconvincedtouserelatedIVs.Braakmann(2011), for example, uses an IV based on month of birth to estimate the effect of education on health-related behaviors. Other researchers have used IVs that index over-time variation in compulsory schooling laws, such as Oreopoulos (2006) for the effect of education on earnings, Machin, Marie, and Vuji (2011) for the effect of education on crime, and Kemptner, Ju¨rges, and Reinhold (2011) for the effect of education on health.12 11Some of the examples we introduce inthis section adopt the traditional setup presented above, wherein the causal effect of interest is a structural constant. Many of the more recent examples adoptthealternativesetupthatwewillintroducelaterinthechapter,whereitisassumedasafirst principlethattreatmenteffectsvaryattheindividuallevel.Fornow,weoffertheseexamplesonlyto demonstratethetypical identifyingassumptionspresentedinFigures9.1(a)and9.2.\n12And,inturn,eachoftheseeffectshasbeenmodeledwithalternativeIVs.Forexample,inthecase ofhealthandhealthbehaviors,Lindahl(2005)usedlotterywinningsasanIVfortheeffectofincome For another example, consider the literature on the effects of military service on subsequentlabormarketoutcomes,atopicthatbotheconomistsandsociologistshave studied for several decades. Some have argued that military service can serve as an effective quasi-job-training program for young men likely to otherwise experience low earnings because of weak attachment to more traditional forms of education (Brown- ing,Lopreato,andPoston1973)orasamoregeneralproductivitysignalthatgenerates a veteran premium (De Tray 1982). In one of the earliest studies, which focused pri- marily on veterans who served around the time of the Korean War, Cutright (1974) concluded that two yearsin the military environment,coupledwith the extensive benefits awardedtoveterans,donot resultinaclearcut,largenetpositiveeffectof service….Therefore,onemayquestionthelikelyutilityofsocialprograms that offer minority men and whites likely to have low earnings a career contingencyinabridgingenvironmentsimilartothatprovidedbymilitary service. (Cutright 1974:326) Followingthe warin Vietnam,attention thenfocused onwhether any military service premium had declined (see Rosen and Taubman 1982; Schwartz 1986; see also Berger and Hirsch 1983).Angrist (1990)used the randomization created by the Vietnam-era draft lottery to estimate the veteran effect. Here, the draft lottery turns date of birth into an IV, in much the same way that compulsory school entry and school-leaving laws turn date of birth into an IV for years of education. Angrist determined that veteranstatushadanegativeeffect onearnings,whichhe attributedto a lossoflabor market experience.13 The quarter-of-birth and draft-lottery IVs are widely discussed because they are determined by processes that are very unlikely to be structured by any of the unob- served determinants of the outcome of interest. Many IVs in the economics literature do not have this feature. As discussed in Section 1.3.2, much of the early debate on the effectiveness of private schooling relative to its alternatives was carried out with observational survey data on high school students from national samples of public and Catholic high schools. In attempts to resolve the concerns over selection bias, EvansandSchwab(1995),Hoxby(1996),andNeal(1997)introducedplausibleIVsfor onhealthand mortality,whileCawley, Moran,and Simon(2010) usedanover-timediscontinuity in SocialSecuritybenefits asanIVfortheeffect ofincomeontheobesityoftheelderly.\n13We do not mean to imply that Angrist’s work on this issue ended in 1990. Not only was his work very important for understanding what IV estimators accomplish in the presence of causal effect heterogeneity (see next section), but he also continued with subsequent substantive work on the military service effect. Angrist and Krueger (1994) estimated the World War II veteran effect, and, in an attempt to reconcile past estimates, concluded: “Empirical results using the 1960, 1970, and 1980 censuses support a conclusion that World War II veterans earn no more than comparable nonveterans, and may well earn less. These findings suggest that the answer to the question ‘Why do World War II veterans earn more than nonveterans?’ appears to be that World War II veterans wouldhaveearnedmorethannonveteransevenhadtheynotservedinthemilitary.Militaryservice, in fact, may have reduced World War II veterans’ earnings from what they otherwise would have been” (Angristand Krueger 1994:92). Then, Angrist(1998) assessedthe effects of voluntary service inthemilitaryinthe1980s, andhefoundmixedevidence. InAngristandChen(2011), herevisited the Vietnam-era veteran effect, analyzing 2000 census data, arguing that the effect on education is positivebecauseoftheGIbillbutisnonetheless closetozeroforearnings.\nCatholic school attendance. Hoxby and Neal argued that the share of the local popu- lation that is Catholic is a valid IV for Catholic school attendance, maintaining that exogenous differences in population composition influence the likelihood of attending aCatholicschool(byloweringthecostsofopeningsuchschools,whichthenlowersthe tuitionthat schoolsneedto chargeandto whichparentsrespondwhenmaking school sector selection decisions). Variation in the number of Catholics in each county was attributedtolaggedeffectsfrompastimmigrationpatternsandwasthereforeassumed to have no direct effect on learning.14 These examples of IV estimation in economics are but the tip of an iceberg of applications.SomeeconomistshavearguedthattheattentiongiventoIVestimationin theappliedliteratureinthepasttwodecadeshasbeenexcessive,andathrivingdebate is now under way on the future direction of observational research in economics, as revealedby a comparisonof AngristandPischke(2010)andImbens (2010)to Deaton (2010), Heckman and Urzua (2010), and Leamer (2010). We will discuss this debate at several points in this chapter and the next.\nMoving beyond researchin economics, examples of IV estimation follow more var- ied patterns. For political science, Dunning (2012), Sekhon and Titiunik (2012), and Soveyand Green(2011)review the growing list of applications that draw on “natural experiments,” some of which are instrumental variable designs. In sociology, Bollen (2012) shows that IV estimation is uncommon but still utilized in models with a structuralequationsfoundation.15 Finally,epidemiologistsandhealthresearchershave notutilized instrumental variableswith substantial frequency, to some extentheeding the warning of Hern´an and Robins (2006b:364) about the “risk [of] transforming the methodologicdreamofavoidingunmeasuredconfoundingintoanightmareofconflict- ing biased estimates.” 9.2.3 The IV Identifying Assumption Cannot Be Tested The basic identification assumption underlying all of the studies just summarized – that Z has no net association with Y except for the one generated by the directed path Z→D→Y – is a strong and untestable assumption. Some researchers believe mistakenlythatthisassumptionisempiricallytestable.Inparticular,theybelievethat the assumption that Z has no direct effect on Y implies that there is no association 14Evans and Schwab (1995) used a student’s religiousidentification as an IV. This IV has proven toberatherunconvincingtomanyscholars(seeAltonji,Elder,andTaber2005a,2005b)becausethe assumedexclusionrestrictionappearsunreasonable.Neal(1997)alsousedthisIVbutonlyselectively inhisanalysis.\n15As noted, IV estimation is an inherent part of structural equation modeling because point esti- matesofcoefficients arenotinfrequentlygenerated byIV-basedorderidentification inthistradition of analysis. For example, Messner, Baumer, and Rosenfeld (2004) estimate a two-equation model, with communities as the unit of analysis, where (1) the effect of community-level social trust on the homicide rate is identified by an instrument for community-level subjective alienation and (2) the effect of community-level social activism on the homicide rate is identified by instruments for thecommunity-levelaverageamountoftelevisionwatchedandextremepoliticalattitudes.Thistype ofapplicationreliesquiteheavilyonthe theoretical rationaleforinstrumentselection, moresothan for the “natural experiment” instruments prized in economics where the prima facie case for the independence oftheinstrumentZ fromcauses ofY other thanD isstronger.\nZ U D Y Figure 9.3 A graph with an unblocked back-door path and a valid IV.\nbetweenZ andY conditionalonD.Thus,ifanassociationbetweenZandY isdetected after conditioning on D, then the assumption must be incorrect.\nCausal graphs show clearly why individuals might believe that the identifying assumption can be tested in this way and also why it cannot. Consider the sim- plest possible causal graph, presented in Figure 9.3, in which (1) an unblocked back- door path between D and Y exists because of the unobserved common cause U, but (2) Z is a valid IV that identifies the causal effect of D on Y.16 Here, the instrument Z is valid because it causes D, has no causaleffect on Yother than through D, and is unconditionally unassociated with U.\nWhyisthesuggestedtestfaulty?Again,therationaleforthetestisthatcondition- ingonDwillblocktheindirectrelationshipbetweenZ andY throughD.Accordingly, if the only associationbetween Z andY is indirect throughD, then it is thoughtthat thereshouldbenoassociationbetweenZ andY afterconditioningonD.Ifsuchanet associationisdetected,thenitmayseemreasonabletoconcludethattheIVidentifying assumption must be false.\nAlthough this rationale feels convincing, it is incorrect. It is certainly true that if the IV assumption is invalid, then Z and Y will be associated after conditioning on D. But the converse is not true. In fact, Z and Y will always be associated after conditioning on D when the IV assumption is valid. The explanation follows from the fact that D in Figure 9.3 is a collider that is mutually caused by both Z and U. As discussed extensively in this book, conditioning on a collider variable creates dependencebetweenthevariablesthatcauseit.Accordingly,conditioningonDinthis graphcreatesdependencebetweenZ andU,eventhoughtheIVidentifyingassumption isvalid.And,asaresult,Z andY willalwaysbeassociatedwithinatleastonestratum of D even if the IV is valid. The faulty test yields an association between Z and Y whenconditioningonDregardlessofwhethertheIVidentifyingassumptionisvalid.17 16Forourpurposeshere,thisgraphisisomorphicwithFigure9.1(a).Wehavereplacedthebidirected edgefromDtoεbyrepresentingtheassociationbetweenDandεasasingleback-doorpathbetween D and Y generated by an unobserved common cause U. We have then eliminated the remainder of thedistributionofεfromthegraphbecauseitisunconditionallyunassociatedwithZ andD(andis, inPearl’sframework,nowtheusualerrorterme Y thatcomesintoviewonlyundermagnification).\n17Forcompleteness,considerwhatthefaultytestrevealswhentheIVassumptionisinvalid.Suppose that Figure 9.3 is augmented by an unobserved cause E and then two edges E→Z and E→U. In this case, Z and Y would be associated within levels of D for two reasons: (1) conditioning on the collider D generates a net association between Z and U (and hence Z and Y) and (2) the common causeE ofZ andU generates anunconditional associationbetween Z andY.\n9.2.4 Recognized Pitfalls of Traditional IV Estimation The traditionalIVliteraturesuggeststhat, aslongas there isaninstrumentthat pre- dicts the causal variable of interest but is linearly unrelated to the outcome variable except by way of the causal variable, then an IV estimator will effectively estimate the causal effect. Even within this traditional setup, however, there are some recog- nized pitfalls of an IV estimation strategy. First, the assumption that an IV does not have a net direct effect on the outcome variable is often hard to defend. Second, even when an IV does not have a net direct effect on the outcome variable, IV estimators are biased in finite samples. Moreover, this bias can be substantial when an instru- ment only weakly predicts the causal variable. We discuss each of these weaknesses here.\nEven “natural experiments” that generate compelling IVs are not immune from criticism.Consider date of birth as an instrument for veteranstatus in estimating the effect of military service in Vietnam on subsequent earnings (Angrist 1990). The case forexcludingdateofbirthfromtheearningsequationthatistheprimaryinterestofthe study is the randomization of the draft lottery, in which draft numbers were assigned at random to different dates of birth. Even though a type of randomization generates the IV, this does not necessarily imply that date of birth has no net direct effect on earnings.Aftertherandomizationoccursandthelotteryoutcomesareknown,employ- ers may behave differently with respect to individuals with different lottery numbers, investing more heavily in individuals who are less likely to be drafted. As a result, lottery number may be a direct, though probably weak, determinant of future earn- ings (see Heckman 1997; Moffitt 1996). IVs that are not generated by randomization are even more susceptible to causal narrativesthat challenge the assumption that the purported IV does not have a net direct effect on the outcome of interest.\nEven in the absence of this complication, there are well-recognized statistical pit- falls.Byusingonlyaportionofthecovariationinthecausalvariableandtheoutcome variable, IV estimators use only a portion of the information in the data. This repre- sents a direct loss in statistical power, and as a result IV estimators tend to exhibit substantiallymoreexpectedsamplingvariancethanotherestimators.Bythecriterion of mean-squared error, a consistent and asymptotically unbiased IV estimator can be outperformed by a biased and inconsistent regressionestimator.\nThe problem canbe especially acute in some cases. It has been shownthat instru- ments that only weakly predict the causal variable of interest should be avoided entirely, even if they generate point estimates with acceptably small estimated stan- dard errors (see Bound, Jaeger, and Baker 1995). In brief, the argument here is four- fold: (1)in finite samples,IVpointestimates canalwaysbe computedbecausesample covariances are never exactly equal to zero; (2) as a result, an IV point estimate can be computed even for an instrument that is invalid because it does not predict the endogenous variable in the population (i.e., even if Cov(D,Z)=0 in the population, renderingEquation(9.13) undefinedbecause its denominatoris equalto 0); (3)atthe sametime,the formulasforcalculatingthestandarderrorsofIVestimatesfailinsuch situations, giving artificially small standard errors (when in fact the true standard error for the undefined parameter is infinity); and (4) the bias imparted by a small violation of the assumption that the IV affects the outcome variable only by way of the causal variable can explode if the instrument is weak.18 To see this last result, consider Equation (9.6), which depicts the expected bias in the Wald estimator for a binary IV as the term E[ε|Z=1]−E[ε|Z=0] . (9.15) E[D|Z=1]−E[D|Z=0] When the identifying assumption is violated, the numerator of Equation (9.15) is nonzero because Z is associated with Y through ε. The bias is then an inverse func- tion of the strength of the instrument; the weaker the instrument, the smaller the denominator and the larger the bias. If the denominator is close to zero, even a tiny violationoftheidentifyingassumptioncangeneratealargeamountofbias.And,unfor- tunately,thisrelationshipisindependentofthesamplesize.Thus,eventhoughaweak instrumentmay suggesta reasonable(or perhaps evenintriguing)pointestimate, and one with an acceptably small estimated standard error, the IV estimate may contain no genuine information whatsoever about the true causal effect of interest (see Hahn and Hausman 2003; Small and Rosenbaum 2008; Staiger and Stock 1997; Wooldridge 2010).19 Beyond these widely recognized pitfalls of standard IV estimation in economics, a third criticism is emerging of current practice, especially in economics. As explained by Angrist and Krueger (2001) and Angrist and Pischke (2009, 2010), the ways in which IVs are used has changed in the past 40 years. Because it has been hard to achieve consensus that particular no-net-direct-effect assumptions are credible, IVs thatarisefromnaturallyoccurringvariationhavebecomemorepopular.Genuine“gifts of nature,” such as variationin the weather and natural boundaries, have become the most prized sources of IVs (see Dunning 2012 and Rosenzweig and Wolpin 2000 for lists of such instruments).\nNotalleconomistsseethisshiftinIVestimationtechniquestowardnaturallyoccur- ring IVs as necessarily a step in the right direction. Rosenzweig and Wolpin (2000) offerone ofthe mostcogentcritiques (butsee alsoDeaton2010;Heckman2000,2005; Heckman and Urzua 2010). Rosenzweig and Wolpin make three main points. First, the variation on which naturally occurring IVs capitalize is often poorly explained and/or does not reflect the variation that maintained theories posit should be impor- tant. As a result, IV estimates from natural experiments have a black-box character that lessens their appeal as informative estimates for the development of theory or policyguidance.Second,the randomvariationcreatedbyanaturallyoccurringexper- iment does not necessarily ensure that an IV has no net direct effect on the outcome.\nOthercausesoftheoutcomecanrespondtothenaturaleventthatgeneratestheIVas well. Third, naturally occurring IVs typically do not estimate structural parameters 18Complications(1), (2), (3),and(4)areallcloselyrelated. Situation(4)canbeconsideredaless extremeversionofthethree-partpredicamentdepicted in(1)–(3).\n19TherearenoclearguidelinesonhowlargeanassociationbetweenanIVandatreatmentvariable must be before analysis can proceed safely. Most everyone agrees that an IV is too weak if it does notyieldateststatisticthatrejectsanullhypotheses ofnoassociationbetween Z andD.However, amainpointofthisliteratureisthattheconverseisnottrue.Ifadatasetislargeenough,thesmall associationbetweenZ andDgeneratedbyaweakIVcanstillyieldateststatisticthatrejectsanull hypotheses ofnoassociation. Evenso,theproblemsinthemaintextarenotvitiated, especiallythe explosionofthebiasgeneratedbyasmallviolationoftheidentifyingassumption.\nof fundamental interest, which can and should be defined in advance of estimation basedoncriteriaotherthanwhether anaturallyoccurringIVisavailable.Rosenzweig and Wolpin contend that natural experiments tend to lead analysts to ignore these issues because natural experiments appear falsely infallible. Reflecting on the same setof issues, Deaton (2010:432)writes, “The generallessonis once againthe ultimate futility of trying to avoid thinking about how and why things work.” Wewillexplainthesepointsfurtherinthischapter,afterintroducingIVestimation in the presence of causal effect heterogeneity. (We will also then revisit this critique in the next chapter on mechanisms.) The new IV literature, to be discussed next, addresses complications of the constant coefficient assumption implied by the stipu- lated constant value of δ in Equations (9.1) and (9.9). The issues are similar to those presentedfor regressionestimatorsinChapter6,inthatheterogeneityinvalidatestra- ditional causal inference from IV estimates. But IV estimators do identify specific narrowslices of averagecausal effects that may be of distinct interest, and as a result they represent a narrowly targeted estimation strategy with considerable appeal.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#instrumental-variable-estimators-in-the-presence-of-individual-level-heterogeneity",
    "href": "extracted/Counterfactuals and Causal Inference.html#instrumental-variable-estimators-in-the-presence-of-individual-level-heterogeneity",
    "title": "Counterfaturals and Causal Inference",
    "section": "9.3 Instrumental Variable Estimators in the Presence of Individual-Level Heterogeneity",
    "text": "9.3 Instrumental Variable Estimators in the Presence of Individual-Level Heterogeneity\nFollowing the adoption of a counterfactual perspective, a group of econometricians\nand statisticians has clarified what IVs identify when individual-level causal effects are heterogeneous. In this section, we will emphasize the work that has developed the connections between traditional IV estimators and potential-outcome-defined treat- ment effects (Angrist and Imbens 1995; Angrist, Imbens, and Rubin 1996; Imbens and Angrist 1994; Imbens and Rubin 1997). The key innovation here is the defini- tion of a new treatment effect parameter: the local average treatment effect (LATE).\nWe will also discuss other important work that has further clarified these issues, and some of this literature is more general than the LATE literature that we introduce first(seeHeckman1996,1997,2000,2010;Heckman,Tobias,andVytlacil2003;Heck- man,Urzua,andVytlacil2006;HeckmanandVytlacil1999,2000,2005;Manski2003; Vytlacil 2002).20 9.3.1 IV Estimation as LATE Estimation Consider the following motivation of the Wald estimator in Equation (9.5), and recall the definition of Y presented in Equation (4.5): Y =Y0+(Y1−Y0)D (9.16) =Y0+δD =μ0+δD+υ0, 20Giventhe rapidityof these developments inthe IV literature, somedisagreement on the origins oftheseideaspervadestheliterature.HeckmanandRobb(1985,1986)didprovideextensiveanalysis of what IV estimators identify in the presence of heterogeneity. Subsequent work by others, as we discussinthissection,hasclarifiedandextendedtheseideas,evenwhileHeckmanandhiscolleagues continuedtorefinetheirideas.\nwhereμ0≡E[Y0]andυ0≡Y0−E[Y0].NotethatδisnowdefinedasY1−Y0,unlikeits structural representationin Equations (9.1) and (9.9) where δ was implicitly assumed to be constant across all individuals.\nTounderstandwhenanIVestimatorcanbeinterpretedasanaveragecausaleffect estimator, Imbens and Angrist (1994) developed a framework to classify individuals intothosewhorespondpositivelytoaninstrument,thosewhoremainunaffectedbyan instrument,andthosewhorebelagainstaninstrument.Theirinnovationwastodefine potentialtreatment assignmentvariables,DZ=z,for eachstate z ofthe instrument Z.\nWhen D and Z are binary variables, there are four possible groups of individuals in the population.21 These can be summarized by a four-category latent variable C for compliance status: DZ=0=0 DZ=1=1, Compliers (C=c): and DZ=0=1 DZ=1=0, Defiers (C=d): and DZ=0=1 DZ=1=1, Always takers (C=a): and DZ=0=0 DZ=1=0.\nNever takers (C=n): and Consider the private schooling example presented earlier in IV Demonstration 1 (see page 294). Students who would enroll in private schools only if offered the voucher are compliers (C=c). Students who would enroll in private schools only if not offered the voucher are defiers (C=d). Students who would always enroll in private schools, regardless of whether they are offered the voucher, are always takers (C=a). And, finally, students who would never enroll in private schools are never takers (C=n).\nAnalogous to the definition of the observed outcome, Y, the observed treatment indicator variable D can then be defined as D=DZ=0+(DZ=1−DZ=0)Z (9.17) =DZ=0+κZ, where κ≡DZ=1−DZ=0.22 The parameterκ in Equation(9.17) is the individual-level causal effect of the instrument on D, and it varies across individuals if DZ=1−DZ=0 varies across individuals (i.e., if observed treatment status varies as the instrument is switched from “off” to “on” for each individual). If the instrument represents encour- agement to take the treatment, such as the randomly assigned school voucher in IV Demonstration1,then κ canbe interpretedasthe individual-levelcomplianceinduce- ment effect of the instrument. Accordingly,κ=1 for compliers and κ=−1 for defiers.\nFor always takers and never takers, κ=0 because none of these individuals respond to the instrument.\n21ThesefourgroupsareconsideredprincipalstrataintheframeworkofFrangakisandRubin(2002).\n22Note alsothat D has now been counterfactually defined with referenceto DZ. Accordingly, the definitionofY inEquation(9.16)isconditionalonthedefinitionofDinEquation(9.17).Furthermore, althoughthereislittlebenefitindoingso,itbearsnotingthatthisdefinitionofDcouldbestructured analogouslytothedefinitionofY inEquation(9.16)sothatthelastlinewouldbecomeD=ζ+κZ+ι, whereζ≡E[DZ=0]andι≡DZ=0−E[DZ=0].Theparameterζwouldthenbetheexpectedprobability ofbeinginthetreatmentifallindividualswereassignedtothestate“instrumentswitchedoff,”and ιwouldbetheindividual-leveldeparturefromthisexpectedvalue,takingonvalues1−E[DZ=0]and −E[DZ=0]tobalancetheright-handsideofEquation(9.17)sothatD isequal toeither1or0.\nGiventhesedefinitionsofpotentialoutcomevariablesandpotentialtreatmentvari- ables,a valid instrument Z for the causaleffect of D on Y must satisfy three assump- tions in order to identify a LATE: Independence assumption: (Y1,Y0,DZ=1,DZ=0) ⊥⊥ Z, (9.18) Nonzero effect of instrument assumption: κ(cid:6)=0 for all i, (9.19) Monotonicity assumption: either κ≥0 for all i or κ≤0 for all i. (9.20) The independence assumptionin Equation(9.18) is analogousto the assumptionthat Cov(Z,ε)=0 in the traditional IV literature; see the earlier discussion of Equation (9.13).23 It stipulates that the instrument must be independent of the potential out- comes and potential treatments. Knowing the value of the instrument for individual i mustnotyieldanyinformationaboutthepotentialoutcomeofindividualiundereither treatmentstate.Moreover,knowingtherealizedvalueoftheinstrumentforindividual imustnotyieldanyinformationabouttheprobabilityofbeinginthetreatmentunder alternative hypothetical values of the instrument. This latter point may well appear confusing, but it is exactly analogous to the independence assumption of potential outcomesfromobservedtreatmentstatus,discussedearlierforEquation(2.6).Avalid instrument predicts observed treatment status (D), but it does not predict potential treatment status (DZ=z).\nThe assumptions in Equations (9.19) and (9.20) are assumptions about individual responsesto shifts in the instrument. The assumptionofa nonzero effect ofZ on D is astipulationthatthe instrumentmustpredicttreatmentassignmentforatleastsome individuals. There must be at least some compliers or some defiers in the population ofinterest.The monotonicityassumptionthenfurther specifies thatthe effect of Z on D must be either weakly positive or weakly negative for all individuals i. Thus, there may be either defiers or compliers in the population but not both.24 If these three assumptions obtain, then an instrument Z identifies the LATE: the averagetreatment effect for the subset of the population whose treatment selection is inducedby the instrument.25 Ifκ≥0forall i,thenthe WaldestimatorfromEquation 23The stable unit treatment value assumption (SUTVA) must continue to hold, and now it must applytopotential treatments as well.Inaddition, as wenoted earlier,our presentation herefollows ImbensandAngrist(1994),AngristandImbens(1995),andAngristetal.(1996).Aswenotelater,IVs canbedefinedinslightlydifferent(insomecasesmoregeneral)ways.Butfornow,werestrictattention to the LATE literature, inwhich assumptions such as complete independence of the instrument are utilized.\n24Manskidefinesthisassumptionasamonotonetreatmentselection(MTS)assumptioninorderto distinguish it from his monotone treatment response (MTR) assumption (see Manski 1997; Manski and Pepper 2000). Vytlacil (2002) establishes its connections to the index structure model laid out in Heckman and Vytlacil (1999), as we discuss in Section 9.3.4. Heckman (2000, 2010), Heckman and Vytlacil (2005, 2007), Heckman et al. (2006), and Heckman and Urzua (2010) provide a broad accountingoftherelationshipsbetweenalternativeIVestimators.\n25TheLATEisoftenreferredtoasthe“complieraveragecausaleffect”tosignifythatthedescriptor localisreallydefinedbytherestrictedapplicabilityoftheLATEestimatetotheaveragecausaleffect of compliers. The followingexample does not use the compliance language explicitly, except insofar asthosewhorespondtothevoucherarelabeledcompliers.TheLATEliteraturethatweciteprovides the explicit connections between LATE and the large literature on noncompliance in randomized experiments(seeinparticularImbens andRubin1997andcitationstherein).\n(9.5) converges to a particular LATE: δˆ IV,WALD−p →E[δ|C=c], (9.21) whichisequaltoE[Y1−Y0|DZ=1=1,DZ=0=0]andisthereforetheaveragetreatment effect among compliers. In contrast, if κ≤0 for all i, then the Wald estimator from Equation (9.5) converges to the opposite LATE: δˆ IV,WALD−p →E[δ|C=d], (9.22) whichisequaltoE[Y1−Y0|DZ=1=0,DZ=0=1]andisthereforetheaveragetreatment effect among defiers. In either case, the treatment effects of always takers and never takers are not informed in any way by the IV estimate.\nIn the next section, we will explain the claims in Equations (9.21) and (9.22) in considerable detail through a more elaborate version of IV Demonstration 1. But the basic intuition is straightforward. A valid IV is nothing more than an exogenous dimensionacrosswhichthe treatmentand outcomevariables areanalyzedjointly.For a binary instrument, this dimension is a simple contrast, which is the ratio presented earlier; see Equations (9.5) and (9.8): EN[yi|zi=1]−EN[yi|zi=0] .\nEN[di|zi=1]−EN[di|zi=0] The numerator is the naive estimate of the effect of Z on Y, and the denominator is the naive estimate of the effect of Z on D.\nTogiveacausalinterpretationtothisratioofdifferencesacrossthethirddimension indexed by Z, a model of individual treatment response must be specified and then usedto interpretthe causaleffect estimate.The modelofindividualresponseadopted foraLATE analysiswithabinaryIVisthe fourfoldtypologyofcompliance,captured by the latent variable C defined earlier for alwaystakers, never takers,compliers, and defiers. Within this model, the always takers and never takers do not respond to the instrument (i.e., they did not choose to take part in the “experiment” created by the IV, and thus their treatment assignment is not determined by Z). This means that theyaredistributedinthesameproportionwithinalternativevaluesoftheinstrument Z. And, as a result, differences in the average value of Y, when examined across Z, are not a function of the outcomes of always takers and never takers.26 Incontrast,defiersand complierscontribute all ofthe variationthat generatesthe IV estimate because only their behavior is responsive to the instrument. For this rea- son, any differences in the average value of Y, when examined across Z, must result from treatment effects for those who move into and out of the causal states repre- sented by D. If compliers are presentbut defiers are not, then the estimate offered by the ratio is interpretable as the average treatment effect for compliers. If defiers are present but compliers are not, then the estimate offered by the ratio is interpretable as the average treatment effect for defiers. If both compliers and defiers are present, then the estimate generatedby the ratio does not have a well-defined causal interpre- tation. In the following demonstration, we will consider the most common case in the 26Inasense,theoutcomes ofalwaystakers andnevertakers representatypeofbackground noise thatisignoredbytheIVestimator.Moreprecisely,alwaystakersandnevertakershaveadistribution ofoutcomes, butthedistributionoftheseoutcomes isbalancedacrossthevaluesoftheinstrument.\nLATEliteratureforwhichthe monotonicityconditionholdsinthe directionsuchthat compliers exist in the population but defiers do not.\nIV Demonstration 2 Recall the setup for IV Demonstration 1 (see page 294). In an attempt to determine whetherprivatehighschoolsoutperformpublichighschools,astateeducationdepart- mentassemblesadatasetonarandomsampleof10,000ninthgraders,{yi,di,zi}1 i=0, 1000, where Y is a standardized test, and D is equal to 1 for students who attend private high schools and 0 for students who attend public high schools. Likewise, Z is equal to 1 for those who win a lottery for a $3,000 school voucher and 0 for those who do not.\nAs noted for IV Demonstration 1, a bivariate regression of the values of yi on di yielded a treatment effect estimate of 9.67; see discussion of Equation (9.7). An alternative IV estimate with Z as an instrument for D yielded an estimate of 5.5; see Equation (9.8). The hypothetical state officials relied on the IV estimate rather than on the regression estimate because they recognized that private school students have more advantaged social backgrounds. And they assumed that the randomization of the voucher lottery, in combination with the relationship between D and Z shown in Table 9.1, established the voucher lottery outcome as a valid IV.\nWe stated just after our discussionof IV Demonstration 1 that the estimate of 5.5 is properly interpreted as a particular LATE: the average causal effect for the subset of all students who would attend a private school if given a voucher but would not attend a private school in the absence of a voucher. To explain the reasoning behind thisconclusion,wewillfirstexplainhowtheobservedvaluesforDandY aregenerated asaconsequenceofvariationinZ.Thenwewillintroducepotentialoutcomesanduse the treatmentresponsemodel inorderto explainwhy the IVestimate is interpretable as the average treatment effect for compliers.\nWe reported the frequency distribution of D and Z in Table 9.1. The same infor- mation is presented again in Table 9.2, but now also as probability values (where, for example, the term PrN[.,.] in the upper left cell is equal to PrN[di=0,zi=0] by plugging the row and column headings into the joint probability statement). We also now report the expectations of the outcome variable Y, conditional on D and Z.\nFirst,considerhowtheleastsquaresandIVestimatesarecalculated.Thecoefficient of9.67onDinEquation(9.7)isequaltothenaiveestimator,EN[yi|di=1]−EN[yi|di= 0]. One can calculate these two conditional expectations from the elements of Table 9.2 by forming weighted averages within columns: .1 .02 EN[yi|di=1]= 60+ 58=59.667, .1+.02 .1+.02 .8 .08 EN[yi|di=0]= 50+ 50=50.0.\n.8+.08 .8+.08 As shown earlier in Equation (9.8), the IV estimate of 5.5 is the ratio of two specific contrasts: EN[yi|zi=1]−EN[yi|zi=0] 51.6−51.111 = =5.5. (9.23) EN[di|zi=1]−EN[di|zi=0] .2−.111 Table 9.2 The Joint Probability Distribution and Conditional Expectations of the Test Score for Voucher Winner by School Sector for IV Demonstrations 1 and 2 Public school Private school d i=0 d i=1 Voucherloser z i=0 N=8000 N=1000 PrN[.,.]=.8 PrN[.,.]=.1 E N[y i|.,.]=50 E N[y i|.,.]=60 Voucherwinner z i=1 N=800 N=200 PrN[.,.]=.08 PrN[.,.]=.02 E N[y i|.,.]=50 E N[y i|.,.]=58 Both of these contrasts are calculated within the rows of Table 9.2 rather than the columns. The contrast in the numerator is the naive estimate of the effect of Z on Y.\nIt is calculated as the difference between .08 .02 EN[yi|zi=1]= 50+ 58=51.6 and .08+.02 .08+.02 .8 .1 EN[yi|zi=0]= 50+ 60=51.111.\n.8+.1 .8+.1 The contrast in the denominator is the naive estimate of the effect of Z on D. It is calculated as the difference between .02 EN[di=1|zi=1]= =.2 and .08+.02 .1 EN[di=1|zi=0]= =.111.\n.8+.1 Thus, calculatingthe IVestimate inthis caseis quite simple anddoes notrequireany consideration of the underlying potential outcomes or potential treatments.\nBut, to interpret the IV estimate when causal effect heterogeneity is present, the potential outcome and potential treatment framework are needed. Consider the three identifying assumptions in Equations (9.18) through (9.20). Because the voucher lot- tery is completely random, the voucher instrument Z is independent of the potential outcomeandpotentialtreatmentvariables.Also,asjustshown,Z predictsD,thereby sustainingthe nonzeroeffectassumption.Thus,the firsttwoassumptionsaresatisfied as explained for IV Demonstration 1.\nOnly the monotonicity assumption in Equation(9.20) requires a new justification.\nFortunately,thereisnoevidenceintheschoolchoiceliteraturethatstudentsandtheir parentsrebelagainstvouchers,changingtheirbehaviortoavoidprivateschoolingonly Table 9.3 The Distribution of Never Takers, Compliers, and Always Takers for IV Demonstration 2 Public school Private school d i=0 d i=1 Voucherloser z i=0 7200 Nevertakers 1000 Always takers 800 Compliers Voucherwinner z i=1 800 Nevertakers 111 Alwaystakers 89 Compliers when offered a voucher.27 Accordingly, it seems reasonable to assume that there are nodefiersinthishypotheticalpopulationandhencethatthemonotonicityassumption obtains.\nThe joint implications of independence and monotonicity for the four groups of individualsinthecellsofTable9.2shouldbeclear.Monotonicityallowsustostipulate thatdefiersdonotexist,whileindependenceensuresthatthesamedistributionofnever takers,alwaystakers,andcompliersispresentamongthosewhowinthevoucherlottery and those who do not. As a result, the proportion of always takers can be estimated consistently from the first row of Table 9.2 and the proportion of never takers can be estimated consistently from the second row of Table 9.2 as PrN[di=1,zi=0] −p →Pr[C=a], (9.24) PrN[zi=0] PrN[di=0,zi=1] −p →Pr[C=n]. (9.25) PrN[zi=1] For this example, the proportion of always takers is 1,000/9,000=.111, and the pro- portion of never takers is 800/1,000=.8. Because no defiers exist in the population with regard to this instrument, these two estimated proportions can be subtracted from 1 in order to obtain the proportion of compliers: 1−PrN[di=1,zi=0] −PrN[di=0,zi=1] −p →Pr[C=c]. (9.26) PrN[zi=0] PrN[zi=1] For this example, the proportionof compliers in the population is 1−.111−.8=.089.\nApplying this distribution of always takers, never takers, and compliers (and a bit of rounding) to the frequencies from Table 9.2 yields the joint frequency distribution presented in Table 9.3.\nFor Table 9.3, notice the symmetry across rows that is generated by the indepen- denceoftheinstrument:1,000/7,200≈111/800(subjecttorounding)and800/9,000≈ 89/1,000(again,subjecttorounding).Ofcourse,thereisonemajordifferencebetween 27Someparents mightreasonthatprivateschoolingisnolonger asattractive ifitisto beflooded with an army of voucher-funded children. Thus, defiers might emerge if the vouchers were widely distributed, and the monotonicity condition would then fail. In this case, however, SUTVA would alsofail,necessitating deeperanalysisinanycase.\nthetworows:Thecompliersareinprivateschoolsamongvoucherwinnersbutinpublic schools among voucher losers.\nBefore continuing, two important points should be noted. First, it is important to recognize that the calculations that give rise to the distribution of never takers, always takers, and compliers in Table 9.3 are not determined solely by the data. In a deeper sense, they are entailed by maintenance of the monotonicity assumption. In theabsenceofthatassumption,anunspecifiednumberofdefierswouldbeinthetable as well, making the calculation of these proportions impossible.\nSecond,notallstudentsinthedatasetcanbeindividuallyidentifiedasalwaystak- ers, never takers, or compliers. Consider the private school students for this example.\nOf these 1,200 students, 1,000 students are known to be always takers, as they have observed values of di=1 and zi=0. The remaining 200 private school students are observationally equivalent, with observed values of di=1 and zi=1. We know, based onthemaintenanceofthemonotonicityandindependenceassumptions,thatthese200 studentsinclude 111alwaystakersand89compliers.Butitisimpossibletodetermine which of these 200 students are among the 111 always takers and which are among the 89 compliers. The same pattern prevails for public school students. Here, we can definitively identify 800students as nevertakers,but the 8,000public schoolstudents who are voucher losers cannot be definitively partitioned into the specific 7,200 never takers and the 800 compliers.\nNow, consider why the IV estimator yields 5.5 for this example, and then why 5.5 is interpretable as the averageeffect of private schooling for those who are induced to enroll in private schools because they have won vouchers. As noted already, because Z is independent of Y1 and Y0, the same proportion of always takers and never takers is present among both voucher winners and voucher losers. The difference in theexpectationofY acrossthetworowsofTable9.2mustarisefrom(1)theexistence of compliers only in public schools in the first row and only in private schools in the second row and (2) the existence of a nonzero average treatment effect for compliers.\nTo see this claim more formally, recall Equation (9.21), in which this particular LATE is defined. By the linearity of expectations and the definition of an individual- level causal effect as a linear difference between y1 and y0, the average causal effect i i amongcompliers,E[δ|C=c],isequaltotheexpectationE[Y1|C=c]minustheexpec- tation E[Y0|C =c]. To obtain a consistent estimate of the average causal effect for compliers,itissufficienttoobtainconsistentestimatesofE[Y1|C=c]andE[Y0|C=c] separately and then to subtract the latter from the former.\nFortunately, this strategy is feasible because the contribution of these two condi- tionalexpectationstothe observeddatacanbe writtenoutintwoequationsandthen solved. In particular, E[Y1|C=c] and E[Y0|C=c] contribute to the expectations of the observed outcome Y, conditional on D and Z, in the following two equations: Pr[C=c] E[Y|D=1,Z=1]= E[Y1|C=c] Pr[C=c]+Pr[C=a] (9.27) Pr[C=a] + E[Y1|C=a], Pr[C=c]+Pr[C=a] Pr[C=c] E[Y|D=0,Z=0]= E[Y0|C=c] Pr[C=c]+Pr[C=n] (9.28) Pr[C=n] + E[Y0|C=n].\nPr[C=c]+Pr[C=n] These two equations are population-level decompositions of the conditional expecta- tions for the observed data that correspond to the two cells of the diagonal of Table 9.2.Thesearethe onlytwocells inwhichcompliersarepresent,andthusthe onlytwo cells in which the observed data are affected by the outcomes of compliers.\nHow can we plug values into Equations (9.27) and (9.28) in order to solve for E[Y1|C=c] and E[Y0|C=c] and thereby obtain all of the ingredients of a consistent estimate of E[δ|C=c]? We have already shown from applying the convergence asser- tionsinEquations(9.24)–(9.26)thatthetermsPr[C=c],Pr[C=a],andPr[C=n]can be consistentlyestimated.And,infact,these aregivenearlierfor the exampledata as .089,.8,and.111.Thus,tosolvethese equationsforE[Y1|C=c]andE[Y0|C=c],the only remaining pieces that need to be estimated are E[Y1|C=a] and E[Y0|C=n], which are the average outcome under the treatment for the always takers and the averageoutcomeunderthecontrolforthenevertakers.Fortunately,theindependence and monotonicity assumptions guarantee that voucher losers in private schools repre- sentarandomsampleofalwaystakers.Thus,E[Y1|C=a]isestimatedconsistentlyby EN[yi|di=1,zi=0],whichis60forthisexample(seetheupperright-handcellinTable 9.2). Similarly, because voucher winners in public schools represent a random sample of never takers, E[Y0|C=n] is estimated consistently by EN[yi|di=0,zi=1], which is equal to 50 for this example (see the lower left-hand cell in Table 9.2). Plugging all of these values into Equations (9.27) and (9.28) then yields .089 .111 58= E[Y1|C=c]+ 60, (9.29) .089+.111 .089+.111 .089 .8 50= E[Y0|C=c]+ 50. (9.30) .089+.8 .089+.8 Solving Equation (9.29) for E[Y1|C =c] results in 55.5, whereas solving Equation (9.30) for E[Y0|C=c] results in 50. The difference between these values is 5.5, which is the average causal effect for the subset of all students who would attend a private school if given a voucher but would not attend a private school in the absence of a voucher.28Thevalueof5.5yieldsnoinformationwhatsoeverabouttheeffectofprivate schooling for the always takers and the never takers.29 28For completeness, consider how the naive estimate and the LATE would differ if all remained the same except the stipulated value of 50 for E N[d i=0,z i=0] in Table 9.2. If E N[d i=0,z i=0] were instead 50.25, then the naive estimate would be 9.44 and the LATE estimate would be 3.00.\nAnd, if E N[d i=0,z i=0] were instead 50.5, then the naive estimate would be 9.21 and the LATE estimate would be .5. Thus, for the example in the main text, compliers on average do no worse in publicschoolsthannevertakers.But,forthesetwovariantsoftheexample,compliersonaveragedo slightly better in public schools than never takers. As a result, the calculations in Equation (9.29) remainthesame,butthevaluesofEquation(9.30)changesuchthatE[Y0|C=c]isequalto52.5and 55.0,respectively. TheLATEestimateisthereforesmallerinbothcases because theperformanceof compliersinpublicschoolsishigher(whereastheperformanceofcompliersinprivateschoolsremains thesame).\n29We can estimate E[Y1|C =a] and E[Y0|C =n] consistently with E N[y i|d i =1,z i =0] and E N[y i|d i=0,z i=1]. But we have no way to effectively estimate their counterfactual analogs: the Of course, the Wald estimate is also 5.5, as shown in Equations (9.8) and (9.23).\nAnd thus, in one sense, the Wald estimator can be thought of as a quick alternative method for calculating all of the steps just presented to solve exactly for E[δ|C=c].\nEven so, this correspondence does not explain when and how the Wald estimator can be interpreted as the average causal effect for compliers. For this example, the cor- respondence arises precisely because we have assumed that there are no defiers in the population, basedon the substance of the applicationand the treatment response model thatwe adopted.As a result,the Wald estimate canbe interpretedas a consis- tent estimate of the averageeffect of private schooling for those who comply with the instrument because it is equal to that value under the assumed model of treatment response we are willing to adopt.30 LATE estimators have been criticized because the identified effect is defined by the instrument under consideration. As a result, different instruments define different averagetreatment effects for the same groupof treated individuals. And, when this is possible, the meanings of the labels for the latent compliance variable C depend on theinstrument,suchthatsomeindividualscanbenevertakersforoneinstrumentand compliers for another. Deaton writes: Without explicit prior consideration of the effect of the instrument choice ontheparameterbeingestimated,suchaprocedureiseffectivelytheoppo- site of standard statistical practice in which a parameter of interest is definedfirst,followedbyanestimatorthatdeliversthatparameter.Instead, we have a procedure in which the choice of the instrument … is implic- itly allowed to determine the parameter of interest. This goes beyond the old story of looking for an object where the light is strong enough to see; rather, we have at leastsome control overthe light but choose to let if fall where it may and then proclaim that whatever it illuminates is what we were looking for all along. (Deaton 2010:429) Although from one perspective the instrument-dependent nature of the LATE is a weakness, from another perspective it is the most attractive feature of the LATE.\nFor IV Demonstration2, the IV estimate does not provide any information about the average effect for individuals who would attend private schooling anyway (i.e., the always takers) or for those who would still not attend the private schools if given a voucher (i.e., the never takers). Instead, the IV estimate is an estimate of a narrowly defined averageeffectonly amongthose induced to take the treatmentby the voucher policy intervention. But, for IV Demonstration 2, this is precisely what should be of interest to the state officials. If the policy question is “What is the effect of vouchers meanoutcomeinpublicschoolsforalwaystakersandthemeanoutcomeinprivatesschoolsfornever takers.\n30In other words, the Wald estimate of 5.5 is also a quick method for calculating an entirely differentcausaleffectunderadifferentsetofassumptions.Ifmonotonicitycannotbedefended,then the IV estimate can be given a traditional structural interpretation, under the assumption that the causal effect is constant for all individuals. In this sense, because the Wald estimate has more than one possible causal interpretation, merely understanding how it is calculated does not furnish an explanationforhowitcanbeinterpreted.\nonschool performance?” then they presumably care most about the averageeffect for compliers.\nThe limited power of the LATE interpretation of an IV estimate is thus, in some contexts,beneficial because ofits targetedclarity.Moreover,when supplementedby a range of additional IV estimates (i.e., different voucher sizes and so on), complemen- taryLATE estimates maycollectively representanextremely useful setof parameters that describe variation in the causal effect of interest for different groups of individ- uals exposed to the cause for alternative (but related) reasons. Before summarizing the marginal treatment effect literature that more completely specifies the interre- lationships among all types of average causal effect estimators, we first lay out the implications of the LATE perspective for traditional IV estimation and consider the relevant graphs for representing IVs that identify LATEs.\n9.3.2 Implications of the LATE Perspective for Traditional IV Estimation TheLATEliteraturespecifiesasetofassumptionsunderwhichitispermissibletogive IVestimatesanaveragecausaleffectinterpretationusingthepotentialoutcomemodel.\nIn this sense, the new framework is mostly a set of guidelines for how to interpret IV estimates. As such, the LATE perspective has direct implications for traditional IV estimation, as introduced earlier in this chapter.\nMonotonicity and Assumptions of Homogeneous Response An important implication of the LATE framework is that many conventional IV esti- mates lack a justifiable average causal effect interpretation if the IV does not satisfy a monotonicity condition. In the presence of causal effect heterogeneity and in the absence of monotonicity of response to the instrument, a conventional IV estimator yields a parameter estimate that has no clear interpretation, as it is likely an uniden- tifiable mixture of the treatment effects of compliers and defiers.\nForIVDemonstration2,weshowedthattheestimateof5.5isapplicabletostudents whose families would change their child’s enrollment choice from a public school to a private schoolfor a $3,000voucher.Canan assumptionbe introducedthat allows the estimate of 5.5 to be be interpreted as informative about other students who do (or who would) attend private schools? Two variants of the same homogeneity assumption allow for such extrapolated inference: the assumption that the causal effect is a structural effect that is (1) con- stant across all members of the population or (2) constant across all members of the populationwhotypicallytakethetreatment.31Initsstrongerform(1),theassumption simply asserts that the causal effect estimate is equally valid for all members of the population,regardlessofwhetherornotthegroupofstudentswhoseenrollmentstatus wouldchangeinresponsetothevoucherisrepresentativeofthepopulationofstudents as a whole. In its weaker form (2), the assumption pushes the assumed constancy of the effect only half as far, stipulating that the IV estimate is valid as an estimate 31 These assumptions are known as constant-coefficient assumptions, homogeneous response assumptions,orshiftedoutcome assumptions(seeAngristandPischke2009;Manski1995, 2003).\nof the ATT only. For IV Demonstration 2, the weaker variant of the homogeneity assumption is equivalent to asserting that the IV estimate provides information only about the achievement gains obtained by private school students. Although weaker, the homogeneity assumption (2) is still quite strong, in that all individuals in private schools are considered homogeneous with respect to the size of the treatment effect.\nIn examples such as IV Demonstration2,it is clear that there are two distinct groups within the treated: always takers and compliers. And there is little reason to expect that both groups respond in exactly the same way to private schooling. Thus, for examplessuchasthisone,Manski(1995:44)arguesthatthishomogeneityassumption “strains credibility” because there is almost certainly patterned heterogeneity in the effect among treated individuals.\nOne traditional way to bolster a homogeneity assumption is to condition on vari- ables in a vector X that can account for all such heterogeneity and then assert a conditional homogeneity of response assumption. To do so, the Wald estimator must be abandonedin favorof a two-stageleastsquares(2SLS)estimator.As showninany econometrics textbook (e.g., Greene 2000; Wooldridge 2010), the endogenous regres- sorsD andX areembeddedinanencompassingXmatrix,whichis n× k, wheren is the number of respondents and k is the number of variables in X plus 2 (one for the constantand one for the treatment variable D). Then, a matrix Z is constructedthat is equivalent to X, except that the column in X that includes the treatment variable D is replaced with its instrument Z. The 2SLS estimator is then δˆ IV,2SLS≡(Z(cid:2) X)−1Z(cid:2) y, (9.31) where y is an n × 1 vector containing the outcomes yi. The strategy is to attempt to condition out all of the systematic variability in the observedresponse and then to simultaneously use the instrument Z to identify a pure net structural effect that can be regarded as an invariant constant.\nIs this strategy a feasible solution? Probably not. If good measures of all of the necessary variables in X are available, a simple OLS estimator probably would have been feasible in the first place. Rarely would all possible necessary variables be avail- able,exceptforasinglevariablethathasanetadditiveconstanteffectontheoutcome that can then be estimated consistently by an available IV.\nOther Challenges for Interpretation IVestimatesarehard,andsometimesimpossible,tointerpretasLATEestimateswhen the instrument measures something other than an incentive to which individuals can consciously respond by complying or defying. Instruments based on exogenous field variation (as championed in Angrist and Krueger 2001 but criticized in Rosenzweig and Wolpin 2000 andDeaton 2010)canbe particularly hardto interpret, because the shifts in costs and benefits that the natural variation is supposed to induce generally remain unspecified, thereby weakening a main link in the narrative that explains why some individuals take the treatment in response to the instrument.\nMoreover,if two or more IVs are available, then the traditional econometric liter- ature suggests that they should both be used to “overidentify” the model and obtain a more precise treatment effect estimate by the 2SLS estimator in Equation (9.31).\nOveridentifiedmodels,inwhichmorethanoneinstrumentisusedtoidentifythesame treatment effect, generate a mixture-of-LATEs challenge.\nConsider the Catholic school example discussed earlier. Suppose that two IVs are used: the share of the county that identifies as Catholic and a student’s religious identification (as in Neal 1997). Even if these potential IVs have no net direct effects on test scores (and, further, that the weak instrument problem discussed earlier is not applicable), can a theoretically meaningful LATE interpretation be given to the effect that the two instruments in this example jointly identify? For the religious identificationinstrument,theimpliedLATEistheaverageeffectofCatholicschooling amongthosewhoarelikelytoattendCatholicschoolsonlybecausethey areCatholic.\nWhen overidentified with the IV represented by the share of the local population that is Catholic, this first LATE is mixed in with a second LATE: the average effect of Catholic schooling among those who attend Catholic schools only because of the small difference in tuition that a high proportion of Catholics in the local population tends to generate.As a result, the overidentifiedcausaleffect that is estimated by the 2SLS estimator would be an average across two very different groups of hypothetical individuals, both of which likely deserve separate attention.32 It is sometimes possible to deconstruct 2SLS estimates into component LATEs when multiple IVs are used, but explaining how to do so is beyond the scope of this book. We advise readers who are in this situation to first consult Angrist and Pischke (2009, section 4.5) and the work cited therein. Our position is that there is comparatively little value in estimating a single treatment effect parameter using a 2SLS model in these cases. Usually, if more than one LATE is identified, then these can and should be estimated separately.\nIn sum, if causal effect heterogeneity is present, then a constant-coefficient inter- pretationofanIVestimateisimplausible.However,iftheinstrumentsatisfiesamono- tonicity condition and can be conceptualized as a proximate inducement to take the treatment, then IV estimates can be given LATE interpretations. These fine-grained interpretations can be very illuminating about particular groups of individuals, even thoughtheymayprovidenoinformationwhatsoeveraboutothergroupsofindividuals in the population (including other individuals who typically choose to take the treat- ment).Thus,thelimitednatureofIVestimatorswheninterpretedasLATEestimators shows both the potential strengths and weaknesses of IV estimation in general.\n9.3.3 Graphs for IVs That Identify LATEs In this section, we will explain how to represent instrumental variables that identify LATEs as observed variables in directed graphs. The primary complication is that compliance with the instrumental variable is a latent class variable, across which it 32There is also the possibility that, contra the justification of Hoxby (1996), the individuals who are induced to attend Catholic schooling because a greater share of the population is Catholic are not at all the same as those who are supposedly at the margin of a tuition-based cost calculation.\nTheremaybeanothermechanismthatgeneratesanyobservedassociationbetweenZ andD,suchas thepossibilitythat theCatholicschools aresimplybetter inthesecommunities andhence aremore attractiveingeneral.ThisisonebasiccriticismthatRosenzweigandWolpin(2000)levelagainstall suchnaturallyoccurringIVs:ThereisoftennoevidencethattheIVisinducingagroupofindividuals totakethetreatment accordingtoanassumedcost-benefitsetofchoices.\nZ D Y Figure9.4 Instrumental variable identification of the causal effect of charter schools (D) on test scores (Y), where Z is the instrument.\nmust be assumed that heterogeneity of effects is present. Recall the charter schools example, as introduced in Section 1.3.2and then as analyzed at length in Section 8.3.\nInthatpriordiscussion,weshowedhowcausalgraphscanbeusedtorepresentcomplex patterns of self-selectionand heterogeneity using a latent class variable. In particular, reconsiderFigure8.6(b),whichweusedtoexplainwhyback-doorconditioningforthe effect of charter schooling D on educational achievement Y was infeasible because of back-door paths through G.33 For simplicity, suppose now that the parental background confounder P is also unobserved.As aresult, the analystis left with no wayto evenbeginto enacta back- door conditioning strategy for the effect of charter schools. Suppose, instead, that an instrumental variable Z is observed, as in Figure 9.4.\nAre there any plausible instrumental variables for charter school attendance? The geographic distance between the student’s residence and the charter school site is similar to the sorts of potential IVs used in the traditional economics literature. The rationale would be that the location of the treatment site is arbitrary but has an effect on enrollment propensity because of the implicit costs of traveling to the site, which are typically borne by the parents, not by the school district. For the charter school example, it is unclear whether such an instrument would have any chance of satisfying the relevant assumptions, and it would depend crucially on the extent to which charter schools are located in arbitrary places. Our reading of the literature is that charter schools tend to be located nearer to students most likely to benefit from charter schooling, both because many have missions to serve disadvantaged students who are thought to benefit most from having a charter school opportunity and also becauseparentsmaythenmovetoneighborhoodsthatareclosertothecharterschools that they select for their children. It is possible that these threats to the identifying assumption could be mitigated by conditioning on other determinants of the location of charter schools within the district and also obtaining family residence data before students entered charter schools.\nForthesakeofmethodologicalclarityinourpresentation,wewilluseasourexam- pleamoreconvincingbutunlikelyinstrumentalvariable,inthesensethatithasnever 33For a real example with a structure that is not too dissimilar from ours, Jin and Rubin (2009) eschew graphs and adopt an alternative principal stratification approach to represent latent classes fortypesofcomplianceaswellasaverageeffectswithintheseclasses.Byomission,theydemonstrate thatgraphsarenotneededinordertoofferasensiblerepresentationofunderlyingheterogeneityand tofocusoncompliancetypesofparticularinterest.Theutilityoftheprincipalstratificationapproach for compliance latent classes, first laid out in Frangakis and Rubin (2002), is unrelated to a more recent debate on its utility for interpreting direct and indirect causal effects (see Joffe 2011; Pearl 2011;VanderWeele 2008,2011a).\nyet become available and is unlikely to become available in the future. Suppose that in New York City conditional cash transfers are offered to families that send their childrentocharterschools.Suppose thatthis programismodeledonNew YorkCity’s recent Opportunity NYC program, which was justified by the position that families should be given incentives to make decisions that promote their children’s futures.\nSuppose that for the new hypothetical program$3,000in cash is offered eachyear to families for each child that they enroll in a charter school. Since charter schools do not charge tuition, families can spend the $3,000 per child however they see fit.\nSupposefurtherthat,becauseofabudgetconstraint,cashtransferscannotbeextended to all eligible families. For fairness, it is decided that families should be drawn at random from among all families resident in New York City with school-age children.\nAccordingly, a fixed number of letters is sent out notifying a set of winning families.\nIt is later determined that 10 percent of students in charter schools received cash transfers. A dataset is then compiled with performance data on all students in the schooldistrict,andthe cashtransferofferis codedasa variableZ,whichis equal to1 forthosewhowereofferedacashtransferand0forthosewhowerenot.Aquickanalysis ofthe datashowsthatsomefamilies whoreceivedoffersofcashtransfersturnedthem down and chose to send their children to regular public schools. Moreover, it is then assumed that at least some of the charter school students who receivedcash transfers wouldhave attended charter schools anyway,and they were simply lucky to have also received a cash transfer.\nBy the standards typical of IV applications, Z would be considered a valid instru- ment. It is randomly assigned in the population, and it is reasonable to assume that it has a direct causal effect on D because it is an effective incentive for charter school attendance.(WehavealsoassumedinthesetupthatthedatashowthatZ predictsD.) Again, the crucial assumption is that the entire association between Z and Y is attributable solely to the directed path, Z →D→Y. As we will discuss below in this section,this assumptionis debatablein this case becausethe subsidy is cashand, withoutfurtherrestrictions,couldbeusedbyfamiliesofcharterschoolstudentstopur- chaseothergoodsthathaveeffectsonY.Anysuchalternativeusesofthecashtransfer would open up additional causal pathways from Z to Y that are not intercepted by D. For now, however, we will provisionally accept this identification assumption.\nWhatparameterdoesZ identify?Supposethatamonotonicityassumptionisvalid whereby the cash transfers do not create a disincentive for anyone to enter charter schools(i.e.,defierswithrespecttoZ donotexistinthepopulation).Thisassumption allows us to abandon the constant coefficient assumption and instead assert that Z identifiesthefollowingLATE:theaverageeffectofcharterschoolingamongthosewho enter charter schools in response to the offer of a conditional cash transfer.\nFigure9.5showsonewaytorepresentestimatorsofthistype.Forthesetwographs, the population can be partitioned into two mutually exclusive groups, compliers and noncompliers (as explained in Section 9.3, and assuming defiers do not exist). Fig- ure 9.5(a) is the graph for compliers. No back-door paths connect D to Y in this graphbecause compliers,by definition, decide to enter charterschoolssolely basedon Z Z D Y D Y (a) Compliers (b) Always takers and never takers Figure9.5 Instrumental variable identification of the causal effect of charter schools (D) on test scores (Y), where separate graphs are drawn for compliers and noncompliers.\nwhether they are offered the conditional cash transfer.34 Analogous to the distribu- tion calculated for Table 9.3, compliers are present in both regularpublic schools and charter schools.\nFigure 9.5(b) is the graph for noncompliers. Always takers enter charter schools regardlessof whether they receivethe offer of a cashtransfer,and nevertakersdo not enter charter schools regardless of whether they receive the offer of a cash transfer.\nAs a result, Z does not cause D for either always takers or never takers. The analyst can therefore place Z within the graph, but the causal effect Z→D must be omitted.\nInstead, the analyst includes D(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)Y to represent the unobserved joint causes of D and Y, as it is these factors that suggest why identification via an instrumental variable is needed.\nGiven that a central theme of this book is the power of graphs to represent causal relationships,wewillconcludebyaddressingafinalquestion:CantheclarityofFigure 9.5berepresentedinasinglecausalgraph,akintothemovefromFigure8.3toFigure 8.4 in Section 8.3? Yes, but readers may not agree that the clarity is preserved.\nFigure9.6isacombinedrepresentationofFigure9.5,whichnowappliestothefull population. The representation of compliance-based heterogeneity is accomplished by augmenting the graphwith a latent class variable, C, which signifies whether an indi- vidualisacomplierornot.35 Inparticular,C takesonthreevalues, oneforcompliers, one for always takers, and one for never takers (and we assume that defiers do not exist in the population). Most importantly, C interacts with Z in determining D, and then C interacts with D in determining Y.36 Now, to make the connection to the fully elaborated Figure 8.7 (see page 285), consider Figure 9.7, which includes all of the relevant back-door paths between D 34WethankPeterSteinerforpointingouttousthat,contrarytofigureA2inMorganandWinship (2012), Figure9.5(a)shouldnotincludeD(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)Y.NoneofthecommoncausesofD andY among noncompliershaveanalogouseffectsforcompliersbecauseDisdeterminedsolelybyZ forcompliers.\n35Analternativeandmorecompact graphcouldbeusedforFigure9.6.Because C isunobserved, onecouldsimplydeclarethatitisamemberofthesetofvariablesthatgeneratethebidirectededge in Figure 9.6 (or as a member of the set of variables in V that will be introduced below for Figure 9.7). We give C its own pair of explicit causal effects on D and Y for clarity, even though it makes thegraphmorecomplexthanitneedstobe.\n36It is possible that one could assume that C does not determine Y. This would be the case, for example, if one had reason to believe that the LATE is equal to the ATE, which would seem to be veryunlikelyinsocialscienceapplications.\nZ D Y C Figure9.6 A combined graph for Figures 9.5(a)–(b), where Z is the instrument and compliance is represented as an unobserved latent class variable (C).\nand Y represented as D(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)Y for Figure 9.6. Still, for simplicity we have replaced the path I →Exp(D→Y)→G from Figure 8.7 with the single variable V.37 The conditionalcashtransfer is then representedas aninstrumental variable Z, which has a sole causaleffect in the graphon D because we haveassumedthat the cashtransfer offer does not have other effects on Y. Finally, we then add the additional back-door path from D to Y through their new common cause C.\nWith the addition of D←C→Y to the graph,two sources of confusion may arise for some readers. First, it remains true that we cannot use back-door conditioning to estimate the effect of D on Y because of the unblockable back-door path through D←V →Y.However,itisimportanttorememberthatthesimilarlystructuredback- doorpathD←C→Y doesnotpresentanyproblemsforanIVestimatorbecauseitis not a back-door path from Z to Y, nor part of a directed path that carries the effect of Z to Y. It only represents an additional unblocked back-door path from D to Y.\nSecond,nothinginthecausalgraphitselfexplainswhyaresultingIVestimatordelivers an average causal effect that applies only to compliers. To understand this point, it may be more helpful to draw two separate causal graphs, as in Figure 9.5. The single causal graph does not reveal that there is an implicit interactionbetween Z and C as causes of D. In particular, the instrument Z does not cause D for noncompliers, and C does not cause D for those who do not receive the offer of a cash transfer. Only the co-occurrence of Z and C switches some members of the population from D=0 to D=1.\nNow, to conclude the discussion of the estimation of the charter school effect, considertwofinalpoints. ItislikelythatFigure9.7improperlyomitsthe likelycausal effect P →C. The parental background variable P implicitly includes within it a variable for family income. Students from families with high incomes should be less likely to switch from regular public schools to charter schools because of an offer of a modestconditionalcashtransfertotheirparents.Addingsuchapath,however,would notharmthe feasibility of the IVestimator, since it does notgeneratean unblockable path from Z to Y. In fact, the effect P →C helps to explain who compliers likely are, because it suggests that they are more likely to be lower income families. In this sense, recognizing the likely presence of this effect helps to interpret the LATE that the IV identifies.38 In addition, this type of effect reveals a distinct advantage of a 37This simplification is permissibleunder the assumption that an impliciterror term e V contains alloftheinformationintheerrortermse I,e Exp,ande G inthecausal graphinFigure8.7.\n38For situations suchas these, Angristand Fernandez-Val (2013) propose alternative methods for usingmultiple IVs and covariate information to put forwardestimates of broader parameters based onidentifiedLATEs(seealsoAronowandCarnegie2013).\nZ V N D P Y C Figure9.7 Identificationofthe LATEusinganinstrument(Z)forthe charterschool graph presented earlier in Figure 8.7. The unobserved variable V is a composite for the causalchain that generates self-selectionin Figure 8.7 throughinformation access and selection on the subjective evaluation of the individual-level causal effect.\nsingle population-levelgraphthat representscompliance asa node within it. Separate graphs for compliance classes do not permit a representation of the effect of P on compliance.\nBut,ofcourse,notalladditionalcausaleffectswillhelptoclarifytheIVestimator.\nSuppose,forexample,thatZ generatesaneffectonN becausethecashtransferisused topayhigherrentinanotherneighborhoodforsomefamilies.Asaresult,adirecteffect fromZ toN isopenedup.ConditioningontheobservedvariableN willblockthenew directed path Z → N → Y. But, because N is a collider on another path, Z → N← V →Y, conditioning on N opens up this pathway by inducing a relationship between Z and V. Thus, conditioning away self-selection into neighborhoods then allows self- selection on the causal effect of charter schooling to confound the IV estimate of the LATE.\n9.3.4 Local IVs and Marginal Treatment Effects In this final section, we discuss one additional perspective on the identifying power of IVs in the presence of individual-level heterogeneity, which shows how a perfect instrument can help to identify a full pattern of causal effect heterogeneity. Heckman andVytlacil(1999,2000,2005,2007),buildinguponHeckman(1997),haveshownthat LATEs and many other average treatment effects can be seen as weighted averages of more fundamental marginal treatment effects.39 Although the generality of their perspective is captivating, and the methodological content of the perspective unifies manystrandsoftheliteratureincausaleffectestimation,wesummarizeitonlybriefly here because the demands on data are quite substantial. The all-powerful IV that is neededtoestimateafullscheduleofmarginaltreatmenteffectswillrarelybeavailable to researchers.\nThe marginal treatment effect (MTE) perspective can be easily graspedwith only a slight modification to the setup of IV Demonstration 2. Instead of 10 percent of students receiving a voucher that is exactly equal to $3,000, suppose instead that 39SeealsoHeckmanetal.(2006) andHeckmanandUrzua(2010).\nthese 10 percent receive a voucher that is a randomdraw from a uniform distribution with a minimum of $1 and a maximum equal to the tuition charged by the most expensive private school in the area.\nFor Heckman and his coauthors, the size of each student’s voucher is a valid instrument Z, maintaining the same assumptions as we did for IV Demonstration 2 (i.e., Z is randomly assigned, Z has a nonzero effect on D, and the effect of Z on D is monotonic). The monotonicity assumption is a little more complex than before, but it stipulates that the true probability of taking the treatment is higher for all individuals with values of Z equal to z(cid:2)(cid:2) rather than z(cid:2) if z(cid:2)(cid:2)&gt; z(cid:2). This fits cleanlyinto the notationintroducedearlierin this chapter by simply allowingZ to be many-valued.\nHeckman and his coauthors then define two related concepts: a local instrumental variable (LIV) and an MTE. An LIV is the limiting case of a component binary IV drawn from Z in which z(cid:2)(cid:2) approaches z(cid:2) for any two values of Z such that z(cid:2)(cid:2)&gt; z(cid:2).\nEach LIV then defines a marginal treatment effect, which is the limiting form of a LATE, in which the IV is an LIV.\nConsider the more elaborate version of IV Demonstration 2 just introduced here.\nOne could form LIVs from Z by stratifying the data by the values of Z and then considering adjacent strata. Given a large enough sample for a large enough voucher program,LIVs could be constructedfor eachdollarincreasein the voucher.EachLIV could then be used to estimate a LATE, and these LIV-identified LATEs could then be considered MTEs.\nHeckman and Vytlacil (2005) show that most average causal effect estimates can be represented as weighted averages of MTEs, identified by LIVs. But the weight- ing schemes differ based on the parameter of interest, some of which, as was the case in our regression chapter, may have no inherent interest. Heckman and Vyt- lacil therefore propose a more general strategy. They argue that researchers should define the policy-relevant treatment effect (PRTE) based on an assessment of how a contemplated policy would affect treatment selection. Then, MTEs should be esti- mated with LIVs and weighted appropriately to obtain the PRTE that is of primary interest.\nThere is much to recommend in this approach, and in fact it should not be con- sidered an approach relevant only to policy research. The approach is quite easily extended to targeted theory-relevant causal effects, for which one wishes to weight marginal causal effects according to a foundational theoretical model. But, in spite of this appeal, the entire approach may well come to represent a gold standard for what ought to be done rather than what actually can be done in practice. If it is generally recognized that IVs satisfying the LATE assumptions are hard to find, then those that satisfy LIV assumptions for all MTEs of interest must be harder still.40 40Partlyforthis reason, Carneiro, Heckman, and Vytlacil (2010) elaborate the PRTE perspective andfocusattentiononalimitingformofthePRTEthattheylabelmarginalpolicy-relevanttreatment effects (MPRTEs).TheyarguethatitiseasiertoestimateMPRTEsandthatthese maybeallthat areneededtoevaluateproposedpolicychanges.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#conclusions-6",
    "href": "extracted/Counterfactuals and Causal Inference.html#conclusions-6",
    "title": "Counterfaturals and Causal Inference",
    "section": "9.4 Conclusions",
    "text": "9.4 Conclusions\nThe impressive development of the IV literature in econometrics and statistics in the\npast two decades suggests a variety of recommendations for practice that differ from those found in the older IV literature: 1. Weakinstrumentsyieldestimatesthatareespeciallysusceptibletofinite sample bias.Consequently,naturalexperimentsshouldbeavoidediftheimpliedIVsonly veryweaklypredictthecausalvariableofinterest.Nomatterhowseductivetheir claimstosatisfyidentificationassumptionsmaybe,resultingpointestimatesand standard errors may be very misleading.\n\nIfindividual-levelcausaleffectheterogeneityispresent,apotentialIVshouldbe used only if it satisfies a monotonicity condition. IV estimates should then be interpreted as LATE estimates defined by the instrument.\nIfindividual-levelcausaleffectheterogeneityis present,IVsshouldprobablynot be combined in a 2SLS model (except in the rare cases in which measures of all of the variables that account for the causal effect heterogeneity are available).\n\nInstead, IV estimates should be offered for those IVs that satisfy monotonic- ity conditions. These alternative estimates should then be interpreted as LATE estimates and reconciled with each other based on a narrative about why the causal effect varies for different types of individuals who are exposed to the cause (and/or different levels of the cause) for different reasons.\n\nWhen possible, IVs should be used to examine general patterns of causal effect heterogeneity. Using IVs to estimate only the ATE or ATT is too narrow of a purpose because there is likely a good deal of variation in the treatment effect that is amenable to analysis with complementary IVs. The possibilities for this type ofanalysisaremostclearlydevelopedinthe literature onthe identification of MTEs using LIVs.\n\nProperlyhandled,thereismuchtorecommendintheIVestimationstrategyforcausal analysis.But,ofcourse,IVsmaynotbeavailable.Wenowturntoothertechniquesthat mayallowforthepointidentificationandestimationofacausaleffectwhenacomplete model of causal exposure cannot be formulated because selection is determined by relevant unobserved variables.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#the-dangers-of-insufficiently-deep-explanations",
    "href": "extracted/Counterfactuals and Causal Inference.html#the-dangers-of-insufficiently-deep-explanations",
    "title": "Counterfaturals and Causal Inference",
    "section": "10.1 The Dangers of Insufficiently Deep Explanations",
    "text": "10.1 The Dangers of Insufficiently Deep Explanations\nBefore considering how mechanisms can be used to identify causal effects, we first\ndiscuss the importance of explanatory depth in causal analysis. To do so, we return to the critical work of Rosenzweig and Wolpin (2000) on the limited appeal of many natural experiments. As discussed inChapter 9, the natural experiment literature in economics uses naturally occurring forms of randomness as instrumental variables (IVs) in order to identify and then estimate causal effects of long-standing interest.\nInitially,thisliteraturewasheraldedasthearrivalofanewageofeconometricanalysis, in which it appeared possible to consistently estimate some of the causal effects of greatest interest to economists, such as the effect of human capital investments in education on earnings. Looking back on these bold claims, Rosenzweig and Wolpin (2000:829–30) conclude, “The impression left by this literature is that if one accepts that the instruments are perfectly random and plausibly affect the variable whose effect is of interest, then the instrumental-variables estimates are conclusive.” They then argue that these estimates are far from conclusive and, in fact, are far more shallow than typically recognized.\nTo somewhat overstate the case, the initial overconfidence of the natural experi- ment movement was based on the mistaken belief that the randomness of a natural experimentallowsonetooffervalidcausalinferenceintheabsenceofanyexplicitthe- ory.Onemightsaythatsomeeconometricianshadbeenseducedbyapositionimplicit in some writing in statistics: We do not need explicit theories in order to perform data analysis. Rosenzweig and Wolpin (2000) counter this position by arguing that the theorythat underlies any modelspecificationis criticalto the interpretationof an estimate of a causal effect, and almost all examples of estimation by natural experi- mentshavemodelspecificationsthatmakeimplicittheoreticalclaims(seealsoDeaton 2010 and our prior discussion in Section 9.3).\nHere, we provide an informal presentation of two of the examples analyzed by RosenzweigandWolpin–the effectofeducationonearningsandthe effectofmilitary service on earnings – each of which was already introduced and discussed briefly in Chapter9.Wewillusedirectedgraphshereinordertodemonstratetheissuesinvolved.\nAngrist and Krueger (1991, 1992) address the ability-bias concern for the estima- tionofthe causaleffectofschoolingonsubsequentlabormarketearnings.Theyassert thatthe quarterinwhichoneis bornis randombutnonetheless predictsone’slevelof education because of compulsory school entry and dropout laws (see the quotation in Section 9.2 that gives the rationale). Angrist and Krueger’s estimates of the increase in log earnings for each year of education fall between .072 and .102, values that are consistent with those found by others using different methods (see Card 1999).\nAs discussed already in Chapter 9, the first limitation of their results is that their IVestimatesapplytoonlyanarrowsegmentofthepopulation:thoseindividualswhose School Wages Quarter of Birth Experience Figure10.1 A directed graph for compliers with quarter of birth as an IV for years of schooling.\nschoolingwouldhave changedif their birthdate was in a different quarter.Again, this is a local average treatment effect (LATE) estimate that applies to those individuals whose years of schooling are responsive to school entry and dropout laws. No one maintainsthatthisnarrowsubpopulationissimplyarandomsampleofallindividuals inthepopulationofinterest,andmostwouldarguethatAngristandKruegerestimated the returns to schooling only for disadvantaged youth prone to dropping out of high school for other reasons. There are, however, complications of how to interpret their estimates even for this subpopulation.\nConsider the directed graph in Figure 10.1, which is based loosely on the critique offeredbyRosenzweigandWolpin(2000)andisasummaryofthedebatethatunfolded inthe yearsfollowingthe publicationofAngristandKrueger(1991).The graphisnot meant to represent a full causal account of how education determines wages, and it is restricted only to the causal effect among compliers. As discussed in Chapter 9, for this example, compliers are those members of the population whose education is (or would be) responsive to a switch in their quarter of birth. Thus, this graph takes it for granted that this particular LATE is the only parameter that is informed by this analysis.1 For Figure 10.1, schooling has both direct and indirect effects on wages. Most important, as is maintained in the human capital literature, schooling is thought to haveanegativeindirecteffectonwagesthroughworkexperience;goingtoschoollonger reducestheamountofworkexperienceoneacquiresbyanyparticularage.Accordingly, there is a causal pathway from schooling to wages via work experience. The quarter- of-birth IV does not provide a separate estimate of this distinct pathway because a change in schooling in response to one’s birthdate also changes work experience.\nInstead, the quarter-of-birth IV estimates only the total effect of schooling on wages, not its direct effect.2 The IV yields a LATE estimate that likely mixes together two 1Thispositionisequivalenttoassumingthatamoreencompassinggraphexiststhatisapplicable to the entire population and that Figure 10.1 applies only to compliers. See our prior discussion of Figure9.5(a).\n2Angrist and Krueger could deal with this problem by conditioning on a measure of work expe- rience, but in their data no such variable is available. The only alternative with their data, which School Wages Military Service Draft Lottery Civilian Experience/Training Figure10.2 A directed graph for compliers with the Vietnam draft lottery as an IV for military service.\ndistinct and countervailing causal pathways: a positive direct effect of schooling on wages and a negative indirect effect via work experience. Given the long-standing interest of economists in the interaction between investments in formal schooling and the provision of on-the-job training, this total effect estimate can be regarded as an insufficiently deep causal account of the effect of education on earnings (even if one is convinced, as we are, that learning about compliers in this case is still illuminating).\nForasecondexample,considertheeffectofmilitaryserviceonlifetimeearnings,as analyzedbyAngrist(1990)andintroducedinSection9.2.Thequestionofinteresthere iswhethermilitaryserviceprovidesimportanttrainingthatincreaseslaterearningsin civilian life or rather whether military service is simply a period of lost civilian work experience. Military service, however, is not random. On the one hand, individuals mustpassamentalabilitytestandahealthexaminationinordertoenlist.Ontheother hand, individuals with attractive schooling opportunities and civilian labor market opportunitiesarelesslikelytoenlist.Todealwiththeproblemofnonrandomselection into the military, Angrist (1990)considers individuals who were potentially eligible to be drafted into the military by a lottery during the later stages of the Vietnam War.\nTo ensure that the draft was fair, the government decided to draft individuals based on a lottery that selected birthdates (see our earlier discussion in Section 9.2).\nConsider now the directed graph in Figure 10.2, again based on the summary of critiquesofthestudycompiledbyRosenzweigandWolpin(2000).Here,therearethree issues to consider. First, as we noted for the last example, the draft lottery identifies a LATE,andthus itis notapplicableto the causaleffectfor alwaystakers(those who voluntarilyenlisted) andnevertakers(those who weredraftdodgers,thosewho failed the mental ability test, and those who failed the physical examination). Accordingly, as for Figure 10.1, the graph in Figure 10.2 also applies to compliers only.\nSecond, note that there is a potential path from the draft lottery to civilian expe- rience/training.If this path exists, then the draft lottery is nota valid IV for military is common in the literature, is to attempt to untangle the effects by conditioning on the number of yearssincetherespondentcompletedhisorherhighestlevelofeducation.However,thisformofcon- ditioning does not completely explain away the association between schooling and work experience, asiswidelyrecognized(seeCard1999).\nservice. As we noted in Chapter 9, Heckman (1997) argued that employers would be likelyto investless inindividuals with unfavorablelotterynumbers. Forexample, itis plausible that employers may have given less on-the-job training to those most likely to be drafted and/or may have assigned such individuals to short-run tasks that did not require the accumulation of skill to master. If this effect exists, then the draft lottery would be an invalid instrument for military service.\nThird,andmostimportantforourconsiderationhere,therearefourseparatecausal pathways between military service and wages. In addition to the direct causal effect of military service on wages, there are two directed paths solely mediated by civilian experience and schooling, respectively. Here, it is generally thought that military ser- vice reduces civilian labor force experience and schooling, both of which then reduce wages.Butthereisthenacountervailingeffectofmilitaryservicethatsnakesthrough the graph via a fourth directed path: Military service reduces schooling, which then increases work experience, and which then increases wages. Because all four of these pathwaysareactivatedbytheshockinducedbythedraftlottery,Angrist’sonlyresort isto assertthathis estimates areforthe total effectofmilitary serviceonwages.But, giventhe inherent interest in untangling how the military service effect interacts with bothschoolingandtheaccumulationofcivilianworkexperience,atotaleffectestimate is insufficiently deep to end all future research, even though this natural experiment was informative and a very important contribution to the literature.\nRosenzweigandWolpin(2000)considermanyotherexamples,allofwhichempha- size the same basic points as these two examples. IV analyses typically provide total causal effect estimates, often in substantive areas in which scholars have an inherent interestintheseparablecausalpathwaysthatgeneratetheoutcomeinresponsetothe cause. Understanding the separable causal pathways that make up these total effects requires an explicit specification of additional intervening and mediating variables, which together compose the full causal mechanism of interest.\nNow consider these two issues more generally, moving away from IV estimates towardmoregeneralestimatesofaveragecausaleffects.Consideranoptimisticscenario for which one obtains what all agree is a consistent estimate of the averagetreatment effect (ATE) for the effect of D on Y (as warranted, for example, by a consensus that one has conditioned on all variables that block all back-door paths from D to Y). Even in this scenario, in which the causal claim is valid by the standards of the counterfactual model, there are two related ways in which such an estimate can be regardedas insufficiently deep.\nFirst, the ATE may not be a parameter of any fundamental interest. This point has been made most forcefully by Heckman (2000, 2005, 2010). If treatment effects are heterogeneous, which often is the case, as we have noted in prior chapters, then whatisoffundamentalinterestareconditionalaveragetreatmenteffectsofsomeform (perhapsevenjustthe averagetreatmenteffectforthe treated(ATT)andthe average treatmenteffectforthecontrols(ATC)).TheoverallATEissimplyaweightedaverage of any such underlying effects. Heckman and many others have noted that the ATE may be of limited use for predicting the outcomes of policy interventions, either for new populations or in different contexts, because the ATE is tied to the current con- figuration of the population and prevailing pattern of causal exposure. Often, social scientists desire explanations for outcomes that can be modified in straightforward wayswhenpopulationsshiftorcontextschangeinwaysthatareseparablefromcondi- tionalaveragecausaleffects(especiallyifthereisreasontobelievethattheconditional averagecasualeffects are morefundamental inthe sense that they canbe expected to remain invariant under any such shifts and changes).\nThe second issue, which is our primary focus in the remainder of this chapter, is that a consistent estimate of the ATE, or any other average causal effect, does not necessarily entail any particular mechanism that explains how D brings about Y. If a theorysuggestswhyandhowD bringsaboutY,thenmerelyprovidingevidenceofthe amountthatY canbeexpectedtochangeinresponsetoaninterventiononDdoesnot then provide any support for the underlying theory. If an assessment of the support for the underlying theory is desired, which is often a primary goal of social science research, then a more narrowly focused analysis of the putative causal pathways that relate D to Y must be undertaken.\nIn the next section, we present Pearl’s approach to this type of analysis. We will make the case that his approach is consistent with decades of prior research in the social sciences and, furthermore, that it provides a particularly clear guide for future researchinthe samemodeofanalysis.Tosetthe stageforPearl’sperspective,wefirst bring this long history of practice to the foreground, presenting the classic literature on the importance of intervening variables in causal explanation.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#the-front-door-criterion-and-identification-of-causal-effects-by-mechanisms",
    "href": "extracted/Counterfactuals and Causal Inference.html#the-front-door-criterion-and-identification-of-causal-effects-by-mechanisms",
    "title": "Counterfaturals and Causal Inference",
    "section": "10.2 The Front-Door Criterion and Identification of Causal Effects by Mechanisms",
    "text": "10.2 The Front-Door Criterion and Identification of Causal Effects by Mechanisms\nFor decades, social scientists have considered the explication of mechanisms through\ntheintroductionofinterveningandmediatingvariablestobeessentialtosoundexplana- tory practice in causal analysis. Duncan and his colleagues wrote in their 1972 book, Socioeconomic Background and Achievement: much of the scientific quest is concerned with the search for intervening variablesthatwillservetointerpretorexplaingrossassociationspresumed toreflectacausalrelationship.(Duncan,Featherman,andDuncan1972:12) The words “interpret” and “explain” are implicit references to the language of social researchthatisusuallyassociatedwithPaulLazarsfeld.Morethantwodecadesearlier, Kendall and Lazarsfeld (1950) distinguished between alternative types of elaboration thatcanbe carriedoutwheninvestigatinganassociationbetweenacausalvariableX and an outcome variable Y.3 Each type of elaboration involves the introduction of a 3The citations in the text are for a retrospective discussion of Samuel Stouffer’s research in The AmericanSoldier (whichwealsodiscussedinChapter1).PatriciaKendallwastheleadauthorforthe 1950piecewecite,andyetsheisalmostnevercreditedinthederivativeliteratureasacontributorto thislanguage.BecauseitisoftenwrittenthatLazarsfeldpresentedanddiscussedthisbasictypology inmanyplaces,itispossiblethatitisfairtocredithimdisproportionatelyfortheseideas.Ourreading of the literature, however, does not yield a clear interpretation. It does suggest to us that Kendall hasreceivedlesscreditthanshedeserved.Indeed,intheversionoftheseideaspublishedinHyman’s widelyreadtextSurveyDesignandAnalysis,Hyman(1955:275)notesonlyinafootnote,“Themajor testfactor(ortestvariable)T,afterwhichtheassociationbetweenthecausalvariable X and the outcome variable Y is calculated for each value of T.\nKendall and Lazarsfeld considered two types of M-elaboration, which arise when the partial association between X and Y within strata defined by T is smaller than theoriginaltotalassociationbetweenX andY.4 AssumingthatbothXandT precede Y in time, the twotypes ofM-elaborationaredeterminedby whether T alsoprecedes X in time: 1. If T follows X in time, then an M-type elaboration can be represented by a chain of mediation, X→T →Y (Kendall and Lazarsfeld 1950:157). They refer tothistypeofelaborationasaninterpretation oftheassociationbetweenX and Y, using a test factor that is an “intervening” variable.\n\nIfT precedesX intime,thenanM-typeelaborationcanberepresentedbyafork of mutual dependence, X ←T →Y (Kendall and Lazarsfeld 1950:157). They refer to this type of elaborationas an explanation of the association between X and Y, using a test factor that is an “antecedent” variable.\n\nAlthough Kendall and Lazarsfeld did not argue that causality can be established by what they call “interpretation,” and although they use the word “explanation” in a rather limited sense (and with a different usage than Duncan and colleagues, as just quoted), Kendall and Lazarsfeld were clearly interested in mechanistic accounts that reveal how causes bring about their effects. For example, they wrote: When we interpreta resultwe tryto determine the processthroughwhich the assumed cause is related to what we take to be its effect. How did the result come about? What are the “links” between the two variables? Answerstothesequestionsareprovidedinthe interpretationofthe result.\n(Kendall and Lazarsfeld 1950:148) Alongtraditionofempiricalsocialscienceexiststhatfollowsthesebasicideas,inwhich a central goal of investigation is the search for variables – intervening, mediating, or processualvariables – thatcanaccountfor anassociationthatis thoughtto be causal (see MacKinnon 2008; Winship and Harding 2008). Even so, as we noted in Chapter 6, applications of the all-cause regression specification approach gradually obscured this goal, leading from the 1970s through the 1990s to more frequent attempts to offer single-equation models in which all effects of all observed putative causes of an outcome are estimated simultaneously.\nFortunately, Pearl (2009)has developed an “inside-out” perspective on the identi- fyingpowerofmechanismsthatcanhelpthesocialsciencesrecapturetheinclinationto pursuemechanisticexplanationofcausaleffectsinempiricalresearch.Pearl’sapproach sections of this chapter have been written by Patricia Kendall and represent an enlargement of an earlieranalyticschema.” 4Theyalsolayoutathirdformofelaboration,referredtoasP-typeelaboration(orspecification).\nHere, the goal is to focus “on the relative size of the partial relationship [between X and Y within strataofthetest factor T]inordertospecifythe circumstances under whichtheoriginalrelationis moreorlesspronounced”(KendallandLazarsfeld1950:157).Thistypeofelaborationisappropriate whenthetestfactorisrelatedtoeitherX orY butnotboth.Weignorethisformofelaborationhere, aswefocusonvariablesthatarerelatedtoboththecausalandoutcomevariables.\nU M D Y N Figure10.3 AdirectedgraphinwhichM andN representanexhaustiveandisolated identifying mechanism for the causal effect of D on Y.\ngoeswellbeyondLazarsfeldianelaboration.Instead,heshowshowonecanconsistently estimatetheeffectofacausalvariableonanoutcomevariablebyestimatingtheeffect asitpropagatesthroughanexhaustiveandisolatedmechanism.Helabelsthisstrategy the “front-door” identification of a causal effect (see Pearl 2009:81–85).\nConsiderFigure10.3,whereanunblockableback-doorpathD←U→Y existsfrom D andY becausethevariableU isunobserved.Asaresult,identificationusingPearl’s back-doorcriterion,aspresentedinChapter4,is infeasible.Nonetheless,the variables M and N intercept the full causal effect of D on Y, and for Pearl these two variables representan identifying mechanism for the effect of D on Y. (Again, recall that there is no assumption of linearity in a directed graph of this type, and thus this model is consistentwithanynonlinearstructuralequationsforthegenerationofD,M,N,and Y.) For this graph, observation of M and N identifies the causal effect of D on Y by a two-part consideration of the back-door criterion: 1. For D→M and D→ N, two back-doorpaths exist: D←U→Y ←M and D← U →Y ←N, respectively.5 Because Y is a collider variable along both of these back-door paths, each path is blocked by Y in the absence of any conditioning.\nAccordingly,theseback-doorpathsdonotcontributetotheobservedassociations between D and either M or N. And, as a result, the causal effects D →M and D→N canbeestimatedconsistentlybytheirsimpleunconditionalassociations.\n\nFor M →Y and N → Y, two back-door paths exist for each causal effect. For M →Y, they are M ←D←U →Y and M ←D→N →Y. For N →Y, they are N ←D←U →Y and N ←D→M →Y. All four of these back-door paths generate noncausal associations between M and Y and also between N and Y 5Both D←U→Y ←M and D←U→Y ←N satisfy the definition of a back-door path, even though they do not end with →M and →N, respectively. They are both paths between pairs of causallyorderedvariables(D andM,ontheonehand, andD andN,ontheother), andtheyboth beginwithanarrowpointingtothe firstvariable(i.e.,D←).Assuch, they areback-door paths for D→M and D→N, respectively, even though they do not resemble most of the other examples of back-door paths presented in this book. We have focused our earlier examples on back-door paths thatmustbeblockedbyconditioning.However,seeourdiscussionofFigure4.12intheappendixto Chapter 4,wherewediscussasimilarback-doorpath.\n\nbecause none of these paths includes collider variables that block them in the absence of any conditioning. Fortunately, all four of these back-door paths can be blocked by conditioning on D. And, as a result, the casual effects M →Y and N → Y can be estimated consistently after conditioning on the observed variable D.\nIn short, for this graph the unblocked back-door path D←U →Y does not prevent consistent estimation of the effect of D on Y as long as both M and N are observed.\nBecauseone canobtainconsistent estimates of the casualeffects ofD on both M and N and, in turn, of both M and N on Y, one can calculate the full causal effect of D on Y by combining these causal effect estimates. Pearl (2009:83) gives the general estimation formula in the underlying probability distributions. For the ATE, the sim- plest case that is also consistent with the structure of Figure 10.3 is one where (1) D is a binary variable, (2) M, N, and Y are interval-scaled variables, (3) all structural equationsarelinearandadditive,e.g.,Y =fY(M,N,eY)=aY +bMM+bNN+eY,and (4) all individual-level causal effects do not vary in the levels of the variables in the mechanism.Inthis case,theATEcanbeestimatedconsistentlybyasumofproducts, (cid:16) (cid:17) (cid:16) (cid:17) ˆbD→M×ˆbM→Y + ˆbD→N×ˆbN→Y , where ˆbD→M is the estimated coefficient for M in a bivariate regression of Y on M, ˆbD→N istheestimatedcoefficientforN inabivariateregressionofY onN,andˆbM→Y and ˆbN→Y are the estimated coefficients for M and N for a multiple regression of Y on M, N, and D.6 Asshownbythisexample,thefront-dooridentificationstrategycanbeverysimple, asit involvesnothing morethana straightforwardtwo-stepconsiderationofthe back- door criterion introduced in Chapter 4 (see our presentation beginning on page 109).\nPearlformalizesthis identificationstrategyby offeringa complementto his back-door criterion, which he labels the front-door criterion (Pearl 2009:82): Front-Door Criterion If one or more unblocked back-door paths connect a causal variable to an outcome variable, the causal effect is identified by conditioning on a set of observed variables, {M}, that make up an identifying mechanism if Condition1(exhaustiveness).Thevariablesintheset{M}inter- cept all directed paths from the causal variable to the outcome variable; and 6Inthiscase,Pearl’sfront-dooradjustmentformulareducestothissumofproductsforthecausal contrast he would label E(Y|do(D=1)−E(Y|do(D=0). When conditions (1) through (3) do not obtain, the computation is more complex because one needs to propagate the effects through the probability distributions of the mechanistic variables, conditional on the causal variable, and then calculate average effects for the chosen contrast (see Pearl 2009). We omit these details because we arefocusinginthischapter ontheessential identificationissues.\nCondition 2 (isolation). No unblocked back-door paths connect the causalvariabletothe variablesinthe set{M},andallback- door paths from the variables in the set {M} to the outcome variable can be blocked by conditioning on the causal variable.7 Noticethatthefront-doorcriteriondoesnotgivedirectguidanceonhowdeepaniden- tifyingmechanismmustbeinordertoqualifyasasufficientlydeepcausalexplanation.\nIt only specifies the features that a mechanismmust have in order to be used to iden- tifyanaverageeffectofacausalvariableonanoutcomevariable.Anysuchidentifying mechanism can be considered shallow by the standards of a particular researchgroup or field of interest. Before addressing this issue, we clarify in the remainder of this section what the requirements of exhaustiveness and isolation entail.\nThe Assumptions That the Mechanism Is Exhaustive and Isolated Thecrucialassumptionsofthisapproach,aswehavenotedalready,arethatthe iden- tifying mechanism is exhaustive and isolated. To see the importance of isolation first, consider the alternative graph presented in Figure 10.4. Here, the variable U is again unobserved,andthustheback-doorpathD←U→Y cannotbeblockedbycondition- ing on any observedvariablesin the graph.In this case,the variableM intercepts the full causal effect of D on Y, and therefore the identifying mechanism is exhaustive, satisfying Condition 1 of Pearl’s front-door criterion. However, the identifying mech- anism M is not isolated because U has a direct causal effect on M. Corresponding to both components of Condition 2 of the front-door criterion, two problems arise.\nThe causal effect U →M generates a new back-door path from M to Y, which is M←U→Y, as well as a new back-door path from D and M, which is D←U→M.\nNeither of the effects that compose the casual pathwayD→M→Y canbe estimated consistently because no observed variables are available to block these new back-door paths by conditioning. With reference to the structure of Pearl’s front-door criterion, the problems are that (1) an unblocked back-door path connects the causal variable to M (D←U →M) and (2) a back-door path from M to Y cannot be blocked by conditioning on D (M←U→Y).\nThis example also shows what is crucial in the criterion of isolation. The mech- anistic variables must be isolated from otherwise unblocked back-door paths so that the back-door criterion can be applied in order to recover the full causal effect from the data. For Figure 10.4, if U were an observed variable, then the back-door paths D←U→M and M←U→Y could be blockedby conditioning on U. In this case, we could then use the front-door criterion in a conditional variant, estimating the effect of D on Y by estimating the effects D→M and then M →Y while conditioning on U.\nMore generally, isolation comes in strong and weak forms, both of which are suffi- cient. For the strong form, none of the variables that lie on back-door paths from D 7In our accounting of Pearl’s front-door criterion, we label his (i) as our Condition 1, which we thencharacterizeasanexhaustivenesscondition.Wealsocombinehis(ii)and(iii)intoourCondition 2,whichwecharacterizeasisolation.\nU M Y D Figure10.4 AdirectedgraphinwhichM isnotanisolatedmechanismforthecausal effect of D on Y.\nto Y can have causal effects on the mechanistic variables, except indirectly through directed paths that pass through D. For Figure 10.3, the only directed paths from U that terminate at M and N pass through D. In this case, conditioning on D alone is sufficient.Fortheweakform,someofthevariablesthatliealongback-doorpathsfrom D to Y can have causal effects on the mechanistic variables through directed paths that do not pass through D, but it must still be possible to block any relevant back- doorpathsby conditioningonD and otherobservedvariablesinthe graph.Theweak formofisolationmakesitclearthatonemustbeconcernedonlyaboutthedependence of the variables in the mechanism on components of back-door paths between D and Y that cannot be blocked by conditioning on observed variables.\nAn implication of the necessity of assuming isolation is that a very good under- standingofthe back-doorpathsbetweenthe causalvariableandthe outcomevariable is needed. If the isolation assumption cannot be maintained, then the mechanistic variables are similarly affected by the same set of dependencies that invalidate basic back-door conditioning as a strategy to identify the causal effect.\nNow return to Condition 1 of the front-door criterion, which requires that the identifying mechanism is exhaustive. For Figure 10.5(a), suppose, again, that there is an unblocked back-door path and also two distinct causal pathways from D to Y, which are represented by the two variables M and N. Finally, unlike for Figure 10.3, suppose that N is unobserved.\nIn this case, the causal effects D→N and N→Y cannot be estimated, and thus the full causaleffectofD onY cannotbe estimatedby front-doorconditioning.Ifone were to asserta mistaken assumption that M is an identifying causal mechanism (for example,bysubstitutingaback-doorpathD←N→Y forthegenuinecausalpathway D→N →Y), then one can obtain a causal effect estimate. But the causal effect of D on Y will then be underestimated (assuming all causal effects are linear, positive, etc.) because the part of the causal effect generated by the pathway D→N →Y is attributed to a mistakenly asserted back-door path D←N→Y.\nRelaxing the Assumption That the Mechanism Is Exhaustive FortheexampledepictedinFigure10.5(a),amechanism-basedempiricalanalysismay stillbeusefulbecauseanisolatedpieceofthecausaleffectcanstillbeestimated.Even though N is unobserved, the causal effect of D on M is identified by their observed U U M M D Y D Y N N (a) The causal pathway via M is (b) The causal pathway via M is identified even though N is not identified unobserved Figure10.5 Directed graphs in which one pathway in an exhaustive and isolated mechanism is unobserved.\nassociation because the back-door path from D to M, which is D←U →Y ←M, is blockedbythecolliderY intheabsenceofanyconditioning.And,asbefore,thecausal effect of M on Y is identified because both back-door paths from M to Y, which are M←D←U→Y andM←D→N→Y,canbeblockedbyconditioningonD.Onecan therebyobtainaconsistentestimateofthe causaleffectofM onY byconditioningon D,whichguaranteesthatthepartofthecausaleffectthattravelsthroughthepathway D→M→Y can be estimated consistently. This is an important result, especially for practice,becauseidentifyingandconsistentlyestimatingadistinctcausalpathwaycan be very useful, even if one cannot in the end offer a causal effect estimate of the full effect of the causal variable on the outcome variable.8 KnightandWinship (2013:290–91)consider anexample with the structure of Fig- ure 10.5(a) and where the populationof interest is womenin the paidlabor force. For their example, D is whether or not women have children, M is the number of hours per week worked in a paid job, N is the amount of bias in compensation practices againstwomen with children, and Y is wagespaid to women. Evenif one cannot esti- mate the effect of bias against women with children on wages received, being able to estimatethewagedifferencesthatareattributabletothereductionofworkhoursthat oftenresultsfromhavingchildrenmaybeimportanttoestablishthecaseforproviding better childcare to support working women.\n8Note, further, that one can then assess the portion of the total variation in D and Y that can beattributedtothepathwaythroughM.Thiscalculationcanbeuseful,butitdoesnotidentifythe amountofthecausaleffectthatisexplainedbyM.TheproblemisthattheassociationbetweenDand Y that is notattributable toM cannot beapportioned acrossthe two unblocked paths D←U→Y and D→N→Y. In addition, if the underlying structural equations are nonlinear, then additional complicationsarisebecauseofthepossibilityofinherentinteractionsbetweenthecausalvariableand mechanisticidentifyingvariablesintheproductionoftheoutcomevariables.Forfullexplanations of these complications, see Pearl (2012a, 2012b), VanderWeele (2009b, 2012, in press), and Wang and Sobel(2013).Wealsodiscussthesecomplicationsintheappendixtochapter11,whereweintroduce aframeworkfordefiningandestimatingnetdirecteffects.\nBut,eventhoughthispartialestimationresultisveryuseful,thereisanimportant implicitassumptionthatishiddenbythisexample:Variablesontheunobservedcausal pathways cannot have direct or indirect causal effects on any of the variables that lie along the observed causal pathways. To see the complications that such dependence could produce, consider the graph in Figure 10.5(b). For this graph, the mechanism is isolated, but the unobserved variable N has a causal effect on M. In this situation, the effect of M on Y is not identified. Three back-door paths between M and Y are still blocked by D: M←D←U→Y, M←D→N→Y, and M←N ←D←U →Y.\nHowever, a fourth back-door path, M ←N →Y, cannot be blocked by conditioning on D or any other observed variable. This path remains unblocked because its only intermediatevariableN isunobservedandisnotacollider.Notonlyisitimpossibleto estimatetheeffectofDontheunobservedvariableN,butthevariableN maytransmit tobothM andY itsownexogenousvariationthatiscompletelyunrelatedtoDandU.\nWithout recognition of this outside source of dependence, one could mistakenly infer that the causal pathway D→M→Y is much more powerful than it is (assuming all causaleffectsarelinear,positive,etc.).KnightandWinship(2013:293)elaboratetheir example,summarizedabove,toshowthisresultaswell.TheyallowunobservedbiasN to affect work hours M. In this case, the analystcan no longer advocate for increased childcare support by building support for the causal pathway D→M →Y because the reductions in wages may all result from the direct effect of bias on wages and the indirect effect of bias on wages through work hours (which could result either from differential work assignments from biased supervisors or the protective withdrawalon the part of working women who confront a hostile workplace).\nAs these simple graphs show, if one wants to use a mechanism-based strategy to identify the full effect of a causal variable on an outcome variable, one must put forwardanidentifying mechanismthat is exhaustiveandisolated.The exhaustiveness requirement can be relaxed if one is satisfied with identifying only part of the causal effect of interest. But, to secure partial estimation of this form, one must be willing to assume that the observed portion of the mechanism is not affected by any of the variablesinthe unobservedportionofthe mechanism.And,toassertthisassumption, onetypicallyneedstohaveaveryspecifictheoreticalmodelofthecompleteidentifying mechanism, even though parts of it remain unobserved.\nIn sum, Pearl’s front-door criterion represents a powerful and original set of ideas that clarifies the extent to which a mechanism, composed of one or more intervening variables, can be used to identify and estimate a causal effect. And, by approaching the causalinference predicamentfromthe inside out, the approachhelps to shape the question of whether a causal claim qualifies as a sufficiently deep explanation. Rather thanestimatingacausaleffectbyback-doorconditioningorwithanaturallyoccurring experimentand then wonderingwhether a mechanismcanbe elaboratedto show how the effect comesabout, Pearlinsteadshowsthat, if we canagreeonthe variablesthat constitute an exhaustive and isolated mechanism, then we can estimate the causal effect from its component causal pathways.\nThe approach cannot be taken out of context, though, lest one claim too much explanatory power for a nonexhaustive and/or nonisolated mechanism. And, at the same time, it must be acknowledged that even a front-door-identified causal effect may not be explained deeply enough by the exhaustive and isolated mechanism that identifies it, for any such mechanism may still be too shallow for a particular sub- stantive area. To consider these issues further, we now turn to recent social scientific writing on mechanisms, wherein the connections among theory construction, genera- tive mechanisms, and modes of explanation have been carefully examined.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#the-appeal-for-generative-mechanisms",
    "href": "extracted/Counterfactuals and Causal Inference.html#the-appeal-for-generative-mechanisms",
    "title": "Counterfaturals and Causal Inference",
    "section": "10.3 The Appeal for Generative Mechanisms",
    "text": "10.3 The Appeal for Generative Mechanisms\nTo some extentinspiredby the workofJonElster(e.g., Elster1989),butmore gener-\nally by their readingof pastsuccessesand failures in explanatoryinquiry inthe social sciences since the 1940s, Peter Hedstr¨om and Richard Swedberg convened a group of leading scholars to discuss a reorientation of explanatory practices in the social sci- ences. A collection of papers was then published in 1998 as Social Mechanisms: An Analytical Approach to Social Theory. At the same time, John Goldthorpe developed his case for grounding all causal modeling in the social sciences on the elaboration of generative mechanisms. His proposal was published in 2001 as “Causation, Statistics, andSociology,”whichthenreceivedcommentsfromavarietyofscholars,includingthe statisticiansDavidCoxandNannyWermuth(whoseresponsewewilldiscussbelow).9 Subsequently, Peter Hedstr¨om laid out in considerable detail his full program for a mechanism-basedsocialscienceinhis2005book,Dissectingthe Social: On the Princi- ples of Analytical Sociology. Along withPeterBearman,Hedstr¨omthen compiledThe Oxford Handbook on Analytical Sociology, which is a collective effort to demonstrate the power of this approach (Hedstr¨om and Bearman 2009). To orient the reader to thispushformechanism-basedsocialscience,wewillfirstpresenttheslightlydifferent proposals of Goldthorpe (2001) and then Hedstr¨om (2005).10 9Goldthorpe’s argument wasrepublishedasachapter inboth thefirstandsecond editions ofhis programmaticcollection,OnSociology (e.g.,Goldthorpe2007,vol1.,ch.9).Ourcitationsaretothe original2001journalarticle.\n10Wewillnottracethefullhistoryofmechanistictheorizinginthesocialsciences,asthepiecesjust cited cover much of the same territory (see also Hedstro¨m and Ylikoski 2010; Knight and Winship 2013). However, it does seem to us that the novelty of recent mechanism-based theorizing has been oversold at least a bit. At the same time that Kendall and Lazarsfeld were directing researchers to buildmechanisticinterpretations ofcausal effects inempiricalresearch,whileholdingupStouffer as a successful practitioner, mechanism-based modes of conjecturing were widespreadamong theorists.\nHedstro¨mandUdehn(2009)lionizeRobertMerton’sproposalforthepursuitofmiddle-rangetheory, whichtheyargueisimplicitlymechanism-based.Likemanyothers,theycontrastMerton’sworkwith the“grand”system-leveltheoreticalprogramofTalcottParsons.ButevenParsonswrotefrequentlyof mechanisms,includingthoseforsocialization,socialcontrol,andtheequilibrationofthesocialsystem (see Parsons 1951, chapters 6 and 7). As an example, Parsons (1951:206) wrote, “A mechanism of social control, then, is a motivational process in one or more individual actors which tends to counteractatendencytodeviancefromthefulfillmentofrole-expectations,inhimselforinoneormore alters. It is a re-equilibrating mechanism.” Explaining his usage of the term “mechanism,” Parsons (1951:22) wrote,“Motivational dynamicsinsociologicaltheory, then,musttaketheforminthefirst instance of the formulationof mechanisms which ‘account for’ the functioning of social systems, for the maintenance or breakdown of given structural patterns, for a typical process of transition from one structural pattern to another. Such a mechanism is always an empirical generalization about the operation of motivational ‘forces’ under the conditions stated.” It is clear from this work that Parsons saw mechanistic theorizing as a way to develop the sort of conjectures that Craver (2007) wouldregardas“how-possible”or“how-plausible”modelsandthatHedstro¨mandBearman(2009:7) label “semigeneral mechanisms.” It is also clear that Parsons’ mechanisms came to be regarded as insufficientlydeepbysubsequentsociologists.Indeed,agreatdealoftheempiricalworkthathasbeen Goldthorpedevelopshisproposalbyfirstattemptingtodriveawedgebetweenthe counterfactualmodel,whichhelabels “causationasconsequentialmanipulation,”and his alternative mechanistic model of causality. To develop his argument, he advances the claim that the counterfactual model is irretrievably tied to actual experimental manipulationsofcausalvariables.Goldthorpe(2001:6)writes,“thecruxofthematter is of course the insistence of Rubin, Holland, and others that causes must be manipu- lable, and their unwillingness to allow causal significance to be accorded to variables that are not manipulable, at least in principle.”11 (See our discussion of this issue in Chapter 13, in which we present the positions of Woodward (2003) and others that this argument is incorrect.) Goldthorpe also argues, citing the work of statisticians Cox and Wermuth (1996; also Cox 1992), that the counterfactual model too easily settles for causalclaims ofinsufficient depth thatdo notaccountfor how causes bring abouttheireffects(apointthatisclearlysupportedbyourpresentationofthenatural experiment literature discussed earlier in this chapter).\nWith this criticism of the counterfactual model in mind, Goldthorpe writes: The approach to causal analysis that is here proposed … is presented in the form of a three phase sequence: (i) establishing the phenomena that formtheexplananda; (ii)hypothesizinggenerativeprocessesatthe levelof social action; and (iii) testing the hypotheses. (Goldthorpe 2001:10) Goldthorpe then proceeds to lay out the basic contours of the first two steps, arguing thatthemostusefulmechanismsinthesocialsciencesarethosethatarebasedonratio- nal choice theory (because these are sufficiently microscopic and focus on the actions and beliefs of individuals). He then explicates the third step of his approach,which is hisrequirementthatonemusttesthypothesessuggestedbythegenerativemechanism that one has proposed.12 And here, he takes the position that generative processes of the sort that he prefers, which are “specified at a ‘deeper,’ or ‘more microscopic’ level, thanthat of the data that constitute the explananda” (15), canalmostnever be directly evaluated. Instead, Goldthorpe advises that analysts spend their effort deter- mining whether the hypothesized generative mechanisms can be indirectly supported throughrepeatedvalidationofentailedhypotheses.Theseentailedhypothesesmaybe atthe levelofthe “microscopic”mechanism,aswouldbethe caseforconjecturedpat- ternsamongcorrelatesoftheunobservedtruepreferencesandmicro-interactionsthat, publishedsincethe1950scanbeinterpretedasattemptstodeepenthemechanisticclaimsthatwere overlyabundant intheworkofParsons,Merton,andotherscholarsoftheirera.\n11It is unclear from this passage what Goldthorpe means by “inprinciple.”However, on the next page of the article, he offers an example that reveals that his conception of a manipulation can be very narrow. Following an example of Holland (1986), he introduces mechanistic variables and arguesthatinsodoinghehasproducedacausalnarrativethathasnothingtodowithhypothetical manipulations/interventions and hence cannot be represented in a counterfactual framework. The argumentseems to bethat themechanistic variables arenonmanipulable because they aretypically voluntarydecisionsofanindividual.\n12Byourreading,Goldthorpe endsupbackatthecounterfactual modelatthispoint. Hisdefense againstsuchareadingisthis:“whileitmightseemthat,atthisstage,attentiondoesafterallcometo focusontheeffectsof–given–causesratherthanonthecausesofeffects,thisiswithinthecontext notofrandomizedexperimentaldesignbutof(whatshouldbe)atheoreticallyinformedaccountofa generativeprocessthatissubjecttoongoingevaluation.”(Goldthorpe2001:13) accordingtothehypothesizedgenerativemechanism,determinetheactionthatgener- ates the outcome. More realistically, these entailed hypotheses would be at the higher level where data are available on the outcome of interest, as would be the case when analyzing conjectured patterns of the outcome itself at the population level(based on further assumptions about how the generative mechanism produces a distribution of outcomesacrosssubgroupsthatcanbeidentifiedbytheirmeasuredcharacteristics).13 Considernowthemoreextendedappealformechanism-basedsocialscienceoffered by Peter Hedstr¨om (2005). Unlike Goldthorpe, Hedstr¨om does not confront the coun- terfactual causalityliterature directly. He instead develops an argumentthat suggests the following orienting principle: “The core idea behind the mechanism approach is that we explain not by evoking universal laws, or by identifying statistically relevant factors, but by specifying mechanisms that show how phenomena are brought about” (Hedstro¨m 2005:24). Hedstr¨om arrives at this position from two different directions.\nFirst, he signs on to the dominant position in the philosophy of science that the best explanation of how a phenomenon is brought about must necessarily be a causal accountofsomeformthatdoesnotrelyonunrealisticpresuppositionsoftheexistence of invariant general (or covering) laws (see Hedstr¨om 2005:15–20). But he also jus- tifies the principle by criticizing regression-based causal models in social science (see Hedstr¨om 2005:20–23): Suchstatisticalanalysisisoftendescribedasaformof“causalanalysis.”If a factor appears to be systematically related to the expected value or the conditional probability of the outcome, then the factor is often referred to as a (probabilistic) “cause” of the outcome. Although it makes little sense to quibble over words, I would like to reserve the word cause for a less casual notion of causality. (Hedstr¨om 2005:23) Like Goldthorpe, Hedstro¨m also lays out a script for the construction of mecha- nisms, which is similar in its appeal to the principles of methodological individualism (although he steps back from Goldthorpe’s stronger preference for forms of rational choice theory). Most importantly, Hedstro¨m does not advocate the testing of mecha- nisms in the way that Goldthorpe does. Instead, he defends the explanatory utility of mechanisms in a much more general way: Mechanismsshouldbeseenastheoreticalpropositionsaboutcausaltenden- cies,not as statements about actualities. An explanationmay be perfectly 13Blossfeld (2009) aims to build on Goldthorpe’s orienting program and argues for the centrality of event history processes in generating relationships that can be interpreted as causal. Blossfeld (2009:101) writes, “We can only hope to make sensible causal statements about how a given or (hypothesized) change in variable Y tA (e.g., pregnancy/birth) in the past affects the probability of a change in variable Y tB (cid:2) (e.g., marriage) in the future. Correspondingly, the basic causal relation becomes:ΔY tA→ΔPr(Y tB (cid:2)),(t&lt;t(cid:3)).Inotherwords,achangeinthetime-dependentcovariateY tAwill changetheprobabilitythatthedependentvariableY tB willchangeinthefuture(t&lt;t(cid:3)).”IfBlossfeld’s (cid:2) “given or (hypothesized)” distinction can be interpreted as consistent with potential outcomes tied to the states A and not-A, then this is simply a restatement of the potential outcome definition of acausal effect. Ifnot, andthisdefinition ismeanttodispensewithcounterfactual dependence, then the only “causal relations” that are well defined for Blossfeld are those between values of observed variablesthatchangeintimeduringtheobservationwindow.Ifitisthelatter,thenthisisjustthesort ofrobustdependencerelationshiprejectedbyGoldthorpe(andBlossfeld),althoughnowexpressedas arobust-dependence-in-timeperspective.\ncorrect if understood as a proposition about a causal tendency, and yet it may be inadequate for predicting actual outcomes if other processes are alsoatwork….Sinceitistheruleratherthantheexceptionthatconcretely observed phenomena are influenced by several different processes, testing a theory by examining the accuracy of its predictions is likely to conflate thetruthorrelevanceofthepostulatedmechanismwiththeimportanceof other processes,andthis may leadus to mistakenly rejectperfectly appro- priate causal accounts. (Hedstr¨om 2005:108) What,then,istheexplanatorystatusofmechanismsthatare“theoreticalpropositions about causal tendencies”? Here, Hedstro¨m seems to argue three basic points: (1) The best explanations are causal accounts; (2) causal accounts must include mechanisms; (3) mechanisms may or may not explain actualities. The direct implication of this position is that the best explanations in social science do not necessarily have to explain actualities, but they must explain causal tendencies.14 In our view, Goldthorpe and Hedstr¨om have developed a wonderful appeal for the need to construct sufficiently deep theories of social processes. Their work is filled with much insight on a variety of promising ways to formulate plausible theoretical mechanisms. And they have helped to further convince many social scientists that specifying the socialprocesses that accountfor how causes bring about their effects is acentralgoalofanalysis.Itisthereforeunsurprisingthatthisnewwaveofscholarship has inspired a scholarlymovementof sorts, which we and many others regardas both promising and very healthy for theory construction in the social sciences.15 But, to be seen as blueprints for explanatory causal analysis, both of these par- ticular perspectives need to be augmented. And we would argue that they can be usefully extended by embracing the counterfactualmodel of causality more directly.16 We explain this position in the remainder of this section, first by offering a slightly 14Itisunclearfromtheforegoingpassagewhattheproblematic“otherprocesses”aremeanttobe.\nClearly,theymustcomeintwodifferentforms:(1)othermechanismsthatarecompletelyindependent of the postulated mechanism of primary interest and (2) other mechanisms that interact with the postulated mechanism of primary interest. If one is estimating the effects of a cause, it is only the latter that areproblematicforthe evaluation of mechanisms,and hence forthe evaluation ofcausal accounts based on mechanisms. See our earlier discussion of partial identification by the front-door criterion.\n15Butwearesomewhatmoretraditionalinfavoringmechanismsthatareformalmodels,asweare lessconvincedoftheutilityofmanysimulation-basedmethodsoftheoryconstruction;seeHedstr¨om (2005:76–87, 131–36, 149) on the appeal of such techniques. We agree with Humphreys’ (2004:132) caution: “Agent-based modelsareapowerfuladditiontothearmoryofsocialscientists, butaswith any black-box computational procedures, the illusion of understanding is all too easy to generate.” Scholars suchas Manzo (2011) disagree sharplywith this position, andwe welcomeefforts that will convinceustochangeourposition.\n16Inmorerecentwork, Hedstro¨m andUdehn (2009:42) writethat the mechanism-based approach to social science “should not necessarily be seen as an alternative to the counterfactual approach, but rather as adding further requirements. As emphasized by Woodward (2002) and Morgan and Winship (2007) there is nothing in the counterfactual approach as such which guarantees sufficient causal depth, because perceptions of sufficient depth are discipline-specific while the counterfactual approachisnot.”Weassumethatthereferencehereistotheargumentthatweofferedinthischapter inthefirsteditionofthisbook.\ndifferentreadingofrecentdevelopmentsin the philosophyof scienceandthen by rais- ing the issue of how social scientists can retain the capacity to adjudicate between competing mechanistic accounts of causal effects.\nPhilosophy of Science and Explanation by Mechanisms Aswenotedatthebeginningofthischapter,theappealtomechanismsaselaborations of causal claims has been entrenched in the sociological literature for many decades, and we suspect that this emphasis is true of all of the social sciences. Where perhaps thefocusongenerativemechanismsisnewisintheproposedelevationoftheirstatusto theobjectofprimaryinvestigation.Thiselevationisnotunrelatedtoshiftingcurrents in the philosophy of science.\nSomeproponentsofamechanism-basedsocialsciencehavedrawninspirationfrom the demise of covering law models of explanation in the philosophy of science (e.g., Gorski 2004; Hedstr¨om 2005). The covering law model, as most famously explicated by Carl Hempel, maintains that all valid explanations can be formulated as logico- deductive entailment from invariant general laws.17 Since 1970 at least, the covering law model has received near-continuous challenges to its basic premises (see Godfrey- Smith 2003; Salmon 1989; and Woodward 2003). The presupposition that general and exceptionless laws exist and that they can be used to warrant all valid causal claimscannotbesustainedinmostscientificdisciplines,andcertainlynotinthesocial sciences.\nIn response, a variety of alternative models of scientific explanation have arisen, with realist models attracting the largest number of adherents (see Psillos 1999). In general, realist models grant ontological status to unobserved quantities (sometimes conferringprovisionaltruthstatusonthem).Mostrealistmodelsrejectcausalnihilism and affirm that valid scientific explanation must necessarily be grounded in causal accounts of some form. Especially when invoked for the social sciences, realist models admitthe possibilityofinherentheterogeneityofcausalrelationships–intime, space, and within populations. But the depth of the appeal to unobservables varies across types of realist models, as does the level of provisional truth status conferred upon unobservables.\nWhat we wish to emphasize in this section is how uneasily the focus ongenerative mechanisms sits within this new terrain, especially when seen as a call for the con- struction of mechanisms that explain only causal tendencies rather than observable actualities.Aswehavejustnoted,theappealformechanisticexplanationinthesocial sciences is attractive partly because it is claimed that it does not rest on the exis- tence of general laws. But some philosophers who endorse the mechanisms position disagree with this claim, arguing that laws are still essential, perhaps even consti- tuting the defining characteristic of what a mechanism is. For example, after having written on the role of mechanisms in scientific explanation for several decades, Mario 17Wedonotattempttogiveafullsummaryofthefallofcoveringlawmodels,asmanyaccessible textsexistinphilosophy(seecitationsinthemaintext)andothersthatarewrittenforsocialscientists alone(e.g.,Gorski2004;Hedstro¨m2005).Nordowegiveafullexplicationofthevarietyofpositions thathavereplacedthecoveringlawmodel,asthesetooarewellsummarizedelsewhere(seecitations in the main text for realist models in particular, as well as the variety of naturalist positions that contend withthem).\nBunge (2004:207)concluded, “No law, no possible mechanism; and no mechanism, no explanation.”18 Hedstr¨om (2005) considers this complication carefully, and he emphasizes that his mechanism-based approach to explanation is less reliant on invariant laws than the covering law models that he rejects. This position is certainly correct, but one must still consider how to grapple with what seem to be three fairly common declarative statements on the relationships between laws and mechanisms: (1) invariant covering laws do not exist, (2) mechanisms depend to some degree on the existence of laws that are weaker than general, invariant laws, (3) mechanisms are nested within each other. Accepting all three statements seems to delimit laws to the smallest possible configuration within each level of a set of nested mechanisms.\nIfamechanismisdesignedtoexplainhowanactualitycomesabout,thenallseems to be fine with this perspective.19 But if one instead maintains, as does Hedstro¨m (2005), that mechanisms are the key to the explanation of causal tendencies only – suchthatthevalidityofamechanismcannotbeunderminedbyitsinabilitytoexplain anything in particular – then this line of thought leads all too easily to the critical realist perspective on mechanisms. We suspect that most empirical social scientists wouldfind critical realismuninspiring. Critical realism’spioneer, Roy Bhaskar,writes with regardto mechanisms: Theworldconsistsofmechanismsnotevents.Suchmechanismscombineto generate the flux of phenomena that constitute the actual states and hap- penings of the world. They may be saidto be real, though it is rarelythat they are actually manifest and rarer still that they are empirically identi- fied by men. They are the intransitive objects of scientific theory. They are quite independent of men – as thinkers, causal agents and perceivers.\nThey are not unknowable though knowledge of them depends upon a rare blending of intellectual, practico-technical and perceptual skills. They are notartificialconstructs.But neither arethey Platonicforms.Forthey can become manifest to men in experience. Thus we are not imprisoned in caves,eitherofourownorofnature’smaking.Wearenotdoomedtoigno- rance. But neither are we spontaneously free. This is the arduous task of science:theproductionoftheknowledgeofthoseenduringandcontinually active mechanisms of nature that produce the phenomena of the world.\n(Bhaskar 1998[1997]:34–35) If the social sciences sign on to the idea that mechanisms are general and transcen- dentally valid explanations that may not explain any actualities or particularities, we will be led inevitably to a fundamental premise of critical realism: The mechanisms that constitute causal explanations are irreducible, even if they are nested in each 18Given Bunge’s position, one then necessarily wonders, How does one discover these crucial explanatory mechanisms? Bunge’s (2004:200) guidance is this: “Thereis no method, letalone logic, for conjecturing mechanisms. True, Peirce wrote about the ‘method of abduction,’ but ‘abduction’ issynonymous with‘conjecturing,’ and this – as Peirce himselfwarned – isan art, not atechnique.\nOnereasonisthat, typically,mechanismsareunobservable, andthereforetheirdescriptionisbound tocontainconcepts thatdonotoccurinempiricaldata.” 19Asbestwecantell,Woodward(2003,section4.6)takesthisposition,notingtheneedforonlya ratherlimited“backing”relationshipbetweencausalclaimsandlaws.\nother. This position is summarized by Andrew Collier (2005:335): “Critical realism defends the idea that reality is many-layered,and each level has its own kind of laws, irreducible to those of any other layer.” For the social sciences, one might argue that such an irreducibility presumption couldbe unifying inoffering protectionagainstincursionsfrombiology andphysics.20 But, if accepted, it would undermine the work of social scientists who have at least some interest in developing causal claims that unite levels of analysis. If irreducibility wereaccepted,howthencouldmethodologicalindividualistssuchasGoldthorpecriti- cize those whoseek todevelopmacrolevelcausalclaimswith onlyminimally sufficient reliance onproximateactors andinstitutions (e.g., Alexander 2003)?21 Gorski(2004), for example, lays out a constructive realist model of explanation, built up from the causal process perspective of Wesley Salmon’s early work, that is completely at odds with the perspective of Goldthorpe (2007).22 But Goldthorpe (2007, chapter 2) ques- tions the explanatory utility of all secondhand historical analysis, in essence rejecting the capacity of historical analysis, as practiced in sociology, to sustain causal claims ofany form. IfGoldthorpe wereto signonto irreducibility, whichwe doubt he would, he could not thereby criticize macrosocial claims of causal relationships.\nGiventhattheseextremepositionsonmechanismsinthe philosophyofscience are likelytobeunhelpfultopracticingsocialscientists,andgiventhatHedstro¨mandothers in the generative mechanisms movement seem to agree (see Hedstr¨om 2005:70–74), which type of philosophy of science gives the appropriate backing for causal analysis? Ifanything,itisthephilosophicalwritingonthecounterfactualmodelthatprovidesa solid and pragmatic foundation, as best representedfor the causal modeling tradition by Woodward (2003). The key to understanding why this is the case is to consider alternative ways to adjudicate between the rival mechanisms proposed by alternative investigators, which we turn to next.\nAdjudication Between Rival Mechanisms Imagine that social scientist A and social scientist B have proposed distinct mecha- nisms for how X brings about Y. How do they determine whose mechanism is sup- ported? According to Goldthorpe (2001, 2007), each scholar is expected to derive entailedhypotheses,typicallyindirect, andtestthem with data.One mighthope that scholars A and B will be able to agree on a clear critical test that could tip the scales in favor of one mechanism or the other. Unfortunately, the mechanisms of the two 20Ofcourse,nontranscendental protectionisavailableaswell,asweexplainbelowwhendiscussing thenotionof“bottomingout”inmechanisticexplanation.EvenStrevens(2008:472),whiledefending reducibility to fundamental physics, can concede that many lower-level details may be suppressed whentheyplaynoroleinproducingtheoutcomeofinterest.\n21Methodological individualism is the basic position of Goldthorpe (2001, 2007) and Hedstro¨m (2005),asinfluencedheavilybythescholarshipofRaymondBoudon(seeBoudon1998andcitations therein).\n22Gorski (2004) endorses the causal process model of Wesley Salmon, as developed in Salmon’s work from the 1970s and early 1980s (see Salmon 1984). Given the ways in which Salmon’s work developedlaterinhiscareer,turningcompletelytowardcausalmechanicalideasbasedonthenotion ofconservedquantities,hisupdatedideasseemcompletelyirrelevanttowhatwetaketobeGorski’s main position: “Social science is ‘nothing but history.’ The real error was ever to think it could be anythingmore”(Gorski2004:30;emphasisinoriginal).\nscholarsmaybe sodifferentthatnosuchcriticaltestcanbederivedandagreedon(as wouldoften be the case if scholar A is a sociologistand scholarB is an economist, for example).If no suchagreementcanbe found, the two scholarsmay end up expending effort seeking to affirm their own entailed indirect hypotheses, producing results that are then regarded as irrelevant by each other.\nConsider the reaction that Goldthorpe’s proposal elicited from the statisticians David Cox and Nanny Wermuth, whose prior work Goldthorpe had used to develop his proposal: Goldthorpe (2001) has argued for this … view of causality as the appro- priate one for sociology with explanation via rational choice theory as an importantrouteforinterpretation.Tobesatisfactorythereneedstobeevi- dence,typicallyarisingfromstudiesofdifferentkinds,thatsuchgenerating processes are not merely hypothesized. Causality is not to be established by merely calling a statistical model causal. (Cox and Wermuth 2001:69) By our interpretation, Cox and Wermuth take the position that generative mecha- nisms must be directly evaluated, not evaluated only by indirect entailed hypotheses.\nAnything shortof this analysis strategy could resultin a flourishing of mechanisms in the social sciences, without an attendant sense of which ones have sufficient empirical support to command attention.\nThe alternative to any such mechanism anarchy could be even worse: mechanism warlordism.The mechanisms of the most industrious scholars – those who can dream up the largest number of hypotheses to affirm, who can recruit the largest number of students to do the same, and who can attract the largest amount of funding to collect the data on their hypotheses – could receive the most affirmation. The only defense for out-of-favormechanisms might then be to appeal to the hidden structures of alternativemechanisms, which one would be tempted to claim cannot be evaluated because of a lack of data.\nInsum,thegenerativemechanismsmovementinthesocialsciencesisanadmirable call for theory construction.23 The appeal for finely articulated “semigeneral” mech- anisms to fill the toolkit of social theory (see Hedstr¨om and Bearman 2009:6–7) is consistent with the appeal to forms of abduction that generate what Craver (2007) has labeled “how-possibly” and “how-plausibly” models: How-possiblymodels areoftenheuristicallyusefulinconstructingandexplor- ing the space of possible mechanisms, but they are not adequate explana- tions. How-actually models, in contrast, describe real components, activi- ties, and organizational features of the mechanism that in fact produces the phenomenon.Betweenthese extremes is a rangeof how-plausibly mod- els that are more or less consistent with the known constraints on the components,theiractivities,andtheirorganization.(Craver2007:111–12).\nWe see the generative mechanisms movement as a call for the construction of how- possibleandhow-plausiblemodels.Suchactivityis worthwhileinits ownright,andit 23Infact,thefirstauthorfounditconvincingandinspiringwhenwritingMorgan(2005).\nmayhelptoinformempiricalresearch.Weseecausalanalysis,incontrast,asadirected effort to evaluate the support for specific claims implied by how-actually models.\nFinally,aslongasthegenerativemechanismsmovementdoesnotvergeintocritical- realisttranscendentalismin the future, it will remaina veryuseful callfor the pursuit of sufficiently deep causal accounts. An elegant mechanism, if how-plausible, may be a crucial stepforwardin convincinga fieldthat anaccepted causalclaimis supported by an underlying mechanistic account that should be seen as too shallow. Thus, even though theory construction is not causal analysis, theory construction may help to establish our goals for explanatory depth. We take the position that genuine causal depth must be secured by empirical analysis, and that such analysis is often best grounded on the counterfactual model. In the next section, we work our way back to Pearl’s front-door criterion, after introducing a language of mechanism sketches and mechanism schemas that is helpful for classifying alternative representations of mechanisms.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#the-pursuit-of-explanation-with-mechanisms-that-bottom-out",
    "href": "extracted/Counterfactuals and Causal Inference.html#the-pursuit-of-explanation-with-mechanisms-that-bottom-out",
    "title": "Counterfaturals and Causal Inference",
    "section": "10.4 The Pursuit of Explanation with Mechanisms That Bottom Out",
    "text": "10.4 The Pursuit of Explanation with Mechanisms That Bottom Out\nAmid the resurgence of writing on mechanisms, we find one statement more help-\nful than many others, the 2000 article “Thinking About Mechanisms” written by Machamer, Darden, and Craver and published in Philosophy of Science. In their arti- cle, Machamer, Darden, and Craver develop two particularly helpful lines of thought: (1) the distinctions between a fully articulated mechanism, a mechanism sketch, and a mechanism schema, and (2) the process of “bottoming out” in mechanistic model building and subsequent explanation. To develop these concepts, Machamer et al.\n(2000:12) first note that “in a complete description of [a] mechanism, there are no gapsthatleavespecificstepsunintelligible;theprocessasawholeisrenderedintelligi- bleintermsofentitiesandactivitiesthatareacceptabletoafieldatatime.”Butthey thenexplainthatexplanatoryinquiryusingmechanismsisnotanall-or-nothingaffair, inwhicheverystepisalwaysspecified.Variabilityintherepresentationofmechanisms is possible because mechanisms occur in nested hierarchies. … The levels in these hierarchies should be thought of as part-whole hierarchies with the additional restric- tion that lower level entities, properties, and activities are components in mechanisms that produce higher level phenomena….” (Machamer et al.\n2000:13) In spite of such nesting, there is a natural bottoming out of mechanism-based expla- nations: Nestedhierarchicaldescriptionsofmechanismstypicallybottomout inlow- estlevel mechanisms.These are the components that are acceptedas rela- tivelyfundamentalortakentobeunproblematicforthepurposesofagiven scientist,researchgroup,orfield.Bottomingoutisrelative:Differenttypes of entities and activities are where a given field stops when constructing mechanisms. The explanation comes to an end, and description of lower- level mechanisms would be irrelevant to their interests. (Machamer et al.\n2000:13) Then, by thinking through the complexity of the nesting of mechanisms, and how scholars represent mechanisms to each other, they develop two related concepts. A mechanism schema is a representation of a mechanism in which some known details (or known nested levels) are suppressed for the sake of simplicity. Or, as Machamer et al. (2000:15) state, “a mechanism schema is a truncated abstract description of a mechanism that can be filled with descriptions of known component parts and activi- ties.” In contrast, a mechanism sketch is quite different: A sketch is an abstraction for which bottom out entities and activities cannot (yet) be supplied or which contains gaps in its stages.The produc- tive continuity from one stage to the next has missing pieces, black boxes, which we do not yet know how to fill in. A sketch thus serves to indicate whatfurther workneedsto be done inorderto havea mechanismschema.\nSometimes a sketch has to be abandoned in the light of new findings. In othercasesitmaybecome aschema,servingasanabstractionthatcanbe instantiated as needed. (Machamer et al. 2000:18) Within this framework, one can conceive of causal analysis in the social sciences as the pursuit of explanations that bottom out.24 Although there will inevitably be dif- ferences of opinion on how deep an explanation must be to bottom out, it would seemuncontroversialto state that a validexplanationthatinvokesamechanismmust bottom out at least as far as the observables in the data at hand.25 This position, although we think it uncontroversial, is still not specific enough for our tastes. In the remainder of this section, we discuss two entangled issues: (1) when deep accounts cannot be provided because nominal causal states are too coarselydefinedand(2)howthe pursuitofdeepcausalaccountsshouldproceedwhen the specification of causal states will allow it.\nCoarse Causal States Impede the Pursuit of Causal Depth. When we introduced in Section 2.1 the causal states that define potential outcomes, we took the position that causal states should be finely articulated and motivate comparisons that are local and reasonable. We also noted, in the subsection beginning on page 39, 24See alsothe discussions of modularityinWoodward (2003, chapter 7) and Knight and Winship (2013).\n25Acriticalrealistcouldescapefromthispositioninavarietyofways:assertingirreducibilityand transcendentalismandthen,morespecifically,byarguingintheendthatthedatathatoneisforced to consider are but a poor reflection of the phenomena that the mechanism truly does explain. For allofthesereasons,thelackofobservedexplanatorypowerforobservedeventswouldthenbeargued tobeuntroubling.Thisposition,however,thenbecomes avariantofanappeal toahiddenbutpre- supposed valid underlyingstructure, which Woodward convincingly argues cannot be anacceptable explanatory strategy for any field that hopes to resolve its explanatory controversies because “the appealtohiddenstructuremakesittooeasytoprotectone’sfavoredtheoryofexplanationfromgen- uinecounterexamples” (Woodward2003:175). Moreover,iftheparticularitiesinthedataaremerely a poor reflection of the phenomenon that the mechanism is supposed to explain, then presumably whatever generates the mismatch can be encoded in the mechanism that explains both the genuine phenomenonofinterestandtheprocessthatgenerates themisleadingdata.\nthat we see value in regarding each state of each treatment as a nominal state with constitutivefeatures(e.g.,entities,activities,andrelations)thatarejointlycapableof producingtheoutcomeofinterest.Wethenprovidedexampleswherethecausalstates are composed of constitutive features. For example, the types of schools that define the causal states for many of the examples in this book are composed of teachers, classrooms, curricula, administrators, normative environments, affiliated institutions, and networks of peers and parents. We maintained that causal effects can still be defined with reference to these nominal states because we can conceive of differences in outcomes that would result from alternative exposure in toto to the constitutive features of each nominal state.\nWe will not repeat the pragmatism-based argument of Section 2.1 here, but the discussionthereendsonacrucialquestionrelevanthere.Afterpresenting,asanexam- ple, the literature that has focused on the particular features that may give Catholic schools an advantage in the production of learning, we asked what should be made of any such lower-level causal claims. More generally, we asked: When should nom- inal causal states be decomposed into component causal states in pursuit of more finely articulatedcausalexplanations?If Catholicschoolsandpublic schoolsareto be regarded as alternative nominal causal states relative to each other, and yet one has somebasisforclaimingthatCatholicschoolsproducealearningadvantagebecause of a greaterendowmentof one particularconstitutive feature – dense parental networks, forexample–thenshouldwedispensewiththe nominalcausalstatesandredefinethe research question solely to enable an examination of this particular feature? Ifinterestexistsinunderstandingwhatreallywouldhappenifweexposedindividu- alstoalternativenominalcausalstates,thenthisinterestaloneissufficientjustification for not doing so. Many policy evaluation studies take this position. Investigatorsmay not be able to discern which particular features of an intervention program are effec- tive, but they still want to know whether the program, altogether, has an effect on average, and, furthermore, whether that effect varies across types of individuals who could be exposed to it. More generally, when nominal causal states are composed of many constitutive features, only some of which contribute to the production of the outcome,therelevantscholarlycommunitymayrecognizethatonlyshalloweffectsare feasible toestimate. Ifdataarenotavailableto analyzeall ofthe constitutivefeatures –eithertoassesstheirautonomouscausalcapacitiesortheprocessesthatimbuethem withjointandinteractivecausalcapacities–thenthecausalclaimsbasedonthenom- inal states alone may be regardedas insufficiently deep and yetstill be as deep as can be sustained by an empirical analysis.\nOverall,whenthesechallengesariseinpractice,weseeinherenttensions,andhence can offer no general guidance, on whether one should (1) preserve the nominal causal states as originally defined andsettle for a shallowaccountof how the cause produces its effect, (2) preserve the nominal causal states as originally defined but then also attempt to deepen the shallow account by specifying a full mechanism for how the cause produces its effect, or (3) decompose the original nominal causal states into component causal states and then specify separable mechanisms that can account for the partial effects attributable to particular constitutive features, now redefined as lower-level nominal states. Making this choice surely depends on the state of relevant theory about the process under analysis, whether the constitutive features can be meaningfully separated and then measured, whether data with such measures are available, and what standards prevail in the field for which the study is intended.\nThe PursuitofCausal Depth byInvestigation ofNested Mechanisms.As we noted at the beginning of this chapter with illustrative quotations fromDuncan et al. (1972) and Kendall and Lazarsfeld (1950), for many decades social scientists have usedinterveningvariablesinempiricalanalysisinattemptstoexplainhowcausesbring abouttheireffects.Inthissection,wewillapplythelanguageofMachameretal.(2000) to this tradition of analysis, using causal graphs and making explicit connections to our presentation of Pearl’s front-door criterion.\nRecall that for Machamer et al. (2000)the difference between a mechanism sketch and a mechanism schema is the source of the abstraction in each. For a schema, all of the parts of the mechanism are known, and the abstraction from them is enacted for presentation purposes. For a sketch, some of the parts are unknown, and thus the abstraction is a representation of the analyst’s epistemic limitations.\nBeforeconsideringdirectedgraphsofthe sortutilizedinthis book,weshouldnote howeasyitistofindarrow-basedfigurativerepresentationsthatcanbeinterpretedas mechanismabstractions.Herearefiveexamplesfromwidelyregardedworkinsociology where →’s are utilized liberally: 1. In Foundations of Social Theory, Coleman (1990:637, see figure 23.4) offers a representation of a feedback process for social policy research where five actors and activities – “Government,”“Intermediaries,”“Policyrecipients,” “Research on social policy,” and “Political representation” – are connected by eight →’s and five (cid:3)(cid:3)(cid:4)’s.\n\nInClassCounts,Wright(1997:262,seefigure10.1)offersamodelfortheeffectsof classlocationonclassidentitywhere“Directclasslocation”and“Mediatedclass location”areconnectedto“Classidentity”throughseven→’sthatareconnected to “Patternsof daily work interaction,”“Materialclass interests,” “Production- centered class experiences,” and “Consumption-centered class experiences.”\nIn “A Plea for Mechanisms,” Elster (1998:63, see figure 3.1) offers mechanisms for the interaction of democracy and religion where “Democracy,” “Religion,” “Irreligion,”“Desires,”“Opportunities,”and“Action”areconnectedbysix→’s.\nInInteraction Ritual Chains,Collins(2004:48,seefigure2.1)offersarepresenta- tion where Durkheimian “Collective effervescence” converts four “Ritual ingre- dients” (group assembly, barrier to outsiders, mutual focus of attention, and shared mood) into four “Ritual outcomes” (group solidarity, emotional energy in the individual, symbols of social relationship, and standards of morality), via a relation ]→[.\nIn A Theory of Fields, Fligstein and McAdam (2012:20, see figure 1.1) offer a representation of “three linked mechanisms” for episodes of contention where two types of actors “Incumbent” and “Challenger” respond to “Destabilizing changes” and “Escalationof perceived uncertainty” by enacting “Attribution of threat/opportunity,” which leads to “Social appropriation,” and then to “Inno- vative collective action.” These mechanisms of action are connected by 12 →’s, Many more examples exist.26 Our point in offering these five examples is to highlight the revealed presentation value of mechanism abstractions that use arrows.\n\nNow,considerthesortoffinelystructuredcausalgraphswehaveconsideredexten- sively in this book. Suppose that one uses some form of back-door conditioning to identify a causal effect of D on Y. Suppose, furthermore, that one has done so from within the counterfactual framework, settling on the ATE as the parameter of first- order interest. One then necessarily confronts the question that we raised in the beginning of this chapter: Does a counterfactually defined and consistent estimate of the causal effect of D on Y by itself meet the standard of an explanation that bottoms out? The answer to this question is clear: It depends on what D and Y are, who is conducting the study, and for what purposes. If one wishes to know only how a hypo- thetical intervention on D would shift Y, and hence has no interest in anything else whatsoever, then bottoming out has been achieved in some minimalist way, as we noted above. The analysis yields up a consistent estimate of the average causal effect of D on Y that holds for the population within which both are observed.In this case, the modelD→Y is then regardedas merely a mechanismsketch,whichsuffices to be treated as a sufficiently deep explanation for the purposes at hand.\nHowever,itwilloftenbethecasethatanestimateofawarrantedcausaleffectofD on Y, grounded in the potential outcomes framework,is properly considered to be an insufficiently deep explanation of how D brings about Y. Such a judgment would be appropriate when the interest of the field is in understanding both how interventions on D and interventions on the mechanistic intervening variables that link D to Y would shift Y. In this case, the model D→Y is a mechanism sketch that, for the purposesathand, cannotbe regardedas asufficiently deepexplanation.The arrowin the sketch D→Y is a black box that must be filled in through further analysis.\nIfawarrantedclaimofacounterfactuallydefinedcausaleffectisproperlyregarded as insufficiently deep, the recourse is not to abandon the counterfactual model but rather to investigate the nested mechanism that intercepts the effect of D on Y. Such analysis may initially take the form of a set of alternative conjectured mechanisms.\nBut, ultimately, any such analysismust returnto the particular observedrelationship betweenDandY inthepopulationofinterest(ormorebroadlyinmultiplewell-defined populations for which the question of interest is relevant). Thus, although theoretical creativity and new measurement techniques may be required, opening up black boxes is, at least in part, an empirical pursuit. At some point, one must specify the causal statesforthevariablesthatconstitutethemechanisms,andeachlinktherebyspecified to give rise to an effect must be submitted to its own causal analysis.\nConsider this process abstractly with reference to a causal graph, after which we willintroduceexamplesfromthepublishedliterature.Supposethatonepursuesfurther theoretical conjecturing and subsequent empirical analysis, and one then determines that the variables A, B, and C constitute an exhaustive and isolated mechanism that identifies thecausaleffectofD onY by Pearl’sfront-doorcriterion.Atthispoint, one may be tempted to declare that a sufficiently deep causal explanation of the effect of 26Anearly(andparticularlyobtuse) oneisParsons(1937:741, footnote 1),wherea“webofinter- wovenstrands”isusedtoexplainhowmeans-endchainsevolveintimeandstructureunitacts.\nD on Y has been secured. Such a claim may well be true, but it is not guaranteed. It couldbe that further nested mechanistic variables exist, such that, for example, three additional variables M, N, and O (each of which is a concept of considerable interest to one’s peers) are then found to elaborate the casual pathway D→ A →Y. In this case,thecausalpathwayD→A→Y isthenitselfbestregardedinhindsightasmerely a component of a mechanism sketch. When M, N, and O are then observed, D→ A →Y isreplacedinthemechanismsketchwith,forexample,oneormorerelatedcausal pathways, such as D→M →A →N→Y and D→A →O→Y. In this example, A, B, and C may well identify the causal effect by the front-door criterion, but they do not qualify as a sufficiently deep causal account of how D brings about Y.\nAs we noted in the first part of this chapter, the progressive deepening of causal explanation through the modeling of intervening processes is entirely consistent with social science tradition. And yet we also claimed that Pearl’s front-door criterion can help guide sharpenedanalysis practices in this regard.To see what we mean, consider the example of Duncan’s research on status attainment processes again. As we noted in Chapter 1, Blau and Duncan (1967) deepened the causal account of how parental socialstatusdeterminesoffsprings’socialstatusby specifyingwhatmostscholarsnow regardas the most important link: levels of educational attainment.\nThereafter,Duncanandhiscolleaguesthensupportedandencouragedfurtherwork on the process of educational attainment, most importantly the Wisconsin model of status attainment that we introduced in Section 1.3.1. This model is a direct exten- sion of Blau and Duncan’s research, in which the causal pathways between parental status and offspring’s attainment were elaborated by the introduction of intervening variables for significant others’ influence and educational aspirations. In fact, in the mostimportantarticleinthistradition,Sewelletal.(1969)usedmechanisticlanguage to introduce the contribution of their study: wepresenttheoryanddataregardingwhatwebelievetobealogicallycon- sistent social psychological model. This provides a plausible causal argu- menttolink stratificationandmentalabilityinputs throughasetofsocial psychologicaland behavioralmechanisms to educationaland occupational attainments.Onecompellingfeatureofthemodelisthatsomeoftheinputs may be manipulated through experimental or other purposive interven- tions. This means that parts of it can be experimentally tested in future research and that practical policy agents can reasonably hope to use it in order to change educational and occupational attainments. (Sewell et al.\n1969:84) The Wisconsinmodelwasveryfavorablyreceivedinsociology,as it wasconsideredto be consistentwith the basic features of the model of BlauandDuncan (1967)andyet had a claim to greater causal depth.27 Even so, as we also noted in Section 1.3.1, critics emerged immediately (see also Morgan2005,chapter2,foramoreextendedsummary).Thebasicargumentwasthat, even if significant others’ influence and educational aspirations have causal effects on 27Anotherwidelyreadexampleofthetimeistheearliermechanisticelaborationintheresearchof KendallandWolf,contributedbyKendalltoHyman(1955:324–27).\neducationalattainment, they are both groundedin partin sourcesoutside of parental status and mental ability (a point the authors of the Wisconsin model recognized).\nThus,althoughsignificantothers’influenceandeducationalaspirationsmaybehelpful tosomeextentinofferinganinterpretationofsomeofthecausalprocessthatgenerates intergenerationalcorrelationsofeducationalattainment,theseinterveningvariablesdo notqualifyasanexhaustiveandisolatedmechanismthatfullyaccountsfortheeffects of parental status on offsprings’ status.\nInthisregard,theBlauandDuncanmodelcanberegardedasamechanismsketch for the status attainment process, and the Wisconsin model can then be regarded as a mechanism-based attempt to deepen its implied explanation. The Wisconsin model was therefore an important step forward, but it was not conclusive and did not settle all further research.\nMore than four decades later, it is now clear that the Wisconsin model itself is a mechanism sketch. The research community of inequality scholars in sociology seems to have concluded that its pathways have not bottomed out, and much research con- tinuesontheprocessesthatgenerateeducationalaspirations(aswellaswhetherornot the relationship between aspirations and attainment is sufficiently explanatory to be useful).Moreover,somescholars(e.g.,Goldthorpe2007)haveproducedentirelydiffer- ent mechanism sketches for the relationship between parental status and educational attainment. The future of this research tradition is clearly careful empirical analysis that can adjudicate between these rival mechanism sketches, which will be decisive only when alternative mechanism sketches are pushed down to lower-level entities on which critical tests can then be performed.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#conclusions-7",
    "href": "extracted/Counterfactuals and Causal Inference.html#conclusions-7",
    "title": "Counterfaturals and Causal Inference",
    "section": "10.5 Conclusions",
    "text": "10.5 Conclusions\nPearl’s front-door strategy for the identification of a causal effect is a powerful and\nilluminating perspective on the explanatory power of mechanisms. It clearly shows that the identification of a causal effect by a mechanism requires that the mechanism be exhaustive and isolated and that its variables be observed. For such a mechanism to count as a sufficiently deep explanation, its causal pathwaysmust be finely enough articulated that it meets whatever standard of bottoming out is maintained in the relevant field of study. If such a standard is not reached, then the causal effect is identifiedeventhoughitisnotaccompaniedbyasufficientlydeepexplanation.Instead, the identifying causal pathways represent a mechanism sketch that demands further analysis.\nConsidering this chapter and the strategies for causal effect estimation from prior chapters, we have come back full circle to our initial presentation of causal modeling optionsinChapter1.Wenotedthere,withreferencetoFigure1.3,thatacausaleffect thatisidentifiedbyboththeback-doorcriterionandanIVisbestexplainedwhenitis also identified by an exhaustive and isolated mechanism. This is the highest standard for an explanatory causal analysis, at least until a field decides that a crucial linkage within a mechanism must then be opened up and subjected to its own analysis.\nInthenextchapter,weturninadifferentdirectiontoconsidertheextenttowhich over-time data on an outcome variable can be used to identify and estimate a causal effect.Oneoftenhearspresentationsinwhichscholarsremark,“Icannotgetatcausal- ity because I do not have longitudinal data.” We will argue in the next chapter that longitudinal data, althoughvery helpful in many cases, are not the panacea that such statementsseemto imply. Moreover,wewill showthatsomelong-standingtechniques that are thought to reveal causal effects are strongly dependent on assumptions that are often entirely inappropriate and sometimes completely unrecognized.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#interrupted-time-series-models",
    "href": "extracted/Counterfactuals and Causal Inference.html#interrupted-time-series-models",
    "title": "Counterfaturals and Causal Inference",
    "section": "11.1 Interrupted Time Series Models",
    "text": "11.1 Interrupted Time Series Models\nTo estimate the treatment effect for a study with an ITS design, a time series model\nis typically offered: Yt=f(t)+Dtb+et, (11.1) where Yt is some function in time (which is represented by f(t) on the right-hand side), Dt is a dummy variable indicating whether the treatment is in effect in time period t, and et is time-varying noise. The basic strategy of an ITS analysis is to use the observed trajectory of Yt prior to the treatment to forecast the future trajectory of Yt in the absence of the treatment (see the introductions in Marcantonio and Cook 1994,McDowall, McCleary, Meidinger, and Hay 1980, and Shadish et al. 2001).\nConsider, as in our prior example in Section 2.8.1 on the year of the fire horse, howpotentialoutcome notationcanbe usedto understandthe ITSdesign.For setup, supposethatwehavediscreteintervalsoftimetthatincreasefrom1toT.Theoutcome variable Yt in Equation (11.1) then has observed values {y 1,y 2,y 3,…,yT}. The two- statecausalvariable,Dt,isequalto1ifthe treatmentisinplaceduringatimeperiod tandis equalto 0 otherwise.For the ITSdesign, it is typicallyassumedthatonce the treatment is introduced in time period t∗, its effect persists through the end of the observation window, T.\nAnalogous to (but a bit simpler than) our general setup in Section 2.8.1, the ITS observed data are defined in terms of potential outcome variables as 1. Before the treatment is introduced (for t&lt;t∗):1 Dt=0 Yt=Y t0 2. After the treatment is in place (from t∗ through T): Dt=1 Yt=Y t1 Y0existsbutiscounterfactual.\nt The causal effect of the treatment is then δt=Y t1−Y t0 (11.2) for time periods t∗ through T. By the definition of the potential outcomes, Equation (11.2) is equal to δt=Yt−Y t0, (11.3) again for time periods t∗ through T.\nThecrucialidentifyingassumptionfortheITSdesignisthattheobservedvaluesof ytbeforet∗ canbeusedtospecifyf(t)foralltimeperiods,includingtimeperiodsfrom t∗ toT.2 Equivalently,theprimaryweaknessofthe ITSdesignis thatthe evolutionof Yt prior to the introduction of the treatment may not be a sufficiently good predictor of how Yt would evolve in the absence of the treatment. In other words, even though the pretreatment evolution of Yt is by definition a perfect reflection of the evolution of Y0 before t∗, it may be unreasonable to extrapolate to posttreatment time periods t in order to estimate treatment effects defined by Equation (11.3).\nConsider the trajectory of Yt in the hypothetical example depicted in Figure 11.1.\nThe solid line represents the observed data on Yt, and the time of the introduction of the treatment is indicated on the horizontal axis, which we defined above as t∗.\nThe true counterfactualevolution of Y0 in the absence of treatment is representedby t the dashedline. Clearly,this counterfactualtrajectorywouldbe poorlypredictedbya straightforward linear extrapolation from the observed data before the treatment. In fact, in this case, assuming that the counterfactual trajectory followed such a linear trajectory would result in substantial overestimation of the treatment effect in all posttreatment time periods.\nFor estimation, no issues beyond those relevant to a standard time series analysis ariseforanITSmodel.Thekeystatisticalconcernisthattheerrorset arelikelytobe correlated over time. If we use least squares regression, the parameter estimates will be consistent, but the standarderrorsandany hypothesis tests basedon them will be incorrect. This problem can be especially acute when the number of data points in a 1Again, as in Section 2.8.1, counterfactual values for Y t1 exist in pretreatment time periods, but thesevaluesarenottypicallyconsideredinanITSanalysis.\n2Asecondaryassumption,whichwedonotemphasize,isthecommonpositionthattheparameter b in Equation (11.1) is a structural constant that does not vary with t. This assumption can be relaxed,allowingbtovaryfromt∗ throughT assomefunctionint.\nY t Observed True counterfactual Assumed counterfactual t* Time Figure11.1 Trajectories of the observed outcome as well as the true and assumed counterfactual outcomes for a faulty ITS model.\ntime series is small. We will not address any of the issues involved in estimating time series models, as there are many books that cover the topic in depth (e.g., Hamilton 1994;Hendry 1995).\nInstead,wewillillustratethebasicthinkingbehind anITSanalysiswithanexam- plefromBraga,Kennedy,Waring,andPiehl(2001),whichispresentedinFigure11.2.\nBragaandhiscolleagueswereinterestedinevaluatingwhetheraninnovativeprogram, “Operation Ceasefire,” initiated by the Boston Police Department in June 1996, pre- ventedyouthhomicides.Figure11.2presentsthetrendinthemonthlyyouthhomicide rate in Boston between June 1991 and May 1998.\nOperationCeasefireinvolvedmeetingswithgang-involvedyouthwhowereengaged ingangconflict.Gangmemberswereofferededucational,employment,andothersocial servicesiftheycommittedtorefrainingfromgang-relateddeviance.Atthesametime, the police made it clear that they would use every legal means available to see that thosewhocontinuedtobeinvolvedinviolentbehaviorweresenttoprison(seeKennedy 1997 for a more detailed description).\nThe vertical line in Figure 11.2 marks the date at which Operation Ceasefire was initiated.Thetwohorizontallinesindicate,respectively,themeanlevelofyouthhomi- cides before and after June 1996. As can be seen in Figure 11.2, there appears to be an abrupt and large drop in the level of youth homicide in Boston immediately after the implementation of Operation Ceasefire.\nBraga and his colleagues carried out a more formal analysis using standard time series techniques (but because their dependent variable is a count variable – number of youth homicides in a month – they used a Poisson regression model). In their first model,theyadjustedonlyforseasonaleffectsbyusingdummyvariablesformonthand a lineartermfor time. Inclusionof the time trend is particularlyimportant. Although it is not clear in Figure 11.2, there is a slight downward time trend in the homicide rateinthe pretreatmenttime period, whichitseemsreasonableto assumewouldhave continued even if Operation Ceasefire had not been implemented. For this model, Ceasefire intervention May 15, 1996 12 smitciv 8 fo rebmuN19-naJ 4 0 19-raM 19-yaM 19-luJ 19-peS 19-voN 29-naJ 29-raM 29-yaM 29-luJ 29-peS 29-voN 39-naJ 39-raM 39-yaM 39-luJ 39-peS 39-voN 49-naJ 49-raM 49-yaM 49-luJ 49-peS 49-voN 59-naJ 59-raM 59-yaM 59-luJ 59-peS 59-voN 69-naJ 69-raM 69-yaM 69-luJ 69-peS 69-voN 79-naJ 79-raM 79-yaM 79-luJ 79-peS 79-voN 89-naJ 89-raM 89-yaM Date Youth Homicides Pre-Test Mean Post-Test Mean Figure11.2 Monthly youth homicide rates in Boston, 1991–1999.\nSource: Braga et al. (2001), figure2.\nBraga and his colleagues reported a large negative and statistically significant effect of Operation Ceasefire on youth homicides.\nIn general, a researcher would usually prefer a situation in which the underlying time trend and the treatment effect are in the opposite directions. In such a case, disentangling the treatment effect and the time trend is far easier, strengthening any warrant for a causal inference. However, for this example, the underlying time trend and the expected program impact move in the same direction. Thus, a researcher should be concerned about the ability to accurately estimate the size of the program effect in the presence of the underlying trend. Recall that Figure 11.1 illustrated a similar but more problematic situation. Not only does the time trend move in the same direction as the effect in that hypothetical example, but there is a change in the time trend in the same direction as the treatment effect, making accurate estimation of the effect impossible with an ITS model.\nThe research of Braga et al. (2001) represents a very high-quality example of how to use an ITS design to investigate a treatment effect. They offered four types of sup- plemental analysis, eachof which is broadly applicable to all ITS designs, and each of whichcanbe usedtostrengthenthe warrantfor acausalclaim. First, they considered additional dependent variables that Operation Ceasefire should have affected. Specif- ically, they analyzed whether the program affected the number of gun assaults and reports of gun shots fired. For these dependent variables, they found an even larger programimpact.Theiranalysiswouldhavebeenstrengthenedfurtheriftheyalsohad considered dependent variables that Operation Ceasefire should not have affected as much(e.g., number ofrobberiesandincidents ofdomestic violence). Here, evidence of an impact would suggest that factors other than the program itself at least partially accounted for the observed drop in youth homicides.\nSecond, they focused their hypothesis and considered it within meaningful sub- groups.Inparticular,theyanalyzedthelevelofgunassaultsinpolicedistrictB-2,the districtwheregangviolencewasthehighestintheearly1990sandOperationCeasefire was most active. As they predicted, the programeffect was largerin district B-2 than in the city as a whole. If there had been districts with high levels of youth violence whereOperationCeasefirewasinactive,it wouldhavebeenuseful to havetestedfora programimpact. If evidence were found that the programhad animpact in these dis- tricts,itwouldsuggestthatsomethingotherthantheprogramwasresponsibleforthe observeddecline inyouthhomicides, gunassaults,andgunshotsfired. Unfortunately, atleastforthe analyst,almostallyouthviolenceinBostonoccurredinthree adjacent police districts, all districts in whichOperationCeasefirewas active. As a result, such an analysis was not possible.\nThird, they includedadditional adjustmentvariablesintheir time seriesmodels in ordertocapturetheunderlyingtimetrendaswellastheyear-by-yearvariabilitybefore and after the introduction of the treatment. These time-varying covariates included unemployment rates, the size of the youth population, the robbery rate, the homicide rate for older victims, and the drug-related arrest rate. The advisability of adjusting for the latter three variables is questionable, given that these variables are also likely to have been affected by Operation Ceasefire to at least some degree. Nonetheless, conditioning on these additional variables produced little change in their estimate of the programimpact on any of their dependent variables.\nFinally,theycomparedthetimetrendinhomicidesinBostonwiththetimetrendin 41 other cities where no targeted interventions for homicide rates were implemented.\nTheir goal was to determine whether other cities experienced declines in rates as abrupt as the one observed in Boston. The explanation of Braga and his colleagues for the abruptness of the decline in Boston – in fact, a decline that emerged in only two months – was that word got out on the street quickly that the police meant business. For many of the other cities considered, homicide rates fell throughout the 1990s. With the exception of New York City, the declines were substantially smaller than in Boston. Braga and his colleagues then showed that abrupt declines did occur in five other cities, but the exact timing of these abrupt declines was different than in Boston. This evidence raises perhaps the greatest doubt about the assertion that OperationCeasefire reduced youth homicide rates in Boston because there is no clear explanation for why these abrupt declines occurred elsewhere either. And, because it may be implausible that OperationCeasefire’s effect could have fully taken hold in as short as two months, the possibility exists that the decline in homicide rates and the introduction of Operation Ceasefire were coincidental.\nIfBragaandhiscolleagueshadcarriedouttheirevaluationanumberofyearslater, theycouldhaveimplementedoneadditionalstrategy.In1999,OperationCeasefirewas cut back and then terminated. If they had performed their analysis for at least a few yearsbeyond1999,theycouldhaveexaminedwhethertheterminationoftheprogram resulted in an increase in homicide rates. In fact, after 1999, the youth homicide rate didincreasesuchthat,bythesummerof2006,itwasatnearlythesamelevelasinthe early1990s(seeBraga,Hureau,andWinship2008).The subsequentincreaseprovides additional evidence for the impact of Operation Ceasefire while it was in place.\nThisexamplenicelyillustratesthevarietyofgeneralstrategiesthatareoftenavail- able to strengthen an ITS analysis: 1. Assess the effect of the cause on multiple outcomes that should be affected by the cause.\n\nAssess the effect of the cause on outcomes that should not be affected by the cause.\nAssess the effect of the cause within subgroups across which the causal effect should vary in predictable ways.\nAdjustfortrendsinothervariablesthatmayaffectorberelatedtotheunderlying time series of interest.\nComparethe focaltime trendwith the time trendforother units orpopulations to determine whether breaksin the time seriesare likelyto occur inthe absence of the cause.\nAssess the impact of the termination of the cause in addition to its initiation.\n\nThesestrategiesareoftenavailableforothertypesofanalysis,andtheyarealsowidely applicable to all formsofdata analysisthatattempt to infer causationfromover-time relationships. Unless one has a case as dramatic as the year of the fire horse, these strategies are essential for building support for a causal inference.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#regression-discontinuity-designs",
    "href": "extracted/Counterfactuals and Causal Inference.html#regression-discontinuity-designs",
    "title": "Counterfaturals and Causal Inference",
    "section": "11.2 Regression Discontinuity Designs",
    "text": "11.2 Regression Discontinuity Designs\nA regression discontinuity (RD) design is very similar to an ITS design, except that\nthe treatment assignment pattern is a function of the values of a variable rather than the passageof time. An RD design is especially appropriate in situations where treat- ment assignment is sharply discontinuous in the values of a variable, and it has been appliedtoavarietyofproblems:theeffectofstudentscholarshipsoncareeraspirations (ThistlewaiteandCampbell1960),theeffectofunemploymentbenefitsforformerpris- oners on recidivism (Berk and Rauma 1983), the effect of financial aid on attendance at a particular college (Van der Klaauw 2002), the effect of class size on student test scores(AngristandLavy1999),andthewillingnessofparentstopayforbetterschools (Black 1999).\nCampbell wasthe firsttoproposethe RDdesign(see Shadishetal.2001;Trochim 1984), but it has evolved considerably since then (see Bloom 2012; Hahn, Todd, and VanderKlaauw2001;ImbensandLemieux2008).Itismosteasilyunderstoodwithan example. Herewe considerthe example ofMarkandMellor (1991),whichis discussed alsoby Shadishet al. (2001).MarkandMellorwere interestedin examiningthe effect thataneventofhighpersonalrelevancemayhaveonhindsightbias–theclaimthatan eventwasforeseeableafteritoccurred.Selectingallmembersofalargemanufacturing union, they examined the specific effect of being laid off from work on retrospective High 3.00 2.75 2.50 snaeM 2.25 thgiseroF 2.00 1.75 1.50 1.25 Low 1.00 5 8 11 14 17 20 23 28 29 32 35 38 Laid-off Survivors Years of Job Seniority Figure11.3 Foreseeability of a layoff as an example of an RD design.\nSource: Mark and Mellor (1991), figure 1.\nforesight claims (measured as agreement with statements such as “I saw it coming all the way”). The study took place just after workers with fewer than 20 years of senioritywerelaidoff.Figure11.3showstherelationshipsbetweenretrospectiveclaims of foresight and both layoff status and seniority.\nAs shown inFigure 11.3, there is an abrupt discontinuity in the relationship between retrospective foresight claims and seniority at the point in seniority where individuals were laid off. All workers, regardless of whether they were laid off, were asked whether they had expected the layoffs that occurred among union members.\nThose who were not laid off (i.e., individuals with 20 or more years of seniority) were on average more likely to claim that the layoffs in the union were expected, even though they were not themselves laid off. At the same time, those who were laid off were less likely to claim that the layoffs were expected. Notice also that the associa- tionbetweenseniorityandretrospectiveclaimsofforesightisinthe oppositedirection of the estimated treatment effect: Individuals with more seniority were less likely to claimthatthelayoffswereexpected,evenamongthosewhoweresubsequentlylaidoff.\nBecause the layoff effect and the underlying seniority association are in the opposite directions,MarkandMellorhadstrongevidencethatbeinglaidoffdecreasedthelike- lihoodthat anindividual who waslaid offwouldclaim that the layoffswere expected.\nThis finding strengthened their overallinterpretation that the personal relevance of a negativeeventdecreasesthelikelihoodthatanindividualwillclaimthattheeventwas expected.Theyconcludedthatthispatternreflectsatypeofself-protection,according to which individuals seek to avoidblaming themselves for not having been sufficiently prepared to mitigate the negative consequences of an event.\nU U D Y f(Z) Y D Z Figure 11.4 An example of a fuzzy RD design.\nIngeneral,anRDmodelcanbeestimatedinthesamewayasanITSmodelbecause mostofthesameissuesapply.OnekeyandhelpfuldifferenceisthatinmostRDdesigns individualsaresampledindependently.Asaresult,the problemofcorrelatederrorsin an ITS design is absent in an RD design.\nA generalization of the RD design, known as the fuzzy RD design, has received recentattention.3Here,thetreatmentvariableisafunctionofanassignmentprocessin whichthereiserrorthatisassociatedwithY.ConsiderthegraphinFigure11.4,where f(Z)representstheintendedassignmentruletoD asafunctioninZ.However,inthis case the assignment is imperfect in the specific sense that the other determinants of assignment,UD,cannotbeassumedtobeindependentoftheunobserveddeterminants of Y, UY. Instead, UD and UY are assumed to be determined by common causes represented by the dashed, bidirected edge in UD(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)UY.\nFor fuzzy RD design, the assignmentrule is notdeterministic because D is a func- tion of both f(Z) and UD, and, furthermore, because UD and UY are determined by commoncauses.ForafuzzyRDanalysis,theinvestigatorconditionsonZ sothatf(Z) can then be used as an instrument for D (because it is mean-independent of both UD and UY and affects Y only through D).4 Conditioning on Z is necessary to eliminate the back-door path f(Z)←Z→Y in order to establish f(Z) as a valid IV; see our prior discussion of conditional IVs in relation to Figure 9.2(b). A fuzzy RD analysis is possible only if f(Z) is some nonlinear function of Z, so that f(Z) and Z are not linearly dependent.\nAngrist and Lavy (1999) use the fuzzy RD design to study the effects of class size on student test performance in Israel. In the Israeli public school system during the period of their study, an additional class was added to a grade within a school when theexistingclassescrossedathresholdsizeof40studentsinresponsetoanincreasein theoverallschoolenrollment.Thispolicycreatedadiscontinuityinthedistributionof classsizes,whichallowedAngristandLavytocreateanonlinearfunctionofenrollment that couldthen be used asaninstrument for classsize.They found that classsize has 3Another type ofgeneralization is towardthe consideration ofmultipleassignment variables(see Wong, Steiner,andCook2013).\n4Thesituationisdirectlyanalogoustoanexperimentwithnoncomplianceinwhichnoncompliance is thought to be nonrandom. As Imbens and Rubin (1997) show, one can deal with noncompliance bytreatingtheintention-to-treat indicatorasaninstrument,Z,fortheactualtreatment, D.\na substantial effect on test performance for fourth and fifth graders, but not for third graders.\nAs shown by these examples, RD designs are simple and can be convincing. But thesameweaknessesofITSdesignsarepresent.Counterfactualvaluesmustbeextrap- olated from observed data below and above the value that triggers the introduction of the treatment. If the assumptions built into the chosen method of extrapolation are unreasonable, then causal effect estimates will be incorrect. Caughey and Sekhon (2011) present a critique of RD analyses where adoption of the assumptions requires substantialadditionalconditioning,preciselyofthesortthatRDdesignsaremeantto avoid. In other cases, where the assumptions are reasonable, RD designs can be very powerful (see Berk, Barnes, Ahlman, and Kurtz 2010; Shadish, Galindo, Wong et al.\n2011).",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#panel-data",
    "href": "extracted/Counterfactuals and Causal Inference.html#panel-data",
    "title": "Counterfaturals and Causal Inference",
    "section": "11.3 Panel Data",
    "text": "11.3 Panel Data\nA severe limitation of time series data is that we have data on only a single unit over\ntime. Because we do not observethe treated unit of analysis in the control state after the treatment is introduced, the only way to estimate the counterfactual outcome is to assumethatthe future canbe predicted accuratelyfromthe past.This assumption is generally untestable.\nPanel data, where multiple individuals or units are observed over time, may solve this problem. Assuming that each individual’s time series is relatively long, separate ITSanalysescouldbeconductedforeachindividualandthenpooledtoformanaverage causaleffectestimate.Moreover,becauseindividualsreceivethetreatmentatdifferent times or do not receive the treatment at all, it is possible to observe how Y0 changes t overtime for someindividuals after othershavereceivedthe treatment.To the degree thatY0 evolvessimilarlyovertimeforindividualsinthetreatmentandcontrolgroups, t it may be possible to make reasonable predictions about the counterfactual values of Y0 for individuals in the treatment group after they are exposed to the treatment.\nt Fortheremainderofthischapter,wewilladoptthepaneldatanotationintroduced in Section 2.8.2 to differentiate between quantities that vary only over individuals (subscriptedbyi),quantitiesthatvaryonlyovertime(subscriptedbyt),andquantities thatvaryoverindividualsandtime(subscriptedbyit).Inmostcases,thesubscripting for i is redundant and is utilized only for additional clarity. For example, in prior chapters,we haverepresentedthe averagetreatmenteffect(ATE)as E[δ], recognizing that the argument of the expectation, δ, can be regarded as a random variable that takes on values that vary across individuals, which we specified was possible when definingtheindividual-levelcausaleffectasδi=y i1−y i0.Ournotationintheremainder of this chapter requires that we write the same time-constant ATE as E[δi], because foratime-varyingATE,wewouldinsteadneedtosubscriptfortaswell,writingE[δit].\nAs explained in Section 2.8.2, we will distinguish between two different treatment indicatorvariables:Dit is a time-varyingdummy variablethatindicates whether indi- vidual i receives the treatment in time period t, and D∗ is a time-constant dummy i variable that indicates whether individual i ever receives the treatment at any point in the time span under study. Dit is best thought of as a treatment exposure indi- cator variable, and D∗ is best thought of as a treatment group indicator variable.\ni Observed and potential outcomes are related to each other by time-specific relations, Yit =DitY i1 +(1−Dit)Y i0 t, where Y i1 t, Y i0 t, and Dit all vary over i and t. Finally, t individual-leveltreatmenteffectsvaryintime,suchthatδit=y i1 t−y i0 tforallt.Asnoted above,theATEisnowlikewisetime-specificandcanbewrittenasE[δit]=E[Y i1 t−Y i0 t].\nThe average treatment effect for the treated (ATT) and the average treatment effect for the controls (ATC), and any other conditional average treatment effect one might be interested in estimating, are defined analogously.\n11.3.1 Traditional Adjustment Strategies Themostcommonsituationinpaneldataanalysisconsistsofnonequivalenttreatment and control groups and two periods of data, where the first wave of data is from pretreatment time period t−1 and the second wave of data is from posttreatment timeperiodt.Suchtwo-period,pretreatment-posttreatmentpaneldataaresometimes thought to be a panacea for not having a randomized experiment. Typically, it is assumedthatchangesovertimeinthecontrolgroupcanbeusedtoadjustthechanges observed for the treatment group, with the net change then representing a consistent and unbiased estimate of the causal effect of the treatment.\nUnfortunately, the situation is far more complicated. There are aninfinite number of ways to adjust for differences in gains between the treatment and control groups, and alternative methods of adjustment give estimates that sometimes differ dramati- cally. Specifically, as we will show in this section,by choosing a particular adjustment technique when analyzingtwo-period,pretreatment-posttreatmentdata, any estimate that a researcher may want can be obtained.\nConsider the two most common methods, usually referred to as change score and analysis of covariance models. The change score model is often referred to as a panel data variantof a difference-in-difference model, especially in the economics literature; seeImbensandWooldridge(2009).Thesetwomodelsareequivalenttoestimatingthe following two equations with least squares regression: Change score: Yit−Yit−1=a+D i∗ c+ei, (11.4) ∗ Analysis of covariance: Yit=a+Yit−1b+D ic+ei. (11.5) These two equations provide different means of adjustment for Yit−1. In the change score model, one adjusts Yit by subtracting out Yit−1. For the analysis of covariance model,oneadjustsYit byregressingitonYit−1.5Recallthatweintroducedtheanalysis of covariance model already in Panel Data Demonstration 1 (see page 273), where we considered its utility when analyzing posttreatment-only data.\n5Also,itbearsmentioningthatwhenwepresentalternativeequations,suchasEquations(11.4)and (11.5)inthischapter,wegivegenericnotation–suchasa,b,andc–toregressionparameters,such asinterceptsandtreatmenteffectestimates.Wedothesame,ingeneral,forregressionresiduals,and soon.Wedonotmeantoimplythatsuchquantitiesareequalacrossequations,butitiscumbersome tointroducedistinctnotation foreachcoefficientacrossequations tomakesurethatweneverimply equalitybyreusinggenericcharacters suchasa,b,c,ande.\nConsider now an example that shows how these two models can yield different results with pretreatment-posttreatment data. After decades of studying the environ- mentalandgeneticdeterminantsofintelligence,considerablecontroversyremainsover theirrelativeeffectsonlifecourseoutcomes.AsdiscussedinDevlin,Fienberg,Resnick, and Roeder (1997) and other similar collections, these debates resurfaced after the publication of The Bell Curve: Intelligence and Class Structure in American Life by HerrnsteinandMurrayin1994.Eventhoughexistingreviewsoftheliteratureempha- sizedthe malleabilityofIQ(see Ceci1991),HerrnsteinandMurrayconcludedintheir widely read book: Taken together, the story of attempts to raise intelligence is one of high hopes, flamboyant claims, and disappointing results. For the foreseeable future, the problems of low cognitive ability are not going to be solved by outside interventions to make children smarter. (Herrnstein and Murray 1994:389) As discussed in Winship and Korenman (1997), the weight of evidence supports the claim that education determines measured intelligence to some degree, even though debate remains on how best to measure intelligence.\nConsidernowaveryspecificquestionassociatedwiththiscontroversy:Whatisthe causaleffectofatwelfthyearofeducationonmeasuredIQ?Thefollowingresults,based ondatafromtheNationalLongitudinalSurveyofYouth,showhowdifferenttheresults fromchangescoreandanalysisofcovariancemodelscanbe(seeWinshipandWinship 2013for additionaldetails). For both models, IQ is measuredbefore the twelfth grade for all individuals who meet various analysis-sample criteria (N =1,354). IQ is then measured after high school completion, and high school completion is designated the treatment variable. A change score model yields a treatment effect estimate of 1.318 (witha standarderrorof.241)andananalysisofcovariancemodel yields atreatment effect estimate of 2.323 (with a standard error of .217).6 These estimates are quite different: The analysis of covariance model suggests that the effect of a twelfth year of schooling on IQ is 76 percent larger than that of the change score model (i.e., [2.323−1.318]/1.318). Which estimate should one use? Before we discuss how (and if) one canchoosebetween these two types oftraditional adjustment, considera more general, but still simple, hypothetical example.\nPanel Data Demonstration 2 For this demonstration, we will again consider the Catholic school effect analyzed by Coleman and his colleagues. Departing from the setup of Panel Data Demonstration 1 (see page 273), in this demonstration we will consider how alternative estimators perform assuming a world in which (1) no Catholic elementary schools or middle 6For completeness, we report additional features of these models here. Each was estimated with three other covariates: age, year of the test, and a standardized measure of socioeconomic status.\nThe coefficients on these three variables were −.18, −.76, and −.43 for the change score model and −.97,−.50,and2.05fortheanalysisofcovariancemodel.TheR2 was.06forthechangescoremodel and .68 for the analysis of covariance model, inwhich the lag coefficient on IQ in the twelfth grade was.62.\nschools exist, (2) all students consider entering either public or Catholic high schools after the end of the eighth grade, and (3) a pretreatment achievement test score is availablefortheeighthgrade.Suchaworlddoesnotexist,because(1)and(2)arenot true (and, furthermore, Coleman and colleagues were not fortunate enough to have (3) either). We offer a demonstration assuming such a world for didactic purposes.\nBasic Setup. AsforPanelDataDemonstration1,wewillconsideronlylinearspeci- ficationsand,exceptwhenotherwisedetailed,restrictallcausaleffectstobeconstants or to vary acrossindividuals in completely randomwaysindependent of allelse in the models. This setup gives traditional panel data regression estimators the best chance of succeeding. Even so, recall that we showed through demonstrations in Chapters 5, 6, and 7 that least squares regression estimators invoke implicit weighting that is unlikely to effectively deal with the nonrandom individual-level heterogeneity of the Catholic school effect on achievement. We hold these additional complications aside in this demonstration in order to focus narrowly on the potential value of traditional panel data estimators of causal effects.\nThe potential outcome variables are Y1 and Y0, where now t={8,9,10} for the it it threegradesthatoccurduringtheassumedobservationwindowfromtheeighthgrade through the tenth grade. Because treatment selection occurs before t=9, we have observeddataonlyforonepretreatmenttimeperiod,andwewillassumethatColeman and his colleagues had the tenth grade data as well (and that no data were collected in the ninth grade). The treatment group indicator variable, D∗, is equal to 1 if the i student enrolls in a Catholic high school and 0 if the student enrolls in a public high school.\nThe observed outcome variable, Yit, is defined with reference to the time-specific treatmentexposureindicatorvariable,Dit.BecausenoonecanbeexposedtoCatholic schoolsinthe eighthgrade(i.e.,we haveassumedthatCatholicmiddle schoolsdo not exist for this demonstration), Di8=0 for all students. As a result, Yi8=Y i0 for all 8 students, and the eighth grade test score is therefore a pretreatmentoutcome that we observe for all students. However, for t={9,10} the observable outcome is equal to the relevant potential outcome defined by our usual definition: DitY i1 t+(1−Dit)Y i0 t.\nWe will assume that those observed to be in Catholic or public schools in the tenth grade were in the same type of school in the ninth grade as well. Accordingly, for this demonstration, D i∗ =Di10, and the definition of the observed outcome in the tenth grade can be written either as Yi10 =Di10Y i1 10+(1−Di10)Y i0 or as Yi10 = 10 D∗Y1 +(1−D∗)Y0 .7 i i10 i i10 Figure 11.5 presents a directed graph for the core features of this demonstration, which we will elaborate below when introducing alternative patterns of treatment selection. The graph has the same basic structure as Figure 8.2, but the first achieve- menttest(nowY )isapretreatmentoutcome,whilethesecondachievementtest(now 8 Y ) is a posttreatment outcome. We are interested in estimating the effect of D on 10 Y , as in the research of Coleman and his colleagues. In comparison to Panel Data 10 7Asistypicalinthistypeofanalysis,studentswhoswitchtreatmentsbetweentheninthandtenth grades receive no special consideration because we do not observe their type of school enrollment in the ninth grade. See the appendix to this chapter, where we introduce the literature on dynamic treatmentregimesthatattemptstomodelallcombinationsoftheeffectsoftime-varyingtreatments.\nX Y 8 E Y O 10 U D Figure11.5 A directed graph for the effect of Catholic schooling on tenth grade achievement when a measure of eighth grade achievement is also available.\nDemonstration 1, we have more reason to be optimistic. We can compare posttreat- ment outcomes for the Catholic school students to their pretreatmentoutcomes when inpublic schoolsandalsoto theoutcomesofstudentsenrolledinpublic schoolsinthe posttreatment time period.\nFor simplicity, our other variables O, X, and U are specified as indices of many underlyingvariables,whichweagainscaleasnormallydistributedcompositevariables.\nX isacompositedeterminantofachievementtestscoresinallyearsthathasnodirect effect on whether students select Catholic schooling. U is a composite variable of unobserved factors that determine both Catholic school attendance and achievement tests in all years. O is a composite variable of ultimate background factors that has effects on U and X, as well as direct effects on Catholic school attendance and test scoresinallyears.Togivethesecompositevariablesdistributionsthatarefamiliarand that align with their counterparts for Panel Data Demonstration 1, O is a standard normal random variable with mean of 0 and variance of 1. Having defined O as an exogenous root variable, we then set X=O+eX and U =O+eU, where eX and eU are independent standard normal random variables with mean of 0 and variance of 1. Finally, E is a normal random variable with mean of 0 and variance of 1 that is a common cause of test scores in all years and is independent of all else in the graph.\nScenarios for Analysis. We will consider eight separate scenarios, defined as a cross-classification of two patterns of between-group differences in the trajectories of outcomes (parallel or divergent trajectories) and four treatment selection patterns (no-self-selection, self-selection on the individual-specific treatment effect, positive selection on the pretreatment outcome, and negative selection on the pretreatment outcome). For the four parallel-trajectoryscenarios, Y0 is defined as it Y i0 8=98+Oi+Ui+Xi+Ei+υ i0 8, (11.6) Y i0 9=99+Oi+Ui+Xi+Ei+υ i0 9, Y i0 10=100+Oi+Ui+Xi+Ei+υ i0 10, where the υ0 terms are values from independent normal random variables with mean it of0andvarianceof10.Onaverage,Y0 followsalineartimepathasdeterminedbythe it intercept values of 98, 99, and 100.8 However, the levels of these potential outcomes for individuals aresetby the time-invariantvalues ofOi, Ui,Xi, andEi, aswell as by time-specific shocks to their outcomes, υ0.\nit To specify a treatment effect that increases in time, Y1 is defined as it Y1=Y0+δ(cid:2) +δ(cid:2)(cid:2) , (11.7) i9 i9 i i Y1 =Y0 +(1+δ(cid:2) )+δ(cid:2)(cid:2) , i10 i10 i i where δ(cid:2) is a baseline individual-level treatment effect, specified as values for each i individual from a normal random variable with mean of 9 and variance of 1. The values of δ(cid:2)(cid:2) are a separate source of individual-level variation in the treatment effect, i specified as values for each individual from a normal random variable with mean of 0 andvarianceof1.Intheno-self-selectionscenarios,δ(cid:2)(cid:2) isadditionalrandomindividual- i level variation. In the scenarios that specify self-selection on the treatment effect, δ(cid:2)(cid:2) i will be an input into treatment selection decisions, as explained below.9 For the four divergent-trajectoryscenarios,we specify group-specificintercepts for Equation(11.6)sothatthetrajectoryofE[Y0]differsacrossthetreatmentandcontrol it groups after the onset of treatment. For the treatment group (D∗=1), the intercepts i are specified as 98 for t=8 and 99 for t=9, but then 100.5 for t=10. For the control group (D∗=0), the intercepts are specified also as 98 for t=8 and 99 for t=9, but i then only 99.5 for t=10. Taken together, by the end of the observation window in the tenth grade, the treatment group’s value for E[Y0 ] is higher by 1 than for the i10 control group (i.e., 100.5−99.5=1). For this “fan spread” pattern, in the absence of treatmentthetestscoresofthoseinthetreatmentgroupincreasefasteraftertheonset oftreatmentthan the test scoresof thosein the control.Inother words,students who select into Catholic schools would have had a boost in achievement even if they had remained in public schools, net of all other determinants of Y0 in Equation (11.6).10 it We consider four types of treatment selection. For the first, treatment selection is on fixed characteristics of individuals unrelated in any way to the outcomes before or after the treatment. Accordingly, the probability of Catholic school enrollment is specified as a logistic distribution 1+ex ep x( p− (−3. 38 .+ 8+Oi O+ i+Ui U) Pr[D i∗ =1|Oi,Ui]= i), (11.8) 8To mimic real data, the intercept values such as 98, 99, and 100 in this demonstration will always be expected values of individual-specific intercepts, where the variation in the intercepts is independentofallelseontheright-handsidesoftherelevantequations.Wesuppressthisfactinthe maintextforsimplicityofexposition.Tobeprecise,wesetupindividual-specifictimetrendsiny i0 tby specifyingindividual-specificmultipliers(fromuniformdistributionswithstrictlypositiveprobability andmeanof1),whichwethenapplytothecommontimetrendsthatdefinetheexpectationsE[Y i0 t], sometimesdifferentiallywithrespecttoD∗.\ni 9Y i1 8 iscounterfactual forallindividuals,andweexcludeitfromEquation(11.7)becausewehave assumed for this demonstration that Catholic middleschools do not exist. Explicitlyallowing for it wouldsuggestotherwise.\n10Wetakenopositiononwhyfanspreadoccurs,althoughinthisdemonstrationitisequivalentto assumingthatanothervariable,Q,existsthatgeneratesthispatternbystructuringY0 ininteraction it with D∗ after the onset of treatment. In many situations in education research, it is assumed that i fanspreadexistsbecauselearningisacumulativeprocess.Weconsiderthistypeofthinkinglaterin thischapter,whenconsideringdynamicscenarioswhereY it isstructureddirectlybyitspriorvalues.\nwhere Oi and Ui are as defined above. As in prior demonstrations, the probabilities defined by Equation (11.8) are then set as the parameters for draws from a binomial distribution, yielding the indicator variable D∗ for Catholic schooling defined above.\ni For the second type of treatment selection, we introduce self-selection on the individual-specific treatment effect, assuming that students and their parents are able to forecast and then choose based on accurate beliefs about how much they wouldbenefit fromattendingaCatholicschool.The treatmentselectionprobabilityis specified as 1+ex ep x( p− (−7. 73 .+ 3+Oi O+ i+Ui U+ i+5δ 5i(cid:2)(cid:2) δ) Pr[D i∗ =1|Oi,Ui]= i(cid:2)(cid:2)), (11.9) where δ(cid:2)(cid:2) is as defined above. For the directed graph in Figure 11.5, this type of self- i selection is equivalent to adding an additional bidirected edge, D(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)Y .11 10 For the final two types of treatment selection, we specify the treatment selection probability as Pr[D i∗ =1|Oi,Ui]= 1+ex ep x( p− (−3. 38 .+ 8+Oi O+ i+Ui U+ i+k( kY (i Y8 i− 8−E E[Y [i Y8] i) 8) ])), (11.10) where (Yi8−E[Yi8]) is the individual deviation from the expectation of the pretreat- ment test. These individual-level values are scaled by k, which is set to either .05 or −.05.Forthepositivevalueofk,studentsandtheirparentsareselectingthetreatment assuming that those with higher pretreatment test scores will be the most likely to benefit from Catholic schooling, perhaps because they believe that Catholic schools haveamorechallengingcurriculumfromwhichonlyhighachieverswillbenefit.Forthe negativevalueofk,theyareassumingtheopposite,perhapsbecausetheybelievethat Catholic schools can compensate for lower achievement in the past. For the directed graphinFigure11.5,this type ofselectionis equivalenttoadding anadditionaldirect causal effect, Y →D.\n8 ResultsfromTraditionalPanelDataEstimators. Considerfirstthefourparallel- trajectoryscenariosinthefirstpanelofTable11.1.Forthefirstcolumn,selectionpat- ternsaresimple andbasedonlyonthe fixedcharacteristicsofindividuals, as specified aboveinEquation(11.8). The trueATE is10.00,whichis equaltothe ATT andATC by construction.\nFor this scenario, the naive estimator yields 14.75 (on average across repeated samples),andthis valueis upwardlybiasedbecauseO andU arepositivelyassociated with both D and Y . We could use a cross-sectional estimator to block the back- 10 door paths through the observed characteristics of individuals, O, which are shown in Figure 11.5. Unfortunately, the unobserved variable U generates a back-door path D←U→Y that remains unblocked after conditioning on O.\n10 Can traditional panel data estimators solve this problem? The change score esti- mator yields a value of 10.00, which is equal to the true ATE, ATT, and ATC. In 11Or,aswiththecharterschoolexampleinSection8.3,wecouldaddafullyelaboratedback-door path using latent classes and attempting to capture the inputs into the self-selection decision itself (seeFigures8.5through8.7).\nTable 11.1 Change Score and Analysis of Covariance Estimates of the Catholic School Effect in the Tenth Grade Setupconditions: Self-selection on thecausal effect No Yes No No Positive self-selection on thepretest No No Yes No Negative self-selection on the pretest No No No Yes Parallel Trajectories Trueaverage treatment effects: ATE 10.00 10.00 10.00 10.00 ATT 10.00 11.51 10.00 10.00 ATC 10.00 9.83 10.00 10.00 Estimated coefficients for D∗: Naiveestimator: Regression of Y 10 on D∗ 14.75 13.86 15.92 13.25 Change score estimator: Regression of (Y 10−Y 8) on D∗ 10.00 11.51 7.96 12.26 Analysis of covariance estimator: Regression of Y 10 on D∗, Y 8, O, and X 10.51 11.75 10.49 10.52 Divergent Trajectories Trueaverage treatment effects: ATE 10.00 10.00 10.00 10.00 ATT 10.00 11.51 10.00 10.00 ATC 10.00 9.83 10.00 10.00 Estimated coefficients for D∗: Naiveestimator: Regression of Y 10 on D∗ 15.75 14.86 16.88 14.30 Change score estimator: Regression of (Y 10−Y 8) on D∗ 11.00 12.51 8.92 13.31 Analysis of covariance estimator: Regression of Y 10 on D∗, Y 8, O, and X 11.52 12.75 11.50 11.53 contrast, the analysis of covariance estimator instead yields a value of 10.51, which is upwardly biased for the ATE, ATT, and ATC. The bias is smaller than for the naive estimator because conditioning on O has removed some of the back-door confound- ing.12 We know that 10.00 is the correct answer and therefore can favor the estimate from the change score model. If we did not know the correct answer ahead of time and/orwereuncertainaboutthecorrectdirectedgraphforthe generationofthedata, 12Atthesametime,itisunclearfromtheseresultswhatthetotalconsequencesareofconditioning furtheronXandY 8.Thelatterisacolliderthat,whenconditionedon,inducesaback-doorassociation between D andY 10 byunblockingthepathD←U→Y 8←E→Y 10.Noticethatconditioning onY 8 wouldalsounblockotherback-doorpathsinthegraph,butalloftheseremainblockedbysimultaneous conditioningonO andX.\nwe would have a hard time picking between these two estimates. Before offering an explanation for this result, it is helpful to consider the next scenario for comparison.\nThe second column of the first panel presents the same results for the scenario where treatment selection is on fixed characteristics as well as on the causal effect itself, as specified above in Equation (11.9). As with past demonstrations, the true ATT is now greater than both the ATE and the ATC. The naive estimator is again upwardly biased for the ATE, ATT, and ATC. The analysis of covariance estimator is also upwardly biased for all three. In contrast, the change score model yields an estimate of 11.51, which is equal to the ATT, but not to the ATE or to the ATC.\nTakentogether,thefirsttwocolumnssuggestthatthechangescoreestimatoryields valuesthatwillonaverageequaltheATT. Whenself-selectionisabsent,theATTwill equal the ATE and the ATC, and as a result a consistent and unbiased estimate of the ATT will also be a consistent and unbiased estimate of the ATE and the ATC.\nWe will explain this result more formally following this demonstration. The core of the explanation is that the change score model subtracts out the effects of all fixed characteristics – observed and unobserved – and can then generate a consistent and unbiasedestimateoftheATTinscenariossuchasthesetwo.Ifoneiswillingtoassume that no self-selection on the causal effect is present, as is the case for the scenario in the firstcolumn, then this estimate ofthe ATT is alsoconsistentandunbiasedfor the ATE and ATC.\nThese resultsmay suggestthatthe changescoremodelis mostcommonlythe best choiceforthesesituations,andonemightalsobeencouragedthateveninthepresence of self-selection it can be used to effectively estimate the ATT. The third and fourth columns were constructed to temper any such enthusiasm. For these two columns, individuals do not self-select on the treatment effect itself, and thus the ATE, ATT, and ATC are all equal. However,treatment selection is on the pretreatmentoutcome, as specified by Equation (11.10), where individuals choose Catholic schooling either as a positive or negative function of the eighth grade test score.\nFor the third and fourth columns of the first panel, the naive estimator is again upwardly biased for the ATE, ATT, and ATC. More important for our considera- tion, the change score model now yields values that are either too small or too large, depending on whether selection is a positive or negative function in the eighth grade test score. In fact, the estimates yielded by the analysis of covariance model are on averagemuch closerto the ATE, ATT, and ATC. In these scenarios,the change score modelcontinuestogenerateestimatesbasedonaveragedifferencesbetweeneighthand tenth grade tests scores within the treatment group, but the average of these differ- ences is no longer a consistent or unbiased estimate of the ATT. If the distribution of the individual-level treatment effects does not vary across the treatment and control groups,the averagedifference,Yi10−Yi8, withinthetreatmentgroupwill betoosmall if those with high values for Yi8 select into Catholic schooling and will be too large if those with low values of Yi8 select into Catholic schooling. The analysis of covariance estimator offers a less extreme adjustment for the eighth grade test score and is thus closer to the true ATE, ATT, and ATC. Nonetheless, the analysis of covariance esti- matorgeneratesvaluesthatdonotequalthetargetparameters,andthissuggeststhat theadjustmentmaynotbecorrect,whichwewillexplainbelowisusuallythecase(i.e., except in the very rare case that the estimated regression coefficient exactly adjusts for a regression to the mean effect that is generated by the behavior of individuals).\nThe second panel of Table 11.1 presents four scenarios for diverging trajectories of Y0, using the same four patterns of treatment selection. The true ATE, ATT, and it ATC are all the same as for the first panel because the underlying fan spread in the potential outcomes only applies to the potential outcome in the control state in the tenth grade, Y0 . The treatment effect continues to be defined by Equation (11.7), i10 which does not vary across the scenarios for parallel and divergent trajectories. To focus on this key point, recall from our discussion above that even for this set of scenariosthe trajectoriesofthe potential outcomeare the same forthe treatmentand control groups from t=8 to t=9 because E[Y0|D∗ =1]−E[Y0|D∗ =0]=98−98=0 i8 i i8 i and E[Y0|D∗ =1]−E[Y0|D∗ =0]=99−99=0.\ni9 i i9 i The difference of 1 emerges between t=9 and t=10 because we specified that E[Y0 |D∗ =1]−E[Y0 |D∗ =0]=100.5−99.5=1.\ni10 i i10 i These divergent trajectories are inconsequential for the true ATE, ATT, and ATC because these target parameters continue to be structured in the same way for both groups. More specifically, the term (1+δ(cid:2))+δ(cid:2)(cid:2) in Equation (11.7) does not vary by i i group.\nConsider the first column in the second panel, which is for the treatment selec- tion pattern where selection is on the fixed characteristics of individuals, Oi and Ui.\nAs was the case for the parallel-trajectory scenarios, the naive estimator and analy- sis of covariance estimator yield values that are too large. Now, however, the change scoreestimatorfailsaswell.ThechangescoreestimatoryieldsacoefficientonD∗ that is equal to 11, assuming an infinite sample (or averaged over repeated samples). In particular, with reference to Equation (11.4), it yields Yi10−Yi8=aˆ+D i∗ cˆ ∗ =1.5+D 11.\ni As we explain in the next section, the intercept is equal to aˆ=E[Y0 |D∗ =0]−E[Y0|D∗ =0] i10 i i8 i =E[Yi10|D i∗ =0]−E[Yi8|D i∗ =0] =99.5−98, whichis the difference in the observedoutcome in the absence of treatmentfor public school students. In addition, the treatment effect estimate is equal to (cid:27) (cid:28) (cid:27) (cid:28) cˆ= E[Y1 |D∗ =1]−E[Y0|D∗ =1] − E[Y0 |D∗ =0]−E[Y0|D∗ =0] i10 i i8 i i10 i i8 i ={E[Yi10|D i∗ =1]−E[Yi8|D i∗ =1]}−{E[Yi10|D i∗ =0]−E[Yi8|D i∗ =0]} ={110.5−98}−{99.5−98}, which is the expected gain in the observed outcome for the students who enrolled in Catholicschoolsminustheexpectedgainintheobservedoutcomeforthestudentswho remained in public schools. The change score estimator delivers an upwardly biased estimate because it assumes implicitly (but incorrectly) that the observed average gain among public school students in test scores between the eighth and tenth grades is the same gainthat those whoenter Catholic schoolswouldhaveexperiencedif they had instead remained in public schools. This assumption was correct for the parallel- trajectory scenario presented in the first panel of Table 11.1, but it is incorrect, by construction, for the scenarios we are considering now. For our divergent-trajectory scenarios, we have set the (counterfactual) gain to be equal to 2.5 for the treatment group and the factual and observed gain to be 1.5 for the control group (i.e., 100.5− 98=2.5 in contrast to 99.5−98=1.5).\nFor completeness, consider the final three columns in the second panel briefly. As shown in the second column, the change score estimator remains upwardly biased for the ATT when self-selection is present, and the magnitude of the bias is exactly the same because the trajectory-induced bias is unrelated to selection on the treatment effect.Asshowninthethirdandfourthcolumns,whenselectionisonthepretreatment outcome, the change score estimator will yield values that are either too small or too largefortheATT,ATE,andATCforthesamereasonsasinthefirstpanelforparallel trajectories.Theanalysisofcovariancemodelsshowthesamebasicpatternsasforthe parallel-trajectoryscenarios.\nAltogether, this demonstration suggests that the change score estimator will offer consistent and unbiased estimates of the ATT when selection is not a function of the pretreatment outcome and when the unobserved average trajectory for the potential outcome in the absence of treatment for the treatment group is equal to the observed trajectory for the control group.13 If individuals do not self-select on the treatment effect, then the ATT will be equal to the ATE and ATC by definition; the change scoreestimatoristhereforeconsistentandunbiasedforallthree.If, however,selection is on the pretreatment outcome or the trajectories are not parallel, then the change score estimator is no longer consistent and unbiased for the ATT (or the ATC or ATE). Finally, althoughwe haveyetto fully explainedwhy, in this demonstrationthe analysis of covariance model never appears to be consistent or unbiased for any of the target parameters, even though it appears to be less sensitive to departures from 13Inthisdemonstration,theparalleltrajectoriesarealsolinear.Linearityisnotrequired.Parallelism existsifE[Y0|D∗=1]−E[Y0|D∗=0]=kforallt,wherekisanyconstantthatdoesnotvaryint.For it i it i thedemonstration, wesetk=0.Parallelisminallvaluesoftissufficient,butitisnotnecessary.As weexplainbelow,weonlyneedktobethesameforthetwotimeperiodsinwhichthepretreatment andposttreatment outcomes areobserved.\nthe parallelismofthe firstfour scenarios.The explanationfor this outcome willfollow the demonstration.\nIn conclusion, we should note four additional points. First, only because we con- structed the data for this demonstration is it clear when the change score estimator outperforms the analysis of covariance estimator. In observational research, the true values for the ATE, ATT, and ATC are unknown and thus no benchmark for com- parisonis available. Second, it is ofcoursepossible to havea situationwhere selection is a function of both the pretreatment outcome and also accurate expectations of the individual-level treatment effect. In this case, the results of the demonstration are as implied: Neither the change score estimator nor the analysis of covariance estimator would deliver estimates that are consistent or unbiased for any of the average treat- menteffects.Third,withdatafromonlytwopointsintime,thereisnowaytoevaluate whether selection is onthe pretreatmentoutcome using the observeddata.This point should be obvious from a consideration of Figure 11.5. If we add the effect Y →D 8 to the graph, we have no way to analyze the data to separate this casual effect from the associationgeneratedby the unobservedvariablein Y ←U→D. Thus, any argu- 8 ment in favor of the change score model would have to rest entirely on an argument grounded in theory or past research. Finally, if the fan spread pattern emerges in the same basic pattern considered here, where it only emerges at the same time as the treatment, analysis will be extremely difficult. However, if the trajectories differ but canbe effectively modeled as a function ofthe pretreatmentdata frommorethan one time period, then the model-based strategy we introduce in the final section of this chapter may be effective.\nReturn to the question that motivated this demonstration, where we are not in the fortunate situation of knowing the true values for the ATE, ATT, or ATC. All we havearealternativetreatmenteffectestimatessuggestedbyachangescoremodel and an analysis of covariance model. How should one choose between them? There are at least three possible ways to decide: 1. Choose the method that gives us the results we want.\n\nChoose basedon the nature of the problem. As Allison (1990)suggests:If selec- tion is based on fixed characteristics, use change score analysis. If selection is based on the dependent variable, use an analysis of covariance.\nUse the data to determine which model, if either, is appropriate(as in Heckman and Hotz 1989).\n\nWe hope that the first approach to the decision is not a serious consideration. The second is a better option, in that it at least suggests that one should begin to think throughthespecificnatureoftheproblemofinterest.Thethirdappearsmostpromis- ing, at least at face value. However, in some cases (perhaps most where these two estimators are utilized), we have data from only two points in time. This is the sit- uation for the estimate of the causal effect of a twelfth year of schooling on IQ. It is also the case for the demonstration that we have just offered. Unfortunately, with only two time periods, the data cannot be used to test whether one of the two mod- els is more appropriate. As we will explain when we discuss model-based approaches in the next section, we need at least two periods of pretreatment data in order to carryoutaninformativetest. For example,wewouldbe able toperformatestfor the demonstration above only if we also had test score data from the seventh grade.\nFor now, consider the case in which we continue to have data from only one pre- treatment time point, t−1, and one posttreatment time point, t. Suppose also that no self-selection on the individual-level treatment effect is present so that the ATT is equal to the ATE. Consider the implicit assumptions that are made if it is asserted thateitherachangescoremodelorananalysisofcovariancemodelisaconsistentand unbiased estimator of the ATT or the ATE: • Thechangescoremodelassumesthat,intheabsenceof treatment,anydifference between the expectations of the outcome for those in the treatment group and those in the control group remains constant over time. With potential outcome notation, the required assumption for two-period, pretreatment-posttreatment dataisthatE[Y0 |D∗=1]−E[Y0 |D∗=0]=kandE[Y0|D∗=1]−E[Y0|D∗= it−1 i it−1 i it i it i 0]=k, where k is the same constant in both time periods t−1 and t. The constant k can be equal to 0, as in the parallel-trajectories scenarios for Panel Data Demonstration 2. In this case, there are no differences in E[Y0] between it the treatment and control groups in time periods t−1 and t.\n• The analysis of covariance model assumes that, in the absence of treatment, any difference between the expectations of the outcome for those in the treat- ment group and those in the control group shrinks by a multiplicative factor r in each subsequent time period. An implication of this assumption is that, afterenoughtime, the analysisofcovariancemodelassumesthattherewouldbe no difference in the expected outcomes for the treatment and control groups if the treatment is not introduced. With potential outcome notation, the required assumption for two-period, pretreatment-posttreatment data is that any differ- ence E[Y0 |D∗=1]−E[Y0 |D∗=0]=k inthe pretreatmenttime periodt−1 it−1 i it−1 i isequaltoE[Y0|D∗=1]−E[Y0|D∗=0]=k×r intheposttreatmenttimeperiod it i it i t, where k is the same constant in both time periods and where r is the amount of between-group shrinkage that is assumed to occur in each and every time period. Any remaining difference between the two groups approaches 0 in the limit so that by time period t=∞, E[Y0 |D∗ =1]=E[Y0 |D∗ =0]. In it=∞ i it=∞ i addition, the analysis of covariance model assumes that r is equal, in an infi- nite sample, to the least squares coefficient on Yit−1 in a regression equation Yit =a+Yit−1b+D i∗c+ei (or Yit =a+Yit−1b+D i∗c+Xiq+ei if additional adjustment variables in Xi are also specified).\nThe key difference between these two models is therefore their implicit assumptions about the evolution of the difference between E[Y0] for the treatment group and for it the control group.\nConsiderageneralequationthatcanbeusedtorepresentthevalueofthe ATEfor the posttreatment time period t (again assuming that the ATE is equal to the ATT because no self-selection is present): (cid:29) (cid:30) E[δit]= E[Y i1 t|D i∗ =1]−E[Y i0 t−1|D i∗ =1] (cid:29) (cid:30) (11.11) −α E[Y0|D∗ =0]−E[Y0 |D∗ =0] it i it−1 i for some unknown value α.14 The term in the first set of parentheses is equal to the average difference in the observed outcome between time periods t−1 and t for the treatmentgroup.Giventhe definitionofthe observedoutcome,this differenceisequal to E[Yit|D i∗=1]−E[Yit−1|D i∗=1],whichis the observedgainin the treatmentgroup.\nThe second term is an adjustment factor. It has two pieces: an unspecified value, α, andaterminparenthesesthatisthedifferencebetweentimeperiodst−1andtinthe potential outcome in the absence of the treatment for the control group. The latter is equal to E[Yit|D i∗=0]−E[Yit−1|D i∗=0], which is the observed gain in the control group. Equation (11.11) can therefore be rewritten as E[δit]=(E[Yit|D i∗ =1]−E[Yit−1|D i∗ =1]) (11.12) −α(E[Yit|D i∗ =0]−E[Yit−1|D i∗ =0]), and its right-hand side can then be written even more simply with words as (treatment group gain in Y) − α (control group gain in Y) (11.13) Thechangescoremodelandtheanalysisofcovariancemodelcanbeseenasalternative methods that make very different and very rigid assumptions about the value of α in Equations (11.11)–(11.13). The change score model implicitly assumes that α=1. In contrast,theanalysisofcovariancemodelimplicitlyassumesthatα=r,wherer isthe intraclasscorrelationbetween Yit and Yit−1 (i.e., r is the correlationcoefficientfor Yit and Yit−1). In other contexts, this correlation coefficient r is known as the reliability of Y. If other covariates are included in the model, then the analysis of covariance model assumes that the coefficient on Yit−1 is a conditional variant of the intraclass correlation (i.e., the intraclass correlation of residualized variants of Yit and Yit−1, from which their common linear dependence on the covariates has been purged).\nResearchersoftenbelievethat,becausethecoefficientonYit−1isestimatedfromthe data,ananalysisofcovariancemodelissuperiortoachangescoremodel.Thisposition is incorrect. To be sure, an analysisof covariancemodel does estimate a coefficient on Yit−1, and this coefficient can be interpreted as an intraclass correlation coefficient.\nThis fact is irrelevant to the more fundamental issue of whether r, or a conditional variant of it, is the correct adjustment factor for generating consistent estimates of average treatment effects. In other words, if the goal is to estimate the ATE or ATT, researchers who favor the analysis of covariance model because it allows the data to 14In this section, we willconsider values for α that would be appropriate for estimating the ATE because this is the typical scenario in which researchers use change score models and analysis of covariance models. We could offer an analogous explanation for the ATT in the presence of self- selection, and here the values for α would be different if self-selection were present. The overall argumentwouldhavethesamestructurebutwouldbeginwithananalogousexpressionforE[δ it|D i∗= 1] instead of Equation (11.11). We avoid having to do this by stating above that no self-selectionis presentforthisexplanation, sothattheATEisequal totheATT.\nE[Y0] t α = 1 α &lt; 1 α &gt; 1 t Figure11.6 ExamplesofpossibletrajectoriesforE[Y0] forthe treatmentgroup(the it upper line of each pair) and the control group (the lower line of each pair) where the correct adjustment favor, α, varies.\ndeterminethecoefficientonYit−1 areassumingimplicitlythatαinEquations(11.11)– (11.13) should be equal to r, or a conditional variant of it that is determined by the relationship between Yit−1 and any covariates that are specified.\nConsider the graph presented in Figure 11.6, which presents three scenarios for changes over time in the expected value of the outcome in the absence of the treat- ment.15 For each pair of lines, the upper line is E[Y0] for the treatment group, and it the lower line is E[Y0] for the control group. For the first pair of lines, the correct it adjustment factor, α, is equal to 1. In this situation, a change score model is appro- priate. For the second pair of lines, the correct adjustment factor is less than 1. In this situation, the change score model is inappropriate, but it is conceivable that the analysisofcovariancemodel candeliveranestimatedcoefficientonYit−1 thatis equal to the correct adjustment factor. It is not guaranteed to do so because, even in an infinite sample, the coefficient on Yit−1 is simply the partial slope for the best linear predictorof Yit. Finally, this graphshows a third possibility where the correctadjust- ment factor is greater than 1. In this case, neither the change score model nor the analysis of covariance model is appropriate. Here, in the absence of treatment, E[Y0] it for the treatment group and for the control group diverge over time. There are many possible examples of this situation, but the most famous is represented by situations described in the Gospel of Matthew, where it is written, “Unto every one that hath shall be given, and he shall have abundance: but from him that hath not shall be taken away even that which he hath” (quoted in Merton 1968, who is credited with introducing this version of the idea into the social sciences).\nThe key point is that different methods of estimation make different implicit assumptions about how the difference in the expectations between the treatment and controlgroups would change with time in the absence of the treatment (which, in the 15See Judd and Kenny (1981, figure 6.4) for a similar figure and explanation that does not use potential outcomes.\ncounterfactualtradition,aredifferentassumptionsabouttreatmentandcontrolgroup differences in the evolution of E[Y0]). Researchers typically use either change score it models or analysis of covariance models without taking note of these assumptions.\nNevertheless, these assumptions canbe very consequential, as we now show in a more general way than for Panel Data Demonstration 2.\nOur claim that any assumption about α is potentially reasonable can be justified by consideration of the following model for the generation of the potential outcome variables: Y i0 t=λi+Tτi, (11.14) Y i1 t=Y i0 t+δi, (11.15) where λi is an individual-varying intercept, the variable T identifies the time period, and τi is an individual-varying coefficient on time T. For this model, the following equality holds: E[Y i0 t|D i∗ =1]−E[Y i0 t|D i∗ =0]=(E[λi|D i∗ =1]−E[λi|D i∗ =0]) (11.16) +T(E[τi|D i∗ =1]−E[τi|D i∗ =0]), wheretheT ontheright-handsideissetequaltothevalueoftinthesubscriptonthe left-hand side. Without loss of generality, assume for the moment that (E[λi|D i∗=1] −E[λi|D i∗=0])&gt;0. In this case, note that whether the initial difference in E[Y i0 t−1] betweenthoseinthetreatmentgroupandthoseinthecontrolgroupremainsthesame, grows, or shrinks, respectively, is a function of whether (E[τi|D i∗=1]−E[τi|D i∗=0]) is equal to 0, is greater than 0, or is less than 0.\nIf we assume that (E[λi|D i∗=1]−E[λi|D i∗=0])=0, then the appropriate adjust- ment factor, α, equals α=1+(E[τi|D i∗ =1]−E[τi|D i∗ =0]). (11.17) If (E[τi|D i∗=1]−E[τi|D i∗=0])=0 (i.e., E[Y i0 t] changes on average over time at the same rate for individuals in the treatment and controlgroup), then α=1 in Equation (11.17),andtheassumptionsofthechangescoremodelareappropriate.If(E[τi|D i∗=1] −E[τi|D i∗=0])=(r−1), which is necessarily nonpositive (because 0&lt;r&lt;1), then α=r inEquation(11.17),andtheassumptionsoftheanalysisofcovariancemodelare appropriate instead.\nOf course, there is no reason that (E[τi|D i∗=1]−E[τi|D i∗=0]) should necessar- ily be equal to either 0 or r−1. Thus, it is possible that neither the change score model nor the analysis of covariancemodel provides the correct adjustment. To bring this point home, consider Table 11.2, in which the stipulated true causal effect is 1. The table reports different estimates of the average treatment effect for differ- ent combinations of correct and assumed adjustment factors. Equivalently, because α=1+(E[τi|D i∗=1]−E[τi|D i∗=0]), the table reports estimates for different actual and assumed values of the difference in slopes for the treatment and control groups.\nNote first that all of the diagonal elements of Table 11.2 are equal to 1. If the assumed adjustment factor equals the correct adjustment factor, we get the correct estimate of the causal effect, 1. Below the diagonal are cases where we have overad- justed (that is, in which the assumed adjustment factor is greater than the correct Table 11.2 Estimated Average Treatment Effects for Different Combinations of Correct and Assumed Adjustment Factors, Where the True Effect Is Equal to 1 Assumed α 2 1.5 1 .5 0 2 1 1.5 2 2.5 3 1.5 .5 1 1.5 2 2.5 Correct α 1 0 .5 1 1.5 2 .5 −.5 0 .5 1 1.5 0 −1 −.5 0 .5 1 one). As a result, we get estimates of the causal effect that are too low, ranging from .5 to −1, including an estimate of no effect at all. Above the diagonal, we have cases where we have underadjusted (that is, the assumed adjustment factor is smaller than the correct one). As a result, our estimates of the causal effect are too high, ranging from 1.5 to 3.\nFor this example, the true average treatment effect is 1 by construction. Across Table11.2,wehaveestimatesrangingfrom−1to3.Wecouldeasilyexpandtherange of these estimates by considering a broader range of correct and assumed adjustment factors.And alternative examples couldbe developedin which the true averagetreat- menteffectequalsalternativevalues,andinwhichtherangeofestimatesvariesjustas widely. Although the calculations behind Table 11.2 are simple, the point of the table is to show that one can obtain any estimate of an averagetreatment effect by making different assumptions about the appropriate adjustment factor.16 Inviewofthisproblem,whatshouldaresearcherdo?Iftherearestrongtheoretical reasons for arguing that a particular adjustment factor is correct, and others agree, then analysisis straightforward.If not, which we suspect is generallythe case,then it may be possible to argue for a range of adjustment factors. In this case, a researcher may be able to bound the causal effect to a regionon which all researcherscan agree.\nIn general, the assumption that a particular adjustment factor is correct must be based on a set of assumptions about how E[Y0] for those in the treatment and it control groups evolves over time. This leads naturally to a more explicit model-based approach, which we present in the next section. As we will also see, with data from more than one pretreatment time period, it may be possible to test the adequacy of the assumptions and thus the appropriateness of a particular adjustment factor.\n16RecallPanelDataDemonstration2.There,thedivergent-trajectoryscenariowithnoself-selection yieldedachangescoreestimatethatwasbiasedupwardby1.Adoptingthelogicofthisexplanation, the correct adjustment factor was 5/3, so that (110.5−98)−(5/3)(99.5−98)=10. However, the changescoreestimatorassumedthatthecorrectadjustmentfactorwas1,resultingin(110.5−98)− (1)(99.5−98)=11.\n11.3.2 Model-Based Approaches Indiscussingpaneldatamodelswehaveuntilnowconsideredonlytraditionalmethods of estimating a causal effect. There is, however, much merit to considering explicit models of the evolution of Y1 and Y0 and asking, “Under what model assumptions it it dodifferentmethodsgiveconsistentestimates?”Inthissection,wetakethisapproach and address four questions: 1. What is the dynamic structure of the outcome? In particular, how are future valuesofthe outcome relatedto previousvaluesofthe outcome?Answeringthis questioniscriticalifourgoalistoestimatecounterfactualvalues.Inthepotential outcome framework for the sort of examples we will consider, we are interested primarilyinthedynamicstructureofY0,whichisthepotentialoutcomevariable it under the control state.\n\nHow is assignment to the treatment determined? As in cross-sectional attempts to estimate causal effects, modeling treatment assignment/selection is crucial if a researcher hopes to generate consistent estimates of a particular causal effect.\nWhatarethe alternativemethods ofestimationthatcanbe usedtoconsistently estimate average effects, given a valid set of assumptions?\nHow can the estimated model be tested against the data? We will consider these four questions in this order.\n\nDynamic Structure As shown in any advanced time series textbook, the dynamic structure of the out- come can be infinitely complex. In the context of panel data models, researchershave typically considered fairly simple structures, often because of the limited number of wavesof data that are available. Rather than trying to provide anexhaustive account – which would take a book in and of itself – we primarily focus on conceptual issues.\nThe broad statistics and econometric literature on panel data models is quite distinct from the estimation of treatment effects from a counterfactual perspective.\nImplicit in much of this literature is the assumption that causal effects are constant across individuals, such that causes/treatments simply shift the outcome by fixed amounts.Fromacounterfactualperspective,suchassumptionsareoverlyrigid.Anec- essarycomponentofestimatingatreatmenteffectistheconsiderationofthehypothet- ical evolution of Y0 for the treatment group after the treatment occurs. If treatment it effects are heterogeneous and selection is on the treatment effect itself, then the ATT is usually the parameter of interest, as it is often the only one that can be identified by any model (and, fortunately, it is also often of inherent substantive interest).\nConsider the following possible two equations for the generation of Y0: it Y i0 t=λi+eit, (11.18) eit=ρeit−1+vit−1, (11.19) Table 11.3 Alternative Trajectories of the Outcome Under the Control State for Different Assumptions About Its Dynamic Structure Model Assumed Constraints Evolution of Y i0 t A ρ=0 Var(λi)(cid:6)=0 Immediate regression of individualvalues to separate group expectations B ρ(cid:6)=0 Var(λi)=0 Regression overtime of individualvalues to a common expectation C ρ(cid:6)=0 Var(λi)(cid:6)=0 Regression overtime of individualvalues to separate group expectations whereλi is atime-constant,individual-varyingfixedeffect,vit−1 is purerandomnoise (that is, uncorrelated with everything), and ρ is the correlation between eit over time (not the correlation between Y0 over time, which we labeled as r earlier). Equation it (11.19) specifies an autoregressive process of order (1). It is order (1) because the current eit is dependent on only the last eit−1, not eit−2 or any errorsfrom priortime periods. There are many possible ways that the current error could be dependent on pasterrors.Thesedefinewhatareknownastheclassofautoregressivemovingaverage (ARMA) models.\nWithinthecurrentcontext(i.e.,assumingthatweknowthatEquations(11.18)and (11.19) are capable of representingthe full dynamic structure of Y0), determining the it dynamicportionofthe modelforY i0 amountsto askingwhether Var(λi)=0, ρ=0, or t both. Multiple tests are available to evaluate these restrictions (see, again, texts such as Hamilton 1994 and Hendry 1995 for comprehensive details). Most standard data analysis programs allow a researcher to estimate a full model on the pretreatment values of Yit, assuming that neither Var(λi)=0 nor ρ=0, and then to reestimate variousconstrainedversions.Thereafter,aresearchercanthenusestandardlikelihood ratio tests of these model constraints. Such tests on the pretreatment data are not full tests of how Y0 evolvesfor the treatment groupin the absence of treatment (here it again, we are back to the issue for the ITS model in Figure 11.1). Thus, a researcher most likely will need to make some untestable assumptions.\nConsider the following scenarios. If both Var(λi) and ρ are nonzero (and, further- more, selection into the treatment is on λi only), how then do the values of Y i0 in t the treatment and control group evolve? When asking this question, we are implic- itly considering how E[Y0|D∗=1] and E[Y0|D∗=0] evolve over time toward one or it i it i morevalues,eventhoughtheevolutionofthesetwoconditionalexpectationsrepresent average trajectories of individual-specific patterns of evolution in trajectories of Y0.\nit ConsiderasummaryofthesedifferentsituationsinTable11.3,whicharethendepicted as pairs of lines in Figure 11.7.\nNote that Model A is consistent with the assumptions of the change score model.\nModelBisconsistentwiththeassumptionsoftheanalysisofcovariancemodel.Model C is consistent with neither, but we suspect that it is the most common scenario in empirical research.\nE[Y0] t Model A Model B Model C t–2 t–1 t Figure11.7 Depictions of possible trajectories, as specified by the models in Table 11.3, for E[Y0|D∗=1] (the upper line of each pair, corresponding to the treatment it i group) and E[Y0|D∗=0] (the lower line of each pair, corresponding to the control it i group).\nMany of the most common models in panel data analysis assume that there is virtually no dynamic structure to the process that generates the outcome. In fact, most versions of the model that generally goes by the name of a “fixed effects” model are based on the following implicit model for the generation of Y0 and Y1: Y i0 t=λi+Tτ+vit, (11.20) Y i1 t=Y i0 t+δi, (11.21) where λi is a fixed time constant, individual-level determinant of the outcome in the absence of treatment, Tτ is a time trend common to all (because T is a variable measuring time, τ is a constant coefficient that does not vary over individuals or time), vit is random noise, and δi is an individual-specific additive causal effect that is assumed to be independent of λi and vit. The assumed data generation process that motivates the most standard form of a fixed effect model is equivalent to the assumption that each individual has his or her own intercept, but there is neither serial correlationin vit nor individual-specific trajectories in time.\nThemotivationforthe standardfixedeffects model canbe generalizedbyallowing each individual to have his or her own slope with respect to time, which is indicated bysubscriptingτ byiinthe assumeddatagenerationmodelinEquations(11.20)and (11.21). This more general model is then Y i0 t=λi+Tτi+vit, (11.22) Y i1 t=Y i0 t+δi, (11.23) which, apartfrom the stochastic term vit, was considered already in the previous sec- tion;seeEquations(11.14)and(11.15).There,weshowedthatallowingfordifferences between E[τi|D i∗=1] and E[τi|D i∗=0] could lead to the necessity of adjustment fac- tors ranging from negative to positive infinity. The attractiveness of this model, of course, is that it allows E[Y0] for the treatment and control groups to evolve in par- it allel, diverge, or converge.This will depend, respectively, on whether the difference in e e e t–2 t–1 t Y t–2 Y t Y t–1 D Figure11.8 A model of endogenous treatment assignment in which selection is on the pretreatment outcome, Yt−1.\nthe expectedslopes forthe treatmentandcontrolgroupsis zero,positive, ornegative.\nBut substantial amounts of data are needed to estimate it, and certainly from more than just one pretreatment time period and one posttreatment time period.\nDetermining the Assignment Process As we have argued throughout this book, the key to estimating a treatment effect is understanding the process of treatment assignment/selection. One of the advantages of conceptualizing and then analyzing the dynamic process of the outcome is that it may provide evidence about the factors that structure the assignment process. Two generalcasesareofparticularinterestandleadtoquitedifferentestimationstrategies.\nThe issue, however, is potentially tricky in that we may want to condition on one or moreendogenousvariables.Aswehavediscussedatmanypointsthroughoutthisbook, conditioning on an endogenous variable that is a collider along a back-door path will unblockanalreadyblockedback-doorpath,thuscreatinganewsourceofconfounding.\nConsiderfirstthe caseinwhichassignmentisdirectlyafunctionofpreviousvalues ofY asinFigure11.8.Inthisgraph,theassociationbetweenYtandDdoesnotidentify the causal effect of D on Yt because they are connected by a back-door path through Yt−1:D←Yt−1→Yt.However,this back-doorpathcanbe blockedbyconditioningon Yt−1.\nNote that Yt−1 is a collider on the path et−2→Yt−2→Yt−1←et−1. Thus, condi- tioningonYt−1 willinduceassociationsbetweenYt−2 andet−1 aswellasbetweenet−2 and et−1. These new associations are unproblematic, however, because they do not create any new as-if back-door paths between D and Yt. Note also that if we thought that treatment assignment D was determined by earlier values of Y, we could condi- tion on these Y’s without creating as-if back-door paths that confound the effect of interest.\nConsider an alternative and much more complex model, presented in Figure 11.9, where treatment assignment D is determined by λ instead of Yt−1. For this model, there is an unblockedback-doorpathconnecting D to Yt: D←λ→Yt. What happens ifweconditiononYt−1?Obviously,theunblockedback-doorpathD←λ→Yt remains unblockedbecauseYt−1doesnotliealongit.Inaddition,conditioningonYt−1unblocks a set of already blocked back-door paths because Yt−1 is a collider on the previously e e e t–2 t–1 t Y Y Y t–2 t–1 t D λ Figure11.9 A model of endogenous treatment assignment in which selection is on a fixed effect that also determines the outcome.\nblockedback-doorpaths representedcollectivelybyD←λ→Yt−1←et−1 (cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)et→ Yt. In combination, conditioning on Yt−1 has only made things worse. We failed to block the original back-door path that was of concern, and we unblocked already blocked back-door paths.\nConsider this problem from another perspective. Suppose that the standard moti- vation of a fixed effect model is in place, such that one has reason to believe that Y0 it and Y1 are generated in the simple way specified for Equations (11.20) and (11.21).\nit Suppose, therefore, that we wish to estimate the following regressionequation: Yit=li+Ditc+eit, (11.24) where the li are individual-specific intercepts, and where we then hope that the esti- mated coefficient c on the treatment exposure variable in time period t will then be equal to the ATE (or the ATT if self-selection is present).\nIfwehadameasureofλi,thenestimatingthemodelinEquation(11.24)wouldbe straightforward. We could put in a dummy variable specification to parameterize the li intercepts. For the graph in Figure 11.9, and from a standard structural equation perspective, Yit−1 can be thought of as a measure of λi. This then suggests that the following regressionequation can be estimated instead of Equation (11.24): Yit=a+Yit−1b+Ditc+eit. (11.25) IfwethinkofYit−1 asameasureofλi,thenitcontainsmeasurementerrorbecauseitis alsoafunctionofeit−1.Asaresult,thecoefficientonYit−1 willbedownwardlybiased.\nIn fact, the estimate of b will be a consistent estimate of r, which is the reliability of Y.ThisisnotsurprisingbecauseEquation(11.25)istheanalysisofcovariancemodel.\nThus, the analysis of covariance model can be interpreted as a fixed effect model in which we have used a noisy measure of λi as an adjustment variable.\nIn the last section, we saw that the choice of either the analysis of covariance model or the change score model can be consequential. Accordingly, it is critical to determine whether assignment to D is function of Yit−1 or λi. If we have two or more pretreatment observations, this is easy to do. The first step is to determine whether b=c or c=0 in the following model: Logit(Di)=a+Yit−1b+Yit−2c. (11.26) InFigure11.8,D isdependentonlyonYt−1.Thus,cshouldequal0.InFigure11.9,D isassociatedwithonlyYt−1 andYt−2 throughtheirjointdependenceonλ.Asaresult, b=c.17 Obviously, with this test, we may also include additional observed variables that we believe also determine D. And the test generalizes in the obvious way when we observe Y at more than two pretreatment time periods.\nEffect Estimation Extensive discussions exist in the econometrics literature on the estimation of the fixedeffectsmodelanditsgeneralizations.Basically,therearetwodifferentestimation strategies. For the differencing approach, the specification is differencing: Yit−Yit−1=(λi−λi)+(Dit−Dit−1)d (11.27) +(Xit−Xit−1)b+(eit−eit−1) =(Dit−Dit−1)d+(Xit−Xit−1)b+(eit−eit−1), where treatment exposure occurs between time period t−1 and t. In contrast, the dummy variable approach is individual dummies: Yit=Pili+Ditd+Xitb+eit, (11.28) where Pi is a dummy variable for person i and li is its associated coefficient. This second method amounts to estimating a separate intercept for each individual. It is alsoequivalenttodifferencingY andX fromtheirrespectiveindividual-levelmeans.If onewantstoestimatethegeneralizedfixedeffectmodelinwhichthereisaninteraction betweenanindividualeffectandtime,onecandothisbyeitherdifferencingadditional timesorbyinteractingtheindividualdummies,Pi,withtimeandestimatingaseparate interaction term for each dummy.\nTo understandthe differences between these two approaches,evolving conventions in data analysis must be noted. For the representationof the change score model and the analysis of covariance model in Equations (11.4) and (11.5), we conformed to the 17Theseassumptionscanmoreeasilybetestedbyestimatingthemodel Logit(D i)=a+Y it−1b+(Y it−1+Y it−2)c and testing whether b=0 or c=0. Here, (Y it−1+Y it−2) is essentially acting as a measure of λ i.\nThisstrategyisbasedonthefollowingtrickoftenusedtotestfortheequalityofcoefficients fortwo variables X and Z. Let the coefficient on X bem and on Z bem+n. Runthe followingregression equation: Y =Xm+Z(m+p)+u =(X+Z)m+Zp+u anduseastandardstatisticaltesttoevaluate thenullhypothesis thatp=0.\nconvention in the literature wherein the models are written out so that they can be estimated easily with a cross-sectionaldataset. In other words,time is encoded in the variables, so that time-varying outcome variables, Yit and Yit−1, are regressed on a cross-sectional treatment group dummy variable D∗ in an implicit dataset with one i record for each of N individuals. This data setup is also the implicit background for the differencing specification of the fixed effect estimator in Equation (11.27).\nAs can be seen in virtually any panel data textbook (e.g., Baltagi 2005), the con- ventionistonowstructureone’sdatasetinperson–timerecords,whichresultsinN×T records rather than N records. Forcing time to be constant within each data record allows for variables such as Dit and D i∗ to be cleanly parameterized in subsequent analysis. This data setup is the implicit background for the individual dummy speci- fication of the fixed effect estimator in Equation (11.28), and that is why there is no referencetotime t−1versustimetinEquation(11.28).Throughouttheremainderof this section,wewillwrite withsuchanN×T datasetinmind. The ideas,however,do not depend onsuchanimplicit structuring, as one canswitchback andforth between both setups based on analogs to Equations (11.27) and (11.28).\nAs for the alternative fixed effect specifications in Equations (11.27) and (11.28), the two methods giveidenticalanswerswhen there are only two points in time. When the errors are correlated across time and there are more than two time periods, the two methods will give somewhat different estimates, although both estimators are consistent. Which estimator is preferable depends on the nature of the correlation structure. We need not be concerned about this issue here; see Baltagi (2005), Hsiao (2003), and Wooldridge (2010) for discussion.\nTraditional fixed effect and differencing methods are generally inefficient, how- ever, if the goal is only to estimate the effect of a treatment. These methods simply eliminate unobserved individual effects from the data. Doing so powerfully eliminates all associations between the treatment variable Dit and unobserved time-constant, individual-level variables. If the coefficients of all observed variables are of interest, then this is appropriate.\nIn the present case, however, our focus is simply on estimating the effect of treat- ment exposure, Dit. As pointed out repeatedly in previous chapters, one approach to consistently estimate the effect of Dit is to balance the data with respect to all systematic determinants of Dit. As discussed in the last section, our interest in the case of linear models (the situation with nonlinear models being more complicated) is in differences in the expected trajectories of Y0 for those in the treatment group it and those in the control group. If we want to use the average observed values of Yit in the controlgroupin the posttreatmenttime periods in orderto predictthe average counterfactualvaluesofY0 inthe treatmentgroupinthe posttreatmenttime periods, it then it is essential that differences in the average trajectories of these two groups be modeled effectively.\nTobemoreconcrete,supposethatwehavethreetime points.Iftheonlydifference inthe expected trajectoriesofY0 for the twogroupsisintheir averagelevels,then all it we need to do is allow for differences in group-level intercepts by estimating ∗ Yit=a+D ib+Ditd+eit. (11.29) Here,thecoefficientbcapturesdifferencesintheexpectedtrajectoriesforthetreatment andcontrolgroups,suchthattheinterceptforthecontrolgroupisaandtheintercept for the treatment group is a+b.18 If the expected trajectories also differ in their slopes, then we need to include a term for time and an interaction term between group membership and time, as in i∗ i∗×T)c(cid:2) Yit=a+D b+Tc+(D +Ditd+eit. (11.30) The coefficient b again captures differences in the expected trajectories, and c(cid:2) now captures differences in the slopes of the expected trajectories. Interactions between D∗ and higher-order polynomials of T (or any other function of time) can also be introduced, assuming sufficient pretreatment data are available.\nEstimating the model in Equation (11.30) is equivalent to differencing out the treatment/controlgroup expectations of λi and τi in the following assumed data gen- eration model for Y0 and Y1, based on an augmentation of Equations (11.22) and (11.23). Expanding a standard fixed effect model separately for the treatment and control groups using the time-constant indicator of the treatment group D∗ yields ∗ forD =0: (11.31) i Y i0 t,D∗=0=(μλ,D∗=0+vi,D∗=0)+T(μτ,D∗=0+τ i(cid:2) ,D∗=0), Y i1 t=Y i0 t+δi, and ∗ forD =1: (11.32) i Y i0 t,D∗=1=(μλ,D∗=1+vi,D∗=1)+T(μτ,D∗=1+τ i(cid:2) ,D∗=1), Y i1 t=Y i0 t+δi.\nHere,μλ,D∗=0 istheexpectationofλi inthecontrolgroup,andλi=μλ,D∗=0+vi,D∗=0 forthoseinthe controlgroup.Likewise,μτ,D∗=0 is the expectationofτi inthe control group, and τi=μτ,D∗=0+τ i(cid:2) for those in the control group. The terms for the λ,D∗=0 treatment group are defined analogously.\nIn this setup, the terms vi,D∗=0, vi,D∗=1, Tτ i(cid:2) ,D∗=0, and Tτ i(cid:2) become compo- ,D∗=1 nents of the error term eit of Equation (11.30) as constant individual-level differences vi andtime-varyingindividualdifferencesTτ i(cid:2).Becausevi,D∗=0,vi,D∗=1,Tτ i(cid:2) ,D∗=0,and Tτ i(cid:2) are all by construction uncorrelated with D i∗, eit is uncorrelated with D i∗, ,D∗=1 assuminganyextraindividualortime-varyingnoiseembeddedwithineit iscompletely random. Furthermore, the coefficient a in Equation (11.30) is equal to μλ,D∗=0, and the coefficient b is equal to μλ,D∗=1− μλ,D∗=0. Thus, b captures the difference in the expected intercept for individuals in the treatment and control groups. Likewise, the coefficientcinEquation(11.30)isequaltoμτ,D∗=0,andthecoefficientc(cid:2) isthenequal toμτ,D∗=1−μτ,D∗=0.Andthusc(cid:2) capturesthedifferenceinexpectedslopeofthetime trends for individuals in the treatment and control groups.\n18Notice that we can include both D it and D i∗ in the same regression equation because we have multiplerecordsforeachindividualovertimeinourdataset.Inposttreatmenttimeperiods,D i∗=D it forallindividuals(assumingthatnooneleavesthetreatmentstatebeforetheendofthestudy),but inpretreatmenttimeperiods,D i∗=D it onlyforindividualsinthecontrolgroup.\nThe coefficient d on Dit is a consistent estimate of the ATE because the expec- tations of λi and τi are balanced across the treatment and control groups. All of their systematic components related to treatment group membership are parameter- ized completely by a, b, c, and c(cid:2). This leaves all remaining components of the distri- butions of λi and τi safely relegated to the error term.19 There are two advantages of estimating Equation (11.30), as opposed to using traditionalmethods forestimating fixed effectmodels andtheir generalizations.First, conceptually, the model makes clear that if the goalis consistent estimation, then the expected trajectories of Y0 for the treatment and control groups must be correctly it modeled, not necessarily all individual-specific trajectories. Later, we show how this principle leads to a general specification test. Second, there are potential efficiency gains. For example, in a standard fixed effect model, half of the overall degrees of freedom are lost by specifying individual-specific fixed effects (when there are only two time periods of data). In estimating Equation(11.30), only one degreeof freedom is lost to an estimate of the difference in the intercept for the mean of Y0. We should it note, however, that this minimization in the loss of degrees of freedom is moderated bythefactthattheerrorsinEquation(11.30)arelikelytobehighlycorrelatedwithin individuals (because the errors within individuals include a common fixed effect). An estimation procedure should be used for the standard errors that accounts for this correlation.\nIn the situation in which Yit is determined only by Yit−1 and Dit, estimation is simpler. As already discussed with reference to Figure 11.8, conditioning on Yit−1 is sufficient to block all back-door paths connecting D to Yit. How the necessary condi- tioningshouldbeperformedwilldependonthedetailsoftheapplication.Conditioning could be done by matching, as in the analysis of Dehejia and Wahba (1999) for the National Supported Work data (although there is no evidence that they attempt to test the suitability of this specification as opposed to a fixed effect specification).20 Alternatively,Yit−1 couldbeconditionedonbyaregressionmodel,asinananalysisof covariancemodel.Thesemodelswillnotyieldthe sameresults,anditmaybe difficult to choose between them. More complicated specifications in which Yit is a function of both Yit−1 and individual-level variables are also possible. Halaby (2004) provides a clear introduction to these methods.\nModel Testing Bynow,we hopeto haveconvincedthe readerthatmaintainedmodelingassumptions can have large consequences. Given this dependence, it is critical that researchers be explicit about the assumptions that they have made and be able to defend those assumptions.Assumptionscanbedefendedeithertheoreticallyoronempiricalgrounds.\nOften neither is done. In fact, they are made often without any explicit recognition.\nFortunately, if pretreatment observations are available for multiple time periods, it is 19Moreover,because thismodelissetupas alinearspecification ofthetreatment effect, alackof balanceinhigher-order(centered) momentsofλ i andτ i doesnotaffecttheestimationofd.\n20Fordetaileddiscussionsoftheappropriatemodelspecificationforthesedata,seeSmithandTodd (2005) andassociatedcommentandreply.\npossible in many circumstances to test the assumptions against the data. Here, we describe two conceptually different, but mathematically closely related, approaches.\nIn discussing strategies to increase confidence in a causal effect estimate from an ITS model, we suggested that a researcher could either use a dependent variable for whichno effect should occur or estimate the effect for a groupfor which no treatment effect should occur. Evidence of a treatment effect in either case is evidence that the model is misspecified.\nHeckmanandHotz(1989)suggestapplyingthissameprincipletopaneldatawhen twoormorepretreatmentwavesofdataareavailable.Specifically,theysuggesttaking one of the pretreatment outcomes and analyzing it as if it occurred posttreatment. A researcherthensimplyappliestheestimationmethodtothenewpseudo-posttreatment data and tests for whether there is evidence of a “treatment effect.” Because neither the treatment nor the control group has experienced a treatment in the data under consideration,evidence ofatreatmenteffectisevidencethatthe modelis misspecified (i.e., that the model has failed to fully adjust for differences between the treatment and control groups).\nIn the analysis of covariance model, care must be taken. Here, it is implicitly assumedthat selection is on Yit−1. For example, for a logit specification of the proba- bility of treatment selection, it is implicitly assumed that ∗ Logit(D i)=a+Yit−1b. (11.33) Inthismodel,D i∗ isafunctionofYit−1.Thisismathematicallyequivalenttomaintain- ing that D i∗ is a function of Yit−2+(Yit−1−Yit−2). Generally, Yit−1 will be correlated with (Yit−1−Yit−2). Consider the following model: ∗ Yit−1=a+Yit−2r+D ic+ui. (11.34) BecauseD i∗ isafunctionofbothYit−1 and(Yit−1−Yit−2),andYit−1 iscorrelatedwith the latter term, in general c will not equal 0. The basic point is that D∗ is partially i a function of a component of Yit−1 that is not contained in Yit−2. In general, the coefficient c on D∗ is a function of this dependence.\ni We can, however, run time backwards. Accordingly, we can estimate Yit−2=a+Yit−1r+vi. (11.35) If we are going to use the testing strategy of Heckman and Hotz (1989) to evaluate an analysis of covariance model, we should then test whether c=0 in the following related model: ∗ Yit−2=a+Yit−1r+D ic+ei. (11.36) Because there is no component of D i∗ that depends on Yit−2 conditional on Yit−1, c shouldequal0 in this model if the analysisof covariancemodel has correctlyadjusted for treatment group differences in Yit−2.\nHeckmanandHotz’stestalsoindicateshowtwo-period,pretreatment-posttreatment data can be used. What we should do is fit a cross-sectional model. We should then treatthepretreatmentoutcomeasifitwereaposttreatmentoutcomeandthentestfor a treatment effect. Evidence of a treatment effect is evidence that our cross-sectional model has failed to fully adjust for pretreatment differences between the treatment and control groups.\nTo better understand these procedures, consider a more general specification of this type of test. Recall that, net of our adjustments for variousfunctions of time and other variables, we seek to evaluate for these tests whether the trajectories of Y0 are it equivalent in the pretreatment data for the treatment and control groups. A variety of different models can be assessed. A fixed effect model allows for differences in the intercepts for two groups.A model with individual- or group-specific time coefficients allows for differences in slopes. If we have enough pretreatment data, we can add additionalfunctionsoftimetoourmodelandtherebyallowforevenmoreheterogeneity for the trajectories of Y0.\nit The most general specification would be to choose one time period as the base, create a dummy variable for all other time periods, and allow these dummy variables to fully interact with our treatment group indicator D∗. This is what is known as the saturatedmodelinthistradition.Itisacompletelyflexiblefunctionalformandallows for completely separate time trajectoriesfor Y0 for the treatment and control groups.\nit It is of little use in estimating the true causal effect.\nUsing just the pretreatment data, we can, however, compare the saturated model with any more restrictive model – such as a fixed effects model – using an F-test or likelihood ratio test. Evidence that the more restrictive model does not fit is evi- dence that the more restrictive model fails to fully model the differences between the treatment and control groups in the trajectories of Y0.\nit ConsidertheresultsofHeckmanandHotz(1989),aportionofwhichispresentedin Table11.4.21 Fortheiranalysis,HeckmanandHotzestimatedawiderangeofalterna- tivemodelsoftheeffectoftheNationalSupportedWorkprogramonthe1978earnings of participants who were high school dropouts. The first column reports selected esti- mated effects from their study. The experimental estimate suggests that there is no evidence that the program has an effect (given a point estimate of −$48 with a stan- darderrorof$144).The regressionandfixedeffectmodels showlargenegativeeffects, whicharestatisticallysignificantbyconventionalstandards.Therandom-growthmod- els,whichallowforindividualslopecoefficientsforthetrajectoriesofearnings,suggest a modest but still nonsignificant negative effect.\nThesecondcolumnofTable11.4reportsthepvaluesfortestsofnotreatmenteffect, in which the preprogram1975 earnings are used as if they were in fact posttreatment earnings. If the models that are tested adequately adjust for underlying differences between the treatment and control groups in the trajectories of earnings, one would expectthe treatmenteffect estimate to be nonsignificant(i.e.,havea highp value). In the case of the regression and fixed effects models, the faux-treatment-effect estimate is highly significant, indicating a lack of model fit. In the case of the random-growth model, however,it appears to fit the data.\n21Although Heckman and Hotz (1989) is an exemplary early example of this sort of analysis, the basicspecificationtestapproachisusedinoneformoranotherinotherworkaswell(e.g.,Petersen, Penner,andHøgsnes2011).\nTable 11.4 Specification Tests from the Analysis of Heckman and Hotz (1989) of the Effect of the National Supported Work Programon the Earnings of High School Dropouts p valuesfor specification tests Preprogram Postprogram Estimated effect, in dollers 1975 earnings 1978 earnings Experiment −48 (144) Regression −1884 .000 .000 (247) Fixed effect model −1886 .000 .000 (pre-1972) (242) Random-growth model −231 .375 .329 (pre-1972 and 1973) (414) Note:Resultsarefromtables3and5ofHeckmanandHotz(1989).\nThe third column reports results from a similar test, where Heckman and Hotz analyze the valid 1978 posttreatment data as if one time period was in fact pretreat- mentdata.Again,theytestforwhetherthereisevidenceofatreatmenteffect.Aswith the tests reported in the second column, if the model is properly specified, then there shouldbenoevidenceofatreatmenteffect.Butherealsothepvaluesfortheregression and fixed effects models suggest a significant treatment effect, indicating that these models do not fit the data. And, as before, the p value for the random-growth model indicates that it fits the data.22 TheNationalSupportedWorkdatahavebeenanalyzedbymanydifferentsocialsci- entists,andtheyareperhapsthemostwidelyuseddatatoassesstherelativeexplana- tory power of alternative types of panel data estimators. There has been considerable debateaboutwhetherornotresearchersneedmethodsthattakeaccountofunobserv- ables or whether adjusting only for observables is sufficient. Smith and Todd (2005; see also the associated comment and reply) show clearly how sensitive estimates can be to the sample that is chosen. Their results support Heckman’s position that there are important situations for which treatment selection is likely to be a function of unobserved variables.\n22A note of caution is warranted here. As in all situations, the power of these tests is a function of sample size. In this case, there are only 566 treatment cases. From the data, it is impossible to tell whether the random-growth model fits the data because it is a sufficiently correct model of the underlyingindividual-specifictrajectoriesorratherbecausethesampleissmall.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#conclusions-8",
    "href": "extracted/Counterfactuals and Causal Inference.html#conclusions-8",
    "title": "Counterfaturals and Causal Inference",
    "section": "11.4 Conclusions",
    "text": "11.4 Conclusions\nLongitudinaldatamaybehelpfulforestimatingcausaleffects,butlongitudinaldatado\nnotconstituteamagicbullet.Defendableassumptionsaboutthetreatmentassignment process must be specified. And, to use longitudinal data to its maximum potential, researchers must carefully consider the dynamic process that generates the outcome, clearly define the causaleffect of interest, andthen use constrainedmodels only when there is reason to believe that they fit the underlying data.\nWith this chapter,we havecompletedourconsiderationofidentificationand anal- ysisstrategiesthatcanbereliedupontoestimatetheATE,ATT, andATC.Wemake no claim to have considered anything but a subset of all strategies that are available, butwehaveattemptedtocoverthematerialthatreceivesthemostattentioninthelit- erature.Inthenextchapter,weconsiderhowanalysiscanproceedwhentheprospects are low for point identification of a causal effect of interest. Informative empirical analysis is still possible, even though strong causal conclusions cannot be developed.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#appendix-to-chapter-11-time-varying-treatment-regimes",
    "href": "extracted/Counterfactuals and Causal Inference.html#appendix-to-chapter-11-time-varying-treatment-regimes",
    "title": "Counterfaturals and Causal Inference",
    "section": "11.5 Appendix to Chapter 11: Time-Varying Treatment Regimes",
    "text": "11.5 Appendix to Chapter 11: Time-Varying Treatment Regimes\nThe longitudinaldatamodels andanalysisstrategiesthatwe haveconsideredupuntil\nthis point make the strong assumptions that the treatment is administered only once and that the timing of the treatment is fixed. Models that relax these assumptions are needed in order to consider research questions where they cannot be sustained, or where maintaining them alters the structure of the questions that are of genuine interest.Socialscientistsregularlyencountersystemsofcausaleffectswherethetiming of the treatment varies across individuals and where the treatment is repeated across multiple time periods in dynamic fashion.\nDealing with data where the timing of the treatment varies and where there are multiple treatments at different times complicates analysis considerably. First, indi- vidualsmaydiffernotonlyinwhethertheyreceivethetreatmentornot,buttheyalso may differ on when the treatment is received. These additional sources of differences betweenindividualsleadtonewidentificationchallenges.Second,newquestionsabout treatmenteffectsmaybeofinterest:Doesitmatterwhenthetreatmentoccurs?Ifthere are repeated treatments, what are the effects of different combinations of treatments? Third, new estimation requirements arise. Even in the seemingly ideal case where ignorabilityholds(i.e., therearenounobservedconfoundersofthetreatmentsandthe outcomes,sothatallcausaleffectsareidentified),standardconditioningmethodssuch as matching and regression do not always provide consistent estimates. As a result, new specialized methods must be utilized.\nRobins and his collaborators have developed several different approaches to mod- eling data where treatments vary in these ways (see Robins 1997, 1998, 1999, 2000; Robins and Hern´an 2009). Unfortunately, these methods do not solve the problem of selectionontheunobservablesthatthemainbodyofthischapteraddresses.Infact,as we will discuss below, serious estimation challenges exist even in the absence of selec- tion on the unobservables, with the main challenge being the dependency between treatmentstatesandintermediateoutcomesevenwhenunconfoundednessholds.Even so, the methods we present in this appendix are an exciting frontier of methodologi- cal scholarship that social scientists need to learn. And directed graphs elucidate the crucial issues.\nIn this appendix, we will follow the presentation of Robins and Hern´an (2009).\nWe will examine methods that areappropriatewhen the datahavebeen generatedby what is known as a “dynamic treatment regime” – a treatment exposure at one point in time is potentially a function of pasttreatment history and/orcurrent and/orpast time-varying covariates. However, we will only discuss the estimation of the effects of what are called “static regimes”: the difference in an outcome between individuals when all individuals follow one regime versus another regime. Thus, although we will assume that the data have been generated by a dynamic regime, we will focus on the effects of static regimes.\nTypes of Regimes Fixed Treatment Regimes. Situations where the timing of a single treatment or multiple treatments is determined at the beginning of the study are considered to have fixed treatment times. The case where treatment occurs at the same time for all individuals provides the simplest case. The Operation Ceasefire study discussed in Section 11.1 is an example. A college or university where promotion to associate professor always occurs in the sixth year after initial appointment is another. More complicatedexamplesarealsopossible.Arandomizedexperimentfortheevaluationof aworkertrainingprogram(LaLonde1986)wouldbeconsideredtohavefixedtreatment times, even though participants in the experiment have work histories of different lengths, because for each individual the timing of treatment assignment is known at baseline and thus fixed. A medical treatment regime where different doses or types of drugs are taken for fixed periods of time would be considered to have fixed treatment times as long as which drugs are taken and how long they are taken are determined at baseline.\nNondynamic Regimes. When treatment assignment is endogenous in the restricted sense that treatment status at one point in time is a (nondeterministic) function of treatment status at prior points in time, the treatment regime is labeled “nondynamic” by Robins and Herna´n (2009). We do not find this label particularly helpful. The classic example is a sequentially randomized experiment where individ- uals are randomized at different stages to different treatment possibilities, such that the probability of receiving a treatment at a later stage is solely a function of the outcome of a previous randomization. A simple example would be a worker training experimentwhere(1)individualsarefirstrandomizedtoeithertrainingornotraining andthen(2)individualswhoareassignedtotrainingarethenrandomizedintospecific trainingprogramsforeithercomputerskillsorconstructionskills.Thekeyfeatureofa nondynamic regime is that all randomizationprobabilities are fixed at baseline before randomizationis enacted, sothat the randomizationprobabilities are notfunctions of eithertime-varyingcovariatesoractualpriortreatmentstatuses.Whensuchadditional dependence does exist, the regime is considered to be dynamic.\nDynamic Regimes. Fixed and nondynamic treatment regimes represent con- strainedformsoftime-varyingtreatmentstructures,andtheyaretheonesthatpresent no new analysis challenges beyond those explained in prior chapters of this book.\nDynamictreatmentregimesareamoregeneralclassofmodelswheretreatmentstatus at time t, Dt, is determined by a covariate or set of time-varying covariates that may be functions of earlier treatments. The classic example comes from medicine, where treatmentattime t is determinedasa function ofthe patient’s observedsymptoms at timet,whichare,inturn,afunctionofwhetherornotthepatientreceivedatreatment in a prior time period. There are many social science examples as well, and we next consider an example that follows from others we have considered in this book.\nThe Catholic School Example as a Dynamic Treatment Regime Consider the effect of Catholic schooling on twelfth grade test scores. For a dynamic treatment regime version of this effect, we allow students to do what some of them areactuallyobservedtodo:changethe typeofschool–Catholicorpublic –thatthey are enrolled in between the tenth and twelfth grades.23 In order to keep the example from becoming too complex, we assume that students can only change type of school at the end of tenth grade (i.e., students are assumed to be in the same type of school in both the eleventh and the twelfth grades).\nThe indicator variables for enrollment type in the tenth grade and in the eleventh and twelfth grades are D and D , respectively. Students may follow any of the 10 12 following four regimes: 1. D =D =0 (public school throughout), 10 12 2. D =D =1 (Catholic school throughout), 10 12 3. D =1, D =0 (Catholic school, then public school), 10 12 4. D =0, D =1 (public school, then Catholic school).\n10 12 The questions for analysis are how twelfth grade tests scores are affected by these alternative treatment regimes, not simply what the effect of twelfth grade enrollment status is on test scores in the twelfth grade. The effect of Catholic schooling is likely to differ acrossstudents whohavebeenenrolledinCatholic schoolscontinuouslyfrom the tenth grade throughthe twelfth grade in comparisonto students who switch from public schools after the tenth grade and are then enrolled in Catholic schools in the eleventh and twelfth grades.\nBecauseofthecomplexityoftreatmentregimepatterns,wethereforeneedtounder- stand the effects that generate tenth grade test scores, even if our primary goal is to estimate effects that can be measured at the end of high school in the twelfth grade.\nAccordingly, we must model test scores in both the tenth and twelfth grades, Y and 10 Y , respectively. For this appendix, we will reduce the complexity of our discussion 12 and the worked example we offer below by analyzing Y and Y as two dummy 10 12 variables that indicate whether students receive high rather than low test scores.\n23For Panel Data Demonstration 1 (see page 273), we considered the effect of Catholic schooling on tenth and twelfth grade test scores, but we restricted attention, as in the existing literature, to studentswhoremainedinthesametypesofschoolsinbothgrades.ForPanelDataDemonstration2 (seepage365),weconsideredonlytheeffects ofCatholicschoolingontenthgradetestscores,which wemodeledusingpretreatmentoutcome measuresfromtheeighthgrade.\nD 10 Y Y 10 D 12 12 U Figure11.10 TheCatholicschooleffectinthetenthandtwelfthgradesasadynamic treatment regime.\nConsider the directed graph in Figure 11.10. In order to keep the discussion as simple as possible, Figure 11.10 does not include any observed variables other than the two treatment indicator variables, D and D , and the two outcome indicator 10 12 variables, Y and Y . Additional observed variables would affect any or all of these 10 12 four variables, as in the other demonstrations in this book that analyze the Catholic schooleffect.ItisappropriatetothinkofFigure11.10asthegraphthatapplieswithin onestratumdefinedbysomecombinationofothervariables.Thissimplificationimplies that, unlike in the other demonstrations, we ignore the determinants of D (see, for 10 example,Equations(5.24)and(5.25)inMatchingDemonstration4).This meansthat we are holding aside all of the other complications shown in prior demonstrations and now considering an additional set of complications that would still remain if we could solve all of the other complications explained in prior demonstrations. A more realistic model would include variables that would allow us to demonstrate all of the complications at once, but our presentation would then lose focus on the issues we wish to explain in this appendix.\nFor Figure 11.10, we also assume that whether a student is enrolled in a Catholic school by the twelfth grade, D , is solely determined by whether the student was 12 enrolled in a Catholic school in tenth grade, D , and by how successful the student 10 was on the test at the end of tenth grade, Y . Thus, the directed graph allows for 10 persistenceeffects(i.e.,studentsmaybemorelikelytobeinthesametypeofschoolin twelfthgradeasinthetenthgrade)andalsothepossibilitythatsomestudentschange school type based on test performance at the end of the tenth grade. For example, the directed graph is consistent with scenarios where students in public schools who perform poorly at the end tenth grade switch to Catholic schools thereafter.\nFinally, note the restrictedway in which the unobservedvariable U structures Y 10 andY andnothingelseinthegraph.Becausewehaveassumedthatweareanalyzing 12 Figure11.10withinastratumdefinedbyvariablesthatmayalsodeterminetreatment assignment,the unobservedvariableU inFigure 11.10is not one ofthe variables that define these strata. U might reflect the portions of innate intelligence, motivation, or other variables that determine the test score outcomes but that have no role in structuringtreatmentselectiondecisions.The criticalassumptioninthe modelis that selection into D is solely a function of observed variables, in this case D and Y .\n12 10 10 Unobserved variables that determine D and either Y or Y are assumed not to 12 10 12 exist. As we discuss below, this assumption is the key to identification.\nTo clarify the language of treatment regimes, note that Figure 11.10 represents a dynamic treatment regime because the second treatment, D , is determined by an 12 intermediate outcome, Y , that is itself determined by the initial treatment, D . If 10 10 Y were omitted from Figure 11.10, we would then have a nondynamic treatment 10 regime because the second treatment, D , would be determined only by the first 12 treatment,D ,inadditionto idiosyncraticdeterminants unrelatedto allelse.And,if 10 the dependence of D on D did not exist, we would have a fixed treatment regime 12 10 consisting of the two treatments, D and D , that could be analyzed separately 10 12 without concern for the implications of one analysis on the other.\nIndependent of whether Figure 11.10 contains Y or not, or whether D is a 10 10 cause of D or not, the directed graph represents a structure of effects that is equiv- 12 alent to a sequentially randomized experiment. Because D is a function of no other 10 variables, it is akin to a randomized treatment (again, within strata of observed and unobservedvariablesthatstructuretreatmentassignmentintheworldsconsideredfor priordemonstrations).Analogously,D canbe thoughtofashavingbeendetermined 12 by a randomization scheme where the probability of receiving the treatment in the twelfth grade is determined by two specific observed variables, D and Y . Since 10 10 the directed graph in Figure 11.10 represents a sequentially randomized experiment, ignorability holds with the result that the total causal effects of D on Y , D on 10 10 10 Y , and D on Y are all identified. We explain this result, and related results for 12 12 12 direct causal effects, in considerable detail below.\nGeneral Identification Conditions As noted in the introduction to this appendix, our concern now is whether it is pos- sible to identify the causal effects of a fixed regime (i.e., the effects of combinations across time of Catholic and public school enrollment) from data generated as part of a dynamic treatment regime. Identification of the causal effect of a fixed regime of treatments holds under three conditions, two of which are demanding and worth explaining.24 The most important condition is that sequential ignorability holds (i.e., conditionalonobservables,treatmentassignmentineachtimeperiodisindependentof the potential outcomes). This assumption is equivalent to maintaining that no unob- servedconfoundersexistthatdetermineboththetreatmentsandoutcomes.Ingeneral, thisconditionisuntestableandmustbedefendedbyappealstosubstantiveknowledge.\nWe have discussed this issue extensively in previous chapters.\nFor this appendix, we are assuming away this problem by focusing on an analysis within a stratum where we can assume that sequential ignorability holds. Return to the directed graph in Figure 11.10. The fact that it has the same structure as the directed graphthat would be an appropriaterepresentationofa sequentially random- ized experiment means that ignorability holds for both D and D separately and 10 12 together. This result can be confirmed by noting that neither D nor D is affected 10 12 by any unobserved confounders that also affect either Y or Y .\n10 12 The second condition is known as positivity. For this condition, it must be the case that at least some individuals have followed each logically possible treatment 24Thethirdconditioniswhatisknownasconsistency,whichstatesthatthevalueoftherealizedY underaspecifictreatmentconditionisequaltothepotentialoutcomeunderthattreatment.Hernan (2005) discussessituationswhereconsistency maynothold.\nregime within each stratum. When there are a large number of possible treatment combinations and/or strata, nonpositivity can be a serious problem because there may well be too few individuals (indeed, perhaps none) in particular combinations of treatments andthe strata defined by observedconfounders. As with any stratification procedure,onemayfacethe“curseofdimensionality.”Aswediscussbelow,themethod ofG-computation,whichisastratification-typeprocedure,isoftenimpracticalbecause ofthecurseofdimensionality(eventhoughG-computationisaveryusefulwaytothink through identification results).\nA Specific Setup of the Dynamic Treatment Regime Variant of the Catholic School Example In order to demonstrate how various methods do or do not work, we now introduce a hypothetical empirical dataset that is consistent with the directed graph in Figure 11.10. We do so in two steps. First, we posit a set of equations consistent with Figure 11.10. To keep matters simple, we use linear equations, although we will allow for interactions. Second, we generate a table of the expected values for the endogenous variables in the directed graph in Figure 11.10. We use expected values as opposed to a fully simulated dataset because this setup makes it easier to demonstrate that a particular estimation strategy will generate consistent estimates of effects of interest.\nFirst, we assume that E[D ]=.20because 20 percentofthe students are enrolled 10 inCatholicschoolsinthe tenth grade.U is adummy indicatorvariablethatmeasures whether a student is high, as opposed to low, on unobserved characteristics, such as motivation, effort, and mental ability. We assume that E[U]=.60 because 60 percent ofstudents areinthe highcategoryforU. Withthese distributionsfor D andU,we 10 set the expected value of test scores at the end of tenth grade as E[Y |D ,U]=.1+.2D +.4U. (11.37) 10 10 10 Enrolling in a Catholic school increases the probability that a student will be in the high-test-score group by .2. In addition, being in the high category of the unobserved variable (U =1) increases the probability of being in the high-test-score category by .4.25 25NotethatwehavenotdefinedE[Y 10|D 10,U]directlyinvaluesofunderlyingpotentialoutcomes.\nWecoulddosobyworkingtowardaconditionalexpectationfunctionanalogoustoEquation(11.37) bystartingwiththreeequations: Y 10 2=.1+.4U+υ0, Y 11 0=Y 10 0+.2+υ1, Y 10=D 10Y 11 0+(1−D 10)Y 10 0.\nWe will not use this type of setup for this example because we will not focus on individual-level variability of causal effects and because the Markov structure of Figure 11.10, along with binary variables, allows us to fit saturated models to recover all conditional expectations that match those we could define explicitly with potential outcomes. This is consistent with the dynamic treatment regime literature, where Markov assumptions for (sometimes implicit) causal graphs are often used toallowforaconsiderationofcausaleffectsthatarestructuredbyhowobservedtreatmentvariables have effects on observed outcome variables. These observed outcome variables could be defined in termsofunderlyingpotential outcomes.\nHaving set the distributions for D and Y , we then set enrollment in Catholic 10 10 schools in the twelfth grade as E[D |D ,Y ]=.5+.4D −.4Y +.4(D ×Y ), (11.38) 12 10 10 10 10 10 10 whichspecifiesacross-productinteractionbetweenD andY .Accordingly,Equation 10 10 (11.38)indicatesthat,forstudentsenrolledinpublicschoolsinthetenthgrade(D = 10 0) and in the low-test-score group (Y =0), their probability of being in a Catholic 10 school in the twelfth grade is .5. However, for students enrolled in a public school in tenth grade (D = 0) and in the high-test-score group (Y =1), their probability of 10 10 being inCatholicschoolinthe twelfthgradeisonly.1.We specify this patterntogive the treatment regimea dynamic structure where students doing well in public schools attheendofthe tenthgradearemuchlesslikelytodecidetoswitchenrollmentstatus to enter into a Catholic school in the twelfth grade. Finally, for students enrolled in Catholic schools in the tenth grade (D =1), the probability of being in a Catholic 10 schoolin the twelfth gradeis .9, regardlessofwhether or notthese students are inthe high-test-score or the low-test-score groups at the end of the tenth grade.\nTo complete the specification ofthe example,we setthe expected value ofthe test scores at the end of the twelfth grade as E[Y |D ,D ,U]=.2+.2D +.1(D ×D )+.4U. (11.39) 12 10 12 12 10 12 TheunobservedvariableU hasthelargesteffectontheexpectedvalueofY (but,at.4, 12 hasthe sameeffectontheexpectedvalueofY asforY ).BeinginaCatholicschool 12 10 in the twelfth grade increases the probability of being in the high-test-score group by .2. However, being in a Catholic school in the tenth grade only increases the chances of being in the high-test-score group in the twelfth grade if one was also enrolled in a Catholic schoolin the twelfth grade.This repeated treatment effect generates a boost of .1 for students enrolled in Catholic schools in both the tenth and twelfth grades.26 Table11.5presentsexpectedvaluesfortheendogenousvariables,Y ,D ,andY 10 12 12 based on this setup. Note that there are four variables, D , Y , D , Y , and that 10 10 10 12 eachtakes on the value 0 and 1. The table reports the conditional expected values for thethreeendogenousvariables:E[Y |D ],E[D |D ,Y ],andE[Y |D ,Y ,D ].\n10 10 12 10 10 12 10 10 12 The final column of Table 11.5 presents the proportion of the sample in the 16 strata defined across the 4 dichotomous variables. These values can be used to calculate additionalconditionalexpectationsdefinedbycombinationsofvaluesforthevariables in the first four columns.\nIdentification of Total and Direct Effects for the Example For total causal effects, which have been the focus of this book, the key identification results in the dynamic treatment regime literature are given by the back-door criterion. In cases wherethetotalcausaleffectisnotequivalenttothedirectcausaleffect(e.g.,theeffect of D on Y in Figure 11.10, which has both a direct effect, D →Y , and two 10 12 10 12 26In other words, there is an implicit term in Equation (11.39) of 0×D 10 because enrollment in a Catholic school in the tenth grade has no effects on twelfth grade test scores, which implies that students do not carrywiththem alagged effect oftenth gradeCatholic schoolingwhen they switch fromCatholicschoolstopublicschoolsfortheeleventh andtwelfthgrades.\nTable 11.5 Expected Values for the Endogenous Variables in the Directed Graph in Figure 11.10 D 10 Y 10 D 12 Y 12 E[Y 10|D 10] E[D 12|D 10,Y 10] E[Y 12|D 10,D 12,Y 10] Proportion 1 1 1 1 .460 .900 .811 .079 1 1 1 0 .460 .900 .811 .018 1 1 0 1 .460 .900 .511 .006 1 1 0 0 .460 .900 .511 .005 1 0 1 1 .460 .900 .657 .054 1 0 1 0 .460 .900 .657 .028 1 0 0 1 .460 .900 .357 .003 1 0 0 0 .460 .900 .357 .006 0 1 1 1 .260 .100 .753 .020 0 1 1 0 .260 .100 .753 .007 0 1 0 1 .260 .100 .553 .135 0 1 0 0 .260 .100 .553 .109 0 0 1 1 .260 .500 .582 .154 0 0 1 0 .260 .500 .582 .110 0 0 0 1 .260 .500 .382 .101 0 0 0 0 .260 .500 .382 .163 indirect effects, D →Y →D →Y and D →D →Y ), the key identification 10 10 12 12 10 12 12 results are given by a related literature on causal mediation; see Pearl (2009), Wang andSobel (2013),andVanderWeele (inpress). Accordingly,the firststepinanidenti- fication analysis, which we offer below for the Catholic school example, is to consider the total causal effects in Figure 11.10 by consulting the back-door criterion. The results that we offer below will be consistent with many others offered in Chapters 4 through7.We thengivesustainedattentionto the identificationofdirecteffects, con- centrating on what have been labeled the “controlled direct effects” in the literature oncausalmediation. These effects havenotbeen consideredinthis book upuntil now in any explicit way, although the careful reader will have seen references to them in the details of Chapter 10. Our identification analysis will make use of the conditional expectations reported in Table 11.5, with reference to Equations (11.37)–(11.39) that generate them. In the section that follows, we will then discuss how to estimate these identified effects from a single sample of data.\nTotal Effects. Table 11.6 indicates which of the eightpossible total causal effects in Figure 11.10 are identified, as well as the method that would need to be used in order to consistently estimate those that are identified.27 Most of the identification resultsin Table 11.6are notsurprising,althoughthe lastthree differ fromothers that 27ThefactthatallofthetotaleffectsofobservedvariablesinFigure11.10areidentifiedmeansthat wecantestwhethertheyareequalto0ornotandthusatleastpartiallyconsidertheappropriateness ofthedirectedgraphasawhole.Elwert(2013,table13.1)givesanexampleofhowsuchtestingcan beorganized.\nTable 11.6 IdentificationStatus of the Total Causal Effects in Figure 11.10 Total Effect Identified? Method for Estimation 1. U→Y 10 No 2. U→Y 12 No 3. D 10→Y 10 Yes Unconditional association 4. Y 10→D 12 Yes Condition on D 10 5. D 12→Y 12 Yes Condition on D 10 and Y 10 6. (Y 10→D 12→Y 12) Yes Front-doorcombination of already identified effects Y 10→D 12 and D 12→Y 12 7. (D 10→D 12)+(D 10→Y 10→D 12) Yes Unconditional association 8. (D 10→Y 12)+(D 10→D 12→Y 12) Yes Unconditional association +(D 10→Y 10→D 12→Y 12) we have considered explicitly in this book. We will examine these eight effects in the order in which they are listed Table 11.6, and they fall into five distinct identification patterns according to the order in which they are listed.\nFirst, because is U is unobserved, the total effects of U on both Y and Y are 10 12 not identified by the observed data. Second, because D and Y are not connected 10 10 byanyconfoundersthatgenerateaback-doorpath,itfollowsthattheirunconditional association identifies D →Y . For our hypothetical data, the effect is equal to the 10 10 difference in the expected values of Y for the two values of D , 10 10 E[Y |D =1]−E[Y |D =0]=.460−.260 10 10 10 10 =.200, giveninTable 11.5.Nonetheless,recallthatthisresultfollowsfromtheconstructionof the example, where we have assumed that we are analyzing the Catholic school effect within a stratum where Figure 11.10 can be accepted as reasonable.\nThird,thenexttwototaleffectsareidentifiedbyconditioningthatiswarrantedby the back-door criterion. For the effect Y →D , three back-door paths are present: 10 12 1. Y ←D →D , 10 10 12 2. Y ←D →Y ←D , 10 10 12 12 3. Y ←U→Y ←D .\n10 12 12 Without any conditioning, paths 2 and 3 are blocked by the collider Y . However, 12 path1remainsunblockedandgeneratesanoncausalassociationbetweenY andD .\n10 12 When D is conditioned on, all three back-door paths are blocked and a consistent 10 estimate of the effect Y →D can be obtained. Similarly, for the effect D →Y , 10 12 12 12 four back-door paths are present: 1. D ←D →Y , 12 10 12 2. D ←Y ←D →Y , 12 10 10 12 3. D ←Y ←U→Y , 12 10 12 4. D ←D →Y ←U→Y .\n12 10 10 12 In the absence of conditioning, path 4 is blocked by the collider Y , while paths 10 1, 2, and 3 remain unblocked. If only D is conditioned on, paths 1, 2, and 4 are 10 blocked, but path 3 remains unblocked. If only Y is conditioned on, paths 2, 3, and 10 4 are blocked, but path 1 remains unblocked. If both D and Y are conditioned 10 10 on, then all four back-door paths are blocked and a consistent estimate of the effect D 12→Y 12 can be obtained.\nFourth, the total causal effect of Y on Y , which is a two-edge directed path 10 12 Y →D →Y , is also identified. This result follows from a double consideration 10 12 12 of the back-door criterion, which is the front-door identification strategy presented in Chapter 10. The edge-by-edge identification results that constitute the front-door identification strategy are given in the corresponding rows of the table immediately above the row for the total effect of Y on Y , and as discussed already.\n10 12 Fifth, the final two total effects are identified but are different because they are composed of both a direct effect and one or more indirect effects through chains of mediation.ThetotalcausaleffectofD onD (whichiscomposedofthetwodirected 10 12 paths D →Y →D and D →D ) is identified by the unconditional association 10 10 12 10 12 between D and D because no back-door paths between D and Y are present 10 12 10 12 that generate confounding. Likewise, the total causal effect of D on Y , which is 10 12 composedof the three directed paths (D →Y →D →Y , D →D →Y , and 10 10 12 12 10 12 12 D →Y ) is identified by the unconditional association between D and Y , again 10 12 10 12 because no back-door paths are present that generate confounding. Note, however, that we have established these last two identification results by construction of the example, just as for our prior consideration of the total effect of D on Y .\n10 10 Overall, the directed graph in Figure 11.10 has a simple structure, allowing for the estimation of all total causal effects of the observed variables, including the total effects ofD onboth Y andY as wellas the total causaleffect ofD onY . The 10 10 12 12 12 simple structure yields straightforward identification results because Figure 11.10 is equivalent to a sequential randomized experiment.\nDirect Effects. Consider now the identification of direct effects, ignoring those thatareequaltotheirtotaleffects(i.e.,D →Y ).Twosuchdirecteffectsarepresent 10 10 in Figure 11.10, one of which is straightforward and of secondary interest (D → 10 D ) and one of which is not straightforward but of primary interest (D →Y ).\n12 10 12 Theseeffectsareidentified,buttheyarenotidentifiedusingtheback-doorcriterionto warrantconditioningvariables(becausenoback-doorpaths confoundthese twodirect effects).\nTobegintoappreciatethecomplications,itisusefultoconsiderhowtheconditional expectations in Equations (11.38) and (11.39) structure these direct effects. Consider first the direct effect D 10→D 12. Here, the direct effect varies with the two values of Y because of the nature of the dynamic treatment regime. We can use Equation 10 (11.38) to see how these effects were set by construction. The first step is to generate the conditional expectations that will define the direct effects: E[D |D =1,Y =1]=.5+.4(1)−.4(1)+.4(1×1) 12 10 10 (11.40) =.9, E[D |D =0,Y =1]=.5+.4(0)−.4(1)+.4(0×1) 12 10 10 (11.41) =.1, E[D |D =1,Y =0]=.5+.4(1)−.4(0)+.4(1×0) 12 10 10 (11.42) =.9, E[D |D =0,Y =0]=.5+.4(0)−.4(0)+.4(0×0) 12 10 10 (11.43) =.5.\nThese values are also given in the sixth column of Table 11.5.\nThe second step is take the values yielded by Equations (11.40)–(11.43) and then calculate what have become known as “controlled direct effects” in the literature on mediation,direct,andindirecteffects(seePearl2001,2009,2012a,2012b;VanderWeele 2009a, 2010; Wang and Sobel 2013): CDED10→D12(Y 10=1) =E[D |D =1,Y =1]−E[D |D =0,Y =1] (11.44) 12 10 10 12 10 10 =.9−.1 =.8, CDED10→D12(Y 10=0) =E[D |D =1,Y =0]−E[D |D =0,Y =0] 12 10 10 12 10 10 (11.45) =.9−.5 =.4.\nThese two controlled direct effects for D →D are two distinct components of the 10 12 directeffect,eachofwhichcanbecalculatedwhenY issettooneofitstwovaluesof 10 0 or 1. The label “controlled” refers to the action of setting the value for the variable Y beforecalculatingtheeffectoftheprimarycausalvariableontheoutcomevariable 10 of interest.\nWhencontrolleddirecteffectsareidentified,thenthedirecteffectcanbeconsidered identified. In other words, the direct effect is identified because all of its component effectsareidentified.28Tounderstandthisresult,noticefirstthatallofthecalculations 28Nonetheless,onemayprefertohaveasinglevalueforadirecteffect,ratherthanmultiplevaluesfor eachcontrolleddirecteffect.Themostcommonsingle-valuedirecteffectiswhathasbeenlabeledboth carried out for Equations (11.40)–(11.46) use values for conditional expectations and probabilities that are functions in observed variables only. As such, if a sample of infinite size were available, we could exactly calculate these effects for such a sample because the sample values would be exactly equal to these population values. This explanation, however, is too shallow. The deepest explanation can be found in the primaryliteratureonresultsthathavebeenestablishedforgraphsthathaveaMarkov structure; see Pearl (2009), after reading our appendix to Chapter 3. The core idea is that the simple structure of the graph in Figure 11.10, where no unblockedback-door paths are present between the two treatment variables, ensures that we can define the conditional expectations using Equations (11.37)–(11.39) and then assert that differences in the estimated values of the conditional expectations on the left-hand sides of Equations (11.40)–(11.43) are causal contrasts that identify controlled direct effects. Consider a counterexample for insight. If the graph in Figure 11.10 cannot be defended for the substantive example because an unobserved confounder of D and 10 D exists, such that a back-door path D ←C→D exists where C is unobserved, 12 10 12 thenthe conditionalexpectationsthatdefinethe controlleddirecteffectsinEquations (11.44)and(11.45)wouldnotidentifycausaleffects.Thedifferencebetweenthesample analogs to these conditional expectations, such as EN[di12=1|di10=1,yi10=1]−E[di12=1|di10=0,yi10=1], would not converge to the relevant controlled direct effect, CDED10→D12(Y =1) 10 because the confounder C generates additional noncausal dependence between D 10 and D within strata defined by Y .29 12 10 We find another explanation of this identification result helpful as well because of the way it connects to the sort of thinking that we have used extensively when the “puredirect effect” and the “natural directeffect” inthe causal mediation literature. Whatever labelchosen,itisaweightedaverageofthecontrolleddirecteffectsthatcorrespondtothedistribution ofthemediatorthatexistsinthecontrolgroup.Inthiscase,thenaturaldirecteffect is NDED10→D12=CDED10→D12(Y 10=1)×Pr[Y 10=1|D 10=0] +CDED10→D12(Y 10=0)×Pr[Y 10=0|D 10=0] (11.46) =(.8×.34)+(.8×.66) =.536, where the values of .34 and .66 for Pr[Y 10=1|D 10=0] and Pr[Y 10=0|D 10=0] are calculated from thefinalcolumnofTable11.5.Inthiscase,thenaturaldirecteffectisacounterfactual quantity:the Catholic school persistence effect, net of the dynamic nature of the treatment regime that we have assumed by construction exists. Thus, apart from how test score performance is determined in the tenth grade, the estimate suggests that the probability of entering a Catholic school in the twelfth gradeis higher by.536 ifa student was enrolled inaCatholic school inthe tenth grade. We do not find this counterfactual single-value direct effect to provide any additional information beyond the controlled direct effects. In the broader literature on causal mediation, natural direct effects yield effects that are more informative, typically when the mediator represents the primary substantive mechanismthatgenerates thetotal effect.\n29In the causal graph literature, this identification result follows from the Markov structure of the graph, which allows all differences in the conditional expectations of observed variables in the pre-intervention graph to be equal to their under-intervention differences. These equalities could be made more explicit by using either potential outcome notation or Pearl’s do(.) operator. When the graphhas aMarkovstructure, such representations areredundant, as weexplained inthe appendix toChapter3.\ninvoking the back-door criterion in this book. Consider the following graphical expla- nation for the role of conditioning in calculating controlled direct effects. In order to estimate the controlled direct effects, we need to condition on Y . The basic idea 10 here is that we need to set the indirect effect of D on Y to 0 by blocking the 10 12 directed path D →Y →D in order to then calculate the separable controlled 10 10 12 direct effects. As a result, conditioning is essential to the calculation of these effects.\nYet,notealsothatY isacollideronapaththatbeginsatD andendsatD ,which 10 10 12 is D →Y ←U →Y ←D . Although this path is not a back-door path between 10 10 12 12 these two variables (because it does not begin with D ←), conditioning on Y does 10 10 nonetheless induce an associationbetweenD andU. Fortunately, this induced asso- 10 ciation is blocked by a second collider on the same path, Y . Accordingly, we can 12 see that conditioning on Y effectively sets the indirect path to 0 without inducing 10 any unwanted noncausal associationsbetween D and D . This result suggests that 10 12 a straightforward approach for the estimation of the direct effect D →D is to 10 12 calculate the conditional associations between D and D for each value of Y .\n10 12 10 Tofullyappreciatethedepthoftheissuesinvolvedinthedynamictreatmentregime literature, we need to consider the direct effect of D on Y , which is D →Y in 10 12 10 12 Figure 11.10. This direct effect is identified according to some of the same reasoning just laid out for the direct effect of D on D , with some very important differences 10 12 we will fully explainbelow. Firstnote that the direct effect D →Y is a muchmore 10 12 importantsubstantiveeffecttoestimatebecauseitisanetaveragetreatmenteffectfor the treatment introduced in the first time period on the final outcome observed. It is also a more complicated direct effect to consider because the indirect effect of D on 10 Y traverses two separate directed paths, D →D →Y and D →Y →D → 12 10 12 12 10 10 12 Y .Fortunately,becausethedirectedpaththroughY liesontopofthedirectedpath 12 10 through D , the indirect effect through Y is fully absorbed into the distribution of 12 10 D . Accordingly, and following the reasoning above, we can set both indirect effects 12 to 0 by conditioning in D .\n12 As was the case for the direct effect D →D , the first step to developing an 10 12 explanation for the identification results is to generate the conditional expectations that define the controlled direct effects, plugging all combinations of values for D 10 and D into Equation (11.39) while allowing U to vary: 12 E[Y |D =1,D =1,U]=.2+.2(1)+.1(1×1)+.4U 12 10 12 (11.47) =.5+.4U, E[Y |D =0,D =1,U]=.2+.2(1)+.1(0×1)+.4U 12 10 12 (11.48) =.4+.4U, E[Y |D =1,D =0,U]=.2+.2(0)+.1(1×0)+.4U 12 10 12 (11.49) =.2+.4U, E[Y |D =0,D =0,U]=.2+.2(0)+.1(0×0)+.4U 12 10 12 (11.50) =.2+.4U.\nNote that, even though Y lies on a path that is part of the indirect effect of D on 10 10 Y , Y is absent from Equation (11.39). According to the graph, this effect is fully 12 10 absorbed into the effect of D on Y . The controlled direct effects are then 12 12 CDED10→Y12(D 12=1) =E[Y |D =1,D =1,U]−E[Y |D =0,D =1,U] 12 10 12 12 10 12 (11.51) =(.5+.4U)−(.4+.4U) =.1, CDED10→Y12(D 12=0) =E[Y |D =1,D =0,U]−E[Y |D =0,D =0,U] 12 10 12 12 10 12 (11.52) =(.2+.4U)−(.2+.4U) =0, where the effects of U cancel.30 These controlled direct effects match the values of Equation(11.39)byconstruction,andthey indicate thatbeing inaCatholicschoolin the tenth grade has no direct effect on test scoresin the twelfth grade unless one is in a Catholic school in the twelfth grade.31 We again must ask: How do we know that the controlled direct effects are all identified?As forthe directeffectD →D ,the coreoftheansweristhesameasfor 10 12 the direct effect D →Y . It is still the case that the controlled directed effects are 10 12 identified by the observed data based of the results established for graphs that have a Markov structure (again, see Pearl 2009 after reading our appendix to Chapter 3).\n30Although we did not specify a value for U in Equations (11.47)–(11.50), and simply allowed U to cancel in the calculation of the controlled direct effects, we could have developed eight separate conditional expectations because weknowthevalues ofU andtheprobabilitydistributionofU.We donotdosobecausethisinformationisnottypicallyavailabletotheanalyst.Itwouldalsorequireus tothenaverageovertheseeightconditionalexpectationstogettothefourvaluesfortheconditional expectationsthatcanbeusedtodirectlycalculatethetruecontrolleddirecteffects.Instead,weshow howtosolveforthesevaluesusingothermethods inthenextsection.\n31Forcompleteness, thenaturaldirecteffect isthen NDED10→Y12=CDED10→Y12(D 12=1)×Pr[D 12=1|D 10=0] (11.53) +CDED10→Y12(D 12=0)×Pr[D 12=0|D 10=0] =(.1×.36)+(0×.64) =.036, wherethevaluesof.36and.64forPr[D 12=1|D 10=0]andPr[D 12=0|D 10=0]arecalculatedfromthe final columnof Table11.5.Thenatural directeffect issmalland isagaina counterfactual quantity: the effect of Catholic schooling in the tenth grade on test scores in the twelfth grade, net of the dynamic nature of the treatment regime that we have assumed by construction exists. Thus, apart fromhow Catholic school attendance is determined inthe twelfth grade, the estimate suggests that the probability of being inthe high-test-score group increases by .036 if astudent was enrolledin a Catholicschoolinthetenthgrade.Thiscounterfactual effect isanexampleofanaturaldirecteffect that probably does not deserve attention. The weighting in Equation (11.53) is a direct function of thenumberofstudentswhoenterCatholicschoolsinthetwelfthgrade,havingbeeninpublicschools inthetenthgrade,andthisispreciselythegroupforwhomthecontrolleddirecteffectisequalto0.\nInthiscase,thecontrolleddirecteffects aresensibleandhaveclearinterpretations.\nThekeyfeaturethatestablishesidentificationisagaintheabsenceofconfoundersthat would generate noncausal associations through unblocked back-door paths between the treatment and outcome variables (in this case between D and Y and between 10 12 D and Y ).\n12 12 Althoughidentificationisagainpositive,alloftheshallowerexplanationsweoffered for the direct effect D →D no longer easily apply. Instead, the same explanatory 10 12 strategies reveal complexities that suggest why a clever set of techniques has been developed to estimate direct effects of these types. When we discussed the identifica- tion of the direct effect D →D , we were able to point out that sample analogs 10 12 to the conditional expectations on the left-hand sides of Equations (11.40)–(11.43) wouldconvergetothetruevaluesforthoseconditionalexpectationsasthesamplesize approachesinfinity.When consideringthe directeffect D →Y , anequivalentclaim 10 12 is true for the conditional expectations on the left-hand sides of Equations (11.47)– (11.50), but with one debilitating caveat: We cannot form the sample analogs to the true conditional expectations because U is an unobserved variable. And, if we try to estimate controlled direct effects by recklessly substituting in sample analogs to E[Y |D ,D ] for what would be the proper sample analogs to E[Y |D ,D ,U] 12 12 10 12 12 10 that are impossible to generate from the observed data, we will obtain inconsistent and biased estimates of the controlled direct effects. The usual culprit produces this bias: a collider. This complication can be seen in the graph, as we now explain.\nRecallour priorgraphicalexplanationfor the crucialrolethat conditioning onthe mediatorplayedinthe identificationofthe controlleddirecteffects forD →D .We 10 12 explainedthatconditioningonY effectivelysetstheindirecteffectpathD →Y → 10 10 10 D to0,enablingidentificationofthecontrolleddirecteffectswithinstratadefinedby 12 themediator,Y .ForthedirecteffectD →Y ,thesituationismorecomplicated.In 10 10 12 order to estimate the controlled direct effects in this case, we again need to condition inawaythatsetstheindirecteffectto0.But, nowweneedtoconditioninawaythat blockstwopaths,D →D →Y andD →Y →D →Y .Theobviouscandidate 10 12 12 10 10 12 12 conditioning variable is D because it lies on both of these paths. At the same time, 12 it should also be obvious that Y is not a good candidate for conditioning. Not only 10 would conditioning on Y fail to block the path D →D →Y , Y is a collider 10 10 12 12 10 on the path D →Y ←U →Y that begins at D and ends at Y . Conditioning 10 10 12 10 12 on Y would induce an associationbetween D and U, which would then generate a 10 10 noncausal association between D and Y because U is a direct cause of Y .\n10 12 12 Upon closer inspection, however,we can see that D is a descendant of Y . As a 12 10 result, conditioning on D will also induce an associationbetween D and U, which 12 10 then generates a noncausal association between D and Y within strata defined by 10 12 the mediator D . Given this predicament, it is not obvious how we can condition on 12 the D to set the indirect effect to 0 without triggeringa new source of confounding.\n12 Yet, without conditioning in a way that will set the indirect effect to 0, we cannot estimate the controlleddirecteffects thataccordingto the causalgraphliteratureare, infact,identifiedbecauseoftheabsenceofunobservedconfounders.Thispredicament is often referred to colloquially in this literature as “damned if you do and damned if you don’t.” Beforetoomuchdespairaccumulates,notethatifwecouldfindawaytocondition on D in order to set the indirect effects to 0 and then also adjust away the induced 12 biasthattravelsbywayofU,wewouldbeabletoestimatethecontrolleddirecteffects.\nThe signal contribution of the literature on dynamic treatment regimes is a solution tothis predicament,whichwe willexplainbelowwhenpresentingestimationmethods in the next section. The key innovation is to use the relationships that constitute the indirect effects (i.e., the joint probability distribution of D , Y , and D ) to adjust 10 10 12 awaythe induced confounding that travelsby way ofthe unobservedvariableU when we condition on D , Y , or both.\n12 10 Estimation Strategies Wewillnotdiscusshowtoestimatetotaleffectsindetailbecausethestrategiesshould be obvious. As shown in Table 11.6, many of these effects can be estimated using the naiveestimatorbecauseunconditionalassociationsidentifytheeffects.Evenwhenthis is not the case, standard back-door conditioning estimators can be used to estimate the others. Instead, we will focus in this section on the two direct effects, D → 10 D and D →Y . Estimation of the first of these effects is straightforward, once 12 10 12 the identification result is known. Estimation of the second of these effects is not straightforwardand is the focus of the dynamic treatment regime literature.\nEstimating the Direct Effect of D10 on D12. How would one estimate the controlled direct effects of D on D in a finite sample? Assuming that conditions 10 12 such as positivity are met for the available data, our identification explanation in the section above suggests one straightforward method. The researcher estimates sample analogs to the conditional expectations on the left-hand sides of Equations (11.40)– (11.43), which would be EN[di12=1|di10=1,yi10=1] for E[D 12|D 10=1,Y 10=1], EN[di12=1|di10=0,yi10=1] for E[D 12|D 10=0,Y 10=1], EN[di12=1|di10=1,yi10=0] for E[D 12|D 10=1,Y 10=0], EN[di12=1|di10=0,yi10=0] for E[D 12|D 10=0,Y 10=0].\nDifferences between these four estimated conditional expectations can then be taken to estimate the controlled direct effects in Equations (11.44) and (11.45).32 In the literature on dynamic treatment regimes, this straightforward estimation strategyislabeledG-computation(Robins 1986;Robins andHern´an2009),where the “G”isanabbreviationof“General.”G-computationisoneofthreerelatedapproaches to the estimation of treatment effects for dynamic treatment regimes. For examples such as this one, where we have three binary variables, positivity, and no emergent conditioning bias from colliders, G-computation takes a particularly simple form and is nearly certain to be feasible. As such, the other two estimation methods, which we detail in the next section, would not need to be used.\nEstimating the Direct Effect of D10 on Y12. To estimate the direct effect of D onY ,thedynamictreatmenteffectliteratureoffersthreemethods.Thefirst,G- 10 12 Computation(Robins 1986),wasjust presented,anditconveysthe coreidentification 32Inaddition,theseestimatedcontrolleddirecteffectscanthenbecombinedintoaweightedaverage, usingthe sampleanalogto Pr[Y 10=1|D 10=0], whichwouldthen yielda consistent estimate of the naturaldirecteffect.\nO D Y Figure11.11 An illustrative directed graph for G-computation.\nchallenge and how it is resolved. As we will show in this section, it is more compli- cated for the direct effect of D on Y . The second approach, known as the estima- 10 12 tion of marginal structural models (MSMs), is feasible for researchscenarios in which G-Computationisinfeasiblebecauseofthecurseofdimensionality(Robins1998,1999, 2000). We will also briefly discuss a third approach, G-Estimation, and the intuition behind it.\nG-Computation.ConsiderthesimpleexampleinFigure11.11ofadirectedgraph whereD is asingle fixedtreatmentandY is anoutcome ofinterest.As inmanyother examples in this book, the association between D and Y does not identify the causal effect of D on Y because of the back-door path D←O→Y. However, because O is observed, we can condition on it and generate a consistent estimate of D→Y for the reasons discussed extensively in Chapters 4 through 7.\nIfD andO arediscrete,thentheoverallcausaleffectofD onY iseasilyestimated viastratification(seeMatchingDemonstration1onpage145).Twodifferentstrategies, however, are possible. The standard approach would be to first estimate the causal effect of Y within strata of O and then calculate the overall causal effect of D on Y as the weighted average of the causal effects across strata where the weights are proportional to stratum size; see Equations (5.5) and (5.6). A second approachwould be to estimate the expectation of each of the potential outcomes, Y1 and Y0, within each stratum of O as p EN[yi|di=1,oi=o]−→E[Y1|O=o], (11.54) p EN[yi|di=0,oi=o]−→E[Y0|O=o].\nWeightedsumsofthesestratifiedestimatescanthenbetaken,whichwillbeconsistent estimates of E[Y1] and E[Y0] because (cid:6) E[Y1]= E[Y1|O=o]Pr(O=o), (11.55) O (cid:6) E[Y0]= E[Y0|O=o]Pr(O=o). (11.56) O To then estimate the ATE, the researcher takes the difference between the sample analogs to the expectations in Equations (11.55) and (11.56).\nThis generalapproachto estimationis G-computation,and Equations(11.55) and (11.56) are an example of what are labeled G-formulas. The “G” for “General” is meant to indicate that this procedure representsa generalapproachto the estimation ofacausaleffect.Ifacausaleffectisidentified,andignorabilityholds,theninprinciple acausaleffectcanbeestimatedusingG-computation.Asimplebutkeyrequirementis that we are consideringaveragecausal effects defined using expectations.In this case, causal effects calculated as weighted averagesof differences within strata are equal to causal effects calculated as differences between weighted outcomes across strata.\nConsider what G-computation does. G-computation stratifies the sample in order to estimate the expected potential outcome for each possible treatment regime under the assumption that all individuals have the same treatment status. With consistent estimatesoftheseexpectedpotentialoutcomes,estimatingthe effectofanytreatment regimerelativetoanyothertreatmentregimethenonlyrequiresthatonecalculatethe differences between these expectations. An important point in this literature is that controlleddirecteffects canbe thoughtof asdifferences between compoundeffects for different combinations of treatments, as we will demonstrate below.\nNow consider again the directed graph in Figure 11.10. From a G-computation perspective, what we want to estimate are the outcomes of Y for the four different 12 regimes (i.e., the four possible combinations of values of D and D ). Because sus- 10 12 pense offers no explanatory value for this appendix, we will revealthese values before we show how to estimate them: E[Y |D =1,D =1]=.74, (11.57) 12 10 12 E[Y |D =0,D =1]=.64, (11.58) 12 10 12 E[Y |D =1,D =0]=.44, (11.59) 12 10 12 E[Y |D =0,D =0]=.44. (11.60) 12 10 12 Fromthe valuesinEquations(11.57)–(11.60),itistrivialtocalculatethecausaleffect ofoneregimerelativetoanother.33 Noticethis shiftinlanguage:fromtotalanddirect effects to alternative treatment regimes. In particular, we can calculate the expected effect of enrollment in Catholic school in the tenth grade as E[Y |D =1,D =1]−E[Y |D =0,D =0]=.74−.44=.3.\n12 10 12 12 10 12 Mostimportantforourconsiderationofdirecteffects,thevaluesinEquations(11.57)– (11.60) can be used to calculate the difference in Y produced by D , separately by 12 10 thevalueofD .Theseare,infact,whatwelabeledthecontrolleddirecteffectsabove: 12 CDED10→Y12(D 12=1) =E[Y |D =1,D =1]−E[Y |D =0,D =1] 12 10 12 12 10 12 (11.61) =.74−.64 =.1, 33Inaddition, twoequivalences areworthnoting at this point. Given the Markovstructure of the graph, the values in Equations (11.57)–(11.60) are equivalent to expected potential outcomes. They are also equivalent to the conditional expectations in Equations (11.47)–(11.50), averaged over the distributionofU.\nCDED10→Y12(D 12=0) =E[Y |D =1,D =0]−E[Y |D =0,D =0] 12 10 12 12 10 12 (11.62) =.44−.44 =0, butnowU isnolongerpresentforreasonswewillexplainbelow;seeEquations(11.51) and (11.52) for comparison. In the literature on dynamic treatment regimes, these differencesaresimplytheeffectofCatholicschoolinginthetenthgradeontestscoresin thetwelfthgradecalculatedfirstfortheregimeinwhichstudentsalsoattendCatholic schools in the twelfth grade and then second for the regime in which students do not attend Catholic schools in the twelfth grade.34 In short, with the values in Equations (11.57)–(11.60), we can calculate all of the treatment effects we want for all contrasts across the permissible treatment regimes.\nHow do we estimate these values with G-computation? We use the appropriate G-formula: E[Y |D ,D ]=E[Y |D ,D ,Y =1]×Pr[Y =1|D ] 12 10 12 12 10 12 10 10 10 (11.63) +E[Y |D ,D ,Y =0]×Pr[Y =0|D ].\n12 10 12 10 10 10 Although the structure of this G-formula is given by the graph and the identifying assumptions that it represents, the computed expectation can be interpreted as the expectedoutcome forY forthe particularcombinationofvaluessetby interventions 12 on D and D . The right-hand side is a sum of two products, where each product 10 12 includes the appropriate conditional expectation weighted by whether Y equals 1 or 10 0. This weight is conditional on D , but not D (because Y is determined by D 10 12 10 10 but not by D ).35 12 Operationally,wetakeeightstratadefinedacrossalltwo-waycombinationsofD , 10 D , and Y and then calculate the mean values for Y . We then averageover strata 12 10 12 defined by Y , conditionalon patterns of D and D , to generate the four values in 10 12 10 Equations (11.57)–(11.60).\nFor this example, the expectations for the relevant eight strata are presented in the seventhcolumn ofTable 11.5. Sample analogsto the conditionalexpectations will converge to the true values for these conditional expectations: p EN[y 12|d 10=1,d 12=1,y 10=1]−→.811, p EN[y 12|d 10=1,d 12=1,y 10=0]−→.657, p EN[y 12|d 10=0,d 12=1,y 10=1]−→.753, p EN[y 12|d 10=0,d 12=1,y 10=0]−→.582, (11.64) 34Inthisliterature,controlleddirecteffectsareconsidereddifferencesincompoundeffectsforalter- nativecombinationsoftreatments.\n35For completeness, we should note that the G-formula for the direct effect D 10→D 12 is much simpler.ItisE[D 12|D 10,Y 10]anddoesnotrequireaveragingoveranyunderlyingstrata.\np EN[y 12|d 10=1,d 12=0,y 10=1]−→.511, p EN[y 12|d 10=1,d 12=0,y 10=0]−→.357, p EN[y 12|d 10=0,d 12=0,y 10=1]−→.553, p EN[y 12|d 10=0,d 12=0,y 10=0]−→.382.\nInserting these conditional expectations into the G-formula in Equation (11.63), and whileassuminganinfinitesample,wecancalculatethedesiredfourvaluesinEquations (11.57)–(11.60) as EN[y 12|d 10=1,d 12=1] =.811×PrN[y 10=1|d 10=1]+.657×PrN[y 10=0|d 10=1] (11.65) =(.811×.55)+(.657×.45) =.74, EN[y 12|d 10=0,d 12=1] =.753×PrN[y 10=1|d 10=0]+.582×PrN[y 10=0|d 10=0] (11.66) =(.753×.34)+(.582×.66) =.64, EN[y 12|d 10=1,d 12=0] =.511×PrN[y 10=1|d 10=1]+.357×PrN[y 10=0|d 10=1] (11.67) =(.511×.55)+(.357×.45) =.44, EN[y 12|d 10=0,d 12=0] =.553×Pr[y 10=1|d 10=0]+.382×PrN[y 10=0|d 10=0] (11.68) =(.553×.34)+(.382×.66) =.44, wheretheconditionalprobabilitiesPrN[y 10=1|d 10=1],PrN[y 10=0|d 10=1],PrN[y 10= 1|d 10=0],andPrN[y 10=0|d 10=0]arecalculatedfromthe finalcolumnofTable11.5.\nWith the four values produced by Equations (11.65)–(11.68), we can estimate the causaleffectforanytwocontrastingtreatmentregimes,asshownabovewithreference to the values in Equations (11.57)–(11.60). In effect, the structure of the graphallows ustocollapsethestratadefinedbyY aslongasthestrataareweightedinaccordance 10 withtheconditionalprobabilitydistributionsencodedbythegraph.Aswewillexplain in the next section, there are alternative methods available to achieve this type of weighted collapsing.\nD 10 Y 10 D Y 12 12 U Figure11.12 Adirectedgraphforapseudo-populationproducedusinginverseprob- ability of treatment weighting.\nAlternatives to G-Computation.If thereis sufficientdataandthe appropriate ignorability assumptions hold, estimating a saturated model via G-computation will always provide consistent estimates of the causal effect of any one regime relative to another. From these treatment regime differences, one can then calculate the relevant controlled direct effects.\nHowever, because of the curse of dimensionality, G-computation-based estimates can be very imprecise because some conditional expectations will be estimated for strata with very small samples. In this final section, we consider two alternative approaches to G-computation that are meant to deal with the curse of dimension- ality: marginal structural models (MSMs) estimated via inverse probability of treat- mentweighting(IPTW),andstructuralnestedmeanmodels(SNMMs)estimatedviaa G-estimation. Our discussion of the later approach will be brief.\nMarginal Structural Models (MSMs). These models are attracting interest in soci- ology and have been used in several published papers (Wimer, Sampson, and Laub 2008;SharkeyandElwert2011;Wodtke,Harding,andElwert2011).Theyarelabeled structural because they estimate a causal effect and marginal because the effect that is estimated is the marginal effect over a set of collapsed strata. MSMs are attracting interest because they are feasible when G-computation is not, because they are com- paratively easy to understand relative to G-estimation (see below), and because they can be estimated using available software.\nConsiderthe directedgraphin Figure 11.12. Notice that D is notdetermined by 12 either D or Y . As a result, D no longer has an indirect effect on Y through 10 10 10 12 Y and D . As a result, there is no reason to condition on either Y or D when 10 12 10 12 estimating the causal effect of D on Y for this graph. Notice also that the path 10 12 D →Y ←U→Y that connects D to Y is blockedby the collider Y . As long 10 10 12 10 12 10 as we do not condition on Y , this path will remain blocked. If the directed graph 10 in Figure 11.12 described our data, the unconditional association between D and 10 Y wouldidentify the (direct) effect of D on Y . It would also be the case that the 12 10 12 unconditionalassociationbetweenD andY wouldidentifytheeffectofD onY .\n12 12 12 12 Of course, the causal dependence of D on D and Y cannot just be assumed 12 10 10 away. Nonetheless, Robins (1999) showed how one can create a pseudo-population in which the directed graph in Figure 11.12 can be substituted for the directed graph in Figure 11.10. The pseudo-population construction is achieved using the inverse prob- ability weighting methods we presented in Chapter 7. In particular, after examining the directed graphin Figure 11.10, one estimates a propensity score model predicting assignment to D as a function of D and Y : 12 10 10 Pr(D =1|D ,Y )=F(D ,Y ). (11.69) 12 10 10 10 10 For each individual, the probability of enrolling in a Catholic school in the twelfth gradecaneither be estimatednonparametricallyfromthe dataif thereareasufficient numberofcasesorusingagenerallinearmodel,suchasalogitorprobit.We canthen define the weights in two different ways: 1 For d 12i=1: wi,MSM= , pˆi 1 For d 12i=0: wi,MSM= 1−pˆi, or swi,MSM=EN[d 12=1] For d 12i=1: , pˆi For d 12i=0: swi,MSM=1−E 1N −[d pˆ1 i2=1] , where pˆis the estimated probability for eachindividual of enteringCatholic schooling in the twelfth grade based on Equation (11.69). Robins and Hern´an (2009) refer to the wi weights as “unstabilized weights” and the swi weights as “stabilized weights.” Unstabilizedweightsgenerallyhavegreatervarianceandtypicallyleadto wider confi- dence intervals. As such, stabilized weights are usually recommended, although there are special circumstances where stabilized weights will produce inconsistentestimates of causal effects (Robins and Herna´n 2009:576).\nTable11.7presentsthepseudo-populationproportionsthatwouldresultfromnon- parametric estimation of the weights for the dynamic treatment regime versionof the Catholic school effect we have been analyzing in this appendix. The final column of this table can be directly compared to the observed population proportions in Table 11.5 that we set by construction for the hypothetical example. If we use these esti- matedproportionstocalculateweightedmeansofY conditionalonvaluesforallfour 12 combinations of D and D , we can then calculate differences to recover the total 10 12 effect of D on Y as well as the two controlled direct effects.\n10 12 The advantage of MSMs, relative to G-computation, is that we do not have to calculate the means of Y within each stratum (i.e., across Y as in our example).\n12 10 Instead, we estimate weights and then calculate contrasts for Y with the weighted 12 data.Thisisthesameadvantagethatthepropensity-score-basedweightingestimators presented in Chapter 7 have relative to the full stratification estimators presented in Chapter5.MSMsstillrequirepositivitywithrespecttoallpossibletreatmentregimes, buttheypermitsparsenessinobservedvariablesthatdeterminetreatmentassignment, just as for propensity-score estimators for a fixed-time treatment regime.\nTable 11.7 Pseudo-PopulationProportions for the Directed Graph in Figure 11.12 Pseudo-Population D 10 Y 10 D 12 Y 12 Proportion 1 1 1 1 .041 1 1 1 0 .010 1 1 0 1 .093 1 1 0 0 .037 1 0 1 1 .031 1 0 1 0 .036 1 0 0 1 .021 1 0 0 0 .025 0 1 1 1 .082 0 1 1 0 .020 0 1 0 1 .011 0 1 0 0 .064 0 0 1 1 .145 0 0 1 0 .104 0 0 0 1 .107 0 0 0 0 .173 Accordingly, MSMs can be a very useful approachto dealing with “damned if you do, damned if you don’t” situations. MSMs, however, are not a panacea and have several weaknesses. First, and most importantly, even stabilized weights can produce unusually large weights resulting in imprecise estimates. In Chapter 7, we have dis- cussedvarious methods, suchas trimming,for dealingwith this situation, noting that these methods will lead to biased estimates. Second, MSMs cannot be used when an instrumentalvariableisavailable.Third,the types ofsensitivityanalysis(seeChapter 12) that can be done with MSMs are limited (Robins and Herna´n 2009:592–93). We next consider a method, G-estimation (not to be confused with G-computation) that does not share these problems. Unfortunately, G-estimation is both more difficult to understand and more difficult to implement.\nG-estimation. Our discussion of G-estimation will be brief because our goal is to give the reader an intuitive understanding of how G-estimation works, with the hope that when readers encounter these methods, they will have a basic understanding of the procedure.G-estimationis closely relatedto the method ofgeneralizedestimating equations (GEE) and other methods-of-moments estimators. G-estimation seeks a set of estimates that satisfies an orthogonality condition. As we have discussed above, identification occurs when ignorability holds. Ignorability holds if the potential out- comes are independent of an individual’s past treatment, conditional on their past and present covariate history. The intuition behind G-estimation is that one wants to create a set of predicted counterfactual potential outcomes by modeling the observed outcomes. This goal is pursued by searching for a set of parameters that results in orthogonality of both observed and the predicted potential outcomes with respect to treatmentassignment,conditionalontreatmenthistoryandcurrentandpastcovariate values. Unfortunately, in most cases it is necessary to use a grid search procedure to findthedesiredsetofparameters,whichcanrequiresubstantialcomputingpowerand time to generate results. Also, as far as we are aware, no software routines have been shared for use with either commercial or freely available data analysis programs. For more details on G-estimation, consult (Robins and Herna´n 2009:577–92).\nConclusions We have chosen a simple example where the data are generated from a hypothetical dynamic treatment regime, and we have then shown how it is possible to identify static treatment effects from such data. This example is rich enough to convey both the basic identification results and the clever ways in which estimation is rendered feasible with the methods developed by Robins and his colleagues. If one’s interest is in identifying dynamic treatment effects, then identification and estimation are con- siderably more challenging (see Robins and Hern´an 2009). If sequential ignorability doesnot holdbecause confounderssuchasU in ourexample determine either or both of the treatment exposure variables, then the models developed in this literature are not identified, just as in the case for fixed treatment regimes. In addition, not all esti- mation issues have been resolved. G-computation is beyond reproach, but it is often infeasible because of insufficient data. Marginal structural models can be fragile for the same reasons as the weighted regression estimators discussed in Chapter 7. The specificationofthemodelthatgeneratesthe weightsmustbecorrect,andthe concern withextremeweightswillbepresentformanyapplications,especiallyifsomepatterns oftreatmentexposurearecomparativelyrare.Finally,G-estimationalsorequiresthat the model predicting potential outcomes be correct,something which may be difficult to test. In addition to Robins and Hern´an (2009), we recommend that readers seek additional guidance in Chakraborty and Moodie (2013).",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#set-identification-with-minimal-assumptions",
    "href": "extracted/Counterfactuals and Causal Inference.html#set-identification-with-minimal-assumptions",
    "title": "Counterfaturals and Causal Inference",
    "section": "12.2 Set Identification with Minimal Assumptions",
    "text": "12.2 Set Identification with Minimal Assumptions\nIfonecannot(ordoesnot)imposeastrongassumptiontopoint-identifyandthenesti-\nmate an average treatment effect, it is natural to wonder about an opposing strategy for analysis:What can be learned about averagecausal effects while imposing weaker but defendable assumptions? In a series of articles and books that have built on less formalized work of the past, Manski (1994, 1995, 1997, 2003, 2013b) has investigated plausible values for treatment effect parameters, such as the ATE, that are consis- tent with the data when weak assumptions alone are maintained. In this section, we introduce Manski’s work to show that, in most researchsituations, the observed data themselves provide some information on the size of average treatment effects without any assumptions. We then introduce some of the additional assumptions considered by Manskito showhowthey boundaveragecausaleffects topermissible intervals.We use the label of “set identification” in contrast to point identification of single values.\nManski often uses the alternative phrase “partial identification,” and many writers refer to this strategy as an “analysis of bounds.” 12.2.1 No-Assumptions Bounds To see why the collection of data can bound the range of permissible values for the ATE, consider a hypothetical example in which we know that both Y1 and Y0 are bounded by 0 and 1, and thus that Y is also bounded by 0 and 1. Examples could be dichotomous potential outcomes for graduating high school or not in response to twocausalstates,suchasCatholicschoolingorpublicschooling,discussedextensively already.OrthepotentialoutcomescouldbewhetheronevotedforAlGore,depending on whether or not one received a butterfly ballot. This latter example (see Section 1.3.2)wouldbe especiallyappropriateto analyzefroma bounds andset-identification perspective because the goal of such a causal analysis would be to determine whether thecausaleffectisplausiblylargeenoughtohaveflippedtheelectionresults.Withthat goal clearly in focus, concerns over putative statistical significance are of secondary concern.\nIn this case, we know from the definitions of Y1 and Y0, even without collect- ing data, that the ATE, E[δ], cannot be greater than 1 or less than −1. This is a straightforward implication of the obvious point that no individual treatment effect can be greater than 1 or less than −1. Accordingly, the maximum ATE of 1 would occur if E[Y1|D=1]=E[Y1|D=0]=1 and E[Y0|D=1]=E[Y0|D=0]=0, whereas the minimum ATE of −1 would occur instead if E[Y1|D=1]=E[Y1|D=0]=0 and E[Y0|D=1]=E[Y0|D=0]=1. Thus, we know that E[δ] must be contained in an intervaloflength2,whichcanbestatedasaknownboundonE[δ],usingthenotation −1≤E[δ]≤1 (12.6) Table 12.1 A Hypothetical Example of the Calculation of Bounds for the ATE E[Y1| .] E[Y0| .] Naive estimator suggests E[δ]=.4 Treatment group E[Y1|D=1]=.7 E[Y0|D=1]= ? Control group E[Y1|D=0]= ? E[Y0|D=0]=.3 Largest possible E[δ]=.7 Treatment group E[Y1|D=1]=.7 E[Y0|D=1]=0 Control group E[Y1|D=0]=1 E[Y0|D=0]=.3 Smallest possible E[δ]=−.3 Treatment group E[Y1|D=1]=.7 E[Y0|D=1]=1 Control group E[Y1|D=0]=0 E[Y0|D=0]=.3 or that E[δ] lies in an interval with closed bounds, as in E[δ]∈[−1,1]. (12.7) Manski has shown that we can improve on these bounded intervals considerably without making additional assumptions but by collecting data on Y and D. By fol- lowing a systematic sampling strategy from a well-defined population, we can assert the specific convergence results stated earlier in Equations (2.9)–(2.11). These would ensure that, for an infinite sample, EN[di]=E[D], EN[yi|di=1]=E[Y1|D=1], and EN[yi|di=0]=E[Y0|D=0].Knowledgeofthesethree quantitiesallowsonetonarrow the bound of width 2 in Equations (12.6) and (12.7) to one with a width of only 1.\nConsider the hypothetical example depicted in Table 12.1, where, as shown in the first panel, we stipulate that E[Y1|D=1]=.7 and E[Y0|D=0]=.3. The naive estimator, EN[yi|di=1]−EN[yi|di=0], would yield values that converge to .4 as the sample size increases. Note that the naive estimator does not use the information about the distribution of the sample across the observed values of D. And, we leave question marks to stand in for the unknown values of the counterfactual conditional expectations E[Y1|D=0] and E[Y0|D=1].\nSuppose that E[D]=.5 and that our sample is infinite such that sampling error is 0. And, for simplicity of notation and consistency with the decomposition in Chap- ter 2, allow π to again stand in for E[D]. For the second and third panels of Table 12.1, the minimum and maximum values of 0 and 1 for the counterfactual conditional expectations E[Y1|D=0] are E[Y0|D=1] and substituted for the question marks in the first panel.\nIf half of the sample is in the treatment group, and if E[Y1|D =1]=.7 and E[Y0|D=0]=.3, then the largest possible treatment effect is .7, whereas the small- est possible treatment effect is −.3. This result is a straightforward calculation using what-if values for the decomposition of the ATE presented in Equation (2.10), which wasusedearlierinChapter 2andelsewhereto discuss the bias ofthe naiveestimator: E[δ]={πE[Y1|D=1]+(1−π)E[Y1|D=0]} (12.8) − {πE[Y0|D=1]+(1−π)E[Y0|D=0]}.\nPlugging in the values from the second panel of Table 12.1 into the decomposition in Equation (12.8) yields the largest possible treatment effect as E[δ]={(.5)(.7)+(1−.5)(1)} −{(.5)(0)+(1−.5)(.3)} =.85−.15 =.7, whereas plugging in the values from the third panel yields the smallestpossible treat- ment effect as E[δ]={(.5)(.7)+(1−.5)(0)} −{(.5)(1)+(1−.5)(.3)} =.35−.65 =−.3.\nThus, the constraints implied by the observeddata alone guarantee,for this example, that E[δ]∈[−.3,.7], which is an interval of length 1 and is half the length of the maximum interval calculated before estimates of π, E[Y1|D=1], and E[Y0|D=0] were obtained from the data.\nManskilabels this intervalthe “no-assumptionsbound” because it requiresknowl- edgeonlyoftheboundsonY1 andY0,aswellascollectionofdataonY andD froma systematic random sample of a well-defined population. Consider now a more general development of these same ideas.\nThe treatment effect can be bounded by finite values only when the potential outcomesY1andY0areboundedbyfinitevalues.Inotherwords,becauseE[Y1|D=0] and E[Y0|D=1] are both unobserved, they can take on any values from −∞ to ∞ in the absence of known restrictions on the ranges of Y1 and Y0. Thus, in the absence of any known restrictions on E[Y1|D=0] and E[Y0|D=1], E[δ] is contained in the completely uninformative interval between −∞ and ∞.\nManski(1994,1995,2003)showsthatwithpotentialoutcomevariablesboundedby 1and0,theno-assumptionsboundwillalwaysbeoflength1.Thisresultisobtainedby a more generalmanipulation of Equation (12.8), for which the lower bound is derived as {πE[Y1|D=1]+(1−π)(0)} −{π(1)+(1−π)E[Y0|D=0]}, (12.9) and the upper bound is derived as {πE[Y1|D=1]+(1−π)(1)} −{π(0)+(1−π)E[Y0|D=0]}. (12.10) SimplifyingandthencombiningEquations(12.9)and(12.10)yieldstheno-assumptions bound for potential outcomes bounded by 1 and 0: πE[Y1|D=1]−(1−π)E[Y0|D=0]−π (12.11) ≤E[δ] ≤πE[Y1|D=1] −(1−π)E[Y0|D=0]+(1−π).\nThe length of the bound is 1 because the upper and lower bounds differ only by two complementaryprobabilities π and1−π that sum to 1. The locationof the bound in the [−1,1] interval is set by the common term πE[Y1|D=1] −(1−π)E[Y0|D=0], to which −π and 1−π are then added to form the bound.\nMore generally, if Y1 and Y0 are bounded by any finite values a and b, where b&gt;a, such as theoretical minimum and maximum scores on a standardized test, then Equation (12.6) can be written more generally as −b+a≤E[δ]≤b−a, (12.12) which then generates the more general no-assumptions bound for the observed data: πE[Y1|D=1]−(1−π)E[Y0|D=0]+a(1−π) −bπ (12.13) ≤E[δ] ≤πE[Y1|D=1]−(1−π)E[Y0|D=0]+b(1−π)−aπ.\nThe same basic results hold as before. The no-assumptions bound always includes 0, anditisonlyhalfaswideastheboundinEquation(12.12)impliedonlybythebounds on the potential outcomes. In this case, the no-assumptions bound is of length b−a rather than of length 2(b−a).2 As with the case for potential outcomes bounded by 1 and 0, the particular location of the interval of length b−a in [−b+a,b−a]is again determined by the same term, πE[Y1|D=1]−(1−π)E[Y0|D=0].\n12.2.2 Bounds Under Additional Weak Assumptions ForManski,calculationoftheno-assumptionsboundisonlythestartingpointofaset- identificationanalysis.Theprimarygoalistoanalyzehowadditionalassumptionscan narrowthe no-assumptionsbound. Manski’sbasicperspectiveis summarizednicely in the following passage: Empirical researchers should be concerned with both the logic and the credibility of their inferences. Credibility is a subjective matter, yet I take there to be wide agreement on a principle I shall call: TheLawofDecreasingCredibility:Thecredibilityofinferencedecreases with the strength of the assumptions maintained.\nThisprincipleimpliesthatempiricalresearchersfaceadilemmaasthey decide what assumptions to maintain: Stronger assumptions yield infer- ences that may be more powerful but less credible. (Manski 2003:1) Manski has shown that weak and often plausible assumptions can substantially nar- row the no-assumptions bound. Consider the following simple assumptions about the direction of individual-level treatment effects and the direction of self selection.3 2To see this result, note that [b−a]+[−1(−b+a)] simplifies to 2(b−a), and [b(1−π)−aπ] +[−1(a(1−π) −bπ)]simplifiestob−a.\n3Forempiricalexampleswiththesamestructure,seefirsttheapplicationsofferedatthetimeMan- skiwasdevelopingtheset-identificationperspective(e.g.,ManskiandNagin1998;Manski,Sandefur, McLanahan, andPowers1992). Morerecently, Manskihasusedthesamebasicapproach tocritique the“duelingcertitudes”andother noncredibleclaimsthatpervadepublicpolicypronouncements in academicresearchandbeyond(Manski2013b). SeealsoReinandWinship(1999).\nMonotone Treatment Response Inmanysituations,itmaybereasonabletoassumethattheindividual-leveltreatment effect cannot be negative, such that δ≥0 for every individual i. Manski labels this assumption the monotone treatment response (MTR) assumption.\nUnder MTR (in the direction where δ≥0), the lower bound for the ATE must be0.MTRimpliesthatmembersofthecontrolgrouphavecounterfactualvaluesofy1 i thatareatleastashighastheir observedvalues ofyi.The reasoninghereis simple:If yi=y i0 for members of the control group, then the MTR assumption that y i1 ≥y i0 for all individuals i implies that y i1 ≥yi for members of the control group. The opposite is likewise true for members of the treatment group; their counterfactual values for y i0 are no higher than their observed values of yi. Under MTR for the hypothetical examplepresentedinTable12.1,onecanthereforereplacetheextremevaluesof1and 0 in the no-assumptions lower bound: {(.5)(.7)+(1−.5)(0)} −{(.5)1+(1−.5)(.3)}=−.3 with less extreme values of .7 and .3. As a result, one obtains a new lower bound: {(.5)(.7)+(1−.5)(.3)} −{(.5)(.7)+(1−.5)(.3)}=0, implyingthattheboundfortheATE,assumingMTRinthis direction,is[0,.7]rather than [−.3,.7].\nMonotone Treatment Selection Itmay alsobe reasonableto assumethatthose who receivethe treatmenthavehigher average outcomes under potential exposure to both the treatment and control, which Manski labels the monotone treatment selection (MTS) assumption. In most cases, one would assume jointly that E[Y1|D=1]≥E[Y1|D=0] and E[Y0|D=1]≥E[Y0| D=0], which is traditionally thought of as positive self-selection. (But one could flip the direction of the assumption, just as we also noted for MTR.) Manski and Pepper (2000)presentthis type ofMTSassumptionforthe example ofthe effectofeducation on earnings, for which it is equivalent to assuming that individuals with higher edu- cation would on average receive higher wages than individuals with lower education, under counterfactual conditions in which they had the same levels of education.\nFor the hypothetical example presentedin Table 12.1, MTS implies that the naive estimator would be an upper bound for the ATE. In short, MTS in this direction stipulates that members of the treatment groupcould not have done any worse in the control state than those observedin the control group(and, vice versa,that members of the controlgroupcouldnot have done any better in the treatment state than those observedinthetreatmentgroup).MaintainingMTSallowsonetoreplacetheextreme values of 1 and 0 in the no-assumptions upper bound, {(.5)(.7)+(1−.5)(1)} −{(.5)0+(1−.5)(.3)}=.7, with the less extreme values of .7 and .3, yielding for this example, {(.5)(.7)+(1−.5)(.7)} −{(.5)(.3)+(1−.5)(.3)}=.4.\nMTS thereby implies that the bound for the ATE is [−.3,.4] rather than [−.3,.7].\nMonotone Treatment Response and Treatment Selection Together ThepowerofManski’sapproachcomesfromtheabilitytoapplymultipleassumptions at the same time in order to narrow the no-assumptions bound to a bound that is considerablymore informative. For the hypothetical example presented in Table 12.1, one can narrow the no-assumptions bound from [−.3,.7] to [0,.4] by invoking the MTR and MTS assumptions together. The resulting bound still includes 0, but in someapplicationssuchnarrowingmaywellbehelpfulinrulingoutsomeunreasonable and extreme causal claims.\nMonotone Instrumental Variables WhereastherecentworkofHeckmanandhiscolleagueshasdemonstratedhowpower- ful the conclusions of a study can be if a perfect and finely articulated IV is available (see Section 9.3.4), Manski’s work on IVs probes the opposite territory, following on the consideration in his early work of the capacity of traditional IVs to narrow the no-assumptionsbound(seeManski1994,1995).ManskiandPepper(2000)investigate what can be learned about the ATE when both standard and weaker IV assumptions are maintained. Their results are then presented as a component of the general set- identification methodology laid out in Manski (2003; see especially chapter 9).\nManski and Pepper (2000) first define the traditional IV assumption in terms of meanindependence,afterconditioningonacovariateX forgenerality.Inournotation, thestandardIVassumptionofnodirecteffectofZ onY (byeitherY1orY0)iswritten out as E[Y1|X,Z=z(cid:2) ]=E[Y1|X,Z=z(cid:2)(cid:2)], (12.14) E[Y0|X,Z=z(cid:2) ]=E[Y0|X,Z=z(cid:2)(cid:2)], (12.15) for any two values z(cid:2) and z(cid:2)(cid:2) of Z (and separately for strata defined by X). In other words, Equations (12.14) and (12.15) require that the expectations of the potential outcomes be equal within strata defined by Z (conditional on X). Accordingly, the boundsanalysispresentedabovethenapplieswithineachstratumofZ,andthebound on the ATE can then be defined as the intersection of the bounds across the strata definedbyZ.Thisresultimpliesthattheno-assumptionsboundcanonlybenarrowed by an IV if the no-assumptions bounds that could be calculated within each stratum z of Z also vary across the strata defined by Z.\nManski and Pepper (2000) then consider a weaker assumption for an IV analy- sis, known as a monotone IV (MIV) assumption. It states that for all values of the instrument Z, in which z(cid:2)(cid:2)≥z(cid:2), the variable Z is an MIV if E[Y1|X,Z=z(cid:2)(cid:2) ]≥E[Y1|X,Z=z(cid:2)], (12.16) E[Y0|X,Z=z(cid:2)(cid:2) ]≥E[Y0|X,Z=z(cid:2)]. (12.17) In Equations (12.16) and (12.17), the expected values of both potential outcomes are weakly increasing in Z. Note that this usage of the concept of monotonicity is quite different than for a local averagetreatment effect (LATE) analysis or an LIV analysis (see Section 9.3, beginning on page 305). For an MIV, monotonicity refers to the relationship between the instrument and the potential outcomes, not the relationship between the treatment and the instrument. The latter type of assumption is referred to as monotone treatment selection (MTS) by Manski and his colleagues (see our discussion above).\nTo what extent does an MIV narrow the bound for the ATE (or, in the words of Manski 2003, shrink the identification region for it)? The short answer: No more than a traditional IV (and usually considerable less), but still enough to have some identifying power.\nItiseasiertoexplainhowanMIVboundstheexpectationofeachpotentialoutcome than it is to demonstrate directly how an MIV bounds the ATE that is a function of these expectations. Consider just the determination of the upper bound for E[Y1].\nUnder the standard IV assumption of mean independence, the upper bound for E[Y1]isequaltothesmallestupperboundacrossthedifferentsubpopulationsdefined by the instrument Z. More precisely, the upper bound is the smallest value that E[Y1|Z=z] takes on across all values z of Z.\nIn contrast, under the weaker MIV assumption, the upper bound for E[Y1] is a weightedaverageofsubpopulationupper bounds,forwhicheachsubpopulationupper bound is defined across the values of Z. The implicit calculation of this upper bound on E[Y1] can be described in a series of as-if algorithmic steps. First, a value of Z is selected as z(cid:2). The upper bound for E[Y1], with respect to z(cid:2), is set as the smallest value that E[Y1|Z=z] takes on across all values z(cid:2)(cid:2) of Z where z(cid:2)(cid:2) ≥z(cid:2).4 After this smallest upper bound is found with z(cid:2) fixed, the next value of z(cid:2) is selected, and a smallest upper bound is found with respect to this next z(cid:2). After all values of Z have been selected as z(cid:2), the upper bound for E[Y1] is set as the weighted average of the subpopulation upper bounds with respect to each value of Z, where the weights are the marginal distribution of Z attached pointwise to the smallest upper bounds set withrespecttoallz(cid:2) ofZ.ThedeterminationofthelowerboundonE[Y1]underMIV is the opposite of this procedure, in the sense that the greatest lower bound is first sought across subpopulations of Z, restricting the range of Z over which one searches in each step to be larger than the selected anchoring point z(cid:2) of Z.\nTofind the bounds implied byanMIVfor the ATE,the bounds onE[Y0]mustbe calculated with the same basic procedure.These bounds can then be substituted into thesamebasicframeworkintroducedinthelastsection,withthemarginaldistribution of D used to characterize the known distribution across treatment states.\nOf course, as we noted above, the goal of a set-identification analysis is to invoke combinations of weak assumptions.5 As with the more general set-identification 4Becausethissmallestupperboundrelativetoz(cid:3)isselectedfromasmallersubsetofpossibleupper bounds (onlythosegreater than z(cid:3) ratherthan allvalues ofZ),theresultingweighted upperbound acrossz(cid:3)isbydefinitionnosmaller(andusuallylarger)thanwouldbetheupperboundsuggestedby amorestringentmean-independenceIVassumption.Asaresult,MIVsnevershrinktheidentification regionmorethantraditionalIVs(andusuallyconsiderableless).\n5Inapriorversionoftheirmanuscript,ManskiandPepperusedtheMTR,MTS,andMIVassump- tionstogethertodeterminetheboundsontheeffectofeducationontheloggedwagesofrespondents fortheNationalLongitudinalSurveyofYouth.WhentheyinvokedMTRandMTSassumptions,they foundthattheboundfortheeffectofatwelfthyearofschoolingwas[0,.199],thattheboundforthe effectofafifteenthyearofschoolingwas[0,.255],andthattheboundfortheeffectofasixteenthyear ofschoolingwas[0,.256].WhentheythenusedtheArmedForcesQualificationTestasanMIVwhile still maintaining the MTR and MTS assumptions, they obtained narrower bounds, respectively, of [0,.126],[0,.162],and[0,.167].\napproach,it is generally difficult to eliminate values of 0 for averagetreatment effects in this tradition, but the methodology can be used, as Manski shows, to convincingly reject extreme causal effect assertions and build regions of credible inference to move the literature forward in any given area. Moreover, it is presumably much easier to find MIVs in any substantiveareathan IVs thatallow for the identificationofLATEs or full schedules of MTEs.\nIn sum, the set-identification approach is a principled and strict framework for developing warranted causal claims. In part because it is so strict, but more funda- mentallybecausescholarsandreviewersvaluepointestimatessohighly,theusagerate of set-identificationstrategies in empirical researchremains quite low. For exceptions, it is well worth consulting the applications offered at the time Manski was developing his set-identification perspective (e.g., Manski and Nagin 1998; Manski et al. 1992).\nMorerecently,Blundell,Gosling,Ichimura,andMeghir(2007)use abounds approach to analyze wage trajectories for men and women. Gunderson, Kreider, and Pepper (2012) offer an MIV application to generate support for the claim that reduced-price lunches in public schools have positive effects on health outcomes of children. Manski and Pepper (2013) offer a full analysis of the deterrence effect of the death penalty.\nAnd, following on the general orientation reflected in this last piece, Manski (2013b) offers an extended critique of the “dueling certitudes” and other noncredible claims that pervade public policy pronouncements in academic research and beyond.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#sensitivity-analysis-for-provisional-causal-effect-estimates",
    "href": "extracted/Counterfactuals and Causal Inference.html#sensitivity-analysis-for-provisional-causal-effect-estimates",
    "title": "Counterfaturals and Causal Inference",
    "section": "12.3 Sensitivity Analysis for Provisional Causal Effect Estimates",
    "text": "12.3 Sensitivity Analysis for Provisional Causal Effect Estimates\nConsiderasituationwherearesearchersuspects,basedonsubstantiveknowledgefrom\nother studies or a particular theoretical perspective, that treatment selection is non- ignorable because selection is, in part, on unobserved variables. Yet, the researcher is unwilling to adopt the set-identification perspective because she feels that the viola- tionsofthepoint-identifyingassumptionsareverysmall.Inthiscase,shemaywantto offer a causal effect estimate under the assumption that treatment selection is ignor- able,butsheshouldthenjudgehowwrongtheresultsmaybeandofferinterpretations that are appropriately cautious.\nAlthough Blalock is often accused of inspiring naive causal analysis (and we have engaged, as well, in our own share of Blalock criticism in Chapter 1), he did warn against overconfident causal claims based on conditioning with regression methods long before most of the methods we have presented in this book were developed. At the end of his influential 1961 book Causal Inferences in Nonexperimental Research, he wrote: It seems safe to conclude that the problem of making causal inferences on the basis of nonexperimental data is by no stretch of the imagination a simple one. A number of simplifying assumptions must be made, per- haps so many that the goal would seem almost impossible to achieve. The temptationmayverywellbetogiveuptheentireventure.But,aswehave suggestedatanumberofpoints,theremaynotbeanysatisfactoryalterna- tives. Most likely, social scientists will continue to make causal inferences, either with or without an explicit awareness of these problems. (Blalock 1964[1961]:184) His recommendation was to report a range of plausible results, and he lamented the pressures to settle in on only one favored set of results: itwouldbe extremelyhelpful ifsocialscientistswoulddevelopthe habitof contrasting the results of several different procedures. … If conclusions or results differed, one might gain valuable insights as to why specific differences have occurred. … Present practices and publication policies are undoubtedly unfavorable to such a strategy. … there are undoubtedly pressures on the individual investigator to report only his “best” results in instances where different techniques have not given the same results.\n(Blalock 1964[1961]:184–85) In the decades since scholars such as Blalock appealed for the multimodel reporting of results, a number of scholars have attempted to systematize this approach.\nInthecounterfactualtradition,theapproachknownassensitivityanalysishasbeen the most influential.6 Based largely on the work of Rosenbaum and his colleagues (see Rosenbaum 1991, 1992, 2002, 2010), the guiding principle of the approach is simple: When reporting and interpreting an estimate of a causal effect, researchers should analyze and report how sensitive the estimates and interpretations are to the maintained assumptions of the analysis.\nFor Rosenbaum, sensitivity analysis of this form is quite distinct from other types of robustness checks on one’s results because of its concern with estimates of causal effects. Rosenbaum (1999:275) writes, “Assumptions are of three kinds: (i) the sci- entific model or hypothesis, which is the focus of scientific interest, (ii) incidental assumptions, needed for statistical inference but of little or no scientific interest and (iii) pivotal assumptions which rival the scientific hypothesis and are the focus of sci- entific controversy.” Sensitivity analysis is usually focused narrowly on the specific and pivotal assumption of ignorability of treatment assignment. Here, the question of interest is usually, How sensitive are estimates of an average causal effect to the potential effects of unobservable treatment selection patterns? Rosenbaum(2002;seealsoRosenbaum2010)devotesalargeportionofhisexcellent book on observational data analysis to strategies for performing sensitivity analysis, especially for matching designs.7 Consider for reference the simple directed graph in 6Thereisarelatedliteratureonsensitivityanalysisthatistiedtosimulationmethodsanddeter- ministic modeling more generally. In this tradition, for example, the parameters of a deterministic simulationofanoutcomearevariedsystematically.Ifvariationinnuisanceparametersofnoinherent interest does not change the basicresults ofthe model, then themodel isrobust. And, as described inSaltelli,Tarantola,Campolongo,andRatto(2004),suchmethodscanbeusedtoassesstheuncer- tainty ofmodel predictions basedonthe uncertainty of modelinputs. Such resultscandirectfuture effort optimally, so as to reduce the uncertainty of those inputs that generate the most uncertainty ofprediction.\n7Forexpositionsofthebasicperspectivewrittenforsocialscientists,seeDiPreteandGangl(2004), Frank(2000), andGangl (2013).\nC U D Y Figure12.1 A graph in which the causal effect of D on Y is confounded by an observed variable C and an unobserved variable U.\nFigure 12.1, where an analyst seeks to estimate the effect of D on Y. In this case, the researcherobservesonlyoneoftwoknownconfounders,C butnotU.ForRosenbaum, adjustingforC wouldremove“overtbias”butwouldleavethe“hiddenbias”produced by D←U→Y untouched. For a sensitivity analysis, the typical steps would be 1. Offer a provisionalpoint estimate of the ATE for the effect of D on Y by condi- tioning on C and assuming that ignorability holds.\n\nChoose multiple pairs of values for the effects of U on D and of U on Y.\nUsing either analytic methods or simulation methods, present results that show howmuchtheprovisionalpointestimateoftheATEwouldbeexpectedtochange assuming each pair of values.\nIdentify and report the pairs of values that would push the provisional point estimateoftheATEbelowthecriticallevelthatwouldpreventonefromrejecting the null hypothesis of no effect.\nUse external information on what is known about U and its relationships to D and Y to assess whether or not the pairs of values that would prevent one from rejecting the null hypothesis of no effect are reasonably likely.8 If, after after executing these steps, the researchercanarguethat all plausible vio- lations of ignorability (i.e., the pairs of values for the effects of U on D and of U on Y)wouldnotchangethequalitativeconclusions,thenonecanreportthelevelsofsen- sitivity from step 3 and confidently stick to the main substantive conclusion that the ATE is sufficiently unlikely to be equal to 0. If, however,plausible violations of ignor- ability would change the main substantive conclusion, because 0 cannot be regarded as implausible, then one should step back from strong conclusions and consider other methods of analysis.\n\nExamplesintheliteraturedemonstratetheutilityofthesensitivityanalysisapproach, althoughfor obvious reasonsit is hardto find published examples where causal asser- tionshavebeenabandonedinresponsetosensitivityanalyses.Instead,sensitivityanal- ysis is usually used to defend conclusions against the reasonable objections of either 8Note how this strategy differs from the set-identification approach presented above. From this alternativeorientation,theresearcherwouldfirstcalculateno-assumptionsboundsfortheconditional averageeffectofDonY withinstrataofC.Then,theresearcherwouldintroduceadditionalcredible assumptions about theindividual-leveland/or average effects ofU onD and U onY inanattempt tonarrowtheno-assumptionsboundstointervalsthatallresearcherscanaccept.\nfictitious fair critics or the specific assertions of real critics. Consider an example of each type.\nIn response to fictitious critics, Harding (2003) assesses the strength of the rela- tionshipthatacompositeofunobservedvariableswouldhavetohavewithatreatment variableandanoutcomevariableinordertochallengethecausalinterpretationsofhis estimatesofthe effectofneighborhoodcontextonthe odds ofcompletinghighschool.\nHe uses Rosenbaum’s specific pair-matching thresholds for violations of ignorability to demonstrate that convincing support for his conclusions is available. He is able to conclude, “Thus, to drive the [estimated] neighborhood effect to nonsignificance, parental involvement would have to be more powerful than family income or having poorly educated parents, net of these variables” (Harding 2003:712).\nForaresponsetorealcritics,VanderWeele(2011b)defendsthe claimofChristakis and Fowler (2007) that obesity is contagious and spreads through social networks.\nThe critics claimed that the results of Christakis and Fowler did not provide sup- port for the causal effects of interest and instead reflected both homophily bias and unmeasured effects of shared environments (see, e.g., Cohen-Cole and Fletcher 2008; ShaliziandThomas2011).VanderWeele(2011b)performedasensitivityanalysis,also based on Rosenbaum’s general procedures, and concluded that his sensitivity analy- sis suggested that the contagion effects on obesity “were reasonably robust to latent homophily” (VanderWeele 2011b:252).The results, however,were not definitive, even iftheywereencouragingtotheoriginalauthors(seeChristakisandFowler2013).Shal- izi(2012)raisedobjectionstotherealismofthesensitivityanalysis,whilealsomaking the more fundamental point that the original models were themselves less suited to the estimation task than Christakis and Fowler recognized when first offering them.\nGiven the close connections between set identification and sensitivity analysis, are there reasons to favor one or the other approach when both are equally feasible? To considerthisquestion,itisusefultofirstreviewthewritingofManskiandRosenbaum.\nManski’s identification focus is clear, as explained in the quotations that we used in Section3.1(seepage78).Incontrast,Rosenbaumseesatargetedfocusonidentification to be considerably less helpful: The idea of identification draws a bright red line between two types of problems. Is this red line useful? … In principle, in a problem that is formally not identified, there may be quite a bit of information about β [acausalparameterofinterest],perhapsenoughforsomeparticularpracti- caldecision….Arguably,abrightredlinerelatingassumptionstoasymp- totics is less interesting than an exact confidence interval describing what has been learned from the evidence actually at hand. (Rosenbaum 2002: 185–86) Rosenbaum’s objection to the bright red line of identification is issued in a discussion ofanIVestimator,whichweexplainedinChapter9canofferanestimateofaformally identified parameter that may be so noisy in a dataset of finite size that one cannot possibly learn anything from the estimate. However, an alternative estimator in the same context – usually a least squares regression estimator – that does not formally identify aparameterbecause itremainsasymptoticallybiasedeveninaninfinite sam- plemaynonethelessprovidesufficientlysystematicinformationsoastoremainuseful, especially if one has a sense from other aspects of the analysis of the likely direction and size of any remaining bias.\nWeacceptRosenbaum’sperspectivetosomeextent.Itisundeniablethatanempir- ical researcher who forsakes all concern with statistical inference could be led astray by consideringonly estimates thatare formallyidentified. But, for this book,ourper- spective has been much closer to that of Manski. We have focused on identification problems almost exclusively because our primary goalhas been to help researchersto determine what assumptions must be maintained in order to identify causal effects andthenestimate them.Accordingly,wedo nottakea particularpositiononwhether set identification or sensitivity analysis is a better strategy when point estimation of a causal effect of interest is infeasible. We give more space with a workedexample for an analysis of bounds only because it fits with the identification focus of this book.\nOurpositionnotwithstanding,Manskidoeshaveaprincipledreasonforfavoringset identification,eventhoughheseesitas“mathematicallycomplementary”tosensitivity analysis(Manski2003:5).HeregardsRosenbaum’ssensitivityanalysisapproachastoo narrow,writing: Where Rosenbaum and I differ is that I do not view the assumption of ignorabletreatmentselectiontohaveaspecialstatusinobservationalstud- ies of treatment effects. As an economist, I usually am inclined to think thattreatmentsarepurposefullyselectedandthatcomparisonofoutcomes plays an important role in the selection process. Perhaps the departures from ignorable treatment selection that Rosenbaum entertains in his sen- sitivity analysis can be interpreted behaviorally in terms of some model of purposeful treatment selection, but for now I do not see how. (Manski 1999:281) Other social scientists may agree with this position, based on whether they also feel that it is too difficult to discuss departures from ignorability of treatment assignment inacoherentwaywithoutreferencetothebehaviorofindividuals.Tosomedegree,we found ourselves in the same situation when discussing the charter school example in Section 8.3, where we found it necessary to elaborate the back-door path that Rosen- baum would regard as a source of hidden bias. This orientation likely also underlies the critique that Shalizi (2012) offers of VanderWeele’s sensitivity analysis in defense of Christakis and Fowler: [VanderWeele2011b]isatrulyingeniouspaper,whichadvancedthefield…\nHowever, it did so under very strong parametric and substantive assump- tions, such as, e.g., all latent homophily being due to a single binary vari- able, which interacts with observables in very specific and limiting ways.\nProvingresultsunderthese restrictionsis morethananyoneelse hasdone, but before one appeals to the results in empirical problems, one needs to eitherhavesomescientificreasontothink the restrictionshold,oramath- ematical reason to think that the conclusions are robust to substantial departuresfromthose assumptions. Since those mathematical reasonsare, at least for now,unavailable,we are forcedto rely on scientific knowledge.\nIs anyone prepared to argue that we ought, on biological or sociological grounds, to think that everything relevant to friendship formation and obesity (in suburban Massachusetts) boils down to one binary variable? (Shalizi 2012:2) It remains to be determined, therefore, whether sensitivity analysis can serve as an effective defense against real critics.\nNonetheless, sensitivity analysis can be and is being generalized, to the extent that the boundary between sensitivity analysis and set identification seems likely to gradually disappear. Consider, for example, savvy applied work such as Berk and de Leeuw (1999), where simulation is used to insert uncertainty into conclusions that may result from violations of assumptions. The prospects for such work are bright, especially when used to extend interpretations of findings by exploring alternative structures for outcomes, rather than simply trying to defend against the claims of critics who challenge identifying assumptions.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#conclusions-9",
    "href": "extracted/Counterfactuals and Causal Inference.html#conclusions-9",
    "title": "Counterfaturals and Causal Inference",
    "section": "12.4 Conclusions",
    "text": "12.4 Conclusions\nInthis chapter,wehaveconsideredthreeseparatestrategiesforhowanalystscanpro-\nceedwhentheyareunabletouseobserveddatatopoint-identifyaveragecausaleffects ofinterest.Afterusingtheclassicselection-biasliteratureasanexampleofhowdistri- butionalassumptionsforunobservablescanidentifysomeestimatesofinterest,wethen tookthepositionofthe morerecentliteraturethatdistributionalassumptionsmaybe particularlyhardto justify. We thenconsideredthe set-identificationliterature,which is motivated by a similar type of skepticism. Rather than issue daring assumptions thatmay be hardto justify, the goalis to offer easilydefendable assumptionsthat are not open to doubt. This literature has shown that through combinations of assump- tions, some causalclaims canbe eliminated. Yet, these methods have notbeen widely used because they typically cannot eliminate 0 as a permissible value for estimated causaleffectsand,evenmoreso,becausesocialscientistscontinuetoverymuchprefer single-value estimates. Finally, we considered an approach that is complementary to setidentification,whereanalystsofferprovisionalpointestimatesofaveragetreatment effects,withfullrecognitionthattheyarelikelyinconsistentandbiased.Analyststhen examine how wrongthese estimates may be byassessingtheir sensitivity to violations of the maintained assumptions.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#objections-to-adoption-of-the-counterfactual-approach",
    "href": "extracted/Counterfactuals and Causal Inference.html#objections-to-adoption-of-the-counterfactual-approach",
    "title": "Counterfaturals and Causal Inference",
    "section": "13.1 Objections to Adoption of the Counterfactual Approach",
    "text": "13.1 Objections to Adoption of the Counterfactual Approach\nThe counterfactual approach is not without serious objections from thoughtful crit-\nics. In this section, we will present three objections from the published literature. If theseobjectionsareaccepted,thenajustificationforeschewingmuchofwhatwehave presented in prior chapters is available. Such a decision, however, would presumably require the adoption of the counterposition(s) of those who raise the following objec- tions. We will not lay out these alternative approaches to causal analysis here, but their main features are implicit in the objections.\nWewillnotfurtherdiscusstwoobjectionsthatwehavealreadyaddressedindetail inpriorchapters.First,foraresponsetothe supposedlimitationsforpracticeimplied by the typical adoption of stable unit treatment value assumption (SUTVA), see Sec- tion 2.5. As argued there, the potential outcome model cannot be considered prob- lematic or inappropriate for the social sciences because it more clearly demonstrates a challenge to the definition and estimation of causal effects than other less complete frameworksforcausalinference.Inaddition,counterfactualanalysiscanproceedwhen SUTVAdoesnothold,althoughthepotentialoutcomemodelthenshowshowdifficult it can be to identify average causal effects of various forms.\nSecond, fora responseto the claimthatthe counterfactualapproachdoes notgive sufficientattentiontogenerativemechanisms,seeChapter10.Whilethecounterfactual approachtakesnogeneralpositiononthenecessarydepthofacausalclaim,weargued there that (1) the counterfactual approach is suitable for use when evaluating levels of support for conjectured alternative mechanisms that generate observed outcomes and(2)thecounterfactualapproachisentirelyconsistentwiththetheoryconstruction agenda of the generative mechanisms movement, as long as such theory construction is not itself passed off as causal explanation.1 1Wewillalsonotdiscusstheclaimthat,byadoptinganotionofcausalitythatgrantscurrencyto counterfactuals, theanalystisforcedtoincludeinanyexplanation anabundance ofancillarycausal claims, typically those grounded in causality by omission (“because the moon did not crash into the earth”) and those grounded in causality by prehistory (“because of the birth of the universe”).\nProponents of this red-herring objection then argue that, because such ancillary claims have little or no explanatory value, but the counterfactual approach requires that they be admitted into the explanation,itmustbethecasethatthecounterfactualapproachtocausationisindefensiblebecause it is incomplete. See Martin (2011) for the style of argument, where he writes, for example, “[W]e cannotaskthequestion,WhatcausesB’sdeath?andbringinanythinglessthananinfinitenumber ofcauses,withlittlewayoftellingthemapart.Almosteverythingthatledourworldtobeourworld (and not some other) was acause of B’s death…. Committed counterfacualists have learned to live Objection 1: Nonmanipulable Causes Cannot Be Analyzed When Using the Potential Outcome Model The counterfactual approachis most natural when one can conceive of a specific pro- cedure for manipulating the cause of interest, or in the words of Berk (2004:91), “in the sense that conscious human action can change things.” If the effects of a cause thatcannotbemanipulatedby“humanaction”areofinterest,thenthepotentialout- comemodel losessomeofits transparencybecausethe counterfactualsbecomeharder to conceptualize. The statistician Paul Holland is usually cited as offering the most eloquentstatement ofthis position, using the motto “no causationwithout manipula- tion”thathe developedinapriordiscussionwithRubin(seeHolland1986:959).2 The objectionwe consider in this section maintains that, because one must agree with the 1986 Holland-Rubin position in order to utilize the potential outcome model, schol- ars who are interested in the effects of (typically) immutable characteristics– such as gender and race – must instead find some other approach to causal analysis to use in theirresearch.And,giventhatsomanysocialscientistsareinterestedinthesesortsof effects, the potential outcome model must therefore be regardedas one that has quite limited utility for observational social science (see, e.g., Goldthorpe 2001).\nWe find this objection unpersuasive for the following reasons. Even if one adopts the counterfactual approach while also accepting the rigid position of “no causation without manipulation,” the entailed restrictions on permissible analysis are not as limitingasisoftenclaimed.Woodward(2003)hasarguedthispositionmorecompletely thananyoneelse(see,inparticular,hissection3.4,“InWhatSenseMustInterventions Be Possible?”).In developinghis conceptionof anintervention,Woodwardconcludes: The sorts of counterfactuals that cannot be legitimately used to elucidate the meaning of causal claims will be those for which we cannot coherently describe what it would be like for the relevant intervention to occur at all or for which there is no conceivable basis for assessing claims about what would happen under such interventions because we have no basis for disentangling, even conceptually, the effect of changing the cause variable alone fromthe effects of other sorts of changesthat accompanychangesin the cause variable. (Woodward 2003:132) In this regard, what matters is not the ability for humans to manipulate the cause throughsomeformofactualphysicalinterventionbutratherthatwebeable,asobser- vational analysts, to conceive of the conditions that would follow from a hypothetical (but perhaps physically impossible) intervention.3 with this strange conclusion” (38). The position that we have maintained in this book is that the simpleanddirectexplanatorygoalsathandarevalidguidesforthedelineationofcausalstates and, furthermore,thatclaimsaboutthesizesofestimatedcausaleffectswillbesufficientlyinformativefor thepurposesathandifthecausalstatesthatdefinethemarelocalandreasonable.Simplyput,claims fortherelevanceofcausalitybyomission,andespeciallycausalitybyprehistory,canbeheldasideby scientificjudgmentalonebecausetheyaresufficientlyremoterelativetothegoalsoftheanalysis.\n2Even so, Holland’s position is frequently misinterpreted. He didnot argue that nonmanipulable causes cannot beanalyzed usingthe potential outcome model but rather that the effects of nonma- nipulablecauses areill-definedand thereforecannot be estimated effectively withany methods. For anupdatetohisargument,seeHolland(2008).\n3Woodward(2003:122)alsodiscusseshowthefocusonconceivableinterventionsallowsonetoavoid havingtocontemplatepreposterouslyunreasonablecounterfactuals.Holland(2008)stillsupportsthe Inaddition,themanipulabilitycriterionisnotasrelevantasissometimessupposed.\nFor example, if discrimination is the topic of study, the attributes of individuals do not need to be manipulated, only the perception of them by potential discriminators.\nDeceptionthencanbe usedto gainleverageonthe causaleffects ofinterest,while the attributes of the subjects of potential discriminationremainfixed. Greiner and Rubin (2011)offer a discussionof appropriateresearchdesigns, consistentwith the potential outcome model, where the causal effects of immutable characteristics can be studied by manipulations of perceptions.\nEven if Woodward’s position is rejected, and thus if a researcher does not feel comfortable using counterfactuals to define the causal effects for hard-to-conceive- of-actually-manipulating attributes, the counterfactual approach can still be used in an as-if mode in order to sharpen the goals and contribution of an analysis. This is the position of Glymour (1986), who responds to the original Holland-Rubin position by arguing that counterfactuals can be used to elucidate effects that are presumed to havebeencausedbyasetofpotentiallymanipulablefactorsbutaremerelyreferredto collectivelybynominallabels.Thegoalofresearchistopushtheanalysisfurtherdown from the nominal labels to the separable manipulable factors. In pursuit of this goal, it can be efficient to first define the counterfactuals associated with nonmanipulable attributes as if they could be easily and naturally manipulated by human action.4 Consider studying the effect of race on socioeconomic outcomes, one of the most commontopicsofstudyintheliteratureonsocialinequality.Althoughracecannotbe manipulatedeasily,theframeworkcanstillbeusedtomotivateanattempttoestimate average gains that employed black adults working full-time, full-year would expect to capture if all prospective employers believed them to be white. This effect would dif- fer from an attempt to estimate what the black–white gap in earnings would be if blackadultshadgrownupinfamilieswiththesameaveragelevelofincomeaswhites, and hence would have had the available resources with which to purchase higher- qualitysecondaryandpostsecondaryeducation.Byhelpingtoframesuchfinedistinc- tions betweenalternative causalstates, the potential outcome model helps to sharpen research questions and then shape reasonable interpretations of whatever results can be distilled from the data that are at hand. Such a basic framing of differentials is a necessary first step, and only thereafter can one begin to systematically investigate the particularmechanismsthatgeneratethe causalrelationshipsandthatcanexplain the sources of the differences that motivate the inquiry in the first place.\nIn this regard, stating merely that an attribute D causes an outcome Y is simply the crudest form of a mechanism sketch (as we discussed in Chapter 10). To further investigate this mechanism sketch, counterfactuals must then be defined for what- ever conjectured process is thought to generate the causal effect of D on Y. Reskin (2003),forexample,providesaclearexpositionofhowtheinvestigationofsucheffects original1986motto, buthispositionismorenuanced thanmuchofthesecondary literatureimplies andappearstohavesoftenedtosomesmalldegree.\n4Weshouldalsonote,consistent withourpriordiscussioninSection 2.1,thatsomeofthecauses that wecaneasilyconceive ofmanipulatingarealsonominal,inthesensethatthecausal capacities inherentinthemmaybeattributabletoonlysomeoftheirconstituentfeatures.Fromthisperspective, perhapsmostofthecausesthatwecanconceiveofmanipulating–obtaininganotheryearofschooling, enrollinginaworkertrainingprogram,movingtoanalternativeneighborhood–arenominalstarting pointsaswell.\nof attributes should proceed. She argues that researchers should lay out alternative mechanismsthatgenerateascriptiveinequality–primarilythosebasedonthediscrim- inatory motives of gatekeepers versus those based on unequal access in structures of opportunity – and then evaluate the relative of importance of each set of mechanisms in targeted empirical analysis.\nObjection 2: The Counterfactual Approach Is Appropriate Only for Modeling the Effects of Causes, Not the Causes of Effects If an investigator is interested in estimating the effect of a particular cause, D, on an outcome of interest, Y, then the potential outcome model offers a strong foundation for empirical inquiry. Causal analysis of this type is often labeled an effects-of-causes analysis, and we have explained the counterfactual approachto such analysis at great length in this book.\nIf,instead,aninvestigatorisinterestedinansweringtheall-encompassingquestion “What causes Y?” then the investigator is interested in conducting what is often labeled a causes-of-effects analysis. No progress in such an investigation is possible without consulting extant theory or abducting relevant hypotheses that suggest that theeffectsofoneormorecandidatecauses–A,B,C,D,andsoon–needtobemodeled to determine whether evidence exists that one or more of these causes contributes to the full account that explains the pattern of all observations of Y. For this type of investigation, the potential outcome model is less natural. In fact, when potential outcomesaredefinedforeachdistinctcombinationofstatesacrossallcandidatecauses, theresultingnotationquicklybecomesanimpedimenttopracticewhenmorethantwo orthreecandidatecausalvariablesmustbeconsidered.Fortunately,thecausalgraphs thatwehavealsoutilizedinthis bookoffercorrespondingdefinitionsforcausaleffects and, asa result, permit efficientrepresentationsof full causalsystems.These systems, when fully written out, can effectively guide model specifications that can, in theory, estimate the effects of an unlimited number of causes of an outcome of interest. For this reason, it is false to claim that the counterfactual approach can only be used to motivatestudies thatestimatethe effects ofcauses.Thisclaimcanonlybe considered reasonableifonerestrictsthecounterfactualapproachtothepotentialoutcomemodel and if one is concerned unduly with the practicality of using potential outcomes to define effects for complex patterns of causal configurations.\nThe issues worth debating, as we see them, are whether social scientists pose too many causes-of-effects questions relative to effects-of-causes questions and whether thecounterfactualapproachdiffersfromotherapproachesinitscapacitytoenablethe analysis of causes-of-effects questions. Michael Sobel has provided perhaps the most vigorousindictment ofthe commonpracticeofattempting to estimate simultaneously large numbers of causes of an effect of interest with observational data. To cite one example of his perspective, he writes in the overview essay “Causal Inference in the Social Sciences” for a millennium issue of the Journal of the American Statistical Association: much of quantitative political science and sociology may be characterized as a highly stylized search for new causes of effects. Researchers typically beginwithoneormoreoutcomesandalistofcausesidentifiedbyprevious workers.Potentiallynewcausesarethenlisted;iftheseaccount(“explain”) for additional variability of the response, then the new causes are held to affect the outcome, and the significant coefficients in the new model are endowed with a causal interpretation. The process is repeated by subse- quent workers, resulting in further “progress.” When researchers realize that they are merely adding more and more variables to a predictive con- ditioning set, one wonders what will take the place of the thousands of purported(causal) effects that currently fill the journals. (Sobel 2000:650) If Sobel is correct (and we are inclined to agree with him), then the social sciences in the pastfew decades have given too much attention to the estimation of the causes of effectsandtoolittleattentiontothesimplerandmoretractablegoalofestimatingthe effects of particular causes. But even if one disagrees with this position, maintaining instead that causes-of-effects questions should always be in the foreground, it is hard to deny that the quest for a full account of the causes of any outcome is aided (and perhaps, at times, best advanced) by the pursuit of well-defined questions that focus narrowlyontheeffectsofparticularcauses.Asknowledgeoftheseeffectsaccumulates, we can then attempt to build full causal accounts of all of the effects on the outcome of interest. If the counterfactual approach is then justified only as an instrumental path toward the ultimate goal of sustaining full causal accounts, little of its appeal is diminished in our view.5 ThephilosopherPaulHumphreysoffersanelegantappealtothispragmaticrealist– empiricist position in the concluding paragraph of his 1989 book, The Chances of Explanation: Causal Explanation in the Social, Medical, and Physical Sciences. After reflectingonthedemiseofthecoveringlawmodelofexplanationandsomeofitsfailed alternatives, Humphreys writes: What, then, do we have to replace the traditional account of explana- tory knowledge? It is not propositional knowledge…. Nor is it de dicto knowledge…. It is de re knowledge of the causes that contributed to the effect, gainedinacumulativemanner,coupledwiththe discoveryofprevi- ouslyunknownstructuresthatpushes the movingboundaryofthe observ- ableevenfurtherfromordinaryexperienceandallowsustobecomeacquainted withfinerandfinerdetailsofhowtheworldworks.Whenweknowofallof the causes, then we shall know all there is to know of the kind with which we are concerned,for all that we will be left is pure chance,and chance is, as I have said, literally nothing. (Humphreys 1989:140–41) 5Onefrontierofcurrentmethodological scholarship,consistentwiththecounterfactual approach, istheelaborationofsufficientcomponentcausemodelsthatbridgeclassicepidemiologicalmodelswith causal graph methodology (see VanderWeele and Robins 2007b, 2008, 2009; VanderWeele, Vanstee- landt,andRobins2010;Vansteelandt,VanderWeele,andRobins2012).Thesecauses-of-effectsmodels adoptathreshold-crossingframeworkwherecombinationsofriskfactorsaremodeledasjointlysuffi- cienttogenerate theoutcome ofinterest(typically, onset ofahealth conditionof someform).Pearl (2009, chapters 9 and 10) has long recognized the value in using his structural equation approach to develop “actual cause” models. We expect that in the coming years recognition that these sorts of models exist will decrease the frequency with which others raise the causes-of-effects objection discussedinthissection.\nThe idea here is that we should strive to explain phenomena by estimating the effects of putative causes on particular outcomes. And, in practice for observational data analysis, most such attempts require a consideration of at least two types of other causesof the outcome: (1) those that may lie along back-doorpaths in a causalgraph and (2) those that constitute the mechanisms that link the putative cause to the outcome. Over time, we collect more data and estimate the effects of the same causes on the same outcomes in a variety of conditions, which deepens our understanding of the additional causes that were considered unobservables initially.\nThe counterfactual approach we have presented in this book is well suited to this pragmatic account of social science research, where progress results from cred- ible advances rather than grand claims. Even so, the counterfactual approach is not inconsistent with the development and analysis of full causal systems that deliver answersforcauses-of-effectsquestions,eventhoughitencouragesskepticismofresults that are warranted only by assumptions of dubious validity.\nObjection 3: Causal Inference Should Not Depend on Metaphysical Quantities Such as Potential Outcomes Inawide-rangingarticletitled“CausalInferenceWithoutCounterfactuals,”thestatis- tician A. Philip Dawid argues that potential outcomes are inherently metaphysical, andthus the counterfactualmodel forcausalinference is“generallyunhelpful andfre- quently misleading” (Dawid 2000:409). He argues that causal claims must rest only oninherently testable ideas,andhe presents analternativethat he arguessucceeds in realizing the goal of estimating the effects of causes.6 Although some aspects of Dawid’s critique are rather involved, some of its central features are quite simple. He first argues that the potential outcome model embraces “fatalism” because it implicitly assumes that the potential outcomes of individuals (i.e., y1 and y0 for a binary cause) are fixed values that are regarded as “predeter- i i mined attributes” of individuals “waiting only to be uncovered by suitable experi- mentation” (Dawid 2000:412). For his alternative, Dawid considers a basic Bayesian decision model that, without reference to potential outcomes, allows a statistician to (1) design a randomized experiment to compare the effects of a treatment on an outcome (in comparison with a base state of either no treatment or an alternative treatment) and (2) convey the results of this experiment to inform a relevant decision makeroftheexpectedeffectofapplyingthetreatmenttoanadditionalsubjectsimilar to those on whom the experiment was conducted.7 After contrasting his model with the counterfactual model, he concludes: Ihavearguedthatthecounterfactualapproachtocausalinferenceisessen- tially metaphysical, and full of temptation to make “inferences” that can- not be justified on the basis of empirical data and are thus unscientific.\n6For brevity, we do not cover Dawid’s position on modeling the causes of effects here. We just addressedthecauses-of-effects versuseffects-of-causes positioninthelastsection.\n7Following in the Bayesian tradition, the decision maker (who could also be the statistician) can then assess the consequences of applying the treatment to the subject, with reference to cost considerations and other determinants of her loss function. These additional points are not stressed byDawid,inpartbecausetheyarenotincompatiblewiththecounterfactual model.\nAn alternative approach based on decision analysis, naturally appealing and fully scientific, has been presented. This approachis completely satis- factory for addressingthe problemof inference about the effects of causes, andthefamiliar“blackbox”approachofexperimentalstatisticsisperfectly adequate for this purpose. (Dawid 2000:423) The response to Dawid’s critique of the potential outcome model has been largely negative,asrevealedinthe commentspublishedalongsideit.The cruxofthe counter- argument is the following. If perfect experiments for every causal question of interest could be designed and then implemented, then potential outcomes are unnecessary (even though they might still be useful for some purposes, such as to think through theresultsthatmighthaveemergedfromalternativeexperimentalprotocols).Further- more, no one seems to disagree with the claim that we should use study designs that can rescue us from having to apply assumptions to what-if quantities. In this regard, it would of course be preferable to be able to use a crossover design in all situations, which Rothman et al. (2008) describe as follows: Theclassiccrossover studyisatypeofexperimentinwhichtwo(ormore) treatments are compared, as in any experimental study. In a crossover study, however, each subject receives both treatments, with one following the other. Preferably, the order in which the two treatments are applied is randomly chosen for each subject. Enough time should be allocated betweenthetwoadministrationssothattheeffectofeachtreatmentcanbe measuredandcansubsidebeforetheothertreatmentisgiven.Apersistent effectofthefirstinterventioniscalledacarryover effect.Acrossoverstudy is only valid to study treatments for which effects occur within a short induction period and do not persist, i.e., carryovereffects must be absent, so that the effect of the second intervention is not intermingled with the effect of the first. (Rothman et al. 2008:125) The appeal of this sort of a study design, in view of Dawid’s critique, is that each ostensiblymetaphysicalpotentialoutcomewouldbecomeanobservedoutcome.Unfor- tunately, asRothmanetal.(2008)note,the crossoverdesignisonlyfeasiblewhenone has control over the allocation of the treatment(s), is only effective when the treat- ment effects of interest do not leave carryover effects behind, and is only possible if the effectshaveashortenoughdurationthatonecanallocateandassesseachofthem during the available observation window. These conditions exist very rarely for the causal questions that concern social scientists, and as a result crossover studies are most common in clinical settings where the goal is to examine “the efficacy of thera- pies intended to reduce the frequency or severity of chronic, recurrent problems, such as seizures” (Rothman et al. 2008:649).\nForobservationaldataanalysis,whichDawidbarelymentionsinhisarticle,wesee no way to escape having to assert what-if assumptions about potential outcomes in ordertomoveforward.RobinsandGreenland(2000),whencommentingontheDawid critique, consider many of the applied examples for which counterfactual models have been used. They conclude: Bynarrowlyconcentratingonrandomizedexperimentswithcompletecom- pliance, Dawid, in our opinion, incorrectly concludes that an approach to causal inference based on“decisionanalysis”andfree ofcounterfactuals is completely satisfactory for addressing the problem of inference about the effects ofcauses.We arguethat whenattempting to estimate the effects of causesinobservationalstudiesorinrandomizedexperimentswithnoncom- pliance … [a]relianceoncounterfactualsor their logicalequivalentcannot be avoided. (Robins and Greenland 2000:431) This basic point is echoed by most of the other commentators on the article. Cox (2000:424) asks this question: “And yet: has the philosophical coherence [of Dawid’s position],ifnotthrownthebabyoutwiththebathwater,atleastleftthebabyseriously bruised in some vital organs?” Casella and Schwartz (2000:425–26)conclude, “Dawid insists that such choices [about how to conduct a causal analysis] … must be based onstrictprinciples that canbe verifiedempirically. We believe thatsuch a programis so overly rigid that, in the end, science is not served.” Even so,Dawid’s objectionto the metaphysicalnature of potential outcomes does bring up a deeper question: What is the epistemological status of the potential out- come model?8 It is certainly not positivist, as it breaks radically from the positivist– empiricist prescription that analysis must be based only on observed quantities. The relianceonwhat-ifpotentialoutcomesandthe considerationofunobservables–inthe treatment assignment process and for the presumed generative mechanism – consigns the counterfactual approach to the postpositivist model of science generally labeled realism(seePsillos1999;Putnam1975;seealsoGodfrey-Smith2003foranoverview).\nBut, because eachunobservedpotential outcome could have become an observedout- come if the unobservables in the treatment assignment process had been configured in an alternative way, and the variables that constitute the generative mechanism could be observed as well, the entire framework aspires to help us become reductive empiricists.\nIn this regard,we suspect thatmost socialscientists who adoptthe counterfactual approach would find the enigmatic but enabling position of Donald Campbell similar to their own, as he laid it out in 1977: I am a fallibilist and antifoundationalist. No part of our system of knowl- edge is immune to correction. There are no firm building blocks, either as indubitable and therefore valid axioms, or in any set of posits that are unequivocaloncemade.Norarethereevenanyunequivocalexperiencesor explicit operations on which to found certainty of communication in lieu of a certainty of knowledge.\n8Whenwadingintothephilosophyliterature,onepointleapsoutinregardtoDawid’scharge.The literature on causality is considered by most philosophers to be properly situated in the subfield of metaphysics.Thus,Dawid’schargethatthepotentialoutcomeframeworkismetaphysicalis,fromthe perspectiveofphilosophers,bothaccurateanduntroubling.SeealsothepositionofPearl(2009:33–34), whoargues that, even ifcounterfactuals aremetaphysical insomesensebecause theyarestructures in the mind, individuals are all too happy to use them in their daily lives. For this reason alone, it seemsnaturaltobuildnotionsofcausalityaroundthem.\nI am some kind of a realist,some kind of a critical,hypothetical, corri- gible, scientific realist. But I am against direct realism, naive realism, and epistemological complacency. (Campbell 1988[1977]:444–45) We read this passage as indicating that Campbell recognized, grudgingly to be sure, that the pursuit of valid knowledge necessitates the invocation of unobservable quan- tities, such as potential outcomes. This necessity tips one into the realm of realism, whereinsuchunobservablesaregivenprovisionaltruthstatus for pragmaticpurposes.\nBut,foranycorrigiblerealistlikeCampbell,theultimateaspirationistobringconjec- tured unobservables out in the open, drawing analysis down to its most generic form as an as-if positivist endeavor.\nFor scholars who find the counterfactual approach to observational data analysis unappealing,perhapsbecauseofthepersuasivenessofsomeoftheobjectionspresented inthissection,avarietyofresponsesexists.Somescholarsargue,simply,thatweshould devotemuchmoreattentionto descriptivemodelingbecause causalanalysiscanbe so intractable. We begin the next section with this position, after which we then move on to consider alternative modes of causal inquiry within which the counterfactual approach can be utilized.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Counterfactuals and Causal Inference.html#modes-of-causal-inquiry-in-the-social-sciences",
    "href": "extracted/Counterfactuals and Causal Inference.html#modes-of-causal-inquiry-in-the-social-sciences",
    "title": "Counterfaturals and Causal Inference",
    "section": "13.2 Modes of Causal Inquiry in the Social Sciences",
    "text": "13.2 Modes of Causal Inquiry in the Social Sciences\nSome scholars argue that many long-standing questions in the social sciences can and\nshould be pursued without any reference to causality. When the sole interest is a par- simonious account of “what the data show” or “what the historical record reveals,” then all strategies for causal analysis are largely irrelevant, including the counterfac- tual approach. But, there are also good reasons to consider descriptive analysis more generally. Berk (2004:218) notes that “good description is the bread and butter of good science and good policy research.” Sobel (1996:376) declares that many ques- tions “neither require nor benefit from the introduction of causal considerations, and the tendency to treat such questions as if they are causal only leads to confusion.” Weagreewiththispositiontoagreatextent.Buttheappealfordescriptiveresearch cannotbetakentoofar.Epistemologicalquestionsstillariseindescriptiveresearch,as notalldescriptiveaccountscanbeconsideredequallyworthyofourattention.Perhaps moreimportantly,socialscientistsmaynotwanttobackpedalfromcausalinquiry,lest journalists,partisanthink-tankscholars,andpoliticianstakeitoverentirely.Wewould mostprefertoseebothjudiciousdescriptiveanalysisandcarefulcausalanalysisjointly crowd out poor causal analysis in the social sciences and beyond.\nAs we have noted at several points, when considering the causal controversies that pervade the literature, many social scientists have echoed the point summarized most clearly for sociology by John Goldthorpe, who writes, “sociologists have to find their own ways of thinking about causation, proper to the kinds of research that they can realistically carry out and the problems that they can realistically address” (Goldthorpe 2001:8). With this appeal in mind, we conclude this book with a discus- sion of the primary modes of causal inquiry that exist in observational social science.\nWe have two goals for this concluding presentation of complementary modes of causal inquiry: (1) to affirm that all of these modes of inquiry are valuable and (2) to argue that adopting a counterfactual approach can help us to move productively betweenthem.Evenso,wewouldnotwanttoargueforthehegemonyofcounterfactual thinking. The specter of widespread mechanical adoption of the potential outcome model is truly frightening to us: No one wishes to have to review journal submissions in which scholars define the average treatment effect for the treated (ATT), offer up a fairly arbitrary set of matching estimates, and then a disingenuous sensitivity analysis that purportedly bolsters the results. This prospect alone is sufficient for us torecommendconsiderablecaution.But,perhapsmoreimportant,wecannotenvision thepursuitofempiricalanalysisinourownresearchareaswithoutengaginginanalysis thatincludesallofthemodesbelow.Inotherwords,wecanseemanyfutureprofitable lines ofinquiry inour ownresearchin whichcounterfactualthinking will be usedonly as a backgroundtool to encourage clear thinking.\nWiththatbacking,weofferthefollowing(necessarilyoversimplified)representation of complementary modes of causal inquiry in observational social science: Mode 1: Associational Analysis. In practice, most causal inquiry begins with an assessment,sometimesunreported,ofwhetherputativeobservedcausesareassociated withanoutcomeofinterestinsomeway.Itisoftenstatedthatestablishingsuchasso- ciationsareapreconditionforsubsequentcausalanalysis,asreflectedinthe aphorism “no causation without association.”9 Mode 2: Conditional Associational Analysis. After associations have been estab- lished, it is customaryto thenreestimate the associationsafter conditioningonvalues of other observed variables. Although quite general, the typical approach usually fol- lowsone of two implementations:(1) conditioning onother variables that arethought to determine the outcome and that may also be related to the cause(s) and(2) condi- tioning on variables that determine the cause(s) and that may also be related to the outcome. Although conceptually quite different (as we noted in our discussion in Sec- tion 4.4), the goal of such conditioning is to eliminate obvious sources of confounding in order to build basic support for causal relevance.\nMode 3a: Targeted Analysis of the Effects of One or More Focal Causes. After an assessment of basic causal relevance for a set of putative causes, the effects of one or more particular causes are then estimated in targeted analysis. This mode of causal inquiry can be (or, we would argue, should be) undertaken after first elaborating a directedgraphentailedbyextanttheory.Inanycase,carefulattentiontomodelspeci- ficationisneeded,adoptingassumptions,forexample,ofignorabilityifidentificationis byback-doorconditioningorexclusionsrestrictionsifidentificationisbyinstrumental variables.\n9Formally,ofcourse,therearecasesforwhichthismaynotbetrue,suchaswhenindividual-varying causaleffects perfectlycancel outeachotherorwhensuppressioneffects exist.Weignoreexceptions such as these here, as they are rare. The sorts of physical equilibriathat rigidlygenerate balancing ofresponsestocausalshockshavenoclearanalogsinthesocialsciencesthatwouldgeneratesimilar perfectcancellationofunit-specificcausaleffects.And,althoughsuppressioneffectsexistinthesocial sciences,wecannot thinkofexamples forwhichthey havebeenshowntocompletely erasebivariate associationsthatareatleastpartlycausal.\nMode 3b: Mechanism-Based Analysis. After (or while) targeted estimation of the effects of one or more causes is undertaken, a common practice in causal inquiry is to then introduce intervening variables between the focal causal variable(s) subjected to targeted analysis and the outcome variable in an effort to develop a mechanistic explanation of the process that generates the causal effect. Such a form of causal inquiry can proceed, as is often the case, even though it may be unclear whether or not all forms of confounding have been eliminated.\nMode 4: All-Cause Structural Analysis. At its most ambitious level, causal inquiry is pursued as an attempt to identify all causes in chains of causality from the causal variables to the outcome variable,eliminating or neutralizing allconfounding in order to identify all parameters of full causal systems. This approach is best represented in the formsofstructuralequationmodelingthatprevailineconomics,whereinallspeci- ficationsarejustifiedwithappealstomicroeconomictheoryandpurporttoexplainthe entire “who, when, where, and how” of all of the causes of the outcome of interest.10 Consider now how the counterfactual approach can be related to these comple- mentary but increasingly ambitious modes of causal inquiry and how adoption of the approach facilitates movement between them as advances in theory construction and data collection are achieved. For Mode 1 (associational analysis), the counterfactual approach encourages the consideration of causes for which one can conceive of the reasonable and theoretically possible conditions that would result from an interven- tion that changes the causal variable from one value to another. When causal inquiry is stuck by convention on the consideration of the effects of attributes for which the conditions ofas-ifinterventionsareunclear, the approachencouragesadditional effort to break the associational analysis into pieces that are more amenable to analysis by consideration of specific counterfactual dependencies. The hope of such a refined and expansive strategy is that the analysis can be brought down to a level where manip- ulations are more easily conceivable, which may then allow for a redirection of the extant associational inquiry. Such redirection may be necessary in order to open up the possibility of advancement beyond Modes 1 and 2.\nFor the transition from Mode 1 to Mode 2 (that is, from associational to condi- tional associational analysis), the counterfactual model encourages separate but com- parative consideration of the determinants of the causes and the determinants of the outcome. Determinants of causal variables lost some deserved attention as regression methods became dominant in observational social science in the 1980s and 1990s,but the matching literature associated with the counterfactual model has restored some of this attention by focusing analysis on the goal of balancing the data with respect to the determinants of the cause. For the subsequent transition to Mode 3a (targeted analysis of one or more focal causes), the joint consideration of both types of vari- ables then allows for a determination, by carefully defined assumptions grounded in theory, of which sufficient subset of such determinants may be used in a conditioning 10In addition, all-cause structural analysis may drill down to model directly the separable causal effectsoftheconstituentfeaturesthatcomposethecausalstates.Inotherwords,thecausalvariables analyzed for Modes 1, 2, and 3a may come to be regarded as too broad to motivate sensible struc- tural models. This decision may emerge following analysis within Mode 3b when the analyst comes to recognize that the relevant generative mechanisms apply to only a subset of the causal state’s constitutive features.\nstrategy to achieve identification of the causal effect by eliminating all confounding.\nIf the assumptions cannot be sustained for any set of observed variables, then point identification of the focal causal effects by back-door conditioning is impossible.\nIf no other researchdesign is possible, such as those that exemplify Modes 3b and 4, then the counterfactual model suggests clearly why analysis should then expand beyond efforts to point-identify causal effects to alternative forms of set identifica- tionandsensitivity analysis.In addition,the counterfactualapproachalsoencourages especially careful examination of all back-door paths from the causal variable to the outcome variable (rather than simply a one-by-one consideration of all variables that lie alonganyback-doorpaths). This formofsystematic considerationofmodel identi- ficationcanpreventresearchersfrommistakenly generatingnew confounding between the causal variables and the outcome variable, as occurs when the analyst conditions on a collider variable that lies along an already blocked back-door path.\nFor the transition to Mode 3b (mechanism-based analysis), the counterfactual approach shows that such a transition is substantive, not methodological. No new estimation techniques beyond those used for Modes 2 and 3a are required. All that is required to pursue Mode 3b is a theory that suggests which variables (and in which configuration) represent the causal mechanism that brings about the causal effect.\nMoreover,the counterfactual approach suggests that typical mechanism-based analy- sesmust be clearlyseparatedinto two verydifferentvarieties: those thatmerely point to possible causal pathways and those that fully identify the causal effects of interest.\nFor analysis of the former type, some explanationcan be achieved.But, to realize the moreambitiousgoalsofthelatter,themechanisticvariablesthatarespecifiedmustbe exhaustive and isolated (or made so by suitable conditioning). Mechanistic variables thatarenotindependentofunblockedback-doorpaths afterconditioningonobserved variables cannot be used to identify a causal effect.\nFor the transition to Mode 4 (all-cause structural analysis), the counterfactual approach sensitizes researchers to the stringency of the required assumptions. Pearl (2009)issurelycorrectthatourambitionshouldalwaysbetogetascloseaspossibleto all-causestructuralmodelswhereaccountscanbeofferedforallofthecausesofanout- come.Adoptingthe counterfactualapproachhelpstoclarifythedubiousnatureofthe maintained assumptions that pervade the published literature where all-cause models are offered. For example, most such models are based on combinations of two identi- fication strategies – basic conditioning and instrumental variable techniques – under maintainedassumptionsthatcausaleffects arehomogeneous(oratleastconditionally random). As the matching literature associated with the counterfactual approach has shown, such homogeneity is rarely justified empirically even for singular causes, and most parametric forms of conditioning average systematic causal effect heterogeneity in arcane ways. Moreover, the instrumented variable (IV) literature associated with the counterfactual approach has shown that, in the presence of such heterogeneity, IVs estimate marginal causal effects that cannot then be extrapolated to other seg- mentsofthe populationofinterestwithoutintroducingunsupportableassumptionsof homogeneity of effects.\nBy making these issues clear, the counterfactual approach shows how high the demandsontheoryandondatamustbeinordertosustaintheall-causemodeofcausal inquiry: Answers to all of the “who, when, where, and how” questions for the causal relationships of interest must be provided. Dodging these questions by introducing homogeneity assumptions that have only a dubious grounding in theory (or a solid grounding in dubious theory) can undermine causal claims, at least in the eyes of a fair critic. In this sense, the counterfactual approach encourages modesty of causal inquiry.\nFinally, such modesty can be pursued outside of these modes of inquiry, after which analysis can then shift into whichever of these modes seems most appropriate.\nAs shown perhaps most clearly when adopting Manski’s set-identification perspective (see Chapter 12), the range that a causal effect may take on can be defined and then examined with the potential outcome model before any data are considered.\nThereafter,anassessmentcanbeundertakenofthedatathatareavailabletoestimate averagecausaleffectsofvariousforms.Forthesesteps,assumptionsaboutwhyacausal relationship may exist need not be introduced, nor in fact assumptions that there is anysystematicrelationshipbetweentheprocessesthatgeneratecausalrelationshipsat the individual level. Such flexibility leaves analysis wide open at the outset, focusing attention on clear definitions of effects of interest, independent of data availability issues.\nBut, once an analysis has begun, a theoretical position must be adopted in order to provide answers to at least some of the “who, when, where, and how” questions for the causal relationship of interest. Given provisional answers to these questions, the counterfactual approach helps one to consider which modes of causal inquiry are feasible. Analysis may have to stop at the associational level, yielding nothing other than analogs to the naive estimator. If some of the determinants of the cause and/or outcome are systematic and observed, then analysis can move down to conditional variants of associational analysis, followed by an analysis of bounds (and perhaps a sensitivity analysis). If a directed graph can be drawn that suggests that ignorability assumptions or exclusionrestrictions are available for focal causaleffects, then it may be feasible to generate consistent estimates of the effects of these specific causes. If theoryanddataareavailabletoexaminewhatbringsabouttheeffectofthecause,then analysis can move down toward a mechanism-based mode of causal inquiry. Finally, if theory is finely articulated and supported by past substantive scholarship, and if all data requirements are met, then full structural modeling can be attempted. Such all-cause models represent a standard that is rarely achieved but properly valued, for they provide complete explanations not only of the causes of an outcome but of every linkageinthe causalchainsbetweenthem. Counterfactualmodeling guidesusasclose to this standard as is appropriate, given the constraints of theory and of data that prevail at any given time.",
    "crumbs": [
      "Data Science",
      "Counterfaturals and Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Causal Inference in the Social and Behavioral Sciences2.html",
    "href": "extracted/Causal Inference in the Social and Behavioral Sciences2.html",
    "title": "Causal Inference in the Social and Behavioral Sciences",
    "section": "",
    "text": "Handbook of Statistical Modeling for the Social and Behavioral Sciences, edited by Gerhard Arminger, Clifford C. Clogg, and Michael E. Sobel. Plenum Press, New York, 1995.\nMICHAEL E. SOBEL • Department of Sociology, University of Arizona, Tucson, Arizona 85721, USA. • For helpful comments and discussion, I am grateful to Gerhard Arminger, Peter Brantley, Henry Byerly, David R. Cox, Otis Dudley Duncan, Judea Pearl, and Herbert L. Smith. Portions of this material were presented at the August 1991 meetings of the American Sociological Association in Cincinnati, Ohio.",
    "crumbs": [
      "Causal Inference",
      "Causal Inference in the Social and Behavioral Sciences"
    ]
  },
  {
    "objectID": "extracted/Causal Inference in the Social and Behavioral Sciences2.html#introduction",
    "href": "extracted/Causal Inference in the Social and Behavioral Sciences2.html#introduction",
    "title": "Causal Inference in the Social and Behavioral Sciences",
    "section": "1 Introduction",
    "text": "1 Introduction\nThe human propensity to think in causal terms is well known (Young 1978), and the manner\nin which judgments about causation are made in everyday life has been studied extensively by psychologists (Einhorn and Hogarth 1986; White 1990). No doubt this propensity con- tributes, for better or worse, to the persistence of causal language in scientific discourse, despite some influential attempts (for example, Russell1913) to banish such talk to the prescientific era.\nIn the social and behavioral sciences, causal talk is currently abundant, and at least in some quarters in sociology, especially since the introduction of path analysis (Wright 1921) to the sociological community (Duncan 1966), the impression that explanation and causation are one and the same is given. (Duncan himself does not make such claims.) Furthermore, with a little bit of substantive theory and some data, inferences about causal relations are readily made using statistics. One simply uses selected variables to draw a path diagram that purports to correspond with some theoretical notions of interest, uses data to estimate the parameters of linear equations corresponding to said diagram, and these pa- rameter estimates, and functions of these, give the effects of interest. In reaction to such excesses, several writers (Cliff 1983; Freedman 1987; Holland 1988; Sobel1990, 1993, 1994) have criticized the cavalier approach to the assessment of causal relations that is often associated with the utilization of modern path models and covariance structure mod- els (often called causal models). Similarly, economists (Judge, Griffiths, Hall, Liitkepohl, and Lee 1985; Leamer 1985; Zellner [ 1979] 1984) have expressed dissatisfaction with the concept of Granger causation, which is often used in conjunction with time series models.\nThis chapter critically examines the literature on causal inference in the social and be- havioral sciences. For a related examination, with emphasis on epidemiology, see Cox (1992). Insofar as the term “causal inference” is vague, it is important to understand that throughout I shall use this term to refer to the act of using evidence to infer causal relations.\nAttention focuses on the relationship between causal inference and an account of causation to which many social scientists who make causal inferences ascribe, if only implicitly.\nSeveral contributions are offered. First, I bring together a philosophical account of causation (Collingwood [ 1940] 1948; Gasking 1955; Harre and Madden 1975; von Wright 1971) that hinges on notions such as manipulability with a formalization of this account and a resulting approach to causal inference (Rubin 1974, 1977, 1978, 1980, 1990) that derives from the statistical literature on experimental design.\nIt is important to note that the account, its formalization, and the approach are general: the account is not limited to the case where the manipulations can actually take place, and the approach in no way hinges on the ability to actually perform an experiment, randomized or otherwise. The formalization comports well with the general idea behind the account, but the account leaves room for other formalizations as well. Some details will be given later. The close correspondence between the account, its formalization, and the resulting approach to causal inference appears to have gone largely unnoticed: philosophers (with the possible exception of Giere (1980)) have done little to attempt to formalize the account and/or implement an approach to causal inference based on this account of causation, and statisticians have done little to say how their work ties to a causal account. By noting how this formal approach to causal inference, which is applicable to both experimental and nonexperimental (observational) studies, dovetails with the account of causation, thereby bringing epistemological and conceptual aspects of the causal relationship into correspon- dence, I accomplish several things. First, once this account (hereafter called a manipula- tive account) is modified slightly, the correspondence privileges the foregoing approach to causal inference (hereafter referred to as an experimental approach) without committing the sin of verificationism. Further, if other approaches to causal inference fail to square with this approach, it is because these approaches are deficient, provided a manipulative account of causation is under consideration. Of course, if an alternative account of causa- tion is under consideration, a different approach to inference might be privileged.\nGiven the foregoing relationship between causal accounts and causal inference, it is important that researchers understand the causal concepts they are using. In that vein, empirical workers almost never explicitly indicate the causal concepts they are using, but they often implicitly commit to a manipulative account when interpreting empirical re- sults. Similar remarks apply to methodologists and statisticians when they indicate how model parameters ought to be interpreted. Unfortunately, many researchers do not appear to understand the consequences of adopting this view for the collection, analysis, and in- terpretation of data. Thus, I show how the experimental approach to causal inference relies on considerations external to the data and models that are typically employed in nonexperi- mental (observational) studies. Further, the considerations are not the usual ones identified in the social and behavioral science literatures. It is also hoped that recognition of the issues above will encourage social scientists who wish to make causal inferences (in this experi- mental sense) to put a higher premium on evidence from well-designed experiments (when these are possible).\nI also identify a number of problems with various treatments of causation and/or causal inference in philosophy, economics, statistics, psychology, and sociology. Some of the problems identified appear fatal to the corresponding treatment (in the sense that the ap- proach does not support the accompanying connotations that are typically imparted), sug- gesting that social scientists would be well advised to not hinge causal inferences on such treatments. Other treatments appear to be more promising, but these have not been fully worked through for the cases that interest social scientists. Some suggestions for further work are also given.\nFinally, empirical workers in the social sciences often incorrectly equate explanation with causation. Although this chapter focuses on the causal relation and causal inference, and does not take up the more general subject of explanation, I hope to indicate, if only by elimination and suggestion, that many of the processes and phenomena that are of interest to social and behavioral scientists are not causal or at least not entirely causal. Explicit recognition of this fact should help researchers to think more clearly about what they are actually attempting to find out, and to make more appropriate inferences about the phe- nomenon under investigation. For example, researchers are often interested in processes that operate over time, such as human development or the intergenerational flow of status.\nHere, statistical modeling can help to give a parsimonious description of the relationships among successive events. In many cases, researchers simply equate such a description with “causal explanation” without even attempting to say what the terms “causation” and “explanation” mean. In doing so, they lose sight of other types of explanation that may actually be of more interest. In addition, by virtue of an implicit commitment to a manipu- lative account of causation, these researchers incur the additional risk of falling into the trap of thinking that the statistical analysis supports policy interventions. For further material on the types of noncausal questions that are central in scientific activity, see, for example, Bunge (1979).\nSince empirical research in the social and behavioral sciences often involves the use of statistical models, attention centers on” statistical” or “probabilistic” accounts of causa- tion. However, probabilistic accounts historically derive from corresponding deterministic accounts, and therefore it is useful to begin by examining the literature on deterministic causation. The chapter is organized as follows: Section 2 selectively reviews the philo- sophical literature on deterministic causation. Here attention focuses on regularity theories and manipulative accounts of causation. Section 3 considers some accounts of probabilistic causation in philosophy (for example, Suppes 1970) that may be viewed as an outgrowth of deterministic regularity theories. Previous criticisms of these accounts are discussed, and a number of new criticisms are offered. Next, the related notion of Granger causa- tion (Granger 1969), which is used in economics, is examined. Previous criticisms of this notion are also discussed, and a number of new criticisms are offered. Section 4 forma- lizes the manipulative account and takes up the resulting approach to causal inference. I relate this approach to the usual model-based approaches to causal inference in the social and behavioral sciences, using single-equation models to show the dependence of the usual approaches on a number of assumptions that are usually implicit (at best). Next, some lim- itations and ambiguities of the account and its formalization are identified. In Section 5, the discussion is extended to the simultaneous-equation models (causal models) that are often used in social sciences to draw causal inferences, and some recent attempts in the econometric literature to redefine exogeneity and causality (though not Granger causality) are examined. In addition, the usual approach to causal inference in sociology (and some parts of psychology), which involves notions of direct, total, and indirect effects, is con- sidered. It is concluded that these new econometric concepts do not correspond strongly to the causal notions they are intended to capture. Similar remarks apply to the effect de- compositions that come from sociology and psychometrics. I conclude by examining an approach due to Holland ( 1988) that offers promise, if suitably generalized.",
    "crumbs": [
      "Causal Inference",
      "Causal Inference in the Social and Behavioral Sciences"
    ]
  },
  {
    "objectID": "extracted/Causal Inference in the Social and Behavioral Sciences2.html#deterministic-causation-in-philosophy",
    "href": "extracted/Causal Inference in the Social and Behavioral Sciences2.html#deterministic-causation-in-philosophy",
    "title": "Causal Inference in the Social and Behavioral Sciences",
    "section": "2 Deterministic Causation in Philosophy",
    "text": "2 Deterministic Causation in Philosophy\nAristotle construed causation broadly, equating this with what would now be called expla-\nnation. Two of the types of causes identified by Aristotle, the material and formal causes, connect objects or events to their concomitant properties by supplying a linkage that is not typically viewed as causal now. In plainer terms, material and formal causes are invoked to answer questions of the form “why” by statements of the form “because” (Barnes 1982). In post-medieval science, it is usual to distinguish between causation and explanation, seeing causation as a special type of explanation. Thus, current discussions of causation focus on either efficient or final causes, the other two types identified by Aristotle. These are most readily associated with the notion that causation is or involves some form of action, and both efficient and final causes are featured in explanations in the social and behavioral sci- ences. In this chapter, causation is also viewed as a special kind of explanation, and only efficient causation is explicitly discussed. The exclusion of final causes is not intended to suggest that teleological causation is strictly reducible to efficient causation, as some philosophers have argued. At the same time, the causal processes that underlie teleological accounts can generally be described in terms of efficient causes (Mackie 1974), and it is this fact that warrants such an exclusion.\nIn this section, two deterministic causal accounts are examined. Roughly speaking, reg- ularity theories take the cause (sometimes called the full cause or the philosophical cause) of a generic event E to be the complex of generic antecedents necessary, sufficient, or nec- essary and sufficient for E. It is understood here that the antecedents are “distinct” from E. For further material on the notion of “distinctness” see Mackie ( 1974). Under this ac- count, a successful causal explanation is one that yields “the causes of effects,” to borrow language from Mill ([1843] 1973). According to Collingwood ([1940] 1948, p. 287) ex- planations of this form are the goal that is sought in “the theoretical sciences of nature.” By way of contrast, in a manipulative account an event C causes an event E if E occurs when the experimenter induces C, and Ec (the complement of E) occurs when the experimenter cc.\ninduces Here, attention focuses on the “effect of causes” and there is no presumption that C is the full cause of E. Collingwood argues that this notion of causation dominates in the applied sciences, such as medicine.\nI begin by considering regularity accounts. Since Hume is often regarded as a precursor to such treatments, his analysis of causation ([1739] 1978, [1740] 1988, [1748] 1988) pro- vides a convenient starting point for the discussion. The prototypical example that Hume considered is the case of two colliding billiard balls. Here, one ball is moving toward a second ball at rest. The two balls collide, setting the second ball in motion. In analyzing this situation, Hume notes that the motion of the first ball preceded that of the second, and that the collision between the two balls sets the second ball in motion. On the basis of these observations, he argues that temporal priority and spatio-temporal contiguity are intrinsic components of cause-effect relationships. However, Hume adds that a singular instance of the colliding billiard balls does not, in and of itself, lead to a causal inference. Such an inference is warranted only by the additional observation that every time the setup has been repeated (or adequately approximated), the same effect appeared. This is the criterion of constant conjunction. According to Hume, these three components exhaust the ontological aspect of causation.\nThe constant conjunction criterion means that the events C and E featured in a causal statement of the form “C caused E” are general, referring to classes of instances, as opposed to a singular instance. (This creates some problems that cannot be taken up here.) From this point of view, a causal statement of the form “C caused E”, where C and E are now viewed as singular instances, means only that C both preceded and was contiguous toE, and that the instance in hand can be subsumed under a wider class of observed instances.\nIn this sense, singular causal statements are completely derivative from the broader class.\nSecond, insofar as the analysis purports to be exhaustive, the causal relation resides, given contiguity and temporal priority, only in the relation of constant conjunction, and not in any necessity that goes beyond constant conjunction, logical or otherwise, by which the cause suffices for the effect. Our idea of the causal relation may involve such notions of necessity, for example, productive principles (powers, forces, or in modern terminology, causal mechanisms) by which a cause brings about an effect, but according to Hume, these notions exist only in our minds, and not in the world itself. (At some points Hume ([1748] 1988), in dealing with necessity as production, appears to take the weaker position that even if such forces exist in the world, they will always be unknowable to us.) Third, insofar as causation hinges on regularities of succession that have been observed in past instances, and as the previous analysis exhausts the meaning of causation, inference to future instances is not warranted in any logical sense. Rather, such inductive inferences depend solely upon beliefs in the uniformity of nature.\nHume’s analysis has been criticized extensively. First, it is not general enough to ac- complish the goals of a regularity theory. Mill ([1843] 1973), who accepts Hume’s critique of necessity as production and the temporal priority criterion, points out that E may follow C whenever C occurs, but it may also follow B whenever B occurs, even if C fails to occur. That is, there may be a plurality of causes. The full cause might then be ( C U B) , where U is the operator “or” in set theory. Second, he points out that the cause C might be conjunctive, that is, C = ( C 1 n Cz), where n is the operator “and” in set theory. (Although Hume does not refer to conjunctive causes, there is nothing in his analysis that excludes such a case.) Second, the relevance of the contiguity criterion has also been questioned. Properly understood, the criterion permits events that are not spatially proximate to be causally re- lated, provided there is a chain of contiguous causes connecting the cause and effect (Hume [1739] 1978). As Bunge (1979) points out, this turns the criterion into a hypothesis that does not derive from experience. And as a hypothesis, some have argued that it is suspect, citing the case of quantum theory in physics. Here, there are relationships (supported by experimental evidence) that apparently feature action at a distance, and some authors have interepreted these as causal. For a brief account, see Skyrms (1988). From this point of view, although contiguity may be a feature of most real-world causal relationships, it ap- pears that a completely general concept of causation which purports to have ontological support would not include the contiguity criterion.\nThird, the temporal priority criterion has been widely debated. Philosophers such as Russell and Schopenhauer have sided with Hume, while others have argued that cause and effect can occur contemporaneously. Kant, for example, took up the case of a ball resting upon a cushion, thereby creating an indentation. And Collingwood ([1940] 1948) argues that when the full cause of an event is sought, cause and effect must be contemporaneous.\nOtherwise, the effect that actually happens could depend on events that occur during the time interval between cause and effect (Cook and Campbell 1979). Others, like Bunge ( 1979), distinguish between the concept of causation and physical causation in the world.\nAccording to Bunge, the concept of causation is independent of temporal priority, but when causes and effects are separated by a distance, physical causation involves temporal priority (at least according to 20th-century theories in physics).\nFourth, and perhaps most importantly, as Mackie ( 197 4) points out, by denying that the causal relationship contains any form of necessity, Hume loses the ability to distinguish causal sequences from sequences, like night and day, that most philosophers and scientists do not intuitively accept as causal, and therefore wish to call noncausal. Mill, who was also aware of this, attempts to deal with the problem by incorporating a notion of necessity into his account. He argues that it is not enough for the cause to be the invariable antecedent in the Humean sense of de facto regularity. In addition, the cause must also be the uncondi- tional invariable antecedent. By this Mill means that the effect will occur in the presence of the putative cause, even under changed circumstances in other antecedents, which may have to be imagined because they have not been observed. For example let C, E, and B be three events, with C and B antecedent toE, and suppose Cis necessary and sufficient forE in the observed data. Suppose also that B always occurs in the observed data. Mill is saying that before we conclude C causes E, we must be able to say that Cis necessary and sufficient forE even if the event Be (the complement of the event B) had occurred.\nThis event may never be observed in the actual data, which means that Mill is arguing that a causal statement must be capable of sustaining certain kinds of counterfactuals.\nModern regularity theorists often argue that legitimate causal statements should sustain counterfactual conditionals, and they use this criterion to distinguish causal sequences from sequences that merely exhibit universal de facto association. Mackie (1974), who accepts the idea that a causal statement should sustain a counterfactual conditional, nonetheless argues by way of several examples that Mill’s attempt to distinguish between causal and noncausal sequences is inadequate. According to him, it is necessary to also include a no- tion of causal priority before causal and noncausal sequences can be distinguished. Further, as he notes, since the examples are ones in which there is a clear temporal order among the events discussed, temporal priority in and of itself cannot accomplish the job of causal pri- ority. This is a blow to regularity theories that put forth the temporal priority criterion and then equate this with causal priority.\nPhilosophers who either accept Mackie’s argument or simply argue that causes and effects may be contemporaneous are thus faced with the problem of introducing a suitable notion of causal priority (causal order). In the absence of such a notion, when C and E are contemporaneous, instead of saying C causes E, one might just as well say that E causes C.\nFor that matter, one might just as well say that C and E cause each other, thereby robbing the concept of causation of its essential asymmetry. But philosophers do not typically accept either of these alternatives as meaningful.\nScientists usually argue that theory dictates the nature of causal ordering, where theory is usually understood to mean statements about causal mechanisms. In other words, causal ordering depends upon the notion of causal mechanism, whose ontological status is denied by followers of the Humean tradition. This maneuver, to be successful, requires explication of the concept of causal mechanism. For some attempts to explicate this concept, see, for example, Harre (1972). It is not clear that such attempts have been successful.\nMackie ( 197 4) argues that the notion of a causal mechanism should hinge on the prior notion of causal order, and he identifies causal order with a notion he calls “fixity,” that is, he takes the statement “Cis causally prior toE” to mean that the event Cis fixed prior to the time that E is fixed. Note that this does not preclude C and E from being contemporaneous, as a future event may be determined by a sufficient set of events in the past. Nor does this appear to rule out “backward” causation.\nOne way to obtain fixity is by human intervention. But Mackie argues that the con- cept of fixity is broader than the anthropomorphic notion that would result if fixity were obtainable only through intervention by a human (or human-like) agent. However, except for brief mention (p. 185) of the notion of an explanatory account (which seems like an appeal to the notion of causal mechanism, a notion Mackie already argued requires expo- sition in terms of the concept of causal priority, and not vice versa), Mackie does little to indicate how fixity can be obtained. These points are important, not only because of the potential circularity of Mackie’s argument, but because the relationship of C toE could easily depend upon the manner in which said fixity is obtained, at least in the nondetermin- istic cases that are of interest in this chapter. To see this; consider the following example, in which educational level precedes subsequent earnings. Under the first scenario, persons choose their level of education, and under the second, persons are randomly assigned by an experimenter to levels of education. Will the relationship between education and earnings be the same under the two different scenarios? Of course not. Under the first scenario, if persons want to maximize lifetime earnings and have good information on how much they would earn under their various educational choices, they will choose the level of education that allows them to maximize lifetime earnings. Under the second scenario, such behavior is precluded. It is clear that under the second scenario, Mackie would take education to be causally prior to subsequent earnings. Under the first scenario, most persons might still to preclude this, especially if the good information persons have is stochastic, that is, good on average, but not necessarily with respect to any particular case.\nOn the logical front, Simon ( 1952) argues that a proposition a1 has causal precedence over a 2 if the set of laws determining a1 are a proper subset of the laws determining a 2• Subsequent work by Simon (1953) and Simon and Rescher (1966) carries this argument over to variables and functions embedded in systems of equations, and identifies the func- tions with mechanisms. Connections between the concepts of exogeneity, endogeneity, and causal order are given. Simon (1952) carefully points out that his efforts to formalize the notion of causal order are not ontological in character. By way of contrast, Bunge (1979) argues that causal priority is essentially an ontological problem; as such, syntactic treat- ments are inadequate. According to him, the meaning of causal priority remains an open issue.\nThe issues raised in the preceding discussion are important to social and behavioral scientists who use causal language. But regularity theories have also been criticized by philosophers who argue that such accounts, which are unsuccessful in any case, do not comport with the manner in which the word “cause” is used in either ordinary or scientific language (von Wright 1971). In this vein, Collingwood ([1940] 1948, p. 285) argues that scientists often use the word “cause” in his second sense, where “that which is ‘caused’ is an event in nature, and its ‘cause’ is an event or state of things by producing or preventing which we can produce or preventthat whose cause it is said to be.” When the word “cause” is used in this sense, which is certainly closer to the way an experimentalist uses causal terminology, a different picture emerges.\nFirst, under this account, there is no presumption that the cause is the full cause that is required in a regularity account. Rather, the cause is simply the state the experimenter produces by manipulating a particular variable. To see how this notion corresponds with a regularity account, let us suppose, to keep matters simple and in accord with the philo- sophical literature, that variable X has two states, x and xc. Similarly, Y, W, and Z are variables with two states, y and yc, wand we, and z and zc, respectively. Suppose that y occurs if and only ifthe full cause ((x n w) U z) occurs. In light of the previous remarks concerning fixity, it may be important to know how the full cause comes about, but for the moment I suppose that no matter how it comes about, y occurs. Now, suppose for the mo- ment that variables X, W, and Z can be manipulated, at least hypothetically. Viewing X as the manipulated variable, y occurs when the experimenter assigns the value x to X, pro- vided W = w or Z = z, wherethevaluesofW or Z mightbeviewedasbackgroundfactors or standing conditions. This point was recognized by Anderson (1938), who argued that the background constitutes a field in which the cause operates. Note also that in the case at hand, had the experimenter assigned X the value xc, y would not have occurred (unless Z = z ); thus the manipulative account is theoretically capable of sustaining counterfactual conditionals.\nSecond, it is just as legitimate to view W as the experimental yariable, in which case W, rather than X, is manipulated. Now the values of the variables X and Z constitute the causal field. Thus, causes are relative (Collingwood [ 1940] 1948). The relativity of causa- tion is important, for it implies that alternative causal explanations of a given phenomenon are not necessarily at odds. Typically, in the social sciences, however, researchers proceed as if the particular explanation they are proposing is inimical to others. Thus, for example, sociologists often spend a great deal of time attacking psychological and economic expla- nations, as well as one another; similarly, researchers from these other disciplines often deny the validity of sociological explanations. From the standpoint here, many of these attacks are misdirected. To be concrete, a physiologist might attempt to explain the onset of depression by altered chemical activity in the brain while a sociologist might with equal legitimacy attempt to give an account that makes reference to dramatic life changes, such as divorce, death of a parent, etcetera. In making this last statement, I do not mean to imply that either the physiologist or the sociologist could actually manipulate the cause in the real world, only that they could hypothetically manipulate the cause. Similarly, a manipulation of social structure may produce declines in birth rates in third-world countries; so might the introduction of birth-control clinics and technologies.\nThird, under this account, the issue of causal priority is neatly resolved, for the state y may be said to be causally prior to x if it is Y that is manipulated, and x is causally prior to y if it is X that is manipulated. Further, since the effect of the cause is measured subsequent to the manipulation, the causal relation apparently features temporal priority. Collingwood ( [ 1940] 1948) claims that temporal priority is an integral feature of the causal relation in the manipulative account. Subsequently, I shall argue that this is incorrect and that to argue for temporal priority on the grounds that the effect is measured subsequent to the imposition of the cause is tantamount to verificationism.\nFourth, if the cause is manipulated independently of variables that are temporally prior to it, the problem of distinguishing noncausal from causal sequences is partially resolved, for at least the cause is not confounded with the effect of prior variables, that is, there are no prior variables that screen offthe relationship between the cause and the effect. (Some philosophers would also require that there be no variables occuring in the time interval between cause and effect that screen off the relationship, a point to which I shall return.) The causal accounts considered in this section are deterministic, and hence the discus- sion may appear irrelevant to current research in the social and behavioral sciences, with its emphasis on statistical relations. This is not so, for two reasons.\nFirst, many historical and comparative sociologists and political scientists compare case studies in a deterministic framework, and the foregoing discussion is relevant to such work.\nA limited methodological attempt to help these workers systematize and formalize these comparisons is given by Ragin (1987), who attempted to implement Mill’s methods (and variants thereof). Ragin appears to be unaware of earlier treatments, such as that in Mack- ie (1974, pp. 297-321). Ragin argues that statistical methods are inappropriate when re- searchers have few cases, and hence that other methods are needed. Especially in such instances, he argues that his approach is superior to a statistical approach. Apart from the dubious logic of the argument, which suggests that a choice between statistical and non- statistical methods can be made on the basis of the number of cases, as opposed to the nature of the phenomenon underinvestigation, Ragin subsequently fails to appreciate Mill’s point that casual statements should sustain counterfactuals. The implication of Mill’s point is that the observed data can be used to eliminate causes, but not, per se, to establish causal relationships. And in this vein, it is evident that with more observed data (in general) more causes can be eliminated. Conversely, with fewer cases, fewer causes can be eliminated.\nBut Ragin fails to see the relation between elimination and the number of cases and he also equates (incorrectly) the failure to eliminate causes with the establishment of causal rela- tionships. Thus, he ends up making the curious argument that the methods he proposes are especially well suited to establishing causal relationships with few cases.\nSecond, there have been numerous attempts to make causal accounts nondeterministic.\nAs noted, historically these attempts hinge on the deterministic accounts, and as such, many of the critical issues that arise in discussing the adequacy of the nondeterministic accounts are similar to the issues just considered.",
    "crumbs": [
      "Causal Inference",
      "Causal Inference in the Social and Behavioral Sciences"
    ]
  },
  {
    "objectID": "extracted/Causal Inference in the Social and Behavioral Sciences2.html#probabilistic-causation-variations-on-a-deterministic-regularity-account",
    "href": "extracted/Causal Inference in the Social and Behavioral Sciences2.html#probabilistic-causation-variations-on-a-deterministic-regularity-account",
    "title": "Causal Inference in the Social and Behavioral Sciences",
    "section": "3 Probabilistic Causation: Variations on a Deterministic Regularity Account",
    "text": "3 Probabilistic Causation: Variations on a Deterministic Regularity Account\n3.1 Philosophical Treatments\nA number of authors have argued the need for a nondeterministic treatment of causation (Good 1961, 1962; Reichenbach 1956; Salmon 1984; Skyrms 1988; Suppes 1970). Var- ious grounds have been given, including: (1) the observation that in everyday life and in scientific activity, causal language is used to discuss phenomena that are not transparently deterministic; (2) the argument that the world is nondeterministic, as purportedly evidenced by quantum theory; and (3) the argument that even if the world is deterministic, matters are often too complicated to permit a deterministic account.\nMuch of the philosophical literature on probabilistic causation may be viewed as an attempt to use probability theory to abandon the constant conjunction criterion, while re- taining many other features of a regularity account. (An exception is Giere 1980.) As such, many of the issues debated in the deterministic context carry over to the probabilistic context.\nIn addition, new concerns are also raised, since at least according to some, it is necessary to exposit the meaning of the term “probabilistic causation” (Fetzer 1988; Salmon 1984; Skyrms 1988). This is because the axioms of probability theory do not speak for them- selves. This means that either a notion of deterministic causation from which probabilistic causation arises must be explicated (philosophers who write on the subject of probabilis- tic causation have not taken this route), or alternatively, the term “probability” must be explicated and tied to some suitable notion of “probabilistic cause,” for example, causal propensity. The concerns above are critical to the approach of this section. However, space considerations preclude detailed discussion; hence, in this section, I will assume (without committing myself to the assumption) that the following accounts can be buttressed by a suitable notion of “probabilistic causation.” Thus, the criticisms outlined in this section are “internal” to the basic account, that is, these criticisms do not question the fundamen- tal premises of the argument. A critique on “external grounds” is a subject for a different manuscript; for some steps in this direction, see Holland (1986) and Sobel (1993).\nRecall that a successful regularity account should distinguish causal from noncausal sequences. This is the key consideration that motivates most probabilistic accounts. In the deterministic context, it was seen that some writers attempted to distinguish between causal sequences and sequences that merely exhibit de facto universal association by requiring causal sequences to fulfill some additional conditions that transcend the observed data.\nPhilosophers working in the probabilistic context have taken another tack. Instead of trying to say what causation is, most have attempted to characterize noncausal relations. In some treatments, the basic argument is that if two events are associated, but the relationship is not causal, there must be a set of prior (not necessarily in the strictly temporal sense) events that “accounts” for this association. This turns the issue of probabilistic causation into the issue of spurious association (Simon 1954), and on the surface this approach seems to have the advantage that it does not require the use of counterfactual conditionals that transcend the observed (or potentially observed) data. Instead, if spuriousness is suspected, one looks for the prior events that account for the association. In principle, by collecting the right data, that is, finding the correct prior events, the causal issue can apparently be decided empirically.\nA typical approach is Suppes’ ( 1970) attempt to modify the Humean account, which I now briefly examine. Suppes begins (p. 12) by defining an event Ct’ to be a prima facie cause of an event Et if and only if ( 1) t’ refers to a time point prior to timet, (2) the event Ct’ has positive probability, and (3) Ct’ is positively relevant to Et, that is, the conditional probability of Et given Ct’, denotedPr(Et I Ct’), satisfies Pr(Et I Ct’) &gt; Pr(Et). He then gives several definitions of spuriousness. For convenience, I examine his second definition (p. 25). Here, Ct’ is a spurious cause of Et if and only if (4) Ct’ is a prima facie cause of Et, (5) there is a time period t” prior tot’ and a partition lit” made up of events Bt” such that for all events in the partition (a) the event Bt” n Ct’ has positive probability, and (b) Ct’IIEt I Bt”, where the symbol II taken fromDawid (1979) is used to denote independence.\nSuppes also considers indirect causes and a number of other issues, but these shall not concern us here.\nSuppes’ account has been criticized extensively. With respect to (1) recall that some philosophers would allow causes and effects to be contemporaneous (which raises some problems for a probabilistic theory that Suppes discussed). With respect to (2), events with probability 0 occur all the time. As for (3), Skyrms (1988) notes that independence between two events does not imply conditional independence of the events, given a third event, and thus Ct’ could be a genuine (in some sense) cause without being a prima facie cause, as required by (4). But this is not really a criticism of the definition of spuriousness, per se. However, others (Davis 1988; Salmon 1984) have criticized the positive relevance criterion in (3). With respect to (5), Davis (1988) argues that by requiring t” to precede t’, Suppes cannot assign the accidental generalization to the class of spurious causes. He gives the example of a pitcher who tips his hat at time t’ before throwing his infamous fastball and striking out the batter. Finally, although Suppes intends his analysis to apply to both frequentist and subjective notions of probability, he offers no support for this intent, nor does he offer a causal account from which probability relations may be derived.\nThe remarks above show that Suppes’ analysis at best might tell us if two associated events Ct’ and Et are spuriously related, on the basis of prior events. But problems remain.\nMost philosophers want to take spuriousness to mean that Ct’ and Et share a common cause, and many interpret Suppes in this light as well, although Suppes does not claim this. This interpretation, however, is incorrect (as illustrated by the example below).\nThe principle of the common cause, put forth in philosophy by Reichenbach ( 1956), is the idea that if two distinct events C and E are associated, it is either because they are causally related or they share a distinct common cause B. (B must occur no later than C, the putative cause, which occurs no later than E.) In the latter case, it is argued that C and E should be independent, given B. Intuitively, this idea appears to have some appeal.\nBut philosophers like Salmon (1984) have given examples (called interactive forks) where one would want to say that two events share a common cause, but conditioning on the common cause does not render the two events independent. This is a criticism of (5b).\nAt the same time, these examples neither suggest nor fail to suggest whether B should be called a common cause in the case where B does screen off C and E. In that vein, it is always possible to find a partition such that clause (5) in Suppes’ definition is satisfied.\nGood ( 1962) points this out in commenting on similar proposals by Reichenbach ( 1956) and Good (1961). Evidently there is no such thing as probabilistic causation at all.\nThere are several ways to deal with the foregoing problem. One is to argue, following Hempel ( 1968), for a partition based on the current knowledge situation. A second way is to partition on the history of the world before C. This is the tactic taken by Granger ( 1969).\nAt the inferential level, both ways are identical, for Granger’s definition is clearly nonop- erational. But even when such strategies are followed, it is not hard to produce genuine probabilistic examples (as opposed to examples which mix deterministic and probabilistic events) where the relationship between the putative cause and the effect is screened off by a prior event that one may not want to call a common cause. To the best of my knowledge, examples of this type have not been given in the literature. A simple example follows.\nLet the random vector (X1, X2, EB, Ec, EE)’ follow a normal distribution with mean vector 0 and covariance matrix: 1 O’\n1 1 1 0’ 0 0 h where 1 =I 0 and I 3 denotes the identity matrix of order 3. Let (1.1) ( 1.2) (1.3) where a =/ 0, f3 =I 0. To ( 1.2) and ( 1.3) I append a “causal” interpretation, namely that X 1 probabilistically causes C, and X2 probabilistically causes E. B, however, is just a linear combination of the respective causal variables, and the error, as opposed to a genuine cause of C and/or E. Temporal subscripts could be placed on these variables, if desired. (Saying that one variable causes another is an abuse of language that is common among scientists.\nProvided it is understood that the actual referent is to events which can be constructed from these random variables, no special problems are created by this language, which I shall use freely.) With these assumptions, the covariance between C and E is afh, which is nonzero. Now (to conform with philosophical treatments that require considerations of events with nonzero probability) let C’ and E’ be Borel sets with positive probability such that Pr( C E C’, E E E’) =/ Pr( C E C’)Pr(E E E’). So C’ is a prima facie cause of E’.\n(Note I have not shown C’ is positively relevant toE’, but the events can be chosen so that this criterion is also satisfied, if desired.) Using standard results on the normal distribution I (Anderson 1984, chapter 2), the distribution of ((C, E) B) is normal with covariance matrix: Setting the covariance to 0, that is, making C and E independent, given B, and solving for 1 yields 1 .618, irrespective of the values of (3 and a, which are only assumed to be nonzero (as X 1 causes C and Xz causes E). The result now follows by forming the events C’ and E’ from C and E.\nThe previous example suggests, along the lines of Mackie’s (1974) argument for the deterministic case, that probability relations cannot, in the absence of a concept of causal priority, distinguish causal from noncausal sequences. Otte (1981) has also made this ar- gument. However, every example he gives relies on deterministic causation. Thus, what Otte really shows is that Suppes’ analysis cannot handle deterministic causes, contrary to Suppes’ claims. No support for the more general conclusion Otte reaches is given in his paper or in the literature. However, it is easy to establish the argument in a purely stochastic framework. To that end, I show (in the simplest case), using variables B, C, and E, that it is impossible, by using probability relations alone, to distinguish between wedges (Band C cause E), forks (B causes C and B causes E), and simple causal chains (B causes C and C causes E).\nLet (B, C, E)’ follow a normal distribution with mean vector 0 and variance covariance matrix: 1 /1 /2 ) ( 11 1 13 12 13 1 Linear equations corresponding to the case of a (interactive) fork are: C = f3cBFB + cc E = f3EBFB + CE, (1.4) where cc and cE are normal random variables uncorrelated with B, with variances a;c and a;E, respectively, and covariance aeceE· Regarding the variance of B as given, and choosing f3cBF = 11· f3EBF = 12· a;c = 1 -If, a;E = 1 - li. aeceE = 13 - 11”12· the covariance matrix above is reproduced. For the case of a wedge, a linear equation is: a’; where lEis a normal random variable uncorrelated with Band C, with variance Treat- E.\ning the variances of Band C, and the covariance of Band C as given, the covariance matrix 1D, is reproduced by setting f3EBW = b2-/1/3)/(1-,f), f3EGW = (r3-/1/2)/(1- and a;E = 1 - + + 2f3EBwf3EGW ). Finally, linear equations for a chain are: = C f3GBGB + E = f3EGGC + c:E:, (1.6) a;.\nwhere c:; and c:E: are normal random variables uncorrelated with B, with variances and a;. , a a;. It, c\nrespectively, and covariance e• e• • Setting f3G BG = /I. = 1 - (3 EGG = 12/ /I,\nE C E C iiht-\nae• e• = /3- 12/’YI· and a;. = 1 + 2/3/2//I reproduces the covariance matrix.\nC E E The example above illustrates the more general point that causal order, viewed as a concept, is a property of a model and not of the data. Econometricians have known this since at least Basmann ( 1965). The example strongly suggests that philosophers would do well to abandon attempts to characterize probabilistic causality without reference to some notion of causal priority that goes beyond temporal priority. As noted, some philosophers have also argued this, and there have been attempts, using recursive structural equation models, to deal with such issues, for example, Cartwright ( 1989).\nAnother recent attempt to derive causal statements from the probability distribution of a set of observed variables is due to Pearl and Verma (1991), who, according to Cox ( 1992), replace the notion of causal priority by the notion of simple structure. They use recur- sive structural equation models to express the conditional independence relations among variables in as simple a way as possible. By requiring the class of models to be recur- sive from the outset (see definition 2 of a causal theory in Pearl and Verma 1991), these authors exclude from further consideration cases like (1.4) and (1.6) where t:G and c:E are correlated. Pearl (personal communication) has argued that it is not so much that a model with correlated errors cannot be causal, but rather, because of the principle of the common cause (applied to the errors), such a model is incomplete. Note that this argument rests on acceptance of the principle of the common cause.\nIn addition, Pearl and Verma (1991) give general definitions of spurious association (both with and without temporal information) and genuine causation, claiming that their definitions comport with a manipulative account of causation. For a criticism of this at- tempt, see Sobel (1993).\nI now turn to a discussion of the notion of Granger causation.\n3.2 Granger Causation in Economics Economists have proposed several approaches to causal inference that are of interest. One approach, which is now common in empirical work in sociology and psychology and to which I shall return, stems from econometric research on simultaneous equation models in the 1940s. Here, a set of variables is partitioned into exogenous and endogenous sub- sets, and a stochastic model (with as many equations as endogenous variables) is proposed.\nThe exogenous variables are viewed as being determined outside the model, and until re- cently the exogeneity assumption was considered untestable. Exogenous variables are also typically viewed as causes of the endogenous variables, and some endogenous variables are causally prior to others. Causal priority is a property of the model that is not testable.\nDissatisfaction with this approach, in particular with the arbitrariness of assumptions about causal priority, for example, the arbitrary classification of variables as exogenous or en- dogenous and the assumptions used to identify the model, led econometricians to develop probabilistic accounts that are similar to those proposed by Suppes ( 1970). The idea was to free empirical researchers from the reliance on untestable assumptions by providing a notion of probabilistic causation and an approach to causal inference that relies on the data alone. Not surprisingly, the critiques ofthese ideas by economists led back to the conclu- sion that some notion of causal priority is indispensable if inferences that might be called causal were to be drawn.\nGranger (1980), whose earlier work (1969) on causation in time series models touched off a large and technical literature on the subject (see Geweke 1984 for an excellent review), proceeds as follows. He defines [ln as the history of the world up to and including the discrete time n, excluding deterministic relations among components of this history. Let Y n denotetherandomvectorYattimen. Granger says that Y n causes Xn+1 if Pr(Xn+1 E A I [}n) =I Pr(Xn+1 E A I [ln- Y n) for some set A. One can also considerthe history of Y up to time n, that is, Y n = {Yt}t&lt;n• and define Y nasa cause of X n+1 if Pr(Xn+1 E A I [}n) =I Pr(X n+1 E A I [ln - Y n) for some set A, as in some other treatments. If I (Xn+diYn) ([}n- Yn),onecouldsayYn doesnotcauseXn+1 (FlorensandMouchart, 1982).-Granger (1980) does not actually define noncausation for the exact case at hand, though his definition of noncausation is consistent with the above. The definition by Florens and Mouchart is also consistent with the above, except that their definition, which refers to the entire history of the sequences, requires the statement above to hold at all times.\nGranger ( 1969) also discusses feedback systems and instantaneous causation. In the present context, a feedback system refers to the case where Y n (or Y n) causes X n+1 and X n (or X toY\nn• defined analogously n) causes Y n+1· Finally, Y n causes X n instantaneously if\nPr(Xn E A I [ln-1 U Y n) =I Pr(Xn E A I [ln-1) for some set A. Granger (1980) also discusses a weaker form of causation, called causation in mean, which need not concern us further.\nThe foregoing definitions are not operational because the stochastic history of the world is inaccessible. Granger operationalizes these definitions by (1) replacing [ln with an in- (Xn. Y n•\nformation set that includes sequencesofdistinctrandom vectors, that is, =\nZn). and (2) relativizing the previous definitions with respect to This is akin to the strategy of partitioning suggested by Hempel ( 1968).\nGranger’s account has distinct advantages over that of Suppes (1970). First, Granger does not need to define prima facie causes (in the sense of Suppes), nor does he include the criterion of positive statistical relevance. His definitions can handle conditional distri- butions, where the event conditioned on has probability zero. Further, partitioning on the stochastic history of the world (or in the operational case, on a particular information set) is tantamount to choosing a fixed partition, thereby avoiding the problem that one can al- ways find a partition such that the putative cause and effect are independent, given events in the partition. In addition, Granger’s account excludes deterministic causation, and thereby avoids the type of objections Otte (1981) raised against Suppes.\nWhile Granger’s account, see also related material by Chamberlain ( 1982) and Florens and Mouchart ( 1982), avoids some of the technical pitfalls in Suppes ( 1970), it is open to a number of criticisms previously raised. For these reasons, some economists have objected to the use of the term causation in this context. For example, Leamer (1985) argues for simply using the term “precedence.” (A better term would be “predictive precedence.”) Judge et al. ( 1985) state that the notion of causation used here is not philosophically ac- ceptable. Zellner ([1979] 1984) notes that the definitions above merely serve to indicate whether one time series predicts another. He argues, following Feigl (1953, p. 408), that causality should be defined as “predictability according to a law” (or set of laws). Thus, Granger’s account or similar accounts are causal, from Zellner’s point of view, only if eco- nomic theory suggests a relation between the series in question. For criticism of the notion that the causal relation should be equated with predictability according to a law, see Bunge 1979, Byerly 1990, and Wold 1966. Briefly, these authors argue that predictability and causation are different (unless one adopts a Humean position) and there are many different types of lawfulness that one might not call causal.\nThe critiques above suggest, albeit in different language, that causal priority should not be reduced to temporal priority, as in the bulk of Granger’s account. Sims (1977), a proponent of the approach, also recognizes this point. He attempts to provide a deeper rationale for Granger’s notion of causation. In so doing, he reintroduces considerations that transcend the available data. To begin, Sims (1977) generalizes Simon’s (1952) definition of causal order. He defines S as the set of possible outcomes, and A and B as subsets of S that arise from imposing restrictions. Functions Px and Py mapS to X andY, respectively.\nHe then says that the ordered pair of restrictions (A, B) determines a causal order from X toY ifandonlyif Px(AnB) == Px(A) and Py(A) == Y. The generalization is defective, for if Px(A) ==X andPy(An B)== Py(A) == Y, there is both acausalorderfromX toY and a causal order from Y to X. Since causal order is viewed as a property of the model, and not as a property of the world, Sims also proposes the concept of structure to link the model to real-world phenomena. Roughly, the idea is that if X is causally prior toY, and one inputs a set of restrictions (in the form of the set A above) the model describes the real world if the outputs in the real world correspond with Py(AnB). Recalling the previous discussion, the idea of structure is related to Mackie’s idea of fixity; in short, structure produces fixity by means of intervention. Thus, in Sim’s account, structure not only connects the model to the real world, it also links the notion of causation to intervention (even if these interventions cannot actually take place). This does not necessarily make the account satisfactory, but it does seems to be an improvement on previous treatments of probabilistic causation, both in philosophy and economics, where almost any variable, no matter how it comes about, is sometimes viewed as causal. For further details, the reader should consult Sims (1977) or Geweke (1984).\nThere is one other remark that should be made before leaving this topic. Although Granger actually believes that temporal priority is a necessary feature of the causal rela- tionship, economists have worked with his notion of instantaneous causation. In that vein, the definition previously given is equivalent to the statement that instantaneous causation holds if X n[IY n I Dn-1 fails to hold. Thus, by the symmetry of independence, the state- ment Y n causes X n instantaneously implies the statement X n causes Y n instantaneously.\nHence, instantaneous causation, as operationalized by the econometricians, entails a com- mitment to the further conclusion that cause and effect instantaneously cause each other.\nBut this is at odds with all previous work on the subject of causation; despite many differ- ent treatments of causation in the philosophical literature, the causal relationship is viewed as intrinsically asymmetric. Therefore (unless one wants to attempt to argue against this tradition for a causal account that is not asymmetric), the concept of instantaneous causa- tion is inherently defective, even when concepts such as structure and the like are added to attempt to shore up the formal account.",
    "crumbs": [
      "Causal Inference",
      "Causal Inference in the Social and Behavioral Sciences"
    ]
  },
  {
    "objectID": "extracted/Causal Inference in the Social and Behavioral Sciences2.html#causation-and-statistics-an-experimental-approach",
    "href": "extracted/Causal Inference in the Social and Behavioral Sciences2.html#causation-and-statistics-an-experimental-approach",
    "title": "Causal Inference in the Social and Behavioral Sciences",
    "section": "4 Causation and Statistics: An Experimental Approach",
    "text": "4 Causation and Statistics: An Experimental Approach\nThe manipulative account of causation discussed in Section 2 suggests an alternative ap-\nproach to causal inference. The idea there is to manipulate an independent variable and see how the value of a response variable Y depends upon the value of the manipulated variable.\nWhile the manipulative account has a number of positive features, philosophers have done little to indicate how this account could be implemented, and the examples discussed in the literature tend to use simple types of effects in conjunction with counterfactual condition- als that warrant strong belief. For example, the conclusion that turning the ignition switch caused the car to start (in any given instance or in general) is sustained by the belief that had the ignition not been turned, the car would not have started. Matters are much less clear, however, if we want to study the effect of exposure versus no exposure to a training program on subsequent earnings of workers (Heckman and Hotz 1989; Heckman, Hotz, and Dabos 1987). Here, a particular person can be exposed to the training program, but unlike the case of the car, it would be unreasonable to believe that we know the value of earnings that would result were that person not exposed. The same remark would hold true on average. Some headway could be made if it were reasonable to assume that an individ- ual’s pre-exposure earnings and his post-exposure earnings without training are identical, but such an assumption would not be reasonable in this substantive context; see Holland and Rubin ( 1983) for further material on the foregoing type of assumption.\nThe foregoing remarks indicate that it will generally be impossible to ascertain the effect of a manipulated variable in a particular instance, at least without imposing some strong assumptions that are not verifiable. (See Holland 1986 for further material on this issue.) That is, a singular causal statement will rely upon a counterfactual conditional, and in many cases of scientific interest, we shall not have the type of information that is needed to form (or believe) the relevant counterfactual.\nRubin (1974, 1977, 1978, 1980), drawing on work by writers such as Neyman ([1923] 1990), Kempthorne ( 1952), and Cox ( 1958), proposes a model for experimental and non- experimental studies that can be regarded as a formalization of a manipulative account.\nUnder the model, certain quantities (parameters) are to be estimated, and estimates from the observed data either are good or poor estimates of these parameters (in a sense to be made precise).\nThe key idea is to begin with the effect in the singular instance. Although this quantity, sometimes called the unit causal effect, cannot typically be observed, the average of the unit causal effects (sometimes called the average causal effect) can be estimated under the right conditions. (Since an effect is by definition causal, the term “causal effect” is redundant, and therefore, despite convention, I shall simply use the term “effect”instead.) For the simplest case (which shall be extended later), Rubin proceeds as follows. To begin, he assumes a population of units, (which we shall index as { i : i E I}), and a set oftreatments { k : k = 1, … , K}. To keep matters simple, let Yik denote the response when treatment k is applied to unit i, and suppose the Yik are drawn from the distribution of a random variable Yk. Note that Yik is defined for every element of the population, whether or not that element is actually assigned to treatment k. Further, it is assumed that this value is unambiguously defined, in the sense that it does not depend on the treatments to which other units are asssigned.\nThis is the stable unit treatment value assumption (SUTVA). Next, define the unit effect of treatment k versus treatment k’ (which might be no treatment) as some function of Yik and Yik’• for example, Yik - Yik’· This effect is typically unobservable, but it may be possible to estimate the average (over the population) effect E(Yk-Yk’ ). In the typical experiment, an investigator assigns experimental units to one of the K treatments. LetT be the random variable denoting treatment assignment. Then the actual data observed by the investigator consist of drawings from the pairs (Y;k, T;), typically obtained from a sample (hopefully random), where T;, which equals k, denotes the treatment to which unit i was assigned. The investigator is interested in estimating the average effects of treatments k versus alternative treatments k’. For fixed k and k’, this is defined as E(Yk - Yk’) = E(Yk) - E(Yk’)· To estimate the average effect, the investigator uses the data on units assigned to treatment k to compute an estimate of E(Yk), for example, Yk. the sample mean among units assigned to treatment k, and he uses the data on units assigned to treatment k’ to estimate E(Yk’).\nI = I =\nIn actuality, however, the investigator has estimated E(Yk T k) and E(Yk’ T k’).\nIn general, the latter quantities are not equal to the respective unconditional expectations.\nHowever, randomization makes the assumption (Yi, · · ·, YK)IIT plausible. In tum, this implies E(Yk I T = k) = E(Yk) for all k. Randomization therefore allows the investigator to use Yk - Yk’ as an estimate of the average effect of treatment k versus treatment k’. In essence, randomization works because the units assigned to treatment k can be viewed as a random subsample from Yk.\nThe approach above is also important for the analysis of data from experimental studies without randomization and nonexperimental (observational) studies, for it clearly reveals the types of assumptions that most social and behavioral scientists implicitly make when using data from such studies to make causal inferences. This is because most social sci- entists, without respect to the study design, use experimental language when interpreting empirical results, thereby entailing a commitment (sometimes not recognized) to a manip- ulative account of causation. See Sobel ( 1990, 1994) for more on this point in the context of covariance structure analysis.\nInferences from nonexperimental studies in the social and behavioral sciences are typi- cally model based, and it is therefore important to relate Rubin’s approach to the model based approach. I begin with the case corresponding to the simple setup previously de- scribed. For this setup, to compare the differences among the K treatments, most re- searchers would estimate a one-way analysis of variance model: (1.7) where k indexes the treatment to which the unit is actually assigned, and e:ik is a random variable with mean 0. Then, it is assumed (generally implicitly) that /-Lk = E(Yk), but this is not true in general, and in fact, /-Lk = E(Yk I T = k). In the absence of random assignment, the sample means Yk. which are also the ordinary least squares estimates for /-Lk. are consistent (under mild conditions). Nevertheless, Yk is not a consistent estimator of E(Yk). Therefore Yk - Yk’ does not consistently estimate the average effect of treatment k versus k’. However, if (Yi, · · ·, E(YkiT = k) = E(Yk). In this case, because Yk is a consistent estimator of /-Lk. it is also a consistent estimator of E(Yk). Therefore, Yk - Yk’ consistently estimates the average effect of treatment k versus treatment k’. In short, under random assignment, the average effect is estimated. But (as seen above) the model can also hold without sustaining the desired interpretation.\nIn addition to making the implicit assumption that /-Lk = E(Yk), many researchers also interpret the model to mean that unit and average effects are identical, that is, the unob- served quantity Yik- Yik’ = E(Yk-Yk’ ). This is tantamount to assuming the error for unit i is invariant across potential treatments. That is, if the error for unit i under treatment k is E:ik. the assumption is E:ik = E:ik’, where k’ = 1, · · · , K. (The reason for distinguishing between e:ik of (1.7) and E:ik is that e:ik = Yik - E(Yk I T = k), whereas E:ik = Yik - E(Yk).\nI and the two errors are identical only if E(Yk) = E(Yk T = k) ). As before, the model given by ( 1. 7) can hold without implying this interpretation.\nTo see the points above in a substantive context, consider the following (oversimpli- fied) nonexperimental study, in which K = 2. A researcher wants to know the average effect of college going (versus not going to college) on subsequent earnings. To estimate the effect, he computes the mean difference in subsequent earnings between college goers and non-college goers. This is valid when T is independent of subsequent earnings (un- der either nonexperimental treatment). If T is not independent of subsequent earnings, as would be the case if people attend or do not attend college based on a good estimate of their subsequent earnings under the two conditions, the researcher would have perfectly I good estimates of E(Yk T = k), but not E(Yk). In this case, the mean difference in earn- ings between college goers and non-college goers estimates the actual average difference between the two groups, but this latter quantity is not the average effect. Economists are also familiar with the types of problems involved in making causal inferences from non- experimental data. In economic parlance, this comes under the heading of selection bias (Heckman 1974, 1976). (Note, however, that until recently, economists did not describe such problems using the explicit notation suggested by Rubin’s approach. This notation lends considerable clarity to the issue.) The simple setup can be extended to the case where treatment assignment is based on a probabilistic rule that depends on a vector of observed covariates Z (Rubin 1977). The covariates usually refer to variables that are temporally prior to the cause. For exceptions, see Rosenbaum ( 1984b) . For this case, for any given value of the covariates Z, T and Z are assumed to have a joint distribution with Pr(T = k I Z = z) &gt; 0 for all z and k.\nliT) I\nAsssume now that ( (}!, · · · , YK) Z. This is the assumption that treatment assignment\nis independent of the response, given a set of covariates. In experimental work, when, given a set of covariates, the investigator uses randomization to assign subjects to treatment groups, this assumption becomes plausible. (In the literature, the two assumptions above are sometimes referred to as the assumption that treatment assignment is strongly ignorable, given Z.) The importance of strongly ignorable treatment assignment for drawing causal infer- ences from nonexperimental studies cannot be overemphasized. In the previous setup, I E(Yk) and the conditional expectation E(Yk T = k) coincided when((}!,···, YK )liT).\nIn nonexperimental studies, this assumption is generally much too strong, as illustrated by the previous example. This suggests that social researchers who want to make appropriate causal inferences must either perform an experiment, which is often impossible, or find another way. Attempting to find a set of covariates that accounts for treatment assignment in nonexperimental work, while not at all trivial, nor fully testable, allows the social re- searcher the hope of drawing more plausible causal inferences, when treatment assignment itself is not random; details follow.\nAnalogously to the case previously discussed, under strongly ignorable treatment as- I I I\nsignment, E(}k Z, T) = E(}k Z). Now let Ykz be a consistent estimate of E(}k Z =\nz, T = k). (The notation suggests that the estimate is a sample average, but this need not be the case.) Under strongly ignorable treatment assignment, fkz - fk,z is a consistent es- timate ofthe average effect of treatment k versus k’ when the covariates have value z. An estimate of the average effect, if desired, is then obtained (at least in theory) by averaging over the distribution of Z.\nSeveral remarks appear to be in order at this point. First, in practice, an investigator may not wish to average over the distribution of Z, but may be more interested in the treatment effect at particular levels of the covariates. In some instances, the distribution of Z may not be known, and a good estimate may not be available. Even if it is possible to estimate this distribution accurately, when there is heterogeneity in these effects across levels, more refined inferences can be obtained by focusing on particular levels. Of course, in general the question of whether or not to average across levels depends upon the purposes of the investigation. In some instances, the investigator may wish to average over some of the I components of Z, but not others. In fact, the investigator can estimate E(Yk Z 1), where I Z = ( by averaging over the conditional distribution Z 2 Z 1• Second, if one is interested in how the response varies with the covariates, say at values I = I =\nz and z, one can compare the estimates of E(Yk Z z) and E(Yk Z z). This\ndoes not mean that the comparison is to be given a causal interpretation, for Z is treated as a covariate and not as a cause. Note also (Holland 1986) that such a comparison would involve comparisons across units, which is not consistent with the manner in which the basic building blocks (the unit causal effects) are used to define average effects.\nThird, as previously noted, the approach above carries over to the analysis of data from nonexperimental studies, and this is its most important application for social scientists.\nHowever, the approach appears to require measurements of the covariates. In this vein, it is important to note that when one or more of the covariates are unmeasured, it may still be possible, under certain types of assumptions, to estimate the effect of the causal variable in some cases (Heckman and Hotz 1989). When this is not the case, sensitivity analyses can be very informative; see Rosenbaum ( 1992) and the references therein.\nFourth, if Z is a discrete random vector and the number of possible values that Z takes is sufficiently small (relative to the sample size), under random assignment, conditional on Z, E(Yk I Z = z) can be estimated by averaging over units with value k of the cause, and covariates z. Estimates of average effects can then be obtained in the manner described above, provided the distribution of Z is known, or the sample studied is a random sam- ple from the population of interest. When Z takes on many values, other techniques must be used (in either experimental or nonexperimental studies) to obtain estimates of interest.\nThese techniques, which are not our primary concern here, go under the headings of match- ing, subclassification, and covariance adjustment (for example, see Rosenbaum and Rubin 1983) in the statistics literature. For an example of matching (on the propensity score) in educational research, see Rosenbaum ( 1986).\nFifth, the assumption of strongly ignorable treatment assignment, which is typically made (implicitly) by social researchers who estimate causal models, should not be taken lightly. By introducing other auxiliary assumptions, it is sometimes possible to test this assumption (Rosenbaum 1984a, 1987; Heckmann and Hotz 1989). More work remains to be done on this topic. However, the test is only as good as these auxiliary assumptions, and if substantive knowledge in an area is limited, the failure to reject the assumption of strongly ignorable treatment assignment should not be taken as seriously as in the case where subject matter knowledge is extensive.\nTo illustrate some of the foregoing material in a simple case, I elaborate on the earnings example, introducing the covariate gender, with Z = 1 if male, Z = 2 if female. Suppose thatO &lt; Pr(T = k I Z = z) &lt; 1 forz = 1,2andk = 1,2. Inthiscase,underthe strongly ignorable treatment assignment assumption, estimates of E(Yk I Z) can be formed by averaging over units with identical values of Z and T. The researcher who wants an estimate ofthe average effect in the population can use these estimates as described above.\nI The researcher who is interested in gender differences can compare the estimates of E(Yk Z = 1) with E(Yk I Z = 2), for college goers and non-college goers, respectively. This will give estimates of the average gender difference in earnings among college goers and non-college goers, respectively. In light of the previous points, however, such a comparison is descriptive and these average differences should not be confused with average effects.\nSuppose now that the strongly ignorable treatment assignment assumption does not hold, that is, gender is not sufficient for treatment assignment. In that case, the level of the causal variable taken on by a subject also depends on covariates other than gender, and it will not be possible to estimate the average effect in the usual way. For example, suppose that Y; measures earnings of the ith survey respondent, and T; = 1 if this respondent does not go to college, T; = 2 otherwise. Suppose that treatment assignment is strongly ignorable among men. Then the average effect of college going among men can be estimated by computing the mean difference between college going and non college going males. Suppose now that women who do not intend to work attend college in order to marry men who will earn high incomes. In this case, treatment assignment will not be strongly ignorable among women.\nThis means that a comparison of mean incomes among college- and non-college-going women would not estimate the average effect of college versus lack of college on female incomes. Nor would comparing the mean difference for men with the mean difference for women tell us the difference between the effects for men and women. Finally, note that if women who attend college end up marrying men with higher incomes and subsequently do not work, independently of their reasons for going to college, treatment assignment may be strongly ignorable among women. In this case, the average effect of college going (versus non-college going) on earnings could be estimated among women.\nRubin’s approach has been extended to the case where the set of treatments is not finite by Pratt and Schlaifer (1988). In this formulation, the key ingredients are: (1) a population I, as before, (2) a set of factors {a: : a: E [2}, where, for convenience of exposition, [2 RK; factors are analogous to treatments; (3) for every value a: E [2 and for every member of I, a vector valued set of concomitants Zxi and a set of disturbances U xzi with a joint distribution; for any particular value a:, the disturbances are independent and identically distributed, for a given value of the concomitants; concomitants are analogous to covariates, and as suggested by the notation, are allowed to depend on the value of the factor; ( 4) a set of hypothetical random vectors {Y xzi} that describes the value of the outcome when the factors have value a: and the random variable Zxi = z; (5) a functiong(a:, z, U xzi) = Y xzi· The assumptions above suffice to generate the conditional distribution of the response at a: when the concomitants have value z, hereafter D(Yx z), and this is the distribution the researcher wishes to estimate. Inferences about the effect of factors, when the concomitants have value z, can be obtained by comparing D(Yx z) across levels ofthe factors, provided this distribution can be estimated. The distribution D(Yx z) is not the distribution of the data; the data are drawn from the distribution D(Y I (X, Z)), where Y denotes the ob- served response vector, and X is a random vector taking values in D. However, D(Yxz) can in principle be estimated from the observed data if (Y xzi II X;) I Z xi for every member of I. This condition, which Pratt and Schlaifer call the observability condition, is anal- ogous to assumption of strongly ignorable treatment assignment. Note, however, it does not require conditional independence of X; and the set of all hypothetical responses, taken jointly. Note also the possible dependence of the covariates on the cause(s).\nTo see how this works for the case of regression analysis, consider the case of a uni- variate response. The causal regression model is: Yxzi =a+ f3’:.c + ‘“‘/1 Zxi + Cxzi, ( 1.8) where E(cxzi I Zxi = z) = 0 for every member of I. Elements of f3 measure the unit effect of the factors, while elements of’”’/ are ordinary regression coefficients.\nIn practice, the researcher observes only the realizations of the random variable li cor- responding to the one value of Xi observed and the one value of Z xi, Zi, that is observed.\nThe regression model considered by the researcher is: _, li = a+f3 xi +i’Zi +c::, ( 1.9) with the usual exogeneity assumption E( c:; I Z i = z, Xi = a:) = 0 for every member of I.\n(Analogous to the discussion following ( 1. 7), the reason for distinguishing between c:£ and Cxzi is thatc:£ = Yxzi- E(Yxzi I Zxi = z, xi= a:), whereas Cxzi = Yxzi- E(Yxzi I Zxi = z), and the two errors are identical only if E(Yxzi I z xi = z) = E(Yxzi I z xi = z, xi =a:).) From the fact that E(ci I Z; = z, X; = :t:) = E(c;zi I Zxi = z, X, = a:), it fol- lows immediately that the parameters of (1.9) are equal to the parameters of (1.8) if the observability condition is satisfied (because the errors are the same when this condition is satisfied). When this condition does not hold, the parameters are not generally equal, and =! ‘)’,\nthus elements do not measure the unit effect of die factors. Further, 1 that is,\nthe regression coefficients in the two models are not identical. Note also that the regression model can hold without sustaining a causal interpretation. That is, if the exogeneity as- sumption in (1.9) is true, the population regression coefficients of (1.9) can be (under mild conditions) consistently estimated by least squares.\nThe results above have several implications for the manner in which sociologists and psychologists use (and should use) regressions to draw causal inferences. First, contrary to opinions that are often held in sociology and psychology, a properly specified regression need not sustain a causal interpretation, and in particular, exogeneity by itself does not suffice to permit a causal interpretation. (In making this last remark, which appears to echo the remarks of econometricians who have studied the relationship between Granger causation and exogeneity, it is important to note that here a different notion of causation is being used.) Second, most social scientists do not draw a clear distinction between factors (causes) and concomitants. Typically, all independent variables are treated as if they are factors, and all regression coefficients are interpreted as unit effects (sometimes called direct effects). Since there are no concomitants in such an analysis, the observability condition in this case is tantamount to the assumption of random assignment to levels ofthe factors.\nIn most instances in social research such an assumption will not be justified. This suggests that social scientists should first consider which variables are to be treated as causes, and then attempt to measure concomitants that suffice (in the sense of making the observability condition hold) for assignment to levels of the factors. In some instances, a variable that an investigator would like to treat as a cause should be treated as a concomitant because assignment to levels of this variable has not been randomized and the investigator cannot measure or does not know the variables that are sufficient for treatment assignment. The regression coefficient corresponding to such a variable should not be interpreted as a unit effect.\nThe manipulative account and the resulting approach to inference, as outlined above, has several advantages over the notions of probabilistic causation treated previously. First, when randomization or conditional randomization is possible to implement, the issue of spuriousness does not arise (at least with respect to variables prior to the cause). Sec- ond, causal inference is tied to explicit counterfactual conditionals at the unit level; the notion that a causal inference supports a counterfactual conditional is typically lacking in the probabilistic versions discussed in Section 3 (though not in some of the justifications for the intuition underlying the definitions). Third, the quantity that one wants to estimate is clearly defined, irrespective of the study design; this too is lacking in much of the econo- metric work discussed in Section 3. Fourth, issues concerning causal priority do not tend to arise as the causes are variables that are manipulated and the effects are measured later.\nThe experimental approach is not without its practical difficulties. Causal inferences are sometimes difficult to make in randomized experiments because of internal validity prob- lems such as nonrandom experimental mortality. A number of external validity problems also arise (Campbell and Stanley [1963] 1966). Some authors have raised these issues in responding to the account (for example, Granger 1986). From the point of view here, most of these issues are relevant, indeed critical to the implementation of an adequate experi- ment, but not particularly relevant to the fundamental perspective offered by the account itself.\nNor is randomization a panacea for all problems. Various authors (Conlisk 1985; Gail, Wieand, and Piantodosi 1984; Smith 1990) have shown that randomization does not allow consistent estimation of unit treatment effects in models where a covariate, omitted from the analysis, interacts with a treatment variable. Thus, if an investigator wants to estimate the unit treatment effect (as opposed to the average effect), randomization will not always allow this.\nOther difficulties arise when the manipulative account is transferred over to the nonex- perimental domain. Philosophers and statisticians have argued aboutt he types of pheno- mena that could be causes. Must a cause be an event or state that can actually be induced in practice? If so, the manipulative account is irrelevant to many sociologists. At the other extreme, sociologists and psychologists who use causal models often seem to think that anything can be a cause. For example, in these disciplines the usual view is that latent variables do not correspond to any real-world entities, but are only hypothetical constructs around which theoretical work is organized. However, this does not stop anyone from speaking explicitly of the effects of these variables (for example, Joreskog 1977) or from reporting estimates of these. Evidently, latent variables are not really real, but these not really real constructs cause real-world effects nevertheless. In some instances the response variable is a latent variable; in this case the not really real constructs cause a real-world effect that is not really real, either. For further treatment of causal inference in models with latent variables, see Sobel (1994).\nCollingwood ([1940] 1948) points out (in the deterministic context)t hat the manipula- tive account of causation is both anthropocentric and anthropomorphic. G. H. von Wright ( 1971) argues that the manipulative account does not hinge on the actual ability to manipu- late the cause, but it does hinge on the ability to potentially manipulate the cause. Holland (1986) also makes this argument. Mackie (1974) finds such accounts unacceptable, for (in part) they imply that causation is inherently linked to the activities of human beings (or en- tities that operate like humans, such as Nature and Prankster in Pratt and Schlaifer 1984).\nIn the absence of such agents, causation does not exist. (But see also Section 2 for criticism of Mackie’s attempt to fix the problem in a nonanthropomorphic manner.) Pratt and Schlaifer ( 1988), who eschew commitment to a particular notion of causation, point out, with respect to the observability condition previously discussed, that it does not matter if the investigator selects case i with value a: or sets the value of the factors on this case to a:. This seems to suggest that one could reduce the dependence of the manipula- tive account on the notion of manipulation by removing this notion and imagining, without saying how, that all observations can receive any value of the factor. This seems true in a formal sense, thereby making the account nonanthropomorphic. On the other hand, it has already been argued that the manner in which the cause is brought about may be critical for understanding the meaning of an effect. Without attempting to definitively settle this issue, when the factors are set to some value a: E [l, either in actuality or in theory, the investigator is forced to indicate how this occurs. This clarifies the meaning of the factors, and hence of the effects. It also allows the investigator to think about the concomitants that are sufficient for assignment to levels of the factors. Finally, the content of the counterfac- tual conditional on which causal inferences rest is clarified (although it may still be difficult to form this counterfactual). If cases were simply selected with value a:, the investigator does not have to indicate how an alternative value could come about, and hence the coun- terfactual conditional is vague, as is the meaning of the factors and their effects. In this case, it is also virtually impossible to imagine the concomitants that are sufficient for as- signment to treatment levels. A natural way to surmount the difficulties raised by selection, as opposed to manipulation, is to reintroduce manipulation by imagining the experiment in which cases are assigned to levels of the factors. Unless there is some other way of dealing with the problems raised by selection (and I do not see another way), it appears that the ability to manipulate the factors, at least hypothetically, is central, at least at the level of implementation in a real case.\nSecond, issues concerning causal priority do not tend to arise under a manipulative account. This is because the cause is under the control of the investigator. In addition, the effect is measured subsequent to the cause, so the causal relation apparently features temporal priority (see Section 2). Some authors (for example, Collingwood [ 1940] 1948; Holland 1986) view temporal priority as an inherent part of the causal relation. Sobel ( 1990) also requires causes to precede effects in time. In his paper, some of the results would change if instantaneous causation were allowed; as he notes, in most instances in the social sciences, the causal relation of interest features temporal priority.\nIt is important to note, however, that the manipulative account does not satisfactorily resolve the issue of temporal priority. The key to this account is the ability to manipulate (if only hypothetically) the cause; the fact that the effect is measured subsequently should be viewed as part of the research design, that is, as part of the experimental approach to inference. But philosophers and statisticians alike have failed to take such a view; in so doing, they have committed the sin ofverificationism.\nI propose to resolve this problem by distinguishing between the time at which there- sponse is measured and the value of the response at different times, incorporating this dis- tinction into the previous formalization of the account. Since a full treatment is beyond the scope of this chapter, matters are kept as simple as possible. Consider the case where the cause takes values k = 0 (say, no treatment) and k = 1 (treatment). Let t0 denote the time at which treatment is initiated and let (Yik)t ,t denote the response of unit i to level k of 0 1 the cause at the time t1, where t1 2:: to. Similarly, let (Yii - Yio)(to,t 1) denote the effect for unit i. Under the usual manipulative account, t 1 denotes a fixed time at which the response is measured, and insofar as it is not possible to actually measure the response at the fixed time t0, t1 &gt; t0• The fact that the response is measured subsequent to the cause appears to be the basis for the claim that temporal priority is an integral feature of the causal relation under a manipulative account. This, however, confuses the approach with the ontological aspect of the causal relation.\nWith fixed times t0 and t 1, as in the foregoing paragraph, there is no real reason to actually introduce the temporal subscripts into the notation for the unit effect. Suppose now we interpret the unit effect in the previous paragraph as a unit effect function, with arguments t 0 and it, subject as above to the restriction it 2 to. For simplicity, suppose also that for all initiation times to the unit effect function is a step function, that is, (lit - lio)(to,t 1) = Lli if it 2 t0+ &gt;.i. 0 otherwise, where Ai is a fixed real number on the nonnegative portion of the real line. For simplicity, suppose the unit effect function is a “constant” effect function, that is, Lli = L1 and Ai = &gt;.. Suppose also that L1 =I 0. (Note how the constant effect case corresponds to a treatment that is akin to the deterministic manipulative account.) In the case at hand, it seems reasonable to say that for every unit the cause is temporally prior to the effect if&gt;. &gt; 0, and to view the case &gt;. = 0 as an instance of instantaneous causation. Thus, temporal priority does not appear to be an integral feature of the causal relation under a (suitably modified) manipulative account. Of course, the experimental approach will not allow for the measurement of instantaneous effects, should these exist.\nThus, an experimental approach that appears to allow instantaneous causation will rely on some untestable assumptions.\nA serious limitation of the usual experimental approach, especially for some types of sociological research, stems from utilization of the stable unit treatment value assumption (SUTVA) (Rubin 1978, 1980). In essence, this assumption states that the same value of the response for unit i to treatment k will occur no matter what treatments have been as- signed to the other units of the population. Pratt and Schlaifer ( 1988) avoid making this assumption explicitly, but assume that the response Y i that is observed when Xi = a: and the other observations have whatever values on the factors and concomitants they take on, corresponds to the value Y xzi that would be observed (a counterfactual) if all observations had value a: on the factors. In other words, Pratt and Schlaifer (1988) do not avoid this issue; they merely do not discuss it.\nRelaxations of the SUTVA assumption for limited types of violations have been dis- cussed in the literature (for example, Cox 1958; Holland 1987; Rosenbaum 1987). But these relaxations do not suffice to allow consideration of many questions that most philoso- phers and scientists would consider causal. For example, does poverty cause crime? Under the formalization of the manipulative account under consideration here, this is not even a sensible question if poverty is defined as lying below some percentile on the income distribution. If, however, poverty is defined by reference to some dollar amount, use of the SUTVA assumption (or the assumption of Pratt and Schlaifer) is tantamount to the as- sumption that the criminal behavior of respondent i is the same whether all persons have the same income or there is an income distribution featuring vast disparities. But this is simply not believable. Further, the problem does not lie with the question, which admits a causal interpretation under a manipulative account. Evidently, use of the SUTVA assumption pre- cludes consideration of certain types of questions that social scientists ask all the time. In philosophy, causal questions with answers that are dependent on distributional properties of the population have been termed frequency dependent by Sober ( 1982), whose examples are drawn from evolutionary biology.",
    "crumbs": [
      "Causal Inference",
      "Causal Inference in the Social and Behavioral Sciences"
    ]
  },
  {
    "objectID": "extracted/Causal Inference in the Social and Behavioral Sciences2.html#causal-inference-in-causal-models",
    "href": "extracted/Causal Inference in the Social and Behavioral Sciences2.html#causal-inference-in-causal-models",
    "title": "Causal Inference in the Social and Behavioral Sciences",
    "section": "5 Causal Inference in “Causal Models”",
    "text": "5 Causal Inference in “Causal Models”\nSection 4 showed that the parameters of an explicitly causal regression model need not\nbe identical with the parameters of the usual linear regression model used in social and behavioral research, even when the latter model is properly specified (at least in the mean structure). Additionally, conditions were given under which the parameters of the two mod- els are identical. In this section, I briefly take up the use of structural equation modeling for drawing causal inferences in social and behavioral research. This approach, which is an outgrowth of econometric work on simultaneous equation models, is usually featured in conjunction with nonexperimental studies, but the interpretation of the model parame- ters (and parameter estimates) typically relies on notions of causation that are similar to those encountered in Section 4 (Sobel 1990, 1993, 1994). Consequently, the material on single-equation models in that section carries over to the simultaneous-equation context.\nIn addition, these models are more complicated than the single-equation models, in partic- ular because they feature relationships among dependent variables. As such, a number of new issues and concerns, not apparent in the single-equation case, arise with respect to the interpretation and estimation of these models.\nI begin with the usual approach, as handed down from econometrics. To keep mat- ters simple, connections with time series models will be minimized, and in the discussion of exogeneity, it will not be necessary to refer to the more general notion that a variable is predetermined. I will also assume simple random sampling from a random vector of observables Z of dimension n + m.\nIn the econometric approach, the variables in Z are first partitioned into subsets X and Y, of dimension n and m, respectively. The variables in X are viewed as “exogenous,” that is, determined outside the system under consideration, and these variables, which often refer to policy instruments in the economic context, are regarded as inputs into the model.\nExogenous variables are causally prior to the variables in Y, which are dependent or en- dogenous variables, and the values ofthe endogenous variables (which are often viewed as outputs) depend upon the values of the exogenous variables, as well as the values of other endogenous variables and stochastic disturbances. The partitioning of Z into exogenous and endogenous sets is to be decided on the basis of economic considerations (and temporal priority), and this assumption is not fully testable. Foro bservation i from the population I, the “structural” model is: Y; =a+BY;+TX;+e;, ( 1.10) where B is an m x m matrix of parameters describing relationships among the endogenous r variables, with diagonal elements 0, is an m x n matrix of parameters connecting exoge- nous and endogenous variables, and e; is a random drawing from a distribution with mean 0 and finite nonsingular covariance matrix E. Technically, it is not necessary to assume that this covariance matrix is nonsingular. In addition, it is assumed that that matrix (I- B) is invertible, that observations are independent, and that e; and X; are independent. This last assumption is the exogeneity assumption, and as stated, is stronger than required, since uncorrelatedness will suffice for deriving consistent estimates. The relationship between the exogeneity assumption and the intuitive notion that exogenous variables are determined outside the system is discussed subsequently.\nThe parameters of the structural model above may or may not be uniquely determined.\nHowever, the parameters a’, II, and tJ! of the reduced form equation: Y;=a’+IIX;+v;, (1.11) where v; = (I- B)-1e;, are uniquely determined, with a’ = (I- B)-1a, II = (I- B)-1T, 1/1 = V(v;) =(I-B)-1E(I- B’)-1 for all i. Theseparameterscharacterizethe conditional mean structure E(Y I X) and the conditional covariance structure of v;, for all i. Using these parameters, in conjunction with restrictions on the structural parameters, it may be possible to uniquely determine (identify) the value of the unrestricted structural parameters. When this is the case, the model is said to be identified. In the following, it is assumed that the model is identified; readers who desire further information about identification can consult an econometrics textbook or Hausman ( 1983).\nEconometric models are used to draw causal inferences in several ways. Under regu- larity conditions on B, the reduced form parameter ’lrrs is usually interpreted as the effect of a one unit change in X;r (the rth element of X;) on Y;. (the sth element of Y .). In economics, such effects are called equilibrium multipliers (Goldberger 1959), and in psy- chology and sociology these quantities are called total effects. Second, economists are typically interested in the structural form of the model. Parameters of the structural form, which are often viewed as more fundamental than the reduced form parameters, are thought to describe the behavior of agents (persons, firms, the government) in the economic sys- tem, and changes in one structural parameter may change the entire reduced form (Judge et al. 1985). The manner in which such a parameter describes this behavior is generally not stated, however.\nEconomists have criticized the structural-equation approach to causal inference on var- ious grounds. First, the concept of a structural parameter is vague at best, meaningless at worst. As Lucas (1976) points out, economic agents may change their behavior when inputs into the economic system change. This would imply that the so-called structural parameters are not invariant to such changes, and in this case, the interpretations in the pre- ceding paragraph would not hold. This is also evident from the material in Section 4. Since each reduced form equation is simply a regression, note that, as in Section 4, the regression may be properly specified, yet ’lrrs may not describe the actual change that would result under manipulation of the exogenous variable Xr. The assumption that 1r rs does describe the effects of this manipulation is external to the model, although it is often overlooked.\nFrom Section 4, it is also clear that if all the exogenous variables are viewed as causes, this is tantamount to assuming that assignment to these variables is random.\nIn response to some of the concerns above, Sims ( 1982) argues that a parameter is structural if it is invariant under a class of modifications ofthe system. Similarly (but more strongly), Engle, Hendry, and Richard (1983, p. 284) define a (conditional) model to be structurally invariant “if all its parameters are invariant for any change in the distribution of the conditioning variables.” Leamer ( 1985) argues that these ideas about invariance should be extended to apply to the concept of exogeneity. The intuitive notion that exogenous variables are determined outside the system of interest does not correspond well with the definition that a variable is exogenous (with respect to some equation) if it is independent of the error. For example, if two random variables are bivariate normal, there are two regressions, and the right-hand- side variable in either regression is exogenous (independent of the error). Thus, exogeneity depends on the equation of interest, and it also implies a committment to certain parameter values. Leamer argues instead that a vector X should be called exogenous with respect to a dependent variable Y. if the distribution D(Y. I X) is invariant to a class of interventions.\nCharacterization of this class may, however, be difficult. This (typically untestable assump- tion) is similar to the concept of superexogeneity proposed by Engle, et al. ( 1983), except that superexogeneity entails invariance to all interventions, and it hinges on a concept of weak exogeneity that is tied to efficient statistical inference. Then, Leamer proposes to call an exogenous variable X, causal with respect to a dependent variable Y. if the distribution D(Y. I X) depends on X,. An endogenous variable }J can also be a cause of another endogenous variable Y2 if the distribution of Y 2 depends on Z, where Z is a “surrogate ex- ogenous variable for Y 1” (Leamer, 1985, p. 258). Leamer does little to clarify the intended meaning of this statement. It is clear, however, from Section 4, that if the observability condition holds, one can think of }J as a cause, and estimate the effect of }J on Y 2• It seems unlikely (given the rest of Leamer’s treatment) that this is what he has in mind, however.\nPsychologists and sociologists who have written on covariance structure analysis, which incorporates the model above as a special case, have tended to borrow the econometrician’s approach to causal inference. But they have not been attentive to the recent concerns in the econometric literature concerning exogeneity and parameter invariance. In addition, they often focus on independent variables that are not subject to intervention (as seen earlier), and unlike much of the economic literature, they also equate the parameters relating depen- dent variables to other dependent variables with effects, a practice criticized below.\nIn that vein, the usual approach in psychology and sociology distinguishes three types of effects: total, direct, and indirect. The direct effect of a variable on another is usu- ally thought of as the effect that is not transmitted through intervening variables, and has been defined explicitly as the outcome that results when the investigator induces a one- unit change in the independent variable, holding intervening variables constant (Alwin and r Hauser 1975). Direct effects are thought to be captured by the elements of and B. Thus, Irs gives the direct effect of Xs on Y,. and f3rs gives the direct effect of Y. on Y,.. Simi- larly, the total effect of X, on Y, is given by 7rm and as in the economics literature, this quantity is interpreted as an equilibrium multiplier. Total effects of endogenous variables on endogenous variables have also been defined in the literature; Sobel ( 1990) shows that these definitions are incorrect.\nAlthough the foregoing definitions are usually applied in nonexperimental studies, the implicit notion of causation in the literature is still manipulative (as indicated above). But investigators who use the experimental metaphor do not take it seriously. Neither do method- ologists who write about such matters (as illustrated below). For example, they do not dis- tinguish between variables that are causes and other variables that are concomitants. Any variable can be a cause, and thus one sees statements (based on a nonzero regression coeffi- cient) that exogenous variables like father’s occupation cause the endogenous variable son’s intelligence (Kenny, 1979, p. 52). Do we really believe that, if we raised the father’s occu- pation one unit on some prestige scale, the son would become more intelligent (presuming here intelligence, which is usually measured as a latent variable, is real)? Admittedly, the concept of intelligence is nebulous; nevertheless, it is doubtful whether any current notions of intelligence would allow a claim along such lines. Second, investigators attempt to con- sider direct effects of alleged causes, even when it is clear that one or more intervening variables the concept of an intervening variable is not even defined in the usual literature, as pointed out in Sobel (1990) cannot be held constant. Third, investigators ignore pos- sible relations among exogenous variables when they compute total effects of exogenous variables. For example, in a status attainment model which includes father’s education and father’s occupation, the total effect offa ther’s education on son’s education that is reported ignores the fact that father’s occupation depends on and is temporally subsequent to father’s education. Duncan ( 197 5) makes a similar point. Note also how the foregoing example il- lustrates that while both variables may be exogenous in the statistical sense with respect to the son’s education equation, it is difficult to argue that father’s occupation is determined outside the model. Fourth, investigators discuss the effects of endogenous variables on other endogenous variables, linking these to elements of the matrix B, or to functions of these elements. But if an endogenous variable is to be viewed as a cause of another endoge- nous variable, and causation involves at least a hypothetical manipulation, as implicit (and sometimes explicit) in the literature, how is this view to be reconciled with the treatment of the (causal) endogenous variable as a stochastic outcome of the model itself? Sobel ( 1990), drawing on Fisher ( 1970), points out that here a very strong invariance assumption is being made, namely that the parameter (or function) relating the two variables would be the same in a different system in which the so-called causal endogenous variables were exogenous.\nThis requires a thought experiment which is difficult to perform in some instances, and the invariance assumption is also often unreasonable. Fifth, mathematical results depend on whether causation is instantaneous or whether the cause is temporally prior to the effect. In many cases, researchers view temporal priority as needed, but this is not reflected in their interpretation of the results, nor in the definition of the effects. To see how the mathemati- cal results may hinge on explicit assumptions about such matters, see Sobel ( 1990). Sixth, as noted in Section 3, investigators often treat simultaneity in these models as meaning that cause and effect simultaneously cause each other. On the subject of simultaneity, see also Cox ( 1992), and for additional criticisms of the causal-modeling approach in psychology and sociology, see Holland (1988) and Sobel (1990, 1994).\nA number of the preceding abuses would be lessened if sociologists and psychologists took the experimental metaphor seriously, as well as the associated econometric literature on exogeneity and invariance. But the econometric approach itself is not without its diffi- culties. To illustrate, I briefly reconsider Leamer’s definition of causation. First, Leamer recognizes that the interpretation of economic data rests upon the experimental metaphor, and he espouses a notion of causation compatible with this metaphor. Thus it is reasonable to ask whether his definition of causality, which is based on the distribution ofthe observed data, and not on the distributions in Section 4, is in line with this metaphor.\nTo that end, consider the joint distribution of height and weight in an adult population, and suppose it is bivariate normal. Imagine a class of interventions in which some persons are induced to gain five pounds, others to lose five pounds. Such a set of interventions could be conducted in such a way that neither the marginal distribution of weight, nor the condi- tional distribution of height given weight changes. Thus, weight is exogenous (Leamer’s definition) to height for such interventions. Furthermore, the distribution of height, given weight, depends on weight. Hence, using Leamer’s definitions, weight causes height. How- ever, we do not believe that inducing an adult person to lose or gain five pounds changes their height. Therefore, it is necessary to conclude that Leamer’s definition of causality (in the sense he intends it) is defective. One might well object to this counterexample on the grounds that no one would consider this relationship causal in the first place or wish to consider such a class of interventions, and/or that a fuller model would uncover the spuri- ousness ofthis relationship. Such objections are beside the point. The counterexample is designed simply to show that the definition itself is defective. A better model might well produce better causal knowledge, and Leamer’s definitions (to the extent these could be implemented), might work under some circumstances (which have not been spelled out), but this certainly does not vindicate the definition itself.\nA more explicit approach is taken by Holland (1988), who applies the experimental approach to a recursive two-equation system with a binary independent variable, which takes values 1 in the treatment group and 0 in the control group. He distinguishes carefully between the causal model and the system of regression equations for this case. Mimicking ( 1.8) (Holland does not write the model in this way) the causal model (note both X and }J are explicitly viewed as causes here) could be written as: = Ylxi a1 + ‘)’nX + C1xi f2xy1i = a2 +’)’21X + fJ21Y1 + C:2xy1i· ( 1.12) The first equation describes the value of the response Ylxi when the independent variable is set to x, for all i, and the second describes the value of the response Y2xy 1; when the independent variable is set to x, for all i, and in addition, }J is set to Y1· The corresponding simultaneous equation model is: Yl(i) = &1 + iuX; + c:i; Y2 = &2 + i’21X; + .821Yl + c:i;. (1.13) Holland assumes random assignment to treatment and control groups. Under this as- sumption, consistent estimates of iu are consistent for ’Yll· Similarly, the reduced form parameter in the regression of Y 2 on X is consistent for the total effect in the causal model.\nBut the estimates of 1 21 and .821 are not consistent for the corresponding causal parameters.\nNote that Sobel’s ( 1990) conclusion that the usual parameters of the simultaneous equa- tion system should not be interpreted as direct effects, a conclusion reached in a different manner, reiterates this result. For further details on this case, see Holland ( 1988), and for other relevant material, see Angrist, lmbens, and Rubin ( 1993), Efron and Feldman ( 1991 ), Robins (1994), and Robins and Greenland (1992).",
    "crumbs": [
      "Causal Inference",
      "Causal Inference in the Social and Behavioral Sciences"
    ]
  },
  {
    "objectID": "extracted/Causal Inference in the Social and Behavioral Sciences2.html#discussion",
    "href": "extracted/Causal Inference in the Social and Behavioral Sciences2.html#discussion",
    "title": "Causal Inference in the Social and Behavioral Sciences",
    "section": "6 Discussion",
    "text": "6 Discussion\nTwo deterministic accounts of causation were considered. Probabilistic notions of causa-\ntion that rely primarily on the concepts of independence and conditional independence do not lead to causal inferences that comport with a manipulative account. Nor does the typ- ical approach to causal inference in nonexperimental studies in the social and behavioral sciences yield inferences that comport with a manipulative account. In that vein, the forma- lization of the manipulative account discussed in Section 4 appears to offer more promise to social scientists. The formalization is identical for experimental and nonexperimental studies, and the resulting approach to causal inference reveals the types of assumptions researchers implicitly make when analyzing data in nonexperimental studies. As such, this approach provides a framework in which the nonexperimental worker can think more clearly about the types of conditions that need to be satisfied in order to make inferences in line with a manipulative account. It should also encourage sociologists, who have typically disdained experimental evidence, to pay more attention to the results from well-designed experiments (when these are possible) and/or to design experiments that will yield infer- ences in line with the manipulative account. This is not to say that the experimental ap- proach is free of difficulties (some of which have been identified in Section 4 ), or that it can always be implemented, or that all scientific inferences should be causal in the first place.\nNor am I suggesting causal inferences are always faulty in the absence of a randomized experiment. In that vein, many, if not most, scientific breakthroughs (for example, Snow lowered the death rate due to cholera by turning off water pumps in London) have been made without the benefits of a randomized experiment.\nExisting formalizations of the manipulative account are not general enough to handle the types of causal questions that social scientists are often interested in addressing. Some of the limitations have already been pointed out in the text. Another problem that could benefit from a formal treatment (noted in Cox 1992) is the subject of hierarchical variation, which is usually addressed by using contextual (multilevel) models. Hopefully some of these gaps will be addressed by future workers.\nREFERENCES Alwin, D. F., and Hauser, R. M. (1975), “The Decomposition of Effects in Path Analy- sis,” American Sociological Review, 40, 37-47.\nAnderson, J. ( 1938), “The Problem of Causality,” Australasian Journal of Psychology andPhilosophy, 16, 127-142.\nAnderson, T. W. (1984), An Introduction to Multivariate Statistical Analysis (2nded.), New York: John Wiley.\nAngrist,J.D.,Imbens,G. W.,andRubin,D.B. (1993), “Identification of Causal Ef- fects Using Instrumental Variables,” unpublished manuscript, Department of S tatis- tics, Harvard University.\nBarnes, J. ( 1982), Aristotle, Oxford: Oxford University Press.\nBasmann, R. L. (1965), “A Note on the Statistical Testability of ‘Explicit Causal Chains’ Against the Class of ‘Interdependent’ Models,” Journal of the American Statistical Association, 60, 1080-1093.\nBunge, M. (1979), Causality and Modern Science (3rded.), New York: Dover.\nByerly, H. (1990), “Causes and Laws: TheAsymmetryPuzzle,”inPSA 1990,Proceed- ings of the 1990 Biennial Meeting of the Philosophy ofS cience Association, Vol. 1, eds. A. Fine, M. Forbes, and L. Wessels, East Lansing, MI: Philosophy of Science Association.\nCampbell, D. T., and Stanley, J. C. (1963) 1966, Experimental and Quasi-Experimen- tal Designs for Research, Chicago: Rand McNally.\nCartwright, N. ( 1989), Nature’s Capacities and Their Measurement, Oxford: Clarendon Press.\nChamberlain, G. (1982), “The General Equivalence of Granger and Sims Causality,” Econometrica, 50,569-581.\nCliff, N. (1983), “Some Cautions Concerning the Application of Causal Modeling,” Multivariate Behavioral Research, 18, 115-126.\nCollingwood, R. G. ( 1940) 1948,An Essay on Metaphysics, Oxford: Oxford University Press.\nConlisk, J. ( 1985), Comment on “Technical Problems in Social Experimentation: Cost vs. Ease of Analysis,” by J. A. Hausman and D. A. Wise, inSocialExperimentation, eds. J. A. Hausman and D. A. Wise, Chicago: University of Chicago Press, pp.\n208-219.\nCook, T. D., and Campbell, D. T. (1979), Quasi-Experimentation: Design and Analy- sis Issues for Field Settings, Boston: Houghton Mifflin.\nCox, D. R. ( 1958), The P Ianning of Experiments, New York: John Wiley.\n–(1992), “Causality; Some Statistical Aspects,” Journal of the Royal Statistical Society, Ser. A, 155,291-301.\nDavis, W. A. ( 1988), “Probabilistic Theories of Causation,” in Probability and Causal- ity: Essays in Honor of Wesley C. Salmon, ed. J. H. Fetzer, Dordrecht, Holland: D.\nReidel, pp. 133-160.\nDawid, A. P. (1979),“Conditional Independence in Statistical Theory” (with discus- sion),Journal of the Royal Statistical Society, Ser. B, 41, 1-31.\nDuncan, 0. D. (1966), “Path Analysis: Sociological Examples”, American Journal of Sociology, 72, 1-16.\n–(1975) Introduction to Simultaneous Equation Models, New York: Academic.\nEfron, B., and Feldman, D. (1991), “Compliance as an Explanatory Variable in Clinical Trials” (with discussion), Journal of the American Statistical Association, 86,9-26.\nEinhorn, H. J., and Hogarth, R. M. (1986), “Judging Probable Cause”, Psychological Bulletin, 99, 3-19.\nEngle, R. F., Hendry, D. F., and Richard, J. F. (1983), “Exogeneity,” Econometrica, 51, 277-304.\nFeigl, H. (1953), “Notes on Causality,” in Readings in the Philosophy of Science, eds.\nH. Feigl and M. Brodbeck, New York: Appleton-Century Crofts, pp. 408–418.\nFetzer, J. H. ( 1988), “Probabilistic Metaphysics,” in Probability and Causality: Essays in Honor of Wesley C. Salmon, ed. J. H. Fetzer, Dordrecht, Holland: D. Reidel, pp.\n109-132.\nFisher, F. M. (1970), “A Correspondence Principle for Simultaneous Equation Mod- els,”Econometrica, 38,73-92.\nFlorens, J.P., andMouchart, M. (1982), “A Note on Noncausality,” Econometrica, 50, 583-591.\nFreedman, D. A. (1987), “As Others See Us: A Case Study in Path Analysis” (with discussion),]o urnal of Educational Statistics, 12, 101-223.\nGail, H. M., Wieand, S., and Piantadosi, S. ( 1984), “Biased Estimates of Treatment Ef- fects in Randomized Experiments with Nonlinear Regression and Omitted Covari- ates,” Biometrika, 71,431–444.\nGasking, D. (1955), “Causation and Recipes,” Mind, 64,479–487.\nGeweke, J. (1984), “Inference and Causality in Economic Time Series Models,” in Handbook of Econometrics (Vol. 2), eds. Z. Griliches and M.D. Intriligator, Ams- terdam: NorthHolland,pp. 1101-1144.\nGiere, R. ( 1980), “Causal Systems and Statistical Hypotheses” (with discussion), in Ap- plications ofI nductive Logic, eds. L. J. Cohen and M. Hesse, Oxford: Oxford Uni- versity Press, pp. 251-290.\nGoldberger, A. S. (1959), Impact Multipliers and Dynamic Properties of the Klein- Goldberger Model, Amsterdam: North Holland.\nGood, I. J. (1961), “A Causal Calculus I,” British Journal ofth e Philosophy ofS cience, 11, 305-318.\n–(1962), “A Causal Calculus II,” British Journal of the Philosophy ofS cience, 12, 42-51.\nGranger, C. W. (1969), “Investigating Causal Relations by Econometric Models and Cross-Spectral Methods,” Econometrica, 37,424–438.\n–(1980), “Testing for Causality: A Personal Viewpoint,” Journal of Economic Dy- namics and Control, 2, 329-352.\n–( 1986), Comment on” Statistics and Causal Inference,” by P. W. Holland, Journal of the American Statistical Association, 81, 967-968.\nHarre, R. (1972), The Philosophies ofS cience, Oxford: Oxford University Press.\nHarre, R., and Madden, E. H. (1975), Causal Powers: A Theory of Natural Necessity, Oxford: Basil Blackwell.\nHausman, J. A. (1983), “Specification and Estimation of Simultaneous Equation Mod- els,” in Handbook of Econometrics(Vol. 1) , eds. Z. Griliches and M. D. Intriligator, Amsterdam: North Holland, pp. 392-448.\nHeckman, J. J. (1974), “Shadow Prices, Market Wages, and Labor Supply,” Economet- rica, 42, 679-694.\n–(1976), “The Common Structure of Statistical Models of Truncation, Sample Se- lection and Limited Dependent Variables and a Simple Estimator for such Models,” Annals of Economic and Social Measurement, 5, 475-492.\nHeckman, J. J., andHotz, V. J. (1989), “Choosing Among Alternative Nonexperimen- tal Methods for Estimating the Impact of Social Programs: The Case of Manpower Training” (with discussion), Journal of the American Statistical Association, 84, 862-880.\nHeckman, J. J., Hotz, V. J., andDabos, M. (1987), “Do We Need Experimental Data to Evaluate the Impact of Manpower Training on Earnings?” Evaluation Review, 11, 395-427.\nHempel, C. G. ( 1968), “Maximal Specificity and Lawl ikeness in Probabilistic Explana- tion,” PhilosophyofScience, 35,116-133.\nHolland, P. W. (1986), “Statistics and Causal Inference” (with discussion), Journal of the American Statistical Association, 81, 945-970.\n–(1987), Comment on “The Role of a Second Control Group in an Observational Study,” by P.R. Rosenbaum, Statistical Science, 2, 306-308.\n–(1988), “Causal Inference, Path Analysis, and Recursive Structural Equation Models” (with discussion), in Sociological Methodology, 1988, ed. C. C. Clogg, Washington, D. C.: American Sociological Association, pp. 449-493.\nHolland, P. W., and Rubin, D. B. (1983), “On Lord’s Paradox,” In Principals of Mod- ern Psychological Measurement, eds. H. Wainer and S. Messnick, Hillsdak, NJ: Lawrence Erlbaum, pp. 3-35.\nHume, D. (1739) 1978,A Treatise ofH uman Nature, Oxford: Oxford University Press.\n–(1740) 1988, An Abstract of a Treatise of Human Nature, in An Enquiry Con- cerning Human Understanding/David H ume: Introduction, Notes, and Editorial Ar- rangement by Anthony Flew, ed. A. Flew, La Salle, IL: Open Court, pp. 29-43.\n–(1748) 1988, An Enquiry Concerning Human Understanding, in An Enquiry Con- cerning Human Un derstanding!David H ume: Introduction, Notes, and Editorial Ar- rangement by Anthony Flew, ed. A. Flew, La Salle, IL: Open Court, pp. 53-195.\nJoreskog, K. G. (1977), “Structural Equation Models in the Social Sciences: Specifi- cation, Estimation and Testing,” in Applications of Statistics, ed. P. R. Krishnaiah, Amsterdam: North Holland, pp. 265-287.\nJudge, G. G., Griffiths, W. E., Hall, R. C., Liitkepohl, H., and Lee, T. C.\n(1985), The Theory and Practice of Econometrics (2nd ed.), New York: John Wi- ley.\nKempthorne, 0. ( 1952), The Design and Analysis ofE xperiments, New York: John Wi- ley.\nKenny, D. A. (1979), Correlation and Causality, New York: John Wiley.\nLeamer, E. E. (1985), “Vector Autoregressions for Causal Inference?” (with discus- sion), in Understanding Monetary Regimes, supplement to Journal ofM onetary Eco- nomics, eds. K. Brunner and A. Meltzer, pp. 255-318.\nLucas, R. E. (1976), “Econometric Policy Evaluation: A Critique” (with discussion), in The Phillips Curve and Labor Markets, supplement to Journal of Monetary Eco- nomics, eds. K. Brunner and A. Meltzer, pp. 19-62.\nMackie, J. L. ( 197 4 ), The Cement of the Universe, Oxford: Oxford University Press.\nMill, J. S. (1843) 1973, A System of Logic: Ratiocinative and Inductive, in The Col- lected Works of John Stuart Mill (Vol. 7), ed. J. M. Robson, Toronto: University of Toronto Press.\nNeyman, J. S. (1923) 1990, “On the Application of Probability Theory to Agri-Cultural Experiments. Essay on Principles. Section 9” (with discussion), Statistical Science, Otte, R. (1981), “A Critique of Suppes’ Theory of Probabilistic Causality,” Synthese, 48, 167-189.\nPearl, J., and Verma, T. S. (1991), “A Theory of Inferred Causation,” in Principles of Know/edge Representation and Reasoning: Proceedings oft he Second International Conference, eds. J. A. Allen, R. Fikes, and E. Sandewall, San Mateo, CA: Morgan Kaufmann, pp. 441-452.\nPratt, J. W., and Schlaifer, R. (1984), “On the Nature and Discovery of Structure” (with discussion), Journal of the American Statistical Association, 79,9-33.\n–(1988), “On the Interpretation and Observation of Laws,” Journal of Economet- rics, 39, 23-52.\nRagin, C. C. (1987), The Comparative Method, Berkeley: University of California Press.\nReichenbach, H. (1956), The Direction of Time, Berkeley: University of California Press.\nRobins, J. M. (1992), “Identifiability and Exchangeability for Direct and Indirect Ef- fects,” Epidemiology, 3, 143-155.\n–( 1994 ), “Correcting for Non-Compliance in Randomized Trials Using Structural Nested Mean Models,” forthcoming in Communications in Statistics, Ser. A.\nRosenbaum, P.R. (1984a), “From Association to Causation in Observational Studies: The Role of Tests of Strongly Ignorable Treatment Asignment,” Journal of the Amer- ican Statistical Association, 79,41-48.\n–( 1984b ), “The Consequences of Adjustment for a Concomitant Variable That Has Been Affected by the Treatment,” Journal of the Royal Statistical Society, Ser. A, 147, 656-666.\n–(1986), “Dropping Out of High School in the United States: An Observational Study,” Journal of Educational Statistics, 11,207-224.\n–(1987), “The Role of a Second Control Group in an Observational Study” (with discussion), Statistical Science, 2, 292-316.\n–(1992), “Detecting Bias with Confidence in Observational Studies,” Biometrika, 79, 367-374.\nRosenbaum, P.R., and Rubin, D. B. ( 1983), “The Central Role of the Propensity Score in 0 bservational Studies for Causal Effects,” Biometrika, 7 0, 41-55.\nRubin, D. B. (1974), “Estimating Causal Effects of Treatments in Randomized and Nonrandomized Studies,” Journal of Educational Psychology, 66, 688-701.\n–(1977), “Assignment to Treatment Groups on the Basis of a Covariate,” Journal of Educational Statistics, 2, 1-26.\n–(1978), “Bayesian Inference for Causal Effects: The Role of Randomization,” The Annals of Statistics, 6, 34-58.\n–(1 980), Comment on “Randomization Analysis of Experimental Data: The Fisher Randomization Test,” by D. Basu, Journal of the American Statistical Association, 75,591-593.\n–(1990), “Formal Modes of Statistical Inference for Causal Effects,” Journal of Statistical Planning and Inference, 25, 279-292.\nRussell, B. (1913), “On the Notion of Cause,” Proceedings of the Aristotelian Society, New Series, 13, 1-26.\nSalmon, W. C. (1984), Scientific Explanation and the Causal Structure of the World, Princeton, NJ: Princeton University Press.\nSimon, H. A. (1952), “On the Definition of the Causal Relation,” Journal ofP hilosophy, 49, 517-528.\n–(1 953), “Causal Ordering and Identifiability,” in Studies in Econometric Methods, eds. W. Hood and T. Koopmans, New York: John Wiley, pp. 49-74.\n–(1954), “Spurious Correlation: A Causal Interpretation,” Journal ofth e American Statistical Association, 49, 467-492.\nSimon, H. A., and Rescher, N. (1966), “Cause and Counterfactual,” Philosophy of Sci- . ence, 33, 323-340.\nSims, C. A. ( 1977), “Exogeneity and Causal Ordering in Macroeconomic Models,” in New Methods in Business Cycle Research: Proceedings from a Conference, ed. C.\nA. Sims, Minneapolis: Federal Reserve Bank of Minneapolis.\n–(1982), “Policy Analysis with Econometric Models,” Brookings Papers onEco- nomic Activity, 1, 107-164.\nSkyrms, B. (1988), “Probability and Causation,” Journal of Econometrics, 39,53-68.\nSmith, H. L. (1990), “Problems of Specification Common to Experimental and Non- experimental Social Research,” inS ociolo gical Methodology, 1990, ed. C. C. Clogg, Oxford: Basil Blackwell, pp. 59-91.\nSobel, M. E. ( 1990), “Effect Analysis and Causation in Linear Structural Equation Models,” Psychometrika, 55,495-515.\n–(1993), “Causation, Spurious Correlation and Recursive Structural Equation Models: A Reexamination,” unpublished manuscript.\n–(1994), “Causal Inference in Latent Variable Models,” forthcoming in Analysis of Latent Variables in Developmental Research, eds. A. von Eye and C. C. Clogg, Newburg Park, CA: Sage.\nSober, E. (1982), “Frequency-Dependent Causation,” Journal of Philosophy, 79, 247- 253.\nSuppes, P. ( 1970), A Probabilistic Theory of Causality, Amsterdam: North Holland.\nvon Wright, G. H. (1971), Explanation and Understanding, Ithaca, N.Y.: Cornell Uni- versity Press.\nWhite, P. ( 1990), “Ideas About Causation in Philosophy and Psychology,” Psychologi- cal Bulletin, 108,3-18.\nWold, H. 0. A. (1966), “On the Definition and Meaning of Causal Concepts,” in La Technique des modeles dans les sciences humaines, ed. H. 0. A. Wold, Monaco: Union Europeenne d ’Editions, pp. 265-275.\nWright, S. (1921), “Correlation and Causation,” Journal of Agricultural Research, 20, 557-585.\nYoung, J. Z. (1978), Programs of the Brain, Oxford: Oxford University Press.\nZellner, A. (1979) 1984, “Causality and Econometrics,” in Basic Issues in Economet- rics, ed. A. Zellner, Chicago: University of Chicago Press, pp. 35-74 .",
    "crumbs": [
      "Causal Inference",
      "Causal Inference in the Social and Behavioral Sciences"
    ]
  },
  {
    "objectID": "documents/spinoza.html",
    "href": "documents/spinoza.html",
    "title": "Treatise on the Emendation of the Intellect",
    "section": "",
    "text": "THE Treatise on the Emendation of the Intellect (TdIE), a short, difficult, but fascinating discourse on method, was first published in Spinoza’s Opera posthuma in 1677. But as the editors of that collection tell us in their preface, both its style and its content show it to be one of Spinoza’s earliest works. If the reference in Letter 6 to a “whole short work” (integrum opusculum) is indeed to this treatise, as scholars have generally assumed,1 then a draft of it must have existed at least by early in 1662, and quite likely Spinoza wrote it before that.2\nVarious forward references in Spinoza’s notes to this treatise indicate that at some stage of his work on it Spinoza conceived it as introductory to another work, to be called (perhaps) Philosophy , a work which would have discussed in a systematic way topics in philosophical theology (II/29, n. z), philosophy of mind (II/15, n. o), epistemology (II/14, nn. k and l), ethics (II/6, n. a; II/7, n. b; II/8, n. c), and perhaps much else (cf. II/9, n. d). Some of the references suggest a work more like the Short Treatise than the Ethics ,3 and Gebhardt argued that the “short work” referred to in Letter 6 was a two-part work, with the TdIE as a methodological prolegomenon to the more systematic KV. According to Gebhardt (I/407), the Latin original of the KV was already in existence when Spinoza began writing the TdIE around the time of Letter 6. But if what I have suggested above is correct (see n. 2), then Gebhardt must be wrong at least about the date of composition of the TdIE. Mignini would argue that Gebhardt is wrong also in thinking that the TdIE was an integral part of the short work Spinoza refers to in Letter 6. Emphasizing the incompleteness of our text of the TdIE, he contends that it could not have been correctly described in Letter 6 as having been composed and that it is earlier than the KV, not merely in date of composition, but also in the stage of the development of Spinoza’s thought that it represents.4 If Mignini’s arguments for the priority of the TdIE are not conclusive, he has, I think, at least established that there is no reason to regard the KV as the earlier work.5 So at this stage the position would seem to be that, if the TdIE is not in fact earlier that the KV, it was probably written at about the same time as the KV and as an introduction to it.\nIn its importance for the study of the development of Spinoza’s thought, the Treatise on the Intellect invites comparison with Descartes’ Regulae. Both are early, unfinished works that show the direction of their author’s thought at a formative stage, that indicate the problems concerning him and the solutions he was inclined toward. Both discuss certain important themes more fully than does any work their author later published. But both works also need to be read with the consciousness that the lines of thought presented in them may not have proved ultimately to be satisfactory to the author.\nFor example, some have argued that in this treatise Spinoza has not fully emancipated himself from Descartes on the distinction between will and intellect,6 and it seems clear that he does tend to confuse mind and intellect.7 I would argue that the discussion of the four kinds of knowledge is not clearly thought out.8 And Joachim has suggested that the whole work may have been intended only to present a popular, imprecise exposition of Spinoza’s thought on these topics.9\nThe most important question, perhaps, is whether the whole concept of method, as Spinoza here presents it, is not incoherent, and so doomed to failure.10 On the one hand, the truth is supposed to require no sign, and having a true idea is supposed to be sufficient to remove doubt (§ 36); on the other, the method is supposed, among other things, to teach us what a true idea is, and how to distinguish it from other perceptions (§ 37).\nBut whatever reservations we may have about the doctrine of this work, it is clear that in the main it continued to satisfy Spinoza for some years. A letter to Bouwmeester in 1666 (Letter 37) repeats some of the Treatise’s main themes—that the intellect, unlike the body, is not subject to chance, external causes, but has the power of forming clear and distinct ideas; that it is necessary above all to distinguish between the intellect and the imagination (this being identified with distinguishing between true ideas and all the rest, the false, fictitious and doubtful). And an interchange with Tschirnhaus in 1675 (Letters 59 and 60) indicates that Spinoza had communicated something similar to him informally, and had given Tschirnhaus some reason to expect that before long he would publish his treatise on method.\nNaturally, then, there have been a variety of suggestions as to why the Treatise never was published in Spinoza’s lifetime. The editors of the Opera posthuma remark that the importance of the topic, the deep contemplations and extensive knowledge it required, made Spinoza’s progress with it very slow. Appuhn suggests that Spinoza broke off the composition because he could not see any satisfactory solution to the problems raised at the end (§§ 102-103, 106-110), and that he did not return to finish it because he came to think it more important to concentrate on his other works on moral and political philosophy (the Ethics , the Theological-Political Treatise , and the Political Treatise). Koyré, on the other hand, tends to emphasize the difficulty raised in § 46 (see the note to II/18/1-2). Ironically, Joachim’s excellent commentary on this work itself remained unfinished at his death because he was unable to resolve to his satisfaction the problem of how Spinoza meant to conclude the Treatise.\nIf the character of this work as unfinished, highly problematic, and only posthumously published invites comparison with Descartes’ Regulae , the apparently autobiographical character of the opening sections equally invites comparison with the Discourse on Method. The tone of the two works is quite different, of course. The dissatisfaction Descartes presents as leading him to philosophy is with the uncertainty of the learning that had been imparted to him as a student. Spinoza’s dissatisfaction is with the insufficiency of the ends men commonly pursue.\nOf course scholars have doubted whether these opening passages should be taken as strictly autobiographical (just as they have doubted the accuracy of Descartes’ account of his life in the Discourse). As Koyré remarks (Koyré 2, xix), the theme de vero bono et de contemptu mundi is as old as the world itself. Various Stoic authors (e.g., Marcus Aurelius and Seneca) have been cited. And Elbogen calls attention to the work of a medieval Jewish author, Shem Tov Falaquera, whose Ha-Mevak-kesh similarly offers knowledge as the path to salvation. However that may be, it remains, as Koyré also remarks, highly significant that Spinoza should begin a treatise on method by reflecting on the true good.\nThe paragraph numbers in brackets are those introduced by Bruder and are included for ease in making and following references. Lettered footnotes are Spinoza’s, numbered footnotes are mine. I have adopted the lettering of Gebhardt’s edition, though (even allowing for differences in the Latin alphabet) it is not entirely consecutive.\n\n\n\nTHIS Treatise on the Emendation of the Intellect etc., which we give you here, kind reader, in its unfinished [NS: and defective] state, was written by the author many years ago now. He always intended to finish it. But hindered by other occupations, and finally snatched away by death, he was unable to bring it to the desired conclusion. But since it contains many excellent and useful things, which—we have no doubt—will be of great benefit to anyone sincerely seeking the truth, we did not wish to deprive you of them. And so that you would be aware of, and find less difficult to excuse, the many things that are still obscure, rough, and unpolished, we wished to warn you of them. Farewell.\n\n\n\n[1] AFTER experience had taught me that all the things which regularly occur in ordinary life are empty and futile, and I saw that all the [10] things which were the cause or object of my fear had nothing of good or bad in themselves, except insofar as [my] mind was moved by them, I resolved at last to try to find out whether there was anything which would be the true good, capable of communicating itself, and which alone would affect the mind, all others being rejected—whether there [15] was something which, once found and acquired, would continuously give me the greatest joy, to eternity.\n[2] I say that I resolved at last —for at first glance it seemed ill-advised to be willing to lose something certain for something then uncertain. I saw, of course, the advantages that honor and wealth bring, and that I would be forced to abstain from seeking them, if I wished to devote [20] myself seriously to something new and different; and if by chance the greatest happiness lay in them, I saw that I should have to do without it. But if it did not lie in them, and I devoted my energies only to acquiring them, then I would equally go without it.\n[3] So I wondered whether perhaps it would be possible to reach my new goal—or at least the certainty of attaining it—without changing [25] the conduct and plan of life which I shared with other men. Often I tried this, but in vain. For most things which present themselves in life, and which, to judge from their actions, men think to be the highest [II/6] good, may be reduced to these three: wealth, honor, and sensual pleasure.3 The mind is so distracted by these three that it cannot give the slightest thought to any other good.\n[4] For as far as sensual pleasure is concerned, the mind is so caught up in it, as if at peace in a [true] good, that it is quite prevented from thinking of anything else. But after the enjoyment of sensual pleasure [5] is past, the greatest sadness follows. If this does not completely engross, still it thoroughly confuses and dulls the mind.\nThe mind is also distracted not a little by the pursuit of honors and wealth, particularly when the lattera is sought only for its own sake, because it is assumed to be the highest good. [5] But the mind is far [10] more distracted by honor. For this is always assumed to be good through itself and the ultimate end toward which everything is directed.\nNor do honor and wealth have, as sensual pleasure does, repentance as a natural consequence. The more each of these is possessed, the more joy is increased, and hence the more we are spurred on to increase [15] them. But if our hopes should chance to be frustrated, we experience the greatest sadness. And finally, honor has this great disadvantage: to pursue it, we must direct our lives according to other men’s powers of understanding—fleeing what they commonly flee and [20] seeking what they commonly seek.\n[6] Since I saw that all of these things stood in the way of my working toward this new goal, indeed were so opposed to it that one or the other must be given up, I was forced to ask what would be more useful to me. For as I say, I seemed to be willing to lose the [25] certain good for the uncertain one. But after I had considered the matter a little, I first found that, if I devoted myself to this new plan of life, and gave up the old, I would be giving up a good by its nature uncertain (as we can clearly infer from what has been said) for one uncertain not by its nature (for I was seeking a permanent good) but only in respect to its attainment.\n[30] [7] By persistent meditation, however, I came to the conclusion that, if only I could resolve, wholeheartedly,4 [to change my plan of life], I would be giving up certain evils for a certain good. For I saw that I [II/7] was in the greatest danger, and that I was forced to seek a remedy with all my strength, however uncertain it might be—like a man suffering from a fatal illness, who, foreseeing certain death unless he employs a remedy, is forced to seek it, however uncertain, with all [5] his strength. For all his hope lies there. But all those things men ordinarily strive for, not only provide no remedy to preserve our being, but in fact hinder that preservation, often cause the destruction of those who possess them,b and always cause the destruction of those who are possessed by them.5\n[10] [8] There are a great many examples of people who have suffered persecution to the death on account of their wealth, or have exposed themselves to so many dangers to acquire wealth that they have at last paid the penalty for their folly with their life. Nor are there fewer examples of people who, to attain or defend honor, have suffered most [15] miserably. And there are innumerable examples of people who have hastened their death through too much sensual pleasure.\n[9] Furthermore, these evils seemed to have arisen from the fact that all happiness or unhappiness was placed in the quality of the object to which we cling with love. For strife will never arise on account of [20] what is not loved, nor will there be sadness if it perishes, nor envy if it is possessed by another, nor fear, nor hatred—in a word, no disturbances of the mind. Indeed, all these happen only in the love of those things that can perish, as all the things we have just spoken of can do.\n[10] But love toward the eternal and infinite thing feeds the mind [25] with a joy entirely exempt from sadness.6 This is greatly to be desired, and to be sought with all our strength.\nBut not without reason did I use these words if only I could resolve in earnest.7 For though I perceived these things [NS: this evil] so clearly in my mind, I still could not, on that account, put aside all greed, [30] desire for sensual pleasure and love of esteem.\n[11] I saw this, however: that so long as the mind was turned toward these thoughts, it was turned away from those things, and was thinking seriously about the new goal. That was a great comfort to me. For I saw that those evils would not refuse to yield to remedies. And [II/8] although in the beginning these intervals were rare, and lasted a very short time, nevertheless, after the true good became more and more known to me, the intervals became more frequent and longer—especially after I saw that the acquisition of money, sensual pleasure, and [5] esteem are only obstacles so long as they are sought for their own sakes, and not as means to other things. But if they are sought as means, then they will have a limit, and will not be obstacles at all. On the contrary, they will be of great use in attaining the end on account of which they are sought, as we shall show in its place.\n[10] [12] Here I shall only say briefly what I understand by the true good, and at the same time, what the highest good is. To understand this properly, it must be noted that good and bad are said of things only in a certain respect, so that one and the same thing can be called both good and bad according to different respects. The same applies [15] to perfect and imperfect. For nothing, considered in its own nature, will be called perfect or imperfect, especially after we have recognized that everything that happens happens according to the eternal order, and according to certain laws of Nature.\n[13] But since human weakness does not grasp that order by its own thought, and meanwhile man conceives a human nature much stronger [20] and more enduring8 than his own, and at the same time sees that nothing prevents his acquiring such a nature, he is spurred to seek means that will lead him to such a perfection. Whatever can be a means to his attaining it is called a true good; but the highest good is to arrive—together with other individuals if possible—at the enjoyment [25] of such a nature. What that nature is we shall show in its proper place: that it is the knowledgec of the union that the mind has with the whole of Nature.9\n[14] This, then, is the end I aim at: to acquire such a nature, and to strive that many acquire it with me. That is, it is part of my happiness [30] to take pains that many others may understand as I understand, so that their intellect and desire agree entirely with my intellect and desire. To do this it is necessary,d first to understand as much of Nature [II/9] as suffices for acquiring such a nature; next , to form a society of the kind that is desirable, so that as many as possible may attain it as easily and surely as possible.\n[15] Third , attention must be paid to Moral Philosophy and to Instruction [5] concerning the Education of children. Because Health is no small means to achieving this end, fourthly , the whole of Medicine must be worked out. And because many difficult things are rendered easy by ingenuity, and we can gain much time and convenience in this life, fifthly , Mechanics is in no way to be despised.\n[10] [16] But before anything else we must devise a way of healing the intellect, and purifying it, as much as we can in the beginning, so that it understands things successfully, without error and as well as possible.10 Everyone will now be able to see that I wish to direct all the sciences toward one ende and goal, viz. that we should achieve, as we [15] have said, the highest human perfection. So anything in the sciences which does nothing to advance us toward our goal must be rejected as useless—in a word, all our activities and thoughts are to be directed to this end.\n[17] But while we pursue this end, and devote ourselves to bringing [20] the intellect back11 to the right path, it is necessary to live. So we are forced, before we do anything else, to assume certain rules of living as good:\n1. To speak according to the power of understanding of ordinary people, and do whatever does not interfere with our attaining our [25] purpose. For we can gain a considerable advantage, if we yield as much to their understanding as we can. In this way, they will give a favorable hearing to the truth.\n2. To enjoy pleasures just so far as suffices for safeguarding our health.\n[30] 3. Finally, to seek money, or anything else, just so far as suffices for sustaining life and health, and conforming to those customs of the community that do not conflict with our aim.\n[18] Having laid down these rules, I come now to what must be [35] done first, before all else: emending12 the intellect and rendering it [II/10] capable of understanding things in the way the attainment of our end requires. To do this, the order we naturally have requires me to survey here all the modes of perceiving which I have had up to now for affirming or denying something without doubt, so that I may choose [5] the best of all, and at the same time begin to know my powers and the nature that I desire to perfect.\n[19] If I consider them accurately, I can reduce them all to four13 main kinds:\n1. There is the Perception we have from report or from some [10] conventional sign.14\n2. There is the Perception we have from random experience,15 that is, from experience that is not determined by the intellect. But it has this name only because it comes to us by chance, and we have no other experiment that opposes it. So it remains with [15] us unshaken.\n3. There is the Perception that we have when the essence of a thing is inferred from another thing, but not adequately. This happens, either fwhen we infer the cause from some effect, or when something is inferred from some universal, which some property always accompanies.17\n[20] 4. Finally, there is the Perception we have when a thing is perceived through its essence alone, or through knowledge of its proximate cause.\n[20] I shall illustrate all of these with examples. I know only from report my date of birth, and who my parents were, and similar things, which I have never doubted. By random experience I know that I [25] shall die, for I affirm this because I have seen others like me die, even though they had not all lived the same length of time and did not all die of the same illness. Again, I also know by random experience that [II/11] oil is capable of feeding fire, and that water is capable of putting it out. I know also that the dog is a barking animal, and man a rational one. And in this way I know almost all the things that are useful in life.\n[21] But we infer [one thing][18](part0013.html#ch1fn36) from another in this way: after we [5] clearly perceive that we feel such a body, and no other, then, I say, we infer clearly that the soul is unitedg to the body, which union is the cause of such a sensation; but we cannot understand absolutely from this whath that sensation and union are. Or after we have come to know the nature of vision, and that it has the property that we see [10] one and the same thing as smaller when we look at it from a great distance than when we look at it from close up, we infer that the sun is larger than it appears to be, and other things of the same kind.20\n[22] Finally, a thing is perceived through its essence alone when, from the fact that I know something, I know what it is to know something, [15] or from the fact that I know the essence of the soul, I know that it is united to the body. By the same kind of knowledge, we know that two and three are five, and that if two lines are parallel to a third line, they are also parallel to each other, etc. But the things I have so far been able to know by this kind of knowledge have been very few.\n[20] [23] That you may understand all these things better, I shall use only one example. Suppose there are three numbers. Someone is seeking a fourth, which is to the third as the second is to the first. Here merchants will usually say that they know what to do to find the fourth number, because they have not yet forgotten that procedure [25] which they simply heard from their teachers, without any demonstration.\n[II/12] Others will construct a universal axiom from an experience with simple numbers, where the fourth number is evident through itself—as in the numbers 2, 4, 3, and 6. Here they find by trial that if the second is multiplied by the third, and the product then divided by the first, the result is 6. Since they see that this produces the same number [5] which they knew to be the proportional number without this procedure, they infer that the procedure is always a good way to find the fourth number in the proportion.\n[24] But Mathematicians know, by the force of the demonstration of Proposition 19 in Book VII of Euclid, which 21 numbers are proportional to one another, from the nature of proportion, and its property, [10] viz. that the product of the first and fourth numbers is equal to the product of the second and third. Nevertheless, they do not see the adequate proportionality of the given numbers. And if they do, they see it not by the force of that Proposition, but intuitively, [NS: or] without going through any procedure.\n[25] To choose the best mode of perceiving from these, we are required [15] to enumerate briefly the means necessary to attain our end:\n1.22 To know exactly our nature, which we desire to perfect, and at the same time,\n2. [To know] as much of the nature of things as is necessary,\n\nto infer rightly from it the differences, agreements and [20] oppositions of things,\nto conceive rightly what they can undergo and what they cannot,\nto compare [the nature of things] with the nature and power of man.\n\nThis done, the highest perfection man can reach will easily manifest itself.\n[25] [26] Having considered these requirements, let us see which mode of perceiving we ought to choose.\nAs for the first, it is evident in itself that from report—apart from the fact that it is a very uncertain thing—we do not perceive any essence of a thing, as is clear from our example. And since the existence [30] of any singular thing23 is not known unless its essence is known (as we shall see afterwards), we can clearly infer from this that all the certainty we have from report is to be excluded from the sciences. For no one will ever be able to be affected by simple report, unless his own intellect has gone before.\n[II/13] [27] As for the second,i again, no one should be said to have the idea of that24 proportion which he is seeking. Apart from the fact that it is a very uncertain thing, and without end, in this way no one will ever perceive anything in natural things except accidents. But these [5] are never understood clearly unless their essences are known first. So that also is to be excluded.\n[28] Concerning the third, on the other hand, we can, in a sense, say that we have an idea of the thing, and that we can also make inferences without danger of error. But still, it will not through itself [10] be the means of our reaching our perfection.\n[29] Only the fourth mode comprehends the adequate essence of the thing and is without danger of error. For that reason, it is what we must chiefly use. So we shall take care to explain how it is to be used, that we may understand unknown things by this kind of knowledge [15] and do so as directly as possible; [30] [NS: i.e.] after we know what Knowledge is necessary for us, we must teach the Way and Method by which we may achieve this kind of knowledge of the things that are to be known.\nTo do this, the first thing we must consider is that there is no infinite regress here. That is, to find the best Method of seeking the [20] truth, there is no need of another Method to seek the Method of seeking the truth, or of a third Method to seek the second, and so on, to infinity. For in that way we would never arrive at knowledge of the truth, or indeed at any knowledge.\nMatters here stand as they do with corporeal tools,25 where someone [25] might argue in the same way. For to forge iron a hammer is needed; and to have a hammer, it must be made; for this another hammer, and other tools are needed; and to have these tools too, other tools will be needed, and so on to infinity; in this way someone might try, in vain, to prove that men have no power of forging iron.\n[30] [31] But just as men, in the beginning, were able to make the easiest things with the tools they were born with (however laboriously and imperfectly), and once these had been made, made other, more difficult things with less labor and more perfectly, and so, proceeding [II/14] gradually from the simplest works to tools, and from tools to other works and tools, reached the point where they accomplished so many and so difficult things with little labor, in the same way the intellect, by its inborn power,k makes intellectual tools for itself, by which it [5] acquires other powers for other intellectual works,l and from these works still other tools, or the power of searching further, and so proceeds by stages, until it reaches the pinnacle of wisdom.\n[32] It will be easy to see that this is the situation of the intellect, provided we understand what the Method of seeking the truth is, and [10] what those inborn tools are, which it requires only26 to make other tools from them, so as to advance further. To show this, I proceed as follows.\n[33] A27 true ideam (for we have a true idea) is something different from its object. For a circle is one thing and an idea of the circle [15] another—the idea of the circle is not something which has a circumference and a center, as the circle does. Nor is an idea of the body the body itself. And since it is something different from its object, it will also be something intelligible through itself; that is, the idea, as far as its formal essence is concerned, can be the object of another objective essence, and this other objective essence in turn will also be, considered [20] in itself, something real and intelligible, and so on, indefinitely.\n[34] Peter, for example, is something real; but a true idea of Peter28 is an objective essence of Peter, and something real in itself, and altogether different from Peter himself. So since an idea of Peter is something real, having its own particular essence, it will also be something intelligible, i.e., the object of a second idea, which will have in [25] itself, objectively, whatever the idea of Peter has formally; and in turn, the idea which is [the idea] of the idea of Peter has again its essence, which can also be the object of another idea, and so on indefinitely. Everyone can experience this, when he sees that he knows what Peter is, and also knows that he knows, and again, knows that he knows that he knows, etc.\n[30] From this it is evident that to understand the essence of Peter, it is [II/15] not necessary to understand an idea of Peter, much less an idea of an idea of Peter. This is the same as if I said that, in order for me to know, it is not necessary to know that I know, much less necessary to know that I know that I know—no more than it is necessary to understand the essence of a circle in order to understand the essence [5] of a triangle.n Indeed, in these ideas the opposite is the case. For to know that I know, I must first know.\n[35] From this it is clear that certainty is nothing but the objective essence itself, i.e., the mode by which we are aware of the formal essence29 is certainty itself. And from this, again, it is clear that, for [10] the certainty of the truth, no other sign is needed than having a true idea. For as we have shown, in order for me to know, it is not necessary to know that I know. From which, once more, it is clear that no one can know what the highest certainty is unless he has an adequate idea or objective essence of some thing. For certainty and an objective essence are the same thing.\n[15] [36] Since truth, therefore, requires no sign, but it suffices, in order to remove all doubt, to have the objective essences of things, or, what is the same, ideas, it follows that the true Method is not to seek a sign of truth after the acquisition of ideas, but the true Method is the way [20] that truth itself, or the objective essences of things, or the ideas (all those signify the same) should be soughto in the proper order.\n[37] Again, the Method must speak about Reasoning, or30 about the intellection; i.e., Method is not the reasoning itself by which we understand the causes of things, much less the understanding of the causes of things; it is understanding what a true idea is by distinguishing it [25] from the rest of the perceptions; by investigating its nature, so that from that we may come to know our power of understanding and so restrain the mind that it understands, according to that standard, everything that is to be understood; and finally by teaching and constructing certain rules as aids, so that the mind does not weary itself in useless things.\n[30] [38] From this it may be inferred that Method is nothing but a [II/16] reflexive knowledge, or an idea of an idea; and because there is no idea of an idea, unless there is first an idea, there will be no Method unless there is first an idea. So that Method will be good which shows how the mind is to be directed according the standard of a given true idea.31\n[5] Next, since the relation between the two ideas is the same as the relation between the formal essences of those ideas, it follows that the reflexive knowledge of the idea of the most perfect Being will be more excellent than the reflexive knowledge of any other ideas. That is, the most perfect Method will be the one that shows how the mind is to be directed according to the standard of the given idea of the most [10] perfect Being.\n[39] From this you will easily understand how the mind, as it understands more things, at the same time acquires other tools, with which it proceeds to understand more easily. For, as may be inferred from what has been said, before all else there must be a true idea in us, as an inborn tool; once this true idea is understood, we understand [15] the difference between that kind of perception and all the rest. Understanding that difference constitutes one part of the Method.\nAnd since it is clear through itself that the mind understands itself the better, the more it understands of Nature, it is evident, from that that this part of the Method will be more perfect as the mind understands more things, and will be most perfect when the mind attends [20] to, or reflects on, knowledge of the most perfect Being.\n[40] Next, the more the mind knows, the better it understands its own powers and the order of Nature. The better the mind understands its own powers, the more easily it can direct itself and propose rules to itself; the better it understands the order of Nature, the more easily it can restrain itself from useless pursuits. In these things, as [25] we have said, the whole of the Method consists.\n[41] Moreover, the idea is objectively in the same way as its object is really. So if there were something in Nature that did not interact with other things, and if there were an objective essence of that thing which would have to agree completely with its formal essence, then [30] that objective essence would not interactp with other ideas, i.e., we could not infer anything about it.32 And conversely, those things that do interact with other things (as everything that exists in Nature does) will be understood, and their objective essences will also have the same interaction, i.e., other ideas will be deduced from them, and [II/17] these again will interact with other ideas, and so the tools for proceeding further will increase, which is what we were trying to demonstrate.\n[42] Next, from what we have just said, that an idea must agree completely with its formal essence, it is again evident that for our mind [5] to reproduce completely the likeness of Nature,33 it must bring all of its ideas forth from that idea which represents the source and origin of the whole of Nature, so that that idea is also the source of the other ideas.\n[43] Here, perhaps, someone will be surprised that, having said that a good Method is one which shows how the mind is to be directed [10] according to the standard of a given true idea, we should prove this by reasoning. For that seems to show that this is not known through itself. So it may be asked whether our reasoning is good? If our reasoning is good, we must begin from a given [true?] idea; and since to begin from a given [true?] idea requires a demonstration, we must again prove our reasoning, and then once more prove that other reasoning, [15] and so on to infinity.\n[44] To this I reply that if, by some fate, someone had proceeded in this way in investigating Nature, i.e., by acquiring other ideas in the proper order, according to the standard of the given true idea, he would never have doubtedq the truth he possessed (for as we have shown, the truth makes itself manifest) and also everything would have flowed to him of its own accord.34\n[20] But because this never or rarely happens, I have been forced to lay things down in this way, so that what we cannot acquire by fate, we may still acquire by a deliberate plan, and at the same time so that it would be evident that to prove the truth and good reasoning, we require no tools except the truth itself and good reasoning. For I have [25] proved, and still strive to prove, good reasoning by good reasoning. [45] Moreover, in this way men become accustomed to their own internal meditations.\nBut the reason why Nature is rarely investigated in the proper order, is, first, that men have prejudices whose causes we shall explain afterwards in our Philosophy. And then, the task requires a considerable [30] capacity for making accurate distinctions (as we shall show later) and much effort. Finally, there is the condition of human affairs, which are quite changeable, as we have already shown. There are still other reasons, which we shall not go into.\n[II/18] [46] If, by chance, someone should ask why I did [not][35](part0013.html#ch1fn62) immediately, before anything else, display the truths of Nature in that order—for does not the truth make itself manifest?—I reply to him […] and at the same time I warn him not to try to reject these things as false because of Paradoxes that occur here and there; he should first [5] deign to consider the order in which we prove them, and then he will become certain that we have reached the truth; and this was the reason why I have put these things first.\n[47] But perhaps, afterwards, some Skeptic would still doubt both the first truth itself and everything we shall deduce according to the [10] standard of the first truth. If so, then either he will speak contrary to his own conciousness, or we shall confess that there are men whose minds also are completely blinded, either from birth, or from prejudices, i.e., because of some external chance. For they are not even aware of themselves. If they affirm or doubt something, they do not know that they affirm or doubt. They say that they know nothing, [15] and that they do not even know that they know nothing. And even this they do not say absolutely. For they are afraid to confess that they exist, so long as they know nothing. In the end, they must be speechless, lest by chance they assume something that might smell of truth.\n[48] Finally, there is no speaking of the sciences with them. (For as far as the needs of life and society are concerned, necessity forces them [20] to suppose that they exist, and to seek their own advantage, and in taking oaths, to affirm and deny many things.) For, if someone proves something to them, they do not know whether the argument is a proof or not. If they deny, grant, or oppose, they do not know that they deny, grant, or oppose. So they must be regarded as automata, completely [25] lacking a mind.\n[49] Let us now return to our subject. First [§§ 1-17], we have treated the end toward which we strive to direct all our thoughts; second [§§ 18-29], we learned which is the best perception, by whose aid we can reach our perfection; third [§§ 30-48], we learned which is the first [30] path our mind must enter on to begin well—which is to proceed in its investigation according to certain laws, taking as a standard a given true idea.\nIf this is to be done properly, the Method must, first [§§ 50-90], show how to distinguish a true idea from all other perceptions, and to restrain the mind from those other perceptions; second [§§ 91-98], [35] teach rules so that we may perceive things unknown according to such [II/19] a standard; third [§ 99-?], establish an order, so that we do not become weary with trifles. When we came to know this Method [§ 38], we saw, fourth, that it will be most perfect when we have the idea of the most perfect Being. So in the beginning we must take the greatest care [5] that we arrive at knowledge of such a Being as quickly as possible.\n[50] Let us begin, therefore, from the first part of the Method, which is, as we have said, to distinguish and separate true ideas from all other perceptions, and to restrain the mind from confusing false, fictitious, and doubtful ideas with true ones. It is my intention to explain this fully here, so as to engage my Readers in the thought of a thing so [10] necessary, and also because there are many who doubt even true ideas, from not attending to the distinction between a true perception and all others. So they are like men who, when they were awake, used not to doubt that they were awake, but who, after they once thought in a dream that they were certainly awake (as often happens), and later [15] found that to be false, doubted even of their waking states. This happens because they have never distinguished between the dream36 and the waking state.\n[51] In the meantime, I warn the reader that I shall not discuss the essence of each perception, and explain it by its proximate37 cause, because that pertains to Philosophy, but shall discuss only what the [20] Method demands, i.e., what false, fictitious and doubtful ideas are concerned with, and how we shall be freed from each of them. Let the first inquiry, therefore, be about the fictitious idea.\n[52] Since every perception is either of a thing considered as existing, or of an essence alone, and since fictions occur more frequently [25] concerning things considered as existing, I shall speak first of them—i.e., where existence alone is feigned, and the thing which is feigned in such an act is understood, or assumed to be understood. E.g., I feign that Peter, whom I know, is going home, that he is coming to visit me, and the like.r Here I ask, what does such an idea concern? I [30] see that it concerns only possible, and not necessary or impossible things.\n[53] I call a thing impossible whose nature38 implies that it would be contradictory for it to exist; necessary whose nature implies that it [II/20] would be contradictory for it not to exist; and possible whose existence,39 by its very nature, does not imply a contradiction—either for it to exist or for it not to exist—but whose necessity or impossibility of existence depends on causes unknown to us, so long as we feign its [5] existence. So if its necessity or impossibility, which depends on external causes, were known to us, we would have been able to feign nothing concerning it.\n[54] From this it follows that, if there is a God, or something omniscient, he can feign nothing at all.40 For as far as We are concerned, after I know that I exist,s I cannot feign either that I exist or that I do [10] not exist; nor can I feign an elephant which passes through the eye of a needle; nor, after I know the nature of God, can I feign either that he exists or that he does not exist.t The same must be understood of the Chimera, whose nature implies that it would be contradictory for it to exist. From this what I have said is evident: that the fiction of which we are speaking here does not occur concerning eternal truths.u [15] I shall also show immediately that no fiction is concerned with eternal truths.\n[55] But before proceeding further, I must note here in passing that the same difference that exists between the essence of one thing and the essence of another also exists between the actuality or existence of [20] the one thing and the actuality or existence of the other. So if we wished to conceive the existence of Adam, for example, through existence in general, it would be the same as if, to conceive his essence, we attended to the nature of being, so that in the end we defined him by saying that Adam is a being. Therefore, the more generally existence [25] is conceived, the more confusedly also it is conceived, and the more easily it can be ascribed fictitiously to anything. Conversely, the more particularly it is conceived, then the more clearly it is understood, and the more difficult it is for us, [even] when we do not attend [II/21] to the order of Nature, to ascribe it fictitiously to anything other than the thing itself.41 This is worth noting.\n[56] Now we must consider those things that are commonly said to be feigned, although we understood clearly that the thing is not really [5] as we feign it. E.g., although I know that the earth is round, nothing prevents me from saying to someone that the earth is a hemisphere and like half an orange on a plate, or that the sun moves around the earth, and the like. If we attend to these things, we shall see nothing that is not compatible with what we have already said, provided we [10] note first that we have sometimes been able to err, and now are conscious of our errors; and then, we can feign, or at least allow, that other men are in the same error, or can fall into it, as we did previously.\nWe can feign this, I say, so long as we see no impossibility and no [15] necessity. Therefore, when I say to someone that the earth is not round, etc., I am doing nothing but recalling the error which I, perhaps, made, or into which I could have fallen, and afterwards feigning, or allowing, that he to whom I say this is still in the same error, or can fall into it. As I have said, I feign this so long as I see no [20] impossibility and no necessity. For if I had understood this, I could have feigned nothing at all, and it would have had to be said only that I had done something.42\n[57] It remains now to note also those things that are supposed in Problems. This sometimes happens even concerning impossible things. E.g., when we say “Let us suppose that this burning candle is not [25] now burning, or let us suppose that it is burning in some imaginary space, or where there are no bodies.” Things like this are sometimes supposed, although this last is clearly understood to be impossible.43 But when this happens, nothing at all is feigned. For in the first case [II/22] I have done nothing but recall to memoryx another candle that was not burning (or I have conceived this candle without the flame), and what I think about that candle, I understand concerning this one, so long as I do not attend to the flame.\nIn the second case, nothing is done except to abstract the thoughts [5] from the surrounding bodies so that the mind directs itself toward the sole contemplation of the candle, considered in itself alone, so that afterwards it infers that the candle has no cause for its destruction. So if there were no surrounding bodies, this candle, and its flame, would remain immutable, or the like. Here, then, there is no fiction, buty [10] true and sheer assertions.44\n[58] Let us pass now to fictions that concern either essences alone or essences together with some actuality or existence. The most important consideration regarding them is that the less the mind understands and the more things it perceives, the greater its power of feigning [15] is; and the more things it understands, the more that power is diminished.\nFor example, as we have seen above, we cannot feign, so long as we are thinking, that we are thinking and are not thinking; in the same way, after we know the nature of body, we cannot feign an infinite [20] fly, or after we know the nature of the soul,z we cannot feign that it is square, though there is nothing that cannot be put into words.\nBut as we have said, the less men know Nature, the more easily they can feign many things, such as, that trees speak, that men are changed in a moment into stones and into springs, that nothing becomes something, that even Gods are changed into beasts and into [25] men, and infinitely many other things of that kind.45\n[II/23] [59] Someone, perhaps, will think that fiction is limited by fiction, but not by intellection.46 That is, after I have feigned something, and willed by a certain freedom to assent that it exists in nature in this way, this has the consequence that I cannot afterwards think it in any [5] other way. For example, after I have feigned (to speak as they do) that body has such a nature, and willed, from my freedom, to be convinced that it really exists in this way, I can no longer feign an infinite fly; and after I have feigned the essence of the soul, I can no longer feign that it is square.\n[60] But this needs to be examined. First, either they deny or they grant that we can understand something. If they grant it, then necessarily [10] what they say about fiction will also have to be said about intellection. But if they deny it, let us—who know that we know something—see what they say.\nEvidently, they say that the soul can sense and perceive in many ways, not itself, nor the things that exist, but only those things that [15] are neither in itself nor anywhere; that is, the soul can, by its own force alone, create sensations or ideas, which are not of things; so they consider it, to some extent, as like God.47\nNext, they say that we, or our soul, has such a freedom that it compels us, or itself, indeed its own freedom. For after it has feigned something, and offered its assent to it, it cannot think or feign it in any other way, and is also compelled by that fiction so that even other [20] things are thought in such a way as not to conflict with the first fiction, just as here too because of their own fiction, they are forced to admit the absurdities which I review here, and which we shall not bother to refute with any demonstrations.\n[25] [61] Rather, leaving them to their madness, we shall take care to draw from the words we have exchanged with them something true and to our purpose, viz.:a when the mind attends to a fictitious thing which is false by its very nature, so that it considers it carefully, and understands it, and deduces from it in good order the things to be deduced, it will easily bring its falsity to light. And if the fictitious [II/24] thing is true by its nature, then when the mind attends to it, so that it understands it, and begins to deduce from it in good order the things that follow from it, it will proceed successfully, without any interruption—just as we have seen that, from the false fiction just mentioned, the intellect immediately applies itself to show its absurdity, and the [5] other things deduced from that.\n[62] So we ought not to fear in any way that we are [merely] feigning something, if only we perceive the thing clearly and distinctly. For if by chance we should say that men are changed in a moment into beasts, that is said very generally, so that there is in the mind no concept, i.e., [10] idea, or connection of subject and predicate. For if there were any concept, the mind would see together the means and causes, how and why such a thing was done. And one does not attend to the nature of the subject and of the predicate.\n[63] Next, provided the first idea is not fictitious, and all the other ideas are deduced from it, the haste to feign things will gradually [15] disappear. And since a fictitious idea cannot be clear and distinct, but only confused, and since all confusion results from the fact that the mind knows only in part a thing that is a whole, or composed of many things, and does not distinguish the known from the unknown (and besides, attends at once, without making any distinction, to the many [20] things that are contained in each thing), from this it follows, first, that if an idea is of some most simple thing, it can only be clear and distinct. For that thing will have to become known, not in part, but either as a whole or not at all.48\n[64] Secondly, it follows that if, in thought, we divide a thing that is composed of many things into all its most simple parts, and attend [25] to each of these separately, all confusion will disappear.\nThirdly, it follows that a fiction cannot be simple, but that it is made from the composition of different confused ideas, which are different things and actions existing in nature; or rather, from attending at once,b without assent, to such different ideas. For if it were simple, [30] it would be clear and distinct, and consequently true. And if it were made from the composition of distinct ideas, their composition would [II/25] also be clear and distinct, and therefore true. For example, once we know the nature of the circle, and also the nature of the square, we cannot then compound these two and make a square circle, or a square soul, and the like.\n[5] [65] Let us sum up again briefly, and see why we do not need to fear that the fiction will in any way be confused with true ideas. For as for the first [fiction][49](part0013.html#ch1fn85) of which we spoke before, viz. where the thing is clearly conceived, we saw that if that thing that is clearly conceived (and also its existence) is, through itself, an eternal truth, we [10] can feign nothing concerning such a thing. But if the existence of the thing conceived is not an eternal truth, we need only to take care to compare the existence of the thing with its essence, and at the same time attend to the order of Nature.\nAs for the second fiction, we said that it consists in attending at once, without assent, to different confused ideas, which are of different [15] things and actions existing in Nature. We saw also that a most simple thing cannot be feigned, but [only] understood, and also that a composite thing can be understood, provided that we attend to the most simple parts of which it is composed. Indeed we also cannot feign from them any actions that are not true; for at the same time we will be forced to consider how and why such a thing happened.\n[20] [66] With these matters thus understood, let us pass now to the investigation of the false idea so that we may see what it is concerned with, and how we can take care not to fall into false perceptions. Neither of these will be difficult for us now, after our investigation of the fictitious idea. For between fictitious and false ideas there is no [25] other difference except that the latter suppose assent; i.e. (as we have already noted), while the presentations appear to him [who has the false idea], there appear no causes from which he can infer (as he who is feigning can) that they do not arise from things outside him. And this is hardly anything but dreaming with open eyes, or while we are awake. Therefore the false idea is concerned with, or (to put it better) [30] is related to the existence of a thing whose essence is known, or to an essence, in the same way as a fictitious idea.\n[67] [The false idea] that is related to existence is emended in the same way as the fiction. For if the nature of the thing known presupposes necessary existence, it is impossible for us to be deceived concerning the existence of that thing. But if the existence of the thing is not an eternal truth (as its essence is), so that50 its necessity or impossibility [35] of existing depends on external causes, then take everything in [II/26] the same way as we said when we were speaking of fictions. For it may be emended in the same way.\n[68] As for the other kind of false idea, which is related to essences, or also to actions, such perceptions must always be confused, composed [5] of different confused perceptions of things existing in nature—as when men are persuaded that there are divinities in the woods, in images, in animals, etc.; or that there are bodies from whose composition alone the intellect is made; or that corpses reason, walk, and speak; or that God is deceived, and the like. But ideas that are clear [10] and distinct can never be false. For the ideas of things that are conceived clearly and distinctly, are either most simple, or composed of most simple ideas, i.e., deduced from most simple ideas. But that a most simple idea cannot be false, anyone can see—provided that he knows what the true is, or the intellect, and at the same time, what the false is.\n[15] [69] As for what constitutes the form of the true, it is certain that a true thought is distinguished from a false one not only by an extrinsic, but chiefly by an intrinsic denomination. For if some architect conceives a building in an orderly fashion, then although such a building never existed, and even never will exist, still the thought of it is true, [20] and the thought is the same, whether the building exists or not.51 On the other hand, if someone says, for example, that Peter exists, and nevertheless does not know that Peter exists, that thought, in respect to him is false, or, if you prefer, is not true, even though Peter really exists. Nor is this statement, Peter exists, true, except in respect to [25] him who knows certainly that Peter exists.\n[70] From this it follows that there is something real in ideas, through which the true are distinguished from the false. This will now have to be investigated, so that we may have the best standard of truth (for we have said that we must determine our thoughts from the given standard of a true idea, and that method is reflexive knowledge), and [30] may know the properties of the intellect. Nor must we say that this difference arises from the fact that the true thought is knowing things through their first causes.52 In this, indeed, it differs greatly from the false, as I have explained it above. For that Thought is also called true which involves objectively the essence of some principle that does not have a cause, and is known through itself and in itself.\n[35] [71] So the form of the true thought53 must be placed in the same [II/27] thought itself without relation to other things, nor does it recognize the object as its cause, but must depend on the very power and nature of the intellect. For if we should suppose that the intellect had perceived some new being, which has never existed (as some conceive [5] God’s intellect, before he created things—for that perception, of course, could not have arisen from any object), and that from such a perception it deduced others legitimately, all those thoughts would be true, and determined by no external object, but would depend only on the power and nature of the intellect. So what constitutes the form of the [10] true thought must be sought in the same thought itself, and must be deduced from the nature of the intellect.\n[72] To investigate this, therefore, let us consider some true idea, of which we know most certainly that its object depends on our power of thinking, and that it has no object in nature. For it is clear from what has already been said that we shall be able more easily to investigate [15] what we wish to in such an idea. E.g., to form the concept of a sphere, I feign a cause at will, say that a semicircle is rotated around a center, and that the sphere is, as it were, produced by this rotation. This idea, of course, is true, and even though we may know that no sphere in nature was ever produced in this way, nevertheless, this perception is true, and a very easy way of forming the concept of a sphere.\n[20] Now it must be noted that this perception affirms that the semicircle is rotated, which affirmation would be false if it were not joined to the concept of a sphere, or to a cause determining such a motion, or absolutely, if this affirmation were isolated. For then the mind would only tend to affirm of the semicircle nothing but motion, which neither is contained in the concept of the semicircle nor arises from the [25] concept of the cause determining the motion. So falsity consists only in this: that something is affirmed of a thing that is not contained in the concept we have formed of the thing, as motion or rest of the semicircle.\nFrom this it follows that simple thoughts cannot but be true; for example, the simple idea of a semicircle, or of motion, or of quantity, [30] etc. Whatever they contain of affirmation matches their concept, and does not extend itself beyond [the concept]. So we may form simple ideas at will, without fear of error.\n[73] It only remains, then, to ask by what power our mind can form these [simple ideas] and how far this power extends. For once this is [35] discovered, we shall easily see the highest knowledge we can reach. It [II/28] is certain that this power does not extend to infinity. For when we affirm of a thing something not contained in the concept we form of it, that indicates a defect of our perception, or that we have thoughts, [5] or ideas, which are, as it were, mutilated and maimed. For we saw that the motion of a semicircle is false when it is in the mind in isolation, but true if it is joined to the concept of a sphere, or to the concept of some cause determining such a motion. But if it is—as it seems at first54—of the nature of a thinking being to form true, or [10] adequate, thoughts, it is certain that inadequate ideas arise in us only from the fact that we are a part of a thinking being, of which some thoughts wholly constitute our mind, while others do so only in part.\n[74] But we still need to consider something which was not worth [15] the trouble of noting concerning fictions, and which gives rise to the greatest deception—viz. when it happens that certain things that appear in the imagination are also in the intellect, i.e., that they are conceived clearly and distinctly. For then, so long as the distinct is not distinguished from the confused, certainty, i.e., a true idea, is mixed up with what is not distinct.\n[20] For example, some of the Stoics heard, perhaps, the word soul , and also that the soul is immortal, which they only imagined confusedly; they also both imagined and at the same time understood that the most subtle bodies penetrate all others, and are not penetrated by any. Since they imagined all these things at once—while remaining certain of this [25] axiom—they immediately became certain that the mind was those most subtle bodies55 and that those most subtle bodies were not divided, etc.\n[75] But we are freed from this also, as long as we strive to consider all our perceptions according to the standard of a given true idea, being on guard, as we said in the beginning, against those we have from report or from random experience. Moreover, such a deception [30] arises from the fact that they conceive things too abstractly. For it is sufficiently clear through itself that I cannot apply what I conceive in its true object to something else. Finally, it arises also from the fact that they do not understand the first elements of the whole of Nature; so proceeding without order, and confusing Nature with abstractions [35] (although they are true axioms), they confuse themselves and overturn [II/29] the order of Nature. But we shall not need to fear any such deception, if we proceed as far as we can in a manner that is not abstract, and begin as soon as possible from the first elements, i.e., from the source and origin of Nature.56\n[5] [76][57](part0013.html#ch1fn93) But as for knowledge of the origin of Nature, we need not have any fear of confusing it with abstractions. For when things are conceived abstractly (as all universals are), they always have a wider extension in our intellect than their particulars can really have in nature. And then, since there are many things in nature whose difference [10] is so slight that it almost escapes the intellect, it can easily happen, if they are conceived abstractly, that they are confused. But since, as we shall see later, the origin of Nature can neither be conceived abstractly, or universally, nor be extended more widely in the intellect than it really is, and since it has no likeness to changeable things, we [15] need fear no confusion concerning its idea, provided that we have the standard of truth (which we have already shown). For it is a unique and infinitez being, beyond which there is no being.a\n[77] So far we have been speaking of the false idea. It remains now [20] to investigate the doubtful idea—i.e., to ask what are the things that can lead us into doubt, and at the same time, how doubt is removed. I am speaking of true doubt in the mind, and not of what we commonly see happen, when someone says in words that he doubts, although his mind does not doubt. For it is not the business of the Method to emend that. That belongs rather to the investigation of [25] stubbornness, and its emendation.\n[78] There is no doubt in the soul, therefore, through the thing itself concerning which one doubts. That is, if there should be only one idea in the soul, then, whether it is true or false, there will be neither doubt nor certainty, but only a sensation of a certain sort. For in itself [this idea] is nothing but a sensation of a certain sort.\n[30] But doubt will arise through another idea which is not so clear and distinct that we can infer from it something certain about the thing [II/30] concerning which there is doubt. That is, the idea that puts us in doubt is not clear and distinct. For example, if someone has never been led, either by experience or by anything else, to think about the deceptiveness of the senses, he will never doubt whether the sun is larger or smaller than it appears to be. So Country People are generally [5] surprised when they hear that the sun is much larger than the earth. But in thinking about the deceptiveness of the senses, doubt arises. I.e., [the person] knows that his senses have sometimes deceived him, but he knows this only confusedly; for he does not know how the senses deceive.58 And if someone, after doubting, acquires a true knowledge of the senses and of how, by their means, things at a [10] distance are presented, then the doubt is again removed.\n[79] From this it follows that, only so long as we have no clear and distinct idea of God, can we call true ideas in doubt by supposing that perhaps some deceiving God exists, who misleads us even in the things most certain. I.e., if we attend to the knowledge we have concerning [15] the origin of all things and do not discover—by the same knowledge we have when, attending to the nature of the triangle, we discover that its three angles equal two right angles—anything that teaches us that he is not a deceiver [NS:, then the doubt remains]. But if we have the kind of knowledge of God that we have of the triangle, then all [20] doubt is removed. And just as we can arrive at such a knowledge of the triangle, even though we may not know certainly whether some supreme deceiver misleads us, so we can arrive at such a knowledge of God, even though we may not know whether there is some supreme deceiver. Provided we have that knowledge, it will suffice, as I have [25] said, to remove every doubt that we can have concerning clear and distinct ideas.\n[80] Further, if someone proceeds rightly, by investigating [first] those things which ought to be investigated first, with no interruption in the connection of things, and knows how to define problems precisely,59 before striving for knowledge of them, he will never have anything but the most certain ideas—i.e., clear and distinct ideas. For [30] doubt is nothing but the suspension of the mind concerning some affirmation or negation, which it would affirm or deny if something did not occur to it, the ignorance of which must render its knowledge of the thing imperfect. From this it is [to be] inferred that doubt always arises from the fact that things are investigated without order.\n[35] [81] These are the matters I promised to discuss in this first part of [II/31] the Method. But to omit nothing that can lead to knowledge of the intellect and its powers, I shall say a few words about memory and forgetting. The most important consideration is that memory is strengthened both with the aid of the intellect and also without its aid. [5] For regarding the first, the more intelligible a thing is, the more easily it is retained; and conversely, the less intelligible, the more easily forgotten. E.g., if I give someone a large number of disconnected words, he will retain them with much more difficulty than if I give him the same words in the form of a story.\n[82] It is also strengthened without the aid the intellect, by the force [10] with which the imagination, or what they call the common sense, is affected by some singular corporeal thing. I say singular , for the imagination is affected only by singular things. If someone, e.g., has read only one Comedy,60 he will retain it best so long as he does not read several others of that kind, for then it will flourish in isolation in the [15] imagination. But if there are several of the same kind, we imagine them all together and they are easily confused. I say also corporeal , for the imagination is affected only by bodies. Therefore since the memory is strengthened both by the intellect and also without the intellect, we may infer that it is something different from the intellect, and that concerning the intellect considered in itself there is neither memory nor forgetting.\n[20] [83] What, then, will memory be? Nothing but a sensation of impressions on the brain, together with the thought of a determinate durationd of the sensation, which recollection also shows. For there the soul thinks of that sensation, but not under a continuous duration. And so the idea of that sensation is not the duration itself of the sensation, [25] i.e., the memory itself. But whether the ideas themselves undergo some corruption, we shall see in [my] Philosophy.\nIf this seems quite absurd to anyone, it will suffice for our purpose if he thinks that the more singular a thing is, the more easily it may be retained, as the example of the Comedy just mentioned makes clear. [II/32] Further, the more intelligible a thing is, the more easily it too is retained. So we cannot but retain a thing that is most singular if only it is also intelligible.\n[84] In this way, then, we have distinguished between a true idea [5] and other perceptions, and shown that the fictitious, the false, and the other ideas have their origin in the imagination, i.e., in certain sensations that are fortuitous, and (as it were) disconnected; since they do not arise from the very power of the mind, but from external causes, as the body (whether waking or dreaming) receives various motions.\n[10] But if you wish, take imagination any way you like here, provided it is something different from the intellect, and in which the soul has the nature of something acted on. For it is all the same, however you take it, after we know that it is something random, by which the soul is acted on, and at the same time know how we are freed from it with the help of the intellect. So let no one be surprised that here, where I [15] have not yet proved that there is a body, and other necessary things, I speak of the imagination, the body and its constitution. For as I have said, it does not matter what I take it to be, after I know that it is something random, etc.62\n[85] We have shown that a true idea is simple, or composed of [20] simple ideas; that it shows how and why something is, or has been done; and that its objective effects proceed in the soul according to the formal nature of its object. This is the same as what the ancients said, i.e., that true knowledge proceeds from cause to effect—except that so far as I know they never conceived the soul (as we do here) as acting [25] according to certain laws, like a spiritual automaton.\n[86] From this we have acquired as much knowledge of our intellect as was possible in the beginning, and such a standard of the true idea that now we do not fear confusing true ideas with false or fictitious ones. Nor will we wonder why we understand certain things that do [30] not fall in any way under the imagination, why there are some things in the imagination which are completely opposed to the intellect, and finally why there are others that agree with the intellect; for we know that those activities by which imaginations are produced happen according to other laws, wholly different from the laws of the intellect, and that in imagination the soul only has the nature of something acted on.\n[35] [87] From this it is also established how easily they can fall into [II/33] great errors, who have not accurately distinguished between imagination and intellection. Such errors as: that extension must be in a place, that it must be finite, that its parts must be really distinguished from one another, that it is the first and only foundation of all things, [5] that it occupies more space at one time than at another, and many other things of the same kind, all of which are completely opposed to the truth, as we shall show in the proper place.\n[88] Next, since words are part of the imagination, i.e., since we feign many concepts, in accordance with the random composition of [10] words in the memory from some disposition of the body, it is not to be doubted that words, as much as the imagination, can be the cause of many and great errors, unless we are very wary of them.\n[89] Moreover, they are established according to the pleasure and power of understanding of ordinary people, so that they are only signs of things as they are in the imagination, but not as they are in the [15] intellect. This is clear from the fact that the names given to things that are only in the intellect, and not in the imagination, are often negative (for example, infinite, incorporeal, etc.), and also from the fact that they express negatively many things that are really affirmative, and conversely (for example, uncreated, independent, infinite, [20] immortal). Because the contraries of these are much more easily imagined, they occurred first to the earliest men, and they used positive names. We affirm and deny many things because the nature of words—not the nature of things—allows us to affirm them. And in our ignorance of this, we easily take something false to be true.\n[25] [90] We avoid, moreover, another great cause of confusion which prevents the intellect from reflecting on itself—viz. when we do not distinguish between imagination and intellection, we think that the things we more easily imagine are clearer to us, and think we understand what we imagine. Hence, what should be put later we put first, [30] and so the true order of making progress is overturned, and no conclusion is arrived at legitimately.\n[91][e](part0013.html#ch1fn101) To arrive finally at the second part of this Method, I shall set [II/34] forth first our aim in this Method, and then the means to attain it. The aim, then, is to have clear and distinct ideas, i.e., such as have been made from the pure mind, and not from fortuitous motions of the body. And then, so that all ideas may be led back to one, we shall [5] strive to connect and order them so that our mind, as far as possible, reproduces objectively the formal character of nature, both as to the whole and as to the parts.\n[92] As for the first, our ultimate end requires (as we have already said) that the thing be conceived either through its essence alone or [10] through its proximate cause. If the thing is in itself, or , as is commonly said, is the cause of itself, then it must be understood through its essence alone; but if it is not in itself, but requires a cause to exist, then it must be understood through its proximate cause. For really, knowledgef of the effect is nothing but acquiring a more perfect knowledge of its cause.\n[15] [93] Therefore, so long as we are dealing with the Investigation of things, we must never infer anything from abstractions, and we shall take very great care not to mix up the things that are only in the intellect with those that are real. But the best conclusion will have to be drawn from some particular affirmative essence, or , from a true and [20] legitimate definition. For from universal axioms alone the intellect cannot descend to singulars, since axioms extend to infinity, and do not determine the intellect to the contemplation of one singular thing rather than another.\n[94] So the right way of discovery is to form thoughts from some given definition. This will proceed the more successfully and easily, [25] the better we have defined a thing. So the chief point of this second part of the Method is concerned solely with this: knowing the conditions of a good definition, and then, the way of finding good definitions. First, therefore, I shall deal with the conditions of definition.\n[95] To be called perfect, a definition will have to explain the inmost [30] essence of the thing, and to take care not to use certain propria in its place. So as not to seem bent on uncovering the errors of others, I shall use only the example of an abstract thing to explain this. For it [II/35] is the same however it is defined. If a circle, for example, is defined as a figure in which the lines drawn from the center to the circumference are equal, no one fails to see that such a definition does not at all explain the essence of the circle, but only a property of it. And though, as I have said, this does not matter much concerning figures and other [5] beings of reason, it matters a great deal concerning Physical and real beings, because the properties of things are not understood so long as their essences are not known. If we neglect them, we shall necessarily overturn the connection of the intellect, which ought to reproduce the connection of Nature, and we shall completely miss our goal.\n[10] [96] These are the requirements which must be satisfied in Definition, if we are to be free of this fault:\n1. If the thing is created, the definition, as we have said, will have to include the proximate cause. E.g., according to this law, a circle would have to be defined as follows: it is the figure that [15] is described by any line of which one end is fixed and the other movable. This definition clearly includes the proximate cause.63\n2. We require a concept, or definition, of the thing such that when it is considered alone, without any others conjoined, all the thing’s properties can be deduced from it (as may be seen in this definition [20] of the circle). For from it we clearly infer that all the lines drawn from the center to the circumference are equal.\nThat this is a necessary requirement of a definition is so plain through itself to the attentive that it does not seem worth taking time to demonstrate it, nor to show also, from this second requirement, that every definition must be affirmative.\n[25] I mean intellectual affirmation—it matters little whether the definition is verbally affirmative; because of the poverty of language it will sometimes, perhaps, [only] be able to be expressed negatively, although it is understood affirmatively.\n[97] These are the requirments for the definition of an uncreated thing:\n1. That it should exclude every cause, i.e., that the object should [30] require nothing else except its own being for its explanation.64\n2. That, given the definition of this thing, there should remain no room for the Question—does it exist?\n3. That (as far as the mind is concerned) it should have no substantives that could be changed into adjectives, i.e., that it should not be explained through any abstractions.\n[35] 4. Finally (though it is not very necessary to note this) it is required [II/36] that all its properties be inferred65 from its definition.\nAll these things are evident to those who attend to them accurately.\n[98] I have also said that the best conclusion will have to be drawn from a particular affirmative essence. For the more particular an idea [5] is, the more distinct, and therefore the clearer it is. So we ought to seek knowledge of particulars as much as possible.\n[99] As for order, to unite and order all our perceptions, it is required, and reason demands,66 that we ask, as soon as possible, whether there is a certain being, and at the same time, what sort of being it is, [10] which is the cause of all things, so that its objective essence may also be the cause of all our ideas, and then our mind will (as we have said)67 reproduce Nature as much as possible. For it will have Nature’s essence, order, and unity objectively.\nFrom this we can see that above all it is necessary for us always to [15] deduce all our ideas from Physical things, or from the real beings, proceeding, as far as possible, according to the series of causes, from one real being to another real being, in such a way that we do not pass over to abstractions and universals, neither inferring something real from them, nor inferring them from something real. For to do [20] either interferes with the true progress of the intellect.\n[100] But note that by the series of causes and of real beings I do not here understand the series of singular, changeable things, but only the series of fixed and eternal things. For it would be impossible for human weakness to grasp the series of singular, changeable things, not [25] only because there are innumerably many of them, but also because of the infinite circumstances in one and the same thing, any of which can be the cause of its existence or nonexistence. For their existence has no connection with their essence, or (as we have already said) is not an eternal truth.\n[30] [101] But there is also no need for us to understand their series. The essences of singular, changeable things are not to be drawn from their series, or order of existing, since it offers us nothing but extrinsic denominations, relations, or at most, circumstances, all of which are [35] far from the inmost essence of things. That essence is to be sought [II/37] only from the fixed and eternal things, and at the same time from the laws inscribed in these things, as in their true codes, according to which all singular things come to be, and are ordered. Indeed these singular, changeable things depend so intimately, and (so to speak) essentially, on the fixed things that they can neither be nor be conceived [5] without them. So although these fixed and eternal things are singular, nevertheless, because of their presence everywhere, and most extensive power, they will be to us like universals, or genera of the definitions of singular, changeable things, and the proximate causes of all things.\n[10] [102] But since this is so, there seems to be a considerable difficulty in our being able to arrive at knowledge of these singular things. For to conceive them all at once is a task far beyond the powers of the human intellect. But to understand one before the other, the order must be sought, as we have said, not from their series of existing, nor [15] even from the eternal things. For there, by nature, all these things are at once. So other aids will have to be sought beyond those we use to understand the eternal things and their laws.\nNevertheless, this is not the place to treat them, nor is it necessary until after we have acquired a sufficient knowledge of the eternal things [20] and their infallible laws, and the nature of our senses has become known to us. [103] Before we equip ourselves for knowledge of singular things, there will be time to treat those aids, all of which serve to help us know how to use our senses and to make, according to certain laws, and in order, the experiments that will suffice to determine [25] the thing we are seeking, so that at last we may infer from them according to what laws of eternal things it was made, and its inmost nature may become known to us, as I shall show in its place.68\nHere, to return to our theme, I shall only try to treat those things that seem necessary for us to be able to arrive at knowledge of eternal things, and for us to form their definitions according to the conditions [30] laid down above. [104] To do this, we must recall what we said above:69 when the mind attends to a thought—to weigh it, and deduce from it, in good order, the things legitimately to be deduced from it—if it is false, the mind will uncover the falsity; but if it is true, the mind will [35] continue successfully, without any interruption, to deduce true things [II/38] from it. This, I say, is required for our purpose. For our thoughts cannot be determined from any other foundation.70 [105] If, therefore, we wish to investigate the first thing of all, there must be some foundation that directs our thoughts to it.\n[5] Next, because Method is reflexive knowledge itself, this foundation, which must direct our thoughts, can be nothing other than knowledge of what constitutes the form of truth, and knowledge of the intellect, and its properties and powers. For once we have acquired this [knowledge], we shall have the foundation from which we shall deduce our [10] thoughts and the way by which the intellect, according to its capacity, will be able to reach the knowledge of eternal things, with due regard, of course, to its own powers.\n[106] But if forming true ideas pertains to the nature of thought, as shown in the first part, here we must investigate what we understand [15] by the powers of the intellect. Since the chief part of our Method is to understand as well as possible the powers of the intellect, and its nature, we are necessarily forced, by what I have taught in this second part of the Method, to deduce these from the very definition of thought and intellect.\n[107] But so far we have had no rules for discovering definitions. [20] And because we cannot give them unless the nature, or definition, of the intellect, and its power are known, it follows that either the definition of the intellect must be clear through itself, or else we can understand nothing. It is not, however, absolutely clear through itself; but because its properties (like all the things we have from intellect) [25] cannot be perceived clearly and distinctly unless their nature is known, if we attend to the properties of the intellect that we understand clearly and distinctly, its definition will become known through itself. We shall, therefore, enumerate the properties of the intellect here, and consider them, and begin to deal with out innate tools.g\n[30] [108] The properties of the intellect which I have chiefly noted, and understand clearly, are these:\n1. That it involves certainty, i.e., that the intellect knows that things are formally as they are contained objectively in itself.\n2. That it perceives certain things, or forms certain ideas, absolutely, [II/39] and forms certain ideas from others. For it forms the idea of quantity absolutely, without attending to other thoughts, but it forms the ideas of motion only by attending to the idea of quantity.\n3. Those that it forms absolutely express infinity, but determinate [5] ideas it forms from others. For if it perceives the idea of a quantity through a cause, then it determines [that idea] through [the idea] of a quantity,71 as when it perceives that a body arises from the motion of some plane, a plane from the motion of a line, and finally, a line from the motion of a point. These perceptions do not help to understand the quantity, but only to determine it. [10] This is evident from the fact that we conceive them as arising from the motion, although the motion is not perceived unless the quantity is perceived, and also because we can continue the motion to form a line to infinity, which we could not do at all, if we did not have the idea of infinite quantity.\n[15] 4. It forms positive ideas before negative ones.\n5. It perceives things not so much under duration as under a certain species of eternity, and in an infinite number—or rather, to perceive things, it attends neither to number nor to duration; but when it imagines things, it perceives them under a certain [20] number, determinate duration and quantity.\n6. The clear and distinct ideas that we form seem to follow so from the necessity of our nature alone that they seem to depend absolutely on our power alone. But with confused ideas it is quite the contrary—they are often formed against our will.\n[25] 7. The mind can determine in many ways the ideas of things that the intellect forms from others—as, for example, to determine the plane of an ellipse, it feigns that a pen attached to a cord is moved around two centers, or conceives infinitely many points always having the same definite relation to some given straight line, or a [30] cone cut by some oblique plane, so that the angle of inclination is greater than the angle of the cone’s vertex, or in infinite other ways.\n8. The more ideas express of the perfection of some object, the more perfect they are. For we do not admire the architect who has designed a chapel so much as one who has designed a notable [35] temple.\n[II/40] [109] I shall not linger over the other things that are referred to thought, such as love, joy, etc. For they contribute nothing to our present purpose, nor can they be conceived unless the intellect is perceived. For if perception is altogether taken away, then all these are taken away.\n[5] [110] False and fictitious ideas have nothing positive (as we have shown abundantly) through which they are called false or fictitious, but they are considered as such only from a defect of our knowledge. So false and fictitious ideas, as such, can teach us nothing concerning the essence of thought. It is rather to be sought from the positive [10] properties just surveyed, i.e., we must now establish something common from which these properties necessarily follow, or such that when it is given, they are necessarily given, and when it is taken away, they are taken away.\nThe rest is lacking.\n1 Spinoza describes his opusculum as being devoted to the question “how things began to be and by what connection they depend on the first cause … and also on the emendation of the intellect.” This strongly suggests that our TdIE was part of the opusculum. But Mignini has cast doubt on this. See the annotation at IV/36/13.\n2 I would be inclined to say earlier than Letter 2 at least, i.e., before September 1661, for reasons suggested in the annotation at II/9/12. Cf. Mignini 2, 106. If, as Mignini thinks, the TdIE is earlier than the KV, and if, as he also thinks, the first draft of the KV was written around the middle of 1660 (see Mignini 1, 239), then the TdIE would have been written a good deal earlier than the spring of 1662.\n3 Notably II/29, n. z. On the other hand, some of the things promised in the forward references do not appear in our version of the KV any more than they do in E, e.g., the extended discussion of wealth foreshadowed in II/6, n. a.\n4 Mignini contends that the teaching of the KV is closer to that of E than is the teaching of the TdIE in regard to the following topics: the nature of the intellect and the doctrine of method, the theory of the kinds of knowledge, the nature of fictions, the will, final causation and perfection. This is not the place for a discussion of his arguments, but I will observe that my own attempt to study the development of Spinoza’s thought about truth (Curley 9), an attempt made before I was aware of Mignini’s work, would have proceeded more smoothly had I adopted his chronology.\n5 This, essentially, is the judgment of M. Matheron, in a recent review of Mignini’s work (Bulletin de l’Association des Amis de Spinoza , no. 10, 1983): “Si les arguments positifs avancés par Mignini, bien qu’ils donnent beaucoup à penser, ne sont peut-être tout à fait convaincants (personellement j’avoue hésiter encore sur ce point), ses arguments négatifs, en revanche, sont décisifs: nous admettions tous comme allant de soi, parce qu’on nous l’avait enseigné, que le C.T.[i.e., KV] était antérieur au TRE [i.e., TdIE], et Mignini démontre qu’il n’y avait à cela absolument aucune raison!”\n6 See Joachim 2, 59, and cf. Mignini 2, 140. Joachim construes this as a survival of Cartesian doctrines advocated in the KV. Mignini, it seems, regards it as evidence of the priority of the TdIE to the KV. I myself am not satisfied with the evidence that Spinoza adopts the Cartesian distinction between will and intellect either in the TdIE or in the KV. For example, it seems to me that § 78 of the TdIE effectively anticipates Spinoza’s critique of the Cartesian doctrine of suspense of judgment in E IIP49S. And I take it that KV II, xiv, also criticizes the Cartesian distinction, though on different grounds.\n7 See the annotation at II/9/12.\n8 See Curley 2; cf. Joachim 2, 24-33.\n9 Cf. Joachim 2, 89-90.\n10 So Joachim argues at any rate. Cf. Joachim 2, 102-111.\n1 By the editors of the Opera posthuma.\n2 The translation of this title is disputed. The Latin for the main title is Tractatus de Intellectus Emendatione , the Dutch Handeling van de Verbetering van’t Verstant. Joachim (2, 1) argued that no English term could reproduce the exact implications of the Latin, but recommended “Purification of the Intellect” as rightly suggesting a project of restoring the intellect to its “natural perfection, by eliminating from it … ideas which are not its own but have come to it from an external source.” DeDeugd’s criticism of Joachim (1, 50-57), while rightly pointing out that the Dutch version cannot plausibly bear that meaning, gives insufficient weight to § 16. Eisenberg (3) argues that no term can reproduce the exact implications of the Latin, since Spinoza’s phrase has no exact implications. At the time of writing this work Spinoza inconsistently conceived of the intellect both as inherently pure and as needing purification. He did not clearly distinguish between the mind, which cannot be entirely freed of external influences, and the intellect, which has no need to be. No translation will solve such difficulties.\nThe subtitle in the NS reads: “and at the same time of the means of making it perfect.”\na I could explain this more fully and distinctly, by distinguishing wealth that is sought for its own sake, or for the sake of honor, or for the sake of sensual pleasure or for the sake of health and the advancement of the arts and sciences. But I reserve this for its own place; such an exact investigation is not appropriate here.\n3 The choice of this particular trinity is probably influenced by Aristotle. Cf. the Nicomachean Ethics I, 4, and the Short Treatise II, v, 6.\n4 “ Modò possem penitùs deliberare.” Deliberare can mean ‘ to deliberate ’ and most translators have given us something like “If only I could reflect thoroughly [on the matter].” But deliberare can also mean ‘to decide as a consequence of deliberation’ and I follow Koyré in thinking that to be the meaning here. When Spinoza comments on this phrase in § 10 it seems clear that he thinks of his difficulty as more volitional than intellectual. Cf. E IVP14.\nb These things are to be demonstrated more accurately.\n5 The NS has: “often cause the destruction of those who possess them (if one may speak thus), and always of those who are possessed by wealth.” It seems likely that the parenthesis is an addition by the translator and bears on the notion of being possessed by wealth.\n6 OP: “Sed amor erga rem aeternam, & infinitam solâ laetitiâ pascit animum, ipsaque omnis tristitiae est expers”; NS: “Maar de liefde tot d’eeuwige en oneindige zaak voed de geest [margin: mens] met blÿschap alleen, en is van alle droefheit uitgesloten.” The translation of this important passage is disputed. Joachim (2, 18, n.4) notes that various translators have rendered it as if it were the love that was exempt from sadness (which makes the Latin ungrammatical, but is what the Dutch implies). He, however, sees here a foreshadowing of the doctrine that God is exempt from sadness. (I.e., ipsa refers not to amor , but the eternal and infinite thing.) This is possible, both grammatically and philosophically, but Joachim surely goes too far when he contends that this interpretation is necessary to explain why love for God feeds the mind with unmixed joy. Appuhn, Koyré, and Caillois all take ipsa to refer to laetitia , an alternative Joachim does not discuss, and to my mind the one most likely.\n7 “ Modò possem seriò deliberare.” In referring back to II/6/21 Spinoza does not in fact quote himself exactly.\n8 Wendel and Cassirer thought it necessary to emend this passage so that it would read: “man conceives a nature much stronger than his own human nature.” But I find Gebhardt’s arguments against this conclusive (II/322-323). The text as it stands is supported by the NS and paralleled by passages both in the Short Treatise (II,4; I/60/21ff.) and the Ethics (IV, Pref., II/208). Koyré (2, 98-99) is right to remark that the passage is a difficult one on any reading, but his comments do not seem to me to stress sufficiently the necessity both of man’s conceiving such a stronger nature and of his striving to attain it.\nc These things will be explained more fully in their place.\nd Note that here I take the trouble only to enumerate the sciences necessary for our purpose, without attending to their order.\ne In the sciences there is only one end, toward which they must all be directed.\n9 If this is taken, as it may be, to mean “knowledge that man is a part of nature, and subject to its universal laws,” then the doctrine is very Stoic. Cf. Marcus Aurelius, Meditations , VII, 9-13; X,6. But the passage is also one which, more than any other perhaps, encourages the interpretation of Spinoza as a mystic.\n10 That the intellect requires purification (expurgatio) is a Baconian doctrine. Cf. the Novum Organum (Bacon, I, 139 = IV, 27). For healing (medendi) the NS has simply “improving” (verbeteren). Eisenberg (3, 175) argues that passages like this one are symptomatic of a tendency to confuse the intellect with the mind “at least during much of the time that he wrote the treatise.” And since, in Letter 2 (IV/8-9), Spinoza is quite critical of Bacon for not distinguishing the intellect from the mind, and for supposing that the intellect is deceived by its own nature, it seems likely that, by the time of writing that letter (September 1661), Spinoza would have regarded passages like this as unsatisfactory. Note that in that letter Spinoza criticizes Bacon for comparing the intellect to an uneven mirror (cf. Bacon, I, 164). A similar comparison occurs in the purification of the intellect passage cited above, except that there it is the mind that is compared to an uneven mirror. See also Mignini 2, 106.\n11 Latin: “ intellectum … redigamus.” NS: “ het verstant … te brengen.” But the language of purification in the preceding paragraph seems to justify the suggestion of returning to an original state of rectitude.\n12 NS: “ zuiveren ,” purify.\n13 NS: “ three ”; but it goes on to enumerate four kinds, as the OP does. Gebhardt thought this might naturally be explained on the assumption that in an earlier draft of the Treatise Spinoza had divided the kinds of ‘knowledge’ into three (as in the Short Treatise and the Ethics) rather than four. He also took it as evidence that the Dutch translation was made, not from the text of the Opera posthuma , but from an independent, earlier manuscript, in which revisions were not consistently carried out. For counter-argument see Mignini 2, 126-127.\n14 On the translation here, and on the classification generally, see Joachim 2, 24-33, and Curley 2, 25-59.\n15 As Joachim notes, this passage echoes one in Bacon, Novum Organum I, 100 (Bacon, I,203 [= IV, 95]). He also calls attention to aphorisms 25, 70, and 105. Perhaps Bacon’s influence is also to be seen in Descartes’ Regulae , AT X, 427.\nf When this happens, we understand nothing about the cause except what we consider in the effect. This is sufficiently evident from the fact that then the cause is explained only in very general terms, e.g., Therefore there is something, Therefore there is some power, etc. Or also from the fact that the terms express the cause negatively, Therefore it is not this, or that, etc. In the second case something clearly conceived is attributed to the cause on account of the effect, as we shall show in an example; but nothing is attributed to it except propria , not the essence of a particular thing.16\n16 OP: “In secundo casu aliquid causae tribuitur propter effectum, quod clarè conciptur, ut in exemplo ostendimus; verùm nihil praeter propria, non verò rei essentia particularis.” This note has more than its share of difficulties. (1) What does in secundo casu refer to? Eisenberg suggests that it could be translated “in a (more) favorable case,” adding a third case to the two already mentioned in the note, but neither he nor I thinks it very likely. Or it could be translated as I have it and refer to the case described in the immediately preceding sentence. But this does not make much sense of the note. Or it could refer to the second case mentioned in the text, in spite of the fact that the note as a whole is attached to the first disjunct. I opt for the third alternative. (2) What is the antecedent of quod clare concipitur? Eisenberg thinks it is obviously effectus , in spite of the gender difficulties. I follow Joachim in taking it to be aliquid. (3) What does particularis modify? Most translators have favored essentia. I follow the NS (along with Joachim and Eisenberg) in making it modify rei , though grammar is neutral on the question. See also the note on proprium in the English-Latin-Dutch section of the Glossary-Index.\n17 OP: “vel cùm concluditur ab aliquo universali, quod semper aliqua proprietas concomitatur”; the NS in effect supplies causa as the subject of concluditur : “when one infers the cause from some universal which is always accompanied by some property.” Elwes takes the quod clause as subject: “when it is inferred from some general proposition that some property is always present.” Koyré has: “when one draws a conclusion from the fact that a universal is always accompanied by a certain property.” Interpreting Spinoza’s note f as I do, I would say that the something which is inferred is a clearly conceived property of a cause, though this is inconsistent with the general description of this kind of knowledge at II/10/16. I am not much moved by the latter consideration, since the second example given in § 21 is also inconsistent with the general description. See the discussions in Joachim 2, 30-32, and Curley 2, 40-49.\ng We see clearly from this example what I have just noted. For we understand nothing through that union except the sensation itself, that is, the effect,19 from which we inferred the cause, concerning which we understand nothing.\nh Although such a conclusion is certain, it is still not sufficiently safe, unless we take the greatest care. For those who do not take such care will immediately fall into errors. When things are conceived so abstractly, and not through their true essence, they are immediately confused by the imagination. What in itself is one, men imagine to be many. For to the things they conceive abstractly, separately, and confusedly, they give names which they use to signify other more familiar things. Hence they imagine these things in the same way as they are accustomed to imagine the things to which the names were first given.\n18 I follow Appuhn, Koyré et al., in supplying “one thing” here; parallelism with II/10/16 would require the “essence of a thing,” but the strict accuracy of that description is put in some doubt both by the second example Spinoza gives and by his note to II/10/17.\n19 OP: effectus , which is ungrammatical, given seventeenth-century conventions about the use of accents. Gebhardt emends to: effectûs , “of the effect.” But most translators have preferred to emend to effectum , which is supported by the NS, and which I take to be correct.\n20 Cf. § 78.\n21 OP: “ quales ,” ‘what kind of;’ but NS: welke. Cf. Joachim 2, 31, n. 2.\n22 Here I adopt Joachim’s emendation of the numbering and punctuation. Joachim 2, 34, n 2.\n23 OP: “ singularis existentia alicujus rei.” As at II/10/34, this is ambiguous. Here the NS take singularis to modify existentia , but wrongly, I think.\ni Here I shall discuss experience somewhat more fully, and examine the Method of proceeding of the Empiricists and of the new Philosophers [NS: … the Empiricists, who want to do everything through experience …].\n24 OP: “ illius ,” NS: “ enige.” Perhaps we should read: ullius , ‘any’.\n25 The comparison which follows may have been suggested by any of various passages in Bacon [e.g., I, 126 (= IV, 14); I, 152 (= IV, 40); I, 157 (= IV, 47)]. But as Joachim notes (2, 53), Spinoza makes a rather different use of the comparison. Similar remarks apply to a passage in Descartes’ Regulae (AT X, 397). Neither Bacon nor Descartes uses the analogy to counter a threatened regress.\nk By inborn power I understand what is not caused in us by external causes. I shall explain this afterwards in my Philosophy.\nl Here they are called works. In my Philosophy, I shall explain what they are.\nm Note that here we shall take care to show not only what we have just said, but also that we have so far proceeded rightly, and at the same time other things that it is quite necessary to know.\n26 Spinoza does seem to mean that these inborn tools are needed only provisionally, until better ones can be made with them, though as Joachim remarks (2, 54, n. 1) this is obscure. Other translators (e.g., Appuhn, Koyré) take Spinoza to mean that these inborn tools are all the intellect requires to make more advanced ones.\n27 NS: “The true idea.” But I take it that this must be a generalizing use of the definite article, since no basis has been laid for reference to any particular true idea (or for any assumption that, ultimately, there is only one true idea).\n28 Joachim (2, 54, n. 2, 80, n. 1) contends that by a “true idea of Peter” Spinoza here means the true idea which someone else may have of Peter. The example Spinoza gives at the end of this paragraph seems to confirm this.\nn Note that here we are not asking how the first objective essence is inborn in us. For that pertains to the investigation of nature, where we explain these things more fully, and at the same time show that apart from the idea there is neither affirmation, nor negation, nor any will.\no In my Philosophy, I shall explain what seeking is in the soul.\n29 OP: “ modus, quo sentimus essentiam formalem.” It is unclear whether modus should be taken as a technical term here.\n30 Perhaps, as Joachim suggests (2, 162, n. 4), we should read et for aut here: “Reasoning and intellection.”\n31 OP: “ datae verae ideae ”; NS: “ ’ t gestelde ware denkbeelt.” Koyré argues that the term datae in this kind of expression is best suppressed, since it does not imply what it is likely to suggest, viz. that the true idea is given to us. All that is implied is that there is a true idea. Gueroult (1, 1:30, n. 42) argues against this that the qualification implies that the true idea is an actual eternal essence in the infinite or finite intellect, and hence produced by God, not by the intellect. Man finds the Idea “en lui sans lui.” Although uncertain of the correctness of Gueroult’s interpretation, I find it impossible to follow Koyré’s policy, which seems to lead to serious difficulty in contexts like § 43.\np To interact with other things is to produce, or be produced by, other things.\n32 The NS version of this sentence runs: “If there were something in nature that did not interact with other things, then its objective essence, which would have to agree completely with the formal essence, would also not interact with other ideas, i.e., we would not be able to understand or infer anything about it.” I have translated the Latin (as emended by Gebhardt to correct a grammatical mistake); Gebhardt thinks it obvious that the conditionalization of the reference to the objective essence is a change made by Spinoza after the Dutch translation was done. But I share Joachim’s feeling (2, 100, n. 2) that the Dutch makes better sense. Gebhardt also adds a phrase in l. 31 from the Dutch, so that the conclusion of the sentence might be translated: “we could neither understand nor infer.…” But it is very unlikely that this indicates an earlier and fuller version of the text. Probably it represents nothing more than the use of two Dutch verbs to render one Latin one.\n33 OP: “ ut mens nostra omninò referat Naturae exemplar.” It is difficult to be confident about the translation of this clause. Joachim (2, 100) offers: “that our mind may reflect ideally in all respects its real Original—i.e., may reflect the formal essence of Nature in its totality and in all its parts,” drawing on § 91 for the gloss. As Joachim points out later (215, n. 1) this passage is prima facie incompatible with his interpretation of Spinoza’s conception of truth.\nq As we also do not here doubt the truth we possess.\n34 I believe § 104 provides a helpful gloss on this passage.\n35 There is no negation in either the OP or the NS, but most editors have felt the need to supply one. If one is supplied, then it seems we must also assume a gap in the text after “I reply to him.” Koyré understands the text in this fashion, and conjectures that Spinoza eventually came to regard the objection as well-founded, so that he concentrated on the Ethics and put the Treatise to one side (cf. his note to this passage, and the Avant-propos).\nGebhardt at one stage thought likewise, but by the time he produced his edition of the Works had come to the conclusion that the text must be defended, not emended (II/326-327). He takes Spinoza to be replying not to an objection to his procedure here, but to an objection to his procedure in his projected Philosophy. Eisenberg (1, 45-49, n. 82) joins Gebhardt in defending the text.\nI prefer Koyré’s reading. I cannot deal fully here with the arguments offered by Gebhardt and Eisenberg, but I will make the following observations: (1) the text of the OP is supported by the NS, but if the conjectured omissions were in Spinoza’s ms., this confirmation does not amount to much; quite possibly the ms. contained a passage which Spinoza struck out and never replaced; (2) I do not see why the emendation would make § 46 a mere duplication of II/17/8-34; (3) if Spinoza were switching suddenly from a defense of his procedure in the TdIE to a defense of his procedure in his Philosophy , I would expect a more explicit indication of it; (4) Eisenberg construes ostenderim in II/18/2 as a future perfect (indicative): “If anyone should seek [perhaps] to know why I shall have shown the truths of Nature in that order at once, before everything.…” But both morphology and syntax require us to construe it as present perfect subjunctive. And the concluding line of the paragraph (in which Eisenberg construes praemiserim as present perfect subjunctive) makes it clear that Spinoza intends to defend what he has already done.\nr See further what we shall note concerning hypotheses that we clearly understand; but the fiction consists in our saying that such as these exist in the heavenly bodies.\n36 OP: “ somnum ,” but NS: “ dromen.” So probably we should read: somnium.\n37 NS: “ eerste/prima.” So perhaps Spinoza originally wrote: “first cause.”\n38 Gebhardt adds the phrase “in existing” from the NS, but I agree with Joachim (2, 116, n. 2) that this is at least unnecessary, if not wrong. Similarly Gebhardt’s addition at II/19/1 seems wrong given that Spinoza goes on (both in the OP and in the NS) to enumerate a fourth task of the method. His text would be translated: “Third [NS: and finally]”.…\ns Because the thing makes itself evident, provided it is understood, we require only an example, without other proof. The same is true of its contradictory—it need only be examined for its falsity to be clear. This will be plain immediately, when we speak of fictions concerning essence.\nt Note. Although many say that they doubt whether God exists, nevertheless they have nothing but the name, or they feign something which they call God; this does not agree with the nature of God, as I shall show later in the proper place.\nu By an eternal truth I mean one, which, if it is affirmative, will never be able to be negative. Thus it is a first and eternal truth that God is ; but that Adam thinks is not an eternal truth. That there is no Chimera is an eternal truth; but not that Adam does not think.\n39 Joachim (ibid.) suggests reading essentia , though the OP’s existentia is supported by the NS. If it were not for the immediately following phrase (ipsâ suâ naturâ), I would think this almost certainly correct. I have translated the Latin as it stands, but (with Eisenberg) I feel certain that what Spinoza means is that the essence of the thing by itself does not entail either that the thing cannot, or that it must, exist.\n40 The text of the OP would be translated: “From this it follows that, if there is a God, or something omniscient, we (nos) can feign nothing at all.” Since this makes very little sense, earlier editors and translators often supplied a phrase to fill it out: “we can feign nothing at all about it.” Gebhardt’s text, which I have translated, reads eum for nos , following the NS. Slightly preferable, perhaps, would be van Vloten and Land’s hoc (= this being) for nos. Textual emendation is a dangerous game, but if anything in this area is certain, we can be sure that the text of the OP is corrupt. For a full discussion see Gebhardt (II/328-330) or Eisenberg 2, 56-60. Eisenberg gives a clear explanation of the thought: since hypotheses concern only the possible (i.e., things whose existence or nonexistence depends on causes unknown to us), a being to whom nothing was unknown would not be able to regard anything as merely possible, hence would not be able to form hypotheses about anything.\n41 The clause “when (ubi) we do not attend to the order of Nature” is puzzling enough to have prompted attempts at emendation. Gebhardt is probably right to reject Elbogen’s suggestion that it has simply been misplaced, but might have considered more seriously Stern’s suggestion that we should read etsi for ubi : “ even if we do not attend …” It would not take a great deal of carelessness in the writing or the reading for a handwritten etsi to be taken for an ubi and etsi would not require a subjunctive (pace Gebhardt). Koyré (2, 106) has a plausible gloss: for Spinoza there are as many modes and degrees of existence as there are modes and degrees of essence; the existence of a man is different from that of an animal or an inanimate object; even when we do not attend to the order of nature (which is a necessary, but not sufficient condition of all feigning), we cannot attribute to a man an animal’s mode of existence unless we think in general terms.\nx Afterwards, when we speak of fiction that concerns essences, it will be clear that the fiction never makes, or presents to the mind, anything new, but that only things which are in the brain or the imagination are recalled to memory, and that the mind attends confusedly to all of them at once. Speech and a tree, for example, are recalled to memory, and since the mind attends confusedly, without distinction, it allows that the tree speaks. The same is understood concerning existence, especially, as we have said, when it is conceived so generally, as being. Then it is easily applied to all things which occur in the mind together. This is very much worth noting.\ny The same must also be understood concerning the hypotheses that are made to explain certain motions, which agree with the phenomena of the heavens; except that when people apply them to the celestial motions, they infer the nature of the heavens from them. But that nature can be different, especially since many other causes can be conceived to explain such motions.\n42 Koyré suggests glossing “done something” by “uttered some words.”\n43 Joachim (2, 120 n.) suggests that Spinoza has in mind Descartes’ Principles IV, 95-101, though it is not clear that Descartes is there involved in either of the suppositions Spinoza here discusses.\n44 I have translated the text of the OP (“ verae ac merae assertiones ”) as it stands, but in spite of the support of the NS and Joachim’s defense (2, 121, n. 2), I question whether verae (‘true’) is correct. Appuhn has: “assertions pure and simple,” which seems more in keeping with parallel passages (II/21/20-21, 21/27-28, 22/20-21).\nz It often happens that a man recalls this term soul to his memory, and at the same time forms some corporeal image. But since these two things are represented together, he easily allows that he imagines and feigns a corporeal soul: because he does not distinguish the name from the thing itself. Here I ask my readers not to hasten to refute this, which, as I hope, they will not do, provided that they attend as accurately as possible to the examples, and at the same time, to the things that follow.\n45 Elbogen points out that most of Spinoza’s examples come from Ovid’s Metamorphoses. But note that there seem to be references also to the Judaeo-Christian doctrine of creation and the Christian doctrine of the incarnation. Cf. Parkinson, 101-102, and E IP8S2, II/49/35.\n46 Koyré sees an allusion both to theologians who hold a voluntarist theory of belief and to Hobbes’ De Corpore I, iii, 8.\n47 Wolfson (1, 2:110-111) thought that this passage was undoubtedly directed against Descartes, citing The Passions of the Soul III, 152. He might, with equal justice, have cited the Fourth Meditation’s claim that it is principally our free will that justifies our thinking of ourselves as made in God’s image (AT VII, 57). De Deugd (90-91) countered that Descartes nevertheless does not ascribe to man a power to create ideas ex nihilo (which is what is in question here in § 60). Still, I do not think that would be a terribly implausible reading of certain passages in the Third Meditation (AT VII, 43-44). Descartes may be the target.\na Although I seem to infer this from experience, and someone may say that this is nothing, because a demonstration is lacking, he may have one, if he wishes; since there can be nothing in nature that is contrary to its laws, but since all things happen according to certain laws of nature, so that they produce their certain effects, by certain laws, in an unbreakable connection, it follows from this that when the soul conceives a thing truly, it proceeds to form the same effects objectively. See below, where I speak of the false idea. [In the OP this note is attached to the last sentence in § 60. Gebhardt places it here, following the NS. De Deugd has defended the placement of the OP (88, n. 1). But Eisenberg (2, 69) argues persuasively that the note is intended, not to disprove the view discussed in § 60, but to support the view presented in § 61.]\nb Note that the fiction, considered in itself, does not differ much from the dream, except that the causes which appear to the waking by the aid of the senses, and from which they infer that those presentations are not presented at that time by things placed outside them, do not appear in dreams. But error, as will be evident immediately, is dreaming while awake. And if it is very obvious, it is called madness.\n48 This sentence occurs only in the OP, which may indicate either an oversight on the part of the translator (as Leopold thought) or a later addition (as Gebhardt thought). This paragraph and the following are very strongly reminiscent of Descartes’ teaching in the Regulae , Rules 10 and 12, AT X, 399, 418, and 420. But even here there is nothing Spinoza could have derived only from Descartes. As Koyré points out, a similar doctrine is taught by St. Thomas, Summa theologiae , Ia. 17, 3.\n49 OP: “ primam ” NS: “ het eerste denkbeelt ” (= ideam). But parallelism with 1. 12 requires: fictionem.\n50 OP: “ sed quòd necessitas.” Joachim (2, 153, n. 2) suggests emending by deleting sed. That still leaves a somewhat awkward construction. What Spinoza means , I think, is that the second clause is a consequence of the first, not a separate condition.\n51 As Joachim notes (2, 91-98), there are two passages in Descartes that Spinoza may have in mind here, one in the Fifth Meditation and one in the Second Replies (AT VII, 64, 103-104). Spinoza’s examples are awkward for those interpreters who emphasize other passages in which Spinoza apparently adopts a correspondence theory of truth (e.g., myself, in Curley 3, 52-56, 122-126, 134-137, 142). But the examples are awkward in any case, since apparently incompatible with the general proposition they are supposed to illustrate, which is not so awkward. For further discussion see Curley 9.\n52 Koyré is probably right to see an allusion to Hobbes here. Cf. De Corpore I, i, 8.\n53 OP: “ cogitationis ”, NS: “ kennis/cognitio.” Gebhardt thinks the OP represents Spinoza’s correction of a mistake he made in the ms. from which the NS translation was done.\n54 OP: “ uti primâ fronte videtur.” Most translators (including the NS) have taken this to be presented as no more than a plausible hypothesis. But Joachim suggests (2, 91) that it is presented as a self-evident principle: “as is apparent at first glance.” Cf. § 106.\n55 Joachim (2, 159, n. 1) suggests following the NS, which reads: “… that was such a most subtle body.…”\n56 Gueroult (1, 1:169 n.) identifies the “first elements of the whole of Nature,” which constitute the source and origin of Nature, with the attributes that constitute God or substance. I agree (Curley 3, 42) and infer that God is not to be identified with the whole of Nature, but only with Natura naturans.\nz These are not attributes of God that show his essence, as I shall show in [my] Philosophy. [Since this topic is one taken up in the Short Treatise (KV I, ii-vii), but not in the Ethics , this note is evidence that the work referred to in the TdIE as “my Philosophy” was more like the Short Treatise than the Ethics.]\na This has already been demonstrated above. For if such a being did not exist, it could never be produced; and therefore the mind would be able to understand more things than Nature could bring about—which we have shown above to be false.\n57 Koyré refers us here to E IIP38 and Hobbes, De Corpore I, vi, 4-13.\n58 In the OP this sentence is printed as a footnote annexed to the Latin phrase here represented by “But in thinking.…” Gebhardt (following a suggestion of Leopold’s) adopts the reading of the NS, which brings it into the text. Joachim (2, 182 n.) thinks this a mistake.\n59 OP: “ quomodò quaestiones sint determinandae.” I adopt Joachim’s paraphrase (2, 183).\nd But if the duration is indeterminate, the memory of the thing is imperfect, as each of us also seems to have learned from nature. For often, to believe someone better in what he says, we ask when and where it happened. Although the ideas themselves also have their own duration in the mind, nevertheless, since we have become accustomed to determine duration with the aid of some measure of motion, which is also done with the aid of the imagination, we still observe no memory that belongs to the pure mind.61\n60 OP: “ Fabulam amatoriam ,” NS: “ tooneelspel van liefde.” Literally, love story or romantic play. But the marginal note in the NS suggests that Spinoza may originally have written Comoedia. The change (if there was one) was presumably made only for stylistic reasons and was not made consistently (cf. 1. 29).\n61 OP: “ sit purae mentis ” NS: “ gantschelijk tot de ziel behoort ” (= belongs entirely to the mind).\n62 The NS at this point gives (instead of “etc.”) a version of the lines occurring above 12-14. But they add that the imagination is not only random , but also unconscious , and that the soul is entirely acted on.\ne The principal Rule of this part (as follows from the first part) is to review all the ideas we discover in us from the pure intellect, so that they are distinguished from those we imagine. This will have to be elicited from the properties of each, i.e., of the imagination and the intellection.\nf Note that it is evident from this that we cannot [NS: legitimately or properly] understand anything of Nature without at the same time rendering our knowledge of the first cause, or God, more ample.\n63 Cf. Hobbes, De Corpore I, i, 5, and his Examinatio et emendatio mathematicae hodiernae , second dialogue. See also Cassirer 2:98ff.\n64 According to Gueroult (1, 1:172-173), Spinoza later modified this requirement and came to regard his definition of God (E ID6) as a genetic, causal definition. It would still be true that God requires nothing else except his own being (i.e., the elements of his being, the attributes) for his explanation. But it would not be correct to say that a definition in terms of those elements excludes every cause. Whereas the notion of being causa sui is here treated as if equivalent to being without a cause, later it will be treated more positively. The key passage is in Letter 60 (IV/270-271).\n65 OP: “ concludantur ” NS: “ verklaart worden ” (literally: ‘be explained’).\n66 Accepting Leopold’s emendation of the text. Cf. Joachim 2, 214 n.\n67 Cf. §§ 42, 91, and 95.\n68 Various scholars (Leopold, Appuhn, Joachim) have seen in this sentence a digression, probably added by Spinoza as a marginal note. Gebhardt, following both the OP and the NS, retains it in the text, rightly, I think.\n69 I take the reference to be to § 61, as Gebhardt apparently does at II/337. But at II/338 he apparently takes it to be to § 70, as part of his case for his emendation of II/38/1-2.\n70 OP: “Nam ex nullo fundamento cogitationes nostrae terminari queunt.” Elwes’ translation of that text is as reasonable as any: “For our thoughts may be brought to a close by the absence of a foundation.” Gebhardt (following the NS) emends to: “Nam ex nullo alio fundamento cogitationes nostrae determinari queunt,” which is what I have translated. But Appuhn’s conjecture is also plausible: “Nam ex nullo fundamento cogitationes nostrae determinari nequeunt” (= “for without a foundation our thoughts cannot be determined”). For a fuller discussion see Eisenberg 1, 103-105, or Gebhardt II/337-339. Cf. Aristotle, NE, 1098 b1-12.\ng Cf. above [II/13-14ff.].\n71 The text is evidently corrupt here. Gebhardt emends along lines suggested by the NS. I believe his version of the text makes sense if understood as I have translated it. For an alternative version and full discussion, see Eisenberg 1, 107-109.",
    "crumbs": [
      "General",
      "Treatise on the Emendation of the Intellect"
    ]
  },
  {
    "objectID": "documents/spinoza.html#treatise-on-the-emendation-of-the-intellect",
    "href": "documents/spinoza.html#treatise-on-the-emendation-of-the-intellect",
    "title": "Treatise on the Emendation of the Intellect",
    "section": "",
    "text": "THE Treatise on the Emendation of the Intellect (TdIE), a short, difficult, but fascinating discourse on method, was first published in Spinoza’s Opera posthuma in 1677. But as the editors of that collection tell us in their preface, both its style and its content show it to be one of Spinoza’s earliest works. If the reference in Letter 6 to a “whole short work” (integrum opusculum) is indeed to this treatise, as scholars have generally assumed,1 then a draft of it must have existed at least by early in 1662, and quite likely Spinoza wrote it before that.2\nVarious forward references in Spinoza’s notes to this treatise indicate that at some stage of his work on it Spinoza conceived it as introductory to another work, to be called (perhaps) Philosophy , a work which would have discussed in a systematic way topics in philosophical theology (II/29, n. z), philosophy of mind (II/15, n. o), epistemology (II/14, nn. k and l), ethics (II/6, n. a; II/7, n. b; II/8, n. c), and perhaps much else (cf. II/9, n. d). Some of the references suggest a work more like the Short Treatise than the Ethics ,3 and Gebhardt argued that the “short work” referred to in Letter 6 was a two-part work, with the TdIE as a methodological prolegomenon to the more systematic KV. According to Gebhardt (I/407), the Latin original of the KV was already in existence when Spinoza began writing the TdIE around the time of Letter 6. But if what I have suggested above is correct (see n. 2), then Gebhardt must be wrong at least about the date of composition of the TdIE. Mignini would argue that Gebhardt is wrong also in thinking that the TdIE was an integral part of the short work Spinoza refers to in Letter 6. Emphasizing the incompleteness of our text of the TdIE, he contends that it could not have been correctly described in Letter 6 as having been composed and that it is earlier than the KV, not merely in date of composition, but also in the stage of the development of Spinoza’s thought that it represents.4 If Mignini’s arguments for the priority of the TdIE are not conclusive, he has, I think, at least established that there is no reason to regard the KV as the earlier work.5 So at this stage the position would seem to be that, if the TdIE is not in fact earlier that the KV, it was probably written at about the same time as the KV and as an introduction to it.\nIn its importance for the study of the development of Spinoza’s thought, the Treatise on the Intellect invites comparison with Descartes’ Regulae. Both are early, unfinished works that show the direction of their author’s thought at a formative stage, that indicate the problems concerning him and the solutions he was inclined toward. Both discuss certain important themes more fully than does any work their author later published. But both works also need to be read with the consciousness that the lines of thought presented in them may not have proved ultimately to be satisfactory to the author.\nFor example, some have argued that in this treatise Spinoza has not fully emancipated himself from Descartes on the distinction between will and intellect,6 and it seems clear that he does tend to confuse mind and intellect.7 I would argue that the discussion of the four kinds of knowledge is not clearly thought out.8 And Joachim has suggested that the whole work may have been intended only to present a popular, imprecise exposition of Spinoza’s thought on these topics.9\nThe most important question, perhaps, is whether the whole concept of method, as Spinoza here presents it, is not incoherent, and so doomed to failure.10 On the one hand, the truth is supposed to require no sign, and having a true idea is supposed to be sufficient to remove doubt (§ 36); on the other, the method is supposed, among other things, to teach us what a true idea is, and how to distinguish it from other perceptions (§ 37).\nBut whatever reservations we may have about the doctrine of this work, it is clear that in the main it continued to satisfy Spinoza for some years. A letter to Bouwmeester in 1666 (Letter 37) repeats some of the Treatise’s main themes—that the intellect, unlike the body, is not subject to chance, external causes, but has the power of forming clear and distinct ideas; that it is necessary above all to distinguish between the intellect and the imagination (this being identified with distinguishing between true ideas and all the rest, the false, fictitious and doubtful). And an interchange with Tschirnhaus in 1675 (Letters 59 and 60) indicates that Spinoza had communicated something similar to him informally, and had given Tschirnhaus some reason to expect that before long he would publish his treatise on method.\nNaturally, then, there have been a variety of suggestions as to why the Treatise never was published in Spinoza’s lifetime. The editors of the Opera posthuma remark that the importance of the topic, the deep contemplations and extensive knowledge it required, made Spinoza’s progress with it very slow. Appuhn suggests that Spinoza broke off the composition because he could not see any satisfactory solution to the problems raised at the end (§§ 102-103, 106-110), and that he did not return to finish it because he came to think it more important to concentrate on his other works on moral and political philosophy (the Ethics , the Theological-Political Treatise , and the Political Treatise). Koyré, on the other hand, tends to emphasize the difficulty raised in § 46 (see the note to II/18/1-2). Ironically, Joachim’s excellent commentary on this work itself remained unfinished at his death because he was unable to resolve to his satisfaction the problem of how Spinoza meant to conclude the Treatise.\nIf the character of this work as unfinished, highly problematic, and only posthumously published invites comparison with Descartes’ Regulae , the apparently autobiographical character of the opening sections equally invites comparison with the Discourse on Method. The tone of the two works is quite different, of course. The dissatisfaction Descartes presents as leading him to philosophy is with the uncertainty of the learning that had been imparted to him as a student. Spinoza’s dissatisfaction is with the insufficiency of the ends men commonly pursue.\nOf course scholars have doubted whether these opening passages should be taken as strictly autobiographical (just as they have doubted the accuracy of Descartes’ account of his life in the Discourse). As Koyré remarks (Koyré 2, xix), the theme de vero bono et de contemptu mundi is as old as the world itself. Various Stoic authors (e.g., Marcus Aurelius and Seneca) have been cited. And Elbogen calls attention to the work of a medieval Jewish author, Shem Tov Falaquera, whose Ha-Mevak-kesh similarly offers knowledge as the path to salvation. However that may be, it remains, as Koyré also remarks, highly significant that Spinoza should begin a treatise on method by reflecting on the true good.\nThe paragraph numbers in brackets are those introduced by Bruder and are included for ease in making and following references. Lettered footnotes are Spinoza’s, numbered footnotes are mine. I have adopted the lettering of Gebhardt’s edition, though (even allowing for differences in the Latin alphabet) it is not entirely consecutive.\n\n\n\nTHIS Treatise on the Emendation of the Intellect etc., which we give you here, kind reader, in its unfinished [NS: and defective] state, was written by the author many years ago now. He always intended to finish it. But hindered by other occupations, and finally snatched away by death, he was unable to bring it to the desired conclusion. But since it contains many excellent and useful things, which—we have no doubt—will be of great benefit to anyone sincerely seeking the truth, we did not wish to deprive you of them. And so that you would be aware of, and find less difficult to excuse, the many things that are still obscure, rough, and unpolished, we wished to warn you of them. Farewell.\n\n\n\n[1] AFTER experience had taught me that all the things which regularly occur in ordinary life are empty and futile, and I saw that all the [10] things which were the cause or object of my fear had nothing of good or bad in themselves, except insofar as [my] mind was moved by them, I resolved at last to try to find out whether there was anything which would be the true good, capable of communicating itself, and which alone would affect the mind, all others being rejected—whether there [15] was something which, once found and acquired, would continuously give me the greatest joy, to eternity.\n[2] I say that I resolved at last —for at first glance it seemed ill-advised to be willing to lose something certain for something then uncertain. I saw, of course, the advantages that honor and wealth bring, and that I would be forced to abstain from seeking them, if I wished to devote [20] myself seriously to something new and different; and if by chance the greatest happiness lay in them, I saw that I should have to do without it. But if it did not lie in them, and I devoted my energies only to acquiring them, then I would equally go without it.\n[3] So I wondered whether perhaps it would be possible to reach my new goal—or at least the certainty of attaining it—without changing [25] the conduct and plan of life which I shared with other men. Often I tried this, but in vain. For most things which present themselves in life, and which, to judge from their actions, men think to be the highest [II/6] good, may be reduced to these three: wealth, honor, and sensual pleasure.3 The mind is so distracted by these three that it cannot give the slightest thought to any other good.\n[4] For as far as sensual pleasure is concerned, the mind is so caught up in it, as if at peace in a [true] good, that it is quite prevented from thinking of anything else. But after the enjoyment of sensual pleasure [5] is past, the greatest sadness follows. If this does not completely engross, still it thoroughly confuses and dulls the mind.\nThe mind is also distracted not a little by the pursuit of honors and wealth, particularly when the lattera is sought only for its own sake, because it is assumed to be the highest good. [5] But the mind is far [10] more distracted by honor. For this is always assumed to be good through itself and the ultimate end toward which everything is directed.\nNor do honor and wealth have, as sensual pleasure does, repentance as a natural consequence. The more each of these is possessed, the more joy is increased, and hence the more we are spurred on to increase [15] them. But if our hopes should chance to be frustrated, we experience the greatest sadness. And finally, honor has this great disadvantage: to pursue it, we must direct our lives according to other men’s powers of understanding—fleeing what they commonly flee and [20] seeking what they commonly seek.\n[6] Since I saw that all of these things stood in the way of my working toward this new goal, indeed were so opposed to it that one or the other must be given up, I was forced to ask what would be more useful to me. For as I say, I seemed to be willing to lose the [25] certain good for the uncertain one. But after I had considered the matter a little, I first found that, if I devoted myself to this new plan of life, and gave up the old, I would be giving up a good by its nature uncertain (as we can clearly infer from what has been said) for one uncertain not by its nature (for I was seeking a permanent good) but only in respect to its attainment.\n[30] [7] By persistent meditation, however, I came to the conclusion that, if only I could resolve, wholeheartedly,4 [to change my plan of life], I would be giving up certain evils for a certain good. For I saw that I [II/7] was in the greatest danger, and that I was forced to seek a remedy with all my strength, however uncertain it might be—like a man suffering from a fatal illness, who, foreseeing certain death unless he employs a remedy, is forced to seek it, however uncertain, with all [5] his strength. For all his hope lies there. But all those things men ordinarily strive for, not only provide no remedy to preserve our being, but in fact hinder that preservation, often cause the destruction of those who possess them,b and always cause the destruction of those who are possessed by them.5\n[10] [8] There are a great many examples of people who have suffered persecution to the death on account of their wealth, or have exposed themselves to so many dangers to acquire wealth that they have at last paid the penalty for their folly with their life. Nor are there fewer examples of people who, to attain or defend honor, have suffered most [15] miserably. And there are innumerable examples of people who have hastened their death through too much sensual pleasure.\n[9] Furthermore, these evils seemed to have arisen from the fact that all happiness or unhappiness was placed in the quality of the object to which we cling with love. For strife will never arise on account of [20] what is not loved, nor will there be sadness if it perishes, nor envy if it is possessed by another, nor fear, nor hatred—in a word, no disturbances of the mind. Indeed, all these happen only in the love of those things that can perish, as all the things we have just spoken of can do.\n[10] But love toward the eternal and infinite thing feeds the mind [25] with a joy entirely exempt from sadness.6 This is greatly to be desired, and to be sought with all our strength.\nBut not without reason did I use these words if only I could resolve in earnest.7 For though I perceived these things [NS: this evil] so clearly in my mind, I still could not, on that account, put aside all greed, [30] desire for sensual pleasure and love of esteem.\n[11] I saw this, however: that so long as the mind was turned toward these thoughts, it was turned away from those things, and was thinking seriously about the new goal. That was a great comfort to me. For I saw that those evils would not refuse to yield to remedies. And [II/8] although in the beginning these intervals were rare, and lasted a very short time, nevertheless, after the true good became more and more known to me, the intervals became more frequent and longer—especially after I saw that the acquisition of money, sensual pleasure, and [5] esteem are only obstacles so long as they are sought for their own sakes, and not as means to other things. But if they are sought as means, then they will have a limit, and will not be obstacles at all. On the contrary, they will be of great use in attaining the end on account of which they are sought, as we shall show in its place.\n[10] [12] Here I shall only say briefly what I understand by the true good, and at the same time, what the highest good is. To understand this properly, it must be noted that good and bad are said of things only in a certain respect, so that one and the same thing can be called both good and bad according to different respects. The same applies [15] to perfect and imperfect. For nothing, considered in its own nature, will be called perfect or imperfect, especially after we have recognized that everything that happens happens according to the eternal order, and according to certain laws of Nature.\n[13] But since human weakness does not grasp that order by its own thought, and meanwhile man conceives a human nature much stronger [20] and more enduring8 than his own, and at the same time sees that nothing prevents his acquiring such a nature, he is spurred to seek means that will lead him to such a perfection. Whatever can be a means to his attaining it is called a true good; but the highest good is to arrive—together with other individuals if possible—at the enjoyment [25] of such a nature. What that nature is we shall show in its proper place: that it is the knowledgec of the union that the mind has with the whole of Nature.9\n[14] This, then, is the end I aim at: to acquire such a nature, and to strive that many acquire it with me. That is, it is part of my happiness [30] to take pains that many others may understand as I understand, so that their intellect and desire agree entirely with my intellect and desire. To do this it is necessary,d first to understand as much of Nature [II/9] as suffices for acquiring such a nature; next , to form a society of the kind that is desirable, so that as many as possible may attain it as easily and surely as possible.\n[15] Third , attention must be paid to Moral Philosophy and to Instruction [5] concerning the Education of children. Because Health is no small means to achieving this end, fourthly , the whole of Medicine must be worked out. And because many difficult things are rendered easy by ingenuity, and we can gain much time and convenience in this life, fifthly , Mechanics is in no way to be despised.\n[10] [16] But before anything else we must devise a way of healing the intellect, and purifying it, as much as we can in the beginning, so that it understands things successfully, without error and as well as possible.10 Everyone will now be able to see that I wish to direct all the sciences toward one ende and goal, viz. that we should achieve, as we [15] have said, the highest human perfection. So anything in the sciences which does nothing to advance us toward our goal must be rejected as useless—in a word, all our activities and thoughts are to be directed to this end.\n[17] But while we pursue this end, and devote ourselves to bringing [20] the intellect back11 to the right path, it is necessary to live. So we are forced, before we do anything else, to assume certain rules of living as good:\n1. To speak according to the power of understanding of ordinary people, and do whatever does not interfere with our attaining our [25] purpose. For we can gain a considerable advantage, if we yield as much to their understanding as we can. In this way, they will give a favorable hearing to the truth.\n2. To enjoy pleasures just so far as suffices for safeguarding our health.\n[30] 3. Finally, to seek money, or anything else, just so far as suffices for sustaining life and health, and conforming to those customs of the community that do not conflict with our aim.\n[18] Having laid down these rules, I come now to what must be [35] done first, before all else: emending12 the intellect and rendering it [II/10] capable of understanding things in the way the attainment of our end requires. To do this, the order we naturally have requires me to survey here all the modes of perceiving which I have had up to now for affirming or denying something without doubt, so that I may choose [5] the best of all, and at the same time begin to know my powers and the nature that I desire to perfect.\n[19] If I consider them accurately, I can reduce them all to four13 main kinds:\n1. There is the Perception we have from report or from some [10] conventional sign.14\n2. There is the Perception we have from random experience,15 that is, from experience that is not determined by the intellect. But it has this name only because it comes to us by chance, and we have no other experiment that opposes it. So it remains with [15] us unshaken.\n3. There is the Perception that we have when the essence of a thing is inferred from another thing, but not adequately. This happens, either fwhen we infer the cause from some effect, or when something is inferred from some universal, which some property always accompanies.17\n[20] 4. Finally, there is the Perception we have when a thing is perceived through its essence alone, or through knowledge of its proximate cause.\n[20] I shall illustrate all of these with examples. I know only from report my date of birth, and who my parents were, and similar things, which I have never doubted. By random experience I know that I [25] shall die, for I affirm this because I have seen others like me die, even though they had not all lived the same length of time and did not all die of the same illness. Again, I also know by random experience that [II/11] oil is capable of feeding fire, and that water is capable of putting it out. I know also that the dog is a barking animal, and man a rational one. And in this way I know almost all the things that are useful in life.\n[21] But we infer [one thing][18](part0013.html#ch1fn36) from another in this way: after we [5] clearly perceive that we feel such a body, and no other, then, I say, we infer clearly that the soul is unitedg to the body, which union is the cause of such a sensation; but we cannot understand absolutely from this whath that sensation and union are. Or after we have come to know the nature of vision, and that it has the property that we see [10] one and the same thing as smaller when we look at it from a great distance than when we look at it from close up, we infer that the sun is larger than it appears to be, and other things of the same kind.20\n[22] Finally, a thing is perceived through its essence alone when, from the fact that I know something, I know what it is to know something, [15] or from the fact that I know the essence of the soul, I know that it is united to the body. By the same kind of knowledge, we know that two and three are five, and that if two lines are parallel to a third line, they are also parallel to each other, etc. But the things I have so far been able to know by this kind of knowledge have been very few.\n[20] [23] That you may understand all these things better, I shall use only one example. Suppose there are three numbers. Someone is seeking a fourth, which is to the third as the second is to the first. Here merchants will usually say that they know what to do to find the fourth number, because they have not yet forgotten that procedure [25] which they simply heard from their teachers, without any demonstration.\n[II/12] Others will construct a universal axiom from an experience with simple numbers, where the fourth number is evident through itself—as in the numbers 2, 4, 3, and 6. Here they find by trial that if the second is multiplied by the third, and the product then divided by the first, the result is 6. Since they see that this produces the same number [5] which they knew to be the proportional number without this procedure, they infer that the procedure is always a good way to find the fourth number in the proportion.\n[24] But Mathematicians know, by the force of the demonstration of Proposition 19 in Book VII of Euclid, which 21 numbers are proportional to one another, from the nature of proportion, and its property, [10] viz. that the product of the first and fourth numbers is equal to the product of the second and third. Nevertheless, they do not see the adequate proportionality of the given numbers. And if they do, they see it not by the force of that Proposition, but intuitively, [NS: or] without going through any procedure.\n[25] To choose the best mode of perceiving from these, we are required [15] to enumerate briefly the means necessary to attain our end:\n1.22 To know exactly our nature, which we desire to perfect, and at the same time,\n2. [To know] as much of the nature of things as is necessary,\n\nto infer rightly from it the differences, agreements and [20] oppositions of things,\nto conceive rightly what they can undergo and what they cannot,\nto compare [the nature of things] with the nature and power of man.\n\nThis done, the highest perfection man can reach will easily manifest itself.\n[25] [26] Having considered these requirements, let us see which mode of perceiving we ought to choose.\nAs for the first, it is evident in itself that from report—apart from the fact that it is a very uncertain thing—we do not perceive any essence of a thing, as is clear from our example. And since the existence [30] of any singular thing23 is not known unless its essence is known (as we shall see afterwards), we can clearly infer from this that all the certainty we have from report is to be excluded from the sciences. For no one will ever be able to be affected by simple report, unless his own intellect has gone before.\n[II/13] [27] As for the second,i again, no one should be said to have the idea of that24 proportion which he is seeking. Apart from the fact that it is a very uncertain thing, and without end, in this way no one will ever perceive anything in natural things except accidents. But these [5] are never understood clearly unless their essences are known first. So that also is to be excluded.\n[28] Concerning the third, on the other hand, we can, in a sense, say that we have an idea of the thing, and that we can also make inferences without danger of error. But still, it will not through itself [10] be the means of our reaching our perfection.\n[29] Only the fourth mode comprehends the adequate essence of the thing and is without danger of error. For that reason, it is what we must chiefly use. So we shall take care to explain how it is to be used, that we may understand unknown things by this kind of knowledge [15] and do so as directly as possible; [30] [NS: i.e.] after we know what Knowledge is necessary for us, we must teach the Way and Method by which we may achieve this kind of knowledge of the things that are to be known.\nTo do this, the first thing we must consider is that there is no infinite regress here. That is, to find the best Method of seeking the [20] truth, there is no need of another Method to seek the Method of seeking the truth, or of a third Method to seek the second, and so on, to infinity. For in that way we would never arrive at knowledge of the truth, or indeed at any knowledge.\nMatters here stand as they do with corporeal tools,25 where someone [25] might argue in the same way. For to forge iron a hammer is needed; and to have a hammer, it must be made; for this another hammer, and other tools are needed; and to have these tools too, other tools will be needed, and so on to infinity; in this way someone might try, in vain, to prove that men have no power of forging iron.\n[30] [31] But just as men, in the beginning, were able to make the easiest things with the tools they were born with (however laboriously and imperfectly), and once these had been made, made other, more difficult things with less labor and more perfectly, and so, proceeding [II/14] gradually from the simplest works to tools, and from tools to other works and tools, reached the point where they accomplished so many and so difficult things with little labor, in the same way the intellect, by its inborn power,k makes intellectual tools for itself, by which it [5] acquires other powers for other intellectual works,l and from these works still other tools, or the power of searching further, and so proceeds by stages, until it reaches the pinnacle of wisdom.\n[32] It will be easy to see that this is the situation of the intellect, provided we understand what the Method of seeking the truth is, and [10] what those inborn tools are, which it requires only26 to make other tools from them, so as to advance further. To show this, I proceed as follows.\n[33] A27 true ideam (for we have a true idea) is something different from its object. For a circle is one thing and an idea of the circle [15] another—the idea of the circle is not something which has a circumference and a center, as the circle does. Nor is an idea of the body the body itself. And since it is something different from its object, it will also be something intelligible through itself; that is, the idea, as far as its formal essence is concerned, can be the object of another objective essence, and this other objective essence in turn will also be, considered [20] in itself, something real and intelligible, and so on, indefinitely.\n[34] Peter, for example, is something real; but a true idea of Peter28 is an objective essence of Peter, and something real in itself, and altogether different from Peter himself. So since an idea of Peter is something real, having its own particular essence, it will also be something intelligible, i.e., the object of a second idea, which will have in [25] itself, objectively, whatever the idea of Peter has formally; and in turn, the idea which is [the idea] of the idea of Peter has again its essence, which can also be the object of another idea, and so on indefinitely. Everyone can experience this, when he sees that he knows what Peter is, and also knows that he knows, and again, knows that he knows that he knows, etc.\n[30] From this it is evident that to understand the essence of Peter, it is [II/15] not necessary to understand an idea of Peter, much less an idea of an idea of Peter. This is the same as if I said that, in order for me to know, it is not necessary to know that I know, much less necessary to know that I know that I know—no more than it is necessary to understand the essence of a circle in order to understand the essence [5] of a triangle.n Indeed, in these ideas the opposite is the case. For to know that I know, I must first know.\n[35] From this it is clear that certainty is nothing but the objective essence itself, i.e., the mode by which we are aware of the formal essence29 is certainty itself. And from this, again, it is clear that, for [10] the certainty of the truth, no other sign is needed than having a true idea. For as we have shown, in order for me to know, it is not necessary to know that I know. From which, once more, it is clear that no one can know what the highest certainty is unless he has an adequate idea or objective essence of some thing. For certainty and an objective essence are the same thing.\n[15] [36] Since truth, therefore, requires no sign, but it suffices, in order to remove all doubt, to have the objective essences of things, or, what is the same, ideas, it follows that the true Method is not to seek a sign of truth after the acquisition of ideas, but the true Method is the way [20] that truth itself, or the objective essences of things, or the ideas (all those signify the same) should be soughto in the proper order.\n[37] Again, the Method must speak about Reasoning, or30 about the intellection; i.e., Method is not the reasoning itself by which we understand the causes of things, much less the understanding of the causes of things; it is understanding what a true idea is by distinguishing it [25] from the rest of the perceptions; by investigating its nature, so that from that we may come to know our power of understanding and so restrain the mind that it understands, according to that standard, everything that is to be understood; and finally by teaching and constructing certain rules as aids, so that the mind does not weary itself in useless things.\n[30] [38] From this it may be inferred that Method is nothing but a [II/16] reflexive knowledge, or an idea of an idea; and because there is no idea of an idea, unless there is first an idea, there will be no Method unless there is first an idea. So that Method will be good which shows how the mind is to be directed according the standard of a given true idea.31\n[5] Next, since the relation between the two ideas is the same as the relation between the formal essences of those ideas, it follows that the reflexive knowledge of the idea of the most perfect Being will be more excellent than the reflexive knowledge of any other ideas. That is, the most perfect Method will be the one that shows how the mind is to be directed according to the standard of the given idea of the most [10] perfect Being.\n[39] From this you will easily understand how the mind, as it understands more things, at the same time acquires other tools, with which it proceeds to understand more easily. For, as may be inferred from what has been said, before all else there must be a true idea in us, as an inborn tool; once this true idea is understood, we understand [15] the difference between that kind of perception and all the rest. Understanding that difference constitutes one part of the Method.\nAnd since it is clear through itself that the mind understands itself the better, the more it understands of Nature, it is evident, from that that this part of the Method will be more perfect as the mind understands more things, and will be most perfect when the mind attends [20] to, or reflects on, knowledge of the most perfect Being.\n[40] Next, the more the mind knows, the better it understands its own powers and the order of Nature. The better the mind understands its own powers, the more easily it can direct itself and propose rules to itself; the better it understands the order of Nature, the more easily it can restrain itself from useless pursuits. In these things, as [25] we have said, the whole of the Method consists.\n[41] Moreover, the idea is objectively in the same way as its object is really. So if there were something in Nature that did not interact with other things, and if there were an objective essence of that thing which would have to agree completely with its formal essence, then [30] that objective essence would not interactp with other ideas, i.e., we could not infer anything about it.32 And conversely, those things that do interact with other things (as everything that exists in Nature does) will be understood, and their objective essences will also have the same interaction, i.e., other ideas will be deduced from them, and [II/17] these again will interact with other ideas, and so the tools for proceeding further will increase, which is what we were trying to demonstrate.\n[42] Next, from what we have just said, that an idea must agree completely with its formal essence, it is again evident that for our mind [5] to reproduce completely the likeness of Nature,33 it must bring all of its ideas forth from that idea which represents the source and origin of the whole of Nature, so that that idea is also the source of the other ideas.\n[43] Here, perhaps, someone will be surprised that, having said that a good Method is one which shows how the mind is to be directed [10] according to the standard of a given true idea, we should prove this by reasoning. For that seems to show that this is not known through itself. So it may be asked whether our reasoning is good? If our reasoning is good, we must begin from a given [true?] idea; and since to begin from a given [true?] idea requires a demonstration, we must again prove our reasoning, and then once more prove that other reasoning, [15] and so on to infinity.\n[44] To this I reply that if, by some fate, someone had proceeded in this way in investigating Nature, i.e., by acquiring other ideas in the proper order, according to the standard of the given true idea, he would never have doubtedq the truth he possessed (for as we have shown, the truth makes itself manifest) and also everything would have flowed to him of its own accord.34\n[20] But because this never or rarely happens, I have been forced to lay things down in this way, so that what we cannot acquire by fate, we may still acquire by a deliberate plan, and at the same time so that it would be evident that to prove the truth and good reasoning, we require no tools except the truth itself and good reasoning. For I have [25] proved, and still strive to prove, good reasoning by good reasoning. [45] Moreover, in this way men become accustomed to their own internal meditations.\nBut the reason why Nature is rarely investigated in the proper order, is, first, that men have prejudices whose causes we shall explain afterwards in our Philosophy. And then, the task requires a considerable [30] capacity for making accurate distinctions (as we shall show later) and much effort. Finally, there is the condition of human affairs, which are quite changeable, as we have already shown. There are still other reasons, which we shall not go into.\n[II/18] [46] If, by chance, someone should ask why I did [not][35](part0013.html#ch1fn62) immediately, before anything else, display the truths of Nature in that order—for does not the truth make itself manifest?—I reply to him […] and at the same time I warn him not to try to reject these things as false because of Paradoxes that occur here and there; he should first [5] deign to consider the order in which we prove them, and then he will become certain that we have reached the truth; and this was the reason why I have put these things first.\n[47] But perhaps, afterwards, some Skeptic would still doubt both the first truth itself and everything we shall deduce according to the [10] standard of the first truth. If so, then either he will speak contrary to his own conciousness, or we shall confess that there are men whose minds also are completely blinded, either from birth, or from prejudices, i.e., because of some external chance. For they are not even aware of themselves. If they affirm or doubt something, they do not know that they affirm or doubt. They say that they know nothing, [15] and that they do not even know that they know nothing. And even this they do not say absolutely. For they are afraid to confess that they exist, so long as they know nothing. In the end, they must be speechless, lest by chance they assume something that might smell of truth.\n[48] Finally, there is no speaking of the sciences with them. (For as far as the needs of life and society are concerned, necessity forces them [20] to suppose that they exist, and to seek their own advantage, and in taking oaths, to affirm and deny many things.) For, if someone proves something to them, they do not know whether the argument is a proof or not. If they deny, grant, or oppose, they do not know that they deny, grant, or oppose. So they must be regarded as automata, completely [25] lacking a mind.\n[49] Let us now return to our subject. First [§§ 1-17], we have treated the end toward which we strive to direct all our thoughts; second [§§ 18-29], we learned which is the best perception, by whose aid we can reach our perfection; third [§§ 30-48], we learned which is the first [30] path our mind must enter on to begin well—which is to proceed in its investigation according to certain laws, taking as a standard a given true idea.\nIf this is to be done properly, the Method must, first [§§ 50-90], show how to distinguish a true idea from all other perceptions, and to restrain the mind from those other perceptions; second [§§ 91-98], [35] teach rules so that we may perceive things unknown according to such [II/19] a standard; third [§ 99-?], establish an order, so that we do not become weary with trifles. When we came to know this Method [§ 38], we saw, fourth, that it will be most perfect when we have the idea of the most perfect Being. So in the beginning we must take the greatest care [5] that we arrive at knowledge of such a Being as quickly as possible.\n[50] Let us begin, therefore, from the first part of the Method, which is, as we have said, to distinguish and separate true ideas from all other perceptions, and to restrain the mind from confusing false, fictitious, and doubtful ideas with true ones. It is my intention to explain this fully here, so as to engage my Readers in the thought of a thing so [10] necessary, and also because there are many who doubt even true ideas, from not attending to the distinction between a true perception and all others. So they are like men who, when they were awake, used not to doubt that they were awake, but who, after they once thought in a dream that they were certainly awake (as often happens), and later [15] found that to be false, doubted even of their waking states. This happens because they have never distinguished between the dream36 and the waking state.\n[51] In the meantime, I warn the reader that I shall not discuss the essence of each perception, and explain it by its proximate37 cause, because that pertains to Philosophy, but shall discuss only what the [20] Method demands, i.e., what false, fictitious and doubtful ideas are concerned with, and how we shall be freed from each of them. Let the first inquiry, therefore, be about the fictitious idea.\n[52] Since every perception is either of a thing considered as existing, or of an essence alone, and since fictions occur more frequently [25] concerning things considered as existing, I shall speak first of them—i.e., where existence alone is feigned, and the thing which is feigned in such an act is understood, or assumed to be understood. E.g., I feign that Peter, whom I know, is going home, that he is coming to visit me, and the like.r Here I ask, what does such an idea concern? I [30] see that it concerns only possible, and not necessary or impossible things.\n[53] I call a thing impossible whose nature38 implies that it would be contradictory for it to exist; necessary whose nature implies that it [II/20] would be contradictory for it not to exist; and possible whose existence,39 by its very nature, does not imply a contradiction—either for it to exist or for it not to exist—but whose necessity or impossibility of existence depends on causes unknown to us, so long as we feign its [5] existence. So if its necessity or impossibility, which depends on external causes, were known to us, we would have been able to feign nothing concerning it.\n[54] From this it follows that, if there is a God, or something omniscient, he can feign nothing at all.40 For as far as We are concerned, after I know that I exist,s I cannot feign either that I exist or that I do [10] not exist; nor can I feign an elephant which passes through the eye of a needle; nor, after I know the nature of God, can I feign either that he exists or that he does not exist.t The same must be understood of the Chimera, whose nature implies that it would be contradictory for it to exist. From this what I have said is evident: that the fiction of which we are speaking here does not occur concerning eternal truths.u [15] I shall also show immediately that no fiction is concerned with eternal truths.\n[55] But before proceeding further, I must note here in passing that the same difference that exists between the essence of one thing and the essence of another also exists between the actuality or existence of [20] the one thing and the actuality or existence of the other. So if we wished to conceive the existence of Adam, for example, through existence in general, it would be the same as if, to conceive his essence, we attended to the nature of being, so that in the end we defined him by saying that Adam is a being. Therefore, the more generally existence [25] is conceived, the more confusedly also it is conceived, and the more easily it can be ascribed fictitiously to anything. Conversely, the more particularly it is conceived, then the more clearly it is understood, and the more difficult it is for us, [even] when we do not attend [II/21] to the order of Nature, to ascribe it fictitiously to anything other than the thing itself.41 This is worth noting.\n[56] Now we must consider those things that are commonly said to be feigned, although we understood clearly that the thing is not really [5] as we feign it. E.g., although I know that the earth is round, nothing prevents me from saying to someone that the earth is a hemisphere and like half an orange on a plate, or that the sun moves around the earth, and the like. If we attend to these things, we shall see nothing that is not compatible with what we have already said, provided we [10] note first that we have sometimes been able to err, and now are conscious of our errors; and then, we can feign, or at least allow, that other men are in the same error, or can fall into it, as we did previously.\nWe can feign this, I say, so long as we see no impossibility and no [15] necessity. Therefore, when I say to someone that the earth is not round, etc., I am doing nothing but recalling the error which I, perhaps, made, or into which I could have fallen, and afterwards feigning, or allowing, that he to whom I say this is still in the same error, or can fall into it. As I have said, I feign this so long as I see no [20] impossibility and no necessity. For if I had understood this, I could have feigned nothing at all, and it would have had to be said only that I had done something.42\n[57] It remains now to note also those things that are supposed in Problems. This sometimes happens even concerning impossible things. E.g., when we say “Let us suppose that this burning candle is not [25] now burning, or let us suppose that it is burning in some imaginary space, or where there are no bodies.” Things like this are sometimes supposed, although this last is clearly understood to be impossible.43 But when this happens, nothing at all is feigned. For in the first case [II/22] I have done nothing but recall to memoryx another candle that was not burning (or I have conceived this candle without the flame), and what I think about that candle, I understand concerning this one, so long as I do not attend to the flame.\nIn the second case, nothing is done except to abstract the thoughts [5] from the surrounding bodies so that the mind directs itself toward the sole contemplation of the candle, considered in itself alone, so that afterwards it infers that the candle has no cause for its destruction. So if there were no surrounding bodies, this candle, and its flame, would remain immutable, or the like. Here, then, there is no fiction, buty [10] true and sheer assertions.44\n[58] Let us pass now to fictions that concern either essences alone or essences together with some actuality or existence. The most important consideration regarding them is that the less the mind understands and the more things it perceives, the greater its power of feigning [15] is; and the more things it understands, the more that power is diminished.\nFor example, as we have seen above, we cannot feign, so long as we are thinking, that we are thinking and are not thinking; in the same way, after we know the nature of body, we cannot feign an infinite [20] fly, or after we know the nature of the soul,z we cannot feign that it is square, though there is nothing that cannot be put into words.\nBut as we have said, the less men know Nature, the more easily they can feign many things, such as, that trees speak, that men are changed in a moment into stones and into springs, that nothing becomes something, that even Gods are changed into beasts and into [25] men, and infinitely many other things of that kind.45\n[II/23] [59] Someone, perhaps, will think that fiction is limited by fiction, but not by intellection.46 That is, after I have feigned something, and willed by a certain freedom to assent that it exists in nature in this way, this has the consequence that I cannot afterwards think it in any [5] other way. For example, after I have feigned (to speak as they do) that body has such a nature, and willed, from my freedom, to be convinced that it really exists in this way, I can no longer feign an infinite fly; and after I have feigned the essence of the soul, I can no longer feign that it is square.\n[60] But this needs to be examined. First, either they deny or they grant that we can understand something. If they grant it, then necessarily [10] what they say about fiction will also have to be said about intellection. But if they deny it, let us—who know that we know something—see what they say.\nEvidently, they say that the soul can sense and perceive in many ways, not itself, nor the things that exist, but only those things that [15] are neither in itself nor anywhere; that is, the soul can, by its own force alone, create sensations or ideas, which are not of things; so they consider it, to some extent, as like God.47\nNext, they say that we, or our soul, has such a freedom that it compels us, or itself, indeed its own freedom. For after it has feigned something, and offered its assent to it, it cannot think or feign it in any other way, and is also compelled by that fiction so that even other [20] things are thought in such a way as not to conflict with the first fiction, just as here too because of their own fiction, they are forced to admit the absurdities which I review here, and which we shall not bother to refute with any demonstrations.\n[25] [61] Rather, leaving them to their madness, we shall take care to draw from the words we have exchanged with them something true and to our purpose, viz.:a when the mind attends to a fictitious thing which is false by its very nature, so that it considers it carefully, and understands it, and deduces from it in good order the things to be deduced, it will easily bring its falsity to light. And if the fictitious [II/24] thing is true by its nature, then when the mind attends to it, so that it understands it, and begins to deduce from it in good order the things that follow from it, it will proceed successfully, without any interruption—just as we have seen that, from the false fiction just mentioned, the intellect immediately applies itself to show its absurdity, and the [5] other things deduced from that.\n[62] So we ought not to fear in any way that we are [merely] feigning something, if only we perceive the thing clearly and distinctly. For if by chance we should say that men are changed in a moment into beasts, that is said very generally, so that there is in the mind no concept, i.e., [10] idea, or connection of subject and predicate. For if there were any concept, the mind would see together the means and causes, how and why such a thing was done. And one does not attend to the nature of the subject and of the predicate.\n[63] Next, provided the first idea is not fictitious, and all the other ideas are deduced from it, the haste to feign things will gradually [15] disappear. And since a fictitious idea cannot be clear and distinct, but only confused, and since all confusion results from the fact that the mind knows only in part a thing that is a whole, or composed of many things, and does not distinguish the known from the unknown (and besides, attends at once, without making any distinction, to the many [20] things that are contained in each thing), from this it follows, first, that if an idea is of some most simple thing, it can only be clear and distinct. For that thing will have to become known, not in part, but either as a whole or not at all.48\n[64] Secondly, it follows that if, in thought, we divide a thing that is composed of many things into all its most simple parts, and attend [25] to each of these separately, all confusion will disappear.\nThirdly, it follows that a fiction cannot be simple, but that it is made from the composition of different confused ideas, which are different things and actions existing in nature; or rather, from attending at once,b without assent, to such different ideas. For if it were simple, [30] it would be clear and distinct, and consequently true. And if it were made from the composition of distinct ideas, their composition would [II/25] also be clear and distinct, and therefore true. For example, once we know the nature of the circle, and also the nature of the square, we cannot then compound these two and make a square circle, or a square soul, and the like.\n[5] [65] Let us sum up again briefly, and see why we do not need to fear that the fiction will in any way be confused with true ideas. For as for the first [fiction][49](part0013.html#ch1fn85) of which we spoke before, viz. where the thing is clearly conceived, we saw that if that thing that is clearly conceived (and also its existence) is, through itself, an eternal truth, we [10] can feign nothing concerning such a thing. But if the existence of the thing conceived is not an eternal truth, we need only to take care to compare the existence of the thing with its essence, and at the same time attend to the order of Nature.\nAs for the second fiction, we said that it consists in attending at once, without assent, to different confused ideas, which are of different [15] things and actions existing in Nature. We saw also that a most simple thing cannot be feigned, but [only] understood, and also that a composite thing can be understood, provided that we attend to the most simple parts of which it is composed. Indeed we also cannot feign from them any actions that are not true; for at the same time we will be forced to consider how and why such a thing happened.\n[20] [66] With these matters thus understood, let us pass now to the investigation of the false idea so that we may see what it is concerned with, and how we can take care not to fall into false perceptions. Neither of these will be difficult for us now, after our investigation of the fictitious idea. For between fictitious and false ideas there is no [25] other difference except that the latter suppose assent; i.e. (as we have already noted), while the presentations appear to him [who has the false idea], there appear no causes from which he can infer (as he who is feigning can) that they do not arise from things outside him. And this is hardly anything but dreaming with open eyes, or while we are awake. Therefore the false idea is concerned with, or (to put it better) [30] is related to the existence of a thing whose essence is known, or to an essence, in the same way as a fictitious idea.\n[67] [The false idea] that is related to existence is emended in the same way as the fiction. For if the nature of the thing known presupposes necessary existence, it is impossible for us to be deceived concerning the existence of that thing. But if the existence of the thing is not an eternal truth (as its essence is), so that50 its necessity or impossibility [35] of existing depends on external causes, then take everything in [II/26] the same way as we said when we were speaking of fictions. For it may be emended in the same way.\n[68] As for the other kind of false idea, which is related to essences, or also to actions, such perceptions must always be confused, composed [5] of different confused perceptions of things existing in nature—as when men are persuaded that there are divinities in the woods, in images, in animals, etc.; or that there are bodies from whose composition alone the intellect is made; or that corpses reason, walk, and speak; or that God is deceived, and the like. But ideas that are clear [10] and distinct can never be false. For the ideas of things that are conceived clearly and distinctly, are either most simple, or composed of most simple ideas, i.e., deduced from most simple ideas. But that a most simple idea cannot be false, anyone can see—provided that he knows what the true is, or the intellect, and at the same time, what the false is.\n[15] [69] As for what constitutes the form of the true, it is certain that a true thought is distinguished from a false one not only by an extrinsic, but chiefly by an intrinsic denomination. For if some architect conceives a building in an orderly fashion, then although such a building never existed, and even never will exist, still the thought of it is true, [20] and the thought is the same, whether the building exists or not.51 On the other hand, if someone says, for example, that Peter exists, and nevertheless does not know that Peter exists, that thought, in respect to him is false, or, if you prefer, is not true, even though Peter really exists. Nor is this statement, Peter exists, true, except in respect to [25] him who knows certainly that Peter exists.\n[70] From this it follows that there is something real in ideas, through which the true are distinguished from the false. This will now have to be investigated, so that we may have the best standard of truth (for we have said that we must determine our thoughts from the given standard of a true idea, and that method is reflexive knowledge), and [30] may know the properties of the intellect. Nor must we say that this difference arises from the fact that the true thought is knowing things through their first causes.52 In this, indeed, it differs greatly from the false, as I have explained it above. For that Thought is also called true which involves objectively the essence of some principle that does not have a cause, and is known through itself and in itself.\n[35] [71] So the form of the true thought53 must be placed in the same [II/27] thought itself without relation to other things, nor does it recognize the object as its cause, but must depend on the very power and nature of the intellect. For if we should suppose that the intellect had perceived some new being, which has never existed (as some conceive [5] God’s intellect, before he created things—for that perception, of course, could not have arisen from any object), and that from such a perception it deduced others legitimately, all those thoughts would be true, and determined by no external object, but would depend only on the power and nature of the intellect. So what constitutes the form of the [10] true thought must be sought in the same thought itself, and must be deduced from the nature of the intellect.\n[72] To investigate this, therefore, let us consider some true idea, of which we know most certainly that its object depends on our power of thinking, and that it has no object in nature. For it is clear from what has already been said that we shall be able more easily to investigate [15] what we wish to in such an idea. E.g., to form the concept of a sphere, I feign a cause at will, say that a semicircle is rotated around a center, and that the sphere is, as it were, produced by this rotation. This idea, of course, is true, and even though we may know that no sphere in nature was ever produced in this way, nevertheless, this perception is true, and a very easy way of forming the concept of a sphere.\n[20] Now it must be noted that this perception affirms that the semicircle is rotated, which affirmation would be false if it were not joined to the concept of a sphere, or to a cause determining such a motion, or absolutely, if this affirmation were isolated. For then the mind would only tend to affirm of the semicircle nothing but motion, which neither is contained in the concept of the semicircle nor arises from the [25] concept of the cause determining the motion. So falsity consists only in this: that something is affirmed of a thing that is not contained in the concept we have formed of the thing, as motion or rest of the semicircle.\nFrom this it follows that simple thoughts cannot but be true; for example, the simple idea of a semicircle, or of motion, or of quantity, [30] etc. Whatever they contain of affirmation matches their concept, and does not extend itself beyond [the concept]. So we may form simple ideas at will, without fear of error.\n[73] It only remains, then, to ask by what power our mind can form these [simple ideas] and how far this power extends. For once this is [35] discovered, we shall easily see the highest knowledge we can reach. It [II/28] is certain that this power does not extend to infinity. For when we affirm of a thing something not contained in the concept we form of it, that indicates a defect of our perception, or that we have thoughts, [5] or ideas, which are, as it were, mutilated and maimed. For we saw that the motion of a semicircle is false when it is in the mind in isolation, but true if it is joined to the concept of a sphere, or to the concept of some cause determining such a motion. But if it is—as it seems at first54—of the nature of a thinking being to form true, or [10] adequate, thoughts, it is certain that inadequate ideas arise in us only from the fact that we are a part of a thinking being, of which some thoughts wholly constitute our mind, while others do so only in part.\n[74] But we still need to consider something which was not worth [15] the trouble of noting concerning fictions, and which gives rise to the greatest deception—viz. when it happens that certain things that appear in the imagination are also in the intellect, i.e., that they are conceived clearly and distinctly. For then, so long as the distinct is not distinguished from the confused, certainty, i.e., a true idea, is mixed up with what is not distinct.\n[20] For example, some of the Stoics heard, perhaps, the word soul , and also that the soul is immortal, which they only imagined confusedly; they also both imagined and at the same time understood that the most subtle bodies penetrate all others, and are not penetrated by any. Since they imagined all these things at once—while remaining certain of this [25] axiom—they immediately became certain that the mind was those most subtle bodies55 and that those most subtle bodies were not divided, etc.\n[75] But we are freed from this also, as long as we strive to consider all our perceptions according to the standard of a given true idea, being on guard, as we said in the beginning, against those we have from report or from random experience. Moreover, such a deception [30] arises from the fact that they conceive things too abstractly. For it is sufficiently clear through itself that I cannot apply what I conceive in its true object to something else. Finally, it arises also from the fact that they do not understand the first elements of the whole of Nature; so proceeding without order, and confusing Nature with abstractions [35] (although they are true axioms), they confuse themselves and overturn [II/29] the order of Nature. But we shall not need to fear any such deception, if we proceed as far as we can in a manner that is not abstract, and begin as soon as possible from the first elements, i.e., from the source and origin of Nature.56\n[5] [76][57](part0013.html#ch1fn93) But as for knowledge of the origin of Nature, we need not have any fear of confusing it with abstractions. For when things are conceived abstractly (as all universals are), they always have a wider extension in our intellect than their particulars can really have in nature. And then, since there are many things in nature whose difference [10] is so slight that it almost escapes the intellect, it can easily happen, if they are conceived abstractly, that they are confused. But since, as we shall see later, the origin of Nature can neither be conceived abstractly, or universally, nor be extended more widely in the intellect than it really is, and since it has no likeness to changeable things, we [15] need fear no confusion concerning its idea, provided that we have the standard of truth (which we have already shown). For it is a unique and infinitez being, beyond which there is no being.a\n[77] So far we have been speaking of the false idea. It remains now [20] to investigate the doubtful idea—i.e., to ask what are the things that can lead us into doubt, and at the same time, how doubt is removed. I am speaking of true doubt in the mind, and not of what we commonly see happen, when someone says in words that he doubts, although his mind does not doubt. For it is not the business of the Method to emend that. That belongs rather to the investigation of [25] stubbornness, and its emendation.\n[78] There is no doubt in the soul, therefore, through the thing itself concerning which one doubts. That is, if there should be only one idea in the soul, then, whether it is true or false, there will be neither doubt nor certainty, but only a sensation of a certain sort. For in itself [this idea] is nothing but a sensation of a certain sort.\n[30] But doubt will arise through another idea which is not so clear and distinct that we can infer from it something certain about the thing [II/30] concerning which there is doubt. That is, the idea that puts us in doubt is not clear and distinct. For example, if someone has never been led, either by experience or by anything else, to think about the deceptiveness of the senses, he will never doubt whether the sun is larger or smaller than it appears to be. So Country People are generally [5] surprised when they hear that the sun is much larger than the earth. But in thinking about the deceptiveness of the senses, doubt arises. I.e., [the person] knows that his senses have sometimes deceived him, but he knows this only confusedly; for he does not know how the senses deceive.58 And if someone, after doubting, acquires a true knowledge of the senses and of how, by their means, things at a [10] distance are presented, then the doubt is again removed.\n[79] From this it follows that, only so long as we have no clear and distinct idea of God, can we call true ideas in doubt by supposing that perhaps some deceiving God exists, who misleads us even in the things most certain. I.e., if we attend to the knowledge we have concerning [15] the origin of all things and do not discover—by the same knowledge we have when, attending to the nature of the triangle, we discover that its three angles equal two right angles—anything that teaches us that he is not a deceiver [NS:, then the doubt remains]. But if we have the kind of knowledge of God that we have of the triangle, then all [20] doubt is removed. And just as we can arrive at such a knowledge of the triangle, even though we may not know certainly whether some supreme deceiver misleads us, so we can arrive at such a knowledge of God, even though we may not know whether there is some supreme deceiver. Provided we have that knowledge, it will suffice, as I have [25] said, to remove every doubt that we can have concerning clear and distinct ideas.\n[80] Further, if someone proceeds rightly, by investigating [first] those things which ought to be investigated first, with no interruption in the connection of things, and knows how to define problems precisely,59 before striving for knowledge of them, he will never have anything but the most certain ideas—i.e., clear and distinct ideas. For [30] doubt is nothing but the suspension of the mind concerning some affirmation or negation, which it would affirm or deny if something did not occur to it, the ignorance of which must render its knowledge of the thing imperfect. From this it is [to be] inferred that doubt always arises from the fact that things are investigated without order.\n[35] [81] These are the matters I promised to discuss in this first part of [II/31] the Method. But to omit nothing that can lead to knowledge of the intellect and its powers, I shall say a few words about memory and forgetting. The most important consideration is that memory is strengthened both with the aid of the intellect and also without its aid. [5] For regarding the first, the more intelligible a thing is, the more easily it is retained; and conversely, the less intelligible, the more easily forgotten. E.g., if I give someone a large number of disconnected words, he will retain them with much more difficulty than if I give him the same words in the form of a story.\n[82] It is also strengthened without the aid the intellect, by the force [10] with which the imagination, or what they call the common sense, is affected by some singular corporeal thing. I say singular , for the imagination is affected only by singular things. If someone, e.g., has read only one Comedy,60 he will retain it best so long as he does not read several others of that kind, for then it will flourish in isolation in the [15] imagination. But if there are several of the same kind, we imagine them all together and they are easily confused. I say also corporeal , for the imagination is affected only by bodies. Therefore since the memory is strengthened both by the intellect and also without the intellect, we may infer that it is something different from the intellect, and that concerning the intellect considered in itself there is neither memory nor forgetting.\n[20] [83] What, then, will memory be? Nothing but a sensation of impressions on the brain, together with the thought of a determinate durationd of the sensation, which recollection also shows. For there the soul thinks of that sensation, but not under a continuous duration. And so the idea of that sensation is not the duration itself of the sensation, [25] i.e., the memory itself. But whether the ideas themselves undergo some corruption, we shall see in [my] Philosophy.\nIf this seems quite absurd to anyone, it will suffice for our purpose if he thinks that the more singular a thing is, the more easily it may be retained, as the example of the Comedy just mentioned makes clear. [II/32] Further, the more intelligible a thing is, the more easily it too is retained. So we cannot but retain a thing that is most singular if only it is also intelligible.\n[84] In this way, then, we have distinguished between a true idea [5] and other perceptions, and shown that the fictitious, the false, and the other ideas have their origin in the imagination, i.e., in certain sensations that are fortuitous, and (as it were) disconnected; since they do not arise from the very power of the mind, but from external causes, as the body (whether waking or dreaming) receives various motions.\n[10] But if you wish, take imagination any way you like here, provided it is something different from the intellect, and in which the soul has the nature of something acted on. For it is all the same, however you take it, after we know that it is something random, by which the soul is acted on, and at the same time know how we are freed from it with the help of the intellect. So let no one be surprised that here, where I [15] have not yet proved that there is a body, and other necessary things, I speak of the imagination, the body and its constitution. For as I have said, it does not matter what I take it to be, after I know that it is something random, etc.62\n[85] We have shown that a true idea is simple, or composed of [20] simple ideas; that it shows how and why something is, or has been done; and that its objective effects proceed in the soul according to the formal nature of its object. This is the same as what the ancients said, i.e., that true knowledge proceeds from cause to effect—except that so far as I know they never conceived the soul (as we do here) as acting [25] according to certain laws, like a spiritual automaton.\n[86] From this we have acquired as much knowledge of our intellect as was possible in the beginning, and such a standard of the true idea that now we do not fear confusing true ideas with false or fictitious ones. Nor will we wonder why we understand certain things that do [30] not fall in any way under the imagination, why there are some things in the imagination which are completely opposed to the intellect, and finally why there are others that agree with the intellect; for we know that those activities by which imaginations are produced happen according to other laws, wholly different from the laws of the intellect, and that in imagination the soul only has the nature of something acted on.\n[35] [87] From this it is also established how easily they can fall into [II/33] great errors, who have not accurately distinguished between imagination and intellection. Such errors as: that extension must be in a place, that it must be finite, that its parts must be really distinguished from one another, that it is the first and only foundation of all things, [5] that it occupies more space at one time than at another, and many other things of the same kind, all of which are completely opposed to the truth, as we shall show in the proper place.\n[88] Next, since words are part of the imagination, i.e., since we feign many concepts, in accordance with the random composition of [10] words in the memory from some disposition of the body, it is not to be doubted that words, as much as the imagination, can be the cause of many and great errors, unless we are very wary of them.\n[89] Moreover, they are established according to the pleasure and power of understanding of ordinary people, so that they are only signs of things as they are in the imagination, but not as they are in the [15] intellect. This is clear from the fact that the names given to things that are only in the intellect, and not in the imagination, are often negative (for example, infinite, incorporeal, etc.), and also from the fact that they express negatively many things that are really affirmative, and conversely (for example, uncreated, independent, infinite, [20] immortal). Because the contraries of these are much more easily imagined, they occurred first to the earliest men, and they used positive names. We affirm and deny many things because the nature of words—not the nature of things—allows us to affirm them. And in our ignorance of this, we easily take something false to be true.\n[25] [90] We avoid, moreover, another great cause of confusion which prevents the intellect from reflecting on itself—viz. when we do not distinguish between imagination and intellection, we think that the things we more easily imagine are clearer to us, and think we understand what we imagine. Hence, what should be put later we put first, [30] and so the true order of making progress is overturned, and no conclusion is arrived at legitimately.\n[91][e](part0013.html#ch1fn101) To arrive finally at the second part of this Method, I shall set [II/34] forth first our aim in this Method, and then the means to attain it. The aim, then, is to have clear and distinct ideas, i.e., such as have been made from the pure mind, and not from fortuitous motions of the body. And then, so that all ideas may be led back to one, we shall [5] strive to connect and order them so that our mind, as far as possible, reproduces objectively the formal character of nature, both as to the whole and as to the parts.\n[92] As for the first, our ultimate end requires (as we have already said) that the thing be conceived either through its essence alone or [10] through its proximate cause. If the thing is in itself, or , as is commonly said, is the cause of itself, then it must be understood through its essence alone; but if it is not in itself, but requires a cause to exist, then it must be understood through its proximate cause. For really, knowledgef of the effect is nothing but acquiring a more perfect knowledge of its cause.\n[15] [93] Therefore, so long as we are dealing with the Investigation of things, we must never infer anything from abstractions, and we shall take very great care not to mix up the things that are only in the intellect with those that are real. But the best conclusion will have to be drawn from some particular affirmative essence, or , from a true and [20] legitimate definition. For from universal axioms alone the intellect cannot descend to singulars, since axioms extend to infinity, and do not determine the intellect to the contemplation of one singular thing rather than another.\n[94] So the right way of discovery is to form thoughts from some given definition. This will proceed the more successfully and easily, [25] the better we have defined a thing. So the chief point of this second part of the Method is concerned solely with this: knowing the conditions of a good definition, and then, the way of finding good definitions. First, therefore, I shall deal with the conditions of definition.\n[95] To be called perfect, a definition will have to explain the inmost [30] essence of the thing, and to take care not to use certain propria in its place. So as not to seem bent on uncovering the errors of others, I shall use only the example of an abstract thing to explain this. For it [II/35] is the same however it is defined. If a circle, for example, is defined as a figure in which the lines drawn from the center to the circumference are equal, no one fails to see that such a definition does not at all explain the essence of the circle, but only a property of it. And though, as I have said, this does not matter much concerning figures and other [5] beings of reason, it matters a great deal concerning Physical and real beings, because the properties of things are not understood so long as their essences are not known. If we neglect them, we shall necessarily overturn the connection of the intellect, which ought to reproduce the connection of Nature, and we shall completely miss our goal.\n[10] [96] These are the requirements which must be satisfied in Definition, if we are to be free of this fault:\n1. If the thing is created, the definition, as we have said, will have to include the proximate cause. E.g., according to this law, a circle would have to be defined as follows: it is the figure that [15] is described by any line of which one end is fixed and the other movable. This definition clearly includes the proximate cause.63\n2. We require a concept, or definition, of the thing such that when it is considered alone, without any others conjoined, all the thing’s properties can be deduced from it (as may be seen in this definition [20] of the circle). For from it we clearly infer that all the lines drawn from the center to the circumference are equal.\nThat this is a necessary requirement of a definition is so plain through itself to the attentive that it does not seem worth taking time to demonstrate it, nor to show also, from this second requirement, that every definition must be affirmative.\n[25] I mean intellectual affirmation—it matters little whether the definition is verbally affirmative; because of the poverty of language it will sometimes, perhaps, [only] be able to be expressed negatively, although it is understood affirmatively.\n[97] These are the requirments for the definition of an uncreated thing:\n1. That it should exclude every cause, i.e., that the object should [30] require nothing else except its own being for its explanation.64\n2. That, given the definition of this thing, there should remain no room for the Question—does it exist?\n3. That (as far as the mind is concerned) it should have no substantives that could be changed into adjectives, i.e., that it should not be explained through any abstractions.\n[35] 4. Finally (though it is not very necessary to note this) it is required [II/36] that all its properties be inferred65 from its definition.\nAll these things are evident to those who attend to them accurately.\n[98] I have also said that the best conclusion will have to be drawn from a particular affirmative essence. For the more particular an idea [5] is, the more distinct, and therefore the clearer it is. So we ought to seek knowledge of particulars as much as possible.\n[99] As for order, to unite and order all our perceptions, it is required, and reason demands,66 that we ask, as soon as possible, whether there is a certain being, and at the same time, what sort of being it is, [10] which is the cause of all things, so that its objective essence may also be the cause of all our ideas, and then our mind will (as we have said)67 reproduce Nature as much as possible. For it will have Nature’s essence, order, and unity objectively.\nFrom this we can see that above all it is necessary for us always to [15] deduce all our ideas from Physical things, or from the real beings, proceeding, as far as possible, according to the series of causes, from one real being to another real being, in such a way that we do not pass over to abstractions and universals, neither inferring something real from them, nor inferring them from something real. For to do [20] either interferes with the true progress of the intellect.\n[100] But note that by the series of causes and of real beings I do not here understand the series of singular, changeable things, but only the series of fixed and eternal things. For it would be impossible for human weakness to grasp the series of singular, changeable things, not [25] only because there are innumerably many of them, but also because of the infinite circumstances in one and the same thing, any of which can be the cause of its existence or nonexistence. For their existence has no connection with their essence, or (as we have already said) is not an eternal truth.\n[30] [101] But there is also no need for us to understand their series. The essences of singular, changeable things are not to be drawn from their series, or order of existing, since it offers us nothing but extrinsic denominations, relations, or at most, circumstances, all of which are [35] far from the inmost essence of things. That essence is to be sought [II/37] only from the fixed and eternal things, and at the same time from the laws inscribed in these things, as in their true codes, according to which all singular things come to be, and are ordered. Indeed these singular, changeable things depend so intimately, and (so to speak) essentially, on the fixed things that they can neither be nor be conceived [5] without them. So although these fixed and eternal things are singular, nevertheless, because of their presence everywhere, and most extensive power, they will be to us like universals, or genera of the definitions of singular, changeable things, and the proximate causes of all things.\n[10] [102] But since this is so, there seems to be a considerable difficulty in our being able to arrive at knowledge of these singular things. For to conceive them all at once is a task far beyond the powers of the human intellect. But to understand one before the other, the order must be sought, as we have said, not from their series of existing, nor [15] even from the eternal things. For there, by nature, all these things are at once. So other aids will have to be sought beyond those we use to understand the eternal things and their laws.\nNevertheless, this is not the place to treat them, nor is it necessary until after we have acquired a sufficient knowledge of the eternal things [20] and their infallible laws, and the nature of our senses has become known to us. [103] Before we equip ourselves for knowledge of singular things, there will be time to treat those aids, all of which serve to help us know how to use our senses and to make, according to certain laws, and in order, the experiments that will suffice to determine [25] the thing we are seeking, so that at last we may infer from them according to what laws of eternal things it was made, and its inmost nature may become known to us, as I shall show in its place.68\nHere, to return to our theme, I shall only try to treat those things that seem necessary for us to be able to arrive at knowledge of eternal things, and for us to form their definitions according to the conditions [30] laid down above. [104] To do this, we must recall what we said above:69 when the mind attends to a thought—to weigh it, and deduce from it, in good order, the things legitimately to be deduced from it—if it is false, the mind will uncover the falsity; but if it is true, the mind will [35] continue successfully, without any interruption, to deduce true things [II/38] from it. This, I say, is required for our purpose. For our thoughts cannot be determined from any other foundation.70 [105] If, therefore, we wish to investigate the first thing of all, there must be some foundation that directs our thoughts to it.\n[5] Next, because Method is reflexive knowledge itself, this foundation, which must direct our thoughts, can be nothing other than knowledge of what constitutes the form of truth, and knowledge of the intellect, and its properties and powers. For once we have acquired this [knowledge], we shall have the foundation from which we shall deduce our [10] thoughts and the way by which the intellect, according to its capacity, will be able to reach the knowledge of eternal things, with due regard, of course, to its own powers.\n[106] But if forming true ideas pertains to the nature of thought, as shown in the first part, here we must investigate what we understand [15] by the powers of the intellect. Since the chief part of our Method is to understand as well as possible the powers of the intellect, and its nature, we are necessarily forced, by what I have taught in this second part of the Method, to deduce these from the very definition of thought and intellect.\n[107] But so far we have had no rules for discovering definitions. [20] And because we cannot give them unless the nature, or definition, of the intellect, and its power are known, it follows that either the definition of the intellect must be clear through itself, or else we can understand nothing. It is not, however, absolutely clear through itself; but because its properties (like all the things we have from intellect) [25] cannot be perceived clearly and distinctly unless their nature is known, if we attend to the properties of the intellect that we understand clearly and distinctly, its definition will become known through itself. We shall, therefore, enumerate the properties of the intellect here, and consider them, and begin to deal with out innate tools.g\n[30] [108] The properties of the intellect which I have chiefly noted, and understand clearly, are these:\n1. That it involves certainty, i.e., that the intellect knows that things are formally as they are contained objectively in itself.\n2. That it perceives certain things, or forms certain ideas, absolutely, [II/39] and forms certain ideas from others. For it forms the idea of quantity absolutely, without attending to other thoughts, but it forms the ideas of motion only by attending to the idea of quantity.\n3. Those that it forms absolutely express infinity, but determinate [5] ideas it forms from others. For if it perceives the idea of a quantity through a cause, then it determines [that idea] through [the idea] of a quantity,71 as when it perceives that a body arises from the motion of some plane, a plane from the motion of a line, and finally, a line from the motion of a point. These perceptions do not help to understand the quantity, but only to determine it. [10] This is evident from the fact that we conceive them as arising from the motion, although the motion is not perceived unless the quantity is perceived, and also because we can continue the motion to form a line to infinity, which we could not do at all, if we did not have the idea of infinite quantity.\n[15] 4. It forms positive ideas before negative ones.\n5. It perceives things not so much under duration as under a certain species of eternity, and in an infinite number—or rather, to perceive things, it attends neither to number nor to duration; but when it imagines things, it perceives them under a certain [20] number, determinate duration and quantity.\n6. The clear and distinct ideas that we form seem to follow so from the necessity of our nature alone that they seem to depend absolutely on our power alone. But with confused ideas it is quite the contrary—they are often formed against our will.\n[25] 7. The mind can determine in many ways the ideas of things that the intellect forms from others—as, for example, to determine the plane of an ellipse, it feigns that a pen attached to a cord is moved around two centers, or conceives infinitely many points always having the same definite relation to some given straight line, or a [30] cone cut by some oblique plane, so that the angle of inclination is greater than the angle of the cone’s vertex, or in infinite other ways.\n8. The more ideas express of the perfection of some object, the more perfect they are. For we do not admire the architect who has designed a chapel so much as one who has designed a notable [35] temple.\n[II/40] [109] I shall not linger over the other things that are referred to thought, such as love, joy, etc. For they contribute nothing to our present purpose, nor can they be conceived unless the intellect is perceived. For if perception is altogether taken away, then all these are taken away.\n[5] [110] False and fictitious ideas have nothing positive (as we have shown abundantly) through which they are called false or fictitious, but they are considered as such only from a defect of our knowledge. So false and fictitious ideas, as such, can teach us nothing concerning the essence of thought. It is rather to be sought from the positive [10] properties just surveyed, i.e., we must now establish something common from which these properties necessarily follow, or such that when it is given, they are necessarily given, and when it is taken away, they are taken away.\nThe rest is lacking.\n1 Spinoza describes his opusculum as being devoted to the question “how things began to be and by what connection they depend on the first cause … and also on the emendation of the intellect.” This strongly suggests that our TdIE was part of the opusculum. But Mignini has cast doubt on this. See the annotation at IV/36/13.\n2 I would be inclined to say earlier than Letter 2 at least, i.e., before September 1661, for reasons suggested in the annotation at II/9/12. Cf. Mignini 2, 106. If, as Mignini thinks, the TdIE is earlier than the KV, and if, as he also thinks, the first draft of the KV was written around the middle of 1660 (see Mignini 1, 239), then the TdIE would have been written a good deal earlier than the spring of 1662.\n3 Notably II/29, n. z. On the other hand, some of the things promised in the forward references do not appear in our version of the KV any more than they do in E, e.g., the extended discussion of wealth foreshadowed in II/6, n. a.\n4 Mignini contends that the teaching of the KV is closer to that of E than is the teaching of the TdIE in regard to the following topics: the nature of the intellect and the doctrine of method, the theory of the kinds of knowledge, the nature of fictions, the will, final causation and perfection. This is not the place for a discussion of his arguments, but I will observe that my own attempt to study the development of Spinoza’s thought about truth (Curley 9), an attempt made before I was aware of Mignini’s work, would have proceeded more smoothly had I adopted his chronology.\n5 This, essentially, is the judgment of M. Matheron, in a recent review of Mignini’s work (Bulletin de l’Association des Amis de Spinoza , no. 10, 1983): “Si les arguments positifs avancés par Mignini, bien qu’ils donnent beaucoup à penser, ne sont peut-être tout à fait convaincants (personellement j’avoue hésiter encore sur ce point), ses arguments négatifs, en revanche, sont décisifs: nous admettions tous comme allant de soi, parce qu’on nous l’avait enseigné, que le C.T.[i.e., KV] était antérieur au TRE [i.e., TdIE], et Mignini démontre qu’il n’y avait à cela absolument aucune raison!”\n6 See Joachim 2, 59, and cf. Mignini 2, 140. Joachim construes this as a survival of Cartesian doctrines advocated in the KV. Mignini, it seems, regards it as evidence of the priority of the TdIE to the KV. I myself am not satisfied with the evidence that Spinoza adopts the Cartesian distinction between will and intellect either in the TdIE or in the KV. For example, it seems to me that § 78 of the TdIE effectively anticipates Spinoza’s critique of the Cartesian doctrine of suspense of judgment in E IIP49S. And I take it that KV II, xiv, also criticizes the Cartesian distinction, though on different grounds.\n7 See the annotation at II/9/12.\n8 See Curley 2; cf. Joachim 2, 24-33.\n9 Cf. Joachim 2, 89-90.\n10 So Joachim argues at any rate. Cf. Joachim 2, 102-111.\n1 By the editors of the Opera posthuma.\n2 The translation of this title is disputed. The Latin for the main title is Tractatus de Intellectus Emendatione , the Dutch Handeling van de Verbetering van’t Verstant. Joachim (2, 1) argued that no English term could reproduce the exact implications of the Latin, but recommended “Purification of the Intellect” as rightly suggesting a project of restoring the intellect to its “natural perfection, by eliminating from it … ideas which are not its own but have come to it from an external source.” DeDeugd’s criticism of Joachim (1, 50-57), while rightly pointing out that the Dutch version cannot plausibly bear that meaning, gives insufficient weight to § 16. Eisenberg (3) argues that no term can reproduce the exact implications of the Latin, since Spinoza’s phrase has no exact implications. At the time of writing this work Spinoza inconsistently conceived of the intellect both as inherently pure and as needing purification. He did not clearly distinguish between the mind, which cannot be entirely freed of external influences, and the intellect, which has no need to be. No translation will solve such difficulties.\nThe subtitle in the NS reads: “and at the same time of the means of making it perfect.”\na I could explain this more fully and distinctly, by distinguishing wealth that is sought for its own sake, or for the sake of honor, or for the sake of sensual pleasure or for the sake of health and the advancement of the arts and sciences. But I reserve this for its own place; such an exact investigation is not appropriate here.\n3 The choice of this particular trinity is probably influenced by Aristotle. Cf. the Nicomachean Ethics I, 4, and the Short Treatise II, v, 6.\n4 “ Modò possem penitùs deliberare.” Deliberare can mean ‘ to deliberate ’ and most translators have given us something like “If only I could reflect thoroughly [on the matter].” But deliberare can also mean ‘to decide as a consequence of deliberation’ and I follow Koyré in thinking that to be the meaning here. When Spinoza comments on this phrase in § 10 it seems clear that he thinks of his difficulty as more volitional than intellectual. Cf. E IVP14.\nb These things are to be demonstrated more accurately.\n5 The NS has: “often cause the destruction of those who possess them (if one may speak thus), and always of those who are possessed by wealth.” It seems likely that the parenthesis is an addition by the translator and bears on the notion of being possessed by wealth.\n6 OP: “Sed amor erga rem aeternam, & infinitam solâ laetitiâ pascit animum, ipsaque omnis tristitiae est expers”; NS: “Maar de liefde tot d’eeuwige en oneindige zaak voed de geest [margin: mens] met blÿschap alleen, en is van alle droefheit uitgesloten.” The translation of this important passage is disputed. Joachim (2, 18, n.4) notes that various translators have rendered it as if it were the love that was exempt from sadness (which makes the Latin ungrammatical, but is what the Dutch implies). He, however, sees here a foreshadowing of the doctrine that God is exempt from sadness. (I.e., ipsa refers not to amor , but the eternal and infinite thing.) This is possible, both grammatically and philosophically, but Joachim surely goes too far when he contends that this interpretation is necessary to explain why love for God feeds the mind with unmixed joy. Appuhn, Koyré, and Caillois all take ipsa to refer to laetitia , an alternative Joachim does not discuss, and to my mind the one most likely.\n7 “ Modò possem seriò deliberare.” In referring back to II/6/21 Spinoza does not in fact quote himself exactly.\n8 Wendel and Cassirer thought it necessary to emend this passage so that it would read: “man conceives a nature much stronger than his own human nature.” But I find Gebhardt’s arguments against this conclusive (II/322-323). The text as it stands is supported by the NS and paralleled by passages both in the Short Treatise (II,4; I/60/21ff.) and the Ethics (IV, Pref., II/208). Koyré (2, 98-99) is right to remark that the passage is a difficult one on any reading, but his comments do not seem to me to stress sufficiently the necessity both of man’s conceiving such a stronger nature and of his striving to attain it.\nc These things will be explained more fully in their place.\nd Note that here I take the trouble only to enumerate the sciences necessary for our purpose, without attending to their order.\ne In the sciences there is only one end, toward which they must all be directed.\n9 If this is taken, as it may be, to mean “knowledge that man is a part of nature, and subject to its universal laws,” then the doctrine is very Stoic. Cf. Marcus Aurelius, Meditations , VII, 9-13; X,6. But the passage is also one which, more than any other perhaps, encourages the interpretation of Spinoza as a mystic.\n10 That the intellect requires purification (expurgatio) is a Baconian doctrine. Cf. the Novum Organum (Bacon, I, 139 = IV, 27). For healing (medendi) the NS has simply “improving” (verbeteren). Eisenberg (3, 175) argues that passages like this one are symptomatic of a tendency to confuse the intellect with the mind “at least during much of the time that he wrote the treatise.” And since, in Letter 2 (IV/8-9), Spinoza is quite critical of Bacon for not distinguishing the intellect from the mind, and for supposing that the intellect is deceived by its own nature, it seems likely that, by the time of writing that letter (September 1661), Spinoza would have regarded passages like this as unsatisfactory. Note that in that letter Spinoza criticizes Bacon for comparing the intellect to an uneven mirror (cf. Bacon, I, 164). A similar comparison occurs in the purification of the intellect passage cited above, except that there it is the mind that is compared to an uneven mirror. See also Mignini 2, 106.\n11 Latin: “ intellectum … redigamus.” NS: “ het verstant … te brengen.” But the language of purification in the preceding paragraph seems to justify the suggestion of returning to an original state of rectitude.\n12 NS: “ zuiveren ,” purify.\n13 NS: “ three ”; but it goes on to enumerate four kinds, as the OP does. Gebhardt thought this might naturally be explained on the assumption that in an earlier draft of the Treatise Spinoza had divided the kinds of ‘knowledge’ into three (as in the Short Treatise and the Ethics) rather than four. He also took it as evidence that the Dutch translation was made, not from the text of the Opera posthuma , but from an independent, earlier manuscript, in which revisions were not consistently carried out. For counter-argument see Mignini 2, 126-127.\n14 On the translation here, and on the classification generally, see Joachim 2, 24-33, and Curley 2, 25-59.\n15 As Joachim notes, this passage echoes one in Bacon, Novum Organum I, 100 (Bacon, I,203 [= IV, 95]). He also calls attention to aphorisms 25, 70, and 105. Perhaps Bacon’s influence is also to be seen in Descartes’ Regulae , AT X, 427.\nf When this happens, we understand nothing about the cause except what we consider in the effect. This is sufficiently evident from the fact that then the cause is explained only in very general terms, e.g., Therefore there is something, Therefore there is some power, etc. Or also from the fact that the terms express the cause negatively, Therefore it is not this, or that, etc. In the second case something clearly conceived is attributed to the cause on account of the effect, as we shall show in an example; but nothing is attributed to it except propria , not the essence of a particular thing.16\n16 OP: “In secundo casu aliquid causae tribuitur propter effectum, quod clarè conciptur, ut in exemplo ostendimus; verùm nihil praeter propria, non verò rei essentia particularis.” This note has more than its share of difficulties. (1) What does in secundo casu refer to? Eisenberg suggests that it could be translated “in a (more) favorable case,” adding a third case to the two already mentioned in the note, but neither he nor I thinks it very likely. Or it could be translated as I have it and refer to the case described in the immediately preceding sentence. But this does not make much sense of the note. Or it could refer to the second case mentioned in the text, in spite of the fact that the note as a whole is attached to the first disjunct. I opt for the third alternative. (2) What is the antecedent of quod clare concipitur? Eisenberg thinks it is obviously effectus , in spite of the gender difficulties. I follow Joachim in taking it to be aliquid. (3) What does particularis modify? Most translators have favored essentia. I follow the NS (along with Joachim and Eisenberg) in making it modify rei , though grammar is neutral on the question. See also the note on proprium in the English-Latin-Dutch section of the Glossary-Index.\n17 OP: “vel cùm concluditur ab aliquo universali, quod semper aliqua proprietas concomitatur”; the NS in effect supplies causa as the subject of concluditur : “when one infers the cause from some universal which is always accompanied by some property.” Elwes takes the quod clause as subject: “when it is inferred from some general proposition that some property is always present.” Koyré has: “when one draws a conclusion from the fact that a universal is always accompanied by a certain property.” Interpreting Spinoza’s note f as I do, I would say that the something which is inferred is a clearly conceived property of a cause, though this is inconsistent with the general description of this kind of knowledge at II/10/16. I am not much moved by the latter consideration, since the second example given in § 21 is also inconsistent with the general description. See the discussions in Joachim 2, 30-32, and Curley 2, 40-49.\ng We see clearly from this example what I have just noted. For we understand nothing through that union except the sensation itself, that is, the effect,19 from which we inferred the cause, concerning which we understand nothing.\nh Although such a conclusion is certain, it is still not sufficiently safe, unless we take the greatest care. For those who do not take such care will immediately fall into errors. When things are conceived so abstractly, and not through their true essence, they are immediately confused by the imagination. What in itself is one, men imagine to be many. For to the things they conceive abstractly, separately, and confusedly, they give names which they use to signify other more familiar things. Hence they imagine these things in the same way as they are accustomed to imagine the things to which the names were first given.\n18 I follow Appuhn, Koyré et al., in supplying “one thing” here; parallelism with II/10/16 would require the “essence of a thing,” but the strict accuracy of that description is put in some doubt both by the second example Spinoza gives and by his note to II/10/17.\n19 OP: effectus , which is ungrammatical, given seventeenth-century conventions about the use of accents. Gebhardt emends to: effectûs , “of the effect.” But most translators have preferred to emend to effectum , which is supported by the NS, and which I take to be correct.\n20 Cf. § 78.\n21 OP: “ quales ,” ‘what kind of;’ but NS: welke. Cf. Joachim 2, 31, n. 2.\n22 Here I adopt Joachim’s emendation of the numbering and punctuation. Joachim 2, 34, n 2.\n23 OP: “ singularis existentia alicujus rei.” As at II/10/34, this is ambiguous. Here the NS take singularis to modify existentia , but wrongly, I think.\ni Here I shall discuss experience somewhat more fully, and examine the Method of proceeding of the Empiricists and of the new Philosophers [NS: … the Empiricists, who want to do everything through experience …].\n24 OP: “ illius ,” NS: “ enige.” Perhaps we should read: ullius , ‘any’.\n25 The comparison which follows may have been suggested by any of various passages in Bacon [e.g., I, 126 (= IV, 14); I, 152 (= IV, 40); I, 157 (= IV, 47)]. But as Joachim notes (2, 53), Spinoza makes a rather different use of the comparison. Similar remarks apply to a passage in Descartes’ Regulae (AT X, 397). Neither Bacon nor Descartes uses the analogy to counter a threatened regress.\nk By inborn power I understand what is not caused in us by external causes. I shall explain this afterwards in my Philosophy.\nl Here they are called works. In my Philosophy, I shall explain what they are.\nm Note that here we shall take care to show not only what we have just said, but also that we have so far proceeded rightly, and at the same time other things that it is quite necessary to know.\n26 Spinoza does seem to mean that these inborn tools are needed only provisionally, until better ones can be made with them, though as Joachim remarks (2, 54, n. 1) this is obscure. Other translators (e.g., Appuhn, Koyré) take Spinoza to mean that these inborn tools are all the intellect requires to make more advanced ones.\n27 NS: “The true idea.” But I take it that this must be a generalizing use of the definite article, since no basis has been laid for reference to any particular true idea (or for any assumption that, ultimately, there is only one true idea).\n28 Joachim (2, 54, n. 2, 80, n. 1) contends that by a “true idea of Peter” Spinoza here means the true idea which someone else may have of Peter. The example Spinoza gives at the end of this paragraph seems to confirm this.\nn Note that here we are not asking how the first objective essence is inborn in us. For that pertains to the investigation of nature, where we explain these things more fully, and at the same time show that apart from the idea there is neither affirmation, nor negation, nor any will.\no In my Philosophy, I shall explain what seeking is in the soul.\n29 OP: “ modus, quo sentimus essentiam formalem.” It is unclear whether modus should be taken as a technical term here.\n30 Perhaps, as Joachim suggests (2, 162, n. 4), we should read et for aut here: “Reasoning and intellection.”\n31 OP: “ datae verae ideae ”; NS: “ ’ t gestelde ware denkbeelt.” Koyré argues that the term datae in this kind of expression is best suppressed, since it does not imply what it is likely to suggest, viz. that the true idea is given to us. All that is implied is that there is a true idea. Gueroult (1, 1:30, n. 42) argues against this that the qualification implies that the true idea is an actual eternal essence in the infinite or finite intellect, and hence produced by God, not by the intellect. Man finds the Idea “en lui sans lui.” Although uncertain of the correctness of Gueroult’s interpretation, I find it impossible to follow Koyré’s policy, which seems to lead to serious difficulty in contexts like § 43.\np To interact with other things is to produce, or be produced by, other things.\n32 The NS version of this sentence runs: “If there were something in nature that did not interact with other things, then its objective essence, which would have to agree completely with the formal essence, would also not interact with other ideas, i.e., we would not be able to understand or infer anything about it.” I have translated the Latin (as emended by Gebhardt to correct a grammatical mistake); Gebhardt thinks it obvious that the conditionalization of the reference to the objective essence is a change made by Spinoza after the Dutch translation was done. But I share Joachim’s feeling (2, 100, n. 2) that the Dutch makes better sense. Gebhardt also adds a phrase in l. 31 from the Dutch, so that the conclusion of the sentence might be translated: “we could neither understand nor infer.…” But it is very unlikely that this indicates an earlier and fuller version of the text. Probably it represents nothing more than the use of two Dutch verbs to render one Latin one.\n33 OP: “ ut mens nostra omninò referat Naturae exemplar.” It is difficult to be confident about the translation of this clause. Joachim (2, 100) offers: “that our mind may reflect ideally in all respects its real Original—i.e., may reflect the formal essence of Nature in its totality and in all its parts,” drawing on § 91 for the gloss. As Joachim points out later (215, n. 1) this passage is prima facie incompatible with his interpretation of Spinoza’s conception of truth.\nq As we also do not here doubt the truth we possess.\n34 I believe § 104 provides a helpful gloss on this passage.\n35 There is no negation in either the OP or the NS, but most editors have felt the need to supply one. If one is supplied, then it seems we must also assume a gap in the text after “I reply to him.” Koyré understands the text in this fashion, and conjectures that Spinoza eventually came to regard the objection as well-founded, so that he concentrated on the Ethics and put the Treatise to one side (cf. his note to this passage, and the Avant-propos).\nGebhardt at one stage thought likewise, but by the time he produced his edition of the Works had come to the conclusion that the text must be defended, not emended (II/326-327). He takes Spinoza to be replying not to an objection to his procedure here, but to an objection to his procedure in his projected Philosophy. Eisenberg (1, 45-49, n. 82) joins Gebhardt in defending the text.\nI prefer Koyré’s reading. I cannot deal fully here with the arguments offered by Gebhardt and Eisenberg, but I will make the following observations: (1) the text of the OP is supported by the NS, but if the conjectured omissions were in Spinoza’s ms., this confirmation does not amount to much; quite possibly the ms. contained a passage which Spinoza struck out and never replaced; (2) I do not see why the emendation would make § 46 a mere duplication of II/17/8-34; (3) if Spinoza were switching suddenly from a defense of his procedure in the TdIE to a defense of his procedure in his Philosophy , I would expect a more explicit indication of it; (4) Eisenberg construes ostenderim in II/18/2 as a future perfect (indicative): “If anyone should seek [perhaps] to know why I shall have shown the truths of Nature in that order at once, before everything.…” But both morphology and syntax require us to construe it as present perfect subjunctive. And the concluding line of the paragraph (in which Eisenberg construes praemiserim as present perfect subjunctive) makes it clear that Spinoza intends to defend what he has already done.\nr See further what we shall note concerning hypotheses that we clearly understand; but the fiction consists in our saying that such as these exist in the heavenly bodies.\n36 OP: “ somnum ,” but NS: “ dromen.” So probably we should read: somnium.\n37 NS: “ eerste/prima.” So perhaps Spinoza originally wrote: “first cause.”\n38 Gebhardt adds the phrase “in existing” from the NS, but I agree with Joachim (2, 116, n. 2) that this is at least unnecessary, if not wrong. Similarly Gebhardt’s addition at II/19/1 seems wrong given that Spinoza goes on (both in the OP and in the NS) to enumerate a fourth task of the method. His text would be translated: “Third [NS: and finally]”.…\ns Because the thing makes itself evident, provided it is understood, we require only an example, without other proof. The same is true of its contradictory—it need only be examined for its falsity to be clear. This will be plain immediately, when we speak of fictions concerning essence.\nt Note. Although many say that they doubt whether God exists, nevertheless they have nothing but the name, or they feign something which they call God; this does not agree with the nature of God, as I shall show later in the proper place.\nu By an eternal truth I mean one, which, if it is affirmative, will never be able to be negative. Thus it is a first and eternal truth that God is ; but that Adam thinks is not an eternal truth. That there is no Chimera is an eternal truth; but not that Adam does not think.\n39 Joachim (ibid.) suggests reading essentia , though the OP’s existentia is supported by the NS. If it were not for the immediately following phrase (ipsâ suâ naturâ), I would think this almost certainly correct. I have translated the Latin as it stands, but (with Eisenberg) I feel certain that what Spinoza means is that the essence of the thing by itself does not entail either that the thing cannot, or that it must, exist.\n40 The text of the OP would be translated: “From this it follows that, if there is a God, or something omniscient, we (nos) can feign nothing at all.” Since this makes very little sense, earlier editors and translators often supplied a phrase to fill it out: “we can feign nothing at all about it.” Gebhardt’s text, which I have translated, reads eum for nos , following the NS. Slightly preferable, perhaps, would be van Vloten and Land’s hoc (= this being) for nos. Textual emendation is a dangerous game, but if anything in this area is certain, we can be sure that the text of the OP is corrupt. For a full discussion see Gebhardt (II/328-330) or Eisenberg 2, 56-60. Eisenberg gives a clear explanation of the thought: since hypotheses concern only the possible (i.e., things whose existence or nonexistence depends on causes unknown to us), a being to whom nothing was unknown would not be able to regard anything as merely possible, hence would not be able to form hypotheses about anything.\n41 The clause “when (ubi) we do not attend to the order of Nature” is puzzling enough to have prompted attempts at emendation. Gebhardt is probably right to reject Elbogen’s suggestion that it has simply been misplaced, but might have considered more seriously Stern’s suggestion that we should read etsi for ubi : “ even if we do not attend …” It would not take a great deal of carelessness in the writing or the reading for a handwritten etsi to be taken for an ubi and etsi would not require a subjunctive (pace Gebhardt). Koyré (2, 106) has a plausible gloss: for Spinoza there are as many modes and degrees of existence as there are modes and degrees of essence; the existence of a man is different from that of an animal or an inanimate object; even when we do not attend to the order of nature (which is a necessary, but not sufficient condition of all feigning), we cannot attribute to a man an animal’s mode of existence unless we think in general terms.\nx Afterwards, when we speak of fiction that concerns essences, it will be clear that the fiction never makes, or presents to the mind, anything new, but that only things which are in the brain or the imagination are recalled to memory, and that the mind attends confusedly to all of them at once. Speech and a tree, for example, are recalled to memory, and since the mind attends confusedly, without distinction, it allows that the tree speaks. The same is understood concerning existence, especially, as we have said, when it is conceived so generally, as being. Then it is easily applied to all things which occur in the mind together. This is very much worth noting.\ny The same must also be understood concerning the hypotheses that are made to explain certain motions, which agree with the phenomena of the heavens; except that when people apply them to the celestial motions, they infer the nature of the heavens from them. But that nature can be different, especially since many other causes can be conceived to explain such motions.\n42 Koyré suggests glossing “done something” by “uttered some words.”\n43 Joachim (2, 120 n.) suggests that Spinoza has in mind Descartes’ Principles IV, 95-101, though it is not clear that Descartes is there involved in either of the suppositions Spinoza here discusses.\n44 I have translated the text of the OP (“ verae ac merae assertiones ”) as it stands, but in spite of the support of the NS and Joachim’s defense (2, 121, n. 2), I question whether verae (‘true’) is correct. Appuhn has: “assertions pure and simple,” which seems more in keeping with parallel passages (II/21/20-21, 21/27-28, 22/20-21).\nz It often happens that a man recalls this term soul to his memory, and at the same time forms some corporeal image. But since these two things are represented together, he easily allows that he imagines and feigns a corporeal soul: because he does not distinguish the name from the thing itself. Here I ask my readers not to hasten to refute this, which, as I hope, they will not do, provided that they attend as accurately as possible to the examples, and at the same time, to the things that follow.\n45 Elbogen points out that most of Spinoza’s examples come from Ovid’s Metamorphoses. But note that there seem to be references also to the Judaeo-Christian doctrine of creation and the Christian doctrine of the incarnation. Cf. Parkinson, 101-102, and E IP8S2, II/49/35.\n46 Koyré sees an allusion both to theologians who hold a voluntarist theory of belief and to Hobbes’ De Corpore I, iii, 8.\n47 Wolfson (1, 2:110-111) thought that this passage was undoubtedly directed against Descartes, citing The Passions of the Soul III, 152. He might, with equal justice, have cited the Fourth Meditation’s claim that it is principally our free will that justifies our thinking of ourselves as made in God’s image (AT VII, 57). De Deugd (90-91) countered that Descartes nevertheless does not ascribe to man a power to create ideas ex nihilo (which is what is in question here in § 60). Still, I do not think that would be a terribly implausible reading of certain passages in the Third Meditation (AT VII, 43-44). Descartes may be the target.\na Although I seem to infer this from experience, and someone may say that this is nothing, because a demonstration is lacking, he may have one, if he wishes; since there can be nothing in nature that is contrary to its laws, but since all things happen according to certain laws of nature, so that they produce their certain effects, by certain laws, in an unbreakable connection, it follows from this that when the soul conceives a thing truly, it proceeds to form the same effects objectively. See below, where I speak of the false idea. [In the OP this note is attached to the last sentence in § 60. Gebhardt places it here, following the NS. De Deugd has defended the placement of the OP (88, n. 1). But Eisenberg (2, 69) argues persuasively that the note is intended, not to disprove the view discussed in § 60, but to support the view presented in § 61.]\nb Note that the fiction, considered in itself, does not differ much from the dream, except that the causes which appear to the waking by the aid of the senses, and from which they infer that those presentations are not presented at that time by things placed outside them, do not appear in dreams. But error, as will be evident immediately, is dreaming while awake. And if it is very obvious, it is called madness.\n48 This sentence occurs only in the OP, which may indicate either an oversight on the part of the translator (as Leopold thought) or a later addition (as Gebhardt thought). This paragraph and the following are very strongly reminiscent of Descartes’ teaching in the Regulae , Rules 10 and 12, AT X, 399, 418, and 420. But even here there is nothing Spinoza could have derived only from Descartes. As Koyré points out, a similar doctrine is taught by St. Thomas, Summa theologiae , Ia. 17, 3.\n49 OP: “ primam ” NS: “ het eerste denkbeelt ” (= ideam). But parallelism with 1. 12 requires: fictionem.\n50 OP: “ sed quòd necessitas.” Joachim (2, 153, n. 2) suggests emending by deleting sed. That still leaves a somewhat awkward construction. What Spinoza means , I think, is that the second clause is a consequence of the first, not a separate condition.\n51 As Joachim notes (2, 91-98), there are two passages in Descartes that Spinoza may have in mind here, one in the Fifth Meditation and one in the Second Replies (AT VII, 64, 103-104). Spinoza’s examples are awkward for those interpreters who emphasize other passages in which Spinoza apparently adopts a correspondence theory of truth (e.g., myself, in Curley 3, 52-56, 122-126, 134-137, 142). But the examples are awkward in any case, since apparently incompatible with the general proposition they are supposed to illustrate, which is not so awkward. For further discussion see Curley 9.\n52 Koyré is probably right to see an allusion to Hobbes here. Cf. De Corpore I, i, 8.\n53 OP: “ cogitationis ”, NS: “ kennis/cognitio.” Gebhardt thinks the OP represents Spinoza’s correction of a mistake he made in the ms. from which the NS translation was done.\n54 OP: “ uti primâ fronte videtur.” Most translators (including the NS) have taken this to be presented as no more than a plausible hypothesis. But Joachim suggests (2, 91) that it is presented as a self-evident principle: “as is apparent at first glance.” Cf. § 106.\n55 Joachim (2, 159, n. 1) suggests following the NS, which reads: “… that was such a most subtle body.…”\n56 Gueroult (1, 1:169 n.) identifies the “first elements of the whole of Nature,” which constitute the source and origin of Nature, with the attributes that constitute God or substance. I agree (Curley 3, 42) and infer that God is not to be identified with the whole of Nature, but only with Natura naturans.\nz These are not attributes of God that show his essence, as I shall show in [my] Philosophy. [Since this topic is one taken up in the Short Treatise (KV I, ii-vii), but not in the Ethics , this note is evidence that the work referred to in the TdIE as “my Philosophy” was more like the Short Treatise than the Ethics.]\na This has already been demonstrated above. For if such a being did not exist, it could never be produced; and therefore the mind would be able to understand more things than Nature could bring about—which we have shown above to be false.\n57 Koyré refers us here to E IIP38 and Hobbes, De Corpore I, vi, 4-13.\n58 In the OP this sentence is printed as a footnote annexed to the Latin phrase here represented by “But in thinking.…” Gebhardt (following a suggestion of Leopold’s) adopts the reading of the NS, which brings it into the text. Joachim (2, 182 n.) thinks this a mistake.\n59 OP: “ quomodò quaestiones sint determinandae.” I adopt Joachim’s paraphrase (2, 183).\nd But if the duration is indeterminate, the memory of the thing is imperfect, as each of us also seems to have learned from nature. For often, to believe someone better in what he says, we ask when and where it happened. Although the ideas themselves also have their own duration in the mind, nevertheless, since we have become accustomed to determine duration with the aid of some measure of motion, which is also done with the aid of the imagination, we still observe no memory that belongs to the pure mind.61\n60 OP: “ Fabulam amatoriam ,” NS: “ tooneelspel van liefde.” Literally, love story or romantic play. But the marginal note in the NS suggests that Spinoza may originally have written Comoedia. The change (if there was one) was presumably made only for stylistic reasons and was not made consistently (cf. 1. 29).\n61 OP: “ sit purae mentis ” NS: “ gantschelijk tot de ziel behoort ” (= belongs entirely to the mind).\n62 The NS at this point gives (instead of “etc.”) a version of the lines occurring above 12-14. But they add that the imagination is not only random , but also unconscious , and that the soul is entirely acted on.\ne The principal Rule of this part (as follows from the first part) is to review all the ideas we discover in us from the pure intellect, so that they are distinguished from those we imagine. This will have to be elicited from the properties of each, i.e., of the imagination and the intellection.\nf Note that it is evident from this that we cannot [NS: legitimately or properly] understand anything of Nature without at the same time rendering our knowledge of the first cause, or God, more ample.\n63 Cf. Hobbes, De Corpore I, i, 5, and his Examinatio et emendatio mathematicae hodiernae , second dialogue. See also Cassirer 2:98ff.\n64 According to Gueroult (1, 1:172-173), Spinoza later modified this requirement and came to regard his definition of God (E ID6) as a genetic, causal definition. It would still be true that God requires nothing else except his own being (i.e., the elements of his being, the attributes) for his explanation. But it would not be correct to say that a definition in terms of those elements excludes every cause. Whereas the notion of being causa sui is here treated as if equivalent to being without a cause, later it will be treated more positively. The key passage is in Letter 60 (IV/270-271).\n65 OP: “ concludantur ” NS: “ verklaart worden ” (literally: ‘be explained’).\n66 Accepting Leopold’s emendation of the text. Cf. Joachim 2, 214 n.\n67 Cf. §§ 42, 91, and 95.\n68 Various scholars (Leopold, Appuhn, Joachim) have seen in this sentence a digression, probably added by Spinoza as a marginal note. Gebhardt, following both the OP and the NS, retains it in the text, rightly, I think.\n69 I take the reference to be to § 61, as Gebhardt apparently does at II/337. But at II/338 he apparently takes it to be to § 70, as part of his case for his emendation of II/38/1-2.\n70 OP: “Nam ex nullo fundamento cogitationes nostrae terminari queunt.” Elwes’ translation of that text is as reasonable as any: “For our thoughts may be brought to a close by the absence of a foundation.” Gebhardt (following the NS) emends to: “Nam ex nullo alio fundamento cogitationes nostrae determinari queunt,” which is what I have translated. But Appuhn’s conjecture is also plausible: “Nam ex nullo fundamento cogitationes nostrae determinari nequeunt” (= “for without a foundation our thoughts cannot be determined”). For a fuller discussion see Eisenberg 1, 103-105, or Gebhardt II/337-339. Cf. Aristotle, NE, 1098 b1-12.\ng Cf. above [II/13-14ff.].\n71 The text is evidently corrupt here. Gebhardt emends along lines suggested by the NS. I believe his version of the text makes sense if understood as I have translated it. For an alternative version and full discussion, see Eisenberg 1, 107-109.",
    "crumbs": [
      "General",
      "Treatise on the Emendation of the Intellect"
    ]
  },
  {
    "objectID": "documents/Program.html",
    "href": "documents/Program.html",
    "title": "2025 Seoul Workshop on Philosophy of Machine Learning",
    "section": "",
    "text": "DAY 1 (Feb 25)\n\n\n\n09:30-10:00\nRegistration\n\n\n\n\n\n10:00-10:10\nOpening\nWelcoming Address Sungkyu Jung (Director of IDIS, Seoul National University)Opening Remarks  Hyundeuk Cheon (Seoul National University) \n\n\n10:10-11:00\nInvited Talk 1\nWill the Advancement of AI Let Us Redefine Science? Insok Ko (Inha University)\n\n\n11:00-11:10\nBreak\n\n\n\n11:10-12:00\nInvited Talk 2\nPredictively-valid “Alien” Features, or Artifacts? Coping with Inscrutable Scientific Progress Cameron Buckner (University of Florida)\n\n\n12:00-13:30\nLunch\n\n\n\n13:30-14:50\nContributed Talks 1\nBeyond Tools: How Working with Coding AI Reshapes Cognition, Agency, and Subjectivity Yubeen Kwon (Seoul National University)Distributed and Probabilistic Model of Representation Lee-Sun Choi (Ewha Womans University)\n\n\n14:50-15:10\nBreak\n\n\n\n15:10-16:00\nInvited Talk 3\nIsolationism for Holists Andre Curtis-Trudel (University of Cincinnati) Emily Sullivan (Utrecht University)\n\n\n16:00-16:10\nBreak\n\n\n\n16:10-18:10\nContributed Talks 2\nArtificial Possibilities Bojana Grujičić (Max Planck School of Cognition) Augmented Intellect: AI as Extended Mind in Scientific Understanding Injin Woo (Sungkyunkwan University)Autonomous Weapon Systems and Just War Theory: A Critical Reevaluation of Jus in BelloPrinciple Sangsu Kim (Korea Military Academy)\n\n\n\nDAY 2 (Feb 26)\n\n\n\n09:30-09:40\nRegistration\n\n\n\n\n\n09:40-10:30\nInvited Talk 4\nAI and the Logic of Scientific Discovery Yeongseo Yeo (Dongduk Women’s University)\n\n\n10:30-10:40\nBreak\n\n\n\n10:40-12:00\nContributed Talks 3\nPrediction, Projection, and Performativity Konstantin Genin (University of Tübingen) Predicting Black Swan Events: The Final Frontier of Machine Learning? Wonki Her (Seoul National University)\n\n\n12:00-13:30\nLunch\n\n\n\n13:30-14:20\nInvited Talk 5\nOn Finding What You’re (not) Looking for: Prospects and Challenges for AI-driven Discovery Andre Curtis-Trudel (University of Cincinnati)\n\n\n14:20-14:30\nBreak\n\n\n\n14:30-15:20\nInvited Talk 6\nThe Moral Importance of Explainable AI Kate Vredenburgh (London School of Economics and Political Science)\n\n\n15:20-15:40\nBreak\n\n\n\n15:40-16:30\nInvited Talk 7\nFoundation Models in Healthcare Require Rethinking Reliability Thomas Grote (University of Tübingen)\n\n\n16:30-16:40\nBreak\n\n\n\n16:40-18:00\nContributed Talks 4\nBeyond Opacity: Why Implementation Details Matter in Understanding ML Models Hyung Suk Lee (Seoul National University)AI as a Pathway to Scientific Knowledge? Nikolaj Jang Lee Linding Pedersen (Yonsei University) Jens Christian Bjerring (Aarhus University)\n\n\n18:00-18:10\nClosing\n\n\n\n\nABSTRACTS\nInvited Talk 1\nWill the Advancement of AI Let Us Redefine Science?\nInsok Ko (Inha University)\nAccording to T. S. Kuhn, science is a collective activity of solving still unsolved puzzles recognized in a specialized domain of research, and this activity is guided by one or more exemplary instances of concrete problem solving. Today, we have more and more cases of scientific research in which AIs are utilized as essential tools. Though the AI agents do not have subjective motivation to solve the puzzle, they will emerge as powerful actors that solve some of the puzzles in a Kuhnian way, or at least help (human-) scientists do it. This would imply that the concepts of science, scientists, and scientific research will change. Will the advancement of AI induce us to redefine science? I will discuss this question from a couple of perspectives.\nInvited Talk 2\nPredictively-valid “Alien” Features, or Artifacts? Coping with Inscrutable Scientific Progress\nCameron Buckner (University of Florida)\nSystems like AlphaFold raise the prospect of predictive AI systems that can blow past previous upper bounds on the performance of hand-designed analytical models in many areas of scientific analysis. It is difficult to disagree with the results of these systems, which can achieve predictive accuracy on problems that were thought to be too complex or chaotic for human scientific theory to solve. However, these models may base their predictions on features that are in some sense beyond the cognitive grasp of humans–“alien” properties that may have predictive utility but which are not natural or cognitively accessible to us. In this talk I will analyze these properties by beginning with a discussion of adversarial attacks, and discuss methods for coping with this epistemic situation in a scientific regime which increasingly relies on complex deep learning models for data analysis.\nInvited Talk 3\nIsolationism for Holists\nAndre Curtis-Trudel (University of Cincinnati)\nEmily Sullivan (Utrecht University)\nModels often idealize their target phenomenon; but when are idealizations successful and how might we evaluate idealizations? Holists argue that justifying and evaluating models and their idealizations must proceed holistically and cannot be a function of aggregating or assessing individual parts of models. The holist argument comes from different pressure points. For some highly complex models it seems practically unfeasible to isolate where model failures occur due to opacity and complexity in interactions between different parts of the model. In other cases, it seems that isolationism suffers from a more fundamental problem: idealizations cannot be removed or isolated without radically changing the character of the model itself. In this talk, we look at the example of AlphaFold, a highly complex model in machine learning. AlphaFold is a paradigmatic example of the kind of highly complex model well suited for the holist project. However, we argue that decomposition and isolationism are necessary (and indeed possible) for evaluating the AlphaFold’s idealizations and the way they contribute to its success. As a result, we argue that holists should endorse the isolationist project.\nInvited Talk 4\nAI and the Logic of Scientific Discovery\nYeongseo Yeo (Dongduk Women’s University)\nIs deep learning AI reliable? AlphaFold2, a deep learning AI renowned for its accurate protein structure predictions, won the 2024 Nobel Prize in Chemistry. Its empirical success is undeniably impressive. However, many philosophers remain concerned about its epistemic opacity. Like other deep learning models, AlphaFold2 operates as a “black box,” meaning that its internal decision-making processes are not entirely interpretable. This lack of transparency raises fundamental questions: When should we rely on deep learning AI, and when not? What conditions must deep learning AI meet to be considered reliable? Can scientific knowledge be derived solely from deep learning AI? Philosophers have extensively debated these concerns, and with the groundbreaking success of AlphaFold2 and AlphaFold3, it is time to raise a new question: Can their empirical achievements challenge the skeptical or pessimistic views of philosophers on AlphaFold and deep learning AI?\nDuede (2023) suggests that deep learning AI may be valuable in the context of discovery, where it generates plausible hypotheses, but not in the context of justification, where scientific claims require rigorous testing and confirmation. But is this old distinction the only way to defend deep learning AI? Should we conclude that an epistemically opaque system like AlphaFold2 is ultimately unreliable?\nOrtmann (2025) challenges this skepticism by distinguishing between why-reliability and whether-reliability. He argues that even if we do not fully understand why AlphaFold2 is reliable, we can still determine whether it is reliable or not. The whether-reliability of alphaFold2 has already been demonstrated through its empirical success. Furthermore, its widespread adoption in contemporary scientific research provides additional support for its whether-reliability. After all, an unreliable tool would not be so extensively used in scientific practice.\nYet, many skeptical philosophers would remain unconvinced. For example, Duede (2022) insists that brute inductive considerations are never enough, that is, transparency is essential for true reliability. Similarly, Mitchell (2020) argues that empirical success must be accompanied by epistemic warrant, since reliability arises from the combination of theory’s epistemic warrant and the stability of supporting evidence.\nThis presentation explores, in response to Duede and Mitchell, whether the Logic of Discovery, understood as a set of problem-solving heuristics, can provide the necessary epistemic warrant for AlphaFold and deep learning AI. The idea is that the methods and principles underlying AlphaFold’s development may serve as a foundation for establishing its why-reliability. By articulating the heuristics that guided the creation of AlphaFold, we may be able to offer sufficient epistemic warrant to address concerns about the transparency required for AlphaFold and deep learning AI.\nInvited Talk 5\nOn Finding What You’re (not) Looking for: Prospects and Challenges for AI-driven Discovery\nAndre Curtis-Trudel (University of Cincinnati)\nRecent high-profile scientific achievements by machine learning (ML) and especially deep learning (DL) systems have reinvigorated interest in ML for automated scientific discovery (e.g., Wang et al. 2023). Much of this work is motivated by the thought that DL methods might facilitate the efficient discovery of phenomena, hypotheses, or even models or theories more efficiently than traditional, theory-driven approaches to discovery. This talk considers some of the more specific obstacles to automated, DL-driven discovery in frontier science, focusing on gravitational-wave astrophysics (GWA) as a representative case study. In the first part of the talk, we argue that despite these efforts prospects for DL-driven discovery in GWA remain uncertain. In the second part, we advocate a shift in focus towards the ways DL can be used to augment or enhance existing discovery methods, and the epistemic virtues and vices associated with these uses. We argue that the primary epistemic virtue of many such uses is to decrease opportunity costs associated with investigating puzzling or anomalous signals, and that the right framework for evaluating these uses comes from philosophical work on pursuitworthiness.\nInvited Talk 6\nThe Moral Importance of Explainable AI\nKate Vredenburgh (London School of Economics and Political Science)\nUnderstanding AI systems is important not just epistemically, but also morally. In this talk, I will do three things. First, I will argue an account of the moral values that are important for two different types of AI systems, what we might call predictive machines versus agents. I argue that enabling individuals to engage in informed self-advocacy is important for predictive machines, whereas values like trust and interpersonal respect are important for agents. The type of AI system thus has implications for what kind of explanations we should aim at, and corresponding scientific paradigms in XAI. Second, for predictive machines, I will use the example of credit scoring to argue that we face a fundamental tension between explaining how to be someone who has some property P and how to be judged to be someone who has some property P. Because of static modeling choices, and uncertainty, the two come apart. While the latter is attractive from a mathematical perspective, it requires background institutions that lessen the cost of mistakes to individuals. The former, however, may not suitably enable informed self-advocacy. Third, I will argue that interpersonal justification is important for agents, even artificial agents, but that providing justifications requires a responsiveness to reasons and social norms that artificial agents lack.\nInvited Talk 7\nFoundation Models in Healthcare Require Rethinking Reliability\nThomas Grote (University of Tübingen)\nA new class of AI models, called foundation models, has entered healthcare. Foundation models violate several basic principles of the standard machine learning paradigm for assessing reliability – they are tested with data they might have seen during training, trained with data from different and oftentimes opaque sources, and generate outputs whose adequacy for purpose is difficult to assess. These violations make it necessary to rethink what guarantees we require to establish warranted trust into foundation models.\nContributed Talks 1\nBeyond Tools: How Working with Coding AI Reshapes Cognition, Agency, and Subjectivity\nYubeen Kwon (Seoul National University)\nWhat does it mean to work alongside AI? What changes are required to collaborate effectively? How does collaborating with AI reshape our understanding of cognition, agency, and subjectivity?\nAI is distinguished from previous technologies in its ability to perform functions traditionally associated with human cognition, such as learning, problem-solving, and autonomous decision-making. Since the release of OpenAI’s ChatGPT, workplaces across various sectors have explored ways to integrate generative AI, sparking critical questions about its effective use in workflows and the management of human-AI teams.\nIn the software development community, coding AI tools such as GitHub Copilot have rapidly gained traction, becoming integral to developers’ practices. This presentation draws on in-depth interviews with 30 developers who routinely use coding AI—including GitHub Copilot, Code Whisperer, Claude, and ChatGPT—as well as observational research on their workflows. The developers formed relationships with AI that go beyond just using it as a tool – they treat it as an assistant, partner, and sometimes even as an extension of themselves. Notably, developers actively “teach” AI their intentions and goals, gradually shaping them into their ‘digital doppelgängers’ through iterative interactions and feedback. This shows how developers aren’t just delegating tasks to AI – they’re sharing their thinking processes with it.\nUsing cognitive and human-machine interface frameworks, this presentation explores the dynamic unfolding of agency in human-AI collaboration, emphasizing the roles of both human and non-human agencies. Frameworks such as distributed cognition and cognitive assemblage illuminate how cognitive processes are redistributed and reconfigured in these interactions. Developers increasingly view AI not merely as a tool but as an extension of their own cognitive processes, resulting in what can be termed a cognitive assemblage. Through analysis of the interactions between human developer and coding AI, this presentation demonstrates the necessity of an expanded concept of subjectivity that reflects the complex entanglements of cognition and agency in everyday interactions with AI.\nDistributed and Probabilistic Model of Representation\nLee-Sun Choi (Ewha Womans University)\nHow is the representation of the world constructed? Roughly speaking, a representation system receives data from external sources, encodes it through its input system, and combines this encoded information in the internal system to deliver and maintain it in working memory. Our world representation is not solely composed of information about individual entities, such as Garfield, Tom, or Cheshire, but also includes representations of categories, such as cats. These categories are called concepts. We represent the world using concepts.\nResearch on representational systems in artificial intelligence can be broadly divided into two processes. The first is the process of concept application, which explains how newly provided information is categorized within an existing conceptual framework. The second is the process of concept formation, which describes how new concepts are created based on data. This study focuses on the latter process, discussing how world representation is determined through concept formation.\nThis study proposes a new representational theory that integrates two major theories in artificial intelligence and cognitive science: distributed representation and probabilistic representation. Distributed representation, a core theory in deep learning, particularly in natural language processing and computer vision, places data in a feature space composed of multiple dimensions. For example, an image of a cat is represented by extracting low-level features such as contours, edges, colors, and textures, which are then combined into more complex features like “having ears” or “having a tail.” This feature space can be seen as a high-dimensional coordinate system, where each feature serves as an axis, and the input data is represented as a single point, or vector, in this space. A point can be understood as a combination of various features.\nProbabilistic representation models, on the other hand, interpret the process of concept formation as analyzing clusters of data in the feature space using specific likelihood functions. Dense data clusters, especially those isolated from other clusters, are more likely to be individuated as single concepts. In contrast, sparse clusters or patterns with multiple clusters are more likely to be interpreted as multiple concepts. This model opens the possibility for various observers to construct equivalent world representations based on the same data, assuming that no privileged world representation, such as a “God’s view,” exists. This aligns with the characteristics of human representation and also sets the conditions for the emergence of new concepts.\nHowever, if different world representation models exist, they must be translatable into one another; otherwise, each model risks being solipsistically isolated. This study proposes a method to evaluate the agreement of concepts in different feature spaces using quantitative metrics based on Kullback-Leibler divergence, assessing the consistency and differences between concepts.\nNevertheless, integrating distributed and probabilistic representations entails several limitations. For instance, the composition of the feature space—what features and how many of them are included—can lead to entirely different clusters for the same external input data. This discrepancy makes translating concept-based clusters across models challenging and highlights the constraints of assuming that all world representation models share the same dimensional structure of the feature space. This study explores the implications of these limitations for designing representation models and investigates the possibilities and boundaries of an integrated representational theory.\nContributed Talks 2\nArtificial Possibilities\nBojana Grujičić (Max Planck School of Cognition)\nScience often deals with issues pertaining to possibilities, contingencies and necessities, by engaging in thought experiments and modeling. This talk discusses how much modal scientific understanding can be obtained by the use of deep neural networks in cognitive science. One epistemically useful feature of neural networks is their runnability – they can be trained to perform a cognitive task and can run when given novel stimuli, demonstrating possibilities of cognitive phenomena based on sets of inductive biases. I focus on the problem of justification of neural network-based inferences about possibilities and outline a plausible justificatory strategy. I consider a number of reasons for taking neural network-demonstrated possibilities to be technological, rather than biological possibilities. Despite this, I argue that they add to our modal scientific understanding of cognitive phenomena.\nAugmented Intellect: AI as Extended Mind in Scientific Understanding\nInjin Woo (Sungkyunkwan University)\nIn this paper, I argue that Artificial Intelligence (AI) advances scientific understanding through the mechanism of (socially) extended cognition. Many researchers speculate that AI, upon reaching AGI, may satisfy certain conditions for agency, such as intentionality and autonomy. By examining the conceptual framework of extended cognition and integrating perspectives from Pritchard and Khalifa’s epistemologies, I demonstrate how AI transcends traditional tool-based cognition to become an active participant in scientific understanding.\nAI can be considered extended cognition, as defined by Chalmers and Clark (1998). Extended cognition involves integrating human cognitive processes with external environments or tools. Three essential conditions must be met: reliable coupling, direct availability, and automatic endorsement. AI is deeply integrated into human life, operating consistently and dependably (e.g., AI assistants). It responds instantly to questions or commands, supporting human cognitive demands in real time. AI systems earn user trust through repeated use and positive experiences. Just as smartphones have demonstrated their potential to function as extended cognition—despite initial technical limitations—AI also holds the potential to constitute extended cognition (Helliwell, 2019).\nBuilding upon the concept of extended cognition, we now turn to the idea of socially extended cognition. Pritchard (2022) explains scientific knowledge by emphasizing how collaboration contributes to understanding. Socially extended cognition occurs when the information-processing activities of others are integrated into an individual’s cognitive process, leading to knowledge beyond individual capability. If AI possesses agency, it can function as part of our socially extended cognition. AI supports and complements cognitive processes through collaboration with humans, unlike human collaboration, which may lack direct availability. AI minimizes or eliminates these limitations, reinforcing its role as a form of socially extended cognition. Pritchard limited his discussion to scientific knowledge, but I aim to integrate it with research on scientific understanding.\nTo grasp how this socially extended cognition enhances not just scientific knowledge, but also scientific understanding, we turn to Khalifa’s EKS model. Khalifa emphasizes that knowledge, particularly explanatory knowledge acquired through scientific explanatory evaluation (SEEing), is at the heart of understanding. SEEing in the EKS Model is a process of considering and comparing a range of plausible potential explanations, then selecting the most compelling one based on evidence and other explanatory considerations. This process of scientific inquiry goes beyond mere belief, leading to well-justified, reliable understanding that minimizes accidental or coincidental elements. Consequently, AI plays a pivotal role in enhancing SEEing, whether as a tool or as a collaborative partner.\nBuilding on this discussion, a critical review of scientists’ research (Krenn et al., 2022) on how AI contributes to scientific understanding highlights three key dimensions: (1) computational microscope, (2) resource of inspiration, and (3) agent of understanding. As a data processing and evaluation tool, AI enhances researchers’ ability to compare potential explanations and identify the most compelling ones. As a collaborator, AI generates hypotheses, refines frameworks, and enhances human cognition, thereby strengthening scientific evaluation. Through these dual roles, AI transforms the processes of SEEing, ultimately contributing to enhanced scientific understanding.\nAutonomous Weapon Systems and Just War Theory: A Critical Reevaluation ofJus in BelloPrinciple\nSangsu Kim (Korea Military Academy)\nThe emergence of Autonomous Weapon Systems (AWS), driven by the revolutionary advancements in artificial intelligence (AI), has fundamentally transformed modern warfare, calling for a critical reevaluation of the jus in bello principles within the framework of Just War Theory (JWT). AWS, as a product of AI innovation, operate independently, making critical decisions without human intervention, thereby enhancing operational efficiency. However, their autonomy raises serious ethical concerns about their ability to adhere to the core principles of discrimination and proportionality under JWT. These concerns are particularly significant given that AWS are weapon systems involving decisions that directly impact human lives, underscoring the urgent need for robust ethical frameworks to govern their use.\nJus in bello is a set of ethical principles that govern the conduct of war, requiring all moral agents involved in warfare to uphold its standards. Widely accepted as a foundational moral guideline in international contexts, these principles serve as the minimum ethical framework for ensuring the dignity and rights of individuals, even in the unavoidable circumstances of war. In particular, discrimination and proportionality are key to maintaining the moral legitimacy of warfare by protecting innocent civilians and ensuring that the use of force remains strictly aligned with legitimate military objectives.\nThe principle of discrimination requires a clear distinction between combatants and non-combatants, safeguarding civilians and other protected entities from unnecessary harm. This principle assumes that decision-makers can assess complex battlefield scenarios and make judgments consistent with international humanitarian law. Nonetheless, AWS, relying on preprogrammed algorithms and datasets, face significant challenges in identifying non-combatants accurately in dynamic and unpredictable environments. When incomplete or biased datasets influence AWS decision-making, there is a heightened risk of serious violations of the principle of discrimination.\nThe principle of proportionality demands that the harm caused by military actions be balanced against the anticipated military advantage. This principle requires nuanced assessments that go beyond mere calculations, incorporating moral and contextual factors. Yet, AWS operate based on predefined parameters, potentially failing to account for the complexity of real-world situations. The possibility of unforeseen outcomes further calls into question whether AWS can consistently uphold the proportionality principle in practice.\nThis presentation critically examines whether AWS can effectively adhere to the principles of discrimination and proportionality. It evaluates the technical and ethical capabilities of AWS to distinguish between combatants and non-combatants, avoid unlawful targets, and make decisions that align with human moral standards. Furthermore, it explores whether the use of lethal force by AWS can be justified under the principle of proportionality and discusses the extent to which human oversight is necessary to ensure compliance with these ethical principles.\nThe presentation is structured around three key discussions. First, it analyzes the technical characteristics and operational roles of AWS to assess whether they align with the established principles of JWT. Second, it reevaluates the ethical and practical interpretations of discrimination and proportionality to determine their applicability to AWS. Third, it proposes alternative approaches to reconfiguring jus in bello principles to reflect the ethical challenges posed by advanced technologies like AWS in modern warfare.\nUltimately, this presentation highlights the ethical urgency of scrutinizing AWS, given their origins in AI innovation and their life-and-death implications. It seeks to provide a framework for assessing AWS within the ethical boundaries of jus in bello, aiming to balance technological innovation with moral accountability. This approach contributes to redefining the ethical standards of modern warfare while ensuring justice and humanity remain central in the context of evolving conflicts.\nContributed Talks 3\nPrediction, Projection, and Performativity\nKonstantin Genin (University of Tübingen)\nIt is widely recognized that in social contexts predictions are not mere causally inert prognostications about future outcomes, but have a causal impact on the outcomes that they intend to predict. This is especially the case when predictions directly inform policy decisions. When predictions can be self-fulfilling, or self-undermining, pragmatic and epistemic considerations are entangled, and the notion of accuracy becomes ambiguous. Moreover, the notion of inductive risk must be revisited: values do not only come into play because the consequences of different kinds of error must be weighed, but also because we worry that predictions might be right for the wrong reasons. Many proposals have been made on how to deal with performativity, including “endogenizing” performative effects, or making predictions that steer outcomes in socially desirable directions. We argue that these approaches are misguided. Many undesirable performative effects arise because the outputs of machine learning models are ambiguous between predictions that predict outcomes by implicitly guessing which policy will be adopted, and counterfactual projections that predict outcomes were some policy option selected. Once we make the right distinction between prediction and projections, pragmatic and epistemic issues can be cleanly distinguished. We argue that only by aiming at accurate projections can machine learning models be not only decision-supportive but discourse-supportive: furnishing the relevant projections to allow discussants with a variety of goals and values to engage in discourse about which of a set of policy options represents the best reflective compromise.\nPredicting Black Swan Events: The Final Frontier of Machine Learning?\nWonki Her (Seoul National University)\nA Black Swan event is an event with the following three principal characteristics: (i) It is an outlier. (ii) It carries an extreme impact. (iii) After the event, we create an explanation (or a reasonable story) that makes it appear less random and more predictable than it was. World War I, the dissolution of the Soviet Union, the 9/11 attacks, and the death of the Inductivist Turkey are paradigmatic examples. Despite their outlier status, many people want to predict Black Swan events. This is because, if we can predict these Black Swan events, we can defend our lives from disastrous situations. Recently, some machine learning researchers have been trying to build Black Swan prediction machines. However, are these meaningful trials?\nIn this presentation, I will present a skeptical argument against building Black Swan prediction machines. For successful machine predictions, the following conditions need to be satisfied: (i) Large sets of high-quality training data, (ii) A well-defined prediction task, (iii) A well-defined target benchmark or specific standard to assess the prediction model, and (iv) Stable background conditions in the target domain.\nAs we know, in recent years, machine learning models have demonstrated incredible success (e.g., in Go, image recognition, and protein structure prediction). In these cases, the design and training of machine learning models meet the conditions above well. However, unlike games or natural science research, predicting rare social events is difficult because those conditions are hard to satisfy.\nFirst, Black Swan events are very rare, making it difficult to prepare a sufficiently large and high-quality dataset for discovering patterns. Second, defining the prediction task itself is challenging. For instance, should we define it as an event in which 5% of the global population dies within five years? Or should it be defined as an event causing a loss of 1 trillion dollars? Similarly, it is difficult to establish criteria for evaluating prediction models. Most importantly, because our social environment is constantly changing, it is unlikely that a successful Black Swan prediction model will remain effective in the future.\nBeyond environmental changes, we also adjust our behavior based on predictions, which introduces the so-called “Preparedness Paradox.” If we predict a Black Swan event, we will take actions to prevent its occurrence. If these actions are successful, the Black Swan event will not happen. The problem is that in this case, we cannot determine whether the prediction model was useful or not because we do not have something like a twin Earth to test our predictions or treatments.\nIn conclusion, building a Black Swan prediction model is not only extremely difficult but also challenging to evaluate, even if we succeed in creating one.\nContributed Talks 4\nBeyond Opacity: Why Implementation Details Matter in Understanding ML Models\nHyung Suk Lee (Seoul National University)\nScientists rely on hypotheses, theories, and models to grasp and justify phenomena. In contrast, Machine Learning (ML) models, introduced to compensate for the limitations of human cognitive capacity, do not rely on theories, laws, mechanisms, or scientific models. Instead, ML models seek a data model that represents the correct correspondence between the input and output data provided for training. Consequently, the data-driven models produced by ML are largely opaque and incomprehensible to humans.\nIn this situation, there is concern that the scientific values of explanation and understanding will be undermined if scientists increasingly adopt opaque and less understandable ML models for prediction or inference. As the use of ML for scientific purposes is steadily growing, the inability to understand and explain the predictive results produced by ML raises the question of whether the goal of science is shifting from explanation to mere prediction.\nIn response, Sullivan(2022) argues that we are unnecessarily worried due to an improper diagnosis of the phenomenon in which our scientific understanding is limited when using ML models. The opacity of ML models does not harm our understanding; the real problem, she claims, is the lack of scientific evidence linking ML models to phenomena. She argues that to promote explanation and understanding of the real world, we must secure evidence connecting models and phenomena, and that knowing more about the internal implementation state of a model does not increase our understanding of the world.\nI believe that Sullivan’s claim that implementation opacity does not hinder understanding of ML models is incorrect. She has merely turned her head away from a harsh reality. Without resolving implementation opacity, we cannot understand the predictions of ML models.\nFirst, I will analyze the three examples provided by Sullivan (Schelling’s segregation model, melanoma detection model, and sexual orientation prediction model) to clarify what she means by “link uncertainty.” This analysis will demonstrate that the connection between model and phenomenon, as Sullivan describes it, is formed through two stages: first, replacing the ML model with a human-cognizable surrogate model, and second, connecting this surrogate model to a traditional scientific model that represents the phenomenon. Next, I will show that if we fail to grasp the implementation process of the ML model, even if the first stage of connection is achieved by replacing the ML model with a human-cognizable surrogate model using sufficiently developed xAI techniques, the success of the second stage can be highly precarious. Consequently, I argue that Sullivan’s claim that we can gain scientific understanding through ML models even without resolving implementation opacity is unacceptable, because without resolving implementation opacity, we cannot resolve link uncertainty.\nAI as a Pathway to Scientific Knowledge?\nNikolaj Jang Lee Linding Pedersen (Yonsei University)\nJens Christian Bjerring (Aarhus University)\nArtificial Intelligence is increasingly positioned as a transformative tool in the pursuit of scientific knowledge, reshaping how we collect, analyze, and interpret data. But under what conditions can an AI system produce scientific knowledge?\nReliability is required for knowledge (or so we shall assume here). A true belief qualifies as knowledge only if it is formed via a reliable belief-forming method or process (i.e. one that generates mostly true beliefs). Thus, true AI-based scientific beliefs qualify as knowledge only if they are formed via reliable AI methods or belief-forming processes (i.e. methods or processes that take AI outcomes as input and deliver beliefs as outputs). We argue that, while reliability may be a necessary condition for AI-based knowledge, it—together with truth—is not sufficient. Reliability must be supplemented by a condition which ensures that the relevant AI belief-forming method or process does not take highly inaccurate inputs.\nWe home in on this condition through considerations on the distinctive nature of the types of errors that AI systems may make.  AI systems can sometimes make “crazy” or “astounding” errors—e.g., classifying a bird as a car. These kinds of errors seem qualitatively different from those that humans would typically make. They do not merely reflect minor inaccuracies but instead reveal extreme failures seemingly disconnected from the data being processed.\nIt is epistemically risky to form beliefs via methods or processes that take such mistaken AI-generated outcomes as inputs, as it undermines the prospects of knowledge. This point is articulated and argued within a framework featuring two levels of epistemic evaluation: the epistemic value of belief outputs of methods or processes and the accuracy of their inputs. Epistemic value  is trichotomous. There are three epistemic values: truth, falsity, and knowledge. Accuracy takes values in the unit interval, i.e. real numbers in [0; 1].\nThe condition that belief-forming methods and processes not take highly inaccurate inputs is a maximin-style condition. The minimum accuracy of inputs must not be too low. Failing this condition means forming beliefs via a method or process that sometimes takes highly inaccurate inputs. This is epistemically risky as it is incompatible with knowledge. Hence, highly inaccurate inputs undermine the prospects of knowledge.\nWe offer the following diagnosis of the connection between high inaccuracy and knowledge: for a belief-forming method or process that takes outputs from source S as input, the competence of S is undermined if some of S’s outputs are wildly inaccurate. However, a source’s failure to be competent means that it cannot serve as a basis for knowledge—even if forming beliefs on the basis of its deliverances leads to the formation of mostly true beliefs. Thus, AI systems that sometimes deliver highly inaccurate outputs cannot serve as the basis of knowledge, even if most beliefs formed on the basis of their outputs are true. This is because such AI systems fail to exhibit competence.\nProgram",
    "crumbs": [
      "Data Science",
      "2025 Seoul Workshop on Philosophy of Machine Learning"
    ]
  },
  {
    "objectID": "documents/Program.html#초록",
    "href": "documents/Program.html#초록",
    "title": "2025 Seoul Workshop on Philosophy of Machine Learning",
    "section": "초록",
    "text": "초록\n초청 강연 1\nAI의 발전으로 과학을 재정의할 수 있을까?\n고인석 (인하대학교)\nT. S. 쿤에 따르면, 과학은 전문화된 연구 영역에서 아직 해결되지 않은 퍼즐을 해결하는 집단적 활동이며, 이 활동은 구체적인 문제 해결의 하나 이상의 모범적인 사례에 의해 안내됩니다. 오늘날, AI가 필수적인 도구로 활용되는 과학 연구 사례가 점점 더 많아지고 있습니다. AI 에이전트들은 퍼즐을 해결하려는 주관적 동기를 가지고 있지 않지만, 쿤적인 방식으로 일부 퍼즐을 해결하거나, 적어도 (인간) 과학자들이 그렇게 할 수 있도록 도와주는 강력한 행위자로 등장할 것입니다. 이는 과학, 과학자, 그리고 과학적 연구의 개념이 변화할 것임을 시사합니다. AI의 발전이 우리로 하여금 과학을 재정의하도록 이끌 것인가? 저는 이 질문을 여러 관점에서 논의할 것입니다.\n초청 강연 2\n예측적으로 유효한 “외계인적” 특성인가, 인공물인가? 이해불가능한 과학적 진보에 대처하기\n카메론 버크너 (플로리다 대학교)\nAlphaFold와 같은 시스템은 많은 과학적 분석 영역에서 수작업으로 설계된 분석 모델의 이전 성능 상한선을 훨씬 뛰어넘는 예측적 AI 시스템의 전망을 제시합니다. 인간의 과학적 이론이 해결하기에 너무 복잡하거나 혼란스럽다고 여겨졌던 문제에서 예측 정확도를 달성할 수 있는 이러한 시스템의 결과에 동의하지 않기는 어렵습니다. 그러나 이러한 모델들은 어떤 면에서는 인간의 인지적 이해를 넘어서는 특성에 기반하여 예측할 수 있습니다 - 예측적 유용성은 있지만 우리에게 자연스럽거나 인지적으로 접근 가능하지 않은 “외계인적” 속성들입니다. 이 강연에서는 적대적 공격(adversarial attacks)에 대한 논의로 시작하여 이러한 특성들을 분석하고, 데이터 분석을 위해 점점 더 복잡한 딥러닝 모델에 의존하는 과학적 체제에서 이러한 인식론적 상황에 대처하는 방법을 논의할 것입니다.\n초청 강연 3\n전체론자를 위한 고립주의\n앙드레 커티스-트루델 (신시내티 대학교)\n에밀리 설리반 (유트레히트 대학교)\n모델은 종종 그들의 대상 현상을 이상화합니다. 그러나 언제 이상화가 성공적이며 어떻게 이상화를 평가할 수 있을까요? 전체론자들은 모델과 그 이상화를 정당화하고 평가하는 것이 전체론적으로 진행되어야 하며 모델의 개별 부분을 집계하거나 평가하는 기능이 될 수 없다고 주장합니다. 전체론적 주장은, 다양한 압력점에서 발생합니다. 일부 매우 복잡한 모델의 경우, 불투명성과 모델의 다른 부분들 간의 상호작용의 복잡성으로 인해 모델 실패가 어디서 발생하는지 실질적으로 분리하기가 어렵습니다. 다른 경우에는, 고립주의가 더 근본적인 문제를 겪는 것으로 보입니다: 이상화는 모델 자체의 특성을 근본적으로 변경하지 않고는 제거하거나 분리할 수 없습니다. 이 강연에서는 머신러닝에서 매우 복잡한 모델인 AlphaFold의 예를 살펴봅니다. AlphaFold는 전체론적 프로젝트에 적합한 일종의 매우 복잡한 모델의 전형적인 예입니다. 그러나 우리는 AlphaFold의 이상화를 평가하고 그것이 성공에 기여하는 방식을 평가하기 위해 분해와 고립주의가 필요하며(실제로 가능하다고) 주장합니다. 결과적으로, 우리는 전체론자들이 고립주의적 프로젝트를 지지해야 한다고 주장합니다.\n초청 강연 4\nAI와 과학적 발견의 논리\n여연경 (동덕여자대학교)\n딥러닝 AI는 신뢰할 수 있는가? 정확한 단백질 구조 예측으로 유명한 딥러닝 AI인 AlphaFold2는 2024년 노벨 화학상을 수상했습니다. 그 경험적 성공은 분명히 인상적입니다. 그러나 많은 철학자들은 여전히 그것의 인식론적 불투명성에 대해 우려하고 있습니다. 다른 딥러닝 모델과 마찬가지로, AlphaFold2는 “블랙박스”로 작동하는데, 이는 내부 의사결정 과정이 완전히 해석 가능하지 않다는 것을 의미합니다. 이러한 투명성 부족은 근본적인 질문을 제기합니다: 언제 딥러닝 AI를 신뢰해야 하고, 언제 그렇지 않아야 하는가? 딥러닝 AI가 신뢰할 수 있다고 간주되기 위해 충족해야 하는 조건은 무엇인가? 과학적 지식이 딥러닝 AI만으로 도출될 수 있는가? 철학자들은 이러한 우려에 대해 광범위하게 논의해 왔으며, AlphaFold2와 AlphaFold3의 획기적인 성공으로 새로운 질문을 제기할 때입니다: 그들의 경험적 성과가 AlphaFold와 딥러닝 AI에 대한 철학자들의 회의적이거나 비관적인 견해에 도전할 수 있는가?\nDuede(2023)는 딥러닝 AI가 타당한 가설을 생성하는 발견의 맥락에서는 가치가 있을 수 있지만, 과학적 주장이 엄격한 테스트와 확인을 필요로 하는 정당화의 맥락에서는 그렇지 않을 수 있다고 제안합니다. 그러나 이 오래된 구분이 딥러닝 AI를 옹호하는 유일한 방법인가요? AlphaFold2와 같은 인식론적으로 불투명한 시스템이 궁극적으로 신뢰할 수 없다고 결론지어야 하는가?\nOrtmann(2025)은 why-reliability와 whether-reliability를 구분함으로써 이러한 회의론에 도전합니다. 그는 우리가 AlphaFold2가 왜 신뢰할 수 있는지 완전히 이해하지 못하더라도, 여전히 그것이 신뢰할 수 있는지 여부를 판단할 수 있다고 주장합니다. AlphaFold2의 whether-reliability는 이미 그것의 경험적 성공을 통해 입증되었습니다. 더욱이, 현대 과학 연구에서의 광범위한 채택은 그것의 whether-reliability에 대한 추가적인 지지를 제공합니다. 결국, 신뢰할 수 없는 도구는 과학적 실천에서 그렇게 광범위하게 사용되지 않을 것입니다.\n그러나, 많은 회의적인 철학자들은 여전히 설득되지 않을 것입니다. 예를 들어, Duede(2022)는 단순한 귀납적 고려사항만으로는 충분하지 않으며, 투명성이 진정한 신뢰성에 필수적이라고 주장합니다. 마찬가지로, Mitchell(2020)은 신뢰성이 이론의 인식론적 보증과 지지 증거의 안정성의 조합에서 발생하기 때문에, 경험적 성공은 인식론적 보증을 동반해야 한다고 주장합니다.\n이 발표는 Duede와 Mitchell에 대한 응답으로, 문제 해결 휴리스틱 집합으로 이해되는 발견의 논리가 AlphaFold와 딥러닝 AI에 필요한 인식론적 보증을 제공할 수 있는지 탐구합니다. 이 아이디어는 AlphaFold 개발의 기초가 되는 방법과 원칙이 그것의 why-reliability를 확립하기 위한 기초로 기능할 수 있다는 것입니다. AlphaFold의 창조를 이끈 휴리스틱을 명시함으로써, 우리는 AlphaFold와 딥러닝 AI에 요구되는 투명성에 대한 우려를 해결하기 위한 충분한 인식론적 보증을 제공할 수 있을지도 모릅니다.\n초청 강연 5\n찾고 있(지 않)는 것을 발견하기: AI 주도 발견의 전망과 도전\n앙드레 커티스-트루델 (신시내티 대학교)\n머신러닝(ML), 특히 딥러닝(DL) 시스템에 의한 최근의 중요한 과학적 성과는 자동화된 과학적 발견을 위한 ML에 대한 관심을 재활성화했습니다(예: Wang 외, 2023). 이러한 작업의 많은 부분은 DL 방법이 전통적인 이론 중심의 발견 접근법보다 더 효율적으로 현상, 가설, 심지어 모델이나 이론의 발견을 촉진할 수 있다는 생각에 의해 동기 부여됩니다. 이 강연은 최첨단 과학에서 자동화된, DL 주도 발견에 대한 더 구체적인 장애물 중 일부를 고려하며, 대표적인 사례 연구로 중력파 천체물리학(GWA)에 초점을 맞춥니다. 강연의 첫 번째 부분에서, 우리는 이러한 노력에도 불구하고 GWA에서 DL 주도 발견의 전망이 여전히 불확실하다고 주장합니다. 두 번째 부분에서, 우리는 DL이 기존의 발견 방법을 증강하거나 향상시키는 데 사용될 수 있는 방법과, 이러한 사용과 관련된 인식론적 미덕과 악덕에 대한 관심의 전환을 지지합니다. 우리는 이러한 많은 사용의 주요 인식론적 미덕이 퍼즐이나 이상 신호를 조사하는 것과 관련된 기회 비용을 감소시키는 것이며, 이러한 사용을 평가하기 위한 올바른 프레임워크는 추구가치성(pursuitworthiness)에 관한 철학적 작업에서 나온다고 주장합니다.\n초청 강연 6\n설명 가능한 AI의 도덕적 중요성\n케이트 브레덴버그 (런던 정치경제대학)\nAI 시스템을 이해하는 것은 인식론적으로뿐만 아니라 도덕적으로도 중요합니다. 이 강연에서, 저는 세 가지를 할 것입니다. 첫째, 우리가 예측 기계와 에이전트라고 부를 수 있는 두 가지 다른 유형의 AI 시스템에 대해 중요한 도덕적 가치에 대한 설명을 주장할 것입니다. 저는 예측 기계의 경우 정보에 입각한 자기 옹호를 가능하게 하는 것이 중요하며, 에이전트의 경우 신뢰와 대인 존중과 같은 가치가 중요하다고 주장합니다. 따라서 AI 시스템의 유형은 우리가 어떤 종류의 설명을 목표로 해야 하는지, 그리고 XAI에서의 상응하는 과학적 패러다임에 대한 영향을 미칩니다. 둘째, 예측 기계의 경우, 저는 신용 평가의 예를 사용하여 어떤 속성 P를 가진 사람이 되는 방법과 어떤 속성 P를 가진 사람으로 판단받는 방법을 설명하는 것 사이에 근본적인 긴장이 있다고 주장할 것입니다. 정적 모델링 선택과 불확실성 때문에, 둘은 분리됩니다. 후자는 수학적 관점에서 매력적이지만, 개인에 대한 실수 비용을 줄이는 배경 기관이 필요합니다. 그러나 전자는 정보에 입각한 자기 옹호를 적절히 가능하게 하지 않을 수 있습니다. 셋째, 저는 대인 간 정당화가 인공 에이전트를 포함한 에이전트에게 중요하지만, 정당화를 제공하기 위해서는 인공 에이전트가 부족한 이유와 사회적 규범에 대한 응답성이 필요하다고 주장할 것입니다.\n초청 강연 7\n의료분야의 파운데이션 모델은 신뢰성에 대한 재고를 요구한다\n토마스 그로테 (튀빙겐 대학교)\n파운데이션 모델이라고 불리는 새로운 종류의 AI 모델이 의료 분야에 진입했습니다. 파운데이션 모델은 신뢰성을 평가하기 위한 표준 머신러닝 패러다임의 몇 가지 기본 원칙을 위반합니다 - 그들은 훈련 중에 보았을 수 있는 데이터로 테스트되고, 다양하고 종종 불투명한 출처의 데이터로 훈련되며, 목적에 대한 적합성을 평가하기 어려운 출력을 생성합니다. 이러한 위반은 파운데이션 모델에 대한 보증된 신뢰를 확립하기 위해 우리가 어떤 보증을 요구하는지 재고할 필요가 있게 만듭니다.\n일반 발표 1\n도구 그 이상: 코딩 AI와의 협업이 인지, 행위성, 그리고 주관성을 재형성하는 방식\n권유빈 (서울대학교)\nAI와 함께 일한다는 것은, 무엇을 의미하는가? 효과적인 협업을 위해 어떤 변화가 필요한가? AI와의 협업이 인지, 행위성, 주관성에 대한 우리의 이해를 어떻게 재형성하는가?\nAI는 학습, 문제 해결, 자율적 의사 결정과 같은 전통적으로 인간 인지와 관련된 기능을 수행할 수 있는 능력에서 이전 기술과 구별됩니다. OpenAI의 ChatGPT 출시 이후, 다양한 부문의 직장들은 생성형 AI를 워크플로우에 통합하고 인간-AI 팀을 관리하는 방법에 대한 중요한 질문을 불러일으키며 통합하는 방법을 탐색해 왔습니다.\n소프트웨어 개발 커뮤니티에서, GitHub Copilot과 같은 코딩 AI 도구들은 빠르게 인기를 얻어 개발자들의 관행에 필수적이 되었습니다. 이 발표는 GitHub Copilot, Code Whisperer, Claude, ChatGPT를 포함한 코딩 AI를 정기적으로 사용하는 30명의 개발자들과의 심층 인터뷰와 그들의 워크플로우에 대한 관찰 연구에 기반합니다. 개발자들은 AI를 단순히 도구로 사용하는 것을 넘어서 - 그들은 AI를 조수, 파트너, 때로는 자신의 확장으로 대우합니다. 주목할 만하게, 개발자들은 의도와 목표를 AI에 적극적으로 “가르치고”, 반복적인 상호작용과 피드백을 통해 점차적으로 AI를 그들의 ’디지털 분신’으로 형성합니다. 이는 개발자들이 단순히 AI에 작업을 위임하는 것이 아니라 - 자신의 사고 과정을 AI와 공유하고 있음을 보여줍니다.\n인지 및 인간-기계 인터페이스 프레임워크를 사용하여, 이 발표는 인간과 비인간 행위성 모두의 역할을 강조하며 인간-AI 협업에서 행위성의 역동적인 전개를 탐구합니다. 분산 인지와 인지적 조립체와 같은 프레임워크는 이러한 상호작용에서 인지 과정이 어떻게 재분배되고 재구성되는지 조명합니다. 개발자들은 점점 더 AI를 단순한 도구가 아니라 자신의 인지 과정의 확장으로 보게 되어, 인지적 조립체라고 부를 수 있는 것이 됩니다. 인간 개발자와 코딩 AI 사이의 상호작용 분석을 통해, 이 발표는 AI와의 일상적인 상호작용에서 인지와 행위성의 복잡한 얽힘을 반영하는 확장된 주관성 개념의 필요성을 보여줍니다.\n분산적이고 확률적인 표상 모델\n최이선 (이화여자대학교)\n세계의 표상은 어떻게 구성되는가? 대략적으로 말하자면, 표상 시스템은 외부 소스로부터 데이터를 받아, 입력 시스템을 통해 그것을 인코딩하고, 내부 시스템에서 이 인코딩된 정보를 결합하여 작업 메모리에 전달하고 유지합니다. 우리의 세계 표상은 가필드, 톰, 체셔와 같은 개별 엔티티에 대한 정보뿐만 아니라 고양이와 같은 범주에 대한 표상도 포함합니다. 이러한 범주를 개념이라고 합니다. 우리는 개념을 사용하여 세계를 표상합니다.\n인공지능에서의 표상 시스템에 관한 연구는 크게 두 과정으로 나눌 수 있습니다. 첫 번째는 개념 적용 과정으로, 새롭게 제공된 정보가 기존 개념적 프레임워크 내에서 어떻게 분류되는지 설명합니다. 두 번째는 개념 형성 과정으로, 데이터를 기반으로 새로운 개념이 어떻게 생성되는지 설명합니다. 이 연구는 후자에 초점을 맞추어, 개념 형성을 통해 세계 표상이 어떻게 결정되는지 논의합니다.\n이 연구는 인공지능과 인지과학의 두 가지 주요 이론인 분산 표상(distributed representation)과 확률적 표상(probabilistic representation)을 통합하는 새로운 표상 이론을 제안합니다. 딥러닝의 핵심 이론인 분산 표상, 특히 자연어 처리와 컴퓨터 비전에서는 여러 차원으로 구성된 특징 공간에 데이터를 배치합니다. 예를 들어, 고양이 이미지는 윤곽, 모서리, 색상, 질감과 같은 저수준 특징을 추출하여 표현되고, 이것은 “귀를 가짐” 또는 “꼬리를 가짐”과 같은 더 복잡한 특징으로 결합됩니다. 이 특징 공간은 고차원 좌표계로 볼 수 있으며, 각 특징은 축으로 작용하고, 입력 데이터는 이 공간에서 단일 점 또는 벡터로 표현됩니다. 하나의 점은 다양한 특징의 조합으로 이해될 수 있습니다.\n반면에, 확률적 표상 모델은 개념 형성 과정을 특정 우도 함수를 사용하여 특징 공간에서 데이터 클러스터를 분석하는 것으로 해석합니다. 밀집된 데이터 클러스터, 특히 다른 클러스터와 분리된 클러스터는 단일 개념으로 개별화될 가능성이 더 높습니다. 반대로, 희소한 클러스터나 여러 클러스터가 있는 패턴은 여러 개념으로 해석될 가능성이 더 높습니다. 이 모델은 “신의 관점”과 같은 특권적인 세계 표상이 존재하지 않는다고 가정하고, 동일한 데이터를 기반으로 다양한 관찰자가 동등한 세계 표상을 구성할 가능성을 열어줍니다. 이는 인간 표상의 특성과 일치하며 새로운 개념의 출현 조건도 설정합니다.\n그러나 다른 세계 표상 모델이 존재한다면, 그것들은 서로 번역 가능해야 합니다. 그렇지 않으면 각 모델은 고립적으로 유아론적인 위험이 있습니다. 이 연구는 Kullback-Leibler 발산에 기반한 정량적 지표를 사용하여 서로 다른 특징 공간에서 개념의 일치도를 평가하고, 개념 간의 일관성과 차이를 평가하는 방법을 제안합니다.\n그럼에도 불구하고, 분산 표상과 확률적 표상의 통합에는 몇 가지 제한이 따릅니다. 예를 들어, 특징 공간의 구성 - 어떤 특징과 얼마나 많은 특징이 포함되는지 - 은 동일한 외부 입력 데이터에 대해 완전히 다른 클러스터로 이어질 수 있습니다. 이러한 불일치는 모델 간에 개념 기반 클러스터를 번역하는 것을 어렵게 만들고, 모든 세계 표상 모델이 특징 공간의 동일한 차원 구조를 공유한다고 가정하는 것의 제약을 강조합니다. 이 연구는 이러한 제한이 표상 모델 설계에 미치는 영향을 탐구하고 통합된 표상 이론의 가능성과 경계를 조사합니다.\n일반 발표 2\n인공적 가능성\n보야나 그루지치치 (막스 플랑크 인지 스쿨)\n과학은 종종 사고 실험과 모델링을 통해 가능성, 우연성, 필연성과 관련된 문제를 다룹니다. 이 발표는 인지 과학에서 딥 뉴럴 네트워크를 사용함으로써 얼마나 많은 양식적 과학적 이해를 얻을 수 있는지 논의합니다. 신경망의 인식론적으로 유용한 특징 중 하나는 실행 가능성입니다 - 신경망은 인지적 작업을 수행하도록 훈련될 수 있으며, 새로운 자극이 주어졌을 때 실행될 수 있어 귀납적 편향 집합에 기반한 인지 현상의 가능성을 보여줍니다. 저는 가능성에 대한 신경망 기반 추론의 정당화 문제에 초점을 맞추고 타당한 정당화 전략을 개략적으로 설명합니다. 저는 신경망이 보여주는 가능성을 생물학적 가능성이 아닌 기술적 가능성으로 간주하는 여러 이유를 고려합니다. 그럼에도 불구하고, 저는 그것들이 인지 현상에 대한 우리의 양식적 과학적 이해에 기여한다고 주장합니다.\n증강된 지성: 과학적 이해에서 확장된 마음으로서의 AI\n우인진 (성균관대학교)\n이 논문에서, 저는 인공지능(AI)이 (사회적으로) 확장된 인지의 메커니즘을 통해 과학적 이해를 발전시킨다고 주장합니다. 많은 연구자들은 AI가 AGI에 도달하면 의도성과 자율성과 같은 행위자성의 특정 조건을 만족시킬 수 있다고 추측합니다. 확장된 인지의 개념적 프레임워크를 검토하고 Pritchard와 Khalifa의 인식론적 관점을 통합함으로써, 저는 AI가 어떻게 전통적인 도구 기반 인지를 초월하여 과학적 이해의 적극적인 참여자가 되는지 보여드립니다.\nAI는 Chalmers와 Clark(1998)이 정의한 대로 확장된 인지로 간주될 수 있습니다. 확장된 인지는 인간의 인지 과정을 외부 환경이나 도구와 통합하는 것을 포함합니다. 세 가지 필수 조건이 충족되어야 합니다: 신뢰할 수 있는 결합, 직접적인 가용성, 자동적인 승인입니다. AI는 일관되고 신뢰할 수 있게 작동하면서 인간 생활에 깊이 통합되어 있습니다(예: AI 비서). AI는 질문이나 명령에 즉시 응답하여 실시간으로 인간의 인지적 요구를 지원합니다. AI 시스템은 반복적인 사용과 긍정적인 경험을 통해 사용자의 신뢰를 얻습니다. 스마트폰이 초기 기술적 한계에도 불구하고 확장된 인지로 기능할 수 있는 잠재력을 보여준 것처럼, AI 또한 확장된 인지를 구성할 잠재력을 가지고 있습니다(Helliwell, 2019).\n확장된 인지의 개념을 기반으로, 이제 사회적으로 확장된 인지의 아이디어로 눈을 돌립니다. Pritchard(2022)는 협업이 이해에 어떻게 기여하는지 강조함으로써 과학적 지식을 설명합니다. 사회적으로 확장된 인지는 다른 사람들의 정보 처리 활동이 개인의 인지 과정에 통합되어 개인 능력을 넘어선 지식으로 이어질 때 발생합니다. AI가 행위자성을 가지고 있다면, 그것은 우리의 사회적으로 확장된 인지의 일부로 기능할 수 있습니다. AI는 직접적인 가용성이 부족할 수 있는 인간 협업과 달리, 인간과의 협업을 통해 인지 과정을 지원하고 보완합니다. AI는 이러한 제한을 최소화하거나 제거하여 사회적으로 확장된 인지의 형태로서의 역할을 강화합니다. Pritchard는 과학적 지식에 대한 논의를 제한했지만, 저는 그것을 과학적 이해에 관한 연구와 통합하는 것을 목표로 합니다.\n이 사회적으로 확장된 인지가 단지 과학적 지식뿐만 아니라 과학적 이해를 어떻게 향상시키는지 파악하기 위해, 우리는 Khalifa의 EKS 모델로 눈을 돌립니다. Khalifa는 과학적 설명적 평가(SEEing)를 통해 얻은 설명적 지식이 이해의 핵심이라고 강조합니다. EKS 모델에서의 SEEing은 타당한 잠재적 설명의 범위를 고려하고 비교한 다음, 증거와 다른 설명적 고려사항에 기반하여 가장 설득력 있는 것을 선택하는 과정입니다. 이 과학적 탐구 과정은 단순한 믿음을 넘어서 우연적이거나 우발적인 요소를 최소화하는 잘 정당화되고 신뢰할 수 있는 이해로 이어집니다. 따라서, AI는 도구로서든 협업 파트너로서든 SEEing을 향상시키는 데 중요한 역할을 합니다.\n이 논의를 바탕으로, AI가 과학적 이해에 어떻게 기여하는지에 대한 과학자들의 연구(Krenn 외, 2022)에 대한 비판적 검토는 세 가지 주요 차원을 강조합니다: (1) 계산적 현미경, (2) 영감의 자원, (3) 이해의 에이전트입니다. 데이터 처리 및 평가 도구로서, AI는 연구자들이 잠재적 설명을 비교하고 가장 설득력 있는 것을 식별하는 능력을 향상시킵니다. 협력자로서, AI는 가설을 생성하고, 프레임워크를 정제하고, 인간의 인지를 향상시켜 과학적 평가를 강화합니다. 이러한 두 가지 역할을 통해, AI는 SEEing의 과정을 변형시켜 궁극적으로 향상된 과학적 이해에 기여합니다.\n자율무기체계와 정의로운 전쟁 이론: 정전론(Jus in Bello) 원칙에 대한 비판적 재평가\n김상수 (육군사관학교)\n인공지능(AI)의 혁명적인 발전에 의해 주도되는 자율무기체계(AWS)의 출현은 현대 전쟁을 근본적으로 변화시켜, 정의로운 전쟁 이론(JWT) 프레임워크 내의 정전론(jus in bello) 원칙에 대한 비판적 재평가를 요구합니다. AI 혁신의 산물인 AWS는 독립적으로 작동하여 인간의 개입 없이 중요한 결정을 내림으로써 운영 효율성을 향상시킵니다. 그러나 그들의 자율성은 JWT 하에서 차별과 비례성의 핵심 원칙을 준수할 수 있는 능력에 대한 심각한 윤리적 우려를 제기합니다. 이러한 우려는 AWS가 인간의 생명에 직접적인 영향을 미치는 결정을 포함하는 무기 시스템이라는 점을 고려할 때 특히 중요하며, 그들의 사용을 관리하기 위한 강력한 윤리적 프레임워크의 긴급한 필요성을 강조합니다.\n정전론은 전쟁 수행을 규제하는 일련의 윤리적 원칙으로, 전쟁에 관련된 모든 도덕적 행위자가 그 기준을 유지하도록 요구합니다. 국제적 맥락에서 널리 받아들여지는 기본적인 도덕적 지침으로서, 이러한 원칙들은 전쟁의 불가피한 상황에서도 개인의 존엄성과 권리를 보장하기 위한 최소한의 윤리적 프레임워크로 봉사합니다. 특히, 차별과 비례성은 무고한 민간인을 보호하고 무력 사용이 정당한 군사적 목표와 엄격하게 일치하도록 보장함으로써 전쟁의 도덕적 정당성을 유지하는 데 핵심적입니다.\n차별의 원칙은 전투원과 비전투원 사이의 명확한 구분을 요구하여, 민간인과 다른 보호 대상을 불필요한 해로부터 보호합니다. 이 원칙은 의사 결정자가 복잡한 전장 시나리오를 평가하고 국제 인도주의법과 일치하는 판단을 내릴 수 있다고 가정합니다. 그럼에도 불구하고, 사전 프로그래밍된 알고리즘과 데이터셋에 의존하는 AWS는 역동적이고 예측 불가능한 환경에서 비전투원을 정확하게 식별하는 데 상당한 도전에 직면합니다. 불완전하거나 편향된 데이터셋이 AWS 의사 결정에 영향을 미칠 때, 차별 원칙의 심각한 위반 위험이 높아집니다.\n비례성의 원칙은 군사 행동으로 인한 해악이 예상되는 군사적 이점과 균형을 이루어야 한다고 요구합니다. 이 원칙은 단순한 계산을 넘어서, 도덕적 및 맥락적 요소를 포함하는 미묘한 평가를 요구합니다. 그러나 AWS는 사전 정의된 매개변수에 기반하여 작동하여, 실제 상황의 복잡성을 고려하지 못할 가능성이 있습니다. 예상치 못한 결과의 가능성은 AWS가 실제로 비례성 원칙을 일관되게 유지할 수 있는지에 대한 의문을 더욱 제기합니다.\n이 발표는 AWS가 차별과 비례성의 원칙을 효과적으로 준수할 수 있는지를 비판적으로 검토합니다. 전투원과 비전투원을 구별하고, 불법적인 목표를 피하고, 인간의 도덕적 기준에 부합하는 결정을 내리는 AWS의 기술적, 윤리적 능력을 평가합니다. 또한, AWS에 의한 치명적인 힘의 사용이 비례성 원칙 하에서 정당화될 수 있는지 탐구하고, 이러한 윤리적 원칙을 준수하기 위해 인간의 감독이 필요한 정도를 논의합니다.\n발표는 세 가지 주요 논의를 중심으로 구성됩니다. 첫째, AWS의 기술적 특성과 운영 역할을 분석하여 JWT의 확립된 원칙과 일치하는지 평가합니다. 둘째, 차별과 비례성의 윤리적, 실질적 해석을 재평가하여 AWS에 적용 가능성을 결정합니다. 셋째, 현대 전쟁에서 AWS와 같은 첨단 기술이 제기하는 윤리적 도전을 반영하도록 정전론 원칙을 재구성하는 대안적 접근법을 제안합니다.\n궁극적으로, 이 발표는 AI 혁신에서 기원하고 생명과 죽음의 의미를 가진 AWS를 면밀히 조사하는 윤리적 긴급성을 강조합니다. 정전론의 윤리적 경계 내에서 AWS를 평가하기 위한 프레임워크를 제공하여, 기술적 혁신과 도덕적 책임성의 균형을 맞추는 것을 목표로 합니다. 이 접근법은 정의와 인간성이 진화하는 분쟁의 맥락에서 중심에 남아 있도록 보장하면서 현대 전쟁의 윤리적 기준을 재정의하는 데 기여합니다.\n일반 발표 3\n예측, 투영, 그리고 수행성\n콘스탄틴 제닌 (튀빙겐 대학교)\n사회적 맥락에서 예측은 미래 결과에 대한 단순한 인과적으로 무력한 예견이 아니라 예측하려는 결과에 인과적 영향을 미친다는 것이 널리 인식되고 있습니다. 이는 특히 예측이 정책 결정에 직접적으로 영향을 미칠 때 그렇습니다. 예측이 자기 충족적이거나 자기 부정적일 수 있을 때, 실용적 고려사항과 인식론적 고려사항이 얽혀 있고, 정확성의 개념이 모호해집니다. 더욱이, 귀납적 위험의 개념은 재고되어야 합니다: 가치는 다른 종류의 오류의 결과를 고려해야 하기 때문에만 작용하는 것이 아니라, 예측이 잘못된 이유로 옳을 수 있다는 우려 때문에도 작용합니다. 수행성에 대처하는 방법에 대해 많은 제안이 이루어졌으며, 여기에는 수행적 효과를 “내재화”하거나, 사회적으로 바람직한 방향으로 결과를 유도하는 예측을 하는 것 등이 있습니다. 우리는 이러한 접근법이 잘못되었다고 주장합니다. 많은 바람직하지 않은 수행적 효과는 머신러닝 모델의 출력이 어떤 정책이 채택될 것인지 암묵적으로 추측하여 결과를 예측하는 예측과, 어떤 정책 옵션이 선택된다면 결과를 예측하는 반사실적 투영 사이에서 모호하기 때문에 발생합니다. 예측과 투영의 올바른 구별을 하면, 실용적 문제와 인식론적 문제를 깨끗하게 구별할 수 있습니다. 우리는 정확한 투영을 목표로 함으로써만 머신러닝 모델이 의사결정을 지원할 뿐만 아니라 담론을 지원할 수 있다고 주장합니다: 다양한 목표와 가치를 가진 논의자들이 정책 옵션 세트 중 어느 것이 최선의 반성적 타협을 나타내는지에 대한 담론에 참여할 수 있도록 관련 투영을 제공합니다.\n블랙 스완 이벤트 예측하기: 머신러닝의 최종 개척지?\n허원기 (서울대학교)\n블랙 스완 이벤트는 다음 세 가지 주요 특성을 가진 이벤트입니다: (i) 그것은 이상치입니다. (ii) 그것은 극단적인 영향을 미칩니다. (iii) 이벤트 이후, 우리는 그것이 실제보다 덜 무작위적이고 더 예측 가능하게 보이도록 하는 설명(또는 합리적인 이야기)을 만듭니다. 제1차 세계 대전, 소련의 해체, 9/11 테러, 귀납주의자 칠면조의 죽음은 전형적인 예입니다. 그들의 이상치 상태에도 불구하고, 많은 사람들이 블랙 스완 이벤트를 예측하고 싶어합니다. 이는 우리가 이러한 블랙 스완 이벤트를 예측할 수 있다면, 재앙적인 상황으로부터 우리의 삶을 방어할 수 있기 때문입니다. 최근, 일부 머신러닝 연구자들은 블랙 스완 예측 기계를 구축하려고 시도해 왔습니다. 그러나, 이것들은 의미 있는 시도입니까?\n이 발표에서, 저는 블랙 스완 예측 기계 구축에 대한 회의적인 논증을 제시할 것입니다. 성공적인 머신 예측을 위해서는 다음 조건들이 충족되어야 합니다: (i) 대량의 고품질 훈련 데이터, (ii) 잘 정의된 예측 작업, (iii) 예측 모델을 평가하기 위한 잘 정의된 대상 벤치마크 또는 특정 기준, (iv) 대상 도메인의 안정적인 배경 조건입니다.\n우리가 알다시피, 최근 몇 년 동안 머신러닝 모델은 놀라운 성공을 보여주었습니다(예: 바둑, 이미지 인식, 단백질 구조 예측). 이러한 경우, 머신러닝 모델의 설계와 훈련은 위의 조건을 잘 충족합니다. 그러나, 게임이나 자연 과학 연구와 달리, 희귀한 사회적 이벤트를 예측하는 것은 그러한 조건을 충족하기 어렵기 때문에 어렵습니다.\n첫째, 블랙 스완 이벤트는 매우 희귀하여, 패턴을 발견하기 위한 충분히 크고 고품질의 데이터셋을 준비하기 어렵습니다. 둘째, 예측 작업 자체를 정의하는 것이 어렵습니다. 예를 들어, 5년 내에 세계 인구의 5%가 사망하는 이벤트로 정의해야 할까요? 아니면 1조 달러의 손실을 초래하는 이벤트로 정의해야 할까요? 마찬가지로, 예측 모델을 평가하기 위한 기준을 설정하기도 어렵습니다. 가장 중요하게는, 우리의 사회적 환경이 끊임없이 변화하고 있기 때문에, 성공적인 블랙 스완 예측 모델이 미래에도 효과적으로 유지될 가능성이 낮습니다.\n환경 변화 외에도, 우리는 예측에 기반하여 행동을 조정하는데, 이는 소위 “준비성 역설”을 도입합니다. 블랙 스완 이벤트를 예측하면, 우리는 그것의 발생을 방지하기 위한 조치를 취할 것입니다. 이러한 조치가 성공적이라면, 블랙 스완 이벤트는 발생하지 않을 것입니다. 문제는 이 경우, 우리의 예측이나 치료를 테스트할 수 있는 쌍둥이 지구와 같은 것이 없기 때문에 예측 모델이 유용했는지 여부를 결정할 수 없다는 것입니다.\n결론적으로, 블랙 스완 예측 모델을 구축하는 것은 매우 어려울 뿐만 아니라, 만약 성공하더라도 평가하기 어렵습니다.\n일반 발표 4\n불투명성을 넘어서: ML 모델 이해에 있어 구현 세부사항이 중요한 이유\n이형석 (서울대학교)\n과학자들은 현상을 파악하고 정당화하기 위해 가설, 이론, 모델에 의존합니다. 반면에, 인간 인지 능력의 한계를 보완하기 위해 도입된 머신러닝(ML) 모델은 이론, 법칙, 메커니즘, 또는 과학적 모델에 의존하지 않습니다. 대신, ML 모델은 훈련을 위해 제공된 입력과 출력 데이터 사이의 올바른 대응을 나타내는 데이터 모델을 찾습니다. 결과적으로, ML에 의해 생성된 데이터 중심 모델은 대부분 불투명하고 인간이 이해하기 어렵습니다.\n이러한 상황에서, 과학자들이 예측이나 추론을 위해 불투명하고 이해하기 어려운 ML 모델을 점점 더 채택한다면 설명과 이해의 과학적 가치가 훼손될 것이라는 우려가 있습니다. 과학적 목적을 위한 ML 사용이 꾸준히 증가함에 따라, ML이 생성한 예측 결과를 이해하고 설명할 수 없는 것은 과학의 목표가 설명에서 단순한 예측으로 이동하고 있는지에 대한 의문을 제기합니다.\n이에 대응하여, Sullivan(2022)은 ML 모델을 사용할 때 우리의 과학적 이해가 제한되는 현상에 대한 부적절한 진단으로 인해 우리가 불필요하게 걱정하고 있다고 주장합니다. ML 모델의 불투명성은 우리의 이해를 해치지 않습니다; 그녀가 주장하는 실제 문제는 ML 모델과 현상을 연결하는 과학적 증거의 부족입니다. 그녀는 실제 세계의 설명과 이해를 촉진하기 위해서는 모델과 현상을 연결하는 증거를 확보해야 하며, 모델의 내부 구현 상태에 대해 더 많이 아는 것이 세계에 대한 우리의 이해를 증가시키지 않는다고 주장합니다.\n저는 구현 불투명성이 ML 모델의 이해를 방해하지 않는다는 Sullivan의 주장이 잘못되었다고 생각합니다. 그녀는 단지 가혹한 현실에서 고개를 돌렸을 뿐입니다. 구현 불투명성을 해결하지 않고는 ML 모델의 예측을 이해할 수 없습니다.\n첫째, 저는 Sullivan이 제공한 세 가지 예(Schelling의 분리 모델, 흑색종 감지 모델, 성적 지향 예측 모델)를 분석하여 그녀가 말하는 “링크 불확실성”이 무엇을 의미하는지 명확히 할 것입니다. 이 분석은 Sullivan이 설명하는 모델과 현상 사이의 연결이 두 단계를 통해 형성된다는 것을 보여줄 것입니다: 첫째, ML 모델을 인간이 인식할 수 있는 대리 모델로 대체하고, 둘째, 이 대리 모델을 현상을 나타내는 전통적인 과학적 모델에 연결하는 것입니다. 다음으로, 저는 ML 모델의 구현 과정을 파악하지 못하면, 충분히 발전된 xAI 기술을 사용하여 ML 모델을 인간이 인식할 수 있는 대리 모델로 대체함으로써 연결의 첫 번째 단계가 달성되더라도, 두 번째 단계의 성공이 매우 불안정할 수 있음을 보여줄 것입니다. 결과적으로, 저는 구현 불투명성을 해결하지 않고도 ML 모델을 통해 과학적 이해를 얻을 수 있다는 Sullivan의 주장이 받아들일 수 없다고 주장합니다. 왜냐하면 구현 불투명성을 해결하지 않고는 링크 불확실성을 해결할 수 없기 때문입니다.\nAI는 과학적 지식의 경로가 될 수 있는가?\n니콜라이 장 리 린딩 페더슨 (연세대학교)\n옌스 크리스티안 비예링 (오르후스 대학교)\n인공지능은 데이터를 수집, 분석, 해석하는 방식을 재형성하며 과학적 지식을 추구하는 데 있어 변혁적인 도구로서 점점 더 자리매김하고 있습니다. 그러나 어떤 조건 하에서 AI 시스템이 과학적 지식을 생산할 수 있을까요?\n지식에는 신뢰성이 요구됩니다(여기서는 그렇게 가정할 것입니다). 진실된 믿음은 신뢰할 수 있는 믿음 형성 방법이나 과정(즉, 대부분 참된 믿음을 생성하는 것)을 통해 형성된 경우에만 지식으로 자격을 갖습니다. 따라서, 진실된 AI 기반 과학적 믿음은 신뢰할 수 있는 AI 방법이나 믿음 형성 과정(즉, AI 결과를 입력으로 취하고 믿음을 출력으로 전달하는 방법이나 과정)을 통해 형성된 경우에만 지식으로 자격을 갖습니다. 우리는 신뢰성이 AI 기반 지식의 필요 조건일 수 있지만, 진실과 함께 충분하지 않다고 주장합니다. 신뢰성은 관련 AI 믿음 형성 방법이나 과정이 매우 부정확한 입력을 취하지 않도록 보장하는 조건으로 보완되어야 합니다.\n우리는 AI 시스템이 만들 수 있는 오류의 특징적 성격에 대한 고려를 통해 이 조건에 집중합니다. AI 시스템은 때때로 “미친” 또는 “놀라운” 오류를 범할 수 있습니다 - 예를 들어, 새를 자동차로 분류하는 것과 같은 오류입니다. 이러한 종류의 오류는 인간이 일반적으로 범하는 오류와 질적으로 다른 것으로 보입니다. 그것들은 단순히 사소한 부정확성을 반영하는 것이 아니라 처리되는 데이터와 연결되지 않은 것처럼 보이는 극단적인 실패를 드러냅니다.\n이런 잘못된 AI 생성 결과를 입력으로 취하는 방법이나 과정을 통해 믿음을 형성하는 것은 지식의 전망을 훼손하기 때문에 인식론적으로 위험합니다. 이 점은 두 수준의 인식론적 평가를 특징으로 하는 프레임워크 내에서 명확히 되고 주장됩니다: 방법이나 과정의 믿음 출력의 인식론적 가치와 그 입력의 정확성입니다. 인식론적 가치는 삼분법적입니다. 세 가지 인식론적 가치가 있습니다: 진실, 거짓, 그리고 지식입니다. 정확성은 단위 간격, 즉 [0; 1]의 실수 값을 취합니다.\n믿음 형성 방법과 과정이 고도로 부정확한 입력을 취하지 않아야 한다는 조건은 최대최소 스타일의 조건입니다. 입력의 최소 정확성이 너무 낮지 않아야 합니다. 이 조건을 충족하지 못한다는 것은 때때로 고도로 부정확한 입력을 취하는 방법이나 과정을 통해 믿음을 형성한다는 것을 의미합니다. 이는 지식과 양립할 수 없기 때문에 인식론적으로 위험합니다. 따라서, 고도로 부정확한 입력은 지식의 전망을 훼손합니다.\n우리는 높은 부정확성과 지식 사이의 연결에 대해 다음과 같은 진단을 제공합니다: 소스 S로부터의 출력을 입력으로 취하는 믿음 형성 방법이나 과정의 경우, S의 일부 출력이 극도로 부정확하다면 S의 역량이 훼손됩니다. 그러나, 소스가 역량을 갖추지 못한다는 것은 그것의 전달에 기반하여 믿음을 형성하는 것이 대부분 참된 믿음으로 이어진다 하더라도 지식의 기초로 기능할 수 없다는 것을 의미합니다. 따라서, 때때로 고도로 부정확한 출력을 제공하는 AI 시스템은 그들의 출력에 기반하여 형성된 대부분의 믿음이 참이라고 하더라도 지식의 기초로 기능할 수 없습니다. 이는 그러한 AI 시스템이 역량을 보여주지 못하기 때문입니다.\n프로그램",
    "crumbs": [
      "Data Science",
      "2025 Seoul Workshop on Philosophy of Machine Learning"
    ]
  },
  {
    "objectID": "extracted/An Introduction to Causal Inference.html",
    "href": "extracted/An Introduction to Causal Inference.html",
    "title": "An Introduction to Causal Inference",
    "section": "",
    "text": "The International Journal of Biostatistics\nVolume 6,Issue 2 2010 Article 7\nCAUSAL INFERENCE\nRecommended Citation:\nPearl, Judea (2010) “An Introduction to Causal Inference,”The International Journal of Biostatistics: Vol. 6: Iss. 2, Article 7.",
    "crumbs": [
      "Causal Inference",
      "An Introduction to Causal Inference"
    ]
  },
  {
    "objectID": "extracted/An Introduction to Causal Inference.html#abstract",
    "href": "extracted/An Introduction to Causal Inference.html#abstract",
    "title": "An Introduction to Causal Inference",
    "section": "Abstract",
    "text": "Abstract\nThis paper summarizes recent advances in causal inference and underscores the paradigmatic shifts that must be undertaken in moving from traditional statistical analysis to causal analysis of multivariate data. Special emphasis is placed on the assumptions that underlie all causal inferences, the languages used in formulating those assumptions, the conditional nature of all causal and counterfactual claims, and the methods that have been developed for the assessment of such claims. These advances are illustrated using a general theory of causation based on the Structural Causal Model (SCM) described in Pearl (2000a), which subsumes and unifies other approaches to causation, and provides a coherent mathematical foundation for the analysis of causes and counterfactuals. In particular, the paper surveys the development of mathematical tools for inferring (from a combination of data and assumptions) answers to three types of causal queries: those about (1) the effects of potential interventions, (2) probabilities of counterfactuals, and (3) direct and indirect effects (also known as “mediation”). Finally, the paper defines the formal and conceptual relationships between the structural and potential-outcome frameworks and presents tools for a symbiotic analysis that uses the strong features of both. The tools are demonstrated in the analyses of mediation, causes of effects, and probabilities of causation.\nKEYWORDS: structural equation models, confounding, graphical methods, counterfactuals, causal effects, potential-outcome, mediation, policy evaluation, causes of effects Author Notes: Portions of this paper are adapted from Pearl (2000a, 2009a,b); I am indebted to EljaArjas,SanderGreenland,DavidMacKinnon,PatrickShrout,andmanyreadersoftheUCLA Causality Blog (http://www.mii.ucla.edu/causality/) for reading and commenting on various segments of this manuscript, and especially to Erica Moodie and David Stephens for their thorougheditorialinput.ThisresearchwassupportedinpartsbyNIHgrant#1R01LM009961-01, NSF grant #IIS-0914211, and ONR grant #N000-14-09-1-0665.",
    "crumbs": [
      "Causal Inference",
      "An Introduction to Causal Inference"
    ]
  },
  {
    "objectID": "extracted/An Introduction to Causal Inference.html#introduction",
    "href": "extracted/An Introduction to Causal Inference.html#introduction",
    "title": "An Introduction to Causal Inference",
    "section": "1. Introduction",
    "text": "1. Introduction\nMost studies in the health, social and behavioral sciences aim to answer causal\nrather than associative – questions. Such questions requiresome knowledgeof the data-generatingprocess, andcannotbecomputedfromthedataalone, norfromthe distributions that govern the data. Remarkably, although much of the conceptual framework and algorithmic tools needed for tackling such problems are now well established, they are not known to many of the researchers who could put them into practical use. Solving causal problems systematically requires certain exten- sions in the standard mathematical language of statistics, and these extensions are not typically emphasized in the mainstream literature. As a result, many statistical researchers have not yet benefited from causal inference results in (i) counterfac- tualanalysis,(ii)nonparametricstructuralequations,(iii)graphicalmodels,and(iv) the symbiosis between counterfactual and graphical methods. This survey aims at making these contemporaryadvances more accessible by providing a gentle intro- duction to causal inference for a more in-depth treatment and its methodological principles(see (Pearl,2000a, 2009a,b)).\nIn Section 2, we discuss coping with untested assumptions and new math- ematical notation which is requiredto move fromassociational to causal statistics.\nSection 3.1 introduces the fundamentals of the structural theory of causation and uses these modeling fundamentals to represent interventions and develop mathe- matical tools for estimating causal effects (Section 3.3) and counterfactual quanti- ties (Section 3.4). Section 4 outlines a general methodology to guide problems of causal inference: Define, Assume, IdentifyandEstimate, with each step benefiting fromthe toolsdevelopedinSection3.\nSection 5 relates these tools to those used in the potential-outcome frame- work, and offers a formal mapping between the two frameworks and a symbiosis (Section 5.3) that exploits the best features of both. Finally, the benefit of this symbiosisisdemonstratedinSection6,inwhichthestructure-basedlogicofcoun- terfactuals is harnessed to estimate causal quantities that cannot be defined within theparadigmofcontrolledrandomizedexperiments. These includedirectandindi- rect effects, the effect of treatmenton the treated, and questions of attribution, i.e., whetheroneevent canbe deemed“responsible” foranother.",
    "crumbs": [
      "Causal Inference",
      "An Introduction to Causal Inference"
    ]
  },
  {
    "objectID": "extracted/An Introduction to Causal Inference.html#from-association-to-causation",
    "href": "extracted/An Introduction to Causal Inference.html#from-association-to-causation",
    "title": "An Introduction to Causal Inference",
    "section": "2. From Association to Causation",
    "text": "2. From Association to Causation\n\n2.1 Understanding the distinction and its implications\nTheaimofstandardstatisticalanalysisistoassessparametersofadistributionfrom samples drawn of that distribution. With the help of such parameters, associations among variables can be inferred, which permits the researcher to estimate prob- abilities of past and future events and update those probabilities in light of new information. These tasks are managed well by standard statistical analysis so long as experimentalconditionsremainthesame. Causal analysis goes onestep further; its aim is to infer probabilities under conditions that are changing, for example, changes inducedbytreatmentsorexternalinterventions.\nThis distinction implies that causal and associational concepts do not mix; thereis nothingin a distributionfunctionto tellus howthat distributionwoulddif- fer if external conditions were to change—say from observational to experimental setup—because the laws ofprobabilitytheorydonotdictatehowonepropertyofa distribution ought to change when another property is modified. This information must be provided by causal assumptions which identify relationships that remain invariantwhen externalconditionschange.\nA useful demarcation line between associational and causal concepts crisp and easy to apply, can be formulated as follows. An associational concept is any relationship that can be defined in terms of a joint distribution of observed vari- ables, and a causal concept is any relationship that cannot be defined from the distribution alone. Examples of associational concepts are: correlation, regres- sion, dependence, conditional independence, likelihood, collapsibility, propensity score, risk ratio, odds ratio, marginalization, conditionalization, “controlling for,” andmanymore. Examplesofcausalconceptsare: randomization,influence,effect, confounding, “holding constant,” disturbance, error terms, structural coefficients, spurious correlation, faithfulness/stability, instrumentalvariables, intervention, ex- planation, and attribution. The former can, while the latter cannot be defined in termofdistributionfunctions.\nThisdemarcationlineisextremelyusefulintracingtheassumptionsthatare needed for substantiating various types of scientific claims. Every claim invoking causalconceptsmustrelyonsomepremisesthatinvokesuchconcepts;itcannotbe inferredfrom,orevendefinedin termsstatisticalassociations alone.\nThis distinction furtherimplies that causal relations cannot be expressed in the language of probability and, hence, that any mathematical approach to causal analysis must acquire new notation – probability calculus is insufficient. To illus- trate,thesyntaxofprobabilitycalculusdoesnotpermitustoexpressthesimplefact that “symptoms do not cause diseases,” let alone draw mathematical conclusions from such facts. All we can say is that two events are dependent—meaning that if we find one, we can expect to encounter the other, but we cannot distinguish sta- tistical dependence, quantified by the conditional probability P(disease|symptom) from causal dependence, for which we have no expression in standard probability calculus.\n\n\n2.2 Untested assumptions and new notation\n1 The preceding two requirements: (1) to commence causal analysis with untested, theoretically or judgmentally based assumptions, and (2) to extend the syntax of probabilitycalculus, constitutethetwoprimarybarrierstotheacceptance ofcausal analysis amongprofessionalswithtraditionaltraininginstatistics.\nAssociational assumptions, even untested, are testable in principle, given sufficiently large sample and sufficiently fine measurements. Causal assumptions, in contrast, cannot be verified even in principle, unless one resorts to experimental control. This difference stands out in Bayesian analysis. Though the priors that Bayesians commonly assign to statistical parameters are untested quantities, the sensitivitytothesepriorstendstodiminishwithincreasingsamplesize. Incontrast, sensitivity to prior causal assumptions, say that treatment does not change gender, remainssubstantial regardlessofsample size.\nThis makes it doubly important that the notation we use for expressing causal assumptions be cognitively meaningful and unambiguous so that one can clearly judge the plausibility or inevitabilityof the assumptions articulated. Statis- ticianscannolongerignorethementalrepresentationinwhichscientistsstoreexpe- rientialknowledge,sinceitisthisrepresentation,andthelanguageusedtoaccess it thatdeterminethereliabilityofthejudgmentsuponwhichthe analysis so crucially depends.\nThoseversedinthepotential-outcomenotation(Neyman,1923,Rubin,1974, Holland,1988),canrecognizecausalexpressions throughthesubscriptsthatareat- tached to counterfactualevents and variables, e.g. Y (u) or Z . (Some authors use x xy parentheticalexpressions,e.g. Y(0),Y(1),Y(x,u)orZ(x,y).) TheexpressionY (u), x for example, stands for the value that outcome Y would take in individual u, had treatment X been at level x. If u is chosen at random,Y is a random variable, and x one can talk about the probability thatY would attain a value y in the population, x written P(Y = y) (see Section 5 for semantics). Alternatively, Pearl (1995) used x expressions of the formP(Y =y|set(X =x)) or P(Y =y|do(X =x)) to denote the probability (or frequency) that event (Y = y) would occur if treatment condition 1 By“untested”Imeanuntestedusingfrequencydatainnonexperimentalstudies.\n2 X =x were enforceduniformlyover thepopulation. Stilla thirdnotationthatdis- tinguishes causal expressions is provided by graphical models, where the arrows convey causal directionality.\nHowever, few have taken seriously the textbook requirement that any in- troduction of new notation must entail a systematic definition of the syntax and semantics that governs the notation. Moreover, in the bulk of the statistical litera- turebefore2000,causalclaimsrarelyappearinthemathematics. Theysurfaceonly in the verbal interpretation that investigators occasionally attach to certain associ- ations, and in the verbal description with which investigators justify assumptions.\nFor example, the assumption that a covariate not be affected by a treatment, a nec- essary assumption for the control of confounding (Cox, 1958, p. 48), is expressed inplainEnglish, not inamathematicalexpression.\nThe next section provides a conceptualization that overcomes these mental barriersbyofferingafriendlymathematicalmachineryforcause-effectanalysisand a formalfoundationforcounterfactualanalysis.",
    "crumbs": [
      "Causal Inference",
      "An Introduction to Causal Inference"
    ]
  },
  {
    "objectID": "extracted/An Introduction to Causal Inference.html#structural-models-diagrams-causal-effects-and-counterfactuals",
    "href": "extracted/An Introduction to Causal Inference.html#structural-models-diagrams-causal-effects-and-counterfactuals",
    "title": "An Introduction to Causal Inference",
    "section": "3. Structural Models, Diagrams, Causal Effects, and Counterfactuals",
    "text": "3. Structural Models, Diagrams, Causal Effects, and Counterfactuals\nAny conception of causation worthy of the title “theory” must be able to (1) represent causal questions in some mathematical language, (2) provide a precise lan- guage for communicating assumptions under which the questions need to be an- swered, (3)providea systematic wayofansweringat least someofthese questions andlabelingothers“unanswerable,” and(4)provideamethodofdeterminingwhat assumptions ornewmeasurementswouldbeneeded toanswer the“unanswerable” questions.\nA “general theory” should do more. In addition to embracing all questions judged to have causal character, a general theorymust also subsume any other the- ory or method that scientists have found useful in exploring the various aspects of causation. In other words, any alternative theory needs to evolve as a special case ofthe“general theory”whenrestrictionsareimposed oneitherthemodel, thetype ofassumptions admitted,orthelanguage inwhichthose assumptionsare cast.\nThestructuraltheorythatweuseinthissurveysatisfiesthecriteriaabove. It is based on the StructuralCausal Model (SCM) developed in (Pearl, 1995, 2000a) 2 Clearly,P(Y =y|do(X =x)) isequivalenttoP(Yx=y). Thisiswhatwenormallyassess ina controlledexperiment,withX randomized,inwhichthedistributionofY isestimatedforeachlevel xofX.\nwhich combines features of the structural equation models (SEM) used in eco- nomicsandsocialscience(Goldberger,1973,Duncan,1975),thepotential-outcome framework of Neyman (1923) and Rubin (1974), and the graphical models devel- oped for probabilistic reasoning and causal analysis (Pearl, 1988, Lauritzen, 1996, Spirtes,Glymour,andScheines, 2000, Pearl,2000a).\nAlthough the basic elements of SCM were introduced in the mid 1990’s (Pearl,1995),andhave been adaptedwidelybyepidemiologists(Greenland,Pearl, andRobins,1999,GlymourandGreenland,2008),statisticians(CoxandWermuth, 2004, Lauritzen, 2001), and social scientists (Morgan and Winship, 2007), its po- tentials as a comprehensive theory of causation are yet to be fully utilized. Its ramificationsthusfarinclude:\n\nThe unification of the graphical, potential outcome, structural equations, de- cision analytical (Dawid, 2002),interventional(Woodward,2003), sufficient component (Rothman,1976) and probabilistic(Suppes, 1970)approaches to causation;witheach approachviewedas a restrictedversionoftheSCM.\nThe definition, axiomatization and algorithmization of counterfactuals and jointprobabilitiesofcounterfactuals\nReducingtheevaluationof“effectsofcauses,”“mediatedeffects,”and“causes ofeffects”toan algorithmiclevelofanalysis.\nSolidifying the mathematical foundations of the potential-outcome model, andformulatingthecounterfactualfoundationsofstructuralequationmodels.\nDemystifyingenigmaticnotionssuchas“confounding,”“mediation,”“ignor- ability,”“comparability,”“exchangeability(ofpopulations),”“superexogene- ity”andothers withina singleand familiarconceptualframework.\nWeeding out myths and misconceptions from outdated traditions (Meek and Glymour, 1994, Greenland et al., 1999, Cole and Herna´n, 2002, Arah,2008, Shrier,2009,Pearl,2009c).\n\nThis section provides a gentle introductionto the structural frameworkand uses it to present the main advances in causal inference that have emerged in the past twodecades.\n\n3.1 A brief introduction to structural equation models\nHowcanoneexpressmathematicallythecommonunderstandingthatsymptomsdo not cause diseases? The earliest attemptto formulatesuch relationshipmathemati- cally was made in the 1920’s by the geneticist SewallWright (1921). Wright used a combination of equations and graphs to communicate causal relationships. For example, if X stands for a disease variable and Y stands for a certain symptom of 3 thedisease, Wrightwouldwritea linearequation: y=βx+u (1) Y where x stands for the level (or severity) of the disease, y stands for the level (or severity) of the symptom, and u stands for all factors, other than the disease in Y question, that could possibly affectY when X is held constant. In interpretingthis equationoneshouldthinkofaphysicalprocesswherebyNatureexaminesthevalues ofx and uand, accordingly,assigns variableY thevaluey=βx+u . Similarly,to Y “explain”theoccurrenceofdisease X,onecouldwritex=u ,whereU standsfor X X allfactorsaffectingX.\nEquation (1) still does not properly express the causal relationship implied bythisassignmentprocess, because algebraicequationsaresymmetricalobjects;if we re-write(1)as x=(y−u )/β (2) Y it mightbemisinterpretedto meanthat thesymptom influencesthe disease. To ex- press the directionality of the underlying process, Wright augmented the equation with a diagram, later called “path diagram,” in which arrows are drawn from (per- ceived)causes to their(perceived)effects, and moreimportantly,theabsence ofan arrowmakestheempiricalclaimthatNatureassignsvaluestoonevariableirrespec- tiveofanother. InFig. 1,forexample, theabsence ofarrowfromY to X represents theclaimthatsymptomY isnotamongthefactorsU whichaffectdiseaseX. Thus, X in our example, the complete model of a symptom and a disease would be written asinFig.1: Thediagramencodesthepossibleexistenceof(direct)causalinfluence of X onY, and the absence of causal influence ofY on X, while the equations en- code the quantitative relationships among the variables involved, to be determined fromthe data. The parameterβ in the equation is called a “path coefficient”and it quantifies the (direct)causal effectof X onY; given the numericalvalues ofβ and U , the equation claims that, a unit increase forX would result inβ units increase Y ofY regardless of the values taken by other variables in the model, and regardless ofwhethertheincrease inX originatesfromexternalorinternalinfluences.\nThevariablesU andU arecalled“exogenous;”theyrepresentobservedor X Y unobserved background factors that the modeler decides to keep unexplained, that is, factors that influence but are not influenced by the other variables (called “en- dogenous”) in the model. Unobserved exogenous variables are sometimes called “disturbances”or“errors”,theyrepresentfactorsomittedfromthemodelbutjudged 3 Linear relations are used here for illustration purposes only; they do not represent typical disease-symptom relationsbutillustratethe historicaldevelopmentof pathanalysis. Additionally, wewillusestandardizedvariables,thatis,zeromeanandunitvariance.\ntoberelevantforexplainingthebehaviorofvariablesinthemodel. VariableU ,for X example, represents factorsthat contributetothe disease X, which mayor maynot becorrelatedwithU (thefactorsthatinfluencethesymptomY). Thus,background Y factors in structural equations differ fundamentally from residual terms in regres- sion equations. The latters are artifacts ofanalysis which, by definition, are uncor- related with the regressors. The formers are part of physical reality (e.g., genetic factors, socio-economic conditions) which are responsible for variations observed in the data; they are treated as any other variable, though we often cannot measure theirvaluespreciselyandmustresigntomerelyacknowledgingtheirexistence and assessing qualitativelyhowthey relatetoothervariablesinthe system.\nIfcorrelationis presumed possible, it is customary to connect the twovari- ables,U andU , byadashed doublearrow,as showninFig. 1(b).\nY X U U U U X Y X Y x = u X y = β x + u Y X β Y X β Y (a) (b) Figure 1: A simple structural equation model, and its associated diagrams. Unob- served exogenousvariables areconnectedbydashed arrows.\nIn reading path diagrams, it is common to use kinship relations such as parent, child, ancestor, and descendent, the interpretation of which is usually self evident. For example, an arrow X →Y designates X as a parent of Y and Y as a child of X. A “path” is any consecutive sequence of edges, solid or dashed. For example, there are two paths between X and Y in Fig. 1(b), one consisting of the directarrowX →Y whilethe othertracingthe nodesX,U ,U andY.\nX Y Wright’s major contribution to causal analysis, aside from introducing the languageofpathdiagrams, hasbeenthedevelopmentofgraphicalrulesforwriting down the covariance ofany pairof observed variables in terms of path coefficients andofcovariancesamongtheerrorterms. Inoursimpleexample, onecanimmedi- atelywritetherelations Cov(X,Y)=β (3) forFig.1(a),and Cov(X,Y)=β+Cov(U ,U ) (4) Y X for Fig. 1(b) (These can be derived of course from the equations, but, for large models, algebraic methods tend to obscure the origin of the derived quantities).\nUnder certain conditions, (e.g. if Cov(U ,U ) =0), such relationships may allow Y X onetosolveforthepathcoefficientsintermofobservedcovariancetermsonly,and this amounts to inferring the magnitude of (direct) causal effects from observed, nonexperimental associations, assuming of course that one is prepared to defend thecausal assumptions encodedin thediagram.\nIt is important to note that, in path diagrams, causal assumptions are en- coded not in the links but, rather, in the missing links. An arrow merely indicates thepossibilityofcausalconnection,thestrengthofwhichremainstobedetermined (from data); a missing arrow represents a claim of zero influence, while a missing double arrow represents a claim of zero covariance. In Fig. 1(a), for example, the assumptions thatpermitsus toidentifythedirecteffectβare encodedby themiss- ingdoublearrowbetweenU andU , indicatingCov(U ,U )=0, togetherwiththe X Y Y X missing arrow from Y to X. Had any of these two links been added to the dia- gram, we would not have been able to identify the direct effectβ. Such additions wouldamountto relaxingthe assumptionCov(U ,U )=0, or theassumption that Y X Y does not effect X, respectively. Note also that both assumptions are causal, not associational, since none can be determined fromthe joint density of the observed variables, X andY; the association between the unobserved terms,U andU , can Y X only be uncovered in an experimental setting; or (in more intricate models, as in Fig.5)fromothercausal assumptions.\nAlthough each causal assumption in isolation cannot be tested, the sum to- tal of all causal assumptions in a model often has testable implications. The chain model of Fig. 2(a), for example, encodes seven causal assumptions, each corre- spondingtoamissingarroworamissingdouble-arrowbetweenapairofvariables.\nNone of those assumptions is testable in isolation, yet the totality of all those as- sumptionsimpliesthatZisunassociatedwithY ineverystratumofX. Suchtestable implications can be read off the diagrams using a graphical criterion known as d- separation (Pearl,1988).\nDefinition 1(d-separation) A set S of nodes is said to block a path p ifeither (i) p containsatleastonearrow-emittingnodethatisinS,or(ii) pcontainsatleastone collision node that is outside S and has no descendant in S. If S blocks all paths fromX toY,itissaidto“d-separateX andY,”andthen,X andY are independent givenS, writtenX⊥⊥Y|S.\nTo illustrate, the path U → Z → X → Y is blocked by S = {Z} and by Z S = {X}, since each emits an arrow along that path. Consequently we can infer thattheconditionalindependenciesU ⊥⊥Y|Z andU ⊥⊥Y|X willbesatisfiedinany Z Z probabilityfunctionthatthismodelcangenerate,regardlessofhowweparametrize the arrows. Likewise, the pathU →Z →X ←U is blocked by the null set {0/} Z X but is not blocked by S = {Y}, since Y is a descendant of the collision node X.\nConsequently, the marginal independence U ⊥⊥U will hold in the distribution, Z X butU ⊥⊥U |Y may or may not hold. This special handling of collision nodes (or Z X colliders, e.g., Z → X ←U ) reflects a general phenomenon known as Berkson’s X paradox (Berkson,1946),wherebyobservationsona commonconsequence oftwo independent causes render those causes dependent. For example, the outcomes of twoindependentcoins are rendereddependentby thetestimony thatat least one of themis atail.\nTheconditionalindependenciesentailedbyd-separationconstitutethemain openingthroughwhichtheassumptionsembodiedinstructuralequationmodelscan confrontthe scrutinyofnonexperimentaldata. Inotherwords,almostall statistical 4 tests capable ofinvalidatingthemodelareentailed bythoseimplications.\nU U U U U U Z X Y Z X Y x 0 Z X Y Z X Y (a) (b) Figure 2: (a) The diagram associated with the structural model of Eq. (5). (b) The diagram associated with the modified model of Eq. (6), representing the interven- tiondo(X =x0).\n\n\n3.2 From linear to nonparametric models and graphs\nStructural equation modeling (SEM) has been the main vehicle for effect analysis in economics and the behavioral and social sciences (Goldberger, 1972, Duncan, 1975, Bollen, 1989). However, the bulk of SEM methodology was developed for linear analysis and, until recently, no comparable methodology has been devised to extend its capabilities to models involving dichotomous variables or nonlinear dependencies. A centralrequirementforany such extension is todetach the notion of “effect” fromits algebraic representation as a coefficientin an equation, and re- define “effect”as a general capacity totransmitchanges among variables. Such an extension, based on simulating hypothetical interventions in the model, was pro- posedin(Haavelmo,1943,StrotzandWold,1960,Spirtes,Glymour,andScheines, 1993, Pearl,1993a, 2000a, Lindley, 2002)andhas led tonew waysofdefiningand estimatingcausal effectsinnonlinearand nonparametricmodels(thatis, modelsin whichthe functionalformofthe equationsis unknown).\n4 Additionalimplicationscalled“dormantindependence”(ShpitserandPearl,2008)maybede- ducedfromsomegraphswithcorrelatederrors(VermaandPearl,1990).\nThe centralidea istoexploittheinvariantcharacteristicsofstructuralequa- tions without committing to a specific functional form. For example, the non- parametric interpretation of the diagram of Fig. 2(a) corresponds to a set of three functions,each correspondingto oneoftheobserved variables:\n\\[z = f_Z(u_Z)\\] \\[x = f_X(z,u_X)\\] \\[y = f_Y(x,u_Y)\\]\nwhere in this particular example \\(U_Z, U_X\\) are assumed to be jointly independent but, otherwise, arbitrarilydistributed. Each ofthese functionsrepresents a causalprocess(ormechanism)thatdeterminesthevalueoftheleftvariable(output) fromthose on the rightvariables (inputs). The absence of a variablefromthe right hand side of an equation encodes the assumption that Nature ignores that variable in the process of determining the value of the output variable. For example, the absence of variable \\(Z\\) from the arguments of \\(f_Y\\) conveys the empirical claim that variations in Z will leave Y unchanged, as long as variables \\(U_Y\\), and \\(X\\) remain constant. A system of such functions are said to be structural if they are assumed to be autonomous,that is,each function is invariant to possible changes in the form of the other functions (Simon,1953,Koopmans, 1953).\n\n3.2.1 Representing interventions\nThis featureofinvariancepermitsusto usestructuralequationsas abasis formod- elingcausal effectsand counterfactuals. This is donethroughamathematicaloper- ator called do(x) which simulates physical interventions by deleting certain func- tionsfromthemodel,replacingthembyaconstantX =x, whilekeepingtherestof themodelunchanged. Forexample, toemulatean interventiondo(x0)that holdsX constant (at X =x0) in model M of Fig. 2(a), we replace the equation for x in Eq.\n(5)withx=x0,and obtainanew model,M x0,\n\\[z = f_Z(u_Z)\\] \\[x = x_0\\] \\[y = f_Y(x,u_Y)\\]\nthegraphicaldescriptionofwhichis showninFig. 2(b).\nThe joint distribution associated with the modified model, denoted \\(P(z,y|do(x_0))\\) describesthepost-interventiondistributionofvariablesY andZ (also called “controlled” or “experimental” distribution), to be distinguished from the pre-intervention distribution, \\(P(x,y,z)\\), associated with the original model of Eq.\n(5). Forexample, ifX represents atreatmentvariable,Y a response variable,and Z some covariate that affects the amount of treatment received, then the distribution P(z,y|do(x0)) gives the proportion of individuals that would attain response level Y =y andcovariatelevel Z =z underthehypotheticalsituationin whichtreatment X =x0 is administereduniformlyto thepopulation.\nIn general, we can formallydefine the post-intervention distributionby the equation:\n\\[P_M(y|do(x)) \\triangleq P_{M_{x}}(y) \\tag{7}\\]\nIn words: In the frameworkof model M, the post-intervention distribution of out- come Y is defined as the probability that model M assigns to each outcome level Y = y.\nFromthisdistribution,oneisabletoassess treatmentefficacybycomparing aspectsofthisdistributionatdifferentlevelsofx0. Acommonmeasureoftreatment efficacyis theaverage difference\n\\[ E(Y|do(x'_0)) - E(Y|do(x_0)) \\tag{8)\\]\nwhere x′ and x0 are two levels (or types) of treatment selected for comparison.\nAnothermeasureis theexperimentalRisk Ratio\n\\[E(Y|do(x′_0)) / E(Y|do(x_0)) \\tag{9}\\]\nThe variance \\(Var(Y|do(x_0))\\), or any other distributional parameter, may also enter the comparison; all these measures can be obtained from the controlled distribu- tion function \\(P(Y =y|do(x)) = ∑_{z} P(z,y|do(x))\\) which was called “causal effect” in Pearl(2000a, 1995)(see footnote2). The centralquestion in the analysis of causal effects is the question of identification: Can the controlled (post-intervention)dis- tribution, \\(P(Y =y|do(x))\\), be estimated from data governed by the pre-intervention distribution, \\(P(z,x,y)\\)?\nThe problemof identificationhas received considerable attention inecono- metrics (Hurwicz, 1950, Marschak, 1950, Koopmans, 1953) and social science (Duncan, 1975, Bollen, 1989), usually in linear parametric settings, where it re- duces to asking whether some model parameter,β, has a unique solution in terms of the parameters of P (the distributionof the observed variables). In the nonpara- metricformulation,identificationismoreinvolved,sincethenotionof“hasaunique solution” does not directly apply to causal quantities such as Q(M) = P(y|do(x)) which have no distinct parametric signature, and are defined procedurally by sim- ulating an intervention in a causal model M (as in (6)). The following definition overcomes these difficulties:\nDefinition 2(Identifiability(Pearl,2000a, p. 77)) A quantity Q(M) is identifiable, given a set of assumptions A, if for any two models M1 and M2 that satisfy A, we have \\[P(M_1)=P(M_2) ⇒ Q(M_1)=Q(M_2) \\tag{10}\\]\nIn words, the details of M1 and M2 do not matter; what matters is that the assumptions in A(e.g., thoseencoded inthediagram)would constrainthevariabil- ity of those details in such a way that equality of P’s would entail equality of Q’s.\nWhen this happens, Q depends on P only, and should therefore be expressible in terms of the parameters of P. The next subsections exemplify and operationalize thisnotion.\n\n\n3.2.2 Estimating the effect of interventions\nTo understand how hypothetical quantities such as P(y|do(x)) or E(Y|do(x0)) can be estimated from actual data and a partially specified model let us begin with a simpledemonstrationonthemodelofFig. 2(a). We willsee that,despite ourigno- rance of f X, f Y, f and P(u), E(Y|do(x0)) is nevertheless identifiable and is given Z bytheconditionalexpectationE(Y|X =x0). Wedothisbyderivingandcomparing theexpressionsforthesetwoquantities,asdefinedby(5)and(6),respectively. The mutilatedmodelinEq. (6)dictates: E(Y|do(x0))=E(f Y(x0,u Y)), (11) whereas thepre-interventionmodelofEq. (5)gives E(Y|X =x0)) = E(f Y(X,u Y)|X =x0) = E(f Y(x0,u Y)|X =x0) (12) = E(f Y(x0,u Y)) whichis identicalto(11). Therefore, E(Y|do(x0))=E(Y|X =x0)) (13) Using a similar derivation, though somewhat more involved, we can show that P(y|do(x)) isidentifiableandgiven bytheconditionalprobabilityP(y|x).\nWe see that the derivationof(13) was enabled by two assumptions; first,Y is a functionofX andU only, and, second,U is independent of{U ,U }, hence Y Y Z X of X. The latter assumption parallels the celebrated “orthogonality” condition in linearmodels,Cov(X,U )=0, whichhas been used routinely,oftenthoughtlessly, Y tojustifytheestimationofstructuralcoefficientsbyregressiontechniques.\nNaturally, if we were to apply this derivation to the linear models of Fig.\n1(a)or1(b),wewouldgettheexpecteddependencebetweenY andtheintervention do(x0): E(Y|do(x0)) = E(f Y(x0,u Y)) = E(βx0+u Y) (14) = βx0\nThis equality endows β with its causal meaning as “effect coefficient.” It is ex- tremely important to keep in mind that in structural (as opposed to regressional) models, β is not “interpreted” as an effect coefficient but is “proven” to be one by the derivationabove. β willretain this causal interpretationregardless of how X is actually selected (throughthe function f , Fig. 2(a))and regardless of whetherU X X andU arecorrelated(asinFig.1(b))oruncorrelated(asinFig.1(a)). Correlations Y may onlyimpedeour abilitytoestimateβ fromnonexperimentaldata, butwillnot change its definition as given in (14). Accordingly, and contrary to endless confu- sions in the literature (see footnote 12) structural equations say absolutely nothing about the conditional expectation E(Y|X = x). Such connection may exist under special circumstances, e.g., ifcov(X,U )=0, as in Eq. (13),butis otherwiseirrel- Y evanttothedefinitionorinterpretationofβaseffectcoefficient,ortotheempirical claims ofEq. (1).\nThe next subsection will circumvent these derivations altogether by reduc- ingtheidentificationproblemtoagraphicalprocedure. Indeed,sincegraphsencode all the information that non-parametric structural equations represent, they should permitustosolvetheidentificationproblemwithoutresortingtoalgebraicanalysis.\n\n\n3.2.3 Causal effects from data and graphs\nCausal analysis in graphical models begins with the realization that all causal ef- fects areidentifiablewheneverthemodelis Markovian,thatis, thegraphis acyclic (i.e., containingno directed cycles) and all the errorterms are jointly independent.\nNon-Markovian models, such as those involving correlated errors (resulting from unmeasured confounders), permit identification only under certain conditions, and these conditionstoo can bedeterminedfromthegraphstructure(Section3.3). The keytothese results restswiththe followingbasic theorem.\nTheorem1 (TheCausal MarkovCondition) AnydistributiongeneratedbyaMarko- vianmodelM can befactorized as: P(v1,v2,…,v n)=∏P(v i|pa i) (15) i whereV1,V2,…,V are theendogenousvariables inM, and pa are (values of)the n i endogenous“parents” ofV in thecausaldiagramassociated with M.\ni For example, the distribution associated with the model in Fig. 2(a) can be factorizedas P(z,y,x)=P(z)P(x|z)P(y|x) (16) since X is the(endogenous)parentofY,Z isthe parentofX, andZ has noparents.\nCorollary1(Truncated factorization) For any Markovian model, the distribution generated by an intervention do(X = x0) on a set X of endogenous variables is givenby thetruncated factorization P(v1,v2,…,v k|do(x0))= ∏ P(v i|pa i)| (17) x=x0 i|Vi̸∈X 5 where P(v |pa)are the pre-interventionconditionalprobabilities.\ni i Corollary 1 instructs us to remove from the product of Eq. (15) those fac- tors that quantify how the intervened variables (members of set X) are influenced by their pre-interventionparents. This removal followsfrom the fact that the post- intervention model is Markovian as well, hence, following Theorem 1, it must generate a distribution that is factorized according to the modified graph, yielding the truncated product of Corollary 1. In our example of Fig. 2(b), the distribution P(z,y|do(x0)) associated withthe modifiedmodelis givenby P(z,y|do(x0))=P(z)P(y|x0) where P(z) and P(y|x0) are identical to those associated with the pre-intervention distribution of Eq. (16). As expected, the distribution of Z is not affected by the intervention,since P(z|do(x0))=∑P(z,y|do(x0))=∑P(z)P(y|x0)=P(z) y y whilethatofY is sensitive tox0, andis givenby P(y|do(x0))=∑P(z,y|do(x0))=∑P(z)P(y|x0)=P(y|x0) z z This example demonstrates how the (causal) assumptions embedded in the model M permit us to predict the post-intervention distribution from the pre-intervention 5 AsimpleproofoftheCausalMarkovTheorem isgiveninPearl (2000a,p.30). Thistheorem wasfirstpresentedinPearlandVerma (1991),butitisimplicitintheworksofKiiveri,Speed,and Carlin(1984)andothers. Corollary1wasnamed“ManipulationTheorem” inSpirtesetal.(1993), andisalsoimplicitinRobins’(1987)G-computationformula. SeeLauritzen(2001).\ndistribution, which further permits us to estimate the causal effect of X onY from nonexperimentaldata,sinceP(y|x0)isestimablefromsuchdata. Notethatwehave made noassumption whatsoever on theformofthe equations orthe distributionof theerrorterms;itisthestructureofthegraphalone(specifically,theidentityofX’s parents)thatpermitsthederivationtogo through.\nThe truncated factorization formula enables us to derive causal quantities directly, without dealing with equations or equation modification as in Eqs. (11)– (13). Consider,forexample,themodelshowninFig.3,inwhichtheerrorvariables Z 1 Z 2 Z 3 X Y Figure 3: Markovian model illustrating the derivation of the causal effect of X on Y,Eq. (20). Errortermsare notshownexplicitly.\nare kept implicit. Instead of writing down the corresponding five nonparametric equations, wecan writethejointdistributiondirectlyas P(x,z1,z2,z3,y)=P(z1)P(z2)P(z3|z1,z2)P(x|z1,z3)P(y|z2,z3,x) (18) where each marginal or conditional probability on the right hand side is directly estimable from the data. Now suppose we intervene and set variable X to x0. The post-intervention distributioncan readily be written (using the truncated factoriza- tionformula(17))as P(z1,z2,z3,y|do(x0))=P(z1)P(z2)P(z3|z1,z2)P(y|z2,z3,x0) (19) andthe causaleffectof X onY can beobtainedimmediatelybymarginalizingover theZ variables,giving P(y|do(x0))= ∑ P(z1)P(z2)P(z3|z1,z2)P(y|z2,z3,x0) (20) z1,z2,z3 Notethatthisformulacorrespondspreciselytowhatiscommonlycalled“adjusting for Z1,Z2 and Z3” and, moreover, we can write down this formula by inspection, without thinking on whether Z1,Z2 and Z3 are confounders, whether they lie on the causal pathways, andso on. Though such questions can be answered explicitly from the topology of the graph, they are dealt with automatically when we write downthetruncatedfactorizationformulaandmarginalize.\nNote also that the truncated factorization formula is not restricted to inter- ventions on a single variable; it is applicable to simultaneous or sequential inter- ventions such as those invokedin the analysis of time varying treatment with time varying confounders (Robins, 1986, Arjas and Parner, 2004). For example, if X and Z2 are both treatment variables, and Z1 and Z3 are measured covariates, then thepost-interventiondistributionwouldbe P(z1,z3,y|do(x),do(z2))=P(z1)P(z3|z1,z2)P(y|z2,z3,x) (21) 6 andthe causal effectofthetreatmentsequence do(X =x),do(Z2=z2) wouldbe P(y|do(x),do(z2))= ∑ P(z1)P(z3|z1,z2)P(y|z2,z3,x) (22) z1,z3 This expression coincides with Robins’ (1987) G-computation formula, which was derived from a more complicated set of (counterfactual) assumptions.\nAsnotedbyRobins,theformuladictatesanadjustmentforcovariates(e.g.,Z3)that mightbeaffectedbyprevioustreatments(e.g., Z2).\n3.3 Coping with unmeasured confounders Thingsaremorecomplicatedwhenwefaceunmeasuredconfounders. Forexample, itisnotimmediatelyclearwhethertheformulainEq.(20)canbeestimatedifanyof Z1,Z2 and Z3 is not measured. A few but challenging algebraic steps wouldreveal thatone canperformthesummationover Z2 toobtain P(y|do(x0))= ∑ P(z1)P(z3|z1)P(y|z1,z3,x0) (23) z1,z3 whichmeans that we needonly adjustfor Z1 and Z3 withoutevermeasuringZ2. In general,itcanbeshown(Pearl,2000a,p.73)that,wheneverthegraphisMarkovian the post-interventional distribution P(Y =y|do(X =x)) is given by the following expression: P(Y =y|do(X =x))=∑P(y|t,x)P(t) (24) t where T is the set of direct causes of X (also called “parents”) in the graph. This allowsustowrite(23)directlyfromthegraph,thusskippingthealgebrathatledto (23). Itfurtherimpliesthat,nomatterhowcomplicatedthemodel,theparentsofX arethe onlyvariablesthatneedto bemeasuredto estimatethecausal effectsofX.\n6 Forclarity,wedropthe(superfluous)subscript0fromx0 andz20.\nIt is not immediately clear however whether other sets of variables beside X’s parents suffice for estimating the effect of X, whether some algebraic manipu- lation can further reduce Eq. (23), or that measurement of Z3 (unlike Z1, or Z2) is necessary in any estimation of P(y|do(x0)). Such considerations become transpar- entfromagraphicalcriteriontobe discussed next.\n3.3.1 Covariateselection– theback-doorcriterion Consider an observational study where we wish to find the effect of X on Y, for example, treatment on response, and assume that the factors deemed relevant to the problem are structured as in Fig. 4; some are affecting the response, some are Z 1 Z 2 W 1 Z 3 W 2 X W 3 Y Figure4: Markovianmodelillustratingtheback-doorcriterion. Errortermsarenot shownexplicitly.\naffecting the treatment and some are affecting both treatment and response. Some of these factors may be unmeasurable, such as genetic trait or life style, others are measurable, such as gender, age, and salary level. Our problem is to select a subsetofthesefactorsformeasurementandadjustment,namely,thatifwecompare treated vs. untreated subjects having the same values of the selected factors, we get the correct treatment effect in that subpopulation of subjects. Such a set of factors is called a “sufficient set” or “admissible set” foradjustment. The problem ofdefininganadmissibleset,letalonefindingone,has baffledepidemiologistsand social scientists fordecades (see (Greenlandetal., 1999,Pearl,1998)forreview).\nThe following criterion, named “back-door” in (Pearl, 1993a), settles this problembyprovidingagraphicalmethodofselectingadmissiblesets offactorsfor adjustment.\nDefinition3(Admissiblesets – theback-doorcriterion) A set S is admissible (or “sufficient”)for adjustmentiftwo conditionshold: 1. No elementofS is adescendantof X 2. The elements of S “block” all “back-door” paths from X to Y, namely all pathsthatend withanarrow pointingtoX.\nIn this criterion, “blocking” is interpreted as in Definition 1. For example, the set S = {Z3} blocks the path X ←W1 ← Z1 → Z3 →Y, because the arrow-emitting node Z3 is in S. However, the set S = {Z3} does not block the path X ←W1 ← Z1→Z3←Z2 →W2→Y, becausenoneofthearrow-emittingnodes, Z1 andZ2, is inS, and thecollisionnodeZ3 is notoutside S.\nBasedonthiscriterionwesee,forexample,thatthesets{Z1,Z2,Z3},{Z1,Z3}, {W1,Z3}, and {W2,Z3}, each is sufficient for adjustment, because each blocks all back-door paths between X andY. The set {Z3}, however, is not sufficient for ad- justment because, as explained above, it does not block the path X ←W1 ←Z1 → Z3 ←Z2 →W2→Y.\nThe intuition behind the back-door criterion is as follows. The back-door paths in the diagram carry spurious associations from X to Y, while the paths di- rected along the arrows from X to Y carry causative associations. Blocking the formerpaths(byconditioningon S)ensures thatthemeasuredassociation between X andY is purely causative, namely, it correctlyrepresents the target quantity: the causaleffectofX onY. Thereasonforexcludingdescendants ofX (e.g.,W3 orany ofitsdescendants) is givenin(Pearl,2009b, pp.338–41).\nFormally, the implication of finding an admissible set S is that, stratifying onS isguaranteedtoremoveallconfoundingbiasrelativethecausal effectofX on Y. In other words, the risk difference in each stratum of S gives the correct causal effectinthatstratum. Inthebinarycase, forexample,theriskdifferenceinstratum s ofS isgivenby P(Y =1|X =1,S=s)−P(Y =1|X =0,S=s) whilethecausal effect(ofX onY)atthat stratumis givenby P(Y =1|do(X =1),S=s)−P(Y =1|do(X =0),S=s).\nThesetwoexpressionsareguaranteedtobeequalwheneverSisasufficientset,such as {Z1,Z3} or {Z2,Z3} in Fig. 4. Likewise, the average stratified risk difference, takenoverall strata, ∑ [P(Y =1|X =1,S=s)−P(Y =1|X =0,S=s)]P(S=s), s gives thecorrectcausal effectofX onY intheentirepopulation P(Y =1|do(X =1))−P(Y =1|do(X =0)).\nIn general, for multi-valued variables X and Y, finding a sufficient set S permitsus towrite P(Y =y|do(X =x),S=s)=P(Y =y|X =x,S=s) and P(Y =y|do(X =x))=∑P(Y =y|X =x,S=s)P(S =s) (25) s Sinceallfactorsontherighthandsideoftheequationareestimable(e.g.,byregres- sion) from the pre-interventional data, the causal effect can likewise be estimated fromsuch datawithoutbias.\nAn equivalentexpression forthecausal effect(25)can beobtainedby mul- tiplyingand dividingbythe conditionalprobabilityP(X =x|S=s), giving P(Y =y,X =x,S=s) P(Y =y|do(X =x))=∑ (26) P(X =x|S=s) s from which the name “Inverse Probability Weighting” has evolved (Pearl, 2000a, pp. 73,95).\nInterestingly, it can be shown that any irreducible sufficient set, S, taken as a unit, satisfies the associational criterion that epidemiologists have been using to define“confounders”. In otherwords,S must beassociated withX and, simultane- ously, associated withY, given X. This need not hold for any specific members of S. For example, the variableZ3 in Fig. 4, though it is a member of every sufficient set and hence a confounder, can be unassociated with bothY and X (Pearl, 2000a, p.195). Conversely,apre-treatmentvariableZ thatisassociated withbothY andX mayneed tobeexcluded fromenteringasufficientset.\nThe back-door criterion allows us to write Eq. (25) directly, by selecting a sufficientsetSdirectlyfromthediagram,withoutmanipulatingthetruncatedfactor- ization formula. The selection criterion can be applied systematically to diagrams of any size and shape, thus freeinganalysts fromjudging whether“X is condition- allyignorablegivenS,” aformidablementaltaskrequiredinthepotential-response framework(RosenbaumandRubin,1983). Thecriterionalsoenablestheanalystto searchforanoptimalsetofcovariate—namely,asetSthatminimizesmeasurement cost orsamplingvariability(Tian, Paz, andPearl, 1998).\nAll in all, one can safely state that, armed with the back-door criterion, causality has removed “confounding”fromits store ofenigmatic andcontroversial concepts.\n3.3.2 Confoundingequivalence–agraphicaltest Another problem that has been given graphical solution recently is that of deter- miningwhetheradjustmentfortwosetsofcovariateswouldresultinthesamecon- founding bias (Pearl and Paz, 2009). The reasons forposing this question are sev- eral. First, an investigator may wish to assess, prior to taking any measurement, whether two candidate sets of covariates, differingsubstantially in dimensionality, measurement error, cost, or sample variability are equally valuable in their bias- reduction potential. Second, assuming that the structure of the underlying DAG is onlypartiallyknown,onemaywishtotest,usingadjustment,whichoftwohypoth- esizedstructuresiscompatiblewiththedata. Structuresthatpredictequalresponse to adjustment for two sets of variables must be rejected if, after adjustment, such equalityis notfoundin thedata.\nDefinition4((c-equivalence)) Define two sets, T and Z of covariates as c-equivalent,(cconnotes“confounding”)ifthefollowingequalityholds: ∑P(y|x,t)P(t) =∑P(y|x,z)P(z) ∀x,y (27) t z Definition5((Markovboundary)) For any set of variables S in a DAG G, the Markov boundary S of S is the minimal subset of S that d-separates X from all m other membersof S.\nInFig.4,forexample,theMarkovboundaryofS={W1,Z1,Z2,Z3}isS m= {W1,Z3}.\nTheorem 2 (PearlandPaz, 2009) Let Z and T be two sets of variables in G, containing no descendant of X. A necessary and sufficient conditions for Z and T to be c-equivalent is that at least oneof thefollowingconditionsholds: 1. Z =T ,(i.e., theMarkov boundaryofZ coincides withthatofT) m m 2. Z andT are admissible (i.e., satisfy the back-doorcondition) For example, the sets T = {W1,Z3} and Z = {Z3,W2} in Fig. 4 are c-equivalent, because each blocks all back-door paths from X to Y. Similarly, the non-admissible sets T = {Z2} and Z = {W2,Z2} are c-equivalent, since their Markovboundariesare the same (T =Z ={Z2}). Incontrast, the sets {W1} and m m {Z1}, although they block the same set of paths in the graph, are not c-equivalent; theyfailbothconditionsofTheorem2.\nTests for c-equivalence (27) are fairly easy to perform, and they can also be assisted by propensity scores methods. The informationthat such tests provide can be as powerful as conditional independence tests. The statistical ramification ofsuch tests areexplicatedin (PearlandPaz, 2009).\n3.3.3 Generalcontrolofconfounding Adjusting for covariates is only one of many methods that permits us to estimate causal effects in nonexperimental studies. Pearl (1995) has presented examples in whichthereexists nosetofvariablesthatissufficientforadjustmentandwherethe causal effect can nevertheless be estimated consistently. The estimation, in such cases, employs multi-stage adjustments. For example, if W3 is the only observed covariate in the model of Fig. 4, then there exists no sufficient set for adjustment (because no set of observed covariates can block the paths from X to Y through Z3), yet P(y|do(x)) can be estimated intwo steps; firstwe estimate P(w3|do(x))= P(w3|x)(byvirtueofthefactthatthereexistsnounblockedback-doorpathfromX toW3), second we estimate P(y|do(w3)) (since X constitutes a sufficientset forthe effectofW3 onY)and, finally,wecombinethe twoeffectstogetherandobtain P(y|do(x))=∑P(w3|do(x))P(y|do(w3)) (28) w3 Inthis example, thevariableW3 acts as a “mediatinginstrumentalvariable” (Pearl, 1993b,Chalak andWhite, 2006).\nThe analysis used in the derivation and validation of such results invokes mathematical rules of transforming causal quantities, represented by expressions such as P(Y = y|do(x)), into do-free expressions derivable from P(z,x,y), since only do-free expressions are estimable from non-experimental data. When such a transformationisfeasible, we areensuredthat thecausal quantityisidentifiable.\nApplications of this calculus to problems involving multiple interventions (e.g., time varying treatments), conditional policies, and surrogate experiments were developed in Pearl and Robins (1995), Kuroki and Miyakawa (1999), and Pearl(2000a,Chapters 3–4).\nA more recent analysis (Tian and Pearl, 2002) shows that the key to iden- tifiabilitylies not in blocking paths between X andY but, rather, in blocking paths between X and itsimmediatesuccessors onthe pathwaystoY. Allexisting criteria foridentificationarespecial cases ofthe onedefinedinthe followingtheorem: Theorem 3 (Tianand Pearl,2002) A sufficientconditionfor identifyingthe causal effectP(y|do(x)) isthatevery pathbetweenX andanyofitschildrentraces atleast 7 onearrow emanatingfroma measured variable.\nForexample,ifW3istheonlyobservedcovariateinthemodelofFig.4,P(y|do(x)) can be estimated since every path from X toW3 (the only child of X) traces either thearrowX →W3, orthearrowW3→Y,bothemanatingfromameasuredvariable (W3).\nShpitser and Pearl (2006) have further extended this theorem by (1) pre- sentinganecessary andsufficientconditionforidentification,and(2)extendingthe condition from causal effects to any counterfactual expression. The correspond- ing unbiased estimands for these causal quantities are readable directly from the diagram.\nGraph-basedmethodsforeffectidentificationundermeasurementerrorsare discussed in (Pearl,2009f, Herna´nandCole, 2009, Caiand Kuroki,2008).\n3.3.4 From identificationtoestimation The mathematical derivation of causal effect estimands, like Eqs. (25) and (28) is merely a first step toward computing quantitative estimates of those effects from finite samples, using the rich traditions ofstatistical estimation and machine learn- ing Bayesian as well as non-Bayesian. Although the estimands derived in (25) and (28) are non-parametric, this does not mean that one should refrain from us- ing parametric forms in the estimation phase of the study. Parameterization is in fact necessary when the dimensionality of a problem is high. For example, if the assumptions of Gaussian, zero-mean disturbances and additive interactions are deemed reasonable, then the estimand given in (28) can be converted to the prod- uctE(Y|do(x))=r r x,wherer isthe(standardized)coefficientofZ in W3X YW3·X YZ·X the regression ofY on Z and X. More sophisticated estimation techniques are the “marginalstructuralmodels”of(Robins,1999),andthe“propensityscore”method of(Rosenbaum and Rubin, 1983)which werefoundto be particularlyuseful when dimensionalityishighand dataaresparse (see Pearl(2009b,pp. 348–52)).\nIt should be emphasized, however, that contrary to conventional wisdom (e.g., (Rubin, 2007, 2009)), propensity score methods are merely efficient estima- torsofthe righthand side of(25);they entailthesame asymptoticbias, andcannot be expected to reduce bias in case the set S does not satisfy the back-door crite- rion(Pearl, 2000a, 2009c,d). Consequently, theprevailingpractice ofconditioning 7 Before applying this criterion, one may delete from the causal graph all nodes that are not ancestorsofY.\non as many pre-treatment measurements as possible should be approached with great caution; some covariates (e.g., Z3 in Fig. 3) may actually increase bias if in- cluded inthe analysis (see footnote16). Using simulationand parametricanalysis, HeckmanandNavarro-Lozano(2004)andWooldridge(2009)indeedconfirmedthe bias-raisingpotentialofcertaincovariatesinpropensity-scoremethods. Thegraph- icaltoolspresentedinthissectionunveilthecharacterofthese covariatesandshow preciselywhatcovariatesshould,andshouldnotbeincludedintheconditioningset forpropensity-scorematching(seealso (PearlandPaz, 2009, Pearl,2009e)).\n3.4 Counterfactual analysis in structural models NotallquestionsofcausalcharactercanbeencodedinP(y|do(x))typeexpressions, thusimplyingthatnotallcausalquestionscanbeansweredfromexperimentalstud- ies. Forexample, questionsofattribution(e.g., whatfractionofdeathcasesaredue to specific exposure?) or of susceptibility (what fraction of the healthy unexposed population would have gotten the disease had they been exposed?) cannot be an- swered from experimental studies, and naturally, this kind of questions cannot be 8 expressed in P(y|do(x)) notation. To answer such questions, a probabilistic anal- ysis ofcounterfactualsis required, one dedicatedto the relation“Y wouldbe y had X been x in situation U = u,” denoted Y (u) = y. Remarkably, unknown to most x economists and philosophers, structural equation models provide the formal inter- 9 pretationandsymbolicmachineryforanalyzingsuchcounterfactualrelationships.\nThe key idea is to interpret the phrase “had X been x” as an instruction to make a minimal modification in the current model, which may have assigned X a different value, say X =x′, so as to ensure the specified condition X = x. Such a minimal modification amounts to replacing the equation for X by a constant x, as we have done in Eq. (6). This replacement permits the constant x to differ from theactual valueofX (namely f (z,u ))withoutrenderingthesystem ofequations X X inconsistent, thus yielding a formalinterpretationof counterfactuals in multi-stage 8 The reason forthisfundamentallimitationis thatnodeath case can be tested twice, withand withouttreatment. For example, if we measure equal proportionsof deaths in the treatment and controlgroups,wecannottellhowmanydeathcasesareactuallyattributabletothetreatmentitself; it is quite possible that many of those who died under treatment would be alive if untreated and, simultaneously,manyofthosewhosurvivedwithtreatmentwouldhavediedifnottreated.\n9 Connectionsbetweenstructuralequationsandarestrictedclassofcounterfactualswerefirstrec- ognizedbySimonandRescher(1966).ThesewerelatergeneralizedbyBalkeandPearl(1995),us- ingsurgeries(Eq.(29)),thuspermittingendogenousvariablestoserveascounterfactualantecedents.\nThe term “surgery definition” was used in Pearl (2000a, Epilogue) and criticized by Cartwright (2007)andHeckman(2005),(seePearl(2009b,pp.362–3,374–9forrebuttals)).\nmodels, wherethedependentvariableinoneequationmaybe anindependentvari- ablein another.\nDefinition6(Unit-levelCounterfactuals–“surgical”definition,Pearl(2000a,p.98)) Let M be a structural model and M a modified version of M, with the equation(s) x of X replaced by X = x. Denote the solution for Y in the equations of M by the x symbolY (u). The counterfactualY (u) (Read: “The value ofY in unit u, had X Mx x been x”)isgiven by: ∆ Y (u)=Y (u). (29) x Mx In words: The counterfactualY (u) in model M is defined as the solution forY in x the“surgicallymodified”submodelM .\nx Weseethattheunit-levelcounterfactualY (u), whichintheNeyman-Rubin x approachis treatedas aprimitive,undefinedquantity,isactuallya derivedquantity in the structural framework. The fact that we equate the experimental unit u with a vectorof backgroundconditions,U =u, in M, reflects the understandingthatthe name ofa unit orits identitydo notmatter; itis onlythe vectorU =u of attributes characterizingaunitwhichdeterminesitsbehaviororresponse. Aswegofromone unit to another, the laws ofnature, as they are reflectedin the functions f , f , etc.\nX Y 10 remaininvariant;onlytheattributesU =uvaryfromindividualtoindividual.\nTo illustrate, consider the solution of Y in the modified model M of Eq.\nx0 (6), which Definition 6 endows with the symbol Y (u ,u ,u ). This entity has x0 X Y Z a clear counterfactual interpretation, for it stands for the way an individual with characteristics (u X,u Y,u Z) would respond, had the treatment been x0, rather than the treatment x = f (z,u ) actually received by that individual. In our example, X X sinceY does notdependonu andu , wecan write: X Z Y x0(u)=Y x0(u Y,u X,u Z)= f Y(x0,u Y). (30) Ina similarfashion,we can derive Y z0(u)= f Y(f X(z0,u X),u Y), 10 The distinctionbetween general, or population-levelcauses (e.g., “Drinking hemlock causes death”) and singular or unit-level causes (e.g., “Socrates’ drinking hemlock caused his death”), whichmanyphilosophershaveregardedasirreconcilable(Eells,1991),introducesnotensionatall inthe structuraltheory. The twotypes ofsentences differmerely inthe level ofsituation-specific informationthat is brought to bear on a problem, that is, in the specificity of the evidence e that enters thequantityP(Yx =y|e). When e includesallfactorsu, we have a deterministic, unit-level causationonourhand;whenecontainsonlyafewknownattributes(e.g., age, income,occupation etc.) whileothersareassignedprobabilities,apopulation-levelanalysisensues.\nX z0,y0(u)= f X(z0,u X), and so on. These examples reveal the counterfactual reading of each individual structuralequationinthemodelofEq.(5). Theequationx= f (z,u ),forexample, X X advertisestheempiricalclaimthat,regardlessofthevaluestakenbyothervariables inthe system, hadZ beenz0, X wouldtakeon noothervaluebutx= f X(z0,u X).\nClearly, the distributionP(u ,u ,u ) induces a well definedprobabilityon Y X Z the counterfactual eventY =y, as well as on joint counterfactual events, such as x0 ‘Y =y ANDY =y′,’ which are, in principle, unobservable if x0 ̸=x1. Thus, to x0 x1 answer attributional questions, such as whether Y would be y1 if X were x1, given that in fact Y is y0 and X is x0, we need to compute the conditional probability P(Y =y1|Y = y0,X = x0) which is well defined once we know the forms of the x1 structural equations and the distribution of the exogenous variables in the model.\nForexample, assuminglinearequations (asinFig. 1), x=u y=βx+u , X X the conditioning eventsY =y0 and X =x0 yieldU =x0 andU =y0−βx0, and X Y wecanconcludethat,withprobabilityone,Y musttakeonthevalue: Y =βx1+ x1 x1 U =β(x1−x0)+y0. In otherwords, ifX were x1 instead ofx0,Y wouldincrease Y by β times the difference (x1−x0). In nonlinear systems, the result would also depend on the distribution of {U ,U } and, for that reason, attributional queries X Y are generally not identifiable in nonparametricmodels (see Section 6.3 and 2000a, Chapter9).\nIn general, if x and x′ are incompatible thenY andY cannot be measured x x′ simultaneously, and it may seem meaningless to attribute probability to the joint statement “Y would be y if X = x and Y would be y′ if X =x′.”11 Such concerns have been a source of objections to treating counterfactuals as jointly distributed randomvariables(Dawid,2000). ThedefinitionofY andY intermsoftwodistinct x x′ submodelsneutralizestheseobjections(Pearl,2000b),sincethecontradictoryjoint statement is mapped into an ordinary event, one where the background variables satisfy both statements simultaneously, each in its own distinct submodel; such events havewell definedprobabilities.\nThe surgical definition of counterfactuals given by (29), provides the con- ceptual and formal basis for the Neyman-Rubin potential-outcome framework, an approach to causation that takes a controlled randomized trial (CRT) as its rul- ing paradigm, assuming that nothing is known to the experimenter about the sci- ence behind the data. This “black-box” approach, which has thus far been denied the benefits of graphical or structuralanalyses, was developed by statisticians who 11 Forexample,“Theprobabilityis80%thatJoebelongstotheclassofpatientswhowillbecured iftheytakethedruganddieotherwise.” found it difficultto cross the two mental barriers discussed in Section 2.2. Section 5 establishes the precise relationship between the structural and potential-outcome paradigms, and outlines how the latter can benefit from the richer representational poweroftheformer.",
    "crumbs": [
      "Causal Inference",
      "An Introduction to Causal Inference"
    ]
  },
  {
    "objectID": "extracted/An Introduction to Causal Inference.html#methodological-principles-of-causal-inference",
    "href": "extracted/An Introduction to Causal Inference.html#methodological-principles-of-causal-inference",
    "title": "An Introduction to Causal Inference",
    "section": "4. Methodological Principles of Causal Inference",
    "text": "4. Methodological Principles of Causal Inference\nThestructuraltheorydescribedintheprevioussectionsdictatesaprincipledmethod-\nologythateliminatesmuchoftheconfusionconcerningtheinterpretationsofstudy results as well as the ethical dilemmas that this confusion tends to spawn. The methodology dictates that every investigation involving causal relationships (and this entails the vast majority of empirical studies in the health, social, and behav- ioralsciences) shouldbe structuredalongthe followingfour-stepprocess: 1. Define: Express the target quantity Q as a function Q(M) that can be com- putedfromany modelM.\n\nAssume: Formulate causal assumptions using ordinary scientific language andrepresenttheirstructuralpartingraphicalform.\nIdentify: Determine if the target quantity is identifiable (i.e., expressible in termsofestimableparameters).\nEstimate: Estimate the target quantity if it is identifiable, or approximate it, if it is not. Test the statistical implications of the model, if any, and modify themodelwhen failureoccurs.\n\n4.1 Defining the target quantity The definitionalphase is the most neglected step in currentpractice of quantitative analysis. The structural modeling approach insists on defining the target quantity, be it “causal effect,” “mediated effect,” “effect on the treated,” or “probability of causation”beforespecifyinganyaspectofthemodel,withoutmakingfunctionalor distributionalassumptions andpriortochoosinga methodofestimation.\nThe investigator should view this definition as an algorithm that receives a model M as an input and delivers the desired quantity Q(M) as the output. Surely, suchalgorithmshouldnotbetailoredtoanyaspectoftheinputM;itshouldbegen- eral, and ready to accommodate any conceivable model M whatsoever. Moreover, the investigator should imagine that the input M is a completely specified model, withallthefunctions f , f ,…andalltheU variables(ortheirassociatedprobabil- X Y ities) given precisely. This is the hardest step for statistically trained investigators to make; knowing in advance that such model details will never be estimable from the data, the definition ofQ(M) appears like a futile exercise in fantasyland – it is not.\nFor example, the formaldefinitionof the causal effectP(y|do(x)), as given in Eq. (7), is universally applicable to all models, parametric as well as nonpara- metric,throughtheformationofasubmodelM . Bydefiningcausaleffectprocedu- x rally, thus divorcing it from its traditional parametric representation, the structural theoryavoids the many pitfallsand confusions thathave plagued the interpretation 12 ofstructuralandregressionalparametersforthepast half century.\n4.2 Explicating causal assumptions This is the second most neglected step in causal analysis. In the past, the diffi- culty has been the lack of a language suitable for articulating causal assumptions which,asidefromimpedinginvestigatorsfromexplicatingassumptions, alsoinhib- itedthemfromgivingcausal interpretationstotheirfindings.\nStructural equation models, in their counterfactual reading, have removed this lingering difficultyby providing the needed language forcausal analysis. Fig- ures 3 and 4 illustrate the graphical component of this language, where assump- tions are conveyed through the missing arrows in the diagram. If numerical or functional knowledge is available, for example, linearity or monotonicity of the functions f , f ,…, those are stated separately, and applied in the identification X Y and estimation phases of the study. Today we understand that the longevity and naturalappeal ofstructuralequationsstem fromthe factthatthey permitinvestiga- tors to communicatecausal assumptions formallyand in the very same vocabulary inwhichscientific knowledgeisstored.\nUnfortunately, however, this understanding is not shared by all causal ana- lysts;someanalystsvehementlyopposethere-emergenceofstructure-basedcausa- tionandinsist, instead,onarticulatingcausalassumptionsexclusivelyintheunnat- ural(thoughformallyequivalent)languageof“potential outcomes,” “ignorability,” “missing data,” “treatmentassignment,” and other metaphors borrowedfromclini- caltrials. Thismodernassaultonstructuralmodelsisperhapsmoredangerousthan the regressional invasion that distorted the causal readings of these models in the 12 NotethatβinEq.(1),theincrementalcausaleffectofX onY,isdefinedprocedurallyby ∆ ∂ ∂ β=E(Y|do(x0+1))−E(Y|do(x0))= E(Y|do(x))= E(Yx).\n∂x ∂x Naturally,allattemptstogiveβstatisticalinterpretationhaveendedinfrustrations(Holland,1988, Whittaker,1990,Wermuth,1992,WermuthandCox,1993),somepersistingwellintothe21stcen- tury(Sobel,2008).\nlate1970s(Richard,1980). Whilesanctioningcausalinferenceinoneidiosyncratic style of analysis, the modern assault denies validity to any other style, including structural equations, thus discouraging investigators fromsubjecting models to the scrutinyofscientificknowledge.\nThis exclusivist attitude is manifested in passages such as: “The crucial ideais toset upthe causal inferenceproblemas oneofmissingdata” or“Ifaprob- lem of causal inferencecannot be formulatedin this manner(as the comparison of potential outcomes under different treatment assignments), it is not a problem of inference for causal effects, and the use of “causal” should be avoided,” or, even morebluntly,“theunderlyingassumptionsneededtojustifyanycausalconclusions should be carefully and explicitly argued, not in terms of technical properties like “uncorrelated error terms,” but in terms of real world properties, such as how the units received the different treatments” (Wilkinson, the Task Force on Statistical Inference,andAPA Board ofScientificAffairs, 1999).\nThe methodology expounded in this paper testifies against such restric- tions. Itdemonstratesthe viabilityandscientific soundness of thetraditionalstruc- turalequationsparadigm,whichstandsdiametricallyopposedtothe“missingdata” paradigm. It renders the vocabulary of “treatment assignment” stifling and irrele- vant (e.g., there is no “treatment assignment” in sex discrimination cases). Most importantly, it strongly prefers the use of “uncorrelated error terms,” (or “omitted factors”)over its“strongignorability”alternative,as the properwayofarticulating causal assumptions. Even the most devout advocates of the “strong ignorability” language use “omitted factors” when the need arises to defend assumptions (e.g., (Sobel,2008)) 4.3 Identification, estimation, and approximation Having unburden itself from parametric representations, the identification process in the structural framework proceeds either in the space of assumptions (i.e., the diagram) or in the space of mathematical expressions, after translating the graph- ical assumptions into a counterfactual language, as demonstrated in Section 5.3.\nGraphical criteria such as those of Definition 3 and Theorem 3 permitthe identifi- cationofcausaleffectstobedecidedentirelywithinthegraphicaldomain,whereit canbenefitfromtheguidanceofscientificunderstanding. Identificationofcounter- factual queries, on the other hand, often require a symbiosis of both algebraic and graphical techniques. The nonparametric nature of the identification task (Defini- tion1)makesit clearthatcontrarytotraditionalfolkloreinlinearanalysis, it isnot the model that need be identified but the query Q – the target of investigation. It also provides a simple way of proving non-identifiability: the construction of two parameterizationof M, agreeing in P and disagreeing in Q, is sufficient to rule out identifiability.\nWhen Q is identifiable, the structural frameworkalso delivers an algebraic expression for the estimand EST(Q) of the target quantity Q, examples of which are given in Eqs. (24) and (25), and estimation techniques are then unleashed as discussed in Section 3.3.4. An integral part of this estimation phase is a test for the testable implications, if any, of those assumptions in M that render Q identifi- able – there is no pointin estimatingEST(Q) ifthe data proves those assumptions false and EST(Q) turns out to be a misrepresentation of Q. Investigators should bereminded,however, thatonlyafraction,called“kernel,”oftheassumptions em- bodied in M are needed for identifying Q (Pearl, 2004), the rest may be violated in the data with no effect on Q. In Fig. 2, forexample, the assumption {U ⊥⊥U } Z X is not necessary for identifying Q = P(y|do(x)); the kernel {U ⊥⊥U ,U ⊥⊥U } Y Z Y X (togetherwith the missing arrows)is sufficient. Therefore, the testable implication of this kernel, Z⊥⊥Y|X, is all we need to test when our target quantity is Q; the assumption{U ⊥⊥U }need notconcernus.\nZ X More importantly,investigators must keep in mind that only a tiny fraction of any kernel lends itself to statistical tests, the bulk of it must remain untestable, at the mercy of scientific judgment. In Fig. 2, for example, the assumption set {U ⊥⊥U ,U ⊥⊥U } constitutes a sufficient kernel for Q = P(y|do(x)) (see Eq.\nX Z Y X (28)) yet it has no testable implications whatsoever. The prevailing practice of submitting an entire structural equation model to a “goodness of fit” test (Bollen, 1989) in support of causal claims is at odd with the logic of SCM (see (Pearl, 2000a,pp.144–5)). Alternativecausalmodelsusuallyexistthatmakecontradictory claims and, yet, possess identical statistical implications. Statistical test can be usedforrejectingcertainkernels,intherarecaseswheresuchkernelshavetestable implications, but thelion’s share of supportingcausal claims fallson the shoulders ofuntestedcausal assumptions.\nWhenconditionsforidentificationarenotmet,thebestonecandoisderive bounds for the quantities of interest—namely, a range of possible values of Q that representsourignoranceaboutthedetailsofthedata-generatingprocessM andthat cannot be improvedwith increasing sample size. A classical example of non iden- tifiable model that has been approximatedby bounds, is the problemof estimating causal effect in experimental studies marred by non compliance, the structure of whichis giveninFig. 5.\nOurtask inthisexample isto findthehighestand lowestvaluesofQ ∆ Q=P(Y =y|do(x))=∑P(Y =y|X =x,U =u )P(U =u ) (31) X X X X u X subject to the equalityconstraints imposed by the observed probabilitiesP(x,y,|z), U U U Z X Y Z X Y Figure5: Causal diagramrepresentingtheassignment (Z), treatment(X), and out- come(Y) ina clinicaltrialwithimperfectcompliance.\nwhere the maximization ranges over all possible functions P(u ,u ), P(y|x,u ) Y X X andP(x|z,u )that satisfythose constraints.\nY Realizing that units in this example fall into 16 equivalence classes, each representing a binary function X = f(z) paired with a binary function y = g(x), 13 BalkeandPearl(1997)wereabletoderiveclosed-formsolutionsforthesebounds.\nThey showed that, in certain cases, the derived bounds can yield significant infor- mationonthetreatmentefficacy. ChickeringandPearl(1997)furtherusedBayesian techniques (with Gibbs sampling) to investigate the sharpness of these bounds as a function of sample size. Kaufman, Kaufman, and MacLenose (2009) used this techniquetobounddirectand indirecteffects(see Section6.1).",
    "crumbs": [
      "Causal Inference",
      "An Introduction to Causal Inference"
    ]
  },
  {
    "objectID": "extracted/An Introduction to Causal Inference.html#the-potential-outcome-framework",
    "href": "extracted/An Introduction to Causal Inference.html#the-potential-outcome-framework",
    "title": "An Introduction to Causal Inference",
    "section": "5. The Potential Outcome Framework",
    "text": "5. The Potential Outcome Framework\nThissectioncomparesthestructuraltheorypresentedinSections1–3tothepotential-\noutcomeframework,usually associated withthenames ofNeyman(1923)andRu- bin (1974), which takes the randomized experiment as its rulingparadigm and has appealed therefore to researchers who do not find that paradigm overly constrain- ing. This framework is not a contender for a comprehensive theory of causation forit is subsumed by the structural theory and excludes ordinarycause-effect rela- tionshipsfromitsassumption vocabulary. We hereexplicate thelogicalfoundation of the Neyman-Rubin framework, its formal subsumption by the structural causal model,andhowitcanbenefitfromtheinsightsprovidedbythebroaderperspective ofthestructuraltheory.\nThe primitive object of analysis in the potential-outcome frameworkis the unit-basedresponsevariable,denotedY (u), read: “thevaluethatoutcomeY would x obtaininexperimentalunitu,hadtreatmentX beenx.” Here, unit maystandforan individual patient, an experimental subject, or an agricultural plot. In Section 3.4 13 These equivalence classes were later called “principal stratification” by Frangakis and Rubin (2002).LooserboundswerederivedearlierbyRobins(1989)andManski(1990).\n(Eq. (29) we saw that this counterfactual entity has a natural interpretation in the SCM; it is the solution for Y in a modified system of equations, where unit is in- terpreted a vector u of background factors that characterize an experimental unit.\nEach structural equation model thus carries a collection of assumptions about the behaviorofhypotheticalunits, andthese assumptions permitus toderivethe coun- terfactual quantities of interest. In the potential-outcome framework, however, no equationsareavailableforguidanceandY (u)istakenasprimitive,thatis,anunde- x finedquantityintermsofwhichotherquantitiesaredefined;notaquantitythatcan be derivedfrom the model. Inthis sense the structuralinterpretationofY (u) given x in(29)providestheformalbasisforthepotential-outcomeapproach;theformation ofthesubmodelM explicatesmathematicallyhowthehypotheticalcondition“had x X beenx” is realized,and whatthelogicalconsequences areofsucha condition.\n5.1 The “black-box” missing-data paradigm Thedistinctcharacteristicofthepotential-outcomeapproachisthat,althoughinves- tigatorsmustthinkandcommunicateintermsofundefined,hypotheticalquantities such asY (u), the analysis itself is conducted almost entirely within the axiomatic x framework of probability theory. This is accomplished, by postulating a “super” probability function on both hypothetical and real events. IfU is treated as a ran- domvariablethenthevalueofthe counterfactualY (u) becomes arandomvariable x as well,denotedasY . The potential-outcomeanalysis proceedsbytreatingthe ob- x serveddistributionP(x1,…,x n)asthemarginaldistributionofanaugmentedproba- bilityfunctionP∗ definedoverbothobservedandcounterfactualvariables. Queries about causal effects (written P(y|do(x)) in the structural analysis) are phrased as queries about the marginal distribution of the counterfactual variable of interest, writtenP∗(Y =y). ThenewhypotheticalentitiesY aretreatedasordinaryrandom x x variables;forexample,theyareassumedtoobeytheaxiomsofprobabilitycalculus, thelaws ofconditioning,andthe axiomsofconditionalindependence.\nNaturally, these hypothetical entities are not entirely whimsy. They are as- sumed to be connected to observed variables via consistency constraints (Robins, 1986)suchas X =x =⇒ Y =Y, (32) x whichstatesthat,foreveryu,iftheactualvalueofX turnsouttobex,thenthevalue thatY would take on if ‘X were x’ is equal to the actual value ofY. For example, a person who chose treatment x and recovered, wouldalso have recovered if given treatmentx by design. When X is binary, it is sometimes more convenient to write (32)as: Y =xY1+(1−x)Y0 Whetheradditionalconstraintsshouldtietheobservablestotheunobservablesisnot aquestionthatcanbeansweredinthepotential-outcomeframework;foritlacksan underlyingmodeltodefine itsaxioms.\nThemainconceptualdifferencebetweenthetwoapproachesisthat,whereas the structuralapproachviews the interventiondo(x) as an operationthatchanges a distributionbutkeepsthevariablesthesame,thepotential-outcomeapproachviews the variable Y under do(x) to be a different variable, Y , loosely connected to Y x through relations such as (32), but remaining unobserved whenever X ̸= x. The problem of inferring probabilistic properties of Y , then becomes one of “missing- x data” forwhich estimation techniques have been developed in the statistical litera- ture.\nPearl(2000a, Chapter7)shows, using thestructuralinterpretationofY (u), x that it is indeed legitimate to treat counterfactuals as jointly distributed random variables in all respects, that consistency constraints like (32) are automatically satisfied in the structural interpretation and, moreover, that investigators need not beconcerned aboutanyadditionalconstraintsexcept thefollowingtwo Y =y forally, subsets Z, andvalues z forZ (33) yz X =x⇒Y =Y forallx, subsets Z, and valuesz forZ (34) z xz z Equation(33)ensures thatthe interventionsdo(Y =y) resultsin theconditionY = y, regardless of concurrent interventions, say do(Z = z), that may be applied to variables other than Y. Equation (34) generalizes (32) to cases where Z is held fixed, atz. (See(Halpern,1998)forproofofcompleteness.) 5.2 Problem formulation and the demystification of “ignorabil- ity” The main drawback of this black-box approach surfaces in problem formulation, namely, the phase where a researcher begins to articulate the “science” or “causal assumptions” behind the problem of interest. Such knowledge, as we have seen in Section 1, must be articulated at the onset of every problem in causal analysis – causal conclusions are only as valid as the causal assumptions upon which they rest.\nTo communicate scientific knowledge, the potential-outcome analyst must express assumptions as constraints on P∗, usually in the form of conditional in- dependence assertions involving counterfactual variables. For instance, in our ex- ample of Fig. 5, to communicate the understanding that Z is randomized (hence independent ofU andU ), the potential-outcome analyst would use the indepen- X Y 14 dence constraint Z⊥⊥ {Y ,Y ,…,Y }. To further formulate the understanding z1 z2 zk that Z does not affect Y directly, except through X, the analyst would write a, so called, “exclusion restriction”:Y =Y .\nxz x A collection of constraints of this type might sometimes be sufficient to permita unique solutionto thequery ofinterest. For example, ifone can plausibly assume that, inFig.4, a setZ ofcovariatessatisfies theconditionalindependence Y ⊥⊥X|Z (35) x (anassumptiontermed“conditionalignorability”byRosenbaumandRubin(1983),) thenthe causaleffectP(y|do(x))=P∗(Y =y) can readilybe evaluatedtoyield x P∗(Y =y) = ∑P∗(Y =y|z)P(z) x x z = ∑P∗(Y =y|x,z)P(z) (using(35)) x z = ∑ P∗(Y =y|x,z)P(z) (using (32)) z ∑ = P(y|x,z)P(z). (36) z Thelastexpressioncontainsnocounterfactualquantities(thuspermittingustodrop theasteriskfromP∗)andcoincidespreciselywiththestandardcovariate-adjustment formulaofEq. (25).\nWeseethattheassumptionofconditionalignorability(35)qualifiesZ asan admissible covariate for adjustment; it mirrors therefore the “back-door” criterion of Definition 3, which bases the admissibility of Z on an explicit causal structure encodedin thediagram.\nThe derivationabove may explain why the potential-outcomeapproachap- peals to mathematical statisticians; instead of constructing new vocabulary (e.g., arrows), new operators (do(x)) and new logic forcausal analysis, almost all math- ematical operations in this framework are conducted within the safe confines of probability calculus. Save for an occasional application of rule (34) or (32)), the analyst may forget thatY stands fora counterfactualquantity—it is treated as any x otherrandomvariable,and theentirederivationfollowsthecourse ofroutineprob- abilityexercises.\nThis orthodoxy exacts a high cost: Instead of bringing the theory to the problem,theproblemmustbereformulatedtofitthetheory;allbackgroundknowl- edge pertaining to a given problem must first be translated into the language of 14 ThenotationY⊥⊥X|ZstandsfortheconditionalindependencerelationshipP(Y =y,X=x|Z= z)=P(Y =y|Z=z)P(X =x|Z=z)(Dawid,1979).\ncounterfactuals(e.g., ignorability conditions)before analysis can commence. This translation may in fact be the hardest part of the problem. The reader may ap- preciate this aspect by attempting to judge whether the assumption of conditional ignorability (35), the key to the derivation of (36), holds in any familiar situation, say intheexperimentalsetupofFig.2(a). Thisassumption reads: “thevaluethatY would obtain had X been x, is independent of X, given Z”. Even the most experi- encedpotential-outcomeexpertwouldbeunabletodiscernwhetheranysubsetZ of 15 covariates in Fig. 4 wouldsatisfy this conditionalindependence condition. Like- wise, toderive Eq. (35)in the languageof potential-outcome(see (Pearl,2000a, p.\n223)), one wouldneed to convey the structure of the chain X →W3 →Y using the cryptic expression: W3 x⊥⊥ {Y w3,X}, read: “the value that W3 would obtain had X beenx is independentofthevaluethatY wouldobtainhadW3 been w3 jointlywith thevalueofX.” Suchassumptions arecastinalanguageso farremovedfromordi- naryunderstandingofscientifictheoriesthat,forallpracticalpurposes,theycannot be comprehended or ascertained by ordinary mortals. As a result, researchers in thegraph-lesspotential-outcomecamprarelyuse“conditionalignorability”(35)to guide the choice of covariates; they view this condition as a hoped-for miracle of 16 natureratherthanatargetto beachieved byreasoneddesign.\nReplacing “ignorability” with a conceptually meaningful condition (i.e., back-door)ina graphicalmodelpermitsresearchers tounderstandwhatconditions covariates must fulfill before they eliminate bias, what to watch for and what to think about when covariates are selected, and what experiments we can do to test, atleast partially,ifwehave theknowledgeneeded forcovariateselection.\nAside fromofferingno guidanceincovariateselection, formulatingaprob- lem in the potential-outcome language encounters three additional hurdles. When counterfactual variables are not viewed as byproducts of a deeper, process-based model, it is hard to ascertain whether all relevantjudgments have been articulated, whether the judgments articulated are redundant, or whether those judgments are self-consistent. The need to express, defend, and manage formidable counterfac- tualrelationshipsofthistypeexplaintheslowacceptance ofcausalanalysisamong health scientists and statisticians, and why most economists and social scientists 15 InquisitivereadersareinvitedtoguesswhetherXz⊥⊥Z|Y holdsinFig.2(a),thenreflectonwhy causalityissoslowinpenetratingstatisticaleducation.\n16 The opaqueness of counterfactual independencies explains why many researchers within the potential-outcome camp are unaware of the fact that adding a covariate to the analysis (e.g., Z3 in Fig. 4, Z in Fig. 5 may actually increase confoundingbias in propensity-scorematching. Paul Rosenbaum,forexample,writes:“thereislittleornoreasontoavoidadjustmentforatruecovariate, a variable describingsubjects before treatment” (Rosenbaum, 2002, p. 76). Rubin(2009)goes as far as stating that refraining from conditioningon an available measurement is “nonscientific ad hockery”foritgoes againstthetenetsof Bayesianphilosophy(see (Pearl, 2009c,d,Heckman and Navarro-Lozano,2004)foradiscussionofthisfallacy).\ncontinue to use structural equation models (Wooldridge, 2002, Stock and Watson, 2003, Heckman, 2008) instead of the potential-outcome alternatives advocated in Angrist,Imbens, andRubin (1996),Holland(1988),Sobel(1998,2008).\nOn the other hand, the algebraic machinery offered by the counterfactual notation,Y (u), once a problemis properly formalized, can be extremely powerful x in refiningassumptions (Angrist et al., 1996, Heckman and Vytlacil, 2005), deriv- ing consistent estimands (Robins, 1986), bounding probabilities of necessary and sufficientcausation (Tian and Pearl, 2000), and combiningdata fromexperimental and nonexperimental studies (Pearl, 2000a). The next subsection (5.3) presents a way of combiningthe best features of the two approaches. It is based on encoding causal assumptions in thelanguage ofdiagrams, translatingthese assumptionsinto counterfactual notation, performing the mathematics in the algebraic language of counterfactuals (using (32), (33), and (34)) and, finally, interpreting the result in graphicaltermsor plaincausal language. The mediationproblemof Section6.1 il- lustrates howsuchsymbiosis clarifiesthe definitionand identificationofdirectand 17 indirect effects, and how it overcomes difficultiesthat were deemed insurmount- ablein theexclusivist potential-outcomeframework(Rubin,2004, 2005).\n5.3 Combining graphs and potential outcomes The formulation of causal assumptions using graphs was discussed in Section 3.\nIn this subsection we will systematize the translation of these assumptions from graphstocounterfactualnotation.\nStructuralequationmodelsembodycausalinformationinboththeequations and the probability function P(u) assigned to the exogenous variables; the former is encoded as missing arrowsin the diagrams the latter as missing (double arrows) dashed arcs. Each parent-childfamily(PA ,X) in a causal diagram G corresponds i i to an equation in the model M. Hence, missing arrows encode exclusion assump- tions,thatis, claimsthatmanipulatingvariablesthatareexcludedfromanequation willnotchangetheoutcomeofthehypotheticalexperimentdescribedbythatequa- tion. Missingdashedarcsencodeindependenciesamongerrortermsintwoormore equations. For example, the absence of dashed arcs between a nodeY and a set of nodes {Z1,…,Z k} implies that the corresponding background variables, U and Y {U ,…,U }, areindependentinP(u).\nZ1 Zk 17 Suchsymbiosisisnowstandardinepidemiologyresearch (Robins,2001,Petersen,Sinisi,and vander Laan, 2006,VanderWeele andRobins,2007,Hafeman and Schwartz, 2009,VanderWeele, 2009)yetstilllackingineconometrics(Heckman,2008,ImbensandWooldridge,2009).\nTheseassumptionscanbetranslatedintothepotential-outcomenotationus- ing two simple rules (Pearl, 2000a, p. 232); the first interprets the missing arrows inthe graph,thesecond, the missingdashed arcs.\n\nExclusionrestrictions: ForeveryvariableY havingparentsPA andforevery Y set ofendogenousvariablesS disjointofPA , wehave Y Y =Y . (37) pa pa ,s Y Y\nIndependence restrictions: If Z1,…,Z is any set of nodes not connected to k Y viadashed arcs, and PA1,…,PA theirrespective sets ofparents, wehave k Y Y⊥⊥ {Z1 pa1,…,Z pak}. (38) pa k The exclusion restrictions expresses the fact that each parent set includes all direct causes of the child variable, hence, fixing the parents of Y, determines the value ofY uniquely, and intervention on any other set S of (endogenous) vari- ables can no longer affectY. The independence restriction translates the indepen- dence between U and {U ,…,U } into independence between the correspond- Y Z1 Zk ing potential-outcome variables. This follows from the observation that, once we set theirparents, thevariables in{Y,Z1,…,Z k}stand in functionalrelationshipsto theU termsintheircorrespondingequations.\n\nAs an example, consider the model shown in Fig. 5, which serves as the canonical representation for the analysis of instrumental variables (Angrist et al., 1996, BalkeandPearl,1997). This modeldisplays the followingparentsets: PA ={0/}, PA ={Z}, PA ={X}. (39) Z X Y Consequently, theexclusion restrictionstranslate into: X = X z yz Z = Z =Z =Z (40) y xy x Y = Y x xz the absence of any dashed arc between Z and {Y,X} translates into the indepen- dence restriction Z⊥⊥ {Y ,X }. (41) x z This is precisely the condition of randomization; Z is independent of all its non- descendants, namely independent of U and U which are the exogenous parents X Y ofY and X, respectively. (Recallthatthe exogenous parentsofany variable,sayY, maybe replacedbythecounterfactualvariableY , because holdingPA constant pa Y Y rendersY a deterministicfunctionofitsexogenous parentU .) Y The roleofgraphsisnotendedwiththeformulationofcausalassumptions.\nThroughout an algebraic derivation, like the one shown in Eq. (36), the analyst may need toemployadditionalassumptions that areentailed by theoriginalexclu- sionandindependenceassumptions, yetarenotshownexplicitlyintheirrespective algebraicexpressions. Forexample,itishardlystraightforwardtoshowthattheas- sumptions of Eqs. (40)–(41)imply the conditional independence (Y ⊥⊥Z|{X ,X}) x z butdonotimplytheconditionalindependence(Y ⊥⊥Z|X). These arenoteasilyde- x rivedbyalgebraicmeansalone. Suchimplicationscan, however,easilybetestedin the graph of Fig. 5 using the graphical reading for conditional independence (Def- inition 1). (See (Pearl, 2000a, pp. 16–17, 213–215).) Thus, when the need arises to employ independencies in the course of a derivation, the graph may assist the procedure by vividly displaying the independencies that logically follow from our assumptions.",
    "crumbs": [
      "Causal Inference",
      "An Introduction to Causal Inference"
    ]
  },
  {
    "objectID": "extracted/An Introduction to Causal Inference.html#counterfactuals-at-work",
    "href": "extracted/An Introduction to Causal Inference.html#counterfactuals-at-work",
    "title": "An Introduction to Causal Inference",
    "section": "6. Counterfactuals at Work",
    "text": "6. Counterfactuals at Work\n6.1 Mediation: Direct and indirect effects\n6.1.1 Direct versustotaleffects The causal effect we have analyzed so far, P(y|do(x)), measures the total effect of a variable (or a set of variables) X on a response variable Y. In many cases, this quantity does not adequately represent the target of investigation and attention is focused instead on the direct effect of X on Y. The term “direct effect” is meant to quantify an effect that is not mediated by other variables in the model or, more accurately,thesensitivityofY tochangesinX whileallotherfactorsintheanalysis are held fixed. Naturally, holding those factors fixed would sever all causal paths from X toY with the exception of the direct link X →Y, which is not intercepted byany intermediaries.\nA classical example of the ubiquity of direct effects involves legal disputes over race or sex discrimination in hiring. Here, neither the effect of sex or race on applicants’ qualification nor the effect of qualification on hiring are targets of litigation. Rather, defendantsmustprovethatsexandracedonotdirectlyinfluence hiring decisions, whatever indirect effects they might have on hiring by way of applicantqualification.\nFrom a policy making viewpoint, an investigator may be interested in de- composing effects to quantify the extent to which racial salary disparity is due to educationaldisparity,or,takingahealth-careexample,theextenttowhichsensitiv- itytoagivenexposure canbereducedby eliminatingsensitivitytoanintermediate factor, standing between exposure and outcome. Another example concerns the identification of neural pathways in the brain or the structural features of protein- signaling networks in molecular biology (Brent and Lok, 2005). Here, the decom- position of effects into their direct and indirect components carries theoretical sci- entific importance, for it tells us “how nature works” and, therefore, enables us to predictbehaviorundera richvarietyofconditions.\nYetdespiteitsubiquity,theanalysisofmediationhas longbeen athornyis- sueinthesocialandbehavioralsciences(JuddandKenny,1981,BaronandKenny, 1986, Muller, Judd, and Yzerbyt, 2005, Shrout and Bolger, 2002, MacKinnon, Fairchild,andFritz,2007a)primarilybecausestructuralequationmodelinginthose sciences were deeply entrenched in linear analysis, where the distinction between 18 causal parameters and their regressional interpretations can easily be conflated.\nAs demands grew to tackle problems involving binary and categorical variables, researchers could no longer define direct and indirect effects in terms of structural or regressional coefficients, and all attempts to extend the linear paradigms of ef- fect decomposition to non-linear systems produced distorted results (MacKinnon, Lockwood, Brown, Wang, and Hoffman, 2007b). These difficulties have accentu- ated the need to redefine and derive causal effects fromfirst principles, uncommit- ted to distributional assumptions or a particular parametric form of the equations.\nThe structural methodology presented in this paper adheres to this philosophy and it has produced indeed a principled solution to the mediation problem, based on the counterfactual reading of structural equations (29). The following subsections summarizethemethodand itssolution.\n6.1.2 Controlleddirect-effects A major impediment to progress in mediation analysis has been the lack of no- tational facility for expressing the key notion of “holding the mediating variables fixed” in the definition of direct effect. Clearly, this notion must be interpreted as (hypothetically)settingtheintermediatevariablestoconstantsbyphysicalinterven- tion, not by analytical means such as selection, regression, conditioning, matching oradjustment. Forexample, considerthesimplemediationmodelsofFig.6,where theerrorterms(notshownexplicitly)are assumed tobeindependent. Itwillnotbe sufficienttomeasure theassociation between gender(X)and hiring(Y)foragiven 18 Allarticlescitedabovedefinethedirectandindirecteffectsthroughtheirregressionalinterpre- tations; I am notaware of any article in thistraditionthat formallyadapts a causal interpretation, freeofestimation-specificparameterization.\nW W 1 2 Z Z X Y X Y (a) (b) Figure6: (a)A genericmodeldepictingmediationthroughZ withnoconfounders, and(b)withtwoconfounders,W1 andW2.\nlevel of qualification (Z), (see Fig. 6(b)) because, by conditioning on the mediator Z, we create spurious associations between X andY throughW2, even when there is nodirecteffectofX onY (Pearl,1998, ColeandHerna´n, 2002).\nUsingthedo(x)notation,enablesustocorrectlyexpressthenotionof“hold- ing Z fixed” and obtain a simple definition of the controlled direct effect of the transitionfromX =x toX =x′: ∆ CDE =E(Y|do(x),do(z))−E(Y|do(x′),do(z)) or,equivalently,usingcounterfactualnotation: ∆ CDE =E(Y )−E(Y ) xz x′z where Z is the set of all mediating variables. The readers can easily verify that, in linearsystems, thecontrolleddirecteffectreducestothepathcoefficientofthelink X →Y (see footnote 12) regardless of whether confounders are present (as in Fig.\n6(b))andregardless ofwhethertheerrortermsare correlatedornot.\nThisseparatesthetaskofdefinitionfromthatofidentification,asdemanded by Section 4.1. The identification of CDE would depend, of course, on whether confounders are present and whether they can be neutralized by adjustment, but these do not alter its definition. Nor should trepidation about infeasibility of the action do(gender=male) enter the definitionalphase of the study, Definitions ap- ply to symbolic models, not to human biology. Graphical identificationconditions for expressions of the type E(Y|do(x),do(z1),do(z2),…,do(z k)) in the presence of unmeasured confounders were derived by Pearl and Robins (1995) (see Pearl (2000a, Chapter 4) and invoke sequential application of the back-door conditions discussed in Section3.2.\n6.1.3 Naturaldirecteffects Inlinearsystems, thedirecteffectisfullyspecified bythepath coefficientattached to the link from X toY; therefore, the direct effect is independent of the values at whichwe hold Z. In nonlinearsystems, those values would,in general, modifythe effect of X onY and thus should be chosen carefully to represent the target policy under analysis. For example, it is not uncommon to find employers who prefer males for the high-paying jobs (i.e., high z) and females for low-paying jobs (low z).\nWhenthedirecteffectissensitivetothelevelsatwhichweholdZ,itisoften moremeaningfultodefinethedirecteffectrelativetosome“natural”base-linelevel thatmayvaryfromindividualtoindividual,andrepresentsthelevelofZ justbefore the change in X. Conceptually, we can define the natural direct effect DE (Y) x,x′ as the expected change inY induced by changing X fromx to x′ while keeping all mediatingfactorsconstantatwhatevervaluetheywouldhaveobtainedunderdo(x).\nThishypotheticalchange,whichRobinsandGreenland(1992)conceivedandcalled “pure”andPearl(2001)formalizedandanalyzedundertherubric“natural,”mirrors what lawmakers instruct us to consider in race or sex discrimination cases: “The central question in any employment-discrimination case is whether the employer would have taken the same action had the employee been of a different race (age, sex, religion, national origin etc.) and everything else had been the same.” (In Carson versus Bethlehem SteelCorp., 70FEPCases 921,7th Cir. (1996)).\nExtending the subscript notation to express nested counterfactuals, Pearl (2001)gave aformaldefinitionforthe“naturaldirecteffect”: DE (Y)=E(Y )−E(Y ). (42) x,x′ x′,Zx x Here,Y representsthevaluethatY wouldattainundertheoperationofsettingX x′,Zx tox′ and, simultaneously, settingZ towhatever valueitwouldhaveobtained under the setting X =x. We see that DE (Y), the natural direct effect of the transition x,x′ fromx to x′, involves probabilitiesof nested counterfactuals and cannot be written intermsofthedo(x)operator. Therefore,thenaturaldirecteffectcannotingeneral beidentified,evenwiththehelpofideal,controlledexperiments(seefootnote8for intuitiveexplanation). However,aidedbythesurgicaldefinitionofEq. (29)andthe notational power of nested counterfactuals, Pearl (2001) was nevertheless able to showthat,ifcertainassumptionsof“noconfounding”aredeemedvalid,thenatural directeffectcan be reducedto DE (Y)=∑ [E(Y|do(x′,z))−E(Y|do(x,z))]P(z|do(x)). (43) x,x′ z The intuitionis simple;the naturaldirecteffectis theweighted average ofthecon- trolleddirecteffect,using thecausal effectP(z|do(x)) as aweighingfunction.\nOneconditionforthevalidityof(43)is thatZ ⊥⊥Y |W holdsforsome set x x′,z W of measured covariates. This technical condition in itself, like the ignorability conditionof(35),isclosetomeaninglessformostinvestigators,asitisnotphrased in terms of realized variables. The surgical interpretation of counterfactuals (29) can be invoked at this point to unveil the graphical interpretationof this condition.\nIt states thatW should be admissible (i.e., satisfy the back-doorcondition) relative thepath(s)fromZ toY. Thiscondition,satisfiedbyW2 inFig.6(b),isreadilycom- prehended by empirical researchers, and the task of selecting such measurements, W, can then be guided by the available scientific knowledge. Additional graphical andcounterfactualconditionsforidentificationarederivedinPearl(2001)Petersen etal. (2006)andImai,Keele, andYamamoto(2008).\nInparticular,itcanbeshown(Pearl,2001)thatexpression(43)isbothvalid andidentifiableinMarkovianmodels(i.e.,nounobservedconfounders)whereeach term on the right can be reduced to a “do-free” expression using Eq. (24) or (25) andthen estimatedbyregression.\nForexample, forthe modelinFig.6(b),Eq. (43)reads: DE x,x′(Y)=∑∑P(w1)[E(Y|x′,z,w1))−E(Y|x,z,w1))]∑P(z|x,w2)P(w2). (44) z w1 w2 whilefortheconfounding-freemodelofFig. 6(a)we have: DE (Y)=∑ [E(Y|x′,z)−E(Y|x,z)]P(z|x). (45) x,x′ z Both(44)and(45)caneasily beestimated bya two-stepregression.\n6.1.4 Naturalindirecteffects Remarkably, the definition of the natural direct effect (42) can be turned around and provide an operational definition for the indirect effect – a concept shrouded in mystery and controversy, because it is impossible, using the do(x) operator, to disable the direct link from X to Y so as to let X influence Y solely via indirect paths.\nThenaturalindirecteffect,IE, ofthetransitionfromxtox′ isdefinedasthe expected change inY affected by holding X constant, at X =x, and changing Z to whatevervalueitwouldhaveattainedhadX beensettoX =x′. Formally,thisreads (Pearl,2001): ∆ IE (Y)=E[(Y )−E(Y )], (46) x,x′ x ,Z x′ x whichisalmostidenticaltothedirecteffect(Eq.(42))save forexchangingx andx′ inthe firstterm.\nIndeed, it can be shown that, in general, the total effect TE of a transition isequal tothedifferencebetweenthe directeffectofthattransitionandtheindirect effectofthereversetransition. Formally, ∆ TE (Y)=E(Y −Y )=DE (Y)−IE (Y). (47) x,x′ x′ x x,x′ x′,x In linear systems, where reversal of transitions amounts to negating the signs of theireffects,we havethe standardadditiveformula TE (Y)=DE (Y)+IE (Y). (48) x,x′ x,x′ x,x′ Sinceeachtermaboveisbasedonanindependentoperationaldefinition,thisequal- ityconstitutesaformaljustificationfortheadditiveformulausedroutinelyinlinear systems.\nNotethat,althoughitcannotbeexpressedindo-notation,theindirecteffect has clear policy-making implications. For example: in the hiring discrimination context, a policy makermay be interestedin predictingthegender mixinthe work force if gender bias is eliminated and all applicants are treated equally—say, the samewaythatmalesarecurrentlytreated. Thisquantitywillbegivenbytheindirect effect of gender on hiring, mediated by factors such as education and aptitude, whichmaybe gender-dependent.\nMore generally, a policy maker may be interested in the effect of issuing a directive to a select set of subordinate employees, or in carefully controlling the routingofmessages in a networkofinteractingagents. Suchapplications motivate the analysis of path-specific effects, that is, the effect of X onY through a selected set ofpaths(Avin, Shpitser,andPearl, 2005).\nInall these cases, the policy interventioninvokesthe selection of signals to be sensed, rather than variables to be fixed. Pearl (2001) has suggested therefore that signal sensing is more fundamental to the notion of causation than manipu- lation; the latter being but a crude way of stimulating the former in experimental setup. The mantra “No causation without manipulation” must be rejected. (See (Pearl,2009b,Section11.4.5).) It is remarkable that counterfactual quantities like DE and IE that could not be expressed in terms of do(x) operators, and appear thereforevoid of empiri- cal content, can, under certain conditions be estimated fromempirical studies, and servetoguidepolicies. Awarenessofthispotentialshouldemboldenresearchersto go through the definitional step of the study and freely articulate the target quan- tity Q(M) in the language of science, i.e., counterfactuals, despite the seemingly speculative natureofeach assumption inthemodel(Pearl,2000b).\n6.2 The MediationFormula: a simplesolutionto a thornyprob- lem This subsection demonstrateshow thesolutionprovidedinequations (45)and(48) can be applied to practical problems of assessing mediation effects in non-linear models. Wewilluse thesimplemediationmodelofFig.6(a),whereallerrorterms (not shown explicitly) are assumed to be mutually independent, with the under- standing that adjustment for appropriate sets of covariates W may be necessary to achievethisindependenceandthatintegralsshouldreplacesummationswhendeal- ingwithcontinuousvariables(Imaietal., 2008).\nCombining (45) and (48), the expression for the indirect effect, IE, be- comes: IE (Y)=∑E(Y|x,z)[P(z|x′)−P(z|x)] (49) x,x′ z whichprovidesageneralformulaformediationeffects,applicabletoanynonlinear system, anydistribution(ofU),andanytypeofvariables. Moreover,theformulais readily estimable by regression. Owed to its generality and ubiquity, Iwill referto thisexpression as the“Mediation Formula.” The Mediation Formula represents the average increase in the outcome Y that the transition from X = x to X = x′ is expected to produce absent any direct effect of X on Y. Though based on solid causal principles, it embodies no causal assumption other than the generic mediation structure of Fig. 6(a). When the out- come Y is binary (e.g., recovery, or hiring) the ratio (1−IE/TE) represents the fraction of responding individuals who owe their response to direct paths, while (1−DE/TE) representsthefractionwhoowetheirresponse toZ-mediatedpaths.\nThe Mediation Formula tells us that IE depends only on the expectation of the counterfactual Y , not on its functional form f (x,z,u ) or its distribution xz Y Y P(Y = y). It calls therefore for a two-step regression which, in principle, can be xz performednon-parametrically. InthefirststepweregressY onX andZ, andobtain theestimate g(x,z)=E(Y|x,z) forevery(x,z)cell. Inthesecond stepweestimatetheexpectationofg(x,z) condi- tionalonX =x′ and X =x, respectively,andtakethe difference: IE (Y)=E (g(x,z)|x′)−E (g(x,z)|x) x,x′ z z Nonparametric estimation is not always practical. When Z consists of a vector of several mediators, the dimensionality of the problem would prohibit the estimation of E(Y|x,z) for every (x,z) cell, and the need arises to use parametric approximation. We can then choose any convenient parametric form for E(Y|x,z) (e.g., linear, logit, probit), estimate the parameters separately (e.g., by regression or maximum likelihood methods), insert the parametric approximation into (49) and estimate its two conditional expectations (over z) to get the mediated effect (VanderWeele, 2009).\nLet us examine what the Mediation Formula yields when applied to both linearandnon-linearversionsofmodel6(a). Inthelinearcase,thestructuralmodel reads: x=u X z=b x+u (50) x Z y=c x+c z+u x z Y Computingtheconditionalexpectationin(49)gives E(Y|x,z)=E(c x+c z+u )=c x+c z x z Y x z andyields IE (Y)=∑ (c x+c z)[P(z|x′)−P(z|x)].\nx,x′ x z z =c [E(Z|x′)−E(Z|x)] (51) z =(x′−x)(c b ) (52) z x =(x′−x)(b−c ) (53) x whereb isthe totaleffectcoefficient,b=(E(Y|x′)−E(Y|x))/(x′−x)=c +c b .\nx z x We thus obtainedthe standard expressions forindirect effectsin linear sys- tems, which can be estimated either as a difference in two regression coefficients (Eq. 53) or a product of two regression coefficients (Eq. 52), with Y regressed on both X and Z. (see (MacKinnon et al., 2007b)). These twostrategies do not gener- alizeto non-linearsystem as weshall see next.\nSupposeweapply(49)toanon-linearprocess (Fig.7)inwhichX,Y,andZ arebinaryvariables,andY andZ aregivenby theBooleanformula Y =AND (x,e )∨ AND (z,e ) x,z,e ,e =0,1 x z x z z=AND (x,e ) z,e =0,1 xz xz Such disjunctive interaction would describe, for example, a disease Y that would be triggered either by X directly, if enabled by e , or by Z, if enabled by e . Let x z us furtherassume that e ,e and e are three independent Bernoulli variables with x z xz probabilities p ,p ,and p , respectively.\nx z xz e z x ( ~ p x z ) e z ( ~ p z ) Z AND AND AND OR Y X e ( ~ p ) x x Figure7: Stochasticnon-linearmodelofmediation. Allvariablesare binary.\nAs investigators, we are not aware, of course, of these underlying mecha- nisms; all we know is that X,Y, and Z are binary, that Z is hypothesized to be a mediator,andthattheassumption ofnonconfoundednesspermitsus touse theMe- diation Formula (49) for estimating the Z-mediated effect of X onY. Assume that our plan is to conduct a nonparametric estimation of the terms in (49) over a very largesampledrawnfromP(x,y.z); itisinterestingtoaskwhattheasymptoticvalue of the Mediation Formula wouldbe, as a functionof the model parameters: p ,p , x z and p .\nxz Fromknowledgeoftheunderlyingmechanism, wehave: P(Z =1|x) = p x x=0,1 xz P(Y =1|x,z) = p x+p z−p p xz x,z=0,1 x z x z Therefore, E(Z|x) = p x x=0,1 xz E(Y|x,z) =xp +zp −xzp p x,z=0,1 x z x z E(Y|x) =∑ E(Y|x,z)P(z|x) z =xp +(p −xp p )E(Z|x) x z x z =x(p +p p −xp p p ) x=0,1 x xz z x z xz Taking x = 0,x′ = 1 and substituting these expressions in (45), (48), and (49)yields IE(Y)= p p (54) z xz DE(Y)= p (55) x TE(Y)= p p +p +p p p (56) z xz x x z xz Twoobservationsareworthnoting. First,weseethat,despitethenon-linear interactionbetweenthetwocausalpaths, theparametersofonedonotinfluenceon thecausaleffectmediatedbytheother. Second,thetotaleffectisnotthesumofthe directandindirecteffects. Instead, we have: TE =DE+IE−DE·IE whichmeansthatafractionDE·IE/TE ofoutcomecasestriggeredbythetransition from X =0 to X =1 are triggered simultaneously, through both causal paths, and wouldhave been triggeredeven ifone ofthepaths wasdisabled.\nNow assume that we choose to approximate E(Y|x,z) by the linear expres- sion g(x,z)=a0+a1x+a2z. (57) After fitting the a’s parameters to the data (e.g., by OLS) and substituting in (49) onewouldobtain IE x,x′(Y) =∑ z(a0+a1x+a2z)[P(z|x′)−P(z|x)] (58) =a2[E(Z|x′)−E(Z|x)] whichholdswheneverweuse theapproximationin(57),regardlessoftheunderly- ingmechanism.\nIf the correct data-generating process was the linear model of (50), we wouldobtainthe expected estimatesa2 =c z,E(z|x′)−E(z|x′)=b x(x′−x) and IE (Y)=b c (x′−x).\nx,x′ x z Ifhoweverwe weretoapplytheapproximationin(57)todatageneratedby the nonlinear model of Fig. 7, a distorted solution wouldensue; a2 would evaluate to a2 =∑ x[E(Y|x,z=1)−E(Y|x,z=0)]P(x) =P(x=1)[E(Y|x=1,z=1)−E(Y|x=1,z=0)] =P(x=1)[(p +p −p p )−p ] x z x z x =P(x=1)p (1−p ), z x E(z|x′)−E(z|x) wouldevaluateto p (x′−x), and(58)wouldyieldtheapproxima- xz tion IˆE x,x′(Y) =a2[E(Z|x′)−E(Z|x)] (59) = p P(x=1)p (1−p ) xz z x We see immediately that the result differs from the correct value p p de- z xz rived in (54). Whereas the approximate value depends on P(x = 1), the correct valueshowsnosuchdependence,andrightlyso;nocausal effectshoulddependon theprobabilityofthe causal variable.\nFortunately, the analysis permits us to examine under what condition the distortion would be significant. Comparing (59) and (54) reveals that the approxi- matemethodalwaysunderestimatestheindirecteffectandthedistortionisminimal forhighvaluesofP(x=1) and(1−p ).\nx Had we chosen to include an interaction term in the approximation of E(Y|x,z), thecorrectresultwouldobtain. To witness, writing E(Y|x,z)=a0+a1x+a2z+a3xz, a2 wouldevaluateto p z, a3 to p xp z, andthe correctresultobtains through: IE x,x′(Y)=∑ (a0+a1x+a2z+a3xz)[P(z|x′)−P(z|x)] z =(a2+a3x)[E(Z|x′)−E(Z|x)] =(a2+a3x)p xz(x′−x) =(p −p p x)p (x′−x) z x z xz Weseethat,inadditiontoprovidingcausally-soundestimatesformediation effects,theMediation Formulaalso enablesresearchers toevaluateanalyticallythe effectiveness of various parametric specifications relative to any assumed model.\nThis type of analytical “sensitivity analysis” has been used extensively in statistics forparameterestimation,butcouldnotbeappliedtomediationanalysis,owedtothe absence of an objective target quantity that captures the notionof indirect effectin bothlinearandnon-linearsystems, freeofparametricassumptions. The Mediation FormulaofEq. (49)explicates this targetquantityformally,andcasts itinterms of estimablequantities.\nThederivationoftheMediationFormulawasfacilitatedbytakingseriously thefourstepsofthestructuralmethodology(Section4)togetherwiththegraphical- counterfactual-structuralsymbiosis spawnedbythesurgicalinterpretationofcoun- terfactuals(Eq. (29)).\nIn contrast, when the mediation problem is approached froman exclusivist potential-outcomeviewpoint,voidofthestructuralguidanceofEq.(29),counterin- tuitive definitions ensue, carrying the label “principal stratification” (Rubin, 2004, 2005), whichare at variance withcommon understandingofdirect and indirectef- fects. For example, the direct effect is definable only in units absent of indirect effects. This means that a grandfather would be deemed to have no direct effect on his grandson’s behavior in families where he has had some effect on the father.\nThis precludesfromtheanalysis alltypicalfamilies,inwhichafatherand agrand- father have simultaneous, complementary influences on children’s upbringing. In linear systems, to take an even sharper example, the direct effect would be unde- fined whenever indirect paths exist from the cause to its effect. The emergence of such paradoxical conclusions underscores the wisdom, if notnecessity ofa symbi- oticanalysis,inwhichthecounterfactualnotationY (u)isgovernedbyitsstructural x 19 definition,Eq. (29).\n6.3 Causes of effects and probabilities of causation The likelihood that one event was the cause of another guides much of what we understand about the world(and howwe act in it). Forexample, knowing whether itwastheaspirinthatcuredmyheadacheortheTVprogramIwaswatchingwould surely affectmy futureuse of aspirin. Likewise, to take an example fromcommon judicial standard, judgment in favor of a plaintiff should be made if and only if it is “more probable than not” that the damage would not have occurred but for the defendant’saction(Robertson, 1997).\nThese two examples fall under the category of “causes of effects” because theyconcernsituationsinwhichweobserveboththeeffect,Y =y,andtheputative causeX =xandweareaskedtoassess, counterfactually,whethertheformerwould have occurredabsent the latter.\nWehaveremarkedearlier(footnote8)thatcounterfactualprobabilitiescon- ditionedon theoutcome cannotin generalbe identifiedfromobservationaloreven experimental studies. This does not mean however that such probabilities are use- less or void of empirical content; the structural perspective may guide us in fact towarddiscoveringtheconditionsunderwhichtheycanbeassessed fromdata,thus definingtheempiricalcontentofthese counterfactuals.\nFollowing the 4-step process of structural methodology – define, assume, identify, and estimate – our first step is to express the target quantity in counter- factual notation and verify that it is well defined, namely, that it can be computed unambiguouslyfromany fully-specifiedcausal model.\nIn our case, this step is simple. Assuming binary events, with X = x and Y = y representing treatment and outcome, respectively, and X =x′, Y = y′ their negations,ourtargetquantitycanbeformulateddirectlyfromtheEnglishsentence: “Find the probability that Y would be y′ had X been x′, given that, in reality,Y is actuallyyand X is x,” togive: PN(x,y)=P(Y =y′|X =x,Y =y) (60) x′ 19 Suchsymbiosisisnowstandardinepidemiologyresearch(Robins,2001,Petersenetal.,2006, VanderWeele andRobins,2007,Hafeman andSchwartz,2009,VanderWeele, 2009)andismaking itswayslowlytowardthesocialandbehavioralsciences.\nThis counterfactual quantity, which Robins and Greenland (1989b) named “probability of causation” and Pearl (2000a, p. 296) named “probability of neces- sity” (PN), to be distinguished from two other nuances of “causation,” is certainly computablefromanyfullyspecifiedstructuralmodel,i.e.,oneinwhichP(u)andall functional relationships are given. This follows from the fact that every structural modeldefines ajointdistributionofcounterfactuals,throughEq. (29).\nHaving written a formal expression for PN, Eq. (60), we can move on to the formulation and identification phases and ask what assumptions would permit us to identify PN from empirical studies, be they observational, experimental or a combinationthereof.\nThis problem was analyzed in Pearl (2000a, Chapter 9) and yielded the followingresults: Theorem 4 IfY is monotonic relative to X, i.e., Y1(u)≥Y0(u), thenPN is identifi- ablewhenever thecausal effectP(y|do(x)) is identifiableand, moreover, P(y|x)−P(y|x′) P(y|x′)−P(y|do(x′)) PN= + . (61) P(y|x) P(x,y) The first term on the r.h.s. of (61) is the familiar excess risk ratio (ERR) that epi- demiologists have been using as a surrogate for PN in court cases (Cole, 1997, Robins and Greenland, 1989b). The second term represents the correction needed toaccount forconfoundingbias, thatis,P(y|do(x′))̸=P(y|x′).\nThissuggeststhatmonotonicityandunconfoundednessweretacitlyassumed by the many authors who proposed or derived ERR as a measure for the “fraction ofexposed cases that areattributabletothe exposure”(Greenland,1999).\nEquation(61)thusprovidesamorerefinedmeasureofcausation,whichcan beusedinsituationswherethecausaleffectP(y|do(x))canbeestimatedfromeither randomized trials or graph-assisted observationalstudies (e.g., through Theorem 3 or Eq. (25)). It can also be shown (Tian and Pearl, 2000) that the expression in (61) provides a lower bound for PN in the general, nonmonotonic case. (See also (RobinsandGreenland,1989a).) Inparticular,thetightupperandlowerboundson PNaregiven by: P(y)−P(y|do(x′)) P(y′|do(x′))−P(x′,y′) max 0, ≤PN ≤min 1, (62) ! P(x,y) ” ! P(x,y) ” It is worth noting that, in drug related litigation, it is not uncommon to ob- tain data from both experimental and observational studies. The former is usually available at the manufactureror the agency that approved the drug for distribution (e.g., FDA), while the latteris easy to obtainby randomsurveys of thepopulation.\nIn such cases, the standard lower bound used by epidemiologists to establish le- gal responsibility, the Excess Risk Ratio, can be improved substantially using the corrective term of Eq. (61). Likewise, the upper bound of Eq. (62) can be used to exonerate drug-makers from legal responsibility. Cai and Kuroki (2006) analyzed thestatistical propertiesofPN.\nPearl (2000a, p. 302) shows that combining data from experimental and observational studies which, taken separately, may indicate no causal relations be- tween X and Y, can nevertheless bring the lower bound of Eq. (62) to unity, thus implyingcausation withprobabilityone.\nSuchextremeresultsdispelallfearsandtrepidationsconcerningtheempiri- calcontentofcounterfactuals(Dawid,2000,Pearl,2000b). Theydemonstratethata quantityPN whichat first glance appears tobe hypothetical,ill-defined,untestable and, hence, unworthy of scientific analysis is nevertheless definable, testable and, in certain cases, even identifiable. Moreover, the fact that, under certain combina- tionofdata, andmakingnoassumptionswhatsoever,animportantlegalclaimsuch as “the plaintiffwould be alive had he not taken the drug” can be ascertained with probabilityapproachingone, isa remarkabletributetoformalanalysis.\nAnothercounterfactualquantitythathasbeenfullycharacterizedrecentlyis theEffectofTreatment ontheTreated (ETT): ETT =P(Y =y|X =x′) x ETT hasbeenusedineconometricstoevaluatetheeffectivenessofsocialprograms on their participants (Heckman, 1992) and has long been the target of research in epidemiology, where it came to be known as “the effect of exposure on the exposed,” or “standardized morbidity” (Miettinen, 1974; Greenland and Robins, 1986).\nShpitserandPearl(2009)havederiveda completecharacterizationofthose models in which ETT can be identified from either experimental or observational studies. They have shown that, despite its blatant counterfactual character, (e.g., “I just took an aspirin, perhaps I shouldn’t have?”) ETT can be evaluated from experimental studies in many, though not all cases. It can also be evaluated from observational studies whenever a sufficient set of covariates can be measured that satisfies the back-doorcriterionand, more generally, in a wide class of graphs that permittheidentificationofconditionalinterventions.\nTheseresultsfurtherilluminatetheempiricalcontentofcounterfactualsand their essential role in causal analysis. They prove once again the triumph of logic andanalysisovertraditionsthata-prioriexcludefromtheanalysisquantitiesthatare nottestableinisolation. Mostofall,theydemonstratetheeffectivenessandviability ofthe scientific approach to causation wherebythe dominantparadigm is tomodel the activities of Nature, rather than those of the experimenter. In contrast to the rulingparadigmofconservativestatistics,webeginwithrelationshipsthatweknow inadvancewillneverbeestimated, testedorfalsified. Onlyafterassembling ahost ofsuch relationshipsandjudgingthemtofaithfullyrepresentourtheoryabouthow Nature operates, we ask whether the parameter ofinterest, crisply definedin terms ofthosetheoreticalrelationships,canbeestimatedconsistentlyfromempiricaldata andhow. Itoftendoes, to thecreditofprogressivestatistics.",
    "crumbs": [
      "Causal Inference",
      "An Introduction to Causal Inference"
    ]
  },
  {
    "objectID": "extracted/An Introduction to Causal Inference.html#conclusions",
    "href": "extracted/An Introduction to Causal Inference.html#conclusions",
    "title": "An Introduction to Causal Inference",
    "section": "7. Conclusions",
    "text": "7. Conclusions\nTraditional statistics is strong in devising ways of describing data and inferring\ndistributional parameters from sample. Causal inference requires two additional ingredients: a science-friendly language for articulating causal knowledge, and a mathematical machinery for processing that knowledge, combining it with data and drawing new causal conclusions about a phenomenon. This paper surveys re- centadvancesincausalanalysisfromtheunifyingperspectiveofthestructuralthe- ory of causation and shows how statistical methods can be supplemented with the needed ingredients. The theory invokes non-parametric structural equations mod- elsas aformalandmeaningfullanguagefordefiningcausal quantities,formulating causal assumptions, testing identifiability, and explicating many concepts used in causal discourse. These include: randomization, intervention, direct and indirect effects, confounding, counterfactuals, and attribution. The algebraic component of the structurallanguage coincides with the potential-outcomeframework,and its graphical component embraces Wright’s method of path diagrams. When unified and synthesized, the two components offer statistical investigators a powerful and comprehensivemethodologyforempiricalresearch.",
    "crumbs": [
      "Causal Inference",
      "An Introduction to Causal Inference"
    ]
  },
  {
    "objectID": "extracted/An Introduction to Causal Inference.html#references",
    "href": "extracted/An Introduction to Causal Inference.html#references",
    "title": "An Introduction to Causal Inference",
    "section": "References",
    "text": "References\nAngrist, J., G. Imbens, and D. Rubin (1996): “Identification of causal effects us-\ninginstrumentalvariables(withcomments),”JournaloftheAmerican Statistical Association, 91, 444–472.\nArah, O. (2008): “The role of causal reasoning in understanding Simp- son’s paradox, Lord’s paradox, and the suppression effect: Covariate se- lection in the analysis of observational studies,” Emerging Themes in Epidemiology, 4, doi:10.1186/1742–7622–5–5, online at &lt;http://www.ete- online.com/content/5/1/5&gt;.\nArjas, E. and J. Parner (2004): “Causal reasoning fromlongitudinaldata,” Scandi- navianJournalofStatistics, 31, 171–187.\nAvin, C., I. Shpitser, and J. Pearl (2005): “Identifiability of path-specific effects,” inProceedings oftheNineteenth InternationalJointConference onArtificial In- telligenceIJCAI-05, Edinburgh,UK:Morgan-KaufmannPublishers, 357–363.\nBalke, A. and J. Pearl (1995): “Counterfactuals and policy analysis in structural models,” in P. Besnard and S. Hanks, eds., Uncertainty in Artificial Intelligence 11,San Francisco: MorganKaufmann,11–18.\nBalke, A. and J. Pearl (1997): “Bounds on treatment effects fromstudies with im- perfect compliance,” Journal of the American Statistical Association, 92, 1172– 1176.\nBaron, R. and D. Kenny (1986): “The moderator-mediator variable distinction in social psychological research: Conceptual, strategic, and statistical considera- tions,”Journalof PersonalityandSocialPsychology, 51,1173–1182.\nBerkson, J. (1946): “Limitations of the application of fourfold table analysis to hospitaldata,” Biometrics Bulletin,2, 47–53.\nBollen, K. (1989): Structural Equations with Latent Variables, New York: John Wiley.\nBrent, R. andL. Lok (2005): “A fishingbuddyforhypothesisgenerators,”Science, 308,523–529.\nCai, Z. and M. Kuroki(2006): “Variance estimators forthree‘probabilitiesofcau- sation’,”Risk Analysis, 25, 1611–1620.\nCai,Z.andM.Kuroki(2008): “Onidentifyingtotaleffectsinthepresenceoflatent variables and selection bias,” in D. A. McAllester and P. Myllyma¨ki, eds., Un- certaintyinArtificialIntelligence,ProceedingsoftheTwenty-FourthConference, Arlington,VA: AUAI, 62–69.\nCartwright, N. (2007): Hunting Causes and Using Them: Approaches in Philoso- phyandEconomics, NewYork,NY: CambridgeUniversityPress.\nChalak, K. and H. White (2006): “An extended class of instrumental variables for theestimationofcausaleffects,”TechnicalReportDiscussionPaper,UCSD,De- partmentofEconomics.\nChickering, D. and J. Pearl (1997): “A clinician’s tool for analyzing non- compliance,”ComputingScienceand Statistics,29, 424–431.\nCole, P. (1997): “Causality in epidemiology, health policy, and law,” Journal of MarketingResearch, 27, 10279–10285.\nCole, S. and M. Herna´n (2002): “Fallibility in estimating direct effects,” Interna- tionalJournal ofEpidemiology,31, 163–165.\nCox, D. (1958): ThePlanningofExperiments, NY: John WileyandSons.\nCox, D. and N. Wermuth (2004): “Causality: A statistical view,” International StatisticalReview, 72, 285–305.\nDawid, A. (1979): “Conditional independence in statistical theory,” Journal of the RoyalStatisticalSociety, Series B, 41,1–31.\nDawid, A. (2000): “Causal inference without counterfactuals(with comments and rejoinder),”JournaloftheAmerican StatisticalAssociation, 95,407–448.\nDawid, A. (2002): “Influencediagrams forcausal modellingand inference,” Inter- nationalStatisticalReview, 70, 161–189.\nDuncan, O. (1975): Introduction to Structural Equation Models, New York: Aca- demicPress.\nEells, E. (1991): Probabilistic Causality, Cambridge, MA: Cambridge University Press.\nFrangakis, C. and D. Rubin (2002): “Principal stratification in causal inference,” Biometrics, 1,21–29.\nGlymour, M. and S. Greenland (2008): “Causal diagrams,” in K. Rothman, S. Greenland, and T. Lash, eds., Modern Epidemiology, Philadelphia, PA: Lip- pincottWilliams&Wilkins, 3rdedition, 183–209.\nGoldberger,A. (1972): “Structuralequationmodelsin thesocial sciences,” Econo- metrica: Journalofthe Econometric Society,40, 979–1001.\nGoldberger, A. (1973): “Structural equation models: An overview,” in A. Gold- berger and O. Duncan, eds., Structural Equation Models in the Social Sciences, NewYork,NY:SeminarPress, 1–18.\nGreenland, S. (1999): “Relation ofprobability ofcausation, relative risk, and dou- bling dose: A methodologic error that has become a social problem,” American JournalofPublic Health,89, 1166–1169.\nGreenland, S., J. Pearl, and J. Robins (1999): “Causal diagrams for epidemiologic research,”Epidemiology,10, 37–48.\nGreenland, S. and J. Robins (1986): “Identifiability,exchangeability, and epidemi- ologicalconfounding,”InternationalJournal ofEpidemiology,15, 413–419.\nHaavelmo, T. (1943): “The statistical implications of a system of simultaneous equations,” Econometrica, 11, 1–12, reprintedin D.F. Hendry and M.S. Morgan (Eds.), The Foundations of Econometric Analysis, Cambridge University Press, 477–490,1995.\nHafeman,D.andS.Schwartz(2009): “Openingtheblackbox: Amotivationforthe assessment ofmediation,”InternationalJournalofEpidemiology,3, 838–845.\nHalpern, J. (1998): “Axiomatizing causal reasoning,” in G. Cooper and S. Moral, eds., Uncertainty in Artificial Intelligence, San Francisco, CA: Morgan Kauf- mann, 202–210, also, Journal of Artificial Intelligence Research 12:3, 17–37, 2000.\nHeckman, J. (1992): “Randomization and social policy evaluation,” in C. Manski andI. Garfinkle,eds., Evaluations: Welfare andTraining Programs, Cambridge, MA:HarvardUniversityPress, 201–230.\nHeckman,J.(2005): “Thescientificmodelofcausality,”SociologicalMethodology, 35,1–97.\nHeckman, J. (2008): “Econometric causality,” InternationalStatisticalReview, 76, 1–27.\nHeckman, J. and S. Navarro-Lozano (2004): “Using matching, instrumental vari- ables,andcontrolfunctionstoestimateeconomicchoicemodels,”TheReview of Economics andStatistics, 86, 30–57.\nHeckman, J. and E. Vytlacil (2005): “Structural equations, treatment effects and econometricpolicy evaluation,”Econometrica, 73,669–738.\nHerna´n, M. and S. Cole (2009): “Invited commentary: Causal diagrams and mea- surementbias,” American JournalofEpidemiology,170, 959–962.\nHolland, P. (1988): “Causal inference,path analysis, andrecursive structuralequa- tions models,” in C. Clogg, ed., Sociological Methodology, Washington, D.C.: AmericanSociologicalAssociation, 449–484.\nHurwicz, L. (1950): “Generalization of the concept of identification,” in T. Koop- mans, ed., StatisticalInference in Dynamic Economic Models, Cowles Commis- sion, Monograph10,New York: Wiley,245–257.\nImai, K., L. Keele, and T. Yamamoto (2008): “Identification, inference, and sen- sitivity analysis for causal mediation effects,” Technical report, Department of Politics,PrinctonUniversity.\nImbens, G. and J. Wooldridge (2009): “Recent developments in the econometrics ofprogramevaluation,”JournalofEconomic Literature, 47, 5–86.\nJudd, C. and D. Kenny (1981): “Process analysis: Estimating mediation in treat- mentevaluations,”EvaluationReview, 5, 602–619.\nKaufman, S., J. Kaufman, and R. MacLenose (2009): “Analytic bounds on causal risk differences in directed acyclic graphs involving three observed binary vari- ables,” JournalofStatisticalPlanningandInference, 139, 3473–3487.\nKiiveri, H., T. Speed, and J. Carlin (1984): “Recursive causal models,” Journal of Australian MathSociety, 36, 30–52.\nKoopmans, T. (1953): “Identification problems in econometric model construc- tion,” in W. Hood and T. Koopmans, eds., Studies in Econometric Method, New York: Wiley, 27–48.\nKuroki, M. and M. Miyakawa (1999): “Identifiability criteria for causal effects of jointinterventions,”Journal oftheRoyal StatisticalSociety,29, 105–117.\nLauritzen, S.(1996): Graphical Models, Oxford: ClarendonPress.\nLauritzen, S. (2001): “Causal inference from graphical models,” in D. Cox and C. Kluppelberg, eds., Complex Stochastic Systems, Boca Raton, FL: Chapman andHall/CRC Press, 63–107.\nLindley, D. (2002): “Seeing and doing: The concept of causation,” International StatisticalReview, 70, 191–214.\nMacKinnon, D., A. Fairchild, and M. Fritz (2007a): “Mediation analysis,” Annual Review ofPsychology, 58, 593–614.\nMacKinnon,D.,C.Lockwood,C.Brown,W.Wang,andJ.Hoffman(2007b): “The intermediateendpointeffectinlogisticand probitregression,” ClinicalTrials, 4, 499–513.\nManski, C. (1990): “Nonparametric bounds on treatment effects,” American Eco- nomicReview, Papers andProceedings, 80, 319–323.\nMarschak,J.(1950): “Statisticalinferenceineconomics,”inT.Koopmans,ed.,Sta- tisticalInferenceinDynamicEconomicModels, NewYork: Wiley,1–50,cowles CommissionforResearch inEconomics, Monograph10.\nMeek, C. and C. Glymour(1994): “Conditioningand intervening,”British Journal ofPhilosophy Science, 45,1001–1021.\nMiettinen, O. (1974): “Proportionofdisease caused or prevented by a given expo- sure, trait,orintervention,”Journalof Epidemiology,99, 325–332.\nMorgan, S. and C. Winship (2007): Counterfactuals and Causal Inference: Meth- odsandPrinciplesforSocialResearch(AnalyticalMethodsforSocialResearch), NewYork,NY:CambridgeUniversityPress.\nMuller, D., C. Judd, and V. Yzerbyt (2005): “When moderation is mediated and mediationismoderated,”JournalofPersonalityandSocialPsychology,89,852– 863.\nNeyman, J. (1923): “On theapplication ofprobabilitytheoryto agriculturalexper- iments. Essay onprinciples. Section9,”StatisticalScience, 5, 465–480.\nPearl, J. (1988): Probabilistic Reasoning in Intelligent Systems, San Mateo, CA: MorganKaufmann.\nPearl, J. (1993a): “Comment: Graphical models, causality, and intervention,” Sta- tisticalScience, 8, 266–269.\nPearl, J. (1993b): “Mediating instrumental variables,” Technical Report R-210, &lt;http://ftp.cs.ucla.edu/pub/stat ser/R210.pdf&gt;, Department of Computer Sci- ence, UniversityofCalifornia,Los Angeles.\nPearl, J. (1995): “Causal diagrams for empirical research,” Biometrika, 82, 669– 710.\nPearl, J. (1998): “Graphs, causality, and structural equation models,” Sociological Methods andResearch, 27,226–284.\nPearl, J. (2000a): Causality: Models, Reasoning, and Inference, New York: Cam- bridgeUniversityPress, second ed., 2009.\nPearl, J. (2000b): “Comment on A.P. Dawid’s, Causal inference without counter- factuals,”JournaloftheAmerican StatisticalAssociation, 95,428–431.\nPearl, J. (2001): “Direct and indirect effects,” in Proceedings of the Seventeenth ConferenceonUncertaintyinArtificialIntelligence,SanFrancisco,CA:Morgan Kaufmann,411–420.\nPearl, J. (2004): “Robustness of causal claims,” in M. Chickering and J. Halpern, eds., Proceedings of the Twentieth Conference Uncertainty in Artificial Intelli- gence,Arlington,VA:AUAI Press, 446–453.\nPearl, J. (2009a): “Causal inference in statistics: An overview,” Statistics Surveys, 3, 96–146,http://www.i-journals.org/ss/viewarticle.php?id=57.\nPearl, J. (2009b): Causality: Models, Reasoning, and Inference, New York: Cam- bridgeUniversityPress, second edition.\nPearl, J. (2009c): “Letter to the editor: Remarks on the method of propensity scores,” Statistics in Medicine, 28, 1415–1416, &lt;http://ftp.cs.ucla.edu/pub/stat ser/r345-sim.pdf&gt;.\nPearl, J. (2009d): “Myth, confusion, and science in causal analysis,” Technical Report R-348, Department of Computer Science, University of California, Los Angeles, CA, &lt;http://ftp.cs.ucla.edu/pub/stat ser/r348.pdf&gt;.\nPearl,J. (2009e): “Onaclass ofbias-amplifyingcovariatesthatendangereffectes- timates,” Technical Report R-346, Department of Computer Science, University ofCalifornia,Los Angeles, CA, &lt;http://ftp.cs.ucla.edu/pub/stat ser/r346.pdf&gt;.\nPearl, J. (2009f): “On measurement bias in causal inference,” Technical Report R-357, &lt;http://ftp.cs.ucla.edu/pub/stat ser/r357.pdf&gt;, Department of Computer Science, UniversityofCalifornia,Los Angeles.\nPearl, J. and A. Paz (2009): “Confounding equivalence in observational studies,” Technical Report R-343, Department of Computer Science, University of Cali- fornia,Los Angeles, CA,&lt;http://ftp.cs.ucla.edu/pub/stat ser/r343.pdf&gt;.\nPearl, J. and J. Robins (1995): “Probabilistic evaluation of sequential plans from causal models with hidden variables,” in P. Besnard and S. Hanks, eds., Uncer- taintyinArtificialIntelligence11,San Francisco: MorganKaufmann, 444–453.\nPearl,J.andT.Verma(1991):“Atheoryofinferredcausation,”inJ.Allen,R.Fikes, andE. Sandewall,eds., Principles ofKnowledgeRepresentationandReasoning: Proceedings of the Second International Conference, San Mateo, CA: Morgan Kaufmann,441–452.\nPetersen, M., S. Sinisi, and M. van der Laan (2006): “Estimation of direct causal effects,”Epidemiology,17, 276–284.\nRichard, J. (1980): “Models with several regimes and changes in exogeneity,” Re- view ofEconomic Studies,47, 1–20.\nRobertson,D.(1997): “Thecommonsenseofcauseinfact,”TexasLawReview, 75, 1765–1800.\nRobins, J. (1986): “A new approach to causal inference in mortality studies with a sustained exposure period– applications to controlof thehealthy workerssur- vivoreffect,”MathematicalModeling, 7, 1393–1512.\nRobins, J. (1987): “A graphical approach to the identification and estimation of causal parametersinmortalitystudies withsustained exposure periods,”Journal ofChronicDiseases, 40, 139S–161S.\nRobins, J. (1989): “The analysis of randomized and non-randomized aids treat- ment trials using a new approach to causal inference in longitudinal studies,” in L. Sechrest, H. Freeman, and A. Mulley, eds., Health Service Research Method- ology: A Focus on AIDS, Washington, D.C.: NCHSR, U.S. Public Health Ser- vice, 113–159.\nRobins, J. (1999): “Testing and estimation of directed effects by reparameterizing directed acyclic with structural nested models,” in C. Glymour and G. Cooper, eds., Computation, Causation, and Discovery, Cambridge, MA: AAAI/MIT Press, 349–405.\nRobins, J. (2001): “Data, design, and background knowledge in etiologic infer- ence,” Epidemiology,12,313–320.\nRobins, J. and S. Greenland (1989a): “Estimability and estimation of excess and etiologicfractions,”Statistics inMedicine, 8, 845–859.\nRobins,J.andS.Greenland(1989b): “Theprobabilityofcausationunderastochas- ticmodelforindividualrisk,”Biometrics, 45, 1125–1138.\nRobins, J. and S. Greenland (1992): “Identifiabilityand exchangeability for direct andindirecteffects,”Epidemiology,3, 143–155.\nRosenbaum, P. (2002): Observational Studies, New York: Springer-Verlag,second edition.\nRosenbaum, P. and D. Rubin (1983): “The central role of propensity score in ob- servationalstudiesforcausal effects,”Biometrika, 70, 41–55.\nRothman, K.(1976): “Causes,” American Journal ofEpidemiology,104, 587–592.\nRubin, D. (1974): “Estimatingcausal effectsoftreatmentsin randomizedand non- randomizedstudies,” Journalof EducationalPsychology, 66, 688–701.\nRubin,D.(2004): “Directandindirectcausaleffectsviapotentialoutcomes,”Scan- dinavianJournalofStatistics, 31, 161–170.\nRubin, D. (2005): “Causal inference using potential outcomes: Design, modeling, decisions,” JournaloftheAmerican StatisticalAssociation, 100,322–331.\nRubin, D. (2007): “The design versus the analysis of observational studies for causal effects: Parallels with the design of randomized trials,” Statistics in Medicine, 26, 20–36.\nRubin, D. (2009): “Author’sreply: Shouldobservationalstudies be designed toal- lowlack ofbalance incovariatedistributionsacross treatmentgroup?” Statistics inMedicine, 28, 1420–1423.\nShpitser, I. and J. Pearl (2006): “Identification of conditional interventional dis- tributions,” in R. Dechter and T. Richardson, eds., Proceedings of the Twenty- Second Conference on Uncertainty in Artificial Intelligence, Corvallis, OR: AUAIPress, 437–444.\nShpitser, I. and J. Pearl (2008): “Dormant independence,” in Proceedings of the Twenty-Third Conference on Artificial Intelligence, Menlo Park, CA: AAAI Press, 1081–1087.\nShpitser, I. and J. Pearl (2009): “Effects of treatment on the treated: Identification and generalization,” in Proceedings of the Twenty-Fifth Conference on Uncer- taintyinArtificialIntelligence,Montreal, Quebec: AUAIPress.\nShrier, I. (2009): “Letter to the editor: Propensity scores,” Statistics in Medicine, 28, 1317–1318, see also Pearl 2009 &lt;http://ftp.cs.ucla.edu/pub/stat ser/r348.pdf&gt;.\nShrout, P. and N. Bolger (2002): “Mediation in experimental and nonexperimen- tal studies: New procedures and recommendations,” Psychological Methods, 7, 422–445.\nSimon,H.(1953): “Causalorderingandidentifiability,”inW.C.HoodandT.Koop- mans,eds.,StudiesinEconometricMethod,NewYork,NY:WileyandSons,Inc., 49–74.\nSimon, H. and N. Rescher (1966): “Cause and counterfactual,” Philosophy and Science, 33, 323–340.\nSobel, M. (1998): “Causal inference in statistical models of the process of socioe- conomicachievement,”SociologicalMethods &Research, 27, 318–348.\nSobel, M. (2008): “Identification of causal parameters in randomized studies with mediatingvariables,”JournalofEducationalandBehavioral Statistics,33,230– 231.\nSpirtes,P.,C.Glymour,andR.Scheines(1993): Causation,Prediction,andSearch, NewYork: Springer-Verlag.\nSpirtes,P.,C.Glymour,andR.Scheines(2000): Causation,Prediction,andSearch, Cambridge,MA: MITPress, 2nd edition.\nStock,J.andM.Watson(2003): IntroductiontoEconometrics, NewYork: Addison Wesley.\nStrotz,R.andH.Wold(1960): “Recursiveversusnonrecursivesystems: Anattempt atsynthesis,” Econometrica, 28,417–427.\nSuppes,P.(1970): AProbabilisticTheoryofCausality,Amsterdam: North-Holland PublishingCo.\nTian, J., A. Paz, and J. Pearl (1998): “Finding minimalseparating sets,” Technical ReportR-254,UniversityofCalifornia,Los Angeles, CA.\nTian,J.andJ.Pearl(2000): “Probabilitiesofcausation: Boundsandidentification,” Annals ofMathematics andArtificialIntelligence,28, 287–313.\nTian, J. and J. Pearl (2002): “A general identificationcondition forcausal effects,” in Proceedings of the Eighteenth National Conference on Artificial Intelligence, MenloPark, CA:AAAIPress/The MIT Press, 567–573.\nVanderWeele, T. (2009): “Marginal structural models for the estimation of direct andindirecteffects,”Epidemiology,20, 18–26.\nVanderWeele, T. and J. Robins (2007): “Four types of effect modification: A clas- sificationbased ondirectedacyclic graphs,”Epidemiology,18, 561–568.\nVerma, T. and J. Pearl (1990): “Equivalence and synthesis of causal models,” in Proceedings of the Sixth Conference on Uncertainty in Artificial Intelligence, Cambridge,MA,220–227,alsoinP.Bonissone,M.Henrion,L.N.KanalandJ.F.\nLemmer(Eds.),UncertaintyinArtificialIntelligence6,ElsevierSciencePublish- ers, B.V., 255–268, 1991.\nWermuth,N. (1992): “On block-recursiveregression equations,”Brazilian Journal ofProbabilityandStatistics (withdiscussion), 6, 1–56.\nWermuth, N. and D. Cox (1993): “Linear dependencies represented by chain graphs,”StatisticalScience, 8, 204–218.\nWhittaker, J. (1990): Graphical Models in Applied Multivariate Statistics, Chich- ester, England: John Wiley.\nWilkinson, L., the Task Force on Statistical Inference, and APA Board of Scien- tific Affairs (1999): “Statistical methods in psychology journals: Guidelines and explanations,”American Psychologist, 54,594–604.\nWoodward, J. (2003): Making Things Happen, New York, NY: Oxford University Press.\nWooldridge, J. (2002): Econometric Analysis of Cross Section and Panel Data, CambridgeandLondon: MIT Press.\nWooldridge, J. (2009): “Should instrumental variables be used as matching variables?” Technical Report https://www.msu.edu/∼ec/faculty/wooldridge/current%20research/treat1r6.pdf, MichiganStateUniversity,MI.\nWright, S. (1921): “Correlation and causation,” Journal of Agricultural Research, 20,557–585.",
    "crumbs": [
      "Causal Inference",
      "An Introduction to Causal Inference"
    ]
  },
  {
    "objectID": "extracted/Causal inference in statistics An overview2.html",
    "href": "extracted/Causal inference in statistics An overview2.html",
    "title": "Causal inference in statistics",
    "section": "",
    "text": "Statistics Surveys Vol. 3 (2009) 96–146 ISSN: 1935-7516 DOI:10.1214/09-SS057\nCausal inference in statistics: An overview∗†‡\nJudea Pearl\nComputer Science Department University of California, Los Angeles, CA 90095 USA e-mail:judea@cs.ucla.edu",
    "crumbs": [
      "Causal Inference",
      "Causal inference in statistics"
    ]
  },
  {
    "objectID": "extracted/Causal inference in statistics An overview2.html#abstract",
    "href": "extracted/Causal inference in statistics An overview2.html#abstract",
    "title": "Causal inference in statistics",
    "section": "Abstract",
    "text": "Abstract\nThis review presents empirical researcherswith recent adv ances in causal inference, and stresses the paradigmatic shifts t hat must be un- dertaken in moving from traditional statistical analysis t o causal analysis of multivariate data. Special emphasis is placed on the assump tions that un- derly all causal inferences, the languages used in formulat ing those assump- tions, the conditional nature of all causal and counterfact ual claims, and the methods that have been developed for the assessment of su ch claims. These advances are illustrated using a general theory of cau sation based on the Structural Causal Model (SCM) described in Pearl (2000a), which subsumes and uniﬁes other approaches to causation, and prov ides a coher- ent mathematical foundation for the analysis of causes and c ounterfactuals. In particular, the paper surveys the development of mathema tical tools for inferring (from a combination of data and assumptions) answ ers to three types of causal queries: (1) queries about the eﬀects of pote ntial interven- tions, (also called “causal eﬀects” or “policy evaluation” ) (2) queries about probabilities of counterfactuals, (including assessment of “regret,” “attri- bution” or “causes of eﬀects”) and (3) queries about direct a nd indirect eﬀects (also known as “mediation”). Finally, the paper deﬁn es the formal and conceptual relationships between the structural and po tential-outcome frameworks and presents tools for a symbiotic analysis that uses the strong features of both.\nKeywords and phrases: Structuralequation models, confounding,graph- ical methods, counterfactuals, causal eﬀects, potential- outcome, mediation, policy evaluation, causes of eﬀects.\nReceived September 2009.",
    "crumbs": [
      "Causal Inference",
      "Causal inference in statistics"
    ]
  },
  {
    "objectID": "extracted/Causal inference in statistics An overview2.html#contents",
    "href": "extracted/Causal inference in statistics An overview2.html#contents",
    "title": "Causal inference in statistics",
    "section": "Contents",
    "text": "Contents\n1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97 2 From association to causation . . . . . . . . . . . . . . . . . . . . . . 99 2.1 The basic distinction: Coping with change . . . . . . . . . . . . .99 2.2 Formulating the basic distinction . . . . . . . . . . . . . . . . . . 99 2.3 Ramiﬁcations of the basic distinction . . . . . . . . . . . . . . . .100 2.4 Two mental barriers: Untested assumptions and new notat ion . 101 ∗Portions of this paper are based on my book Causality (Pearl, 2000, 2nd edition 2009), and have beneﬁted appreciably from conversations with read ers, students, and colleagues. †This research was supported in parts by an ONR grant #N000-14 -09-1-0665. ‡This paper was accepted by Elja Arjas, Executive Editor for t he Bernoulli.\n3 Structural models, diagrams, causal eﬀects, and counterf actuals . . . . 102 3.1 Introduction to structural equation models . . . . . . . . . . . .103 3.2 From linear to nonparametric models and graphs . . . . . . . . .107 3.2.1 Representing interventions . . . . . . . . . . . . . . . . . . 107 3.2.2 Estimating the eﬀect of interventions . . . . . . . . . . . . 109 3.2.3 Causal eﬀects from data and graphs . . . . . . . . . . . . 110 3.3 Coping with unmeasured confounders . . . . . . . . . . . . . . . 113 3.3.1 Covariate selection – the back-door criterion . . . . . . . .113 3.3.2 General control of confounding . . . . . . . . . . . . . . . 116 3.3.3 From identiﬁcation to estimation . . . . . . . . . . . . . . 117 3.3.4 Bayesianism and causality, or where do the probabilit ies come from? . . . . . . . . . . . . . . . . . . . . . . . . . . 117 3.4 Counterfactual analysis in structural models . . . . . . . . . . . . 119 3.5 An example: Non-compliance in clinical trials . . . . . . . . . . .122 3.5.1 Deﬁning the target quantity . . . . . . . . . . . . . . . . . 122 3.5.2 Formulating the assumptions – Instrumental variable s . . 122 3.5.3 Bounding causal eﬀects . . . . . . . . . . . . . . . . . . . 124 3.5.4 Testable implications of instrumental variables . . . . . .125 4 The potential outcome framework . . . . . . . . . . . . . . . . . . . . 126 4.1 The “Black-Box” missing-data paradigm . . . . . . . . . . . . . . 127 4.2 Problem formulation and the demystiﬁcation of “ignorab ility” . . 128 4.3 Combining graphs and potential outcomes . . . . . . . . . . . . 131 5 Counterfactuals at work . . . . . . . . . . . . . . . . . . . . . . . . . . 132 5.1 Mediation: Direct and indirect eﬀects . . . . . . . . . . . . . . . .132 5.1.1 Direct versus total eﬀects: . . . . . . . . . . . . . . . . . 132 5.1.2 Natural direct eﬀects . . . . . . . . . . . . . . . . . . . . . 134 5.1.3 Indirect eﬀects and the Mediation Formula . . . . . . . . 135 5.2 Causes of eﬀects and probabilities of causation . . . . . . . . . .136 6 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139 References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139",
    "crumbs": [
      "Causal Inference",
      "Causal inference in statistics"
    ]
  },
  {
    "objectID": "extracted/Causal inference in statistics An overview2.html#introduction",
    "href": "extracted/Causal inference in statistics An overview2.html#introduction",
    "title": "Causal inference in statistics",
    "section": "1. Introduction",
    "text": "1. Introduction\nThe questions that motivate most studies in the health, soci al and behavioral sciences are not associational but causal in nature. For exa mple, what is the eﬃcacy of a given drug in a given population? Whether data can prove an employer guilty of hiring discrimination? What fraction of past crimes could have been avoided by a given policy? What was the cause of deat h of a given individual, in a speciﬁc incident? These are causal questions because they require some knowledge of the data-generating process; they cannot be computed from the data alone, nor from the distributions that govern the da ta. Remarkably, although much of the conceptual framework and a lgorithmic tools needed for tackling such problems are now well establi shed, they are hardly known to researchers who could put them into practical use. T he main reason is educational. Solving causal problems systematically requ ires certain extensions in the standard mathematical language of statistics, and th ese extensions are not generally emphasized in the mainstream literature and educ ation. As a result, large segments of the statistical research community ﬁnd it hard to appreciate and beneﬁt from the many results that causal analysis has pro duced in the past two decades. These results rest on contemporary advances in four areas:\n\nCounterfactual analysis\nNonparametric structural equations\nGraphical models\nSymbiosis between counterfactual and graphical methods .\n\nThis survey aims at making these advances more accessible to the general re- search community by, ﬁrst, contrasting causal analysis wit h standard statistical analysis, second, presenting a unifying theory, called “st ructural,” within which most (if not all) aspects of causation can be formulated, ana lyzed and compared, thirdly, presenting a set of simple yet eﬀective tools, spaw ned by the structural theory, for solving a wide variety of causal problems and, ﬁn ally, demonstrating how former approaches to causal analysis emerge as special c ases of the general structural theory. To this end, Section 2begins by illuminating two conceptual barriers that im- pede the transition from statistical to causal analysis: (i ) coping with untested assumptions and (ii) acquiring new mathematical notation. Crossing these bar- riers, Section 3.1then introduces the fundamentals of the structural theory of causation, with emphasis on the formal representation of causal assump- tions, and formal deﬁnitions of causal eﬀects, counterfact uals and joint prob- abilities of counterfactuals. Section 3.2uses these modeling fundamentals to represent interventions and develop mathematical tools fo r estimating causal eﬀects (Section 3.3) and counterfactual quantities (Section 3.4). These tools are demonstrated by attending to the analysis of instrumental v ariables and their role in bounding treatment eﬀects in experiments marred by n oncompliance (Section 3.5). The tools described in this section permit investigators to communicate causal assumptions formally using diagrams, then inspect the diag ram and\n\nDecide whether the assumptions made are suﬃcient for obta ining consis- tent estimates of the target quantity;\nDerive (if the answer to item 1is aﬃrmative) a closed-form expression for the target quantity in terms of distributions of observed qu antities; and\nSuggest (if the answer to item 1 is negative) a set of observ ations and ex- periments that, if performed, would render a consistent est imate feasible.\n\nSection 4relates these tools to those used in the potential-outcome f rame- work, and oﬀers a formal mapping between the two frameworks a nd a symbiosis (Section 4.3) that exploits the best features of both. Finally, the beneﬁ t of this symbiosis is demonstrated in Section 5, in which the structure-based logic of counterfactuals is harnessed to estimate causal quantitie s that cannot be de- ﬁned within the paradigm of controlled randomized experime nts. These include direct and indirect eﬀects, the eﬀect of treatment on the tre ated, and ques- tions of attribution, i.e., whether one event can be deemed “ responsible” for another.",
    "crumbs": [
      "Causal Inference",
      "Causal inference in statistics"
    ]
  },
  {
    "objectID": "extracted/Causal inference in statistics An overview2.html#from-association-to-causation",
    "href": "extracted/Causal inference in statistics An overview2.html#from-association-to-causation",
    "title": "Causal inference in statistics",
    "section": "2. From association to causation",
    "text": "2. From association to causation\n\n2.1. The basic distinction: Coping with change\nThe aim of standard statistical analysis, typiﬁed by regres sion, estimation, and hypothesis testing techniques, is to assess parameters of a distribution from samples drawn of that distribution. With the help of such par ameters, one can infer associations among variables, estimate beliefs or pr obabilities of past and future events, as well as update those probabilities in ligh t of new evidence or new measurements. These tasks are managed well by standar d statistical analysis so long as experimental conditions remain the same . Causal analysis goes one step further; its aim is to infer not only beliefs or p robabilities under static conditions, but also the dynamics of beliefs under changing conditions , for example, changes induced by treatments or external inte rventions. This distinction implies that causal and associational con cepts do not mix. There is nothing in the joint distribution of symptoms and di seases to tell us that curing the former would or would not cure the latter. Mor e generally, there is nothing in a distribution function to tell us how that dist ribution would diﬀer if external conditions were to change—say from observation al to experimental setup—because the laws of probability theory do not dictate how one property of a distribution ought to change when another property is mo diﬁed. This in- formation must be provided by causal assumptions which iden tify relationships that remain invariant when external conditions change. These considerations imply that the slogan “correlation do es not imply cau- sation” can be translated into a useful principle: one canno t substantiate causal claims from associations alone, even at the population leve l—behind every causal conclusion there must lie some causal assumption tha t is not testable in observational studies.1\n\n\n2.2. Formulating the basic distinction\nA useful demarcation line that makes the distinction betwee n associational and causal concepts crisp and easy to apply, can be formulated as follows. An as- sociational concept is any relationship that can be deﬁned i n terms of a joint distribution of observed variables, and a causal concept is any relationship that cannot be deﬁned from the distribution alone. Examples of as sociational con- cepts are: correlation, regression, dependence, conditio nal independence, like- lihood, collapsibility, propensity score, risk ratio, odd s ratio, marginalization, 1The methodology of “causal discovery” ( Spirtes et al. 2000 ;Pearl 2000a , Chapter 2) is likewise based on the causal assumption of “faithfulness”o r “stability,”a problem-independent assumption that concerns relationships between the struct ure of a model and the data it generates. conditionalization, “controlling for,” and so on. Example s of causal concepts are: randomization, inﬂuence, eﬀect, confounding, “holding co nstant,” disturbance, spurious correlation, faithfulness/stability, instrume ntal variables, intervention, explanation, attribution, and so on. The former can, while t he latter cannot be deﬁned in term of distribution functions. This demarcation line is extremely useful in causal analysi s for it helps in- vestigators to trace the assumptions that are needed for sub stantiating various types of scientiﬁc claims. Every claim invoking causal conc epts must rely on some premises that invoke such concepts; it cannot be inferr ed from, or even deﬁned in terms statistical associations alone.\n\n\n2.3. Ramiﬁcations of the basic distinction\nThis principle has far reaching consequences that are not ge nerally recognized in the standard statistical literature. Many researchers, for example, are still convinced that confounding is solidly founded in standard, frequentist statis- tics, and that it can be given an associational deﬁnition say ing (roughly): “ Uis a potential confounder for examining the eﬀect of treatment Xon outcome Y when both UandXandUandYare not independent.” That this deﬁnition and all its many variants must fail ( Pearl,2000a , Section 6.2)2is obvious from the demarcation line above; if confounding were deﬁnable in terms of statistical associations, we would have been able to identify confounde rs from features of nonexperimental data, adjust for those confounders and obt ain unbiased esti- mates of causal eﬀects. This would have violated our golden r ule: behind any causal conclusion there must be some causal assumption, unt ested in obser- vational studies. Hence the deﬁnition must be false. Theref ore, to the bitter disappointment of generations of epidemiologist and socia l science researchers, confounding bias cannot be detected or corrected by statist ical methods alone; one must make some judgmental assumptions regarding causal relationships in the problem before an adjustment (e.g., by stratiﬁcation) c an safely correct for confounding bias. Another ramiﬁcation of the sharp distinction between assoc iational and causal concepts is that any mathematical approach to causal analys is must acquire new notation for expressing causal relations – probability cal culus is insuﬃcient. To illustrate, the syntax of probability calculus does not per mit us to express the simple fact that “symptoms do not cause diseases,” let alone draw mathematical conclusions from such facts. All we can say is that two events are dependent— meaning that if we ﬁnd one, we can expect to encounter the othe r, but we can- not distinguish statistical dependence, quantiﬁed by the c onditional probability P(disease|symptom ) from causal dependence, for which we have no expression in standard probability calculus. Scientists seeking to ex press causal relation- ships must therefore supplement the language of probabilit y with a vocabulary 2For example, any intermediate variable Uon a causal path from XtoYsatisﬁes this deﬁnition, without confounding the eﬀect of XonY. for causality, one in which the symbolic representation for the relation “symp- toms cause disease” is distinct from the symbolic represent ation of “symptoms are associated with disease.”\n\n\n2.4. Two mental barriers: Untested assumptions and new nota tion\nThe preceding two requirements: (1) to commence causal anal ysis with untested,3 theoretically or judgmentally based assumptions, and (2) t o extend the syntax of probability calculus, constitute the two main obstacles to the acceptance of causal analysis among statisticians and among professiona ls with traditional training in statistics. Associational assumptions, even untested, are testable in principle, given suf- ﬁciently large sample and suﬃciently ﬁne measurements. Cau sal assumptions, in contrast, cannot be veriﬁed even in principle, unless one re sorts to experimental control. This diﬀerence stands out in Bayesian analysis. Th ough the priors that Bayesians commonly assign to statistical parameters are un tested quantities, the sensitivity to these priors tends to diminish with incre asing sample size. In contrast, sensitivity to prior causal assumptions, say tha t treatment does not change gender, remains substantial regardless of sample si ze. This makes it doubly important that the notation we use for ex pressing causal assumptions be meaningful and unambiguous so that one can cl early judge the plausibility or inevitability of the assumptions articula ted. Statisticians can no longer ignore the mental representation in which scientist s store experiential knowledge, since it is this representation, and the languag e used to access it that determine the reliability of the judgments upon which the an alysis so crucially depends. How does one recognize causal expressions in the statistica l literature? Those versed in the potential-outcome notation ( Neyman ,1923;Rubin ,1974;Holland , 1988), can recognize such expressions through the subscripts th at are attached to counterfactual events and variables, e.g. Yx(u) orZxy. (Some authors use parenthetical expressions, e.g. Y(0),Y(1),Y(x, u) orZ(x, y).) The expression Yx(u), for example, stands for the value that outcome Ywould take in indi- vidual u, had treatment Xbeen at level x. Ifuis chosen at random, Yxis a random variable, and one can talk about the probability that Yxwould attain a value yin the population, written P(Yx=y) (see Section 4for semantics). Alternatively, Pearl (1995a ) used expressions of the form P(Y=y|set(X=x)) orP(Y=y|do(X=x)) to denote the probability (or frequency) that event (Y=y) would occur if treatment condition X=xwere enforced uniformly over the population.4Still a third notation that distinguishes causal expressio ns is provided by graphical models, where the arrows convey cau sal directionality.5 3By “untested” I mean untested using frequency data in nonexp erimental studies. 4Clearly, P(Y=y|do(X=x)) is equivalent to P(Yx=y). This is what we normally assess in a controlled experiment, with Xrandomized, in which the distribution of Yis estimated for each level xofX. 5These notational clues should be useful for detecting inade quate deﬁnitions of causal concepts; any deﬁnition of confounding,randomization or i nstrumental variables that is cast in However, few have taken seriously the textbook requirement that any intro- duction of new notation must entail a systematic deﬁnition o f the syntax and semantics that governs the notation. Moreover, in the bulk o f the statistical liter- ature before 2000, causal claims rarely appear in the mathem atics. They surface only in the verbal interpretation that investigators occas ionally attach to cer- tain associations, and in the verbal description with which investigators justify assumptions. For example, the assumption that a covariate n ot be aﬀected by a treatment, a necessary assumption for the control of confo unding ( Cox,1958, p. 48), is expressed in plain English, not in a mathematical e xpression. Remarkably, though the necessity of explicit causal notati on is now recognized by many academic scholars, the use of such notation has remai ned enigmatic to most rank and ﬁle researchers, and its potentials still la y grossly underuti- lized in the statistics based sciences. The reason for this, can be traced to the unfriendly semi-formal way in which causal analysis has bee n presented to the research community, resting primarily on the restricted pa radigm of controlled randomized trials. The next section provides a conceptualization that overcom es these mental barriers by oﬀering a friendly mathematical machinery for c ause-eﬀect analysis and a formal foundation for counterfactual analysis.",
    "crumbs": [
      "Causal Inference",
      "Causal inference in statistics"
    ]
  },
  {
    "objectID": "extracted/Causal inference in statistics An overview2.html#structural-models-diagrams-causal-eﬀects-and-counter-factuals",
    "href": "extracted/Causal inference in statistics An overview2.html#structural-models-diagrams-causal-eﬀects-and-counter-factuals",
    "title": "Causal inference in statistics",
    "section": "3. Structural models, diagrams, causal eﬀects, and counter factuals",
    "text": "3. Structural models, diagrams, causal eﬀects, and counter factuals\nAny conception of causation worthy of the title “theory” mus t be able to (1) represent causal questions in some mathematical language, (2) provide a precise language for communicating assumptions under which the que stions need to be answered, (3) provide a systematic way of answering at lea st some of these questions and labeling others “unanswerable,” and (4) prov ide a method of determining what assumptions or new measurements would be n eeded to answer the “unanswerable” questions. A “general theory” should do more. In addition to embracing allquestions judged to have causal character, a general theory must also subsume any other theory or method that scientists have found useful in explor ing the various aspects of causation. In other words, any alternative theor y needs to evolve as a special case of the “general theory” when restrictions are imposed on either the model, the type of assumptions admitted, or the language in which those assumptions are cast. The structural theory that we use in this survey satisﬁes the criteria above. It is based on the Structural Causal Model (SCM) developed in (Pearl,1995a , 2000a ) which combines features of the structural equation models (SEM) used in economics and social science ( Goldberger ,1973;Duncan ,1975), the potential- outcome framework of Neyman (1923) and Rubin (1974), and the graphical models developed for probabilistic reasoning and causal an alysis ( Pearl,1988; Lauritzen ,1996;Spirtes et al. ,2000;Pearl,2000a ). standard probability expressions, void of graphs, counter factual subscripts or do(∗) operators, can safely be discarded as inadequate. Although the basic elements of SCM were introduced in the mid 1990’s ( Pearl, 1995a ), and have been adapted widely by epidemiologists ( Greenland et al. , 1999;Glymour and Greenland ,2008), statisticians ( Cox and Wermuth ,2004; Lauritzen ,2001), and social scientists ( Morgan and Winship ,2007), its poten- tials as a comprehensive theory of causation are yet to be ful ly utilized. Its ramiﬁcations thus far include:\n\nThe uniﬁcation of the graphical, potential outcome, stru ctural equations, decision analytical ( Dawid ,2002), interventional ( Woodward ,2003), suf- ﬁcient component ( Rothman ,1976) and probabilistic ( Suppes ,1970) ap- proaches to causation; with each approach viewed as a restri cted version of the SCM.\nThe deﬁnition, axiomatization and algorithmization of c ounterfactuals and joint probabilities of counterfactuals\nReducing the evaluation of “eﬀects of causes,” “mediated eﬀects,” and “causes of eﬀects” to an algorithmic level of analysis.\nSolidifying the mathematical foundations of the potenti al-outcome model, and formulating the counterfactual foundations of structu ral equation models.\nDemystifying enigmatic notions such as “confounding,” “ mediation,” “ig- norability,” “comparability,”“exchangeability (of popu lations),” “superex- ogeneity” and others within a single and familiar conceptua l framework.\nWeeding out myths and misconceptions from outdated tradi tions (Meek and Glymour ,1994;Greenland et al. ,1999;Cole and Hern´ an ,2002; Arah,2008;Shrier ,2009;Pearl,2009b ). This section provides a gentle introduction to the structur al framework and uses it to present the main advances in causal inference that have emerged in the past two decades.\n\n\n3.1. Introduction to structural equation models\nHow can one express mathematically the common understandin g that symp- toms do not cause diseases? The earliest attempt to formulat e such relationship mathematically was made in the 1920’s by the geneticist Sewa ll Wright ( 1921). Wright used a combination of equations and graphs to communi cate causal re- lationships. For example, if Xstands for a disease variable and Ystands for a certain symptom of the disease, Wright would write a linear e quation:6 y=βx+uY (1) where xstands for the level (or severity) of the disease, ystands for the level (or severity) of the symptom, and uYstands for all factors, other than the disease in question, that could possibly aﬀect Ywhen Xis held constant. In interpreting 6Linear relations are used here for illustration purposes on ly; they do not represent typical disease-symptom relations but illustrate the historical d evelopment of path analysis. Addi- tionally, we will use standardized variables, that is, zero mean and unit variance. this equation one should think of a physical process whereby Nature examines the values of xanduand, accordingly, assigns variable Ythe value y=βx+uY. Similarly, to “explain” the occurrence of disease X, one could write x=uX, where UXstands for all factors aﬀecting X. Equation ( 1) still does not properly express the causal relationship im plied by this assignment process, because algebraic equations are s ymmetrical objects; if we re-write ( 1) as x= (y−uY)/β (2) it might be misinterpreted to mean that the symptom inﬂuence s the disease. To express the directionality of the underlying process, Wr ight augmented the equation with a diagram, later called “path diagram,” in whi ch arrows are drawn from (perceived) causes to their (perceived) eﬀects, and mo re importantly, the absence of an arrow makes the empirical claim that Nature ass igns values to one variable irrespective of another. In Fig. 1, for example, the absence of arrow fromYtoXrepresents the claim that symptom Yis not among the factors UX which aﬀect disease X. Thus, in our example, the complete model of a symptom and a disease would be written as in Fig. 1: The diagram encodes the possible existence of (direct) causal inﬂuence of XonY, and the absence of causal inﬂuence of YonX, while the equations encode the quantitative relationship s among the variables involved, to be determined from the data . The parameter β in the equation is called a “path coeﬃcient” and it quantiﬁes the (direct) causal eﬀect of XonY; given the numerical values of βandUY, the equation claims that, a unit increase for Xwould result in βunits increase of Yregardless of the values taken by other variables in the model, and regardl ess of whether the increase in Xoriginates from external or internal inﬂuences. The variables UXandUYare called “exogenous;” they represent observed or unobserved background factors that the modeler decides to k eep unexplained, that is, factors that inﬂuence but are not inﬂuenced by the ot her variables (called “endogenous”) in the model. Unobserved exogenous v ariables are some- times called “disturbances” or “errors”, they represent fa ctors omitted from the model but judged to be relevant for explaining the behavior o f variables in the model. Variable UX, for example, represents factors that contribute to the dis - easeX, which may or may not be correlated with UY(the factors that inﬂuence the symptom Y). Thus, background factors in structural equations diﬀer f unda- mentally from residual terms in regression equations. The l atters are artifacts of analysis which, by deﬁnition, are uncorrelated with the r egressors. The form- ers are part of physical reality (e.g., genetic factors, soc io-economic conditions) which are responsible for variations observed in the data; t hey are treated as any other variable, though we often cannot measure their val ues precisely and must resign to merely acknowledging their existence and ass essing qualitatively how they relate to other variables in the system. If correlation is presumed possible, it is customary to conn ect the two vari- ables, UYandUX, by a dashed double arrow, as shown in Fig. 1(b). In reading path diagrams, it is common to use kinship relatio ns such as parent, child, ancestor, and descendent, the interpretati on of which is usually X Y X Y YX β X Y β X YU U U U x = u βy = x + u (b) (a) Fig 1. A simple structural equation model, and its associated dia grams. Unobserved exogenous variables are connected by dashed arrows. self evident. For example, an arrow X→Ydesignates Xas a parent of YandY as a child of X. A “path” is any consecutive sequence of edges, solid or dash ed. For example, there are two paths between XandYin Fig. 1(b), one consisting of the direct arrow X→Ywhile the other tracing the nodes X, U X, UYandY. Wright’s major contribution to causal analysis, aside from introducing the language of path diagrams, has been the development of graph ical rules for writing down the covariance of any pair of observed variable s in terms of path coeﬃcients and of covariances among the error terms. In our s imple example, one can immediately write the relations Cov(X, Y) =β (3) for Fig. 1(a), and Cov(X, Y) =β+Cov(UY, UX) (4) for Fig. 1(b) (These can be derived of course from the equations, but, f or large models, algebraic methods tend to obscure the origin of the d erived quantities). Under certain conditions, (e.g. if Cov(UY, UX) = 0), such relationships may allow one to solve for the path coeﬃcients in term of observed covariance terms only, and this amounts to inferring the magnitude of (direct ) causal eﬀects from observed, nonexperimental associations, assuming of cour se that one is prepared to defend the causal assumptions encoded in the diagram. It is important to note that, in path diagrams, causal assump tions are en- coded not in the links but, rather, in the missing links. An ar row merely in- dicates the possibility of causal connection, the strength of which remains to be determined (from data); a missing arrow represents a clai m of zero inﬂu- ence, while a missing double arrow represents a claim of zero covariance. In Fig. 1(a), for example, the assumptions that permits us to identif y the direct ef- fectβare encoded by the missing double arrow between UXandUY, indicating Cov(UY, UX)=0, together with the missing arrow from YtoX. Had any of these two links been added to the diagram, we would not have been abl e to identify the direct eﬀect β. Such additions would amount to relaxing the assumption Cov(UY, UX) = 0, or the assumption that Ydoes not eﬀect X, respectively. Note also that both assumptions are causal, not association al, since none can be determined from the joint density of the observed variabl es,XandY; the association between the unobserved terms, UYandUX, can only be uncovered in an experimental setting; or (in more intricate models, as in Fig. 5) from other causal assumptions. Z X Y Z X YU U U Z X0x (b)YU U U (a)X Y Z Fig 2. (a) The diagram associated with the structural model of Eq. (5). (b) The diagram associated with the modiﬁed model of Eq. ( 6), representing the intervention do(X=x0). Although each causal assumption in isolation cannot be test ed, the sum to- tal of all causal assumptions in a model often has testable im plications. The chain model of Fig. 2(a), for example, encodes seven causal assumptions, each corresponding to a missing arrow or a missing double-arrow b etween a pair of variables. None of those assumptions is testable in isolati on, yet the totality of all those assumptions implies that Zis unassociated with Yin every stratum ofX. Such testable implications can be read oﬀ the diagrams usin g a graphical criterion known as d-separation (Pearl,1988). Deﬁnition 1 (d-separation) .A set Sof nodes is said to block a path pif either (i)pcontains at least one arrow-emitting node that is in S, or (ii) pcontains at least one collision node that is outside Sand has no descendant in S. IfS blocks allpaths from XtoY, it is said to “ d-separate XandY,” and then, X andYare independent given S, written X⊥ ⊥Y|S. To illustrate, the path UZ→Z→X→Yis blocked by S={Z}and by S={X}, since each emits an arrow along that path. Consequently we c an infer that the conditional independencies UX⊥ ⊥Y|ZandUZ⊥ ⊥Y|Xwill be satisﬁed in any probability function that this model can generate, re gardless of how we parametrize the arrows. Likewise, the path UZ→Z→X←UXis blocked by the null set{∅}but is not blocked by S={Y}, since Yis a descendant of the collider X. Consequently, the marginal independence UZ⊥ ⊥UXwill hold in the distribution, but UZ⊥ ⊥UX|Ymay or may not hold. This special handling of col- liders (e.g., Z→X←UX)) reﬂects a general phenomenon known as Berkson’s paradox (Berkson ,1946), whereby observations on a common consequence of two independent causes render those causes dependent. For e xample, the out- comes of two independent coins are rendered dependent by the testimony that at least one of them is a tail. The conditional independencies induced by d-separation constitute the main opening through which the assumptions embodied in structur al equation models can confront the scrutiny of nonexperimental data. In other words, almost all statistical tests capable of invalidating the model are ent ailed by those implica- tions.7 7Additional implications called “dormant independence” ( Shpitser and Pearl ,2008) may be deduced from some graphs with correlated errors.\n\n\n3.2. From linear to nonparametric models and graphs\nStructural equation modeling (SEM) has been the main vehicl e for eﬀect analysis in economics and the behavioral and social sciences ( Goldberger ,1972;Duncan , 1975;Bollen ,1989). However, the bulk of SEM methodology was developed for linear analysis and, until recently, no comparable methodo logy has been devised to extend its capabilities to models involving dichotomous variables or nonlinear dependencies. A central requirement for any such extension is to detach the notion of “eﬀect” from its algebraic representation as a coe ﬃcient in an equation, and redeﬁne “eﬀect” as a general capacity to transmit changes among variables. Such an extension, based on simulating hypothetical interv entions in the model, was proposed in ( Haavelmo ,1943;Strotz and Wold ,1960;Spirtes et al. ,1993; Pearl,1993a ,2000a ;Lindley ,2002) and has led to new ways of deﬁning and estimating causal eﬀects in nonlinear and nonparametric mo dels (that is, models in which the functional form of the equations is unknown). The central idea is to exploit the invariant characteristic s of structural equa- tions without committing to a speciﬁc functional form. For e xample, the non- parametric interpretation of the diagram of Fig. 2(a) corresponds to a set of three functions, each corresponding to one of the observed v ariables: z=fZ(uZ) x=fX(z, uX) (5) y=fY(x, uY) where UZ, UXandUYare assumed to be jointly independent but, otherwise, arbitrarily distributed. Each of these functions represen ts a causal process (or mechanism) that determines the value of the left variable (o utput) from those on the right variables (inputs). The absence of a variable fr om the right hand side of an equation encodes the assumption that Nature ignor es that variable in the process of determining the value of the output variabl e. For example, the absence of variable Zfrom the arguments of fYconveys the empirical claim that variations in Zwill leave Yunchanged, as long as variables UY, and X remain constant. A system of such functions are said to be structural if they are assumed to be autonomous, that is, each function is invar iant to possible changes in the form of the other functions ( Simon ,1953;Koopmans ,1953).\n\n3.2.1. Representing interventions\nThis feature of invariance permits us to use structural equa tions as a basis for modeling causal eﬀects and counterfactuals. This is done th rough a mathemat- ical operator called do(x) which simulates physical interventions by deleting certain functions from the model, replacing them by a consta ntX=x, while keeping the rest of the model unchanged. For example, to emul ate an interven- tiondo(x0) that holds Xconstant (at X=x0) in model Mof Fig. 2(a), we replace the equation for xin Eq. ( 5) with x=x0, and obtain a new model, Mx0, z=fZ(uZ) x=x0 (6) y=fY(x, uY) the graphical description of which is shown in Fig. 2(b). The joint distribution associated with the modiﬁed model, d enoted P(z, y| do(x0)) describes the post-intervention distribution of variab lesYandZ(also called “controlled” or “experimental” distribution), to b e distinguished from the pre-intervention distribution, P(x, y, z ), associated with the original model of Eq. (5). For example, if Xrepresents a treatment variable, Ya response variable, andZsome covariate that aﬀects the amount of treatment received , then the distribution P(z, y|do(x0)) gives the proportion of individuals that would attain response level Y=yand covariate level Z=zunder the hypothetical situation in which treatment X=x0is administered uniformly to the population. In general, we can formally deﬁne the post-intervention dis tribution by the equation: PM(y|do(x))∆=PMx(y) (7) In words: In the framework of model M, the post-intervention distribution of outcome Yis deﬁned as the probability that model Mxassigns to each outcome levelY=y. From this distribution, one is able to assess treatment eﬃca cy by compar- ing aspects of this distribution at diﬀerent levels of x0. A common measure of treatment eﬃcacy is the average diﬀerence E(Y|do(x/prime 0))−E(Y|do(x0)) (8) where x/prime 0andx0are two levels (or types) of treatment selected for comparis on. Another measure is the experimental Risk Ratio E(Y|do(x/prime 0))/E(Y|do(x0)). (9) The variance V ar(Y|do(x0)), or any other distributional parameter, may also enter the comparison; all these measures can be obtained fro m the controlled dis- tribution function P(Y=y|do(x)) =/summationtext zP(z, y|do(x)) which was called “causal eﬀect” in Pearl (2000a ,1995a ) (see footnote 4). The central question in the analysis of causal eﬀects is the question of identiﬁcation : Can the controlled (post-intervention) distribution, P(Y=y|do(x)), be estimated from data gov- erned by the pre-intervention distribution, P(z, x, y )? The problem of identiﬁcation has received considerable attention in econo- metrics ( Hurwicz ,1950;Marschak ,1950;Koopmans ,1953) and social science (Duncan ,1975;Bollen ,1989), usually in linear parametric settings, were it re- duces to asking whether some model parameter, β, has a unique solution in terms of the parameters of P(the distribution of the observed variables). In the nonparametric formulation, identiﬁcation is more invo lved, since the notion of “has a unique solution” does not directly apply to causal q uantities such as Q(M) =P(y|do(x)) which have no distinct parametric signature, and are de- ﬁned procedurally by simulating an intervention in a causal model M(7). The following deﬁnition overcomes these diﬃculties: Deﬁnition 2 (Identiﬁability ( Pearl,2000a , p. 77)) .A quantity Q(M) is iden- tiﬁable, given a set of assumptions A, if for any two models M1andM2that satisfy A, we have P(M1) =P(M1)⇒Q(M1) =Q(M2) (10) In words, the details of M1andM2do not matter; what matters is that the assumptions in A(e.g., those encoded in the diagram) would constrain the variability of those details in such a way that equality o fP’s would entail equality of Q’s. When this happens, Qdepends on Ponly, and should therefore be expressible in terms of the parameters of P. The next subsections exemplify and operationalize this notion.\n\n\n3.2.2. Estimating the eﬀect of interventions\nTo understand how hypothetical quantities such as P(y|do(x)) orE(Y|do(x0)) can be estimated from actual data and a partially speciﬁed mo del let us be- gin with a simple demonstration on the model of Fig. 2(a). We will show that, despite our ignorance of fX, fY, fZandP(u),E(Y|do(x0)) is nevertheless iden- tiﬁable and is given by the conditional expectation E(Y|X=x0). We do this by deriving and comparing the expressions for these two quan tities, as deﬁned by (5) and ( 6), respectively. The mutilated model in Eq. ( 6) dictates: E(Y|do(x0)) =E(fY(x0, uY)), (11) whereas the pre-intervention model of Eq. ( 5) gives E(Y|X=x0)) = E(fY(X, u Y)|X=x0) =E(fY(x0, uY)|X=x0) (12) =E(fY(x0, uY)) which is identical to ( 11). Therefore, E(Y|do(x0)) =E(Y|X=x0)) (13) Using a similar derivation, though somewhat more involved, we can show that P(y|do(x)) is identiﬁable and given by the conditional probability P(y|x). We see that the derivation of ( 13) was enabled by two assumptions; ﬁrst, Y is a function of XandUYonly, and, second, UYis independent of {UZ, UX}, hence of X. The latter assumption parallels the celebrated “orthogon ality” con- dition in linear models, Cov(X, U Y) = 0, which has been used routinely, often thoughtlessly, to justify the estimation of structural coe ﬃcients by regression techniques. Naturally, if we were to apply this derivation to the linear m odels of Fig. 1(a) or1(b), we would get the expected dependence between Yand the intervention do(x0): E(Y|do(x0)) = E(fY(x0, uY)) =E(βx0+uY) =βx0(14) This equality endows βwith its causal meaning as “eﬀect coeﬃcient.” It is extremely important to keep in mind that in structural (as op posed to regres- sional) models, βis not “interpreted” as an eﬀect coeﬃcient but is “proven” to be one by the derivation above. βwill retain this causal interpretation re- gardless of how Xis actually selected (through the function fX, Fig. 2(a)) and regardless of whether UXandUYare correlated (as in Fig. 1(b)) or uncorrelated (as in Fig. 1(a)). Correlations may only impede our ability to estimate βfrom nonexperimental data, but will not change its deﬁnition as g iven in ( 14). Ac- cordingly, and contrary to endless confusions in the litera ture (see footnote 15) structural equations say absolutely nothing about the cond itional expectation E(Y|X=x). Such connection may be exist under special circumstances , e.g., ifcov(X, U Y) = 0, as in Eq. ( 13), but is otherwise irrelevant to the deﬁnition or interpretation of βas eﬀect coeﬃcient, or to the empirical claims of Eq. ( 1). The next subsection will circumvent these derivations alto gether by reduc- ing the identiﬁcation problem to a graphical procedure. Ind eed, since graphs encode all the information that non-parametric structural equations represent, they should permit us to solve the identiﬁcation problem wit hout resorting to algebraic analysis.\n\n\n3.2.3. Causal eﬀects from data and graphs\nCausal analysis in graphical models begins with the realiza tion that all causal eﬀects are identiﬁable whenever the model is Markovian , that is, the graph is acyclic (i.e., containing no directed cycles) and all the er ror terms are jointly independent. Non-Markovian models, such as those involvin g correlated errors (resulting from unmeasured confounders), permit identiﬁc ation only under cer- tain conditions, and these conditions too can be determined from the graph structure (Section 3.3). The key to these results rests with the following basic theorem. Theorem 1 (The Causal Markov Condition) .Any distribution generated by a Markovian model Mcan be factorized as: P(v1, v2, . . ., v n) =/productdisplay iP(vi|pai) (15) where V1, V2, . . ., V nare the endogenous variables in M, and paiare (values of) the endogenous “parents” of Viin the causal diagram associated with M. For example, the distribution associated with the model in F ig.2(a) can be factorized as P(z, y, x ) =P(z)P(x|z)P(y|x) (16) since Xis the (endogenous) parent of Y, Zis the parent of X, and Zhas no parents. Corollary 1 (Truncated factorization) .For any Markovian model, the distri- bution generated by an intervention do(X=x0)on a set Xof endogenous variables is given by the truncated factorization P(v1, v2, . . ., v k|do(x0)) =/productdisplay i|Vi/negationslash∈XP(vi|pai)|x=x0 (17) where P(vi|pai)are the pre-intervention conditional probabilities.8 Corollary 1instructs us to remove from the product of Eq. ( 15) all factors associated with the intervened variables (members of set X). This follows from the fact that the post-intervention model is Markovian as we ll, hence, following Theorem 1, it must generate a distribution that is factorized accordi ng to the modiﬁed graph, yielding the truncated product of Corollary 1. In our example of Fig. 2(b), the distribution P(z, y|do(x0)) associated with the modiﬁed model is given by P(z, y|do(x0)) =P(z)P(y|x0) where P(z) andP(y|x0) are identical to those associated with the pre-interventi on distribution of Eq. ( 16). As expected, the distribution of Zis not aﬀected by the intervention, since P(z|do(x0)) =/summationdisplay yP(z, y|do(x0)) =/summationdisplay yP(z)P(y|x0) =P(z) while that of Yis sensitive to x0, and is given by P(y|do(x0)) =/summationdisplay zP(z, y|do(x0)) =/summationdisplay zP(z)P(y|x0) =P(y|x0) This example demonstrates how the (causal) assumptions emb edded in the model Mpermit us to predict the post-intervention distribution fr om the pre- intervention distribution, which further permits us to est imate the causal eﬀect ofXonYfrom nonexperimental data, since P(y|x0) is estimable from such data. Note that we have made no assumption whatsoever on the f orm of the equations or the distribution of the error terms; it is the st ructure of the graph alone (speciﬁcally, the identity of X’s parents) that permits the derivation to go through. 8A simple proof of the Causal Markov Theorem is given in Pearl (2000a, p. 30). This theorem was ﬁrst presented in Pearl and Verma (1991), but it is implicit in the works ofKiiveri et al. (1984) and others. Corollary 1was named “Manipulation Theorem” in Spirtes et al. (1993), and is also implicit in Robins’ ( 1987)G-computation formula. See Lauritzen (2001). Z1 Z3Z2 YX Fig 3. Markovian model illustrating the derivation of the causal eﬀect of XonY, Eq. ( 20). Error terms are not shown explicitly. The truncated factorization formula enables us to derive ca usal quantities directly, without dealing with equations or equation modiﬁ cation as in Eqs. (11)–(13). Consider, for example, the model shown in Fig. 3, in which the er- ror variables are kept implicit. Instead of writing down the corresponding ﬁve nonparametric equations, we can write the joint distributi on directly as P(x, z1, z2, z3, y) =P(z1)P(z2)P(z3|z1, z2)P(x|z1, z3)P(y|z2, z3, x) (18) where each marginal or conditional probability on the right hand side is directly estimable from the data. Now suppose we intervene and set var iableXtox0. The post-intervention distribution can readily be written (using the truncated factorization formula ( 17)) as P(z1, z2, z3, y|do(x0)) =P(z1)P(z2)P(z3|z1, z2)P(y|z2, z3, x0) (19) and the causal eﬀect of XonYcan be obtained immediately by marginalizing over the Zvariables, giving P(y|do(x0)) =/summationdisplay z1,z2,z3P(z1)P(z2)P(z3|z1, z2)P(y|z2, z3, x0) (20) Note that this formula corresponds precisely to what is comm only called “ad- justing for Z1, Z2andZ3” and, moreover, we can write down this formula by inspection, without thinking on whether Z1, Z2andZ3are confounders, whether they lie on the causal pathways, and so on. Though such questi ons can be an- swered explicitly from the topology of the graph, they are de alt with automati- cally when we write down the truncated factorization formul a and marginalize. Note also that the truncated factorization formula is not re stricted to in- terventions on a single variable; it is applicable to simult aneous or sequential interventions such as those invoked in the analysis of time v arying treatment with time varying confounders ( Robins ,1986;Arjas and Parner ,2004). For ex- ample, if XandZ2are both treatment variables, and Z1andZ3are measured covariates, then the post-intervention distribution woul d be P(z1, z3, y|do(x), do(z2)) =P(z1)P(z3|z1, z2)P(y|z2, z3, x) (21) and the causal eﬀect of the treatment sequence do(X=x), do(Z2=z2)9would be P(y|do(x), do(z2)) =/summationdisplay z1,z3P(z1)P(z3|z1, z2)P(y|z2, z3, x) (22) 9For clarity, we drop the (superﬂuous) subscript 0 from x0andz20. This expression coincides with Robins’ ( 1987)G-computation formula, which was derived from a more complicated set of (counterfactual) assumptions. As noted by Robins, the formula dictates an adjustment for cova riates (e.g., Z3) that might be aﬀected by previous treatments (e.g., Z2).\n\n\n\n3.3. Coping with unmeasured confounders\nThings are more complicated when we face unmeasured confoun ders. For exam- ple, it is not immediately clear whether the formula in Eq. ( 20) can be estimated if any of Z1, Z2andZ3is not measured. A few but challenging algebraic steps would reveal that one can perform the summation over Z2to obtain P(y|do(x0)) =/summationdisplay z1,z3P(z1)P(z3|z1)P(y|z1, z3, x0) (23) which means that we need only adjust for Z1andZ3without ever measuring Z2. In general, it can be shown ( Pearl,2000a , p. 73) that, whenever the graph is Markovian the post-interventional distribution P(Y=y|do(X=x)) is given by the following expression: P(Y=y|do(X=x)) =/summationdisplay tP(y|t, x)P(t) (24) where Tis the set of direct causes of X(also called “parents”) in the graph. This allows us to write ( 23) directly from the graph, thus skipping the algebra that led to ( 23). It further implies that, no matter how complicated the mod el, the parents of Xare the only variables that need to be measured to estimate the causal eﬀects of X. It is not immediately clear however whether other sets of var iables beside X’s parents suﬃce for estimating the eﬀect of X, whether some algebraic manipu- lation can further reduce Eq. ( 23), or that measurement of Z3(unlike Z1, or Z2) is necessary in any estimation of P(y|do(x0)). Such considerations become transparent from a graphical criterion to be discussed next .\n\n3.3.1. Covariate selection – the back-door criterion\nConsider an observational study where we wish to ﬁnd the eﬀec t ofXonY, for example, treatment on response, and assume that the factors deemed relevant to the problem are structured as in Fig. 4; some are aﬀecting the response, some are aﬀecting the treatment and some are aﬀecting both treatm ent and response. Some of these factors may be unmeasurable, such as genetic tr ait or life style, others are measurable, such as gender, age, and salary level . Our problem is to select a subset of these factors for measurement and adjus tment, namely, that if we compare treated vs. untreated subjects having the same values of the selected factors, we get the correct treatment eﬀect in that subpopulation of subjects. Such a set of factors is called a “suﬃcient set” or “ admissible set” for Z1 Z3Z2 YXW W W1 Fig 4. Markovian model illustrating the back-door criterion. Er ror terms are not shown ex- plicitly. adjustment. The problem of deﬁning an admissible set, let al one ﬁnding one, has baﬄed epidemiologists and social scientists for decades (s ee (Greenland et al. , 1999;Pearl,1998) for review). The following criterion, named “back-door” in ( Pearl,1993a ), settles this problem by providing a graphical method of selecting admiss ible sets of factors for adjustment. Deﬁnition 3 (Admissible sets – the back-door criterion) .A set Sis admissible (or “suﬃcient”) for adjustment if two conditions hold:\n\nNo element of Sis a descendant of X\nThe elements of S“block” all “back-door” paths from XtoY, namely all paths that end with an arrow pointing to X.\n\nIn this criterion, “blocking” is interpreted as in Deﬁnitio n1. For example, the setS={Z3}blocks the path X←W1←Z1→Z3→Y, because the arrow- emitting node Z3is inS. However, the set S={Z3}does not block the path X←W1←Z1→Z3←Z2→W2→Y, because none of the arrow-emitting nodes, Z1andZ2, is in S, and the collision node Z3is not outside S. Based on this criterion we see, for example, that the sets {Z1, Z2, Z3},{Z1, Z3}, {W1, Z3}, and{W2, Z3}, each is suﬃcient for adjustment, because each blocks all back-door paths between XandY. The set{Z3}, however, is not suﬃ- cient for adjustment because, as explained above, it does no t block the path X←W1←Z1→Z3←Z2→W2→Y. The intuition behind the back-door criterion is as follows. The back-door paths in the diagram carry spurious associations from XtoY, while the paths directed along the arrows from XtoYcarry causative associations. Blocking the former paths (by conditioning on S) ensures that the measured association between XandYis purely causative, namely, it correctly represents the ta rget quantity: the causal eﬀect of XonY. The reason for excluding descendants of X(e.g., W3or any of its descendants) is given in ( Pearl,2009a , p. 338–41). Formally, the implication of ﬁnding an admissible set Sis that, stratifying on Sis guaranteed to remove all confounding bias relative the ca usal eﬀect of X onY. In other words, the risk diﬀerence in each stratum of Sgives the correct causal eﬀect in that stratum. In the binary case, for example , the risk diﬀerence in stratum sofSis given by P(Y= 1|X= 1, S=s)−P(Y= 1|X= 0, S=s) while the causal eﬀect (of XonY) at that stratum is given by P(Y= 1|do(X= 1), S=s)−P(Y= 1|do(X= 0), S=s). These two expressions are guaranteed to be equal whenever Sis a suﬃcient set, such as{Z1, Z3}or{Z2, Z3}in Fig. 4. Likewise, the average stratiﬁed risk diﬀerence, taken over all strata, /summationdisplay s[P(Y= 1|X= 1, S=s)−P(Y= 1|X= 0, S=s)]P(S=s), gives the correct causal eﬀect of XonYin the entire population P(Y= 1|do(X= 1))−P(Y= 1|do(X= 0)). In general, for multivalued variables XandY, ﬁnding a suﬃcient set S permits us to write P(Y=y|do(X=x), S=s) =P(Y=y|X=x, S=s) and P(Y=y|do(X=x)) =/summationdisplay sP(Y=y|X=x, S=s)P(S=s) (25) Since all factors on the right hand side of the equation are es timable (e.g., by regression) from the pre-interventional data, the causal e ﬀect can likewise be estimated from such data without bias. Interestingly, it can be shown that any irreducible suﬃcien t set, S, taken as a unit, satisﬁes the associational criterion that epidemio logists have been using to deﬁne “confounders”. In other words, Smust be associated with Xand, simultaneously, associated with Y, given X. This need not hold for any speciﬁc members of S. For example, the variable Z3in Fig. 4, though it is a member of every suﬃcient set and hence a confounder, can be unassoci ated with both YandX(Pearl,2000a , p. 195). Conversely, a pre-treatment variable Zthat is associated with both YandXmay need to be excluded from entering a suﬃcient set. The back-door criterion allows us to write Eq. ( 25) directly, by selecting a suﬃcient set Sdirectly from the diagram, without manipulating the trunca ted factorization formula. The selection criterion can be appl ied systematically to diagrams of any size and shape, thus freeing analysts from ju dging whether “Xis conditionally ignorable given S,” a formidable mental task required in the potential-response framework ( Rosenbaum and Rubin ,1983). The criterion also enables the analyst to search for an optimal set of covar iate—namely, a set Sthat minimizes measurement cost or sampling variability ( Tian et al. ,1998). All in all, one can safely state that, armed with the back-doo r criterion, causality has removed “confounding” from its store of enigm atic and controver- sial concepts.\n\n\n3.3.2. General control of confounding\nAdjusting for covariates is only one of many methods that per mits us to es- timate causal eﬀects in nonexperimental studies. Pearl (1995a ) has presented examples in which there exists no set of variables that is suﬃ cient for adjust- ment and where the causal eﬀect can nevertheless be estimate d consistently. The estimation, in such cases, employs multi-stage adjustm ents. For example, ifW3is the only observed covariate in the model of Fig. 4, then there exists no suﬃcient set for adjustment (because no set of observed cova riates can block the paths from XtoYthrough Z3), yet P(y|do(x)) can be estimated in two steps; ﬁrst we estimate P(w3|do(x)) =P(w3|x) (by virtue of the fact that there exists no unblocked back-door path from XtoW3), second we estimate P(y|do(w3)) (since Xconstitutes a suﬃcient set for the eﬀect of W3onY) and, ﬁnally, we combine the two eﬀects together and obtain P(y|do(x)) =/summationdisplay w3P(w3|do(x))P(y|do(w3)) (26) In this example, the variable W3acts as a “mediating instrumental variable” (Pearl,1993b ;Chalak and White ,2006). The analysis used in the derivation and validation of such re sults invokes mathematical rules of transforming causal quantities, rep resented by expressions such as P(Y=y|do(x)), into do-free expressions derivable from P(z, x, y ), since onlydo-free expressions are estimable from non-experimental dat a. When such a transformation is feasible, we are ensured that the causal q uantity is identiﬁable. Applications of this calculus to problems involving multip le interventions (e.g., time varying treatments), conditional policies, an d surrogate experiments were developed in Pearl and Robins (1995),Kuroki and Miyakawa (1999), and Pearl (2000a , Chapters 3–4). A recent analysis ( Tian and Pearl ,2002) shows that the key to identiﬁability lies not in blocking paths between XandYbut, rather, in blocking paths between Xand its immediate successors on the pathways to Y. All existing criteria for identiﬁcation are special cases of the one deﬁn ed in the following theorem: Theorem 2 (Tian and Pearl ,2002).A suﬃcient condition for identifying the causal eﬀect P(y|do(x))is that every path between Xand any of its children traces at least one arrow emanating from a measured variable .10 For example, if W3is the only observed covariate in the model of Fig. 4, P(y|do(x)) can be estimated since every path from XtoW3(the only child of X) traces either the arrow X→W3, or the arrow W3→Y, both emanating from a measured variable ( W3). More recent results extend this theorem by (1) presenting a necessary and suf- ﬁcient condition for identiﬁcation ( Shpitser and Pearl ,2006), and (2) extending 10Before applying this criterion, one may delete from the caus al graph all nodes that are not ancestors of Y. the condition from causal eﬀects to any counterfactual expr ession (Shpitser and Pearl, 2007). The corresponding unbiased estimands for these causal qu antities are readable directly from the diagram.\n\n\n3.3.3. From identiﬁcation to estimation\nThe mathematical derivation of causal eﬀect estimands, lik e Eqs. ( 25) and ( 26) is merely a ﬁrst step toward computing quantitative estimat es of those eﬀects from ﬁnite samples, using the rich traditions of statistica l estimation and ma- chine learning Bayesian as well as non-Bayesian. Although t he estimands derived in (25) and ( 26) are non-parametric, this does not mean that one should refr ain from using parametric forms in the estimation phase of the st udy. Parametriza- tion is in fact necessary when the dimensionality of a proble m is high. For exam- ple, if the assumptions of Gaussian, zero-mean disturbance s and additive inter- actions are deemed reasonable, then the estimand given in ( 26) can be converted to the product E(Y|do(x)) =rW3XrY W3·Xx,where rY Z·Xis the (standardized) coeﬃcient of Zin the regression of YonZandX. More sophisticated estima- tion techniques are the “marginal structural models” of ( Robins ,1999), and the “propensity score” method of ( Rosenbaum and Rubin ,1983) which were found to be particularly useful when dimensionality is high and da ta are sparse (see Pearl (2009a , pp. 348–52)). It should be emphasized, however, that contrary to conventi onal wisdom (e.g., (Rubin ,2007,2009)), propensity score methods are merely eﬃcient estimators of the right hand side of ( 25); they cannot be expected to reduce bias in case the setSdoes not satisfy the back-door criterion ( Pearl,2009a ,b,c). Consequently, the prevailing practice of conditioning on as many pre-trea tment measurements as possible should be approached with great caution; some co variates (e.g., Z3 in Fig. 3) may actually increase bias if included in the analysis (see footnote 20). Using simulation and parametric analysis, Heckman and Navarro-Lozano (2004) andWooldridge (2009) indeed conﬁrmed the bias-raising potential of certain co- variates in propensity-score methods. The graphical tools presented in this sec- tion unveil the character of these covariates and show preci sely what covariates should, and should not be included in the conditioning set fo r propensity-score matching (see also ( Pearl and Paz ,2009)).\n\n\n3.3.4. Bayesianism and causality, or where do the probabili ties come from?\nLooking back at the derivation of causal eﬀects in Sections 3.2and3.3, the reader should note that at no time did the analysis require nu merical assess- ment of probabilities. True, we assumed that the causal mode lMis loaded with a probability function P(u) over the exogenous variables in U, and we likewise assumed that the functions vi=fi(pai, u) map P(u) into a proba- bility P(v1, v2, . . ., v n) over the endogenous observed variables. But we never used or required any numerical assessment of P(u) nor any assumption on the form of the structural equations fi. The question naturally arises: Where do the numerical values of the post-intervention probabilities P(y|do(x)) come from? The answer is, of course, that they come from the data togethe r with stan- dard estimation techniques that turn data into numerical es timates of statisti- cal parameters (i.e., aspects of a probability distributio n). Subjective judgments were required only in qualitative form, to jump start the identiﬁcation process, the purpose of which was to determine what statistical param eters need be es- timated. Moreover, even the qualitative judgments were not about properties of probability distributions but about cause-eﬀect relati onships, the latter be- ing more transparent, communicable and meaningful. For exa mple, judgments about potential correlations between two Uvariables were essentially judgments about whether the two have a latent common cause or not. Naturally, the inﬂux of traditional estimation techniques into causal analy- sis carries with it traditional debates between Bayesians a nd frequentists, sub- jectivists and objectivists. However, this debate is ortho gonal to the distinct problems confronted by causal analysis, as delineated by th e demarcation line between causal and statistical analysis (Section 2). As is well known, many estimation methods in statistics invo ke subjective judgment at some level or another; for example, what paramet ric family of functions one should select, what type of prior one should as sign to the model parameters, and more. However, these judgments all refer to properties or pa- rameters of a static distribution function and, accordingl y, they are expressible in the language of probability theory. The new ingredient th at causal analysis brings to this tradition is the necessity of obtaining expli cit judgments not about properties of distributions but about the invariants of a di stribution, namely, judgment about cause-eﬀect relationships, and those, as we discussed in Section 2, cannot be expressed in the language of probability. Causal judgments are tacitly being used at many levels of tra ditional sta- tistical estimation. For example, most judgments about con ditional indepen- dence emanate from our understanding of cause eﬀect relatio nships. Likewise, the standard decision to assume independence among certain statistical pa- rameters and not others (in a Bayesian prior) rely on causal i nformation (see discussions with Joseph Kadane and Seraﬁn Moral ( Pearl,2003)). However the causal rationale for these judgments has remained implicit for many decades, for lack of adequate language; only their probabilistic ramiﬁc ations received formal representation. Causal analysis now requires explicit art iculation of the under- lying causal assumptions, a vocabulary that diﬀers substan tially from the one Bayesian statisticians have been accustomed to articulate . The classical example demonstrating the obstacle of causal vocabulary is Simpson’s paradox ( Simpson ,1951) – a reversal phenomenon that earns its claim to fame only through a causal interpretation of the dat a (Pearl,2000a , Chapter 6). The phenomenon was discovered by statisticians a century ago (Pearson et al. ,1899;Yule,1903) analyzed by statisticians for half a century (Simpson ,1951;Blyth,1972;Cox and Wermuth ,2003) lamented by statisticians (Good and Mittal ,1987;Bishop et al. ,1975) and wrestled with by statisticians till this very day ( Chen et al. ,2009;Pavlides and Perlman ,2009). Still, to the best of my knowledge, Wasserman (2004) is the ﬁrst statistics textbook to treat Simpson’s paradox in its correct causal context ( Pearl,2000a, p. 200). Lindley and Novick (1981) explained this century-long impediment to the understanding of Simpson’s paradox as a case of linguistic h andicap: “We have not chosen to do this; nor to discuss causation, because the c oncept, although widely used, does not seem to be well-deﬁned” (p. 51). Instea d, they attribute the paradox to another untestable relationship in the story —exchangeability (DeFinetti ,1974) which is cognitively formidable yet, at least formally, ca n be cast as a property of some imaginary probability function. The same reluctance to extending the boundaries of probabil ity language can be found among some scholars in the potential-outcome frame work (Section 4), where judgments about conditional independence of counter factual variables, however incomprehensible, are preferred to plain causal ta lk: “Mud does not cause rain.” This reluctance however is diminishing among Bayesians pri marily due to recognition that, orthogonal to the traditional debate bet ween frequentists and subjectivists, causal analysis is about change, and change demands a new vocab- ulary that distinguishes “seeing” from “doing” ( Lindley ,2002) (see discussion with Dennis Lindley ( Pearl,2009a , 2nd Edition, Chapter 11). Indeed, whether the conditional probabilities that enter E qs. (15)–(25) origi- nate from frequency data or subjective assessment matters n ot in causal analysis. Likewise, whether the causal eﬀect P(y|do(x)) is interpreted as one’s degree of belief in the eﬀect of action do(x), or as the fraction of the population that will be aﬀected by the action matters not in causal analysis. What matters is one’s readiness to accept and formulate qualitative judgments ab out cause-eﬀect re- lationship with the same seriousness that one accepts and fo rmulates subjective judgment about prior distributions in Bayesian analysis. Trained to accept the human mind as a reliable transducer of e xperience, and human experience as a faithful mirror of reality, Bayesi an statisticians are beginning to accept the language chosen by the mind to commun icate experience – the language of cause and eﬀect.\n\n\n\n3.4. Counterfactual analysis in structural models\nNot all questions of causal character can be encoded in P(y|do(x)) type ex- pressions, thus implying that not all causal questions can b e answered from experimental studies. For example, questions of attributi on (e.g., what fraction of death cases are due to speciﬁc exposure?) or of susceptibility (what fraction of the healthy unexposed population would have gotten the di sease had they been exposed?) cannot be answered from experimental studie s, and naturally, this kind of questions cannot be expressed in P(y|do(x)) notation.11To answer 11The reason for this fundamental limitation is that no death c ase can be tested twice, with and without treatment. For example, if we measure equal proportions of deaths in the treatment and control groups, we cannot tell how many death c ases are actually attributable to the treatment itself; it is quite possible that many of tho se who died under treatment would such questions, a probabilistic analysis of counterfactua ls is required, one dedi- cated to the relation “ Ywould be yhadXbeenxin situation U=u,” denoted Yx(u) =y. Remarkably, unknown to most economists and philosophers, struc- tural equation models provide the formal interpretation an d symbolic machinery for analyzing such counterfactual relationships.12 The key idea is to interpret the phrase “had Xbeenx” as an instruction to make a minimal modiﬁcation in the current model, which may ha ve assigned X a diﬀerent value, say X=x/prime, so as to ensure the speciﬁed condition X=x. Such a minimal modiﬁcation amounts to replacing the equation for Xby a constant x, as we have done in Eq. ( 6). This replacement permits the constant xto diﬀer from the actual value of X(namely fX(z, uX)) without rendering the system of equations inconsistent, thus yielding a formal interpreta tion of counterfactuals in multi-stage models, where the dependent variable in one e quation may be an independent variable in another. Deﬁnition 4 (Unit-level Counterfactuals, Pearl (2000a , p. 98)) .LetMbe a structural model and Mxa modiﬁed version of M, with the equation(s) of X replaced by X=x. Denote the solution for Yin the equations of Mxby the symbol YMx(u). The counterfactual Yx(u) (Read: “The value of Yin unit u, hadXbeenx” is given by: Yx(u)∆=YMx(u). (27) We see that the unit-level counterfactual Yx(u), which in the Neyman-Rubin approach is treated as a primitive, undeﬁned quantity, is ac tually a derived quantity in the structural framework. The fact that we equat e the experimental unituwith a vector of background conditions, U=u, inM, reﬂects the un- derstanding that the name of a unit or its identity do not matt er; it is only the vector U=uof attributes characterizing a unit which determines its be havior or response. As we go from one unit to another, the laws of natu re, as they are reﬂected in the functions fX, fY, etc. remain invariant; only the attributes U=uvary from individual to individual.13 To illustrate, consider the solution of Yin the modiﬁed model Mx0of Eq. ( 6), which Deﬁnition 4endows with the symbol Yx0(uX, uY, uZ). This entity has a be alive if untreated and, simultaneously, many of those who survived with treatment would have died if not treated. 12Connections between structural equations and a restricted class of counterfactuals were ﬁrst recognizedby Simon and Rescher (1966). These were later generalizedby Balke and Pearl (1995) to permit endogenous variables to serve as counterfactual antecedents. 13The distinction between general, or population-level caus es (e.g., “Drinking hemlock causes death”) and singular or unit-level causes (e.g., “So crates’ drinking hemlock caused his death”), which many philosophers have regarded as irreconc ilable ( Eells,1991), introduces no tension at all in the structural theory. The two types of sent ences diﬀer merely in the level of situation-speciﬁc information that is brought to bear on a p roblem, that is, in the speciﬁcity of the evidence ethat enters the quantity P(Yx=y|e). When eincludes allfactors u, we have a deterministic, unit-level causation on our hand; when e co ntains only a few known attributes (e.g., age, income, occupation etc.) while others are assig ned probabilities, a population-level analysis ensues. clear counterfactual interpretation, for it stands for the way an individual with characteristics ( uX, uY, uZ) would respond, had the treatment been x0, rather than the treatment x=fX(z, uX) actually received by that individual. In our example, since Ydoes not depend on uXanduZ, we can write: Yx0(u) =Yx0(uY, uX, uZ) =fY(x0, uY). (28) In a similar fashion, we can derive Yz0(u) =fY(fX(z0, uX), uY), Xz0,y0(u) =fX(z0, uX), and so on. These examples reveal the counterfactual reading of each individual structural equation in the model of Eq. ( 5). The equation x=fX(z, uX), for example, advertises the empirical claim that, regardless o f the values taken by other variables in the system, had Zbeenz0,Xwould take on no other value butx=fX(z0, uX). Clearly, the distribution P(uY, uX, uZ) induces a well deﬁned probability on the counterfactual event Yx0=y, as well as on joint counterfactual events, such as ‘Yx0=yAND Yx1=y/prime,’ which are, in principle, unobservable if x0/negationslash=x1. Thus, to answer attributional questions, such as whether Ywould be y1ifXwere x1, given that in fact Yisy0andXisx0, we need to compute the conditional probability P(Yx1=y1|Y=y0, X=x0) which is well deﬁned once we know the forms of the structural equations and the distribution of th e exogenous variables in the model. For example, assuming linear equations (as in F ig.1), x=uX y=βx+uX, the conditioning events Y=y0andX=x0yieldUX=x0andUY=y0−βx0, and we can conclude that, with probability one, Yx1must take on the value: Yx1=βx1+UY=β(x1−x0) +y0. In other words, if Xwerex1instead of x0, Ywould increase by βtimes the diﬀerence ( x1−x0). In nonlinear systems, the result would also depend on the distribution of {UX, UY}and, for that reason, attributional queries are generally not identiﬁable in non parametric models (see Section 5.2and2000a , Chapter 9). In general, if xandx/primeare incompatible then YxandYx/primecannot be measured simultaneously, and it may seem meaningless to attribute pr obability to the joint statement “ Ywould be yifX=xandYwould be y/primeifX=x/prime.”14 Such concerns have been a source of objections to treating co unterfactuals as jointly distributed random variables ( Dawid ,2000). The deﬁnition of YxandYx/prime in terms of two distinct submodels neutralizes these object ions (Pearl,2000b ), since the contradictory joint statement is mapped into an or dinary event, one where the background variables satisfy both statements sim ultaneously, each in its own distinct submodel; such events have well deﬁned prob abilities. 14For example, “The probability is 80% that Joe belongs to the c lass of patients who will be cured if they take the drug and die otherwise.” The structural deﬁnition of counterfactuals also provides the conceptual and formal basis for the Neyman-Rubin potential-outcome frame work, an approach to causation that takes a controlled randomized trial (CRT) as its ruling paradigm, assuming that nothing is known to the experimenter about the science behind the data. This “black-box” approach, which has thus far been denied the bene- ﬁts of graphical or structural analyses, was developed by st atisticians who found it diﬃcult to cross the two mental barriers discussed in Sect ion2.4. Section 4es- tablishes the precise relationship between the structural and potential-outcome paradigms, and outlines how the latter can beneﬁt from the ri cher representa- tional power of the former.\n\n\n3.5. An example: Non-compliance in clinical trials\nTo illustrate the methodology of the structural approach to causation, let us consider the practical problem of estimating treatment eﬀe ct in a typical clinical trial with partial compliance. Treatment eﬀect in such a set ting is in general nonidentiﬁable, yet this example is well suited for illustr ating the four major steps that should be part of every exercise in causal inferen ce:\n\nDeﬁne: Express the target quantity Qas a function Q(M) that can be computed from any model M.\nAssume: Formulate causal assumptions using ordinary scientiﬁc lan guage and represent their structural part in graphical form.\nIdentify: Determine if the target quantity is identiﬁable.\nEstimate: Estimate the target quantity if it is identiﬁable, or approx imate it, if it is not.\n\n\n3.5.1. Deﬁning the target quantity\nThe deﬁnition phase in our example is not altered by the speci ﬁcs of the ex- perimental setup under discussion. The structural modelin g approach insists on deﬁning the target quantity, in our case “causal eﬀect,” bef ore specifying the process of treatment selection, and without making functio nal form or distri- butional assumptions. The formal deﬁnition of the causal eﬀ ectP(y|do(x)), as given in Eq. ( 7), is universally applicable to all models, and invokes the f orma- tion of a submodel Mx. By deﬁning causal eﬀect procedurally, thus divorcing it from its traditional parametric representation, the str uctural theory avoids the many confusions and controversies that have plagued the interpretation of structural equations and econometric parameters for the pa st half century (see footnote 15).\n\n\n3.5.2. Formulating the assumptions – Instrumental variabl es\nThe experimental setup in a typical clinical trial with part ial compliance can be represented by the model of Fig. 5(a) and Eq. ( 5) where Zrepresents a ran- domized treatment assignment, Xis the treatment actually received, and Yis X Y Z X Y Z (a) (b)U U U U U U Z X Y0x Y Z X Fig 5. (a) Causal diagram representing a clinical trial with impe rfect compliance. (b) A diagram representing interventional treatment control. the observed response. The UYterm represents all factors (unobserved) that inﬂuence the way a subject responds to treatments; hence, an arrow is drawn fromUYtoY. Similarly, UXdenotes all factors that inﬂuence the subject’s compliance with the assignment, and UZrepresents the random device used in deciding assignment. The dependence between UXandUYallows for certain fac- tors (e.g., socio economic status or predisposition to dise ase and complications) to inﬂuence both compliance and response. In Eq. ( 5),fXrepresents the pro- cess by which subjects select treatment level and fYrepresents th process that determines the outcome Y. Clearly, perfect compliance would amount to setting fX(z, uX) =zwhile any dependence on uXrepresents imperfect compliance. The graphical model of Fig. 5(a) reﬂects two assumptions.\n\nThe assignment Z does not inﬂuence Ydirectly but rather through the actual treatment taken, X. This type of assumption is called “exclusion” restriction, for it excludes a variable ( Z) from being a determining argu- ment of the function fY, as in Eq. ( 5).\nThe variable Z is independent of UYandUX; this is ensured through the randomization of Z, which rules out a common cause for both ZandUY (as well as for Z and UX).\n\nBy drawing the diagram of Fig. 5(a) an investigator encodes an unambiguous speciﬁcation of these two assumptions, and permits the tech nical part of the analysis to commence, under the interpretation provided by Eq. (5). The target of causal analysis in this setting is to estimate t he causal eﬀect of the treatment ( X) on the outcome ( Y), as deﬁned by the modiﬁed model of Eq. (6) and the corresponding distribution P(y|do(x0)). In words, this distribution describes the response of the population to a hypothetical e xperiment in which we administer treatment at level X=x0uniformly to the entire population and let x0take diﬀerent values on hypothetical copies of the populati on. An inspection of the diagram in Fig. 5(a) reveals immediately that this distribution is not identiﬁable by adjusting for confounders. The graphi cal criterion for such identiﬁcation (Deﬁnition 3) requires the existence of observed covariates on the “back-door” path X←UX↔︎UY→Y, that blocks the spurious associations created by that path. Had UX(orUY) been observable, the treatment eﬀect would have been obtained by stratiﬁcation on the levels of UX. P(Y=y|do(x0)) =/summationdisplay uXP(Y=y|X=x0, UX=uX)P(UX=uX) (29) thus yielding an estimable expression that requires no meas urement of UYand no assumptions relative the dependence between UYandUX. However, since UX(andUY) are assumed to be unobserved, and since no other blocking co - variates exist, the investigator can conclude that confoun ding bias cannot be removed by adjustment. Moreover, it can be shown that, in the absence of ad- ditional assumptions, the treatment eﬀect in such graphs ca nnot be identiﬁed by any method whatsoever ( Balke and Pearl ,1997); one must therefore resort to approximate methods of assessment. It is interesting to note that it is our insistence on allowin g arbitrary functions in Eq. ( 5) that curtails our ability to infer the treatment eﬀect from nonexperi- mental data (when UXandUYare unobserved). In linear systems, for example, the causal eﬀect of XonYis identiﬁable, as can be seen by writing:15 y=fY(x, u) =βx+uY; (30) multiplying this equation by zand taking expectations, gives β=Cov(Z, Y)/(Cov(Z, X) (31) which reduces βto correlations among observed measurements. Eq. ( 31) is known as the instrumental variable estimand ( Bowden and Turkington ,1984). Similarly, Angrist and Imbens (1991) have shown that a broader class of nonlin- ear functions fXandfYmay render the causal eﬀect identiﬁable. Angrist et al. (1996) and Heckman and Vytlacil (2005) further reﬁned this analysis by con- sidering a variety of causal eﬀect measures, each applicabl e to a special (albeit non-identiﬁable and transient) segment of the population.\n\n\n3.5.3. Bounding causal eﬀects\nWhen conditions for identiﬁcation are not met, the best one c an do is derive bounds for the quantities of interest—namely, a range of possible v alues that represents our ignorance about the data-generating proces s and that cannot be improved with increasing sample size. In our example, this a mounts to bound- ing the average diﬀerence of Eq. ( 8) subject to the constraint provided by the 15Note that βrepresents the incremental causal eﬀect of XonY, deﬁned by β∆=E(Y|do(x0+ 1)) −E(Y|do(x0)) =δ δxE(Y|do(x)) =δ δxE(Yx). Naturally, all attempts to give βstatistical interpretation have ended in frustrations ( Holland , 1988;Whittaker ,1990;Wermuth ,1992;Wermuth and Cox ,1993), some persisting well into the 21st century ( Sobel,2008). observed distribution P(x, y|z) =/summationdisplay uX,uYP(x, y, u X, uY|z) =/summationdisplay uX,uYP(y|x, uY, uX)P(x|z, uX)P(uY, uX) (32) where the product decomposition is licensed by the conditio nal independencies shown in Fig. 5(a). Likewise, since the causal eﬀect is governed by the modi ﬁed model of Fig. 5(b), it can be written P(y|do(x/prime))−P(y|do(x/prime/prime)) =/summationdisplay u[P(y|x/prime, uY)−P(y|x/prime/prime, uY)]P(uY) (33) Our task is then to bound the expression in Eq. ( 33) given the observed prob- abilities P(y, x|z) as expressed in Eq. ( 32). This task amounts to a constrained optimization exercise of ﬁnding the highest and lowest valu es of Eq. ( 33) subject to the equality constraints in Eq. ( 32), where the maximization ranges over all possible functions P(uY, uX), P(y|x, uY, uX) and P(x|z, uY) that satisfy those constraints. Realizing that units in this example fall into 16 equivalent classes, each representing a binary function X=f(z) paired with a binary function y= g(x),Balke and Pearl (1997) were able to derive closed-form solutions for these bounds.16They showed that despite the imperfection of the experiment s, the derived bounds can yield signiﬁcant and sometimes accurate information on the treatment eﬃcacy. Chickering and Pearl (1997) further used Bayesian tech- niques (with Gibbs sampling) to investigate the sharpness o f these bounds as a function of sample size.\n\n\n3.5.4. Testable implications of instrumental variables\nThe two assumptions embodied in the model of Fig. 5(a), that Zis randomized and has no direct eﬀect on Y, are untestable in general ( Bonet ,2001). However, if the treatment variable may take only a ﬁnite number of values , the combination of these two assumptions yields testable implications, and these can be used to alert investigators to possible violations of these assu mptions. The testable implications take the form of inequalities which restrict a spects of the observed conditional distribution P(x, y|z) from exceeding certain bounds ( Pearl,1995b ). One specially convenient form that these restrictions assu me is given by the inequality max x/summationdisplay y[max zP(x, y|z)]≤1 (34) Pearl (1995b ) called this restriction an instrumental inequality , because it con- stitutes a necessary condition for any variable Zto qualify as an instrument 16These equivalence classes were later called “principal str atiﬁcation” by Frangakis and Rubin ( 2002). Looser bounds were derived earlier by Robins (1989) and Manski (1990). relative to the pair ( X, Y). This inequality is sharp for binary valued X, but becomes loose when the cardinality of Xincreases.17 If all observed variables are binary, Eq. ( 34) reduces to the four inequalities P(Y= 0, X= 0|Z= 0) + P(Y= 1, X= 0|Z= 1)≤1 P(Y= 0, X= 1|Z= 0) + P(Y= 1, X= 1|Z= 1)≤1 P(Y= 1, X= 0|Z= 0) + P(Y= 0, X= 0|Z= 1)≤1 P(Y= 1, X= 1|Z= 0) + P(Y= 0, X= 1|Z= 1)≤1 (35) We see that the instrumental inequality is violated when the controlling instru- mentZmanages to produce signiﬁcant changes in the response varia bleYwhile the direct cause, X, remains constant. The instrumental inequality can be used in the detection of u ndesirable side- eﬀects. Violations of this inequality can be attributed to o ne of two possibilities: either there is a direct causal eﬀect of the assignment ( Z) on the response ( Y), unmediated by the treatment ( X), or there is a common causal factor inﬂu- encing both variables. If the assignment is carefully rando mized, then the latter possibility is ruled out and any violation of the instrument al inequality (even un- der conditions of imperfect compliance) can safely be attri buted to some direct inﬂuence of the assignment process on subjects’ response (e .g., psychological aversion to being treated). Alternatively, if one can rule o ut any direct eﬀects ofZonY, say through eﬀective use of a placebo, then any observed vio lation of the instrumental inequality can safely be attributed to s purious dependence between ZandUY, namely, to selection bias.",
    "crumbs": [
      "Causal Inference",
      "Causal inference in statistics"
    ]
  },
  {
    "objectID": "extracted/Causal inference in statistics An overview2.html#the-potential-outcome-framework",
    "href": "extracted/Causal inference in statistics An overview2.html#the-potential-outcome-framework",
    "title": "Causal inference in statistics",
    "section": "4. The potential outcome framework",
    "text": "4. The potential outcome framework\nThis section compares the structural theory presented in Se ctions 1–3to the potential-outcome framework, usually associated with the names of Neyman (1923) and Rubin (1974), which takes the randomized experiment as its rul- ing paradigm and has appealed therefore to researchers who d o not ﬁnd that paradigm overly constraining. This framework is not a conte nder for a com- prehensive theory of causation for it is subsumed by the stru ctural theory and excludes ordinary cause-eﬀect relationships from its assu mption vocabulary. We here explicate the logical foundation of the Neyman-Rubin f ramework, its for- mal subsumption by the structural causal model, and how it ca n beneﬁt from the insights provided by the broader perspective of the stru ctural theory. The primitive object of analysis in the potential-outcome f ramework is the unit-based response variable, denoted Yx(u), read: “the value that outcome Y would obtain in experimental unit u, had treatment Xbeen x.” Here, unit may stand for an individual patient, an experimental subjec t, or an agricultural plot. In Section 3.4(Eq. ( 27) we saw that this counterfactual entity has a nat- ural interpretation in the SCM; it is the solution for Yin a modiﬁed system 17The inequality is sharp in the sense that every distribution P(x,y, z) satisfying Eq. ( 34) can be generated by the model deﬁned in Fig. 5(a). of equations, where unitis interpreted a vector uof background factors that characterize an experimental unit. Each structural equati on model thus carries a collection of assumptions about the behavior of hypotheti cal units, and these assumptions permit us to derive the counterfactual quantit ies of interest. In the potential-outcome framework, however, no equations are av ailable for guidance andYx(u) is taken as primitive, that is, an undeﬁned quantity in term s of which other quantities are deﬁned; not a quantity that can be deriv edfromthe model. In this sense the structural interpretation of Yx(u) given in ( 27) provides the formal basis for the potential-outcome approach; the forma tion of the submodel Mxexplicates mathematically how the hypothetical condition “hadXbeenx” is realized, and what the logical consequences are of such a c ondition.\n\n4.1. The “Black-Box” missing-data paradigm\nThe distinct characteristic of the potential-outcome appr oach is that, although investigators must think and communicate in terms of undeﬁn ed, hypothetical quantities such as Yx(u), the analysis itself is conducted almost entirely within the axiomatic framework of probability theory. This is acco mplished, by postu- lating a “super” probability function on both hypothetical and real events. If Uis treated as a random variable then the value of the counterf actual Yx(u) becomes a random variable as well, denoted as Yx. The potential-outcome analy- sis proceeds by treating the observed distribution P(x1, . . ., x n) as the marginal distribution of an augmented probability function P∗deﬁned over both observed and counterfactual variables. Queries about causal eﬀects (written P(y|do(x)) in the structural analysis) are phrased as queries about the ma rginal distribution of the counterfactual variable of interest, written P∗(Yx=y). The new hypo- thetical entities Yxare treated as ordinary random variables; for example, they are assumed to obey the axioms of probability calculus, the l aws of conditioning, and the axioms of conditional independence. Naturally, these hypothetical entities are not entirely wh imsy. They are as- sumed to be connected to observed variables via consistency constraints ( Robins , 1986) such as X=x=⇒Yx=Y, (36) which states that, for every u, if the actual value of Xturns out to be x, then the value that Ywould take on if ‘ Xwerex’ is equal to the actual value of Y. For example, a person who chose treatment xand recovered, would also have recovered if given treatment xby design. When Xis binary, it is sometimes more convenient to write ( 36) as: Y=xY1+ (1−x)Y0 Whether additional constraints should tie the observables to the unobservables is not a question that can be answered in the potential-outco me framework; for it lacks an underlying model to deﬁne its axioms. The main conceptual diﬀerence between the two approaches is that, whereas the structural approach views the intervention do(x) as an operation that changes a distribution but keeps the variables the same, the potenti al-outcome approach views the variable Yunder do(x) to be a diﬀerent variable, Yx, loosely con- nected to Ythrough relations such as ( 36), but remaining unobserved whenever X/negationslash=x. The problem of inferring probabilistic properties of Yx, then becomes one of “missing-data” for which estimation techniques have been developed in the statistical literature. Pearl (2000a , Chapter 7) shows, using the structural interpretation of Yx(u), that it is indeed legitimate to treat counterfactuals as joi ntly distributed random variables in all respects, that consistency constraints li ke (36) are automatically satisﬁed in the structural interpretation and, moreover, t hat investigators need not be concerned about any additional constraints except th e following two: Yyz=yfor all y,subsets Z,and values zforZ (37) Xz=x⇒Yxz=Yzfor all x,subsets Z,and values zforZ (38) Equation ( 37) ensures that the interventions do(Y=y) results in the condition Y=y, regardless of concurrent interventions, say do(Z=z), that may be applied to variables other than Y. Equation ( 38) generalizes ( 36) to cases where Zis held ﬁxed, at z.\n\n\n4.2. Problem formulation and the demystiﬁcation of “ignora bility”\nThe main drawback of this black-box approach surfaces in pro blem formula- tion, namely, the phase where a researcher begins to articul ate the “science” or “causal assumptions” behind the problem at hand. Such knowl edge, as we have seen in Section 1, must be articulated at the onset of every problem in causal analysis – causal conclusions are only as valid as the causal assumptions upon which they rest. To communicate scientiﬁc knowledge, the potential-outcom e analyst must express assumptions as constraints on P∗, usually in the form of conditional independence assertions involving counterfactual variab les. For instance, in our example of Fig. 5(a), to communicate the understanding that Zis randomized (hence independent of UXandUY), the potential-outcome analyst would use the independence constraint Z⊥ ⊥{Yz1, Yz2, . . ., Y zk}.18To further formulate the understanding that Zdoes not aﬀect Ydirectly, except through X, the analyst would write a, so called, “exclusion restriction”: Yxz=Yx. A collection of constraints of this type might sometimes be s uﬃcient to permit a unique solution to the query of interest. For example, if on e can plausibly assume that, in Fig. 4, a set Zof covariates satisﬁes the conditional independence Yx⊥ ⊥X|Z (39) (an assumption termed “conditional ignorability” by Rosenbaum and Rubin (1983),) then the causal eﬀect P(y|do(x)) =P∗(Yx=y) can readily be evaluated 18The notation Y⊥ ⊥X|Zstands for the conditional independence relationship P(Y= y, X=x|Z=z) =P(Y=y|Z=z)P(X=x|Z=z) (Dawid ,1979). to yield P∗(Yx=y) =/summationdisplay zP∗(Yx=y|z)P(z) =/summationdisplay zP∗(Yx=y|x, z)P(z) (using ( 39)) =/summationdisplay zP∗(Y=y|x, z)P(z) (using ( 36)) =/summationdisplay zP(y|x, z)P(z). (40) The last expression contains no counterfactual quantities (thus permitting us to drop the asterisk from P∗) and coincides precisely with the standard covariate- adjustment formula of Eq. ( 25). We see that the assumption of conditional ignorability ( 39) qualiﬁes Zas an admissible covariate for adjustment; it mirrors therefo re the “back-door” criterion of Deﬁnition 3, which bases the admissibility of Zon an explicit causal structure encoded in the diagram. The derivation above may explain why the potential-outcome approach ap- peals to mathematical statisticians; instead of construct ing new vocabulary (e.g., arrows), new operators ( do(x)) and new logic for causal analysis, almost all mathematical operations in this framework are conducted wi thin the safe con- ﬁnes of probability calculus. Save for an occasional applic ation of rule ( 38) or (36)), the analyst may forget that Yxstands for a counterfactual quantity—it is treated as any other random variable, and the entire deriv ation follows the course of routine probability exercises. This orthodoxy exacts a high cost: Instead of bringing the th eory to the problem, the problem must be reformulated to ﬁt the theory; a ll background knowledge pertaining to a given problem must ﬁrst be transla ted into the lan- guage of counterfactuals (e.g., ignorability conditions) before analysis can com- mence. This translation may in fact be the hardest part of the problem. The reader may appreciate this aspect by attempting to judge whe ther the assump- tion of conditional ignorability ( 39), the key to the derivation of ( 40), holds in any familiar situation, say in the experimental setup of Fig .2(a). This assump- tion reads: “the value that Ywould obtain had Xbeenx, is independent of X, given Z”. Even the most experienced potential-outcome expert woul d be unable to discern whether any subset Zof covariates in Fig. 4would satisfy this conditional independence condition.19Likewise, to derive Eq. ( 39) in the language of potential-outcome (see ( Pearl,2000a , p. 223)), one would need to convey the structure of the chain X→W3→Yusing the cryptic expression: W3x⊥ ⊥{Yw3, X}, read: “the value that W3would obtain had Xbeenxis inde- pendent of the value that Ywould obtain had W3beenw3jointly with the value ofX.” Such assumptions are cast in a language so far removed from ordinary 19Inquisitive readers are invited to guess whether Xz⊥ ⊥Z|Yholds in Fig. 2(a), then reﬂect on why causality is so slow in penetrating statistical educa tion. understanding of scientiﬁc theories that, for all practica l purposes, they cannot be comprehended or ascertained by ordinary mortals. As a res ult, researchers in the graph-less potential-outcome camp rarely use “condi tional ignorability” (39) to guide the choice of covariates; they view this condition as a hoped-for miracle of nature rather than a target to be achieved by reaso ned design.20 Replacing “ignorability” with a conceptually meaningful c ondition (i.e., back- door) in a graphical model permits researchers to understan d what conditions covariates must fulﬁll before they eliminate bias, what to w atch for and what to think about when covariates are selected, and what experime nts we can do to test, at least partially, if we have the knowledge needed for covariate selection. Aside from oﬀering no guidance in covariate selection, form ulating a problem in the potential-outcome language encounters three additi onal hurdles. When counterfactual variables are not viewed as byproducts of a d eeper, process-based model, it is hard to ascertain whether allrelevant judgments have been articu- lated, whether the judgments articulated are redundant , or whether those judg- ments are self-consistent. The need to express, defend, and manage formidable counterfactual relationships of this type explain the slow acceptance of causal analysis among health scientists and statisticians, and wh y most economists and social scientists continue to use structural equation m odels ( Wooldridge , 2002;Stock and Watson ,2003;Heckman ,2008) instead of the potential-outcome alternatives advocated in Angrist et al. (1996);Holland (1988);Sobel (1998, 2008). On the other hand, the algebraic machinery oﬀered by the coun terfactual no- tation, Yx(u), once a problem is properly formalized, can be extremely po werful in reﬁning assumptions ( Angrist et al. ,1996;Heckman and Vytlacil ,2005), de- riving consistent estimands ( Robins ,1986), bounding probabilities of necessary and suﬃcient causation ( Tian and Pearl ,2000), and combining data from exper- imental and nonexperimental studies ( Pearl,2000a ). The next subsection ( 4.3) presents a way of combining the best features of the two appro aches. It is based on encoding causal assumptions in the language of diagrams, translating these assumptions into counterfactual notation, performing the mathematics in the algebraic language of counterfactuals (using ( 36), (37), and ( 38)) and, ﬁnally, interpreting the result in graphical terms or plain causal l anguage. The media- tion problem of Section 5.1illustrates how such symbiosis clariﬁes the deﬁnition and identiﬁcation of direct and indirect eﬀects. In contrast, when the mediation problem is approached from a n orthodox potential-outcome viewpoint, void of the structural guida nce of Eq. ( 27), para- doxical results ensue. For example, the direct eﬀect is deﬁn able only in units absent of indirect eﬀects ( Rubin ,2004,2005). This means that a grandfather 20The opaqueness of counterfactual independencies explains why many researchers within the potential-outcome camp are unaware of the fact that addi ng a covariate to the analysis (e.g., Z3in Fig. 4,Zin Fig. 5a) may actually increase confounding bias in propensity-score matching. Paul Rosenbaum, for example, writes: “there is li ttle or no reason to avoid adjust- ment for a true covariate, a variable describing subjects be fore treatment” ( Rosenbaum ,2002, p. 76). Rubin (2009) goes as far as stating that refraining from conditioning on an available measurement is “nonscientiﬁcad hockery” for it goes agains t the tenets of Bayesian philosophy (see (Pearl,2009b ,c;Heckman and Navarro-Lozano ,2004) for a discussion of this fallacy). would be deemed to have no direct eﬀect on his grandson’s beha vior in families where he has had some eﬀect on the father. This precludes from the analy- sis all typical families, in which a father and a grandfather have simultaneous, complementary inﬂuences on children’s upbringing. In line ar systems, to take a sharper example, the direct eﬀect would be undeﬁned wheneve r indirect paths exist from the cause to its eﬀect. The emergence of such parad oxical conclusions underscores the wisdom, if not necessity of a symbiotic anal ysis, in which the counterfactual notation Yx(u) is governed by its structural deﬁnition, Eq. ( 27).21\n\n\n4.3. Combining graphs and potential outcomes\nThe formulation of causal assumptions using graphs was disc ussed in Section 3. In this subsection we will systematize the translation of th ese assumptions from graphs to counterfactual notation. Structural equation models embody causal information in bo th the equa- tions and the probability function P(u) assigned to the exogenous variables; the former is encoded as missing arrows in the diagrams the la tter as missing (double arrows) dashed arcs. Each parent-child family ( PAi, Xi) in a causal diagram Gcorresponds to an equation in the model M. Hence, missing arrows encode exclusion assumptions, that is, claims that manipul ating variables that are excluded from an equation will not change the outcome of t he hypothetical experiment described by that equation. Missing dashed arcs encode independen- cies among error terms in two or more equations. For example, the absence of dashed arcs between a node Yand a set of nodes {Z1, . . ., Z k}implies that the corresponding background variables, UYand{UZ1, . . ., U Zk}, are independent inP(u). These assumptions can be translated into the potential-out come notation using two simple rules ( Pearl,2000a , p. 232); the ﬁrst interprets the missing arrows in the graph, the second, the missing dashed arcs. 1.Exclusion restrictions: For every variable Yhaving parents PAYand for every set of endogenous variables Sdisjoint of PAY, we have YpaY=YpaY,s. (41) 2.Independence restrictions: IfZ1, . . ., Z kis any set of nodes not connected toYvia dashed arcs, and PA1, . . ., PA ktheir respective sets of parents, we have YpaY⊥ ⊥{Z1pa1, . . ., Z k pa k}. (42) The exclusion restrictions expresses the fact that each par ent set includes all direct causes of the child variable, hence, ﬁxing the parent s ofY, determines the value of Yuniquely, and intervention on any other set Sof (endogenous) variables can no longer aﬀect Y. The independence restriction translates the 21Such symbiosis is now standard in epidemiology research ( Robins ,2001;Petersen et al. , 2006;VanderWeele and Robins ,2007;Hafeman and Schwartz ,2009;VanderWeele ,2009) yet still lacking in econometrics ( Heckman ,2008;Imbens and Wooldridge ,2009). independence between UYand{UZ1, . . ., U Zk}into independence between the corresponding potential-outcome variables. This follows from the observation that, once we set their parents, the variables in {Y, Z1, . . ., Z k}stand in func- tional relationships to the Uterms in their corresponding equations. As an example, the model shown in Fig. 5(a) displays the following parent sets: PAZ={∅}, PAX={Z}, PAY={X}. (43) Consequently, the exclusion restrictions translate into: Xz=Xyz Zy=Zxy=Zx=Z (44) Yx=Yxz the absence of any dashed arc between Zand{Y, X}translates into the inde- pendence restriction Z⊥ ⊥{Yx, Xz}. (45) This is precisely the condition of randomization; Zis independent of all its non-descendants, namely independent of UXandUYwhich are the exogenous parents of YandX, respectively. (Recall that the exogenous parents of any variable, say Y, may be replaced by the counterfactual variable YpaY, because holding PAYconstant renders Ya deterministic function of its exogenous par- entUY.) The role of graphs is not ended with the formulation of causal assumptions. Throughout an algebraic derivation, like the one shown in Eq . (40), the analyst may need to employ additional assumptions that are entailed by the original exclusion and independence assumptions, yet are not shown e xplicitly in their respective algebraic expressions. For example, it is hardl y straightforward to show that the assumptions of Eqs. ( 44)–(45) imply the conditional independence (Yx⊥ ⊥Z|{Xz, X}) but do not imply the conditional independence ( Yx⊥ ⊥Z|X). These are not easily derived by algebraic means alone. Such i mplications can, however, easily be tested in the graph of Fig. 5(a) using the graphical read- ing for conditional independence (Deﬁnition 1). (See ( Pearl,2000a, pp. 16–17, 213–215).) Thus, when the need arises to employ independenc ies in the course of a derivation, the graph may assist the procedure by vividl y displaying the independencies that logically follow from our assumptions .",
    "crumbs": [
      "Causal Inference",
      "Causal inference in statistics"
    ]
  },
  {
    "objectID": "extracted/Causal inference in statistics An overview2.html#counterfactuals-at-work",
    "href": "extracted/Causal inference in statistics An overview2.html#counterfactuals-at-work",
    "title": "Causal inference in statistics",
    "section": "5. Counterfactuals at work",
    "text": "5. Counterfactuals at work\n\n5.1. Mediation: Direct and indirect eﬀects\n\n5.1.1. Direct versus total eﬀects:\nThe causal eﬀect we have analyzed so far, P(y|do(x)), measures the totaleﬀect of a variable (or a set of variables) Xon a response variable Y. In many cases, this quantity does not adequately represent the target of invest igation and attention is focused instead on the direct eﬀect of XonY. The term “direct eﬀect” is meant to quantify an eﬀect that is not mediated by other varia bles in the model or, more accurately, the sensitivity of Yto changes in Xwhile all other factors in the analysis are held ﬁxed. Naturally, holding those fact ors ﬁxed would sever all causal paths from XtoYwith the exception of the direct link X→Y, which is not intercepted by any intermediaries. A classical example of the ubiquity of direct eﬀects involve s legal disputes over race or sex discrimination in hiring. Here, neither the eﬀect of sex or race on applicants’ qualiﬁcation nor the eﬀect of qualiﬁcation o n hiring are targets of litigation. Rather, defendants must prove that sex and ra ce do not directly inﬂuence hiring decisions, whatever indirect eﬀects they m ight have on hiring by way of applicant qualiﬁcation. Another example concerns the identiﬁcation of neural pathw ays in the brain or the structural features of protein-signaling networks i n molecular biology (Brent and Lok ,2005). Here, the decomposition of eﬀects into their direct and indirect components carries theoretical scientiﬁc import ance, for it predicts be- havior under a rich variety of hypothetical interventions. In all such examples, the requirement of holding the mediati ng variables ﬁxed must be interpreted as (hypothetically) setting the in termediate variables to constants by physical intervention, not by analytical me ans such as selection, conditioning, or adjustment. For example, it will not be suﬃ cient to measure the association between gender ( X) and hiring ( Y) for a given level of qualiﬁ- cation Z, because, by conditioning on the mediator Z, we may create spurious associations between XandYeven when there is no direct eﬀect of XonY (Pearl,1998;Cole and Hern´ an ,2002). This can easily be illustrated in the model X→Z←U→Y, where Xhas no direct eﬀect on Y. Physically holding Z constant would sustain the independence between XandY, as can be seen by deleting all arrows entering Z. But if we were to condition on Z, a spurious association would be created through U(unobserved) that might be construed as a direct eﬀect of XonY.22 Using the do(x) notation, and focusing on diﬀerences of expectations, thi s leads to a simple deﬁnition of controlled direct eﬀect : CDE∆=E(Y|do(x/prime), do(z))−E(Y|do(x), do(z)) or, equivalently, using counterfactual notation: CDE∆=E(Yx/primez)−E(Yxz) (46) where Zis any set of mediating variables that intercept all indirec t paths be- tween XandY. Graphical identiﬁcation conditions for expressions of th e type E(Y|do(x), do(z1), do(z2), . . ., do (zk)) were derived by Pearl and Robins (1995) (see ( Pearl,2000a , Chapter 4)) using sequential application of the back-door condition (Deﬁnition 3). 22According to Rubin (2004,2005), R.A. Fisher made this mistake in the context of agri- culture experiments. Fisher, in fairness, did not have grap hs for guidance.\n\n\n5.1.2. Natural direct eﬀects\nIn linear systems, Eq. ( 46) yields the path coeﬃcient of the link from XtoY; independent of the values at which we hold Z, independent of the distribution of the error terms, and regardless of whether those coeﬃcien ts are identiﬁable or not. In nonlinear systems, the values at which we hold Zwould, in general, modify the eﬀect of XonYand thus should be chosen carefully to represent the target policy under analysis. For example, it is not uncommo n to ﬁnd employers who prefer males for the high-paying jobs (i.e., high z) and females for low- paying jobs (low z). When the direct eﬀect is sensitive to the levels at which we ho ldZ, it is often meaningful to deﬁne the direct eﬀect relative to a “nat ural representative” of those levels or, more speciﬁcally, as the expected change inYinduced by changing Xfromxtox/primewhile keeping all mediating factors constant at whatever value they would have obtained under do(x). This hypothetical change, which Robins and Greenland (1992) called “pure” and Pearl (2001) called “natural,” mirrors what lawmakers instruct us to consider in race or sex discrimination cases: “The central question in any employment-discrimina tion case is whether the employer would have taken the same action had the employe e been of a diﬀerent race (age, sex, religion, national origin etc.) an d everything else had been the same.” (In Carson versus Bethlehem Steel Corp. , 70 FEP Cases 921, 7th Cir. (1996)). Extending the subscript notation to express nested counter factuals, Pearl (2001) gave the following deﬁnition for the “natural direct eﬀect”: DEx,x/prime(Y)∆=E(Yx/prime,Zx)−E(Yx). (47) Here, Yx/prime,Zxrepresents the value that Ywould attain under the operation of setting Xtox/primeand, simultaneously, setting Zto whatever value it would have obtained under the original setting X=x. We see that DEx,x/prime(Y), the natural direct eﬀect of the transition from xtox/prime, involves probabilities of nested coun- terfactuals and cannot be written in terms of the do(x) operator. Therefore, the natural direct eﬀect cannot in general be identiﬁed, even wi th the help of ideal, controlled experiments (see footnote 11for intuitive explanation). Pearl (2001) has nevertheless shown that, if certain assumptions of “unc onfoundedness” are deemed valid, the natural direct eﬀect can be reduced to DEx,x/prime(Y) =/summationdisplay z[E(Y|do(x/prime, z))−E(Y|do(x, z))]P(z|do(x)). (48) The intuition is simple; the natural direct eﬀect is the weig hted average of the controlled direct eﬀect ( 46), using the causal eﬀect P(z|do(x)) as a weighing function. One suﬃcient condition for the identiﬁcation of ( 47) is that Zx⊥ ⊥Yx/prime,z|W holds for some set Wof measured covariates. However, this condition in itself, like the ignorability condition of ( 42), is close to meaningless for most investiga- tors, as it is not phrased in terms of realized variables. The symbiotic analysis of Section 4.3can be invoked at this point to unveil the graphical interpre tation of this condition (through Eq. ( 45).) It states that Wshould be admissible (i.e., satisfy the back-door condition) relative the path(s) from ZtoY. This condition is readily comprehended by empirical researchers, and the t ask of selecting such measurements, W, can then be guided by the available scientiﬁc knowledge. Se e details and graphical criteria in Pearl (2001,2005) and in Petersen et al. (2006). In particular, expression ( 48) is both valid and identiﬁable in Markovian models, where each term on the right can be reduced to a “ do-free” expression using Eq. ( 24).\n\n\n5.1.3. Indirect eﬀects and the Mediation Formula\nRemarkably, the deﬁnition of the natural direct eﬀect ( 47) can easily be turned around and provide an operational deﬁnition for the indirect eﬀect – a concept shrouded in mystery and controversy, because it is impossib le, using the do(x) operator, to disable the direct link from XtoYso as to let Xinﬂuence Ysolely via indirect paths. The natural indirect eﬀect, IE, of the transition from xtox/primeis deﬁned as the expected change in Yaﬀected by holding Xconstant, at X=x, and changing Zto whatever value it would have attained had Xbeen set to X=x/prime. Formally, this reads ( Pearl,2001): IEx,x/prime(Y)∆=E((Yx,Zx/prime)−E(Yx)), (49) which is almost identical to the direct eﬀect (Eq. ( 47)) save for exchanging x andx/prime. Indeed, it can be shown that, in general, the total eﬀect TEof a transition is equal to the diﬀerence between the direct eﬀect of that transition and the indirect eﬀect of the reverse transition. Formally, TEx,x/prime(Y)∆=E(Yx/prime−Yx) =DEx,x/prime(Y)−IEx/prime,x(Y). (50) In linear systems, where reversal of transitions amounts to negating the signs of their eﬀects, we have the standard additive formula TEx,x/prime(Y) =DEx,x/prime(Y) +IEx,x/prime(Y). (51) Since each term above is based on an independent operational deﬁnition, this equality constitutes a formal justiﬁcation for the additiv e formula used routinely in linear systems. For completeness, we explicate (from ( 48) and ( 51)) the expression for indirect eﬀects under conditions of nonconfoundedness: IEx,x/prime(Y) =/summationdisplay zE(Y|x, z)[P(z|x/prime)−P(z|x)] (52) This expression deserves the label Mediation Formula , due to its pivotal role in mediation analysis ( Imai et al. ,2008), which has been a thorny issue in several sciences ( Shrout and Bolger ,2002;MacKinnon et al. ,2007;Mortensen et al. , 2009). When the outcome Yis binary (e.g., recovery, or hiring) the ratio (1 − IE)/TE represents the fraction of responding individuals who owe t heir re- sponse to direct paths, while (1 −DE)/TErepresents the fraction who owe their response to Z-mediated paths. In addition to providing researchers with a principled, parametric-free target quantity that is valid in both linear and non- linear models, the formula can also serve as an analytical la boratory for testing the eﬀectiveness of various estimation techniques under va rious types of model mispeciﬁcation ( VanderWeele ,2009). Note that, although it cannot be expressed in do-notation, the indirect eﬀect has clear policy-making implications. For example: in the h iring discrimination context, a policy maker may be interested in predicting the g ender mix in the work force if gender bias is eliminated and all applicants ar e treated equally— say, the same way that males are currently treated. This quan tity will be given by the indirect eﬀect of gender on hiring, mediated by factor s such as education and aptitude, which may be gender-dependent. More generally, a policy maker may be interested in the eﬀect of issuing a directive to a select set of subordinate employees, or in car efully controlling the routing of messages in a network of interacting agents. S uch applications motivate the analysis of path-speciﬁc eﬀects , that is, the eﬀect of XonYthrough a selected set of paths ( Avin et al. ,2005). Note that in all these cases, the policy intervention invoke s the selection of signals to be sensed, rather than variables to be ﬁxed. Pearl (2001) has suggested therefore that signal sensing is more fundamental to the notion of causation thanmanipulation ; the latter being but a crude way of testing the former in experimental setup. The mantra “No causation without manip ulation” must be rejected. (See ( Pearl,2000a , Section 11.4.5.).) It is remarkable that counterfactual quantities like DEandIDthat could not be expressed in terms of do(x) operators, and appear therefore void of empiri- cal content, can, under certain conditions be estimated fro m empirical studies. A general characterization of those conditions is given in ( Shpitser and Pearl , 2007). Additional examples of this “marvel of formal analysis” are given in the next section and in ( Pearl,2000a , Chapters 7, 9, 11). It constitutes an unassailable argument in defense of counterfactual analysis, as express ed in Pearl (2000b ) against the stance of Dawid (2000).\n\n\n\n5.2. Causes of eﬀects and probabilities of causation\nThe likelihood that one event was the cause of another guides much of what we understand about the world (and how we act in it). For examp le, knowing whether it was the aspirin that cured my headache or the TV pro gram I was watching would surely aﬀect my future use of aspirin. Likewi se, to take an example from common judicial standard, judgment in favor of a plaintiﬀ should be made if and only if it is “more probable than not” that the da mage would not have occurred but for the defendant’s action ( Robertson ,1997). These two examples fall under the category of “causes of eﬀec ts” because they concern situations in which we observe both the eﬀect, Y=y, and the putative cause X=xand we are asked to assess, counterfactually, whether the former would have occurred absent the latter. We have remarked earlier (footnote 11) that counterfactual probabilities con- ditioned on the outcome cannot in general be identiﬁed from o bservational or even experimental studies. This does not mean however that s uch probabilities are useless or void of empirical content; the structural per spective may guide us in fact toward discovering the conditions under which the y can be assessed from data, thus deﬁning the empirical content of these count erfactuals. Following the 4-step process of structural methodology – de ﬁne, assume, iden- tify, and estimate – our ﬁrst step is to express the target qua ntity in counterfac- tual notation and verify that it is well deﬁned, namely, that it can be computed unambiguously from any fully-speciﬁed causal model. In our case, this step is simple. Assuming binary events, wit hX=xand Y=yrepresenting treatment and outcome, respectively, and X=x/prime,Y=y/prime their negations, our target quantity can be formulated dire ctly from the English sentence: “Find the probability that Ywould be y/primehadXbeen x/prime, given that, in reality, Yis actually yandXisx,” to give: PN(x, y) =P(Yx/prime=y/prime|X=x, Y=y) (53) This counterfactual quantity, which Robins and Greenland (1989a ) named “probability of causation” and Pearl (2000a , p. 296) named “probability of ne- cessity” (PN), to be distinguished from other nuances of “ca usation,” is certainly computable from any fully speciﬁed structural model, i.e., one in which P(u) and all functional relationships are given. This follows fr om the fact that every structural model deﬁnes a joint distribution of counterfac tuals, through Eq. ( 27). Having written a formal expression for PN, Eq. ( 53), we can move on to the formulation and identiﬁcation phases and ask what assumpti ons would permit us to identify PN from empirical studies, be they observatio nal, experimental or a combination thereof. This problem was analyzed by Pearl (2000a , Chapter 9) and yielded the following results: Theorem 3. IfYis monotonic relative to X, i.e., Y1(u)≥Y0(u), then PNis identiﬁable whenever the causal eﬀect P(y|do(x))is identiﬁable and, moreover, PN =P(y|x)−P(y|x/prime) P(y|x)+P(y|x/prime)−P(y|do(x/prime)) P(x, y). (54) The ﬁrst term on the r.h.s. of ( 54) is the familiar excess risk ratio (ERR) that epidemiologists have been using as a surrogate for PN in court cases ( Cole, 1997;Robins and Greenland ,1989a ). The second term represents the correction needed to account for confounding bias, that is, P(y|do(x/prime))/negationslash=P(y|x/prime). This suggests that monotonicity and unconfoundedness were tacitly assumed by the many authors who proposed or derived ERR as a measure fo r the “frac- tion of exposed cases that are attributable to the exposure” (Greenland ,1999). Equation ( 54) thus provides a more reﬁned measure of causation, which can be used in situations where the causal eﬀect P(y|do(x)) can be estimated from either randomized trials or graph-assisted observational studies (e.g., through Theorem 2or Eq. ( 25)). It can also be shown ( Tian and Pearl ,2000) that the expression in ( 54) provides a lower bound for PN in the general, nonmonotonic case. (See also ( Robins and Greenland ,1989b ).) In particular, the tight upper and lower bounds on PN are given by: max/braceleftBig 0,P(y)−P(y|do(x/prime)) P(x,y)/bracerightBig ≤PN≤min/braceleftBig 1,P(y/prime|do(x/prime))−P(x/prime,y/prime) P(x,y)/bracerightBig (55) It is worth noting that, in drug related litigation, it is not uncommon to obtain data from both experimental and observational studi es. The former is usually available at the manufacturer or the agency that app roved the drug for distribution (e.g., FDA), while the latter is easy to obtain by random surveys of the population. In such cases, the standard lower bound used by epidemiologists to establish legal responsibility, the Excess Risk Ratio, c an be substantially im- proved using the lower bound of Eq. ( 55). Likewise, the upper bound of Eq. ( 55) can be used to exonerate drug-makers from legal responsibil ity.Cai and Kuroki (2006) analyzed the statistical properties of PN. Pearl (2000a , p. 302) shows that combining data from experimental and ob- servational studies which, taken separately, may indicate no causal relations between XandY, can nevertheless bring the lower bound of Eq. ( 55) to unity, thus implying causation with probability one . Such extreme results dispel all fears and trepidations conc erning the empir- ical content of counterfactuals ( Dawid ,2000;Pearl,2000b ). They demonstrate that a quantity PN which at ﬁrst glance appears to be hypothet ical, ill-deﬁned, untestable and, hence, unworthy of scientiﬁc analysis is ne vertheless deﬁnable, testable and, in certain cases, even identiﬁable. Moreover , the fact that, under certain combination of data, and making no assumptions what soever, an im- portant legal claim such as “the plaintiﬀ would be alive had h e not taken the drug” can be ascertained with probability one, is a remarkab le tribute to formal analysis. Another counterfactual quantity that has been fully charac terized recently is the Eﬀect of Treatment on the Treated (ETT): ETT =P(Yx=y|X=x/prime) ETT has been used in econometrics to evaluate the eﬀectivene ss of social pro- grams on their participants ( Heckman ,1992) and has long been the target of research in epidemiology, where it came to be known as “the eﬀ ect of exposure on the exposed,” or “standardized morbidity” ( Miettinen ,1974; Greenland and Robins, 1986). Shpitser and Pearl (2009) have derived a complete characterization of those models in which ETT can be identiﬁed from either experimenta l or observa- tional studies. They have shown that, despite its blatant co unterfactual char- acter, (e.g., “I just took an aspirin, perhaps I shouldn’t ha ve?”) ETT can be evaluated from experimental studies in many, though not all cases. It can also be evaluated from observational studies whenever a suﬃcien t set of covariates can be measured that satisﬁes the back-door criterion and, m ore generally, in a wide class of graphs that permit the identiﬁcation of condit ional interventions. These results further illuminate the empirical content of c ounterfactuals and their essential role in causal analysis. They prove once aga in the triumph of logic and analysis over traditions that a-priori exclude from the analysis quantities that are not testable in isolation. Most of all, they demonst rate the eﬀective- ness and viability of the scientiﬁc approach to causation whereby the dominant paradigm is to model the activities of Nature, rather than th ose of the experi- menter. In contrast to the ruling paradigm of conservative s tatistics, we begin with relationships that we know in advance will never be esti mated, tested or falsiﬁed. Only after assembling a host of such relationship s and judging them to faithfully represent our theory about how Nature operates, we ask whether the parameter of interest, crisply deﬁned in terms of those theo retical relationships, can be estimated consistently from empirical data and how. I t often does, to the credit of progressive statistics.",
    "crumbs": [
      "Causal Inference",
      "Causal inference in statistics"
    ]
  },
  {
    "objectID": "extracted/Causal inference in statistics An overview2.html#conclusions",
    "href": "extracted/Causal inference in statistics An overview2.html#conclusions",
    "title": "Causal inference in statistics",
    "section": "6. Conclusions",
    "text": "6. Conclusions\nTraditional statistics is strong in devising ways of descri bing data and infer- ring distributional parameters from sample. Causal infere nce requires two ad- ditional ingredients: a science-friendly language for art iculating causal knowl- edge, and a mathematical machinery for processing that know ledge, combining it with data and drawing new causal conclusions about a pheno menon. This paper surveys recent advances in causal analysis from the un ifying perspective of the structural theory of causation and shows how statisti cal methods can be supplemented with the needed ingredients. The theory invok es non-parametric structural equations models as a formal and meaningful lang uage for deﬁning causal quantities, formulating causal assumptions, testi ng identiﬁability, and ex- plicating many concepts used in causal discourse. These inc lude: randomization, intervention, direct and indirect eﬀects, confounding, co unterfactuals, and attri- bution. The algebraic component of the structural language coincides with the potential-outcome framework, and its graphical component embraces Wright’s method of path diagrams. When uniﬁed and synthesized, the tw o components oﬀer statistical investigators a powerful and comprehensi ve methodology for empirical research.",
    "crumbs": [
      "Causal Inference",
      "Causal inference in statistics"
    ]
  },
  {
    "objectID": "extracted/Causal inference in statistics An overview2.html#references",
    "href": "extracted/Causal inference in statistics An overview2.html#references",
    "title": "Causal inference in statistics",
    "section": "References",
    "text": "References\nAngrist, J. andImbens, G. (1991). Source of identifying information in eval- uation models. Tech. Rep. Discussion Paper 1568, Departmen t of Economics, Harvard University, Cambridge, MA. Angrist, J. ,Imbens, G. andRubin, D. (1996). Identiﬁcation of causal ef- fects using instrumental variables (with comments). Journal of the American Statistical Association 91444–472. Arah, O. (2008). The role of causal reasoning in understanding Simp- son’s paradox, Lord’s paradox, and the suppression eﬀect: C ovariate se- lection in the analysis of observational studies. Emerging Themes in Epidemiology 4doi:10.1186/1742–7622–5–5. Online at &lt;http://www.ete- online.com/content/5/1/5 &gt;. Arjas, E. andParner, J. (2004). Causal reasoning from longitudinal data. Scandinavian Journal of Statistics 31171–187. Avin, C. ,Shpitser, I. andPearl, J. (2005). Identiﬁability of path-speciﬁc eﬀects. In Proceedings of the Nineteenth International Joint Confere nce on Artiﬁcial Intelligence IJCAI-05 . Morgan-Kaufmann Publishers, Edinburgh, UK. Balke, A. andPearl, J. (1995). Counterfactuals and policy analysis in struc- tural models. In Uncertainty in Artiﬁcial Intelligence 11 (P. Besnard and S. Hanks, eds.). Morgan Kaufmann, San Francisco, 11–18. Balke, A. andPearl, J. (1997). Bounds on treatment eﬀects from studies with imperfect compliance. Journal of the American Statistical Association 921172–1176. Berkson, J. (1946). Limitations of the application of fourfold table an alysis to hospital data. Biometrics Bulletin 247–53. Bishop, Y. ,Fienberg, S. andHolland, P. (1975). Discrete multivariate analysis: theory and practice . MIT Press, Cambridge, MA. Blyth, C. (1972). On Simpson’s paradox and the sure-thing principle. Journal of the American Statistical Association 67364–366. Bollen, K. (1989). Structural Equations with Latent Variables . John Wiley, New York. Bonet, B. (2001). Instrumentality tests revisited. In Proceedings of the Sev- enteenth Conference on Uncertainty in Artiﬁcial Intellige nce. Morgan Kauf- mann, San Francisco, CA, 48–55. Bowden, R. andTurkington, D. (1984). Instrumental Variables . Cambridge University Press, Cambridge, England. Brent, R. andLok, L. (2005). A ﬁshing buddy for hypothesis generators. Science 308523–529. Cai, Z. andKuroki, M. (2006). Variance estimators for three ‘probabilities of causation’. Risk Analysis 251611–1620. Chalak, K. andWhite, H. (2006). An extended class of instrumental variables for the estimation of causal eﬀects. Tech. Rep. Discussion P aper, UCSD, Department of Economics. Chen, A. ,Bengtsson, T. andHo, T. (2009). A regression paradox for linear models: Suﬃcient conditions and relation to Simpson’s para dox.The Ameri- can Statistician 63218–225. Chickering, D. andPearl, J. (1997). A clinician’s tool for analyzing non- compliance. Computing Science and Statistics 29424–431. Cole, P. (1997). Causality in epidemiology, health policy, and law. Journal of Marketing Research 2710279–10285. Cole, S. andHern´an, M. (2002). Fallibility in estimating direct eﬀects. In- ternational Journal of Epidemiology 31163–165. Cox, D. (1958). The Planning of Experiments . John Wiley and Sons, NY. Cox, D. andWermuth, N. (2003). A general condition for avoiding eﬀect reversal after marginalization. Journal of the Royal Statistical Society, Series B (Statistical Methodology) 65937–941. Cox, D. andWermuth, N. (2004). Causality: A statistical view. International Statistical Review 72285–305. Dawid, A. (1979). Conditional independence in statistical theory. Journal of the Royal Statistical Society, Series B 411–31. Dawid, A. (2000). Causal inference without counterfactuals (with co mments and rejoinder). Journal of the American Statistical Association 95407–448. Dawid, A. (2002). Inﬂuence diagrams for causal modelling and inferen ce.In- ternational Statistical Review 70161–189. DeFinetti, B. (1974). Theory of Probability: A Critical Introductory Treat- ment. Wiley, London. 2 volumes. Translated by A. Machi and A. Smit h. Duncan, O. (1975). Introduction to Structural Equation Models . Academic Press, New York. Eells, E. (1991). Probabilistic Causality . Cambridge University Press, Cam- bridge, MA. Frangakis, C. andRubin, D. (2002). Principal stratiﬁcation in causal infer- ence.Biometrics 121–29. Glymour, M. andGreenland, S. (2008). Causal diagrams. In Modern Epi- demiology (K. Rothman, S. Greenland and T. Lash, eds.), 3rd ed. Lippinc ott Williams & Wilkins, Philadelphia, PA, 183–209. Goldberger, A. (1972). Structural equation models in the social sciences. Econometrica: Journal of the Econometric Society 40979–1001. Goldberger, A. (1973). Structural equation models: An overview. In Struc- tural Equation Models in the Social Sciences (A. Goldberger and O. Duncan, eds.). Seminar Press, New York, NY, 1–18. Good, I. andMittal, Y. (1987). The amalgamation and geometry of two-by- two contingency tables. The Annals of Statistics 15694–711. Greenland, S. (1999). Relation of probability of causation, relative ris k, and doubling dose: A methodologic error that has become a social problem. Amer- ican Journal of Public Health 891166–1169. Greenland, S. ,Pearl, J. andRobins, J. (1999). Causal diagrams for epi- demiologic research. Epidemiology 1037–48. Greenland, S. andRobins, J. (1986). Identiﬁability, exchangeability, and epidemiological confounding. International Journal of Epidemiology 15413– ## 419. Haavelmo, T. (1943). The statistical implications of a system of simulta neous equations. Econometrica 111–12. Reprinted in D.F. Hendry and M.S. Mor- gan (Eds.), The Foundations of Econometric Analysis , Cambridge University Press, 477–490, 1995. Hafeman, D. andSchwartz, S. (2009). Opening the black box: A motivation for the assessment of mediation. International Journal of Epidemiology 3 838–845. Heckman, J. (1992). Randomization and social policy evaluation. In Evalu- ations: Welfare and Training Programs (C. Manski and I. Garﬁnkle, eds.). Harvard University Press, Cambridge, MA, 201–230. Heckman, J. (2008). Econometric causality. International Statistical Review 761–27. Heckman, J. andNavarro-Lozano, S. (2004). Using matching, instrumental variables, and control functions to estimate economic choi ce models. The Review of Economics and Statistics 8630–57. Heckman, J. andVytlacil, E. (2005). Structural equations, treatment eﬀects and econometric policy evaluation. Econometrica 73669–738. Holland, P. (1988). Causal inference, path analysis, and recursive str uctural equations models. In Sociological Methodology (C. Clogg, ed.). American Sociological Association, Washington, D.C., 449–484. Hurwicz, L. (1950). Generalization of the concept of identiﬁcation. In Sta- tistical Inference in Dynamic Economic Models (T. Koopmans, ed.). Cowles Commission, Monograph 10, Wiley, New York, 245–257. Imai, K. ,Keele, L. andYamamoto, T. (2008). Identiﬁcation, inference, and sensitivity analysis for causal mediation eﬀects. Tech. re p., Department of Politics, Princton University. Imbens, G. andWooldridge, J. (2009). Recent developments in the econo- metrics of program evaluation. Journal of Economic Literature 47. Kiiveri, H. ,Speed, T. andCarlin, J. (1984). Recursive causal models. Journal of Australian Math Society 3630–52. Koopmans, T. (1953). Identiﬁcation problems in econometric model const ruc- tion. In Studies in Econometric Method (W. Hood and T. Koopmans, eds.). Wiley, New York, 27–48. Kuroki, M. andMiyakawa, M. (1999). Identiﬁability criteria for causal eﬀects of joint interventions. Journal of the Royal Statistical Society 29105–117. Lauritzen, S. (1996). Graphical Models . Clarendon Press, Oxford. Lauritzen, S. (2001). Causal inference from graphical models. In Com- plex Stochastic Systems (D. Cox and C. Kluppelberg, eds.). Chapman and Hall/CRC Press, Boca Raton, FL, 63–107. Lindley, D. (2002). Seeing and doing: The concept of causation. International Statistical Review 70191–214. Lindley, D. andNovick, M. (1981). The role of exchangeability in inference. The Annals of Statistics 945–58. MacKinnon, D. ,Fairchild, A. andFritz, M. (2007). Mediation analysis. Annual Review of Psychology 58593–614. Manski, C. (1990). Nonparametric bounds on treatment eﬀects. American Economic Review, Papers and Proceedings 80319–323. Marschak, J. (1950). Statistical inference in economics. In Statistical Inference in Dynamic Economic Models (T. Koopmans, ed.). Wiley, New York, 1–50. Cowles Commission for Research in Economics, Monograph 10. Meek, C. andGlymour, C. (1994). Conditioning and intervening. British Journal of Philosophy Science 451001–1021. Miettinen, O. (1974). Proportion of disease caused or prevented by a given exposure, trait, or intervention. Journal of Epidemiology 99325–332. Morgan, S. andWinship, C. (2007). Counterfactuals and Causal Inference: Methods and Principles for Social Research (Analytical Met hods for Social Research) . Cambridge University Press, New York, NY. Mortensen, L. ,Diderichsen, F. ,Smith, G. andAndersen, A. (2009). The social gradient in birthweight at term: quantiﬁcation of th e mediating role of maternal smoking and body mass index. Human Reproduction To appear, doi:10.1093/humrep/dep211. Neyman, J. (1923). On the application of probability theory to agricul tural experiments. Essay on principles. Section 9. Statistical Science 5465–480. Pavlides, M. andPerlman, M. (2009). How likely is Simpson’s paradox? The American Statistician 63226–233. Pearl, J. (1988). Probabilistic Reasoning in Intelligent Systems . Morgan Kauf- mann, San Mateo, CA. Pearl, J. (1993a). Comment: Graphical models, causality, and interv ention. Statistical Science 8266–269. Pearl, J. (1993b). Mediating instrumental variables. Tech. Rep. TR- 210, &lt;http://ftp.cs.ucla.edu/pub/stat ser/R210.pdf &gt;, Department of Computer Science, University of California, Los Angeles. Pearl, J. (1995a). Causal diagrams for empirical research. Biometrika 82 669–710. Pearl, J. (1995b). On the testability of causal models with latent and instru- mental variables. In Uncertainty in Artiﬁcial Intelligence 11 (P. Besnard and S. Hanks, eds.). Morgan Kaufmann, San Francisco, CA, 435–44 3. Pearl, J. (1998). Graphs, causality, and structural equation models .Sociolog- ical Methods and Research 27226–284. Pearl, J. (2000a). Causality: Models, Reasoning, and Inference . Cambridge University Press, New York. 2nd edition, 2009. Pearl, J. (2000b). Comment on A.P. Dawid’s, Causal inference without coun- terfactuals. Journal of the American Statistical Association 95428–431. Pearl, J. (2001). Direct and indirect eﬀects. In Proceedings of the Seventeenth Conference on Uncertainty in Artiﬁcial Intelligence . Morgan Kaufmann, San Francisco, CA, 411–420. Pearl, J. (2003). Statistics and causal inference: A review. Test Journal 12 281–345. Pearl, J. (2005). Direct and indirect eﬀects. In Proceedings of the American Statistical Association, Joint Statistical Meetings . MIRA Digital Publishing, Minn., MN, 1572–1581. Pearl, J. (2009a). Causality: Models, Reasoning, and Inference . 2nd ed. Cam- bridge University Press, New York. Pearl, J. (2009b). Letter to the editor: Remarks on the method of propensity scores. Statistics in Medicine 281415–1416. &lt;http://ftp.cs.ucla.edu/pub/stat ser/r345-sim.pdf &gt;. Pearl, J. (2009c). Myth, confusion, and science in causal analy- sis. Tech. Rep. R-348, University of California, Los Angele s, CA. &lt;http://ftp.cs.ucla.edu/pub/stat ser/r348.pdf &gt;. Pearl, J. andPaz, A. (2009). Confounding equivalence in observational studies. Tech. Rep. TR-343, University of California, Los A ngeles, CA. &lt;http://ftp.cs.ucla.edu/pub/stat ser/r343.pdf &gt;. Pearl, J. andRobins, J. (1995). Probabilistic evaluation of sequential plans from causal models with hidden variables. In Uncertainty in Artiﬁcial Intelli- gence 11 (P. Besnard and S. Hanks, eds.). Morgan Kaufmann, San Franci sco, 444–453. Pearl, J. andVerma, T. (1991). A theory of inferred causation. In Princi- ples of Knowledge Representation and Reasoning: Proceedin gs of the Second International Conference (J. Allen, R. Fikes and E. Sandewall, eds.). Morgan Kaufmann, San Mateo, CA, 441–452. Pearson, K. ,Lee, A. andBramley-Moore, L. (1899). Genetic (reproduc- tive) selection: Inheritance of fertility in man. Philosophical Transactions of the Royal Society A 73534–539. Petersen, M. ,Sinisi, S. andvan der Laan, M. (2006). Estimation of direct causal eﬀects. Epidemiology 17276–284. Robertson, D. (1997). The common sense of cause in fact. Texas Law Review 751765–1800. Robins, J. (1986). A new approach to causal inference in mortality stud ies with a sustained exposure period – applications to control of the healthy workers survivor eﬀect. Mathematical Modeling 71393–1512. Robins, J. (1987). A graphical approach to the identiﬁcation and estim ation of causal parameters in mortality studies with sustained ex posure periods. Journal of Chronic Diseases 40139S–161S. Robins, J. (1989). The analysis of randomized and non-randomized aids treat- ment trials using a new approach to causal inference in longi tudinal studies. In Health Service Research Methodology: A Focus on AIDS (L. Sechrest, H. Free- man and A. Mulley, eds.). NCHSR, U.S. Public Health Service, Washington, D.C., 113–159. Robins, J. (1999). Testing and estimation of directed eﬀects by repara meter- izing directed acyclic with structural nested models. In Computation, Cau- sation, and Discovery (C. Glymour and G. Cooper, eds.). AAAI/MIT Press, Cambridge, MA, 349–405. Robins, J. (2001). Data, design, and background knowledge in etiologi c infer- ence.Epidemiology 12313–320. Robins, J. andGreenland, S. (1989a). The probability of causation under a stochastic model for individual risk. Biometrics 451125–1138. Robins, J. andGreenland, S. (1989b). Estimability and estimation of excess and etiologic fractions. Statistics in Medicine 8845–859. Robins, J. andGreenland, S. (1992). Identiﬁability and exchangeability for direct and indirect eﬀects. Epidemiology 3143–155. Rosenbaum, P. (2002). Observational Studies . 2nd ed. Springer-Verlag, New York. Rosenbaum, P. andRubin, D. (1983). The central role of propensity score in observational studies for causal eﬀects. Biometrika 7041–55. Rothman, K. (1976). Causes. American Journal of Epidemiology 104587–592. Rubin, D. (1974). Estimating causal eﬀects of treatments in randomiz ed and nonrandomized studies. Journal of Educational Psychology 66688–701. Rubin, D. (2004). Direct and indirect causal eﬀects via potential out comes. Scandinavian Journal of Statistics 31161–170. Rubin, D. (2005). Causal inference using potential outcomes: Design , modeling, decisions. Journal of the American Statistical Association 100322–331. Rubin, D. (2007). The design versus the analysis of observational studies for causal eﬀects: Parallels with the design of randomized tria ls.Statistics in Medicine 2620–36. Rubin, D. (2009). Author’s reply: Should observational studies be de signed to allow lack of balance in covariate distributions across t reatment group? Statistics in Medicine 281420–1423. Shpitser, I. andPearl, J. (2006). Identiﬁcation of conditional interventional distributions. In Proceedings of the Twenty-Second Conference on Uncertaint y in Artiﬁcial Intelligence (R. Dechter and T. Richardson, eds.). AUAI Press, Corvallis, OR, 437–444. Shpitser, I. andPearl, J. (2007). What counterfactuals can be tested. In Proceedings of the Twenty-Third Conference on Uncertainty in Artiﬁcial In- telligence . AUAI Press, Vancouver, BC, Canada, 352–359. Also, Journal of Machine Learning Research , 9:1941–1979, 2008. Shpitser, I. andPearl, J. (2008). Dormant independence. In Proceedings of the Twenty-Third Conference on Artiﬁcial Intelligence . AAAI Press, Menlo Park, CA, 1081–1087. Shpitser, I. andPearl, J. (2009). Eﬀects of treatment on the treated: Iden- tiﬁcation and generalization. In Proceedings of the Twenty-Fifth Conference on Uncertainty in Artiﬁcial Intelligence . AUAI Press, Montreal, Quebec. Shrier, I. (2009). Letter to the editor: Propensity scores. Statistics in Medicine 281317–1318. See also Pearl 2009 &lt;http://ftp.cs.ucla.edu/pub/stat ser/r348.pdf &gt;. Shrout, P. andBolger, N. (2002). Mediation in experimental and non- experimental studies: New procedures and recommendations .Psychological Methods 7422–445. Simon, H. (1953). Causal ordering and identiﬁability. In Studies in Econometric Method (W. C. Hood and T. Koopmans, eds.). Wiley and Sons, Inc., New York, NY, 49–74. Simon, H. andRescher, N. (1966). Cause and counterfactual. Philosophy and Science 33323–340. Simpson, E. (1951). The interpretation of interaction in contingency t ables. Journal of the Royal Statistical Society, Series B 13238–241. Sobel, M. (1998). Causal inference in statistical models of the proce ss of socioeconomic achievement. Sociological Methods & Research 27318–348. Sobel, M. (2008). Identiﬁcation of causal parameters in randomized s tudies with mediating variables. Journal of Educational and Behavioral Statistics 33230–231. Spirtes, P. ,Glymour, C. andScheines, R. (1993). Causation, Prediction, and Search . Springer-Verlag, New York. Spirtes, P. ,Glymour, C. andScheines, R. (2000). Causation, Prediction, and Search . 2nd ed. MIT Press, Cambridge, MA. Stock, J. andWatson, M. (2003). Introduction to Econometrics . Addison Wesley, New York. Strotz, R. andWold, H. (1960). Recursive versus nonrecursive systems: An attempt at synthesis. Econometrica 28417–427. Suppes, P. (1970). A Probabilistic Theory of Causality . North-Holland Pub- lishing Co., Amsterdam. Tian, J. ,Paz, A. andPearl, J. (1998). Finding minimal separating sets. Tech. Rep. R-254, University of California, Los Angeles, CA . Tian, J. andPearl, J. (2000). Probabilities of causation: Bounds and identi- ﬁcation. Annals of Mathematics and Artiﬁcial Intelligence 28287–313. Tian, J. andPearl, J. (2002). A general identiﬁcation condition for causal eﬀects. In Proceedings of the Eighteenth National Conference on Artiﬁ cial Intelligence . AAAI Press/The MIT Press, Menlo Park, CA, 567–573. VanderWeele, T. (2009). Marginal structural models for the estimation of direct and indirect eﬀects. Epidemiology 2018–26. VanderWeele, T. andRobins, J. (2007). Four types of eﬀect modiﬁcation: A classiﬁcation based on directed acyclic graphs. Epidemiology 18561–568. Wasserman, L. (2004). All of Statistics: A Concise Course in Statistical In- ference . Springer Science+Business Media, Inc., New York, NY. Wermuth, N. (1992). On block-recursive regression equations. Brazilian Jour- nal of Probability and Statistics (with discussion) 61–56. Wermuth, N. andCox, D. (1993). Linear dependencies represented by chain graphs. Statistical Science 8204–218. Whittaker, J. (1990). Graphical Models in Applied Multivariate Statistics . John Wiley, Chichester, England. Woodward, J. (2003). Making Things Happen . Oxford University Press, New York, NY. Wooldridge, J. (2002). Econometric Analysis of Cross Section and Panel Data. MIT Press, Cambridge and London. Wooldridge, J. (2009). Should instrumental vari- ables be used as matching variables? Tech. Rep. &lt;https://www.msu.edu/ ∼ec/faculty/wooldridge/current%20research/treat1r6.p df&gt;, Michigan State University, MI. Wright, S. (1921). Correlation and causation. Journal of Agricultural Research 20557–585. Yule, G. (1903). Notes on the theory of association of attributes in s tatistics. Biometrika 2121–134.",
    "crumbs": [
      "Causal Inference",
      "Causal inference in statistics"
    ]
  },
  {
    "objectID": "extracted/Jack_Martin10.html",
    "href": "extracted/Jack_Martin10.html",
    "title": "Reinterpreting Internalization and Agency through G.H. Mead’s Perspectival Realism",
    "section": "",
    "text": "Human Development 2006;49:65–86 DOI: 10.1159/000091333",
    "crumbs": [
      "General",
      "Reinterpreting Internalization and Agency through G.H. Mead’s Perspectival Realism"
    ]
  },
  {
    "objectID": "extracted/Jack_Martin10.html#reinterpreting-internalization-and-agency-through-g.h.-meads-perspectival-realism",
    "href": "extracted/Jack_Martin10.html#reinterpreting-internalization-and-agency-through-g.h.-meads-perspectival-realism",
    "title": "Reinterpreting Internalization and Agency through G.H. Mead’s Perspectival Realism",
    "section": "Reinterpreting Internalization and Agency through G.H. Mead’s Perspectival Realism",
    "text": "Reinterpreting Internalization and Agency through G.H. Mead’s Perspectival Realism\nJack Martin\nSimon Fraser University, Burnaby , Canada Key Words Agency (cid:1) G.H. Mead (cid:1) Internalization (cid:1) Perspective taking (cid:1) Social ontology",
    "crumbs": [
      "General",
      "Reinterpreting Internalization and Agency through G.H. Mead’s Perspectival Realism"
    ]
  },
  {
    "objectID": "extracted/Jack_Martin10.html#abstract",
    "href": "extracted/Jack_Martin10.html#abstract",
    "title": "Reinterpreting Internalization and Agency through G.H. Mead’s Perspectival Realism",
    "section": "Abstract",
    "text": "Abstract\nToward the end of his life, George Herbert Mead developed a theory of perspec- tives that may be used to reinterpret his social, developmental psychology. This paper attempts such a reinterpretation, leading to the emergence of a theory of perspective taking in early childhood that looks quite diff erent from that which is assumed in most extant work in developmental psychology. Theoretical and empirical implications of Mead’s perspectivism and perspective taking are also explored, with particular focus on questions of internalization and agency. In addition, important distinctions are drawn between Mead’s view of human development and most contemporary theories.\nCopyright © 2006 S. Karger AG, Basel\nVarious conceptions of internalization and agency can be found in the contem- porary literature of developmental psychology, but relatively little consensus has been achieved concerning their specifi c nature and role in the development of the minds and selves of human beings during ontogenesis [Chapman, 1999; Martin, Sugarman, & Thompson, 2003; Nicolopoulou & Weintraub, 1998]. Broadly speak- ing, internalization refers to a collection of social, psychological processes whereby public linguistic and other social, relational phenomena somehow are transformed into private cognitive and other psychological phenomena [e.g., Vygotsky, 1934/ 1986]. In similar broad strokes, agency typically is formulated as a kind of self-de- termination that is itself determined by sociocultural and biophysical structures and processes, yet is not entirely reducible to such non-psychological systems [e.g., Bruner, 1990]. In recent years, a number of developmentalists have proposed theo- ries of self-development that assume conceptions of internalization and agency that attempt to avoid overly strong forms of psychological constructivism on the one hand, and overly strong forms of social constructionism on the other [e.g., Bickhard, 2004; Harré, 1998, 2004; Tomasello, 1999]. These theoretical positions understand social interactivity and communication as developmentally indispensable to, and in many ways constitutive of, psychological personhood. Yet, they leave room for the exercise of rational and moral agency, whereby individuals can control (at least to some extent) and be held accountable for their actions. Such views are frequently associated with the theorizing of Vygotsky [1934/1986, 1978], sometimes with the work of Piaget [e.g., Carpendale & Lewis, 2004; Chapman, 1991, 1999], and occa- sionally with the body of ideas articulated by George Herbert Mead [1932/2002, 1934, 1938].\nIn developmental psychology, especially in more recent years, Mead’s interac- tionist view of the self-societal dialectic has been both endorsed as an early relation- al theory of the development of mind and consciousness through participation with others [e.g., Marková, 1987], and derided as a form of social determinism that dis- places genuinely moral and rational forms of human agency [e.g., Davidson & Youniss, 1995]. More recently, Mead’s work has received brief and passing mention in major volumes concerned with the social and cultural origins of human thought, mind, and selfhood [e.g., Hobson, 2002; Tomasello, 1999]. Such differential and ab- breviated treatment is understandable given the well-know diffi culties in interpret- ing Mead’s oeuvre. Much of it is derived from lectures and unpublished fragments that have been preserved and published through the note taking and editing of oth- ers. Mead also seems to have championed somewhat different views in different writings. It is thus not surprising that Mead scholars have offered several interpreta- tions of his work [e.g., Blumer, 1980; Cook, 1993; Gillespie, 2005; Joas, 1997; Wiley, 1995].\nHerein, Mead is interpreted as a perspectival realist who had a great deal to say that is highly relevant to contemporary debates and questions within developmental psychology concerning internalization and agency. In what follows, it will be main- tained that Mead’s theory of perspective taking offers a viable, alternative account of internalization that is both theoretically progressive and empirically suggestive.\nMoreover, this is an account that provides a plausible compatibilist interpretation of agency as both determined and determining, in the societal-personal, co-constitu- tive manner seemingly desired by many developmentalists [e.g., Bruner, 1990; Ro- goff, 1992; Valsiner, 1991].\nConsequently, what follows, while centrally concerned with perspective taking, is not in any way intended as a review of, or detailed commentary on, the vast lit- erature in developmental psychology that is concerned with perspective taking [for this, see recent reviews and commentaries by Chandler, 2001; Flavell, 1992; Menna & Cohen, 1997; Schober, 1998]. Rather, the central intention is to describe Mead’s theory of perspectivism and perspective taking in the context of his social, develop- mental psychology, and to consider some of its possible theoretical and empirical implications for conceptualizing and studying internalization and agency. Unlike most contemporary developmental psychologists, Mead does not treat perspective taking primarily as a signifi cant developmental accomplishment that marks our progress as epistemic agents. Instead, he considers perspective taking as a basic con- dition of our sociality and ontological constitution as agentive selves in interaction with others.\nMead’s Perspective Realism and Theory of Perspectives The term ‘perspective’ was not used by Mead until about 1920, when he began to articulate his mature philosophical position in opposition to traditional meta- physics. In the traditional view, for something to be objective or real, that thing can- not depend on any other thing, but must stand on its own. Mead was concerned that such an assumption relegated many important and infl uential social and psycho- logical entities and processes to the realm of the illusory and imaginary, and threat- ened to sweep social and developmental psychology toward the twin brinks of ideal- ism and solipsism. In developing his theory of the objective reality of perspectives [Mead, 1932/2002, pp. 153–170], Mead was at pains to put our sociocultural and psychological functioning back into the world in such a way that it might be the ob- ject of rigorous scientifi c study and consideration.\n‘In his later years, Mead often used “being in the perspective of the other” in- stead of “taking the role of the other”’ [Miller, 1982, p. 17]. Cook [1993] has noted that Mead came to use the phrases, ‘take the attitude of the other … taking the role of the other,’ and ‘take the perspective of the other … more or less interchangeably’ (pp. 79f). For Mead, our entire human sociocultural and psychological world is real, but perspectival (i.e., dependent on us). Mead defi ned perspectives as orientations within a larger context that arise through, and always remain related to, human con- duct in the world. ‘The perspective is the world in its relationship to the individual and the individual in his relationship to the world’ [Mead, 1938, p. 115]. ‘The world, things and the individual are what they are because of this relation’ [Mead, 1938, p. 215]. When entered into, perspectives are both perceptual and conceptual. Al- though they arise within particular sequences of social interactivity, they are not fi xed to a particular present. As a consequence, once they are experienced, they can be used imaginatively.\nThus, a perspective is an orientation to an environment that is associated with acting within that environment. Perspectives emerge out of activity and enable in- creasingly complex, differentiated, and abstracted forms of activity. Because the hu- man world is a social world, all perspectives arise and are employed within interper- sonal interactivity. Even though perspectives may be elaborated imaginatively and honed refl ectively, they are seeded and maintained through interactions with others.\nThis is not to say that there is no biophysical world that constrains and also enables human interactivity. It is simply to recognize that biophysical conditions, although necessary, are in no way suffi cient for perspectivity of the kind that enables the de- velopment and functioning of social-psychological phenomena like mind and self. It is important to emphasize that for Mead, the taking of perspectives is not primarily an epistemological matter through which we come to understand our world and our selves. Rather, it is an ontological matter. It is by taking perspectives that exist in the sociocultural world in which we are embedded from birth that we come to exist as self-interpreting beings at all.\nSocial acts are collective acts that involve two or more participating individuals, and social objects are collective objects with meanings that can be shared by par- ticipating individuals. Social objects are what they are by virtue of their embedded- ness within the matrix of social acts that makes up the life of a society. Bones of animals become weapons in the experience of early human individuals engaged in social acts of confl ict, and balloons become toys when bounced back and forth be- tween a mother and her child. At a more abstract level, minds and selves also arise out of human interactive activity, especially communicative activity supported by the signifi cant symbols of language. Mead [in Reck, 1964, pp. 134–141] maintains that communication in humans begins, both phylogenetically and ontogenetically, as a conversation of gestures that gradually becomes transformed into a conversation of signifi cant symbols (i.e., language). Signifi cant symbols ‘call out’ in the individual using them functionally similar responses to what they call out in others to whom they are directed.\nTaking the perspective of the other is essential to Mead’s conception of the sig- nifi cant symbol [Gillespie, 2005]. Most importantly for current purposes, signifi cant symbols are not to be understood only as shared, singular perspectives (i.e., as the evocation of the same meaning in different individuals, as in Morris’ introduction to Mead, 1934, p. xxi), but more importantly as simultaneously experienced, dual perspectives. ‘It is through the ability to be the other at the same time that he is him- self that the symbol becomes signifi cant’ [Mead, in Reck, 1964, p. 244]. For example, as I tell what I regard as an amusing anecdote to a friend, I watch his reactions for signs of enjoyment, simultaneously adjusting and embellishing my story, at least in part, on the basis of what I fi nd there.\nWith this in mind, consider Miller’s [1982] statement about the centrality of the signifi cant symbol to Mead’s thought.\nMead’s most profound insight consists in understanding that the signifi cant symbol, the language symbol, consists of a gesture whose meaning is had by both the one who makes the gesture and the other to whom it is addressed. He spent most of his intellectual life unravel- ing this insight. (pp. 10–11) However, as Gillespie [2005] has argued, based on Mead’s later perspectivism, the true importance of the signifi cant symbol with respect to the development of thought, consciousness, and selfhood concerns the simultaneous positioning of the individual within two or more perspectives. It is being in two perspectives at the same time, simultaneously taking multiple positions within meaningful sequences of conduct, that defi nes sociality for Mead. It is within this sociality that mind and self emerge.\nFor Mead, human conduct must be understood as an emergent unfolding of se- quences of social acts within which individuals react to both others and themselves.\nSuch a conception of social conduct makes it possible to understand Mead’s theory of how consciousness and selfhood arise through a graduated, social developmental process of intersubjectivity. It is within interactions with others that infants become other to themselves. They do this by taking the perspectives of others, and then by reacting to the self and other perspectives that emerge within their ongoing interac- tivity.\n‘Internalization’ and Agency within Sociality The self is something which has a development; it is not there, at birth, but arises in the process of social experience and activity, that is, develops in the given individual as a result of his relations to that process as a whole and to other individuals within that process.\n[Mead, 1934, p. 135] What distinguishes the forms of consciousness that can be experienced by the normal, adult human being from the more basic forms of sensitivity to the environ- ment likely experienced by other animals and infants is the refl exivity of the self.\nThis is a refl exivity that only can arise through interactions with others within an ongoing social process. Pre-refl ective consciousness refers to a world that is there, but refl ective consciousness or refl exivity refers to a world as experienced by a self that is capable of being both a subject and an object to itself. The individual becomes ‘an object to himself by taking the attitudes of other individuals toward himself within an organized setting of social relationships’ [Mead, 1934, p. 255].\nBy reinterpreting Mead’s social developmental psychology, as set forth in Mind, Self, and Society and several of his earlier essays, through his theory of perspectives within social conduct, it is possible to arrive at a detailed understanding of what is involved in achieving selfhood, self-understanding, and agency. Such an understand- ing highlights two features of Mead’s theory of perspective taking: (1) the importance of simultaneously being in one’s own and another’s perspective, and (2) the impor- tance of reacting to the multiple perspectives that one is in.\nBeing in Different Perspectives Simultaneously In Vygotsky’s [1978, p. 56] famous analysis of the child’s internalization of the meaning of pointing, he provides a feedback theory in which the mother responds to the child’s reaching by bringing an object closer to the child, thus converting the child’s grasping into pointing. Although feedback theorizing of this kind moves from a dyadic, child-object to a triadic, child-object-other model of explanation, it does not deal adequately or fully with the intersubjective, subject-subject relation [Gil- lespie, 2005]. In this example, the feedback theory does not endow the mother with a perspective that can be taken by the child, and occupied together with the child’s own initial perspective. Consequently, the feedback theory cannot explain adequate- ly how the child becomes other to himself.\nFor Mead, the child displays the meaning of pointing when she is able to re- spond appropriately to the situational pointing of her mother as well as to stimulate herself to act as her mother would act in response to her (the child’s) own pointing gestures. To understand how one might become other to oneself, Mead turned to social conduct, especially to the subject-subject relation, in a manner that brought the perspective of the other into the analysis. What he realized is that from the earli- est days of life, the developing self already is engaging with the perspective of the other in rudimentary social interactions. With this realization, the key question be- came one of understanding how the developing child could begin to experience the position or situation of the other (parent or caregiver) within social interaction. The answer for Mead lay in the young child’s repeated, and somewhat predictable se- quences of interaction with others in which she has exchanged roles and positions (e.g., sometimes passing a ball and sometimes receiving it; sometimes crying and sometimes comforting; sometimes asking and sometimes receiving; sometimes dis- puting and sometimes placating).\nVery early in development, such perspective taking is exceedingly rudimentary, amounting to little more than a pre-refl ective recollection and anticipation of p hases and positions within very simple gestural sequences (e.g., pushing a ball back and forth, with some assistance from a caregiver). However, through repeated social ex- perience of sequences of gestures, responses, and consequences, in interaction with their caretakers, infants gradually comprehend and anticipate the meanings of rou- tine social gestures. They simultaneously build up clearer recognitions of their care- givers and other objects in their micro social environments. Through repetitively shared sequences of interactive gestural activity, young children acquire a primitive sense of gestural meanings and come to distinguish particular social objects like mother and father. They then can begin to develop awareness of their own actions and selves through interactions that use signifi cant symbols, and eventually through more refl ective forms of interpersonal and societal perspective taking [Baldwin, 1986].\nAs Gillespie [2005] makes clear, for Mead the way to understand perspective taking was to stay focused on the social act: A social act refers to a social interaction that has become an institution, with established positions (i.e., buyer/seller, teacher/student, parent/child, boss/subordinate) that are stable over time. The introduction of both time and social structure is a breakthrough. Although the perspectives of self and other within any ongoing social act are necessarily divergent, if one takes into account time and a stable social structure, then it is possible that at some previous point in time, the positions of self and other were reversed. Given this, each par- ticipant in a social act may, by virtue of previous responses while in the position of the other, already possess the attitude of the other … It is because self and other are often in the same situations, or social positions, and acting toward the same objects, that the child comes to acquire the same attitudes that others have. (pp. 27–28) Over time, and in this manner, as the child’s social interactions widen and deepen, she eventually acquires the perspectives of others common to the social pro- cesses and communities in which she participates, thus taking the attitude of what Mead calls the generalized other or generalized others [Cronk, 1973]. This more ab- stracted process of perspective taking eventually can be continued vicariously and imaginatively through engagements with orientations and views available in diverse media including literature and fi lm.\nOnce the child has taken the perspectives of others in the way Gillespie [2005] has described, she only has to react to herself through these perspectives that she previously has engaged in interactions with others. As already hinted, the key here lies in exchanging and reversing roles within sequences of social interactivity, espe- cially in coming to occupy two or more positions or perspectives simultaneously.\nOne major way in which such multiple occupation of perspectives is developed is through play and games, which are characterized by positional exchange, both ac- tual and imaginary. Gillespie [2005] points out that games encourage the simultane- ous evocation of two or more perspectives by (1) providing opportunities for moving between complementary social positions (e.g., receiving and making a pass in a game of football), (2) providing rules that bridge perspectives housed in different positions and situations within the game (e.g., passing and receiving a football in ways that do not run afoul of the off-side rule), and (3) providing a context in which vocal gestures between players can serve to integrate perspectives in an immediately concrete man- ner (e.g., calling for a ‘pass’ and responding to that call). The important point is that it is through repeated and graduated participation in different positions within rou- tine, everyday social interactions (including play and games) that the child is able to take different perspectives, and eventually to occupy different perspectives simulta- neously. Such multiple perspectivity allows the child to be other to herself, so that she is able to react to those very perspectives that now constitute her as a social be- ing (i.e., as a ‘Me’).\nReacting to Perspectives The importance of reacting to the perspectives of others that one has previous- ly experienced in social interactions that have involved reversals of roles and posi- tions should not be underestimated. For Mead, the activity of the self is conditioned by, but not determined by the social situations and processes within which it emerg- es. Human agency is conditional but free. In order for the self to become an object to itself, it is not enough to take the perspectives of others as experienced in one’s past and current history of interactivity. In addition, it is necessary to react to the self that appears in current action and imagination as a consequence of such past engagement. Mead’s self thus has two dimensions or phases: (1) a ‘Me’ that consists in the perspectives of others based on past experience, and (2) an ‘I’ that reacts to the ‘Me’ and the current situation in terms of an imagined future in which the ‘Me’ is restructured. Mead’s distinction between the ‘Me’ and the ‘I’ brings both tempo- rality and sociality to bear on agency. The ‘Me’ is an objective self that contains per- spectives and possibilities for social interaction gleaned from a past history of social interactivity. The ‘I,’ especially in novel and problematic situations, reacts to the ‘Me’ in the immediate moment of action, and, in so doing, enters into a reconstruct- ed ‘Me’ of the next moment, while simultaneously preparing the ground for a newly emergent future ‘I.’ Mead’s conception of emergence [Mead, 1932/2002] is that of a disruption in experience – an impasse in the continuity of passage from the present to the future, which anticipates a more distant future in which harmony will be restored. As Saw- yer [2002, p. 9] recently has pointed out, sociality, or simultaneous positioning with- in different systems and perspectives, was, for Mead, an integral aspect of emer- gence. In particular, emergence is a consequence of occupying perspectives in ways that admit to heretofore unexperienced and unimagined possibilities. However, Mead, unlike many theorists of emergence in contemporary science and social sci- ence, insisted on a social level of reality with unique constitutive powers that was not reducible to biophysical levels of the world [also see Archer, 1995; Bhaskar, 1979; Martin, 2003].\nFor Mead, the immediate moment of action brings together a concern of the present with both recollections of relevant past activity and anticipations of a future in which the concern or problem to which the action of the present is directed is resolved or somehow made manageable. Such concerns typically are emergent in the fi eld of activity, within the ongoing dynamic interplay of social, interpersonal, and personal perspectives. They arise in the immediate context of novel, unpredict- able occurrences that constitute a change in past action sequences and perspectives.\nIf such emergent change were not common, our minds and selves would be deter- mined entirely by our past interactions in our biophysical and sociocultural world, and our worldly conduct would not be punctuated and experienced in temporal terms. It is precisely because of the emergence of change that our temporal experi- ence and agency also arise. Psychological time requires markers, and change sup- plies them.\nTo summarize, Mead’s theory of perspectives treats the taking of perspectives as embedded in, and emergent from, positional exchange and simultaneity within interpersonal interactivity. Mead’s perspective taking arises from participation within, and experience of, different positions and orientations within intersubjective communicative sequences and contexts. It is not a matter of somehow converting social processes to psychological ones, but of coming to participate in social interac- tivity as self-aware psychological persons. Mead never talked about having a perspec- tive on something. One is in a perspective and part of a perspective. A perspective is a relational, not a mental, entity. It is a relation of an individual or group to a situation, with respect to acting in that situation. To understand Mead’s approach to perspective taking, taking must not be given a mentalistic interpretation. More- over, the agency that is exercised by a self-aware psychological person is not deter- mined by biophysical and/or sociocultural factors, but is a reaction of a self-inter- preting being to those perspectives she is immersed in through her ongoing social interactions with herself, others, and the social, cultural communities in which she acts. In short, agency is a reaction to the situation in which one fi nds one’s self, and that situation always is a social situation. For Mead, both selfhood and agency arise developmentally through perspective taking (positional exchange, simultaneity, and coordination) within social acts.\nPerspectival Selfhood in Context Recall that a major rationale for Mead’s perspectival realism was to restore so- cial and psychological phenomena to the world, and to forestall a rush to subjectiv- ism, idealism, and solipsism. By treating social psychological perspectives as both real and emergent, he also hoped to resist reductive forms of social and psychologi- cal theorizing that he viewed as pseudo-scientifi c, in that they inappropriately re- duce, and thereby distort, exactly those entities (like mind, self, and consciousness) that need to be explained. Perspectives, in Mead’s sense, are always in the world.\nIndeed, they make up our social and cultural world. They have an objectivity that derives from the extent to which they are shared and function within our individual and collective experience [Mead, 1938].\nFor Mead, the reality and organization of perspectives is apparent in social con- duct within which the individual and others are immersed in a cooperative process of perspective taking. If a number of others are involved, the individual is able to take the perspectives of all of them, both as individuals and as a collective. She or he is able to do this by understanding what it is that they wish to accomplish – in other words, by comprehending the problematic situation they all confront, and in- ferring a sense of what would constitute a resolution for all concerned. At the begin- ning of interactions with others in problematic circumstances, such a common ele- ment in the perspectives of all participants might be framed as nothing more than the removal of the diffi culty that confronts them all. However, over time, and with accumulated interactions in the problem context through which different actions with respect to the problem are discussed and attempted, the individual is able to enter into the perspectives of others. At the same time, she enters into an emerging, more detailed common perspective as a consequence of her participation in this overall process of problem solving, a process which in turn is nested in the overall social process.\nWhat ultimately organizes these various perspectives is the extent to which they achieve collective support within the problem context and the social process in gen- eral. Since all perspectives are initially, at least to some extent, hypothetical, it is the development and application of perspectives within their contexts that organizes them. Perspectives that are unsuccessful in moving the group toward a resolution of the problem confronting them are discarded in favor of those that yield more suc- cess. Perspectives are organized in terms of their utility and viability across problem situations and distributed among those individuals interactive within them. Such organization and distribution result in a variety of generalized others, depending on the diversity of the social group and community in question. Mead’s generalized oth- ers may be thought of as organizations of perspectives that facilitate awareness of how various attitudes and roles are coordinated within complex social acts. Perspec- tives are social and objectively real in that they both constrain (acting consistently with generalized others in conventional situations) and enable (acting contrary to, or extending generalized others, especially in problem situations where convention- al perspectives fail).\nTo the extent that all emergent, hypothetical perspectives have the potential to become realized in social conduct, especially in problem situations, they are objec- tively in the real world that is the sum total of all perspectives. In Mead’s words, the emergent value which the individual organism confers upon the common world belongs to that world in so far as it leads to its creative reconstruction. In so far as the world is pass- ing into a future, there is an opportunity for that which is not objective to become objective.\n[Mead, 1938, p. 613] For Mead, the relation of an organism and an environment is continuously dy- namic. The natural and social world consists of a multiplicity of perspectives, any one of which may enter into an organism’s fi eld of activity. It is by virtue of the or- ganism’s ability to be several things simultaneously, in the sense of taking on (acting within) two or more different perspectives, that the organism is able to deal with emergent events or novel, unexpected occurrences. Because human persons are themselves social, their perspective taking may be enhanced greatly by communica- tion with others through signifi cant symbols.\nIt is precisely because human individuals are able to take the perspectives of others within the social process that they may acquire selves that are constituted by the perspectives available in their ongoing social encounters. Because social life is dynamically unfolding, the perspectival self is continuously emergent. Nonetheless, such a self is able to achieve suffi cient stability within the larger social process of organized, and potentially objective perspectives so that it can function with some success within the problem contexts that it necessarily will face in the course of liv- ing. As a ‘Me,’ the self consists of perspectival understandings and orientations. As an ‘I,’ the self is an active agent simultaneously occupying situations that have been in one sense determined by the past, but which (because of the ever-present emer- gence of novel circumstances) in another sense are open to determination by the momentary activity of the ‘I’ in the fl eeting present. By being simultaneously present in both of these temporal perspectives, the self is a source of both the achieved wis- dom of the past and the agentive cultivation of the future. Perspectives constitutive of selfhood must be coordinated suffi ciently with other social and interpersonal per- spectives to ensure functional levels of intelligibility and interactivity. However, such required coordination still leaves room for considerable creativity in achieving perspectival coordinations that might prove more functional and inclusive than con- ventionally extant organizations of perspectives [Martin, 2005].\nImplications for Contemporary Theory and Research Perspective Taking as ‘Internalization’ Mead’s theory of perspectives and perspective taking is a participation theory in which the functional meanings, self-other differentiations, and perspectival actuali- ties and possibilities resident in interactivity constitute our minds and selves. On this interpretation of Mead (even though he occasionally uses the term ‘internalization’ himself), there is no need to think of any of these developmental processes as requir- ing empathic or intentional theorizing that involves simulating how one would feel, think, and act in the situations of others, including their mental states. Of course, as developed adults, we are able to do all of these things, but according to Mead, we do not initially learn to do them through developing theories of minds. Such mental feats are products of more basic developmental processes. They are not primary develop- mental processes themselves. To posit them as basic mechanisms of internalization is to assume exactly what needs to be explained. Thus, unlike contemporary versions of theory of mind in developmental psychology [see Carpendale & Lewis, 2004 for a recent critical review], Mead understood interpreting the actions of others as an in- tersubjective process that privileges action with others over introspective thought.\nMoreover, processes like imitation and identifi cation, which many contemporary de- velopmental theorists [e.g., Hobson, 2002; Tomasello, 1999] understand as basic mechanisms of internalization, are treated by Mead as developmental consequences of the kind of participatory positioning and perspective taking he endorsed.\nPossible Theoretical Progress. M ead’s developmental account, as interpreted through his theory of perspectives, runs counter to much contemporary developmental psychology. In particular, it does not talk about the development of general or specifi c theories of mind [e.g., Gopnik & Wellman, 1992], esoteric forms of introspection that might be associated with imaginatively understanding one’s own or another’s inner functioning [e.g., Harris, 1992], or arrays of innate capabilities that make ‘mindfulness’ possible [e.g., Baron-Cohen, 1995]. In Mead’s approach, the mind and self are in the world as much as they are in individuals. It simply is a matter of perspective, and the taking of perspectives is fi rst and foremost a social activity.\nHowever, Mead’s account also departs in signifi cant ways from neo-Vygotskian accounts of internalization and from what may reasonably be regarded as neo- Meadian accounts by developmentalists like Marková [1987] and Hobson [2002].\nIn many ways, Mead’s perspectival theorizing, when applied to his social, develop- mental account, yields a participation alternative to internalization that demon- strates many of the theoretical advantages that Matusov [1998] previously has pre- sented in arguing for the participation theories of Lave and Wegner [1991] and Ro- goff [1990, 2003]. Not only does Mead’s theorizing seem helpful in overcoming dualisms inherent in internalization accounts, such as individual-social, inner-outer, and mind-action, it also provides a non-reductive account of the ongoing transfor- mation of social and cultural processes through the embedded, situated activity of real human agents. Moreover, it does so with at least somewhat greater precision than the more general descriptions provided by invoking vehicles of induction and transformation such as ‘legitimacy of participation’ and ‘communities of practice’ [Lave & Wenger, 1991, p. 117], as useful as such general terms may be as pointers to the important sociocultural practices to which they refer. Finally, Mead’s strong emphases on position exchange and simultaneity are not found in most neo-Vy- gotskian, participation theories.\nIt is perhaps easiest to evaluate critically Mead’s perspectival realism as a po- tential contribution to contemporary developmental theory by considering it in rela- tion to what may be the most thoroughly Meadian of all contemporary works, Hob- son’s [2002] The Cradle of Thought. The aim of Hobson’s work is to ‘begin with the mental life of babies and to end up with a story of how thinking … emerges in the course of early development’ (p. xiii). Hobson’s account assumes a central role for perspective taking, in that, ‘Thinking becomes possible because the child separates out one person’s perspective from another’s. More than this: thinking arises out of repeated experiences of moving from one psychological stance to another in relation to things and events’ (p. 105). According to Hobson, ‘the mechanism by which all this occurs is the process of identifi cation … To identify with someone is to assume the other person’s stance or characteristics’ (p. 105). To explain how the child be- comes aware of herself and others as beings who have and who can adopt perspec- tives, she fi rst has to take a perspective on herself and her own attitudes. It is only by doing this, by taking a view on her own ways of construing the world, that she can begin to think in terms of her own and others’ perspectives. This happens through a particular species of identifi cation: the child identifi es with others’ attitudes towards the child’s own attitudes and actions (p. 106).\nIn many ways, Hobson’s account is amazingly similar to the perspectival ren- dering of Mead’s developmental thought offered herein. Nonetheless, there are im- portant theoretical disjunctions that may be explored both theoretically and empir- ically in ways that might prove fruitful for contemporary developmental theorizing.\nTo make his thought more concretely accessible, Hobson [2002] employs a model consisting of a triangle of relations in which an infant relates to objects, persons, or events in the world; to herself as the other relates to her; and to the other’s relation to the world [also see Chapman, 1991, 1999]. One of the theoretical purposes to which Hobson puts his relatedness triangle is to explain how the infant becomes able to understand that there is not just one (i.e., her own) but two perspectives (e.g., her own and her mother’s) involved in her interactions with another concerning some aspect of the world (e.g., an object such as a toy). ‘What we need to explain is how the child comes to know that her movement into this position of the other amounts to her taking up a new perspective’ [Hobson, 2002, pp. 108–109]. Hobson’s answer, making use of his relatedness triangle, is to claim that through triangulation, a given object is experienced as in receipt of two different attitudes and meanings, and that ‘it is this that prompts the infant to separate out her own attitude from that of the other’ (p. 109).\nLike Mead, Hobson [2002] emphasizes the importance of simultaneously being in one’s own and another’s perspective in achieving an understanding of mind and self. Hobson also emphasizes the likely importance of taking cooperative, comple- mentary perspectives so that a rudimentary, pre-refl ective understanding of what is involved in sharing may serve as a stepping stone to experiencing connectedness with (when sharing is present), and separation from (when sharing is absent), some- one else [Hobson, 2002, p. 252]. However, where Hobson departs from the perspec- tival theorizing of Mead is by considering the perspective taking involved in the triangulation experiences he describes to be a kind of imitation made possible by a process of identifi cation. ‘There is something about our propensity to imitate others that is as basic as our intellectual prowess … It is the capacity to identify with oth- ers’ [Hobson, 2002, p. 215].\nJust as one person’s expressions of feeling can move someone else to feel things in sympathy, so a person may identify with someone else in the act of imitation. This, too, involves a kind of movement into the other person’s position. The person who imitates assumes something of the mental orientation of the other person. (pp. 221–222) And, just in case there is any doubt about Hobson’s intentions concerning the primacy of processes of imitation and identifi cation with respect to perspective tak- ing, ‘Identifying with people is what leads to perspective taking’ (p. 271).\nOn a Meadian account, Hobson’s [2002] invoking of imitation and identifi ca- tion is both unnecessary and ill-advised. One problem is that neither imitation nor identifi cation, in Hobson’s theorizing and research, are given referential grounds or criteria other than those that defi ne the perspective taking they are supposed to ex- plain. Indeed, there is much in Hobson’s prose to suggest that imitation and identi- fi cation are identical to, or developmental consequences of, perspective taking, rath- er than causal or constitutive antecedents. A second problem is that in positing imi- tation and identifi cation as foundational, Hobson comes dangerously close to re-introducing exactly those aspects of conventional theory of mind and simulation theory that he seems otherwise at pains to dispel with his Wittgensteinian-inspired participation theorizing – ‘in relating to people we get access to minds directly, not via a convoluted route of inferences, deductions and analogies. Minds are neither so hidden nor so abstract as they seem’ [Hobson, 2002, p. 251].\nIn fact, though, it is not a mentalistic theory of mind with which Hobson wish- es to align himself, but Vygotskian internalization, exactly what the presentation of Meadian perspective taking herein is intended to replace (because of its dualism and mystery). According to Hobson, when all is said and done, we should look to Vy- gotsky, for his theory of internalization ‘is a process that may explain what we need to explain: the newly appearing qualities of thinking and the new kinds of self and self-awareness. This is the process of interiorization described by Lev Vygotsky and central to psychoanalytic accounts of development. It is the process by which things that happen between people become things that happen within the individual’s own mind’ [Hobson, 2002, p. 257].\nFor Mead, mind is not an individual property. As stated earlier it is a relation- al entity distributed across and within those coordinated, intersubjective patterns of interaction with others that imbue our worldly actions with meaning. Moreover, there is no need to get behind perspectives. What are most basic are perspectives through which we engage and share in the social process in general, as well as in its particular manifestations in our life histories of interpersonal exchanges within which we emerge as self-conscious, self-interpreting beings. This is not to deny that we eventually come to be able to think in private, to theorize about other minds, or to chart and plan our lives. It is to say that all of these and our other mental and per- sonal activities and capabilities have their ontogenetic sources in social interactivity and participation, not in pre-existing or deeply interiorized mental capabilities and representations which afford us a detached view of the world. Although Hobson [2002] captures many of Mead’s insights concerning perspective taking and offers a potentially useful extension to Mead’s account by emphasizing the centrality of a social- emotional orientation to the development of mind, he seems at times to want to go beneath Mead’s developmental bedrock of social interactivity with others.\nThere can be little doubt that Mead would resist any such excavation.\nSuggested Empirical Research. If Mead’s perspectival social psychology is really to constitute a viable alternative to theories of internalization in contemporary developmental psychology, it should be possible to point to empirical implications and demonstrations and/or assessments of its central claims. First, however, it should be noted that the Meadian conception of perspectives (as action orientations in relation to a larger context or environment) is quite different from the ‘in the head’ conception of perspectives frequently traced to Piaget. Consequently, in addition to extant and possibly future empirical evidence, support for Mead’s perspectivist interpretation of self and mental development necessarily involves appeals to scientifi c criteria such as parsimony, simplicity, and elegance. On such grounds, the preceding critical analysis of Hobson’s [2002] work and ideas is suffi cient to demonstrate that the Meadian account articulated herein makes fewer assumptions and avoids the logical circularity that besets many competitor accounts of the development of mind and self. For example, biological accounts [e.g., the nativism of Meltzoff & Brooks, 2001; the modularity of Baron-Cohen, 1995, 1999; and the evolutionary-ecological approach of Butterworth, 2003] assume many innately seeded internal mechanisms and competencies that Mead does not. More cognitive theories [e.g., the primary and secondary intersubjectivity of Trevarthan, 1993; the intentional insight approach of Tomasello, 1999] are replete with many mentalistic assumptions concerning representation and cognitive architecture that seem to suppose very early refl ective and conceptual abilities that are highly arguable [cf. Carpendale & Lewis, 2004]. Even more socially sensitive theories [e.g., Hobson, 2002; Moore & Corkum, 1994] seem to posit meta-representational capacities [Penner, 1991] and/or very early forms of identifi cation and imitation that are contestable.\nBy comparison, Mead’s perspectival realism gives us a rather straightforward account of the psychological consequences of participation with others in routine gestural and communicative interactions sanctioned within particular sociocultural contexts. It is interactivity within these conventional social practices that enables developing infants and children to experience and occupy a variety of social and personal perspectives, and to use them in both action and imagination. Of course, it may be that Mead’s approach is insuffi ciently replete with distinctions and mecha- nisms required to provide a fully satisfying theory of the development of mind and selfhood. But Mead’s approach offers a comparatively lean account that contains relatively little in the way of contestable assumptions and logical diffi culties. It also fi ts the existing empirical record as well as its competitors. The Meadian approach suggests at least two kinds of research that have not, to date, been popular in the empirical arm of developmental psychology.\nBecause little is assumed in Mead’s theory that is entirely hidden (i.e., all of the developmental mechanisms and events he describes may be quite readily located in sequences of social interaction), intensive longitudinal videotaping of interactions between neonates and their caregivers over the fi rst two years of life would provide a marvelously rich source of data against which to check Mead’s assertions in com- parison with those of other socially oriented theorists like Hobson [2002], as well as more cognitively and/or biologically oriented theorists like Trevarthan [1993]. In particular, it would be important in such studies to construct a number of opera- tional pointers to key processes such as identifi cation, imitation, intersubjectivity, and perspective taking (especially multiple perspective taking, in terms of role rever- sals, combinations, and coordinations) that might be used to adjudicate amongst competing accounts of key developmental accomplishments and processes.\nFor example, indications of perspective taking in intersubjective interactional sequences could be indicated by role reversals in which a caregiver and year-old child occupy different perspectives in simple, repeated actions – a child holds out a piece of food to a mother who takes a bite and then offers the food to the child by moving it toward the child’s mouth while simultaneously pointing with her other hand to the child’s mouth. Completion of such a simple sequence of role reversal and intersub- jective perspective taking might be indicated by the child taking a bite of the food and then offering it once again to the mother. Children’s play with dolls and other toys also may be observed for instances of positional exchange and simultaneity. If such instances could be interpreted reasonably as re-enactments of previously expe- rienced exchanges with caregivers, they would support Mead’s theoretical position.\nIn general, if perspective taking is developmentally foundational in the manner pro- posed by Mead, the child’s occupation and simultaneous coordination of roles and phases in diverse social interactions ought to be affected by the ways in which care- givers coordinate the child’s perspective with their own. This being so, it would be especially interesting to note possible differences in the quantity and quality of chil- dren’s perspective taking that might be related to their interactions with those pri- mary caregivers with whom they are most active socially.\nOf course, to some extent, it remains a matter of interpretation as to whether to treat particular aspects of events like food sharing or doll play as instances of par- ticipatory role and perspective taking or identifi cation and imitation. However, it also might be possible to train caregivers (or research assistants acting as caregivers) to take advantage of naturally occurring events of this kind, and follow them with quasi-scripted actions that are less immediately interactive in order to determine what responses, if any, the child might make to them. For example, following the food-sharing scenario just described, the caregiver or research assistant might move away from the child and begin engaging in a novel form of activity without looking at the child, or otherwise directing her movements to the child. If children consis- tently imitate the actions of others under these less interactive conditions, Mead’s thesis concerning the necessity of relational interactivity for perspective taking would be unsupported empirically. Obviously, a great deal remains to be worked out in any such potential program of research. However, it is clear that such work would need to be conceived in considerable theoretical detail, would be methodologically very challenging, and would demand a great commitment of time and energy from both participating families and researchers.\nA second kind of research that might be especially instructive with respect to examining empirically some of Mead’s central theoretical propositions could in- volve experimental or quasi-experimental interventions with young children in day- care centers. Mead has been interpreted [both herein and by Gillespie, 2005] as maintaining that cooperative interactions may be especially powerful bases for the development and taking of complementary perspectives, which very likely are the fi rst kinds of perspectives to be held simultaneously. This being so, structured ac- tivities involving role-play or games within which young children (both immediate- ly prior to and following the beginnings of language use) might be encouraged and helped to experience complementary phases or roles in structured communicative, action sequences could be arranged. The consequences of such interactivity then might be examined on subsequent tasks in which participating children are asked to demonstrate their perspective taking capability and self-understanding. By compar- ing such demonstrations to those of similar children who have not participated in the ‘complementary perspective’ interventions, it might be possible to gauge some- thing of the likely effects of such experiences.\nOf course, any such interventions would need to be of a reasonably lengthy du- ration, and the studies themselves would benefi t greatly from intensive, longitudinal recording and analysis of a carefully planned set of gradually more demanding and sophisticated forms of perspective sharing and multiple perspective taking over the course of the interventions. It might also prove instructive in such studies to contrast Meadian and Vygotskian forms of facilitative intervention. In the former, young children might be encouraged to participate in and reverse their participation across complementary roles within different phases of interactivity. In the latter, young children might be encouraged to expand and increase their perspective taking capa- bilities by building on the instructional scaffolding provided by more developmen- tally advanced others (perhaps including modeling that emphasizes identifi cation with, and imitation of, researcher-teachers and/or older children).\nThe simultaneous occupation and reactive consideration of non-complemen- tary, even antagonistic, perspectives may be viewed as demanding greater accumu- lated experience of perspective taking and multiple perspectival involvement. It is an empirical question as to whether these more oppositional forms of perspective taking really can develop out of initially complementary perspective taking as Mead suggests. Certainly there are several extant theoretical perspectives [e.g., Bakhtin, 1986; Billig, 1987; Hermans, 2002; Wertsch, 1991] that might contest such a devel- opmental sequence as too facile.\nPerspective Taking and Agency It is by means of perspectives, which are experientially occupied and available actually and imaginatively as situated resources for action, that individuals become Meadian ‘Mes.’ However, agency goes beyond the ‘Me’ in that it manifests as a reac- tion to the ‘Me,’ one which may become increasingly self-interpretive with repeated and differentiated experiences, especially in problem-solving situations. Of course, this Meadian ‘I’ need not be self-consciously or even consciously engaged. In many ways, Mead seems to suggest that a basic pre-refl ective, reactive agency is part of what it is to be a human being participating in social processes with other human beings. In this sense, one is an agent by acting and reacting to extant perspectives available in social situations. However, there is little doubt that Mead also is com- mitted to a rather strong program of self-refl ective rational and moral agency, espe- cially during adulthood: There are no absolute values. There are only values which, on account of incomplete social organization, we cannot as yet estimate, and in face of these the fi rst enterprise should be to complete the organization if only in thought so that some rough sort of estimate in terms of the other values involved becomes conceivable. [Mead in Reck, 1964, p. 262] As a functional reaction to perspectives and situations, our agency is constantly emergent within those concerns and problems that we encounter in our sociocul- tural and biophysical world. Mead understood agency as a situated reaction to extant perspectives that goes beyond them in the act of reacting to them. His account of agency thus resists the classic dualism of free will versus determinism.\nPossible Theoretical Progress At least a few contemporary developmental theorists have formulated theories of emergent agency that may be related to aspects of Mead’s thought. For example, Bidell and Fischer [1997] have presented an epigenetic account that treats our ge- netic make-up and sociocultural context and participation as active self-organizing systems that, together with persons as self-organizing systems, jointly determine our intellectual and agentic development. However, unlike Mead, Bidell and Fischer understand the human agent not as multiply situated, reactive, and functionally ori- ented to the future resolution of problems, but as actively creative in the construc- tion, within a process of hierarchical integration, of new concepts and skills. Despite their declarations of systems-wide epigenesis, Bidell and Fischer, like many contem- porary developmentalists, adopt a highly cognitive, representational, and operation- al framework that locks the developing agent inside her own cerebral mechanisms in interaction with her environment and genetic make-up, rather than viewing her as creatively participating in social processes and interpersonal interactions in ways that transform both her society and her self.\nA more Meadian outlook may be found in the work of Mark Bickhard [1999, 2004]. To Bickhard [2004], ‘An infant is a socially tuned biological creature with marvelous capacity for development into a participant in, and co-creator of, social realities’ (p. 125). For Bickhard, social realities take the form of situational and in- stitutional conventions. Some of these conventions hold across multiple times and people. Some must constantly be worked out in an ongoing process of interpersonal interactivity. Conventionalization consists in large part of common understandings and practices that contain distinctive roles and functions. Participation in social conventions constitutes the world of the individual in a deeply normative sense.\nNormativities themselves ‘are emergent from, ontologically involved in, and func- tion as constraints – and enabling constraints – upon individual level values and actions’ (p. 119). For Bickhard [2004], ontogenetic development is the story of the emergence of an entirely new kind of being, one who participates in society and culture and history. And the person, in so participating, participates in the emergent creation of society in turn … The person is constituted in the multiple ways of being social that that individual has de- veloped in that society and culture and historical time. (pp 125–126) Bickhard’s work follows the general pragmatist approach taken by Mead [1934], especially with respect to emphasizing the naturalness of the functional relations he assumes between persons and their environments. ‘Interactive representation … emerges with complete naturalism out of certain sorts of functional organizations’ [Bickhard, 1999, p. 450]. Note that this is not the kind of cognitive representation thought to consist of encodings of external objects and events. What is represented is not objects, things, or entities in the world, but possibilities for acting. Such ‘func- tions’ are always emerging, and differentiate the environment in ways that open up interactive possibilities. With respect to persons and their societies, Bickhard under- stands both as constantly emergent and co-constitutive. The sociocultural environ- ment is constitutive of personhood in two senses: constructive and interactive. Constructively, learning to engage in the simpler social interactions of childhood provides the scaffolded resources for the eventual construc- tion of the adult social person. Interactively, the person is being social insofar as he or she is interacting with or within those social realities. … Personhood, in being a socially con- stituted constructive emergent, is itself a social and historical ontology. [Bickhard, 1992, p. 86] For Bickhard, the person is a socially spawned agent capable of contributing to her participation in those interactions and social processes in which she exists. Her previous social experiences have provided her with a set of functions she can use to think and act in relation to current and future contexts. This is a very Meadian un- derstanding of agency, yet one which still does not make full use of the theoretical resources that Mead’s perspectivism has to offer.\nTo date, no contemporary developmental psychologist, or any other contempo- rary psychologist for that matter, has theorized agency in a manner specifi cally con- sistent with Mead’s perspectivism – as a constantly emergent reactivity to those multiple perspectives within which the socially involved and constituted person is situated and active. As already noted, in early development, such an agency is most- ly pre-conceptual and non-deliberatively reactive. However, with greater experience in conventional social processes and interactions, the developing human agent is increasingly able to take and work within a multiplicity of perspectives. Such multi- perspectival experience enables a much more refl ective, deliberative agency that may be targeted at specifi c problems and concerns [Martin, Sugarman, & Thompson, 2003].\nSuggested Empirical Research To indicate ways in which a more truly Meadian conception of agency might be infused into research in developmental psychology, it is possible to extend the two lines of research suggested and developed earlier when considering research on ‘in- ternalization.’ For example, the kind of naturalistic, longitudinal study outlined above might explore opportunities for children to apply their nascent ability to oc- cupy two complimentary perspectives to novel situations. For instance, a third indi- vidual (another research assistant) might enter the room and point at what remains of the food that had been offered and received by mother and child in the earlier example, and then point to her own mouth. The ability of young children with dif- fering experiences of complimentary perspectival exchange and coordination to re- spond agentically in such relatively unfamiliar interpersonal contexts would speak directly to the developmental links between perspective taking and personal agency posited by Mead. With older children who have some use of language and greater familiarity with simple picture books, toy models, and audiovisual media, more ad- vanced forms of perspective taking might be examined. To this end, researchers might consider assisting caregivers and research assistants to sprinkle their ongoing interactions with their young charges with a diverse range of perspective taking ac- tivities. Useful ideas for such activities are readily available in the various scenarios that frequently have been used by developmental psychologists who have studied role and perspective taking over the years [e.g., Light, 1979]. Of course, a careful, longitudinal recording of instances of perspectival exchange, coordination, and ap- plication to novel circumstances would speak directly to Mead’s perspectival theo- rizing with or without such planned, quasi-scripted extensions to ongoing, naturally occurring interactions between adults and children. Nonetheless, the deployment of such extensions would certainly increase the amount and variety of interaction di- rectly relevant to perspective taking in Mead’s terms.\nThe second kind of research suggested earlier consisted of experimental or quasi-experimental interventions in which cooperative interactions that encour- aged the simultaneous occupation of complementary perspectives were facilitated in an attempt to expedite the perspective taking and self-understanding of young children. Such studies also could examine relationships between participation in interventions that encourage the occupation of multiple perspectives and the agen- tic reactivity of children to these perspectives. Once again, creative variations on a variety of extant role- and perspective-taking tasks and demonstrations might be employed to examine direct and vicarious indications of agentic capability that, ac- cording to Mead, might be expected to emerge from experiences of multiple per- spectivity. Actions potentially indicative of agency might be theorized and coded within situations and tasks that are purposefully constructed to contain novel and/ or problem elements not found in the contexts and tasks employed in the interven- tions per se. Many childhood games (e.g., hide-and-seek, I spy, and clue) are condu- cive to perspectival exchange, simultaneity, and coordination, and can be tailored by researchers to enhance further the various kinds of persepctivity encouraged and to introduce novel elements into routine sequences of game activity. Diffi cult con- ceptual and theoretical issues concerning what constitutes suffi cient similarity and difference to warrant ascriptions of agency to children’s interactive and situational actions would obviously pose signifi cant challenges in such research. However, there is no reason to suspect that these would, at least in principle, prove any more diffi cult than the host of conceptual, defi nitional, and theoretical matters that at- tend extant research on perspective taking [see Chandler, 2001; Menna & Cohen, 1997; Schober, 1998].\nConclusion In an autobiographical refl ection on his then 35 years as a developmental psy- chologist studying perspective taking, John Flavell [1992], whose neo-Piagetian ac- count stands as one of the major theoretical positions in this area of theory and re- search, states that: My coworkers and I get the impression when testing young 3-year-olds that most of them are simply not ‘maturationally ready’ to understand our questions about mental representa- tions, and that the best we can do is just wait for them to grow a little older. … There is just not enough there yet on which to build. (p. 133) But, if, as Flavell goes on to say, ‘young children do not know that they and other people have conceptual, perceptual, and affective perspectives … [and] they do not know that people mentally represent the world’ (pp. 133–134), why do so many developmental psychologists insist on describing perspective taking in terms of simulation theories and theories of mind? Such theories assume that young infants understand other persons as animate agents, and so share emotions and en- gage with them dyadically; 9-months-olds understand other persons as goal-directed agents and so share goals (and perception) and engage them triadically; and 14-month-olds under- stand other persons as intentional agents and so share intentions (and attention) and engage with them collaboratively (so creating, via internalization, dialogic cognitive representa- tions). [Tomasello, Carpenter, Call, Behne, & Moll, in press] What Mead’s perspectivism, as applied to his social, developmental account of children’s perspective taking, reveals is that a viable theoretical option is to treat activity with others as a source of orientations toward action within routine situa- tions (i.e., as perspectives) that may be shared and occupied in pre-refl ective ways, thus creating important developmental bases for mind, self, and later forms of un- derstanding that are more clearly representational. For Mead, theories of develop- ment that assume that infants and very young children identify with, and imitate, others as consciously self-refl ective agents with unique mental perspectives and rep- resentations assume exactly what developmental theories should set out to explain.\nOur obviously important abilities to act refl ectively, intentionally, and self-con- sciously grow out of our activity with others and the early forms of perspective taking that such interactivity enables. They should not be invoked to make sense of the early intersubjectivity on which they depend. Mead consistently gave developmental primacy to social interactivity as a basis for higher forms of consciousness and cog- nition.\nIt is, of course, true that Mead’s defi nitions and conceptions of early perspective taking do not distinguish between perceptual and conceptual perspective taking [Chandler, 2001] or among a speaker’s situation and identity, conceptualizations, conversational agenda, and knowledge [Schober, 1998]. Without in any way denying that such distinctions may be both important and necessary for particular theoreti- cal and practical purposes, it nonetheless remains doubtful that they are needed to make plausible sense of perspective taking in early childhood. For Mead, perspective taking is a basic fact of sociality, which he understands as being in two or more per- spectives simultaneously. This form of perspective taking is not predominately men- talistic. It is relational and positional. It constitutes the very social reality in which we are embedded from birth, and through our ontogenetic experience it comes to constitute us as socially formed agents whose multiperspectival reactivity is a defi n- ing feature of the human condition and the ongoing self-societal dialectic. In many ways, more interactionist and participatory theories of early childhood development such as those of Bickhard [1999, 2004], Hobson [2002], and Rogoff [2003] begin to approach at least some of the Meadian ideas articulated herein, especially with re- spect to social, interpersonal processes related to ‘internalization’ and agency. How- ever, even here, the constitutive processes most central to Mead’s theorizing, multi- perspectival occupation and reactivity, have not to date received the attention they deserve.\nPerhaps, contemporary developmentalists have been overly infl uenced by the somewhat dismissive reception that Mead has been accorded by leading scholars like John Flavell. Flavell praises Mead for making ‘it diffi cult for all subsequent theorists, both to ignore the importance of communication processes in human development, and to ignore the importance of role taking in communicative processes’ [Flavell, Botkin, Fry, Wright, & Jarvis, 1968, pp. 15–16]. However, he goes on to criticize Mead for an alleged inability to explain the fi ner details of perspective taking – ‘he does not [explain] how A acquires the ability to discern B’s qualities as a responder generally, and in particular how he acquires the ability to select those gestures which will, in fact, arouse the same response in B’ [Flavell et al., 1968, pp. 15–16]. Hope- fully, one consequence of the interpretation of Mead’s theory of perspective taking offered herein (especially the joint processes of being within different perspectives simultaneously and responding agentively to them) will be to challenge such assess- ments of Mead’s actual and potential contribution to developmental thought, theo- ry, and research. Of course, any such reassessment of Mead’s contribution must await further theoretical and empirical inquiry into his detailed hypotheses concern- ing the social development of mind and self. At this writing, it is by no means clear that Mead’s theory of perspective taking is suffi cient as a developmental account of our ascendance to self-conscious experience during ontogenesis, or that it is capable of dealing with the challenges posed by perspectives that may be much more dra- matically oppositional than those available in the vast majority of his discussions and examples. However, it quite obviously is a more developed, specifi c, and de- tailed account than that assumed in much of the developmental literature that has referred to Mead’s ideas [e.g. Davidson & Youniss, 1995; Flavell et al., 1968].\nTo date, only a very few studies exist that have investigated Mead’s views em- pirically and theoretically in comparison with those of infl uential developmental theorists like Piaget and Vygotsky. One of these was concerned with the relationship between private speech and a child’s awareness of the meanings of actions [Kohl- berg, Yaeger, & Hjertholm, 1968]. Another [Light, 1979] dealt specifi cally with role taking in a manner that lends itself readily to Mead’s theorizing about perspectives and perspective taking as developed herein. The authors of both of these studies speculated that Piaget’s conception of egocentrism could potentially be tied to Mead’s emphasis on perspective taking in a highly complementary manner. Light [1979], in particular, suggests that where Piaget equated the problem of centering on a particular social perspective with that of cen- tering on a particular aspect of a situation … Mead [makes] the same equation, and [argues] that social decentration is a necessary condition for intellectual decentration. (p. 12) However, for Mead, perspective taking serves both epistemological and onto- logical functions during ontogenesis. It is not only our knowing, but more fundamen- tally our being or existence as psychological selves and agents that is at stake. It is only by occupying and reacting to perspectives available in the social reality in which we are active that we become psychological beings for whom understanding is a con- cern.",
    "crumbs": [
      "General",
      "Reinterpreting Internalization and Agency through G.H. Mead’s Perspectival Realism"
    ]
  },
  {
    "objectID": "extracted/Jack_Martin10.html#references",
    "href": "extracted/Jack_Martin10.html#references",
    "title": "Reinterpreting Internalization and Agency through G.H. Mead’s Perspectival Realism",
    "section": "References",
    "text": "References\nArcher, M.S. (1995). Realist social theory: The morphogenetic approach. New York, NY: Cambridge Univer- sity Press.\nBakhtin, M.M. (1986). Speech genres and other late essays (V.W. McGee, Trans.). Austin, TX: University of Texas Press.\nBaldwin, J.D. (1986). George Herbert Mead: A unifying theory for sociology. Newbury Park, CA: Sage.\nBaron-Cohen, S. (1995). Mindblindness: An essay on autism and theory of mind . Cambridge, MA: MIT Press.\nBaron-Cohen, S. (1999). The evolution of a theory of mind. In M.C. Corballis & S.E.G. Lea (Eds.), The de- scent of mind: Psychological perspectives on hominid evolution (pp. 261–277). Oxford, UK: Oxford University Press.\nBhaskar, R. (1979). The possibility of naturalism. Brighton, UK: Harvester Press.\nBickhard, M. H. (1992). How does the environment affect the person? In L.T. Winegar & J. Valsiner (Eds.), Children’s development within social contexts: Vol. 1. Metatheory and theory (pp. 63–92). Hillsdale, NJ: Erlbaum.\nBickhard, M.H. (1999). Interaction and representation. Theory & Psychology, 9, 435–458.\nBickhard, M.H. (2004). The social ontology of persons. In J.I.M. Carpendale & U. Müller (Eds.), Social in- teraction and the development of knowledge (pp. 111–132). Mahwah, NJ: Lawrence Erlbaum.\nBidell, T.R., & Fischer, K.W. (1997). Between nature and nurture: The role of human agency in the epigen- esis of intelligence. In R.J. Sternberg & E.L. Grigorenko (Eds.), Intelligence, heredity, and environment (pp. 193–242). New York, NY: Cambridge University Press.\nBillig, M. (1987). Arguing and thinking: A rhetorical approach to social psychology . Cambridge, UK: Cam- bridge University Press.\nBlumer, H. (1980). Mead and Blumer: The convergent methodological perspectives of social behaviorism and symbolic interactionism. American Sociological Review, 45, 409–419.\nBruner, J.S. (1990). Acts of meaning. Cambridge, MA: Harvard University Press.\nButterworth, G. (2003). Pointing is the royal road to language for babies. In S. Kita (Ed.), Pointing: Where language, culture, and cognition meet (pp. 9–33). Mahwah, NJ: Lawrence Erlbaum.\nCarpendale, J.I.M., & Lewis, C. (2004). Constructing an understanding of mind: The development of chil- dren’s social understanding within social interaction. Behavioral and Brain Sciences, 27, 79–96.\nChandler, M. (2001). Perspective taking in the aftermath of theory-theory and the collapse of the social role- taking literature. In A. Tryphon & J. Vonèche, J. (Eds.), Working with Piaget: Essays in honour of Bär- bel Inhelder (pp. 39–63). East Sussex, UK: Psychology Press.\nChapman, M. (1991). The epistemic triangle: Operative and communicative components of cognitive devel- opment. In M. Chandler & M. Chapman (Eds.), Criteria for competence: Controversies in the conceptu- alization and assessment of children’s abilities (pp. 209–228). Mahwah, NJ: Lawrence Erlbaum.\nChapman, M. (1999). Constructivism and the problem of reality. Journal of Applied Developmental Psychol- ogy, 20, 31–43.\nCook, G.A. (1993). George Herbert Mead: The making of a social pragmatist . Urbana, IL: University of Illi- nois Press.\nCronk, G. (1973). Symbolic interactionism: A ‘left-Meadian’ interpretation. Social Theory and Practice, 2, 313–333.\nDavidson, P., & Youniss, J. (1995). Moral development and social construction. In W.M. Kurtines & J.L.\nGewirtz (Eds.), Moral development: An introduction (pp. 289–310). Boston, MA: Allyn and Bacon.\nFlavell, J.H. (1992). Piaget’s theory: Perspectives on perspective taking. In H. Beilin & P. Pufall (Eds.), Pia- get’s theory: Prospects and possibilities (pp. 107–139). Mahwah, NJ: Lawrence Erlbaum.\nFlavell, J.H., Botkin, P.T., Fry, C.L., Wright, J.W., & Jarvis, P.E. (1968). The development of role-taking and communication skills in children. New York, NY: Wiley.\nGillespie, A. (2005). G.H. Mead: Theorist of the social act. Journal for the Theory of Social Behaviour, 35, 19–39.\nGopnick, A., & Wellman, H.M. (1992). Why the child’s theory of mind really is a theory. Mind and Language, 7, 145–171.\nHarré, R. (1998). The singular self: An introduction to the psychology of personhood. London, UK: Sage.\nHarré, R. (2004). The social construction of persons. In C. Lightfoot, C. LaLonde, & M. Chandler (Eds.), Changing Conceptions of psychological life (pp. 241–250). Mahwah, NJ: Lawrence Erlbaum.\nHarris, P.L. (1992). From simulation to folk psychology. Mind and Language, 7, 120–144.\nHermans, H.J.M. (2002). The dialogical self as a society of mind: Introduction. Theory & Psychology, 12, 147–160.\nHobson, P. (2002). The cradle of thought: Exploring the origins of thinking. London, UK: Macmillan.\nLave, J., & Wenger, E. (1991). Situated learning: Legitimate peripheral participation . New York, NY: Cam- bridge University Press.\nLight, P. (1979). The development of social sensitivity: A study of social aspects of role-taking in young children.\nCambridge, UK: Cambridge University Press.\nJoas, H. (1997). G.H. Mead: A contemporary re-examination of his thought (R. Meyer, Trans.). Cambridge, MA: MIT Press.\nKohlberg, L., Yaeger, J., & Hjertholm, E. (1968). Private speech: Four studies and a review of theories. Child Development, 39, 691–733.\nMarková, I. (1987). Human awareness: Its social development. London, UK: Hutchinson.\nMartin, J. (2003). Emergent persons. New Ideas in Psychology, 21, 85–99.\nMartin, J. (2005). Perspectival selves in interaction with others: Re-reading G.H. Mead’s social psychology.\nJournal for the Theory of Social Behavior, 35, 2 31–254.\nMartin, J., Sugarman, J., & Thompson, J. (2003). Psychology and the question of agency. Albany, NY: State University of New York Press.\nMatusov, E. (1998). When solo activity is not privileged: Participation and internalization models of devel- opment. Human Development, 41, 326–349.\nMead, G. H. (1934). Mind, self, & society from the standpoint of a social behaviorist (C.W. Morris, Ed.). Chi- cago, IL: University of Chicago Press.\nMead, G.H. (1938). The philosophy of the act (C.W. Morris, Ed.). Chicago, IL: University of Chicago Press.\nMead, G.H. (1932/2002). The philosophy of the present. Amherst, NY: Prometheus.\nMeltzoff, A.N., & Brooks, R. (2001). ‘Like me’ as a building block for understanding other minds: Bodily acts, attention, and intention. In B.F. Malle, L.J. Moses, & D.A. Baldwin (Eds.), Intentions and intentional- ity (pp. 171–191). Cambridge, MA: MIT Press.\nMenna, R., & Cohen, N.J. (1997). Social perspective taking. In M. McCallum & W.E. Piper (Eds.), Psycho- logical mindedness: A contemporary understanding (pp. 189–210), Mahwah, NJ: Lawrence Erlbaum.\nMiller, D.L. (Ed.). (1982). The individual and the social self. Chicago, MA: University of Chicago Press. (A compendium of papers and unpublished lectures/notes by George Herbert Mead).\nMoore, C., & Corkum, V. (1994). Social understanding at the end of the fi rst year of life. Developmental Re- view, 14, 349–372.\nNicolopoulou, A., & Weintraub, J. (1998). Individual and collective representations in social context: A mod- est contribution to resuming the interrupted project of a sociocultural developmental psychology. Hu- man Development, 41, 215–235.\nPenner, J. (1991). Understanding the representational mind . Cambridge, MA: MIT Press.\nReck, A.J. (Ed.). (1964). Selected writings: George Herbert Mead. Chicago, IL: University of Chicago Press.\nRogoff, B. (1990). Apprenticeship in thinking: Cognitive development in social context. New York, NY: Oxford University Press.\nRogoff, B. (1992). Three ways to relate person and culture: Thoughts sparked by Valsiner’s review of Appren- ticeship in Thinking. Human Development, 35, 316–320.\nRogoff, B. (2003). The cultural nature of human development. Oxford, UK: Oxford University Press.\nSawyer, R.K. (2002). Emergence in psychology: Lessons from the history of non-reductionist science. Human Development, 45, 2–28.\nSchober, M.F. (1998). Different kinds of conversational perspective taking. In S.R. Fussell & R. J. Kreuz (Eds.), Social and cognitive approaches to interpersonal communication (pp. 145–174). Mahwah, NJ: Lawrence Erlbaum.\nTomasello, M. (1999). The cultural origins of cognition. Cambridge, MA: Harvard University Press.\nTomasello, M., Carpenter, M., Call, J., Behne, T., & Moll, H. (in press). Understanding and sharing inten- tions: The origins of cultural cognition. Behavioral and Brain Sciences.\nTrevarthan, C. (1993). The self born in intersubjectivity: The psychology of an infant communicating. In U.\nNeisser (Ed.), The perceived self: Ecological and interpersonal sources of self-knowledge (pp. 121–173).\nNew York, NY: Cambridge University Press.\nValsiner, J. (1991). Building theoretical bridges over a lagoon of everyday events. A review of Apprenticeship in Thinking: Cognitive Development in Social Context. Human Development, 34, 307–315.\nVygotsky, L.S. (1934/1986). Thought and language (A. Kozulin, Trans.). Cambridge, MA: MIT Press.\nVygotsky, L.S. (1978). Mind in society: The development of higher psychological processes (M. Cole, V. John- Steiner, S. Scribner, & E. Souberman, Eds.). Cambridge, MA: Harvard University Press.\nWertsch, J.V. (1991). Voices of the mind: A sociocultural approach to mediated action. Cambridge, MA: Har- vard University Press.",
    "crumbs": [
      "General",
      "Reinterpreting Internalization and Agency through G.H. Mead’s Perspectival Realism"
    ]
  },
  {
    "objectID": "extracted/Pearl-epilogue.html",
    "href": "extracted/Pearl-epilogue.html",
    "title": "The Art and Science of Cause and Effect",
    "section": "",
    "text": "CAUSALITY: Models, Reasoning, and Inference, Second Edition",
    "crumbs": [
      "Causal Inference",
      "The Art and Science of Cause and Effect"
    ]
  },
  {
    "objectID": "extracted/Pearl-epilogue.html#인과관계의-예술과-과학",
    "href": "extracted/Pearl-epilogue.html#인과관계의-예술과-과학",
    "title": "The Art and Science of Cause and Effect",
    "section": "인과관계의 예술과 과학",
    "text": "인과관계의 예술과 과학\n1996년 11월 UCLA 교수 연구 강연 프로그램의 일환으로 진행된 공개 강연입니다.\n이 강연의 주제는 인과관계(causality)입니다 - 즉, 세상에서 무엇이 무엇을 일으키는지에 대한 우리의 인식과 그것이 왜 중요한지에 관한 것입니다.\n비록 인간 사고의 기본이지만, 인과관계는 신비와 논쟁, 그리고 주의로 가려진 개념입니다. 과학자들과 철학자들이 하나의 사건이 다른 사건을 진정으로 일으키는 때를 정의하는 데 어려움을 겪어왔기 때문입니다.\n우리 모두는 수탉의 울음이 해가 뜨게 하는 원인이 아니라는 것을 이해하지만, 이런 간단한 사실조차도 수학적 방정식으로 쉽게 변환될 수 없습니다.\n오늘, 저는 이러한 종류의 현상을 연구하는 데 매우 유용하다고 생각한 아이디어들을 여러분과 공유하고자 합니다. 이러한 아이디어들은 여러분이 인과관계를 다음에 접할 때 유용할 것이라고 생각하는 실용적인 도구로 이어졌습니다.\n여기 계신 분들 중 인과관계를 다루지 않는 사람을 상상하기 어렵습니다.\n여러분이 이중 언어 교육 프로그램의 영향을 평가하든, 쥐가 음식과 위험을 어떻게 구별하는지에 대한 실험을 수행하든, 줄리어스 시저가 왜 루비콘 강을 건넜는지에 대해 추측하든, 환자를 진단하든, 누가 대통령 선거에서 이길지 예측하든, 여러분은 복잡하게 얽힌 인과관계를 다루고 있습니다.\n제가 지금부터 말씀드릴 이야기는 연구자들이 이러한 고려사항들의 복잡성을 다루고 그 의미를 명확히 하는 데 도움을 주는 것을 목표로 합니다.\n이 강연은 세 부분으로 나뉩니다.\n먼저 인과관계에 대해 다양한 학문 분야들이 겪어온 어려움에 대한 간략한 역사적 개요를 시작합니다.\n다음으로 이러한 역사적 어려움들을 줄이거나 제거하는 아이디어들을 설명합니다.\n마지막으로, 제 공학적 배경을 기념하며, 이러한 아이디어들이 어떻게 통계학과 사회과학 분야에서 실증될 간단한 실용적인 도구로 이어지는지 보여드리겠습니다.\n처음에는, 우리가 알 수 있는 한, 인과관계는 문제가 되지 않았습니다.\n왜라고 묻는 충동과 인과적 설명을 찾는 능력은 인간 발달의 매우 초기 단계에서부터 왔습니다.\n예를 들어, 성경은 지식의 나무에서 맛을 본 지 몇 시간 후에 아담이 이미 인과 논쟁의 전문가가 되었다고 알려줍니다.\n하나님이 “네가 그 나무에서 먹었느냐?”라고 물으셨을 때, 아담은 이렇게 대답합니다: “당신이 내게 주신 여자가 나무 열매를 내게 주었고, 나는 먹었습니다.”\n이브도 마찬가지로 능숙합니다: “뱀이 나를 속였고, 나는 먹었습니다.”\n이 이야기에서 주목할 점은 하나님은 설명을 요구하지 않고 단지 사실만을 물었다는 것입니다 - 설명의 필요성을 느낀 것은 아담이었습니다. 메시지는 분명합니다: 인과적 설명은 인간이 만든 개념입니다.\n이 이야기의 또 다른 흥미로운 점: 설명은 전적으로 책임을 전가하는 데 사용됩니다.\n실제로, 수천 년 동안 설명에는 다른 기능이 없었습니다. 따라서, 오직 신들, 사람들, 그리고 동물들만이 사건을 일으킬 수 있었고, 물체나 사건, 물리적 과정들은 그럴 수 없었습니다.\n자연 현상들은 고대 세계에서 사건들이 단순히 예정되어 있었기 때문에 인과적 설명에 훨씬 나중에 들어왔습니다.\n폭풍과 지진은 분노한 신들에 의해 통제되었으며, 그 결과에 대한 인과적 책임을 스스로 지지 않을 수 있었습니다.\n주사위 던지기와 같은 불규칙하고 예측 불가능한 사건조차도 우연한 사건이 아니라 적절한 해석을 요구하는 신의 메시지로 간주되었습니다.\n그러한 메시지 중 하나는 요나 선지자가 하나님의 배신자로 지목되어 바다에 던져졌을 때 그에게 큰 두려움을 주었습니다.\n요나서에서 인용하면: “선원들이 말했다: ‘누구 때문에 이 재앙이 닥쳤는지 알아보기 위해 제비를 뽑자.’ 그래서 그들이 제비를 뽑았고 제비는 요나에게 떨어졌습니다.”\n분명히, 이 호화로운 페니키아 유람선에서 “제비 뽑기”는 오락이 아니라 소통 수단으로 사용되었습니다 - 중요한 메시지를 처리하기 위한 일방향 모뎀이었습니다.\n요약하자면, 고대 세계에서 인과적 힘의 대행자는 목적을 위해 일을 일으키는 신들이거나, 자유 의지를 가진 인간과 동물들이었습니다. 그들은 이로 인해 처벌받거나 보상받았습니다.\n이러한 인과관계의 개념은 순진했지만, 명확하고 문제가 없었습니다.\n문제들은, 언제나 그렇듯이, 공학에서 시작되었습니다; 기계들이 유용한 일을 하도록 만들어져야 했을 때입니다.\n공학자들이 야심을 갖게 되면서, 그들은 지구도 움직일 수 있다고 결정했지만, 단일 지렛대로는 불가능했습니다.\n이러한 규모의 프로젝트를 위해서는 하나가 다른 것을 움직이는 많은 도르래와 바퀴로 구성된 시스템이 필요했습니다.\n그리고 사람들이 다단계 시스템을 구축하기 시작하면서, 인과관계에 흥미로운 일이 일어났습니다 - 물리적 물체들이 인과적 특성을 갖기 시작했습니다.\n그런 시스템이 고장났을 때, 신이나 운영자를 비난하는 것은 무의미했습니다 - 대신, 끊어진 로프나 녹슨 도르래가 더 유용한 설명이었습니다. 단순히 이것들은 쉽게 교체할 수 있고 시스템이 작동하게 만들 수 있기 때문입니다.\n역사의 그 시점에서, 신들과 인간들은 인과적 힘의 유일한 대행자가 되기를 멈추었습니다 - 생명이 없는 물체와 과정들이 책임의 파트너가 되었습니다.\n앞의 바퀴가 돌고 멈췄기 때문에 바퀴가 돌고 멈췄습니다 - 인간 운영자는 이차적인 존재가 되었습니다.\n놀랍게도, 이러한 새로운 인과관계의 대행자들은 그들의 전임자들 - 신들과 인간들의 일부 특성을 받아들였습니다.\n자연 물체들은 공로와 비난의 대상이 될 뿐만 아니라 힘, 의지, 심지어 목적의 담지자가 되었습니다.\n아리스토텔레스는 목적 측면에서의 설명을 어떤 것이 왜 그런지에 대한 유일하게 완전하고 만족스러운 설명으로 간주했습니다.\n그는 심지어 그것을 최종 원인(final cause)이라고 불렀습니다 - 즉, 과학적 탐구의 최종 목표였습니다.\n그 시점부터, 인과관계는 이중 역할을 수행했습니다: 원인들은 한편으로는 공로와 비난의 대상이었고, 다른 한편으로는 물리적 제어 흐름의 담지자였습니다.\n이러한 이중성은 르네상스 시대에 개념적 어려움에 봉착할 때까지 상대적으로 평온하게 유지되었습니다.\n무슨 일이 일어났는지는 1575년에 출판된 영어로 된 첫 번째 과학 서적인 레코드의 “지식의 성”이라는 책의 제목 페이지에서 볼 수 있습니다.\n운명의 수레바퀴는 신의 지혜가 아니라 인간의 무지에 의해 움직입니다.\n그리고 최종 원인으로서의 신의 역할이 인간 지식에 의해 대체되면서, 인과적 설명의 전체 개념이 공격받기 시작했습니다.\n침식은 갈릴레오의 작업으로 시작되었습니다.\n우리 대부분은 갈릴레오를 지동설을 옹호하여 종교 재판소에 세워지고 투옥된 사람으로 알고 있습니다.\n하지만 그 모든 일이 진행되는 동안, 갈릴레오는 또한 조용히 과학이 알고 있는 가장 심오한 혁명을 일으켰습니다.\n이 혁명은 로마에서 멀리 떨어진 레이든에서 출판된 1638년의 “담론(Discorsi)” 책에서 설명되었으며, 두 가지 격언으로 구성되어 있습니다:\n첫째, 설명 전에 먼저 묘사 - 즉, “어떻게”가 “왜”보다 선행한다는 것입니다.\n둘째, 묘사는 수학의 언어, 즉 방정식으로 수행됩니다.\n갈릴레오는 물체가 아래에서 끌려서인지 위에서 밀려서인지 떨어지는 이유를 묻지 말라고 했습니다.\n물체가 특정 거리를 이동하는 데 걸리는 시간을 얼마나 정확히 예측할 수 있는지, 그리고 그 시간이 물체마다 어떻게 다를지, 그리고 트랙의 각도가 변할 때 어떻게 달라질지를 물어보라고 했습니다.\n더욱이, 갈릴레오는 그러한 질문에 대한 답변을 인간 언어의 질적이고 미끄러운 뉘앙스로 시도하지 말고, 수학적 방정식의 형태로 말하라고 했습니다.\n오늘날 우리는 1638년 비에타(Vieta)가 대수적 표기법을 도입한 지 겨우 50년 후에 그 아이디어가 얼마나 이상하게 들렸는지 이해하기 어렵습니다. 대수학을 과학의 보편적 언어로 선언하는 것은 오늘날 에스페란토를 경제학의 언어로 선언하는 것과 같이 들릴 것입니다.\n자연이 왜 하필 대수학으로 말하기로 동의했을까요? 모든 언어 중에서요?\n하지만 성공에는 이의를 제기할 수 없습니다.\n물체가 이동한 거리는 실제로 시간의 제곱에 비례하는 것으로 밝혀졌습니다.\n실험 결과를 예측하는 것보다 더 성공적이었던 것은 대수 방정식의 계산적 측면이었습니다.\n그것은 엔지니어들이 역사상 처음으로 “만약 ~한다면 어떻게 될까?”라는 질문 외에도 “어떻게 해야 ~할까?”라는 질문을 할 수 있게 했습니다.\n“만약 우리가 빔을 좁히면, 그것이 하중을 견딜 수 있을까?”라고 묻는 것 외에도, 그들은 더 어려운 질문을 하기 시작했습니다: “어떻게 빔을 형성해야 하중을 견딜 수 있을까?” [14]\n이것은 방정식을 푸는 방법의 가용성으로 가능해졌습니다.\n대수적 기계는 변수들을 차별하지 않습니다; 매개변수 측면에서 행동을 예측하는 대신, 우리는 상황을 뒤집어 원하는 행동 측면에서 매개변수를 풀 수 있습니다.\n이제 갈릴레오의 첫 번째 격언 - “설명보다 기술이 먼저” - 에 집중해 봅시다. 왜냐하면 그 아이디어는 과학자들에 의해 매우 진지하게 받아들여져 과학의 성격을 사변적인 것에서 경험적인 것으로 바꾸었기 때문입니다.\n물리학은 극도로 유용한 경험적 법칙들로 가득 차게 되었습니다.\n스넬의 법칙[15], 훅의 법칙, 옴의 법칙, 줄의 법칙은 더 근본적인 원리에 의해 설명되기 훨씬 전에 발견되고 사용된 순수한 경험적 일반화의 예들입니다.\n그러나 철학자들은 인과적 설명이라는 아이디어를 포기하기를 꺼려했고, 그 성공적인 갈릴레오 방정식들의 기원과 정당성을 계속 찾았습니다.\n예를 들어, 데카르트는 원인을 영원한 진리에 귀속시켰습니다.\n라이프니츠는 원인을 자명한 논리적 법칙으로 만들었습니다.\n마침내, 갈릴레오 이후 약 100년 후, 데이비드 흄[16]이라는 이름의 스코틀랜드 철학자가 갈릴레오의 첫 번째 격언을 극단적으로 끌고 갔습니다[17].\n흄은 ’왜’가 ’어떻게’에 단순히 두 번째가 아니라, ’왜’가 ’어떻게’에 포함되어 있기 때문에 완전히 불필요하다고 설득력 있게 주장했습니다.\n흄의 “인간 본성에 관한 논문”[18] 156페이지에서, 우리는 인과관계를 오늘날까지도 회복하지 못할 정도로 철저히 흔들어 놓은 단락을 찾을 수 있습니다.\n나는 항상 그것을 읽을 때 흥분합니다: “따라서 우리는 불꽃이라고 부르는 물체의 종류를 보았고, 열이라고 부르는 감각의 종류를 느꼈던 것을 기억합니다. 우리는 마찬가지로 모든 과거의 사례에서 그들의 지속적인 연결을 기억합니다. 더 이상의 의식 없이, 우리는 하나를 원인이라 부르고 다른 하나를 결과라 부르며, 하나의 존재에서 다른 하나의 존재를 추론합니다.”\n따라서, 흄에 따르면 인과적 연결은 관찰의 산물입니다. 인과관계는 마치 광학적 환상만큼이나 허구적이고 파블로프의 조건화만큼이나 일시적인, 마음의 배울 수 있는 습관입니다.\n흄이 그의 제안된 방법에 내재된 어려움을 인식하지 못했다고 믿기는 어렵습니다.\n그는 수탉의 울음이 일출과 지속적으로 연결되어 있지만, 그것이 태양이 뜨는 원인이 아니라는 것을 매우 잘 알고 있었습니다.\n그는 기압계 판독이 비와 지속적으로 연결되어 있지만 비의 원인이 아니라는 것을 알고 있었습니다.\n오늘날 이러한 어려움들은 ’인과관계를 의미하지 않는 상관관계’라는 이름으로 분류됩니다.\n이제, 모든 지식은 마음에 상관관계로 코딩된 경험에서 온다는 흄의 격언과 상관관계가 인과관계를 의미하지 않는다는 우리의 관찰을 고려하면, 우리는 인과관계의 첫 번째 수수께끼로 이어집니다: 사람들은 어떻게 인과관계에 대한 지식을 얻게 되는가?\n우리는 수탉의 예에서 연속의 규칙성이 충분하지 않다는 것을 보았습니다; 무엇이 충분할까요?\n어떤 경험 패턴이 연결을 “인과적”이라고 부르는 것을 정당화할까요?\n게다가: 어떤 경험 패턴이 사람들에게 연결이 “인과적”이라고 확신시킬까요?\n첫 번째 수수께끼가 인과 연결의 학습에 관한 것이라면, 두 번째는 그 사용에 관한 것입니다: 내가 특정 연결이 인과적이거나 인과적이 아니라고 말하면 어떤 차이가 있을까요?\n우리의 예를 계속하면, 수탉이 태양이 뜨는 원인이라고 말하면 어떤 차이가 있을까요?\n이것은 사소한 것처럼 들릴 수 있습니다.\n명백한 대답은 “무엇이 무엇의 원인인지” 아는 것이 우리의 행동 방식에 큰 차이를 만든다는 것입니다.\n만약 수탉의 울음이 태양이 뜨는 원인이라면, 우리는 우리의 수탉을 더 일찍 깨워서 그를 울게 할 수 있습니다 - 예를 들어, 그에게 최신 수탉 농담을 해줌으로써 - 그래서 밤을 더 짧게 만들 수 있습니다.\n하지만 이 수수께끼는 생각처럼 사소하지 않습니다.\n만약 인과적 정보가 연속의 규칙성을 넘어서는 경험적 의미를 가지고 있다면, 그 정보는 물리학 법칙에 나타나야 합니다.\n하지만 그렇지 않습니다!\n철학자 버트란드 러셀은 1913년에 이런 주장을 했습니다[19]:\n“모든 철학자들은,” 러셀이 말합니다, “인과관계가 과학의 기본 공리 중 하나라고 상상하지만, 이상하게도 선진 과학에서는 ’원인’이라는 단어가 전혀 등장하지 않습니다… 나는 인과성 법칙이 과거 시대의 유물이라고 믿습니다. 군주제처럼 해를 끼치지 않는다고 잘못 생각되기 때문에만 살아남았습니다.”\n인과관계의 중요성을 주장한 또 다른 철학자 패트릭 서페스는 다음과 같이 언급했습니다:\n“’물리 리뷰’의 각 호는 제목에 ’원인’이나 ’인과성’을 사용하는 논문을 최소한 하나 이상 포함하고 있지 않은 경우가 거의 없습니다.”\n이 교환에서 우리가 결론짓는 것은 물리학자들이 한 가지 방식으로 말하고, 쓰고, 생각하면서 다른 방식으로 물리학을 공식화한다는 것입니다.\n그러한 이중 언어 활동은 인과성이 단순히 편리한 의사소통 장치로 사용된다면 - 그렇지 않으면 많은 방정식이 필요한 복잡한 물리적 관계 패턴을 표현하는 약자로 - 용서받을 수 있습니다.\n결국! 과학은 약어로 가득 차 있습니다: 우리는 “x를 5번 자신에게 더하기” 대신 “x에 5를 곱하기”를 사용합니다; 우리는 “무게와 부피의 비율” 대신 “밀도”라고 말합니다.\n왜 인과성을 문제 삼나요?\n“인과성은 다르기 때문입니다,” 러셀 경은 주장할 것입니다. “물리학 법칙은 모두 대칭적이고 양방향으로 작동하는 반면, 인과 관계는 단방향적이며 원인에서 결과로 향하기 때문에 약어일 수 없습니다.”\n예를 들어, 뉴턴의 법칙을 살펴보세요: f = ma.\n대수학의 규칙은 우리가 이 법칙을 다양한 구문 형식으로 쓸 수 있게 합니다. 모두 같은 의미입니다 - 세 가지 양 중 두 가지를 알면 세 번째가 결정된다는 것입니다.\n그러나 일반적인 담론에서 우리는 힘이 가속도의 원인이라고 말합니다 - 가속도가 힘의 원인이라고 말하지 않으며, 우리는 이 구별에 대해 매우 강한 느낌을 가지고 있습니다.\n마찬가지로, 우리는 f/a의 비율이 질량을 결정하는 데 도움이 된다고 말하지만, 그것이 질량의 원인이라고 말하지는 않습니다.\n그러한 구별은 물리학 방정식에 의해 지지되지 않으며, 이는 인과적 어휘 전체가 순전히 형이상학적인 것인지, “군주제처럼 살아남는지”를 묻게 합니다.\n다행히도, 매우 적은 수의 물리학자들만이 러셀의 수수께끼에 주의를 기울였습니다. 그들은 사무실에서 방정식을 쓰고 구내식당에서 원인-결과에 대해 이야기하는 것을 계속했습니다; 놀라운 성공으로 그들은 원자를 분해하고, 트랜지스터와 레이저를 발명했습니다.\n엔지니어링에서도 마찬가지입니다.\n그러나 다른 영역에서는 이러한 긴장이 눈에 띄지 않을 수 없었습니다. 왜냐하면 그 영역에서는 인과적 관계와 다른 관계를 구별하는 요구가 매우 명확했기 때문입니다.\n이 영역은 통계학입니다.\n이야기는 약 100년 전, 상관관계의 발견으로 시작됩니다.\n프란시스 갈톤[20], 지문법의 발명가이자 찰스 다윈의 사촌은, 꽤 이해할 수 있게도 재능과 미덕이 가족 내에서 이어진다는 것을 증명하고자 했습니다.\n갈톤의 연구는 그로 하여금 한 집단의 개인이나 물체의 특성이 다른 집단의 특성과 어떻게 관련되는지 측정하는 다양한 방법을 고려하게 했습니다.\n1888년, 그는 사람의 팔뚝 길이와 그 사람의 머리 크기를 측정하고 이 두 양 중 하나가 다른 하나를 어느 정도 예측할 수 있는지 질문했습니다[21].\n그는 다음과 같은 발견에 우연히 도달했습니다: 만약 당신이 한 양을 다른 양에 대해 그래프로 그리고 두 축을 적절히 조정한다면, 최적 적합선의 기울기는 몇 가지 좋은 수학적 특성을 가집니다. 기울기는 한 양이 다른 양을 정확히 예측할 수 있을 때만 1이 됩니다; 예측이 무작위 추측보다 나을 것이 없을 때는 0이 됩니다; 그리고 가장 놀랍게도, 기울기는 X를 Y에 대해 그래프로 그리든 Y를 X에 대해 그래프로 그리든 동일합니다.\n“상관관계(co-relation)는 두 기관의 변이가 부분적으로 공통 원인에 기인한다는 결과임을 보는 것은 쉽습니다,”라고 갈톤은 말했습니다.\n여기에서 우리는 처음으로 두 변수가 서로 어떻게 “관련”되어 있는지에 대한 객관적인 측정법을 갖게 되었습니다. 이는 순전히 데이터에 기반하여, 인간의 판단이나 의견과는 별개로 이루어집니다.\n갈톤의 발견은 그의 제자 중 한 명인 칼 피어슨[22]을 매료시켰습니다. 그는 현대 통계학의 창시자 중 한 명으로 간주됩니다.\n피어슨은 당시 30세였으며, 변호사로 전향하려던 성취된 물리학자이자 철학자였습니다. 그리고 이것이 그가 45년 후[23] 갈톤의 발견에 대한 그의 초기 반응을 묘사하는 방식입니다:\n“나는 드레이크 시대의 해적처럼 느꼈습니다…”\n“나는… 갈톤이 인과관계보다 더 넓은 범주, 즉 상관관계가 있으며, 인과관계는 그 한계일 뿐이고, 이 새로운 상관관계 개념이 심리학, 인류학, 의학, 그리고 사회학의 큰 부분을 수학적 처리의 영역으로 가져왔다는 것을 의미한다고 해석했습니다.”\n이제, 피어슨은 “한니발을 알프스로, 마르코 폴로를 중국으로 데려간 종류의 추진력과 결단력을 가진 사람”으로 묘사되었습니다.\n피어슨이 해적처럼 느꼈을 때, 그가 그의 전리품을 얻게 될 것이라고 확신할 수 있습니다.\n1911년에는 그의 책 “과학의 문법”의 3판이 출판되었습니다. 여기에는 “우발성과 상관관계 - 인과관계의 불충분성”이라는 새로운 장이 포함되어 있었고, 이것이 피어슨이 그 장에서 말한 내용입니다:\n“’물질’과 ’힘’과 같은 폐기된 기본 개념들을 넘어서, 현대 과학의 불가해한 비밀 가운데 또 다른 우상이 놓여 있습니다. 바로 인과관계의 범주입니다.”\n그리고 피어슨은 구시대적인 인과관계 범주를 무엇으로 대체합니까? 여러분은 귀를 믿지 못할 것입니다: 우발성 테이블[24]입니다.\n“이러한 표는 우발성 테이블이라고 하며, 두 가지 사이의 관계에 대한 궁극적인 과학적 진술이나 설명은 항상 이러한 우발성 테이블로 되돌릴 수 있습니다…”\n“독자가 이러한 표의 성격을 깨닫는 순간, 그는 원인과 결과 사이의 연관 개념의 본질을 파악하게 될 것입니다.”\n따라서, 피어슨은 상관관계를 넘어선 독립적인 인과관계 개념의 필요성을 단호히 부정합니다.\n그는 평생 동안 이 견해를 유지했으며, 그에 따라 그의 기술적 논문 어디에서도 인과관계를 언급하지 않았습니다.\n“의지”와 “힘”과 같은 정령론적 개념들에 대한 그의 십자군 원정은 너무 격렬했고 결정론에 대한 그의 거부는 너무 절대적이어서, 그는 인과관계가 통계학에 뿌리를 내릴 기회를 갖기도 전에 통계학에서 인과관계를 근절시켰습니다.\n25년이 더 지나고 또 다른 강한 의지의 인물인 로널드 피셔 경[25]이 등장하기까지 통계학자들은 무작위 실험을 공식화했습니다. 이는 데이터로부터 인과관계를 테스트하는 유일하게 과학적으로 입증된 방법이며, 오늘날까지도 주류 통계학에서 허용되는 유일한 인과 개념입니다.\n그리고 대략 오늘날의 상황이 그렇습니다.\n인과관계에 관해 작성된 박사 논문, 연구 논문 또는 교과서 페이지 수를 세면, 피어슨이 여전히 통계학을 지배하고 있다는 인상을 받습니다.\n“통계과학 백과사전”은 상관관계에 12페이지를 할애하지만 인과관계에는 단 2페이지만 할애하며 - 그 중 한 페이지는 “상관관계가 인과관계를 의미하지 않는다”는 것을 보여주는 데 사용됩니다.\n현대 통계학자들이 인과관계에 대해 무엇이라고 말하는지 들어봅시다.\n“생물통계학(Biometrika)” (피어슨이 창간한 저널)의 현 편집자 필립 도위드(Philip Dawid)는 인정합니다: “인과추론은 통계학의 가장 중요하고, 가장 미묘하며, 가장 간과된 문제 중 하나입니다.”\n생물측정학회(Biometric Society)의 전 회장이자 (O.J. 심슨 살인 재판의 전문 증인으로 기억하실) 테리 스피드(Terry Speed)는 선언합니다: “인과관계에 대한 고려는 통계학에서 항상 다루어진 방식으로 다루어져야 합니다: 가급적이면 전혀 다루지 않되, 필요하다면 매우 큰 주의를 기울여야 합니다.”\n데이비드 콕스 경과 낸시 베르무스(Nanny Wermuth)는 몇 달 전에 출판된 책에서 다음과 같이 사과합니다: “우리는 이 책에서 인과적 또는 인과관계라는 단어를 사용하지 않았습니다… 우리가 조심스러운 이유는 한 연구에서 인과관계에 대한 확고한 결론을 내릴 수 있는 경우가 드물기 때문입니다.”\n이러한 주의와 회피의 입장은 지침을 위해 통계학을 바라보는 많은 분야, 특히 경제학과 사회과학을 마비시켰습니다.\n한 저명한 사회과학자는 1987년에 다음과 같이 말했습니다: “더 많은 연구자들이 원인과 결과와 같은 용어를 생각하고 사용하는 것을 포기한다면 매우 건강할 것입니다.”\n이러한 상황이 단 한 사람의 작업일 수 있을까요? 심지어 피어슨 같은 해적도 말입니까?\n저는 그것을 의심합니다.\n그러나 어떻게 다른 방식으로 통계학이, 가설 검정과 실험 설계와 같은 강력한 개념을 세계에 제공한 분야가, 인과관계에 대해서는 너무 일찍 포기했는지 설명할 수 있을까요?\n한 가지 명백한 설명은 물론 인과관계가 상관관계보다 측정하기 훨씬 어렵다는 것입니다.\n상관관계는 단일 통제되지 않은 연구에서 직접 추정할 수 있지만, 인과적 결론은 통제된 실험을 필요로 합니다.\n하지만 이것은 너무 단순합니다; 통계학자들은 어려움에 쉽게 굴하지 않으며, 아이들은 통제된 실험을 수행하지 않고도 인과관계를 배울 수 있습니다.\n답은 제 생각에 더 깊이 있으며, 그것은 통계학의 공식 언어, 즉 확률의 언어와 관련이 있습니다.\n이것이 여러분 중 일부에게는 놀라울 수 있겠지만, ’원인’이라는 단어는 확률 이론의 어휘에 없습니다; 우리는 확률의 언어로 ’진흙이 비를 일으키지 않는다’는 문장을 표현할 수 없습니다 - 우리가 말할 수 있는 것은 두 가지가 상호 연관되어 있거나 의존적이라는 것뿐입니다 - 즉, 하나를 발견하면 다른 하나를 예상할 수 있다는 의미입니다.\n당연히, 특정 개념을 명시적으로 표현할 언어가 부족하다면, 우리는 그 개념을 중심으로 과학적 활동이 발전할 것을 기대할 수 없습니다.\n과학적 발전은 지식이 한 연구에서 다른 연구로 신뢰성 있게 전달되는 것을 요구하며, 갈릴레오가 350년 전에 보여준 바와 같이, 그러한 전달은 형식 언어의 정밀성과 계산적 이점을 필요로 합니다.\n저는 곧 언어와 표기법의 중요성에 대해 논의하러 돌아오겠지만, 먼저 인과관계가 어려움을 겪은 또 다른 분야의 이야기로 이 역사적 개요를 마무리하고 싶습니다.\n이번에는 컴퓨터 과학입니다 - 기호의 과학으로, 비교적 새로운 분야이지만 언어와 표기법에 엄청난 중요성을 둔 분야이므로 문제에 대한 유용한 관점을 제공할 수 있습니다.\n연구자들이 컴퓨터를 사용하여 인과관계를 인코딩하기 시작했을 때, 인과관계의 두 수수께끼가 새로운 활력으로 일깨워졌습니다.\n이 로봇[26]의 입장이 되어 주방이나 실험실에서 무슨 일이 일어나고 있는지 이해하려고 노력해보세요.\n개념적으로, 로봇의 문제는 국가 부채를 모델링하려는 경제학자나 질병의 확산을 이해하려는 역학자가 직면한 문제와 동일합니다.\n우리의 로봇, 경제학자, 역학자 모두 제한된 행동과 노이즈가 있는 관찰을 사용하여 환경에서 인과 관계(cause-effect relations)를 추적해야 합니다.\n이것은 그들을 인과관계에 관한 흄(Hume)의 첫 번째 수수께끼로 이끕니다: 어떻게?\n인과관계의 두 번째 수수께끼도 로봇의 세계에서 역할을 합니다.\n우리가 지름길을 택해서 이 방에서의 원인과 결과에 대해 우리가 알고 있는 모든 것을 로봇에게 가르치고 싶다고 가정해 봅시다[27].\n로봇은 이 정보를 어떻게 구성하고 활용해야 할까요?\n따라서, 인과관계의 두 가지 철학적 수수께끼는 이제 구체적이고 실용적인 질문으로 변환됩니다:\n로봇은 환경과의 상호작용을 통해 어떻게 인과 정보를 획득해야 할까요? 로봇은 창조자-프로그래머로부터 받은 인과 정보를 어떻게 처리해야 할까요?\n다시 말하지만, 두 번째 수수께끼는 생각만큼 사소하지 않습니다. 인과 관계와 물리 방정식이 양립할 수 없다는 러셀 경(Lord Russell)의 경고는 이제 논리의 명백한 결함으로 나타납니다.\n예를 들어, “잔디가 젖어 있으면, 비가 왔다”와 “이 병을 깨뜨리면, 잔디가 젖을 것이다”라는 정보가 주어지면, 컴퓨터는 “이 병을 깨뜨리면, 비가 왔다”라고 결론을 내릴 것입니다[28].\n이러한 프로그래밍 버그가 표면화되는 빠른 속도와 특이성으로 인해 인공 지능 프로그램은 인과관계의 세부 사항을 연구하는 이상적인 실험실이 되었습니다.\n이것은 강의의 두 번째 부분으로 이어집니다: 방정식과 그래프를 결합하여 인과관계의 두 번째 수수께끼를 어떻게 해결할 수 있는지, 그리고 이 해결책이 첫 번째 수수께끼를 덜 어렵게 만드는 방법입니다.\n원인과 결과의 예술과 과학 413\n이 해결책에서 가장 중요한 아이디어는 다음과 같습니다: 첫째 - 인과관계를 개입(interventions) 하에서의 행동의 요약으로 취급하는 것입니다. 둘째 - 방정식과 그래프를 인과적 사고가 표현되고 조작될 수 있는 수학적 언어로 사용하는 것입니다.\n그리고 이 둘을 결합하기 위해서는 세 번째 개념이 필요합니다: 개입을 방정식에 대한 수술(surgery)로 취급하는 것입니다.\n인과관계를 광범위하게 사용하고 이와 관련해 문제가 없었던 분야부터 시작해 봅시다: 공학입니다.\n여기 회로도의 공학 도면[29]이 있는데, 이는 회로의 신호들 간의 인과 관계를 보여줍니다. 이 회로는 AND 게이트와 OR 게이트로 구성되어 있으며, 각각은 입력과 출력 사이에서 논리 함수를 수행합니다. 이 다이어그램을 자세히 살펴봅시다. 그 단순함과 친숙함이 매우 기만적입니다. 사실, 이 다이어그램은 과학의 가장 위대한 경이로움 중 하나입니다. 수백만 개의 대수 방정식이나 확률 함수 또는 논리 표현보다 더 많은 정보를 전달할 수 있습니다. 이 다이어그램을 훨씬 더 강력하게 만드는 것은 정상 조건에서 회로가 어떻게 동작하는지뿐만 아니라 수백만 개의 비정상 조건에서 회로가 어떻게 동작할지 예측할 수 있는 능력입니다. 예를 들어, 이 회로도가 주어지면 어떤 입력이 0에서 1로 변경될 때 출력이 어떻게 될지 쉽게 알 수 있습니다. 이는 정상적이며 간단한 입력-출력 방정식으로 쉽게 표현할 수 있습니다. 이제 비정상적인 부분이 나옵니다. 우리는 Y를 0(제로)으로 설정하거나, X에 연결하거나, 이 AND 게이트를 OR 게이트로 변경하거나, 이러한 작업의 수백만 가지 조합 중 어느 것을 수행할 때 출력이 어떻게 될지도 알 수 있습니다. 이 회로의 설계자는 그러한 이상한 개입을 예상하거나 고려하지 않았지만, 놀랍게도 우리는 그 결과를 예측할 수 있습니다. 어떻게요? 이러한 표현력은 어디서 오는 것일까요?\n이는 초기 경제학자들이 자율성(autonomy)이라고 부른 것에서 비롯됩니다. 즉, 이 다이어그램의 게이트들은 독립적인 메커니즘을 나타냅니다 - 다른 것을 변경하지 않고 하나를 변경하는 것이 쉽습니다. 다이어그램은 이러한 독립성을 활용하여 개입 하에서도 변경되지 않는 빌딩 블록을 정확히 사용하여 회로의 정상 기능을 설명합니다.\n볼터 홀(Boelter Hall)의 제 동료들은 제가 마치 세계의 8번째 경이로움인 것처럼 공학적 사소함에 대해 떠들고 있는 것을 의아해하고 있을 것입니다. 저는 이렇게 하는 데 세 가지 이유가 있습니다. 첫째, 저는 엔지니어들이 당연시하는 관행에 많은 미개발된 지혜가 있다는 것을 보여드리려고 합니다.\n둘째, 저는 경제학자들과 사회과학자들에게 이 다이어그램적 방법의 이점을 상기시키려고 합니다. 그들은 75년 이상 구조방정식 모델링(structural equation modeling)과 경로 다이어그램(path diagrams)이라는 유사한 방법을 간헐적으로 사용해 왔지만, 최근 몇 년 동안 대수적 편의성이 다이어그램 표현과 그 이점을 억제하도록 허용했습니다. 마지막으로, 이러한 다이어그램은 인과관계의 본질, 즉 비정상적인 상황과 새로운 조작의 결과를 예측하는 능력을 포착한다고 생각합니다. 예를 들어, S.Wright의 다이어그램[30]에서는 입력으로 보여지는 환경적 요인(E)이나 심지어 부모와 자손 사이의 중간 노드로 보여지는 유전적 요인(H)을 변경할 경우 기니피그 새끼의 코트 패턴이 어떻게 될지 예측할 수 있습니다. 이러한 예측은 대수적 또는 상관관계 분석만으로는 불가능합니다.\n인과관계를 이런 방식으로 보면 과학자들이 왜 그렇게 열성적으로 인과적 설명을 추구하는지, 그리고 인과 모델을 얻는 것이 왜 “깊은 이해”와 “통제력을 가진다”는 느낌을 주는지 설명할 수 있습니다.\n깊은 이해[31]란 단지 어제 일이 어떻게 일어났는지 아는 것이 아니라 새로운 가상의 상황에서 일이 어떻게 일어날지 아는 것을 의미하며, 통제는 그러한 상황 중 하나입니다. 흥미롭게도, 우리가 그러한 이해를 가질 때, 실제로 통제할 실용적인 방법이 없더라도 “통제감”을 느낍니다. 예를 들어, 우리는 천체 운동을 통제할 실용적인 방법이 없지만, 그럼에도 불구하고 중력 이론은 우리에게 이해와 통제의 느낌을 줍니다. 왜냐하면 가상의 통제를 위한 청사진을 제공하기 때문입니다. 우리는 예상치 못한 새로운 사건(예: 달이 유성에 부딪히거나 중력 상수가 갑자기 2배로 감소하는 경우)이 조수파에 미치는 영향을 예측할 수 있으며, 똑같이 중요한 것은 중력 이론이 지구상의 일반적인 조작이 조수파를 통제하지 않을 것이라는 확신을 제공한다는 것입니다. 인과 모델이 반응적이거나 본능적인 반응과 의도적인 추론을 구별하는 리트머스 테스트로 간주되는 것은 놀라운 일이 아닙니다. 새와 원숭이들은 깨진 전선을 고치는 것과 같은 복잡한 작업을 수행하도록 훈련될 수 있을지 모르지만, 그것은 시행착오 훈련이 필요합니다. 반면, 의도적인 추론자는 그러한 조작을 시도해보지 않고도 새로운 조작의 결과를 예상할 수 있습니다.\n회로도의 일부를 확대해 봅시다[32]. 그러면 왜 다이어그램이 방정식이 예측할 수 없는 결과를 예측할 수 있는지 이해할 수 있습니다. 또한 논리 게이트에서 선형 방정식으로 전환하고(모두가 더 편안하게 느끼도록), 우리가 단 두 개의 구성 요소를 포함하는 시스템을 다루고 있다고 가정해 봅시다: 승수기(multiplier)와 가산기(adder)입니다. 승수기는 입력을 받아 2배의 인자로 곱합니다. 가산기는 입력을 받아 1을 더합니다. 이 두 구성 요소를 설명하는 방정식은 왼쪽에 제시되어 있습니다.\n하지만 이 방정식들은 오른쪽의 다이어그램과 동등한가요? 분명히 아닙니다! 만약 그렇다면, 변수들을 바꿔보고, 결과적으로 나온 두 방정식은 아래 표시된 회로와 동등해야 합니다. 하지만 이 두 회로는 다릅니다. 위쪽 회로는 Y를 물리적으로 조작하면 Z에 영향을 미칠 것이라고 알려주지만, 아래쪽 회로는 Y를 조작하면 X에 영향을 미치고 Z에는 영향을 미치지 않을 것을 보여줍니다. 게다가, 우리의 방정식에 추가적인 대수 연산을 수행함으로써, 우리는 아래에 보이는 두 개의 새로운 방정식을 얻을 수 있습니다. 이것들은 구조를 전혀 가리키지 않습니다. 단순히 세 변수에 대한 두 가지 제약 조건을 나타낼 뿐, 그것들이 서로 어떻게 영향을 미치는지 알려주지 않습니다. Y를 물리적으로 조작하는 - 예를 들어, Y를 0으로 설정하는 - 효과를 결정하는 정신적 과정을 더 자세히 살펴봅시다[33]. 분명히, 우리가 Y를 0으로 설정할 때, X와 Y 사이의 관계는 더 이상 곱셈기(multiplier)에 의해 주어지지 않습니다. 이제 X가 아무런 영향을 미치지 못하는 새로운 메커니즘이 Y를 제어합니다. 방정식 표현에서는 Y → 2X라는 방정식을 Y → 0이라는 새로운 방정식으로 대체하고 새로운 방정식 집합을 풀면 Z → 1이 됩니다. 만약 우리가 하단 모델을 나타내는 하단 방정식 쌍에 이 수술을 수행하면, 당연히 다른 해결책을 얻게 됩니다. 두 번째 방정식을 대체해야 할 것이고, 이는 X → 0을 산출하고 Z는 제약받지 않게 됩니다.\n이제 이 중재(intervention) 모델이 어떻게 인과관계의 공식적 정의로 이어지는지 볼 수 있습니다: “Y가 Z의 원인이라는 것은 Y를 조작함으로써 Z를 변경할 수 있다는 것입니다. 즉, Y에 대한 방정식을 외과적으로 제거한 후, Z에 대한 해결책이 Y에 대해 대체한 새로운 값에 의존하게 된다는 것입니다.” 또한 이 과정에서 다이어그램이 얼마나 중요한지도 볼 수 있습니다. 다이어그램은 Y를 조작할 때 어떤 방정식을 삭제해야 하는지 알려줍니다. 그 정보는 화면 하단에 표시된 것처럼 방정식을 대수적으로 동등한 형태로 변환할 때 완전히 사라져버립니다. 이 방정식 쌍만으로는 Y를 0으로 설정한 결과를 예측하는 것이 불가능합니다. 왜냐하면 어떤 수술을 수행해야 할지 모르기 때문입니다 - “Y에 대한 방정식”이라는 것이 존재하지 않습니다.\n요약하자면, 중재는 방정식에 대한 수술(다이어그램에 의해 안내됨)이며 인과관계는 그러한 수술의 결과를 예측하는 것을 의미합니다.\n이것은 물리적 시스템을 넘어서는 보편적인 주제입니다. 사실, 중재를 “방정식을 지우는” 것으로 모델링하는 아이디어는 1960년에 경제학자인 Herman Wold에 의해 처음 제안되었지만, 그의 가르침은 경제학 문헌에서 거의 사라졌습니다. 역사책들은 이 미스터리한 사라짐을 Wold의 성격 탓으로 돌리지만, 저는 이유가 더 깊다고 믿습니다: 초기 계량경제학자들은 매우 신중한 수학자들이었습니다. 그들은 자신들의 대수학을 깨끗하고 형식적으로 유지하기 위해 열심히 싸웠고, 다이어그램과 같은 요령으로 그것이 오염되는 것을 동의할 수 없었습니다. 그리고 화면에서 볼 수 있듯이, 수술 작업은 다이어그램 없이는 수학적 의미가 없습니다. 왜냐하면 이것은 우리가 방정식을 쓰는 방식에 민감하기 때문입니다.\n이 새로운 수학적 연산의 속성을 설명하기 전에, 통계학과 경제학의 개념을 명확히 하는 데 얼마나 유용한지 시연해 보겠습니다.\n왜 우리는 비통제 연구보다 통제된 실험을 선호할까요? 특정 장애를 앓고 있는 환자들의 회복에 대한 약물 치료의 효과를 연구하고 싶다고 가정해 봅시다. 각 환자의 행동을 지배하는 메커니즘은 구조적으로 앞서 본 회로 다이어그램과 유사합니다. 회복은 치료와 사회경제적 조건, 생활 방식, 식이요법, 나이 등의 다른 요인들의 함수입니다. 여기서는 그러한 요인 중 하나만 표시됩니다 [34].\n통제되지 않은 조건에서는 치료 선택은 환자에게 달려 있으며 환자의 사회경제적 배경에 따라 달라질 수 있습니다. 이것은 문제를 야기합니다. 왜냐하면 회복률의 변화가 치료 때문인지 그러한 배경 요인들 때문인지 알 수 없기 때문입니다. 우리가 원하는 것은 비슷한 배경을 가진 환자들을 비교하는 것이며, 이것이 바로 Fisher의 무작위 실험이 달성하는 것입니다. 어떻게? 실제로 이것은 무작위화(randomization)와 중재(intervention) 두 부분으로 구성됩니다.\n중재란 개인의 자연스러운 행동을 변경한다는 것을 의미합니다: 우리는 피험자들을 치료군과 대조군이라는 두 그룹으로 나누고, 피험자들이 실험 정책을 따르도록 설득합니다. 우리는 정상적인 상황에서는 치료를 받지 않을 일부 환자들에게 치료를 할당하고, 그렇지 않으면 치료를 받을 환자들에게 위약(placebo)을 제공합니다. 이것은 우리의 새로운 어휘에서는 수술을 의미합니다 - 우리는 하나의 기능적 연결을 끊고 다른 것으로 대체하고 있습니다. Fisher의 위대한 통찰은 새로운 연결을 무작위 동전 던지기에 연결하면 우리가 끊고자 하는 연결이 실제로 끊어진다는 것을 보장한다는 것이었습니다. 그 이유는 무작위 동전은 거시적 수준에서 우리가 측정할 수 있는 어떤 것에도 영향을 받지 않는 것으로 가정되기 때문입니다 - 물론 환자의 사회경제적 배경도 포함됩니다.\n이 그림은 보편적으로 받아들여지는 무작위 시험 절차에 대한 의미 있고 공식적인 근거를 제공합니다. 반면에, 다음 예제는 수술 아이디어를 사용하여 널리 받아들여지는 절차의 부적절함을 지적합니다.\n이 예제[35]는 정부 관리가 어떤 정책 - 예를 들어, 과세 - 의 경제적 결과를 평가하려고 시도하는 것을 포함합니다. 세금을 올리거나 내리는 의도적인 결정은 경제 모델에 대한 수술입니다. 왜냐하면 그것은 모델이 구축되었을 때 존재하던 조건을 수정하기 때문입니다. 경제 모델은 일정 기간 동안 수집된 데이터를 기반으로 구축되며, 이 기간 동안 세금은 일부 경제적 조건이나 정치적 압력에 대응하여 내려가고 올라갔습니다.\n그러나 정책을 평가할 때, 우리는 동일한 경제적 조건 하에서 대안 정책들을 비교하고 싶습니다 - 즉, 과거에 정책들을 그러한 조건에 연결했던 이 연결을 끊고 싶습니다. 이러한 설정에서는 물론 우리의 정책을 동전 던지기에 연결하고 통제된 실험을 실행하는 것이 불가능합니다. 우리는 그것을 위한 시간이 없고, 실험이 끝나기 전에 경제를 망칠 수도 있습니다. 그럼에도 불구하고 우리가 수행해야 할 분석은 수술되지 않은 모델에 의해 지배되는 데이터로부터 이 절단된 모델의 행동을 추론하는 것입니다.\n저는 ’수행해야 한다’고 말했습니다. 왜냐하면 어떤 경제학 교과서에서도 그러한 분석을 찾을 수 없기 때문입니다. 앞서 언급했듯이, Herman Wold의 수술 아이디어는 1970년대에 경제학 문헌에서 철저히 제거되었으며, 제가 찾을 수 있는 모든 정책 분석에 관한 논의는 절단된 모델이 전반적으로 지배한다고 가정합니다. 평가 시점에 과세가 정부 통제 하에 있다는 것이 과세를 전체적으로 외생 변수로 취급하기에 충분하다고 가정되지만, 실제로 과세는 모델 구축 단계에서는 내생 변수이며 평가될 때만 외생 변수가 됩니다. 물론, 저는 수술 모델을 복원하면 정부가 하룻밤 사이에 예산을 균형 잡을 수 있다고 주장하는 것이 아니지만, 그것은 확실히 시도해 볼 가치가 있는 것입니다.\n이제 수술 해석이 어떻게 인과 관계의 방향성과 물리 방정식의 대칭성 사이의 충돌에 관한 Russell의 수수께끼를 해결하는지 살펴보겠습니다. 물리학의 방정식은 실제로 대칭적이지만, “A가 B를 일으킨다” 대 “B가 A를 일으킨다”라는 문구를 비교할 때, 우리는 단일 방정식 집합에 대해 이야기하는 것이 아닙니다. 오히려, 우리는 두 가지 다른 방정식 집합으로 표현되는 두 세계 모델을 비교하고 있습니다: 하나는 A에 대한 방정식이 외과적으로 제거된 것이고, 다른 하나는 B에 대한 방정식이 제거된 것입니다. Russell은 아마도 이 시점에서 우리를 멈추고 물을 것입니다: “실제로는 물리학의 모든 방정식을 합친 하나의 세계 모델만 있는데, 어떻게 두 세계 모델에 대해 이야기할 수 있는가?” 대답은: 맞습니다. 만약 당신이 모델에 전체 우주를 포함시키기를 원한다면, 인과관계는 사라집니다. 왜냐하면 중재가 사라지기 때문입니다 - 조작하는 자와 조작되는 것이 그들의 구분을 잃게 됩니다. 그러나 과학자들은 거의 우주 전체를 조사 대상으로 고려하지 않습니다. 대부분의 경우 과학자는 우주에서 한 조각을 잘라내어 그 조각을 ‘인(in)’으로 선언합니다 - 즉, 조사의 초점입니다. 우주의 나머지 부분은 ’아웃(out)’ 또는 배경으로 간주되며 경계 조건이라고 부르는 것으로 요약됩니다. 이러한 인과 아웃의 선택은 우리가 사물을 바라보는 방식에 비대칭성을 만들어내고, 이 비대칭성이 우리로 하여금 “외부 중재”에 대해 이야기할 수 있게 하며, 따라서 인과관계와 원인-결과 방향성에 대해 이야기할 수 있게 합니다.\n이것은 데카르트의 고전적인 그림[36]을 사용하여 꽤 멋지게 설명할 수 있습니다. 전체로서, 이 손-눈 시스템은 인과관계에 대해 아무것도 모릅니다. 그것은 단지 슈뢰딩거 방정식을 최선을 다해 따르려는 입자와 광자의 혼란스러운 플라즈마일 뿐이며, 이 방정식은 대칭적입니다.\n그러나 그것에서 한 덩어리를 잘라내서 - 예를 들어, 객체 부분[37] - 우리는 손의 움직임이 이 빛의 광선이 각도를 변경하게 하는 원인이라고 말할 수 있습니다.\n다른 방식으로 잘라내서, 뇌 부분[38]에 초점을 맞추면, 보라! 이제는 빛의 광선이 손이 움직이게 하는 원인입니다 - 정확히 반대 방향입니다. 교훈은 우리가 우주를 어떻게 잘라내는가가 우리가 원인과 결과와 연관시키는 방향성을 결정한다는 것입니다. 그러한 잘라내기는 모든 과학적 조사에서 암묵적으로 가정됩니다. 인공지능에서는 J. McCarthy에 의해 “circumscription”이라고 불렸습니다. 경제학에서 circumscription은 모델 내에서 어떤 변수가 내생적으로 간주되고 어떤 것이 외생적인지, 모델 내부인지 외부인지를 결정하는 것을 의미합니다.\n방정식 모델과 인과 모델 사이의 본질적인 차이를 요약해 봅시다[39]. 둘 다 정상 조건을 설명하기 위해 대칭 방정식 집합을 사용합니다. 그러나 인과 모델은 세 가지 추가 요소를 포함합니다: (i) 인(in)과 아웃(out) 사이의 구별; (ii) 각 방정식이 독립적인 메커니즘에 해당하므로 별도의 수학적 문장으로 보존되어야 한다는 가정; 그리고 (iii) 그러한 메커니즘에 대한 수술로 해석되는 중재. 이것은 우리를 인과관계를 물리학의 친숙한 부분으로 만드는 꿈을 실현하는 데 더 가깝게 합니다. 그러나 하나의 요소가 빠져있습니다: 대수학. 우리는 앞서, 갈릴레오 시대의 과학자들과 엔지니어들에게 대수학의 계산 기능이 얼마나 중요했는지 논의했습니다. 우리는 그러한 대수학적 기능이 인과관계에도 도움이 될 것으로 기대할 수 있을까요? 다르게 표현해 보겠습니다: 우리가 알고 있는 과학적 활동은 두 가지 기본 요소로 구성됩니다:\n관찰[40]과 중재[41].\n둘의 조합이 우리가 실험실[42]이라고 부르는 것입니다. 실험실은 우리가 일부 조건을 통제하고 다른 조건을 관찰하는 장소입니다. 표준 대수학이 관찰 요소에는 매우 잘 기여했지만 지금까지는 중재 요소에는 혜택을 주지 못했다는 것이 우연히 발생했습니다. 이것은 방정식의 대수학, 부울 대수학, 확률 계산에 모두 해당됩니다 - 모두 관찰 문장을 제공하도록 맞춰져 있지만 중재 문장에는 맞춰져 있지 않습니다.\n예를 들어, 확률 이론을 살펴보겠습니다. 만약 우리가 잔디가 젖었다는 것을 보고, 비가 왔을 확률을 알고 싶다면, 우리는 다음과 같이 형식적인 문장으로 우리의 질문을 표현할 수 있습니다: P(Rain | Wet). “젖었다는 것을 보고, 비가 왔을 확률”로 읽습니다[43]. 수직 막대는 “~를 본다는 조건 하에”라는 구문을 나타냅니다. 우리는 이 질문을 공식적인 문장으로 표현할 수 있을 뿐만 아니라, 확률 이론의 기계를 사용하여 문장을 다른 표현으로 변환할 수도 있습니다. 우리 예에서는, 왼쪽 문장을 오른쪽 문장으로 변환할 수 있습니다. 만약 더 편리하거나 유익하다고 생각한다면 말입니다.\n그러나 다른 질문을 한다고 가정해 봅시다: “우리가 잔디를 젖게 만든다면, 비가 왔을 확률은 얼마인가?” 우리는 확률의 구문으로 우리의 질문을 표현할 수 없습니다. 왜냐하면 수직 막대는 이미 “~를 본다는 조건 하에”라는 의미로 사용되고 있기 때문입니다. 우리는 ’do’라는 새로운 기호를 발명할 수 있고, 막대 뒤에 do를 볼 때마다 “우리가 ~를 한다는 조건 하에”로 읽을 수 있습니다 - 그러나 이것은 확률의 규칙이 이 새로운 읽기에 적용되지 않기 때문에 우리의 질문에 대한 답을 계산하는 데 도움이 되지 않습니다. 우리는 직관적으로 답이 무엇이어야 하는지 알고 있습니다: P(Rain). 왜냐하면 잔디를 젖게 만드는 것은 비가 올 확률을 변경하지 않기 때문입니다. 그러나 이 직관적인 답변과 이와 유사한 다른 답변들이 직관이 실패할 때 우리의 생각을 위로할 수 있도록 기계적으로 도출될 수 있을까요?\n대답은 예이며, 새로운 대수학이 필요합니다. 먼저, 우리는 “우리가 ~를 한다는 조건 하에”라는 새로운 연산자에 기호를 할당합니다. 둘째, 우리는 이 새로운 기호를 포함하는 문장을 조작하는 규칙을 찾습니다. 우리는 수학자들이 표준 대수학의 규칙을 찾은 방식과 유사한 과정을 통해 그것을 수행합니다.\n당신이 16세기의 수학자라고 상상해 보세요. 당신은 이제 덧셈의 대수학 전문가이고, 하루 종일 숫자를 자신에게 더하는 데 지쳐서 새로운 연산자, 곱셈을 도입할 급박한 필요성을 느낍니다[44]. 당신이 가장 먼저 하는 일은 새로운 연산자에 기호를 할당하는 것입니다: 곱하기. 그런 다음 연산자의 의미로 내려가서 그 변환 규칙을 추론할 수 있습니다. 예를 들어: 곱셈의 교환 법칙은 그런 방식으로 추론될 수 있습니다. 결합 법칙 등이 있습니다. 우리는 이제 이 모든 것을 고등학교에서 배웁니다.\n정확히 같은 방식으로, 우리는 새로운 기호를 지배하는 규칙을 추론할 수 있습니다: do(·). 우리는 보는 것에 대한 대수학을 가지고 있습니다 - 즉, 확률 이론. 우리는 새로운 옷을 입고 매우 명확한 의미를 가진 새로운 연산자를 가지고 있으며, 이것은 수술 절차에 의해 우리에게 주어집니다. 추론의 문이 열려 있고, 그 결과는 다음 슬라이드[45]에 주어져 있습니다.\n놀라지 마세요. 저는 당신이 지금 이 방정식들을 읽기를 기대하지 않습니다. 하지만 당신은 이 새로운 계산의 맛을 느낄 수 있을 것이라고 생각합니다. 그것은 행동과 관찰을 포함하는 표현을 다른 유형의 표현으로 변환할 수 있게 해주는 세 가지 규칙으로 구성됩니다. 첫 번째는 무관한 관찰을 무시할 수 있게 해주고, 세 번째는 무관한 행동을 무시할 수 있게 해줍니다. 두 번째는 행동을 같은 사실에 대한 관찰로 교환할 수 있게 해줍니다. 오른쪽에 있는 기호들은 무엇인가요? 그것들은 변환이 합법적일 때마다 다이어그램이 우리에게 주는 “녹색 신호”입니다. 우리는 다음 예제에서 그것들이 작동하는 것을 볼 것입니다.\n이것은 강의의 세 번째 부분으로 우리를 인도합니다. 여기서 저는 지금까지 제시된 아이디어들이 실질적으로 중요한 새로운 문제들을 해결하는 데 어떻게 사용될 수 있는지 보여드리겠습니다.\n흡연이 폐암에 미치는 영향에 관한 수 세기 동안의 논쟁을 고려해 보세요[46]. 1964년, 미국 공중보건국 국장은 담배 흡연을 사망, 암, 특히 폐암과 연관시키는 보고서를 발표했습니다. 이 보고서는 흡연과 폐암 사이에 강한 상관관계가 발견된 비실험적 연구에 기반했으며, 주장은 발견된 상관관계가 인과적이라는 것이었습니다: 만약 우리가 흡연을 금지한다면, 암 발생률은 대략 오늘날 인구 중 비흡연자들에게서 발견되는 것과 같을 것입니다.\n이 연구들은 담배 산업으로부터 심각한 공격을 받았으며, 그들을 지원한 것은 Ronald Fisher 경을 포함한 매우 저명한 통계학자들이었습니다. 그들의 주장은 관찰된 상관관계가 흡연과 폐암 사이에 인과적 연결이 없는 모델로도 설명될 수 있다는 것이었습니다. 대신에, 암을 동시에 유발하고 니코틴에 대한 선천적인 갈망을 생산하는 관찰되지 않은 유전자형이 존재할 수 있다는 것입니다. 공식적으로, 이 주장은 우리의 표기법으로 다음과 같이 작성될 것입니다: P(Cancer | do(Smoke)) = P(Cancer). 이것은 인구가 흡연하게 하거나 흡연을 중단하게 하는 것이 암 발생률에 영향을 미치지 않을 것이라는 의미입니다. 통제된 실험은 두 모델 중 어느 것이 옳은지 결정할 수 있지만, 이러한 실험은 수행하는 것이 불가능하며 (이제는 불법입니다).\n이것은 모두 역사입니다. 이제 우리는 양측 대표자들이 만나서 그들의 차이점을 해결하기로 결정하는 가상의 시대로 들어갑니다. 담배 산업은 흡연과 암 사이에 약한 인과적 연결이 있을 수 있다는 것을 인정하고, 보건 그룹의 대표자들은 유전적 요인에 약한 연결이 있을 수 있다는 것을 인정합니다. 따라서, 그들은 이 결합 모델을 그리고, 문제는 데이터로부터 다양한 연결의 강도를 평가하는 것으로 귀결됩니다. 그들은 이 질문을 통계학자에게 제출하고 답변은 즉시 돌아옵니다: 불가능. 즉, 데이터로부터 강도를 추정할 방법이 없습니다. 왜냐하면 어떤 데이터도 이 두 극단적 모델 중 하나에 완벽하게 맞을 수 있기 때문입니다. 그래서 그들은 포기하고 평소처럼 정치적 싸움을 계속하기로 결정합니다. 헤어지기 전에, 한 가지 제안이 제기됩니다: 아마도 우리가 몇 가지 보조 요소들을 측정한다면 우리의 차이점을 해결할 수 있을 것입니다. 예를 들어, 인과 관계 모델(causal-link model)은 흡연이 폐에 타르 축적을 통해 폐암에 영향을 준다는 이해를 기반으로 하므로, 아마도 우리는 표본 개인들의 폐에 있는 타르 축적량을 측정할 수 있고, 이것이 연결 고리를 정량화하는 데 필요한 정보를 제공할 수 있을 것입니다. 양측 모두 이것이 합리적인 제안이라는 데 동의하므로, 그들은 통계학자에게 새로운 질문을 제출합니다: 타르 축적의 중간 측정값이 사용 가능하다고 가정할 때 흡연이 암에 미치는 영향을 찾을 수 있을까요? 통계학자는 좋은 소식을 가지고 돌아옵니다: 그것은 계산 가능하며, 더욱이 그 해결책은 수학적 형태로 닫혀 있습니다. 어떻게 그럴까요?\n통계학자는 문제를 받아 고등학교 대수학 문제로 취급합니다: 우리는 가설적 행동 하에서 P(Cancer)를 비실험적 데이터, 즉 행동이 포함되지 않은 표현으로부터 계산해야 합니다. 또는: 우리는 초기 표현에서 “do” 기호를 제거해야 합니다. 제거 과정은 일반적인 대수 방정식 해법과 같이 진행됩니다 - 각 단계에서[47], 다이어그램의 일부 하위 그래프에 의해 허용된 새로운 규칙이 적용되어 결국 “do” 기호가 포함되지 않은 공식으로 이어지며, 이는 비실험적 데이터로부터 계산 가능한 표현을 나타냅니다.\n아마도 이 유도가 흡연-암 논쟁을 해결하는지 궁금할 것입니다. 답은 아닙니다. 우리가 타르 축적에 대한 데이터를 얻을 수 있다 하더라도, 우리의 모델은 꽤 단순화되어 있습니다. 왜냐하면 그것은 양측이 동의하지 않을 수 있는 특정 가정에 기반하고 있기 때문입니다 - 예를 들어, 타르 축적에 의해 매개되지 않은 흡연과 폐암 사이의 직접적인 연결이 없다는 것입니다. 그러면 모델은 세분화되어야 할 것이고, 우리는 20개 이상의 변수를 포함하는 그래프로 끝날 수 있습니다. 누군가가 “당신은 이 요소나 저 요소를 고려하지 않았다”라고 말할 때 공황 상태에 빠질 필요가 없습니다. 오히려 그래프는 그런 새로운 아이디어를 환영합니다. 왜냐하면 모델에 요소와 측정을 추가하는 것이 매우 쉽기 때문입니다. 이제 간단한 테스트를 통해 연구자가 그래프를 살펴보고 한 변수가 다른 변수에 미치는 영향을 계산할 수 있는지 결정할 수 있습니다.\n다음 예는 오래된 문제가 순전히 그래프적 수단으로 어떻게 해결되는지를 보여줍니다 - 새로운 대수학에 의해 증명됩니다. 이 문제는 조정 문제(adjustment problem) 또는 “공변량 선택 문제(covariate selection problem)”라고 불리며 심슨의 역설(Simpson’s paradox)의 실질적인 측면을 나타냅니다[48].\n심슨의 역설은 1899년 칼 피어슨이 처음 발견한 것으로, 두 변수 간의 모든 통계적 관계가 분석에 추가 요소를 포함시킴으로써 역전될 수 있다는 불안한 관찰에 관한 것입니다. 예를 들어, 연구를 실행하여 담배를 피우는 학생들이 더 높은 성적을 받는다는 것을 발견할 수 있습니다. 그러나 나이를 조정하면, 모든 연령 그룹에서 반대가 사실입니다. 즉, 흡연은 낮은 성적을 예측합니다. 부모 소득을 추가로 조정하면, 모든 연령-소득 그룹에서 다시 흡연이 높은 성적을 예측하는 것을 발견하게 됩니다.\n마찬가지로 불안한 것은 어떤 요소가 분석에 포함되어야 하는지 누구도 우리에게 말해주지 못했다는 사실입니다. 이러한 요소들은 이제 간단한 그래프적 수단으로 식별될 수 있습니다. 심슨의 역설을 보여주는 고전적인 사례는 1975년 UC-버클리가 대학원 입학에서 성별 편향을 조사받았을 때 발생했습니다. 이 연구에서 전체 데이터는 남성 지원자들 사이에서 더 높은 입학률을 보여주었습니다. 하지만 학과별로 세분화하면, 데이터는 여성 지원자들을 입학시키는 데 약간의 편향을 보여주었습니다. 설명은 간단합니다: 여성 지원자들은 남성보다 더 경쟁이 치열한 학과에 지원하는 경향이 있었고, 이러한 학과에서는 남성과 여성 모두에게 입학률이 낮았습니다.\n이 점을 설명하기 위해, 큰 그물망과 작은 그물의 두 가지 그물을 가진 낚시 배를 상상해보세요[49]. 물고기 무리가 배를 향해 헤엄치고 지나가려고 합니다. 암컷 물고기는 작은 그물망의 도전을 시도하는 반면, 수컷 물고기는 쉬운 경로를 시도합니다. 수컷은 통과하고 암컷만 잡힙니다. 최종 포획량으로 판단하면, 암컷에 대한 선호도가 명백히 드러납니다. 그러나 개별적으로 분석하면, 각 그물은 분명히 암컷보다 수컷을 더 쉽게 잡을 것입니다.\n또 다른 예는 1970년대 사회과학 문헌에서 다루어진 “역 회귀(reverse regression)”라고 불리는 논쟁을 포함합니다. 우리는 급여 차별 사례에서 동등한 자격을 갖춘 남성과 여성의 급여를 비교해야 할까요, 아니면 동등한 급여를 받는 남성과 여성의 자격을 비교해야 할까요?\n놀랍게도, 두 선택은 반대 결론으로 이어졌습니다. 남성은 동등한 자격을 갖춘 여성보다 더 높은 급여를 받았고, 동시에 남성은 동등한 급여를 받는 여성보다 더 자격이 있었습니다. 교훈은 우리가 비교할 때 어떤 변수를 일정하게 유지하기로 선택하느냐에 따라 모든 결론이 극도로 민감하다는 것이며, 그것이 조정 문제가 관찰 연구 분석에서 매우 중요한 이유입니다.\n우리가 X가 Y에 미치는 영향, 예를 들어 치료가 반응에 미치는 영향을 찾고자 하는 관찰 연구를 고려해보세요[50]. 우리는 문제와 관련된 많은 요소들을 생각할 수 있습니다. 일부는 치료에 영향을 받고, 일부는 치료에 영향을 미치며, 일부는 치료와 반응 모두에 영향을 미칩니다. 이러한 요소 중 일부는 유전적 특성이나 생활 방식과 같이 측정 불가능할 수 있습니다. 다른 요소들은 성별, 나이, 급여 수준과 같이 측정 가능합니다. 우리의 문제는 측정 및 조정을 위해 이러한 요소들의 부분집합을 선택하여, 우리가 그러한 측정 값이 동일한 대상을 비교하고 평균을 내면 올바른 결과를 얻을 수 있도록 하는 것입니다.\n두 개의 후보 측정값 Z₁과 Z₂가 충분한지 테스트하는 데 필요한 단계를 함께 따라가 봅시다[51]. 단계는 상당히 간단하며, 큰 그래프에서도 수동으로 수행할 수 있습니다. 그러나 기계화 가능성을 느끼게 하기 위해, 저는 꽤 빠르게 이 단계들을 진행하겠습니다. 시작합니다[52-56].\n이러한 조작의 끝에, 우리는 질문에 대한 답을 얻습니다: “X가 Y와 분리되어 있다면, Z₁과 Z₂는 적절한 측정값입니다.”\n이제 이 강의의 중심 메시지를 간략히 요약하고자 합니다. 원인과 결과를 테스트하는 것은 어렵다는 것은 사실입니다. 결과의 원인을 발견하는 것은 더욱 어렵습니다. 하지만 인과 관계는 신비롭거나 형이상학적인 것이 아닙니다. 그것은 간단한 과정으로 이해될 수 있으며, 컴퓨터 분석을 위한 친근한 수학적 언어로 표현될 수 있습니다.\n오늘 여러분께 제시한 것은 일종의 포켓 계산기, 즉 수학적 정밀도로 원인과 결과의 특정 문제들을 조사하는 데 도움을 주는 주판[57]입니다. 이것이 인과 관계의 모든 문제를 해결하는 것은 아니지만, 기호와 수학의 힘을 과소평가해서는 안 됩니다[58].\n많은 과학적 발견들이 아이디어를 증폭시키고 과학자들이 결과를 소통할 수 있게 해주는 수학적 언어의 부재로 인해 수세기 동안 지연되어 왔습니다. 저는 많은 발견들이 인과 관계를 다룰 수 있는 수학적 언어의 부재로 인해 우리 세기에 지연되었다고 확신합니다. 예를 들어, 저는 칼 피어슨이 1901년에 수학에 인과 다이어그램을 허용했다면 무작위화된 실험 아이디어를 생각해 낼 수 있었을 것이라고 확신합니다.\n하지만 정말 도전적인 문제들은 여전히 앞에 있습니다: 우리는 여전히 빈곤과 암과 편협함에 대한 인과적 이해를 갖고 있지 않으며, 오직 데이터의 축적과 위대한 마음들의 통찰력만이 결국 그러한 이해로 이어질 것입니다.\n데이터는 모든 곳에 있고, 통찰력은 여러분의 것이며, 이제 주판도 여러분의 처분에 맡겨져 있습니다. 저는 이 조합이 이러한 각 구성 요소들을 증폭시키기를 바랍니다.\n감사합니다.",
    "crumbs": [
      "Causal Inference",
      "The Art and Science of Cause and Effect"
    ]
  },
  {
    "objectID": "extracted/Pearl-epilogue.html#감사의-말",
    "href": "extracted/Pearl-epilogue.html#감사의-말",
    "title": "The Art and Science of Cause and Effect",
    "section": "감사의 말",
    "text": "감사의 말\n슬라이드 1(뒤러, 아담과 이브, 1504년 판화)은 포그 미술관, 하버드 대학교 미술관, 프랜시스 캘리 그레이 컬렉션에서 윌리엄 그레이의 기증품의 허가를 받았습니다. 사진: 릭 스태포드; 이미지 저작권 © 하버드 대학교 총장 및 연구원, 하버드 대학교. 슬라이드 2(도레, 롯의 탈출) 저작권 윌리엄 H. 와이즈 & 컴퍼니. 슬라이드 3(보드 게임을 하는 네페론페의 이집트 벽화)는 시카고 대학교 동양학 연구소의 허가를 받았습니다.\n다음 이미지들은 Bernard Quaritch, Ltd.(런던)의 허가를 받아 고서적 카탈로그에서 복제되었습니다: 슬라이드 4, 5, 6, 7, 8, 9, 15, 27, 31, 36, 37, 38, 40, 42, 58.\n슬라이드 10과 11은 The Courier Press의 저작권입니다. 슬라이드 13과 14는 I. Bernard Cohen의 The Album of Science에서 Macmillan Library Reference USA의 허가를 받아 재인쇄되었습니다. 저작권 © 1980 Charles Scribner’s Sons.\n슬라이드 16은 캘리포니아 주립 대학교 롱비치 도서관의 허가를 받았습니다. 슬라이드 20과 22는 Cambridge University Press의 허가를 받아 재인쇄되었습니다. 슬라이드 25: 사진 저작권 A. C. Barrington Brown, 허가를 받아 복제되었습니다.\n슬라이드 30: S. Wright(1920)의 Proceedings of the National Academy of Sciences, vol. 6에서; 미국 철학 학회와 시카고 대학교 출판부의 허가를 받아 복제되었습니다. 슬라이드 57은 Vandenhoeck & Ruprecht와 MIT Press의 허가를 받아 재인쇄되었습니다.\n참고: 슬라이드 19, 26, 28-29, 32-35, 43-56의 컬러 버전은 !http://www.cs.ucla.edu/~judea/에서 다운로드할 수 있습니다.",
    "crumbs": [
      "Causal Inference",
      "The Art and Science of Cause and Effect"
    ]
  },
  {
    "objectID": "extracted/Sobel.html",
    "href": "extracted/Sobel.html",
    "title": "Discussion - The Scientific Model of Causality",
    "section": "",
    "text": "Michael E. Sobel",
    "crumbs": [
      "Data Science",
      "Discussion - The Scientific Model of Causality"
    ]
  },
  {
    "objectID": "extracted/Sobel.html#introduction",
    "href": "extracted/Sobel.html#introduction",
    "title": "Discussion - The Scientific Model of Causality",
    "section": "1. INTRODUCTION",
    "text": "1. INTRODUCTION\nHeckmanadvocatesanapproachtocausalinferencethatdrawsupon structural modeling of the outcome(s) of interest (which he calls scientific), and he contrasts this approach sharply with that arising out of the statistical literature on experimentation. Drawing exten- sively on several previous papers—for example, Heckman (1997, 2000, 2001) and Heckman and Navarro-Lozano (2004)—Heckman goes even further here, arguing that the statistical literature on causal inference is incomplete because it does not attempt to model the process by which subjects are selected into treatments (or what statis- ticians have called the ‘‘treatment assignment mechanism’’) and that this literature confounds the task of defining parameters with the tasks of identifying and estimating these parameters. I shall return to these points later.\nBut whereas Heckman distinguishes sharply between these approaches (and hence between certain literatures in economics and statistics), on balance I find the similarities in the approaches he discusses much more profound than the dissimilarities. To elaborate, while there has been and continues to be much philosophical disagreement about the nature of the causal relation, in both these literatures, there are strong similarities in the way that the word ‘‘cause’’ is used. In particular, a causal relation sustains a counter- factual conditional, while a noncausal relation need not do so.\nSecond, causal effects are allowed to be heterogeneous across units, a point that both statisticians and Heckman have emphasized. Third, dovetailing with this shared perspective on the nature of the causal relation,thepotentialoutcomesnotationinventedbyNeyman(1923), widelyusedsincebystatisticiansworkingonexperimentaldesign(see for example, the textbooks by Cox [1958] and Kempthorne [1952]), is now standard notation in both these literatures. This notation, adopted also by Heckman during the latter 1980s and since in a number ofhis papers(andhere) nicely capturesthe idea that acausal relationship sustains a counterfactual conditional statement. To be sure, this idea can be represented in other ways (Robins and Greenland 2000), but the potential outcomes notation is very easy to work with and easy to use without leading oneself astray. The importance of good notation cannot be emphasized strongly enough.\nAsWhitehead([1911],1958:39)pointedout,‘‘Byrelievingthebrainof all unnecessary work, a good notation sets it free to concentrate on more advanced problems, and in effect increases the power of the race.’’ I would also propose that the use of a common notation encourages investigators to think similarly about a problem.\nThe incorporation of Neyman’s notation into the modern literature on causal inference is due to Rubin (1974, 1977, 1978, 1980), who, using this notation, saw the applicability of the work from the statistical literature on experimental design to observational studiesandgaveexplicitconsiderationtothekeyroleofthetreatment assignment mechanism in causal inference, thereby extending this work to observational studies. To be sure, previous workers in statis- tics and economics (and elsewhere) understood well in a less formal waytheproblemsofmakingcausalinferencesinobservationalstudies where respondents selected themselves into treatment groups, as evi- denced,forexample,byCochran’sworkonmatchingandHeckman’s workonsampleselectionbias.ButRubin’sworkwasacriticalbreak- through. The introduction of a suitable notation allowed in principle the clarification and formalization of the problem of making causal inferences with non-experimental data. Further, the use of this notation allowed the tasks of defining etimands to be separated from the tasks of identifying and estimating these. This separation enabledRubinnotonlytopinpointthekeyroleofthetreatmentassign- ment mechanism but to state precise conditions under which this mechanism was ‘‘ignorable’’ or not. These conditions have been used by subsequent workers (including Heckman) to evaluate and clarify existing procedures for causal inference (for example, instrumental variables) and to develop new methods for estimating causal effects (forexample,bycreatingmatchedsamplesusingpropensityscores).\nAnd fourth, although Heckman criticizes the ‘‘treatment effects’’ literature for modeling the effects of causes, as opposed to modeling the causes of effects, the majority of his paper also focuses on modeling the effects of an intervention (cause) on an outcome of interest.\nThat said, some of the problems involved in making causal inferences about agents who are not (or cannot in practice be) subjected by an investigator to one or another treatment of interest will be somewhat different than those that typically arise when a treatment is applied or not to a plot of land in an agricultural experiment. In the latter case, where a randomized experiment can be conducted, the treatment assignment mechanism is essentially a (possibly biased) coin toss (or a coin toss within distinguishable types of plots). Causal inference is typically more straightforward in this case. However, in observational studies, individuals typically sort themselves into treatment groups and how they do so may also be of independent interest. Economists often argue that individuals make choices by behavingas if they are maximizing expected utility.\nWhen the utility associated with making particular choices is also related to the outcome under consideration, this may create pro- blems when the agent uses more information than that available to theeconomist(ortheeconomistsimplydoesnotknowthetreatment assignment mechanism). In this case, consideration of the available information may be inadequate for a ‘‘sufficient’’ description of the process by which agents allocate themselves to treatment groups.\nHere, the assignment mechanism cannot be treated as a coin toss (net of the available information). Thus, methods based on this premise are inadequate for this case. In other social and behavioral sciences, where notions of decision making may take on a different flavor, the above may or may not be problematic. In any event, the point is that even when the same notion of causation is under consideration, some variation by discipline in approaches to causal inference should be expected.\nIn addition, although assumptions are always present, investi- gatorsdifferintheextenttowhichtheyarecomfortableusingtheseto make inferences. Heckman advocates herein what he has elsewhere (Heckman 2000) called a structural approach to estimating causal parameters. This model based approach can be very powerful and can be used as a basis for generating inferences that are sometimes much stronger and broader in scope than those typically made in the statistical literature Heckman criticizes. But the structural approach also typically features stronger assumptions. As Heckman (2000) documents, frustration with the seemingly arbitrary nature of the assumptions (for example, exclusion restrictions) used to identify structuralmodels has ledseveral generations ofeconomists toeschew structural modeling in favor of other approaches, recently including experimentation(Heckmanisquitecriticalofthis‘‘naturalexperiment movement;’’ for a nice treatment of the issues see Rosenzweig and Wolpin(2000)).Asbefore,evenwhenthesamenotionofcausationis held, some differences in approaches to causal inference should be expected.\nHowever,ifonetakestheviewthatstatisticalproceduresshould be tailored to address questions of interest to various constituencies (for example, different groups of scientists and policymakers), such differences should be regarded as both natural and desirable.\nAccordingly, I aim primarilytogive a balancedoverview oftheissues.\nTo make my discussion as useful as possible for Sociological Methodology readers, I sometimes elaborate on material covered by Heckman in this or previous papers. Second (and primarily for the same reason), my remarks are organized around the following four themes in Heckman’s paper: 1) the nature of the causal relation, 2) definitions of causal estimands, 3) policy evaluation and forecasting, and 4) the identification and estimation of causal effects. Although I do not find simultaneous equation models (and more generally, structural equation models) in their current form very useful for causal inference, I do not take up this subject here, in large measure because a thorough treatment would require substantially increasing the length of an already long discussion.\nFor some previous and related discussions of causality in simultaneous equation models, the reader might also wish to con- sult Strotz and Wold (1960), Fisher (1970), and Sobel (1990).\nTo improve readability, in most instances, I include here the equations referred to, even if some of these already appear in Heckman’s article. Whenever possible, I use notation similar or iden- tical to Heckman’s. In some instances, in order to retain consistency of style, minor deviations have been necessary.",
    "crumbs": [
      "Data Science",
      "Discussion - The Scientific Model of Causality"
    ]
  },
  {
    "objectID": "extracted/Sobel.html#the-causal-relation",
    "href": "extracted/Sobel.html#the-causal-relation",
    "title": "Discussion - The Scientific Model of Causality",
    "section": "2. THE CAUSAL RELATION",
    "text": "2. THE CAUSAL RELATION\nHeckman argues (page 2, this volume) that ‘‘Science is all about constructing models of the causes of effects’’ (vs. studying the effects ofcauses).Healsoarguesthatthenotionofcausalityinvolvesmanip- ulating one or more variables and comparing the outcomes of these manipulations. Economists perform these (hypothetical) manipula- tions using models. And since models are mental constructs, Heckman concludes that causality resides in the mind. In addition, as different people think different thoughts and therefore construct different models, causes are ‘‘relative’’ (to use the language of Collingwood ([1940], 1972). That is, with equal legitimacy, different investigators may identify different factors as causes, while ignoring others. This is part of what Heckman refers to as the provisional nature of causal knowledge. The implications of this are further discussed in Sobel (1995), which readers may also wish to consult for more background on the causal relation.\nModelingthecausesofeffectsiscertainlyanimportantscientific activity. But it should also be understood that many ‘‘scientific’’ ques- tionsarenotcausal.Forexample,NASArecentlycrashedaprobefrom the Deep Impact spacecraft into comet Tempel1 with the objective of learningmoreaboutthestructureandcompositionof cometary nuclei.\nSee Bunge (1979) for a discussion of the many kinds of noncausal questionsthatareofscientificinterest.Further,studyingtheeffectsof causes is an important scientific activity: figuring out the causes of global warming would be considerably less important if the effects of global warming were inconsequential.\nNext,thenatureofthecausalrelationhasconsumedtheatten- tion of philosophers since well before Hume, without resolution.\nRegularity theories are one attempt to explicate the nature of causation. Here the cause (or causes of the effect) is (are) usually thought of as some set of necessary and/or sufficient antecedents for the effect. Regularity theories are both general and (typically) deter- ministic.Inaddition,contemporaryregularitytheoriesusuallyrequire that a causal statement sustain a counterfactual conditional. The foregoing ideas may be expressed mathematically using functions, as in an ‘‘all-causes’’ model: yðsÞ¼g ðx;uÞ; ð1Þ s where y(s) is an outcome of interest depending on state s, g is a s function of x, a vector of observables, and u, a vector of unobserva- bles.Byvaryingthecomponentsofg ,effectsofthearguments(which s may be state specific) can be defined under suitable conditions. In other instances, attention focuses on the results of manipulating the states s, which might, for example, index a set of treatments that are to be applied.\nThe antecedents above are also held to have causal priority overtheeffect.Explicatingthenatureofthispriorityhasproventobe adifficulttask.Mostphilosophersholdtotheviewthatthereismore to causal prioritythanmere temporal order.Thus, somesequencesare toberegardedascausalwhileothersarenot.Althoughmanipulatinga causeisonewaytoestablishthepriorityofthecauseovertheeffect,in many theories of causation, including regularity theories, manipul- ability is not regarded as essential.\nOn the other hand, manipulability theories of causation emphasize the ability of a human agent to manipulate a cause: ‘‘A causeisaneventorstateofthingswhichitisinourpowertoproduce or prevent, and by producing or preventing which we can produce or prevent that whose cause it is said to be’’ (Collingwood [1940], 1972: p. 296–97). Whereas regularity theories are theories about the causes of effects, manipulability theories are theories about the effects of causes.Suchtheoriescorrespondmorecloselywiththewayanexperi- mentalist thinks of causation. These theories are also readily com- bined with singular theories of the causal relation.\nAt first glance, it appears that manipulability theories are inherently at odds with regularity theories. Thus, it might be argued that the modern literatures on causal inference in both statistics and econometrics, because these literatures are typically concerned with theidentificationandestimationoftheeffect(s)ofparticularcauses— for example, the effects of a policy intervention, as in Heckman’s paper—are, from the scientific standpoint advocated by Heckman, misdirected. Importantly, this is not the case, and manipulability theoriescanbereconciledwithregularitytheoriesbynotingthatamanipu- latedcauseissimplyonecomponentof(1)withuunknown(somecompo- nentsofumaybeunknownandotherssimplynotobserved).Toillustrate thispointusing(1),supposethetreatmentvariablesis0(notreatment)or1 (treatment),x2(cid:2) andu2(cid:2) ¼ (cid:2) [(cid:2) ,with(cid:2) (cid:2) ¼ ;.Suppose x u 0u 1u 0u 1u thatfor(x,u) 2 (cid:2) (cid:2) (cid:2) , g (x, u) ¼ g (x, u) ¼ 0, while for (x, u) 2 x 0u 0 1 (cid:2) (cid:2) (cid:2) , g (x, u) ¼ 0, g (x, u) ¼ 1. In a manipulability theory, the x 1u 0 1 variable s is singled out for attention. If the investigator knows (s, x, u) and the functions g, the effect of s varies over x and u in a known s (to the investigator) way. In practice, the investigator observes only s andx,inwhichcasetheeffectofs(whichtheinvestigatormaynotbe able to identify from data) varies over x in an apparently nondeter- ministic manner.\nThe relativity of causation (part of what Heckman calls the provisional nature of causal knowledge) is also easily illustrated. In (1) the treatment variable s may be singled out for attention and manipulated. The other arguments (x and u) remain in the causal background. A different investigator might identify one or more components of x (cid:3) (x , x ) as the cause and rewrite (1) as h 1 2 x1 (x , u, s).\n2 When the cause can be manipulated, each unit in a research study can receive any of the various levels of the cause (even though in practice a given unit is observed only at one level). In his presentation of what has come to be known in the statistical community as ‘‘Rubin’s model for causal inference,’’ Holland (1986), like Heckman, also emphasizes the importance of mani- pulating the cause, going so far as to coin the (unfortunate) phrase, ‘‘No causation without manipulation.’’ Whereas Holland appears to insist on the actual ability of an investigator to manipulate the cause(s), many others, including Heckman, have argued that it is the idea of manipulating the cause, even if this can only be done hypothetically, that is key in defining causal relation- ships.Ifthispointofviewistaken(butnotifnot),Hollandappearsto be conflating the distinct problems of defining and identifying causal effects.\nBut perhaps the most controversial aspect of Heckman’s brief treatmentofcausalityishisclaimthat‘‘causalityisinthemind.’’This claimstemsfrom(a)thefactthatcausaleffectsaredefinedaschanges in outcomes when variables in a model are (hypothetically) manipu- lated and (b) the view that models are mental constructs made up by the scientist, ‘‘not empirical statements or descriptions of actual worlds’’ (page 3). While Heckman’s conclusion is consistent with (a) and (b), and Heckman is certainly free to define causality in this fashion, I do not believe that most scientists (or philosophers) would subscribe to this view, and were they to do so, they would presumablyhavelittlefurtherinterestincausality(assciencetypically purports to be concerned with the real world).\nIn this vein, models (be they mathematical or of some other sort) are often constructed by scientists to represent causal processes (causalmechanisms)believedtobeoperating inthe actualworld(not justthemind).Tobesure,themodelshavetobeimaginedandinthis sense, our notion of the causal process(es) at play comes from the mind, but the processes (which wemay or may notaccurately model) are also believed to reside in the actual world. That is, the causal relation is typically held to describe a relation that is believed to exist in the real world.",
    "crumbs": [
      "Data Science",
      "Discussion - The Scientific Model of Causality"
    ]
  },
  {
    "objectID": "extracted/Sobel.html#defining-causal-estimands",
    "href": "extracted/Sobel.html#defining-causal-estimands",
    "title": "Discussion - The Scientific Model of Causality",
    "section": "3. DEFINING CAUSAL ESTIMANDS",
    "text": "3. DEFINING CAUSAL ESTIMANDS\nIn the statistical literature on causal inference, as in Heckman, assumptions (A-1) and (A-2) are typically made; Rubin (1980) has called this the stable unit treatment value assumption (SUTVA).\nWhentheseassumptionsarenotmade,theproblemofdefiningcausal estimands is more difficult, as is the problem of making inferences about these. In addition to Heckman, several others have worked on this problem (Halloran and Struchiner 1995; Sobel 2001, 2003). But this is fertile ground for social scientists, where interference due to social interactions and other constraints are the norm. Nevertheless, following Heckman, I shall hereafter assume SUTVA holds.\nWith (A-1) and (A-2) in hand, the response of unit ! to level s ofthecausemaybewrittenasY(!);forthepurposesathand,assume s that each unit can take on every level of the cause. Individual (unit) causal effects are then defined as an intra-unit, between-treatment comparison h(Y (!), Y (!)). Because each study unit can actually be s s0 observed only under one treatment, it is not possible to observe unit causal effects. Holland (1986) refers to this fact as ‘‘the fundamental problem of causal inference.’’ Heckman focuses attention on three estimands in this paper, theaveragecausaleffect(ACE),theeffectoftreatmentonthetreated (TT), and the marginal treatment effect (MTE). Although the MTE can be useful for understanding other estimators, I do not discuss it further herein, asI believe sociologists will usually be more interested in the other two estimands. The local average treatment effect (LATE) will be discussed subsequently.\nLetSdenoteasetoftreatmentsofinterest.Theaveragecausal effect of treatment s versus s0 (ACE(s, s0)) is defined as EðY (cid:4)Y Þ; ð2Þ s s0 in which h(Y (!), Y (!)) ¼ (Y (!) (cid:4) Y (!)). The ACE can also be s s0 s s0 definedconditionallyoncovariatesW;asinHeckman,thisisdenoted ACE(s, s0 j W), and when it is obvious which treatments are being compared (as in the case where there is just one treatment compared tonotreatment)simplyACE(W),orACEinthecasewherethereare no covariates. Since, following Heckman, Y (!) is defined as the out- s come of unit ! when treatment s is received, herein the ACE is the average difference when all units receive treatment s as versus s0. It is also(byvirtueofassumptions(A-1)and(A-2)),theeffectofreceiving treatment s versus s0 for a randomly selected person from the population.\nTheaverageeffectoftreatmentsversuss0onthetreated(TT(s,s0)) is another parameter of longstanding interest: EððY (cid:4)Y ÞjD¼sÞ; ð3Þ s s0 where D is the random variable denoting which treatment in S is actually received. Thus, TT(s, s0) is the average effect of treatment s versus s0 for those units that actually take up treatment s.\nTo round out the discussion, I also want to consider a para- meter that has received a great deal of attention from biostatisticians and the public health community, the so called ‘‘intent to treat’’ estimand (ITT(s, s0)). For all s 2 S, we define Y~(!) as the outcome s of unit ! when assigned to treatment s. (The treatment to which a subject is assigned may differ from the treatment received because subjects will not always take up the treatment to which they are assigned; thus Y~(!) 6¼ Y(!) in general.) ITT(s, s0) is then defined s s by (2) with Y~ and Y~ replacing Y and Y , respectively. Note that in s s0 s s0 the case where all subjects would take up their assignments, for any possible assignment, Y~(!) ¼ Y (!) and ITT(s, s0) ¼ ACE(s, s0).\ns s Therehasbeensomecontroversyoverwhichoftheparameters aboveareofgreatestinterest.Itaketheviewthatitalldependsonthe problem at hand, the goals of the scientist(s) analyzing the data and the purposes of the person(s) making policy on the basis of the analysis. Some examples where one or more of the parameters above are of interest follow.\nForpolicieswithuniversalcoverageanduniversalparticipation, theACEistheobviousparameterofinterest.Forexample,considerthe effect of a specific currency devaluation (s ¼ 0 if no devaluation, 1 otherwise)onhouseholdspending.HereY~(!) ¼ Y(!)forall!,imply- s s ingACE ¼ ITT.Ifthedevaluationisimplemented,ACE ¼ TTaswell (aseveryunittakesupthetreatment).\nFor policies with universal coverage that do not require parti- cipation, some units may not take up the treatment. Because non- participating units will not obtain the benefits of participation, it might be argued that knowing the average effect of treatment for these units is irrelevant, suggesting TT is the parameter of interest.\nHowever, the untreated might take up treatment in the future if they believed the treatment were effective (for them). Thus, we might wish to also know the TUT (effect of treatment on the untreated).\nAlternatively, policymakers might want to know the effect for the nonparticipatingunits,forifthisisdeemedsubstantial,theywillthen want to make efforts to obtain the participation of such units. They will then also want to know the ACE, which is a weighted average of the TT and the effect of treatment on the untreated (TUT).\nBut some might argue instead that the effect that should be of interestistheeffectofofferingtheprogram.Forexample,considerthe case of a new contraceptive method. Whereas some scientists may be moreinterestedintheACE(orpossiblytheTT),whichmeasuresmore directly the clinical effectiveness of the contraceptive, policymakers considering whether or not to widely distribute the contraceptive in a developing country are more concerned with the cost and the efficacy of the contraceptive in the field (where some people do not follow instructions). Consequently, they are more interested in the ITT.\nFinally, it is worth noting that if receipt of treatment is inde- pendentofthepotentialoutcomes,givenasetofknowncovariatesW (includingthe caseofnocovariates),TT(W) ¼ TUT(W) ¼ ACE(W).\nHeckman also discusses a number of outcome measures that may be of interest to social scientists and economists but which are not discussed in the statistical literature he criticizes, where the out- comes Y (!) are typically straightforward measures of the status of a s unit—for example, the income of a family under treatment s or the survival time of a subject after surgery. In particular, Heckman con- siders outcomes V(Y (!)) where V is some function of the outcome— s for example, the utility of Y (!) to individual ! (or to a policymaker) s under policy s. He then uses these to define various parameters comparing the benefit (welfare) associated with alternative policies.\nAlthough mathematically nothing new is involved here, this is useful, especially because it is possible that E(V(Y ) (cid:4) V(Y )) (cid:5) 0 when s s0 (2) &gt; 0, for example. Thus, if V were to measure a social planner’s utility, the planner would not wish to choose policy s over s0 even thoughtheaveragecausaleffectisgreaterthan0.Choosingapolicyis often not this simple, however; for some interesting recent work that applies decision theory to the problem of treatment choice, see Manski (2000, 2004).\nThe estimands above are differences between means. Because the integral is a linear operator, these estimands only require knowl- edge of the marginal distributions F(y) and F(y 0) of potential s s outcomes.Undersomecircumstances(discussedlater),thesedistribu- tions can be identified.\n(cid:2) (cid:3) Heckmanalsodiscussesanumberofotherestimandsh Y ;Y0 s s (cid:2) (cid:3) of substantive interest that depend on the joint distribution F y ;y0 s s of ðY ;Y Þ. However, the fundamental problem of causal inference s s0 precludes the simultaneous observation of Y(!) and Y0ð!Þ, implying s s that it is not possible to know more than the marginal distributions.\nAnd while knowledge of the marginal distributions imposes some constraints on the joint distribution, these constraints often do not allow much useful information on the joint to be extracted (for example, if the marginals are normal with known means and var- iances, this is consistent with non-normal joint distributions, as well as a bivariate normal with any correlation between (cid:4)1 and 1). Thus, much stronger assumptions will be required to point identify and estimate parameters depending on the joint distribution of potential outcomes than parameters depending only on the marginal distribu- tion of the potential outcomes (for an example of this, see Carneiro, Hansen and Heckman 2003). Since the data impose few constraints (as discussed above) and the joint distribution of potential outcomes is not even an explicit auxiliary consideration in any substantive theory I can think of, the possibility that mathematical assumptions made primarily for the sake of convenience or tractability may be in large measure generating the ‘‘empirical’’ results seems especially strong here; sensitivity analyses should be a must.",
    "crumbs": [
      "Data Science",
      "Discussion - The Scientific Model of Causality"
    ]
  },
  {
    "objectID": "extracted/Sobel.html#policy-evaluation-and-forecasting",
    "href": "extracted/Sobel.html#policy-evaluation-and-forecasting",
    "title": "Discussion - The Scientific Model of Causality",
    "section": "4. POLICY EVALUATION AND FORECASTING",
    "text": "4. POLICY EVALUATION AND FORECASTING\nDrawing upon themes exposited at greater length in Heckman (2000, 2001) and several subsequent papers, Heckman emphasizes the value of the ‘‘scientific approach’’ (as exemplified by structural models) for policy evaluation and forecasting. He distinguishes three problems: (1) evaluating policies that have been implemented, (2) extrapolation of these to new environments, and (3) forecasting the effects of policies that have not been implemented to new environments.\nHeckman uses a structural equation model of the form (cid:2)(X(!), U(!)) to examine this problem, writing the expectation of the observedoutcome Y in the historical population, conditional on X as Z E ðYjX¼xÞ¼ (cid:2)ðx;uÞdF ðujxÞ; ð4Þ H H U whereF (u j x)istheconditionaldistributionofUgivenX ¼ xinthe H historicalpopulation.Forproblem2,wewanttoknowE (Y j X ¼ x).\nT It is clear from equation (4) that this problem is easily solved if the distribution F (u j X ¼ x) is known in the new environment (target), T assuming also the invariance of (cid:2) and the condition that the support of(X,U)inthetargetpopulationiscontainedinthesupportof(X,U) in thehistorical population.Of course,the assumptions andinforma- tion needed to solve this problem are very strong. The third problem canbedealtwith inasimilarfashion(see theappendixtoHeckman’s paper), although it is more complicated.\nAs Heckman points out, the statistical literature on causal inference has focused on estimating the impact of policies in a given environment and problems 2 and 3 have not received much explicit attention. But certainly problem 2 is easy to address within the usual ‘‘treatment effect’’ framework and perhaps this is why it has not been addressed explicitly; problem 3 I discuss momentarily.\nInowproceedtodiscussproblem2withina‘‘treatmenteffects’’ framework forseveral reasons. First, I want the reader tounderstand that the ‘‘treatment effects’’ framework and the ‘‘scientific’’ frame- work, despite apparent differences, often yield very similar answers torealquestions.Inparticular,thatmustbethecasewhenweseethat the answers actually rest on similar assumptions, once these are exposited. Second, in comparing Heckman’s structural approach with the alternative I exposit below, I believe that some researchers who might need to address this problem in their future substantive work may find it easier to think about this problem from the ‘‘treat- ment effects’’ perspective.\nFor the sake of concreteness, consider the problem of extra- polating the historical ACE E (Y (cid:4) Y ) to a new population H 1 0 T. The obvious thing to do is to think of a set of covariates Z such that the historical and target ACEs are identical, and to average the historical ACE over the marginal distribution of Z in the target population.\nMore formally (assuming Y and Y are real valued scalars), 1 0 the conditional ACE in the target population is Z Z E ððY (cid:4)Y ÞjZ¼zÞ¼ y dF ðy jzÞ(cid:4) y dF ðy jzÞ: ð5Þ T 1 0 1 T 1 0 T 0 R R Knowledge of the target distributions F (y j z) and F (y j z) is T 0 T 1 sufficient to determine the value of equation (5); of course, the pro- blem is that target distributions are unknown and it might be very difficulttospecifythem.Thesimplestthingistoassumethehistorical and target distributions are the same (where these are both defined) F (y j z) ¼ F (y j z) for s ¼ 0, 1. Alternatively, in this case, we H s T s might just as well assume the weaker condition E ((Y (cid:4) Y ) j T 1 0 Z ¼ z) ¼ E ((Y (cid:4) Y ) j Z ¼ z). Either of these is an invariance H 1 0 assumption and should not be lightly made. But this characterization of the problem seems to be one that is intuitively easy to understand, and this should allow an investigator to think reasonably about the necessary components of Z. Continuing, the target ACE is then Ð E (Y (cid:4) Y ) ¼ (E ((Y (cid:4) Y ) j z)dF (z). Of course, to average T 1 0 R H 1 0 T the integrand over the target distribution, it must be defined for all values (up to a set of probability measure 0) that Z takes on in the target population. This will be the case, for example, when the sup- ports of (Y, Z) in the target population are contained in the supports s of (Y, Z) in the historical population.\ns Now suppose Y is, as in Heckman, the invariant (over the s historical and target population) structural equation; Y ¼ (cid:2) (Z, U ) s s s for s ¼ 0, 1, then Z E ðY jZ¼zÞ¼ (cid:2) ðz;u ÞdF ðu jzÞ: ð6Þ T s s s T s R Analogous to the case above, if the target distributions F (u j z) and F (u j z) are known, the value of (6) is known. If T 0 T 1 these are assumed to be identical to their historical counterparts, thisimpliesF (y j z) ¼ F (y j z)fors ¼ 0,1; ifsomeotherassump- H s T s tion is made, this cannot be the case. Note also that F (y j z) ¼ F (y j z) for s ¼ 0, 1 does not imply invariance of the H s T s structural equation model nor the conditional distributions of U. As s before, the ACE is obtained by averaging over the marginal distribu- tion of Z in the target population.\nAs for the second point, I at least find it easier to think about the distributions F (y j z) (or the conditional ACE) than to think T s aboutinvariantstructuralequationsandtheconditionaldistributions of the unobservables. (Of course, this does not invalidate a structural approach.) Heckman is also very critical of the ‘‘treatment effects litera- ture’’ for its failure to deal with problem P3, and he briefly (see some of Heckman’s more recent work with Vytlacil for a more detailed treatment) considers this problem here, suggesting that treatments be viewed as a bundle of characteristics. The relationship between these characteristics (as versus just the treatments themselves) and the response (possibly with covariates) can then be modeled, and the relationship transported to the new environment, as per problem P2.\nThis idea is obvious (although its implementation can be difficult), which makes one wonder why statisticians have not addressed this topic. In that regard, several points are in order.\nFirst, formorethan75years, statisticiansand appliedworkers have been using factorial experiments in conjunction with Fisher’s analysis of variance (and more generally, response surface meth- odology) to both identify and estimate the effects of the factors (characteristics) comprising the treatment on the response, and to extrapolate these to conditions not actually experienced. A simple example is a partial factorial design, where higher order interactions are assumed to be 0, allowing extrapolation to combinations of the components not actually observed.\nThe solution above to problem P3 will be inadequate when the effects of the factors vary by covariates whose distributions are different in the historical and target population. In this case, it would be necessary to estimate the effects conditionally and then average over the distribution of these in the target population, as above. Conceptually, this is straightforward. Practically, the pro- blem is to know what covariates to use and the relationship between the effects of the factors and the covariates. In the sim- plest case, where the investigator really does know what covariates to use and the covariates take on only a few levels, it may not be necessary to introduce (possibly arbitrary) modeling assumptions about the relationship between the effects of the factors and the covariates to make headway. But when there are many covariates and/or several continuous covariates, such assumptions become necessary.\nThere are two matters that make for additional complexity and the need for yet more assumptions. In observational studies, treatment assignment may not be ignorable. If it is ignorable, given known covariates, one can (in theory) proceed as above. If not, other avenuesmustbeconsideredtoachieveidentificationofparametersof interest.\nFinally and perhaps critically, in contrast to the case in the experimental design literature, in most observational studies and social experiments, the number of characteristics an investigator would like to consider may far exceed the number of treatment groups. This will make for identification problems and point identifi- cation may end up resting on a number of assumptions that are difficult to substantively justify. For example, consider the case of an observational study where it is reasonable to assume treatment assign- ment is ignorable (without covariates) and the average effects do not depend on covariates whose distributions differ in the historical and target populations. In this case, transporting the relationship between theresponseanditscomponentstothenewenvironmentissimple,once therelationshipisdetermined.Supposenowthereare5components,each having2values(i.e.,thereare32combinationsofcomponentvalues);to identifyalltheeffects inthemostgeneral case, 32treatmentgroupsare needed.Evenifmanyofthehigherorderinteractionsdisappear,identi- ficationproblemswillremainiftherearefewtreatmentgroups,asinthe usual case. This maybe theprimary reason thatthe ‘‘treatment effects’’ literature has not explicitly unbundled the components of interventions andattemptedtoaddressproblemP3initsfullgenerality.Thatsaid,itis unfortunatethatsocialexperimentsarenotusuallydesignedtofacilitate understandingtherelationshipbetweenthecomponentsandtheeffect.",
    "crumbs": [
      "Data Science",
      "Discussion - The Scientific Model of Causality"
    ]
  },
  {
    "objectID": "extracted/Sobel.html#identifying-and-estimating-causal-effects",
    "href": "extracted/Sobel.html#identifying-and-estimating-causal-effects",
    "title": "Discussion - The Scientific Model of Causality",
    "section": "5. IDENTIFYING AND ESTIMATING CAUSAL EFFECTS",
    "text": "5. IDENTIFYING AND ESTIMATING CAUSAL EFFECTS\n5.1. Background Since the invention of randomization (generally attributed to Fisher [1925]), statisticians have emphasized the importance of study design fortheestimationofcausaleffects.Inacompletelyrandomizedexperi- ment—assumingrandomsamplingfromthepopulationofinterestand (A-1)and(A-2)—theoutcomesofsubjectsassignedtoreceivetreatment sarearandomsamplefromthedistributionofY~;thus,thisdistribution s canbeconsistentlyestimatedfromthedatacollectedintheexperiment.\nConsequently,aspreviouslynoted,comparisonsofpotentialout- comes that only require knowledge of the marginal distribution of out- comescanbemadeinrandomizedexperiments.Forexample,statisticians havetestedwhetherornottheoutcomeundertreatmentsisstochastically higherthantheoutcomeundertreatments0.AnotherexampleistheITT.\nLettingsdenotetreatmentands0 thecontroltreatment,statisticianshave longknownthatwhendataarecollectedusingrandomizedexperiments, thedifference between the treatmentgroup mean andthe control group meanontheoutcomeisanunbiasedestimateoftheITT.\nUnder complete randomization the set of potential outcomes ðfY~ g ÞkA; ð7Þ s s2S where A is the treatment assignment variable and the notation is used to denote statistical independence. (Note that A refers to the treatment assigned, which may not be the treatment actually received.) Letting Y~ denote the observed response, under (7), E(Y~ j A ¼ s) ¼ E(Y~ j A ¼ s) ¼ E(Y~); thus, the observable condi- s s tional expectations identify the parameter ITT(s, s0).\nThe completely randomized experiment is a special case of the conditionally randomized experiment in which subjects are first grouped according to a set W of pretreatment covariates, and a completely randomized experiment is then conducted within the groups. Under conditional randomization, treatment assignment is ‘‘ignorable’’ given the covariates W: ðfY~ g ÞkAjW: ð8Þ s s2S Consequently, ITT(s, s0 j W) is identified from the observable condi- tional expectations: EðY~ (cid:4)Y~ jWÞ¼EðYjA¼s;WÞ(cid:4)EðYjA¼s0;WÞ: ð9Þ s s0 Rubin (1977, 1978) saw that the conditionally randomized study provides a means to bridge the gap between experimental and observational studies. In observational studies, it is often not reason- able to believe the ignorability assumption: ðfY g ÞkD: ð10Þ s s2S However, if covariates W can be found that determine the treatment receipt process (in the sense that given these covariates, receipt of treatment does not depend on the potential outcomes), treatment assignment is ignorable, given the covariates (Barnow, Cain and Goldberger 1980 dubbed this ‘‘selection on observables’’):1 1Editor’s Note: This sentence is misprinted. The latter part of this sentence should read as follows: ‘‘… treatment assignment is ignorable, given the covariates (Barnow, Cain and Goldberger 1980). Heckman dubbed this ‘selection on observables’):’’ After this page was typeset and finalized, it was discoveredthatthecharacterstring‘‘).Heckman’’wasinadvertentlyomitted.\nðfY g ÞkDÞjW: ð11Þ s s2S Under (11), the conditional means for treatments s and s0 identify ACE(s, s0 j W): EðY (cid:4)Y jWÞ¼EðYjD¼s;WÞ(cid:4)EðYjD¼s0;WÞ: ð12Þ s s0 Theintuitionbehind(11)isstraightforwardandreadilylendsitself to use by empirical investigators. Within levels of W, treatment receipt is decided (inthe binarycase) bythetossofa(possiblybiased) coin. Ifthe parameter(2)isofinterest,asversus(12),thisisobtainedbyaveragingover themarginaldistributionofW.Iftheaverageeffectisthesameforallvalues ofW,itisnotnecessarytoknowthedistributionofW.Otherwise,itmustbe possibletoestimatethisdistributionfromthedataorthedistributionmust beknown;inpractice,itmaybethatneitheroftheseconditionsisattainable.\nBy way of contrast, despite a longstanding interest in making causal statements, until more recently economists were less interested in experimental data than statisticians. In part, this is due to the fact that economists are interested in many questions that are not parti- cularly amenable to experimentation.\nEconomists have also long recognized that human agents make choicesandtheyusetheoriesofrationaldecisionmakingtocharacterize the manner in which agents choose among alternatives. That is, econo- mistsattempttocarefullyconsideronesetofmechanismsthatindividuals might use to allocate themselves to treatments (how agents choose D).\nFurther,thisallocationprocessisoftenofintrinsicinteresttoeconomists.\nHeckmancharacterizesthestatisticalliteratureasincomplete,in part because statisticians do not model the allocation process. An example of this is adjusting for covariates using regression analysis, longadvocatedbystatisticians.Heremodelingtheconditionalexpecta- tion E(Y j W, D) alone leads to an estimate of (12). If interest resides solelyinestimating(12)when(11) holds,thereisnoneedtomodelthe allocation process. But even when (11) holds, especially in an observa- tional study where W may be a large vector, statisticians will often advocate modeling the allocation process to reduce the dimensionality of the estimation problem, a subject to which I shall return.\nNevertheless,thefocusinthestatisticalliteratureisprimarilyon obtainingthebestpossibleestimateofthecausalparameterofinterest.\nFromthispointofview,allelsebeingequal,giventhechoicebetweena randomized experiment and an observational study where units select their own treatment, the experiment is typically preferred (especially when ITT is the parameter ofinterest and/or ACE is the parameter of interest and subjects comply with their assignments (that is, for all ! and for all s 2 S, subject ! takes up assignment s when assigned to s).\nIngeneral,thewayinwhichunitsareallocatedintheexperiment will not reflect the real-world allocation mechanism where human agents are making choices, as studied by economists. As such, the opportunity to learn about this mechanism (at least from the experi- mentalstudy)isgivenup.Thisisthepricewepaytoensure(7)or(8).\nIn the observational study, however, we cannot be certain that allrelevantcovariateshavebeentakenintoaccount.If(11)holdsand the regression function is modeled correctly, we can learn about both the allocation process and the causal parameter(s) of interest. But if one or more covariates have not been taken into account and (11) is assumed,credibleestimatesofcausalparametersmaynotbeobtained.\nAs Heckman points out, individuals making decisions may have rele- vantinformationthatisnotaccessibletotheinvestigatorandtherefore such information cannot be included in the investigator’s model of the agent’s choice. In economic models of behavior, agents use this ‘‘hidden’’ information in computing the expected utility of different choices. The agent then makes the choice that maximizes expected utility. Since it is not unreasonable to suppose that utility is a mono- tonefunctionofmanyofthetypesofoutcomes(forexample,earnings) studied by economists, in such circumstances (11) will in general not be satisfied for the set of pretreatment covariates accessible to the investigator, and (12) will then not hold. In this case, if (11) is (correctly) not assumed for a given set of available covariates W, credibleestimatesmightbeobtainedusingothermethods—forexam- ple, fixed effects models (including differences in differences), control functions, instrumental variables. But if the assumptions underlying the use of these alternatives are incorrect in the application under consideration,thenasbefore,credibleestimatesmaynotbeobtained.\n5.2. Matching, Control Functions, and Instrumental Variables These are three approaches to estimating causal parameters.\nInterestingly, although the rationale and assumptions needed to justify these approachesdiffer, the propensity score(discussed below) figures prominently in all three.\nIn observational studies where it is believed that (11) holds, therestillremainstheproblemofestimatingE(Y j W,D).WhenWis a high-dimensional vector and/or several components have many values, it may be difficult to specify the form of this function cor- rectly, which can lead to faulty inferences. Matching will also be problematic in this case.\nLet S ¼ {0,1}. In a key paper, Rosenbaum and Rubin (1983) showed that when (11) holds and 0&lt;PrðD¼1jWÞ&lt;1; ð13Þ then ðfY g ÞkDÞjPðWÞ; ð14Þ s s2S 0&lt;PrðD¼1jPðWÞÞ&lt;1; ð15Þ where P(W) ¼ Pr(D ¼ 1 j W) is the ‘‘so called’’ propensity score.\nImbens (2000) generalizes the notion of a propensity score to the case of finitely many treatments. Imai and van Dyk (2004) extend thenotionofapropensityscoretothemoregeneralcasewhereDmay take on infinitely many values.\nAs a consequence of (15), EðY (cid:4)Y ÞjPðWÞÞ¼EðYjD¼1;PðWÞÞ(cid:4)EðYjD¼0;PðWÞÞ: ð16Þ 1 0 Equation (16) provides the mathematical justification for matching on the one-dimensional propensity score (as opposed to the multidimen- sionalvectorW,whichmaywellbesparse),inwhichobservationswith thesamevaluesofP(W)—one withD ¼ 1, the other withD ¼ 0—are randomly paired, their difference providing an unbiased estimate of (16).Anunbiasedestimateoftheparameter(2)canthenbeformedby taking the appropriate weighted average. Equation (16) can also be used to justify a related method called subclassification and to justify covariance adjustment using only D and P(W) (as versus D and W).\nOther parameters (for example, TT) can also be estimated using these methods.Atthispoint,thereisalargestatisticalliteratureonmatching and related methods. The interested reader might wish to consult Smith (1997) for a sociological application and Imbens (2004) for a nice overview of estimating average treatment effects under the assumption (11).\nThe beauty of matching is explained quite nicely by Heckman (page65,thisvolume)andinHeckmanandNavarro-Lozano(2004:33): matching ‘‘does not require separability of outcome or choice equa- tions into observable and unobservable components, exogeneity of conditioning variables, exclusion restrictions or adoption of specific functionalformsofoutcomeequations.’’Othermethodsofestimating causal effects, such as instrumental variables, fixed effects, and con- trolfunctions,normallyrequireoneormoreassumptionsoftheform above.\nNevertheless, Heckman is quite critical of matching on the propensity score. First, the method breaks down if P(W) ¼ 0 or 1 for one or more values of W. In practice, even in less extreme cases, an investigator may encounter the case where the estimated P(W) is close to, for example, 1 and there are no ‘‘good’’ matches from the control group. When such data are excluded, as is often the case, the causal parameter that is actually estimated (an average effect on a common support) may be of less interest. Second, when P(W) is unknown (the typical case) and it is estimated nonparametrically, the dimensionality problem is simply transferred to this estimation problem.\nHeckman also argues that it is often difficult to justify the use of (11) for some conditioning set W. According to him, this situation isexacerbatedbytheabsenceofanexplicitmodeloftreatmentchoice.\nFinally, he states that (11) is quite strong substantively, implying MTE(W) ¼ ACE(W) ¼ TT(W).\nOfcourse,itcanbearguedthat(14)mayholdevenif(11)does not. But it is difficult to think of substantive situations where we would want to argue that (14) holds and hence that (16) holds but (11) does not. We should note also that (12) may hold even if (11) does not hold, and that (16) can hold even if (14) does not. However, as above, it is difficult to think of instances where we would want to argue that one of the weaker conditions holds, but the stronger does not. Thus, I do not consider it worthwhile to further entertain argu- ments of this nature.\nHeckman questions the value of assumption (11) in social contexts.Hesuggeststhatwhenagentshavehunchesaboutthevalues of the potential outcomes, and treatment choice is based on those hunches, assumption (11) will not hold. While often true, there may nevertheless be situations where an investigator knows and measures the covariates on which the agents’ decisions are based, in which case (11) holds. See also Imbens (2004) for less trivial examples.\nWhen investigators do not think carefully about the treatment assignment process in observational studies, they are likely to omit important covariates from consideration. That said, it is not the statistician’s job to substantively justify a particular model of choice.\nNorwoulditbecorrecttosuggestthatstatisticiansareignorantof,or do not stress the importance of understanding the treatment assign- ment mechanism. Indeed, going back to Fisher (quoted in Cochran 1965) statisticians have long acknowledged the importance of having a good theory of the treatment assignment mechanism; see also Rosenbaum (2002, ch. 1), who pays a great deal of attention to this matter.) Rosenbaum and others (see Rosenbaum [2002] for further citations) have also studied the consequences due to the failure to adjust for relevant omitted covariates.\nNevertheless, even when an investigator pays very close atten- tion to the treatment assignment mechanism, a covariate (set of covariates) known to be relevant may be missing from the data and/ orsomerelevantcovariatesareunknowntotheinvestigator.Thiswill bethecaseinsomeinstanceswheretreatmentassignmentistheresult of an economic agent behaving rationally and in other instances where some other process describes the allocation to treatment groups. Unfortunately, assumption (11) is not directly testable, though it may be possible, by introducing auxiliary assumptions, to test this indirectly. Heckman’s Tables 2 and 3 simply demonstrate what they should: if the assumptions underlying the use of matching are incorrect and the assumptions underlying Heckman’s particular example of the use of control functions are correct, the observable parameters that also equal TT and ACE in the case where matching hold are now biased for TT and ACE. When it is suspected that (11) does not hold, an investigator can attempt to conduct sensitivity analyses (as statisticians have long advocated), construct bounds on the parameter(s) of interest—for example, Manski (1990) and Robins (1989)—or use some other approach—for example, fixed effects, instrumental variables, control functions—to estimate the causal parameter of interest.\nFollowing Heckman, I now examine the method of control functions, expositing the additively separable case also considered by him. He assumes (his equations 22a–22c) V¼(cid:3) ðWÞþU ; EðU jWÞ¼0; ð17Þ V V V Y ¼(cid:3) ðXÞþU ; EðU jX¼0Þ; ð18Þ s s s s where s ¼ 0 or 1 and D ¼ 1 if and only if V &gt; 0.\nThe observable conditional expectations (Y ¼ Y if D ¼ 1, Y 1 0 if D ¼ 0) are (using 18) EðYjX;Z;D¼sÞ¼(cid:3) ðXÞþEðU jX;Z;DÞ: ð19Þ s s Under assumption (18), when (11) holds (with (X, Z) ¼ W), E(Y j X, Z, D ¼ s) ¼ E(Y j X, Z) ¼ (cid:3)(X). Note that the first equality s s followsfrom(11)andthesecondfromtheadditionalassumption(18);that is,theadditionalassumption(18)isnotneededtojustifymatchingonthe propensityscore.Inthemethodofcontrolfunctions,however,assumption (11) is not made and the components E(U j X, Z, D ¼ s) are modeled.\ns Notethat E(U j X, Z, D ¼ 1) ¼ E(U j X, Z, V &gt; 0) ¼ E(U j X, Z, 1 1 1 U &gt; (cid:4)(cid:3) (Z)) by virtue of assumption (17); similarly, E(U j X, Z, V V 0 D ¼ 0) ¼ E(U j X,Z,V (cid:5) 0).Thus,under(17) and(18),itmightseem 0 that the method of control functions is more general than matching. But modeling E(U j X, Z, D ¼ s) will require additional assumptions—for s example, Heckman’s assumption (C-1): (U , U , U )??(X, Z).\n1 0 V Assumption (C-1) implies (U , U ??(X, Z) j U , so that E(U j X, Z, 1 0 V s D ¼ s)dependsonX,ZonlythroughthepropensityscoreP(X,Z).As inmatching,aprobleminvolvinghighdimensionalityisnowreducedto aone-dimensionalproblemthroughtheuseofthepropensityscore.Itis worthnotingthatassumption[C-1]doesnotimply(11).Nordoes(11) imply(C-1).Thus,evenif(17)and(18)hold,itisnotthecasethat‘‘the controlfunctionapproachismoregeneralthanthematchingapproach’’ (page 73, this volume). (Heckman points out that assumption (C-1) is not essential. Nevertheless, if this assumption is removed, others will have to be made.) The two approaches simply make different assump- tionsandwillthusbeusefulindifferentcircumstances.\nOne other point should be made. Heckman notes: ‘‘Without invoking parametric assumptions, the method of control functions requires an exclusion restriction (a variable in Z that is not in X) to achieve nonparametric identification.’’ But he is far less critical of these assumptions (and others noted above) than he is of those required to justify matching and the use of instrumental variables.\nIn that vein, Vella (1998, p. 131) points out the sensitivity to para- metricassumptionsofHeckman’soriginalwork:‘‘Asestimationrelies heavily on the normality assumption, the estimates are inconsistent if normality fails.’’ Vella (1998, p. 135) also notes that the exclusion restriction is ‘‘controversial’’ and he argues that many theoretical economic models of behavior, including the Roy model discussed by Heckman, explicitly impose Z ¼ X.\nUsinginstrumentalvariablesisanotherwaytoestimatetreatment effectsinobservationalstudies,anditmakesassumptionsthataredifferent than those made in matching or the method of control functions.\nSocial scientists have long used instrumental variables to estimate treat- ment effects when treatment choice is ‘‘endogenous.’’ Traditionally, the techniqueisexpositedasfollows.Considertheregression Y¼(cid:3)ðXÞþ(cid:4)Dþ”; ð20Þ where D ¼ 1 if the treatment is received, 0 otherwise, (cid:4) is the desired treatment effect, and E(” j X) ¼ 0. The problem here is that D is correlated with “, so in general E(” j X, D) 6¼ 0 (equivalently, E(Y j X, D) ¼ (cid:3)(X) þ (cid:4)D þ E(” j X, D)). However, if a variable Z canbeobtainedthatisassociatedwithYonlythroughD,i.e., Zdoes not directly affect the outcome, E(” j X, Z) ¼ E(” j X) ¼ 0, in which case E(Y j X, Z) ¼ (cid:3)(X) þ (cid:4)E(D j X, Z). Consequently (assuming E(D j X, Z ¼ 1) (cid:4) E(D j X, Z ¼ 0) 6¼ 0), EðYjX;Z¼1Þ(cid:4)EðYjX;Z¼0Þ (cid:4) ¼ : ð21Þ EðDjX;Z¼1Þ(cid:4)EðDjX;Z¼0Þ From a causal standpoint, the formulation above is quite vague. Heckman has helped to clarify the literature on instrumental variables. Angrist, Imbens, and Rubin (1996) is another paper that I find useful, and the approach taken there is somewhat different than Heckman’s.Thus,Ibrieflyexpositthisapproachandsubsequentlytie it to the exposition in Heckman; see also Vytlacil (2002).\nI will focus on several parameters discussed by Heckman (ACE(X)), the local average treatment effect (hereafter LATE(X)), TT(X), and I will also briefly discuss ITT(X). Following Heckman, Z is the instrumentalvariable. It will also betaken tobe binary,as in Angrist et al. (1996). (See Angrist and Imbens [1995] for some gen- eralizationsofthesetupconsideredherein.)LetZ(previouslydenoted A)denotethetreatmenttowhichasubjectisassigned(0ifassignedto the control group, 1 if assigned to the treatment group). Let D(!) denotetheobservedchoiceofunit(!)andletD (!)denotethechoice z unit ! makes when assigned to treatment z 2 {0, 1}. Similarly, let Y (!) denote the response of unit ! when that unit is assigned to (z,Dz) treatment z and chooses outcome D (!). (Previously, Y (!) was z (z,Dz) denoted Y~ (!).) Let Y (!) denote the outcome of unit ! when that z zs unitisassignedtotreatmentzand‘‘takesup’’treatments,forz ¼ 0,1, s ¼ 0, 1. Note that for each assignment, individuals take up only one treatment; nevertheless, as above, potential outcomes assuming they had taken up the treatment they did not take up can be defined.\nTo begin, it is useful to formalize the exclusion restriction— that is, the idea that the instrumental variable only affects the out- come by affecting D. This is the assumption (Holland 1988) Y ð!Þ¼Y ð!Þ ð22Þ ð0;sÞ ð1;sÞ for s ¼ 0, 1 and all !. Consequently, the potential outcomes may be writtenasY(!).Theexclusionrestrictionisverystrong,anditcanbe s quite difficult to find instruments that satisfy this assumption.\nTheproblemwithestimatingtheeffectofD(conditionalonthe covariates X) on the outcome is that (11) will not generally hold, becauseDis‘‘endogenous’’;thus,ingeneral,E(Y j D ¼ s,X) ¼6 E(Y j X).\ns However,if(8)holds(withZinplaceofA),aswouldbethecaseina randomized experiment, EðYjZ¼1;XÞ(cid:4)EðYjZ¼0;XÞ¼EðY (cid:4)Y jXÞ; ð23Þ 1;D1 0;D0 that is, ITT(X) is the numerator of the IV estimand (21). (Recall the previous discussion, which suggests that at least in some instances, ITT(X) and/or ITT may be the parameter(s) of greatest interest to a policymaker.) Continuing, ITT(X) may be broken down into the following four components: EðY (cid:4)Y jXÞ¼EEððY (cid:4)Y ÞjD ;D ;XÞ; ð24Þ 1;D1 0;D0 1;D1 0;D0 0 1 where (D , D ) ¼ (0, 0) or (0, 1) or (1, 0) or (1, 1). By virtue of the 0 1 exclusion restriction (22), units who always take up the treatment (D (!) ¼ D (!) ¼ 1), hereafter called ‘‘always takers,’’ or never take 0 1 up the treatment (D (!) ¼ D (!) ¼ 0), hereafter called ‘‘never 0 1 takers,’’ contribute nothing to (24). Angrist et al. (1996) call subjects with D ¼ 1, D ¼ 0 compliers and subjects with D ¼ 0, D ¼ 1 1 0 1 0 defiers; only these two types of units contribute to (24) under the exclusion restriction.\nAngrist et al. (1996) also assume there are no defiers (the monotonicity assumption), in which case ITTðXÞ¼EððY (cid:4)Y ÞjD ¼0;D ¼1;XÞPrðD ¼0;D ¼1jXÞ: ð25Þ 1;D1 0;D0 0 1 0 1 Dividing ITT(X) by the compliance probability (assuming this is greater than 0) gives the parameter LATE(X), the average treatment effect for the compliers (at X). The compliance probability Pr(D ¼ 1, 1 D ¼ 0 j X) &gt; 0 may also be written (under the assumptions 0 here) as E((D (cid:4) D ) j X). But this is equal to E(D j X, Z ¼ 1) (cid:4) 1 0 E(D j X, Z ¼ 0) when treatment assignment (Z) is ignorable, given X, as here. Thus, under the assumptions above, LATE(X) ¼ IV(X). Note alsothatthecomplianceprobabilitymaybewrittenasPr(D ¼ 1jX) 1 (cid:4) Pr(D ¼ 1 j X) ¼ P(X, 1) (cid:4) P(X, 0), which makes the connection 0 withthepropensityscoreevident.\nThe parameter LATE(X) (or LATE when there are no covari- ates X) will not always have policy implications of interest. To begin, thecompliersconstitutealatentsubpopulation.So,evenifwewanted toadministerthetreatmentonlytothecompliersanditwaspolitically feasible to do so, it is not possible to identify these individuals (in practice, we could model the probability of being a complier and administer the program to those deemed ‘‘most likely’’ to be compliers). Second, when the compliers are a ‘‘small’’ fraction of the population, it may be difficult to argue that the results are of great interest. For example, the question addressed by Angrist et al. (1996) istheexcesscivilianmortality(between1974and1983)resultingfrom service in the Vietnam War (not the excess mortality among compliers). For men born in 1950, the compliers constitute only 15.9 percent of the population; technically, LATE only applies to this fraction of the population. In some applications, however, even if the compliers are a small fraction of the population, LATE (or LATE(X)) is nevertheless a parameter of great interest. This would be the case when it could be argued that the noncompliers, had they complied, would experience the same benefits as the compliers.\nI return to this subject momentarily. Third, Heckman (1997) has also pointed out that LATE (LATE(X)) is an unusual parameter, insofar as its very definition depends on the instrumental variable chosen.\nThus,insomecases,LATE(X)and/orLATEmayidentifyaparameter with policy relevance (as when Z represents assignment under a parti- cular policy of interest), and in other cases it may not. For further discussion of LATE and other possible parameters of interest, see the discussion following Angrist et al. (1996) and Heckman (1997).\nAlthoughtheparametersLATEandLATE(X)maynotalways be of great substantive interest, the methodological point is that the meaning of the IV estimand has been clarified (which has great substantive implications). In particular, a basis is provided that makes it very easy to ask if IV(X) identifies other parameters of possibly greater interest, such as TT(X) and ACE(X).\nToseethis,considertheparameterTT(X),whichconditionson receipt of treatment (D ¼ 1). The units receiving treatment are the compliersinthetreatmentgroupandthealwaystakers(stillassuming there are no defiers). It follows from the foregoing results that IV(X) 6¼ TT(X) in general, and that IV(X) ¼ TT(X) if and only if the average effect of receiving treatment for the always takers (assuming the probability of being an always taker is greater than 0) and compliers is the same. Put this way, an analyst can ask whether the equality of treatment effects across these two groups is a reason- ableassumptiontomake.Iftheanalystsuspects,forexample,thatthe always takers know that (even after conditioning on X) they will benefit by taking up the treatment (or have higher gains than others bysodoing),heorshewillnotwanttoassumeequalityacrossgroups and hence that IV(X) ¼ TT(X).\nIt is also easy to see that there is one important case where IV(X) must equal TT(X). If the treatment cannot be obtained in the control group, as in many social programs, it is not possible to be an alwaystaker.Inthiscase,LATE(X) ¼ TT(X)(withoutitbeingneces- sary to assume that the average effects of receiving treatment are the same for compliers and always takers), hence IV(X) ¼ TT(X).\nSimilarly,iftheaverageeffectofDontheresponseisthesame for compliers, always takers, and never takers, IV(X) ¼ LATE(X) ¼ TT(X) ¼ ACE(X). If it is not possible to be an always taker, LATE(X) ¼ TT(X) (as above) and LATE(X) ¼ ACE(X) (hence IV(X) ¼ ACE(X)) when it is assumed that the average effects of receiving treatment are identical for never takers and compliers. In cases where it is impossible to be a never taker (programs with universal coverage and participation), LATE(X) ¼ ACE(X) if it is assumed that the average effects of D on Y are identical for always takers and compliers.\nInthecasewheretheuniteffectsofDonYarethesameforall !, the average effects of receiving treatment must be the same for all units, hence all groups, implying IV ¼ TT ¼ ACE. Of course, the assumption of constant effect is quite strong and not likely to be substantively reasonable in most social science applications.\nFinally, if the probability of being a defier is nonzero, in general IV(X) 6¼ LATE(X); but in the special case where the average effect of receiving treatment for compliers and defiers is the same, IV(X) ¼ LATE(X).Angristet al.(1996)alsodiscusstheconsequences of violating the exclusion restriction, and there is some literature on estimating complier average causal effects in the absence of this restriction (for example, see, Jo [2002]).\nHeckman approaches this subject somewhat differently. He imposes the additively separable model (18) on the potential out- comes. He then writes the observed outcome Y in terms of the potential outcomes as Y¼(cid:3) ðXÞþð(cid:3) ðXÞ(cid:4)(cid:3) ðXÞþU (cid:4)U ÞDþU ; ð26Þ 0 1 0 1 0 0 expresses the parameters TT(X) and ACE(X) in terms of (26), and states identifiability conditions in terms of D, U , and U .\n0 1 The assumption of a constant effect holds (Y (cid:4) Y is the same 1 0 for all units) if U ¼ U (cid:3) U. In this case, the instrumental variable Z 0 1 needstosatisfytheconditionE(U j X,Z) ¼ E(U j X) ¼ 0(equivalently, under(18)E(Y j X,Z) ¼ E(Y j X)fors ¼ 0,1)).Asabove,asufficient s s condition for this is YkZ j X for s ¼ 0, 1, and as above, assuming s P(X,1) (cid:4) P(X,0) ¼6 0,IV(X) ¼ LATE(X) ¼ TT(X) ¼ ACE(X).\nWhen the constant effect assumption fails but E(U (cid:4) U j X, 1 0 D ¼ 1) ¼ 0, Heckman (1997) shows that TT(X) ¼ ACE(X). A suffi- cient condition for this is ðU (cid:4)U ÞkDjX ð27Þ 1 0 (or more generally (Y (cid:4) Y )D j X). Though weaker than the condi- 1 0 tion (11), which was not presumed to hold, Heckman points out that the sufficient condition above is nevertheless quite strong, requiring thatreceiptoftreatmentnotdepend,givenX,ongainsanticipatedby subjects. That is, in general, we should not expect TT(X) ¼ ACE(X).\nWe can also see this from the results above, where it was established thatiftherearenodefiers,andtheaverageeffectofDontheresponse is identical for compliers and always takers, LATE(X) ¼ TT(X) ¼ ACE(X).Similarly,iftherearedefiersandtheaverageeffectofreceiving treatmentisidenticalfordefiersandcompliers,andforcompliersand always takers, LATE(X) ¼ TT(X) ¼ ACE(X).\nHeckman also gives general conditions under which IV(X) ¼ TT(X) and IV(X) ¼ ACE(X). As in the simpler case above, and for the same reasons, Heckman argues that these conditions are quite strong.Again,thisargumentseemsmostcompellingwhentheanalyst doesnothave accesstodatathat thedecision makerisusing tomake his decision and this information is predictive of the potential out- comes.Forfurtherdetails,thereadermayconsultHeckman(1997)or his paper in this volume.",
    "crumbs": [
      "Data Science",
      "Discussion - The Scientific Model of Causality"
    ]
  },
  {
    "objectID": "extracted/Sobel.html#conclusion",
    "href": "extracted/Sobel.html#conclusion",
    "title": "Discussion - The Scientific Model of Causality",
    "section": "6. CONCLUSION",
    "text": "6. CONCLUSION\nHeckman argues for the use of an approach to causal inference in which structural models play a central role. It is worth remembering thatthesemodelsareoftenpowerfulinpartbecausetheymakestrong assumptions. When these assumptions are correct, powerful (and correct) inferences may be obtained. Such inferences are likely to be stronger than those that would be made by advocates of randomized experiments. For example, using a structural model in an observa- tionalstudy,wemightlearn aboutthetreatmentassignment mechan- ism and various average effects, and we might extrapolate the results to a new policy in a new environment. But when the assumptions are arbitrarily invoked in applications or require the use of knowledge thattheinvestigatordoesnothave,asseemsoftenthecase,soarethe inferencesderivedfromsuchmodelingexercises.Thus,aninvestigator might well prefer to stick with simple estimators from randomized experiments,wheneverpossible.Insuchacase(presumingtheexperi- ment did not get botched and subjects complied with experimental protocols), the investigator can have greater confidence in his or her estimates of parameters such as ITT and ACE, for example.\nButIdonotwanttoarguethatstructuralmodelingisnotuseful, nor do I want to suggest that methodologists should bear complete responsibility for the use of the tools they have fashioned. To my mind, both structural modeling and approaches that feature weaker assumptions have their place, and in some circumstances, one will be moreappropriatethantheother.Whichapproachismorereasonablein a particular case will often depend on the feasibility of conducting a randomizedstudy,whatwecanactuallysayaboutthereasonablenessof invoking various assumptions, as well as the question facingthe inves- tigator (which might be dictated by a third party, such as a policy- maker). An investigator’s tastes and preferences may also come into play. A cautiousandrisk-averse investigator maycareprimarilyabout beingright,evenifthislimitstheconclusionsheorshedraws,whereas another investigator who wants (or is required) to address a bigger questionmayhave(orneedtohave)agreatertoleranceforuncertainty aboutthevalidityofhisorherconclusions.\nIn his introductory section, Heckman claims to make two major points: (1) that ‘‘causality is a property of a model of hypothe- ticals’’ (page 2), and (2) that statisticians have conflated the distinct tasksofdefiningparametersofinterest,identification,andestimation.\nIhavealreadydiscussedthefirstpoint.Iconcludewithadiscussionof thesecond.Withrespecttothispoint,Heckmanwrites(page5):‘‘This emphasisonrandomizationoritssurrogates(likematching)rulesout a variety of alternative channels of identification of counterfactuals from population or sample data. It has practical consequences because of the conflation of step one with steps two and three in Table 1. Since randomization is used to define the parameters of interest, this practice sometimes leads to the confusion that randomi- zation is the only way—or at least the best way—to identify causal parameters from real data.’’ Heckman appears to be arguing here that statisticians are putting the cart before the horse by focusing interest on average causaleffectsthatdonotdependonthejointdistributionofpotential outcomes and emphasizing identification conditions in observational studies that parallel random assignment, thus justifying estimation methods such as matching and even randomization itself. While it is impossible to assess such a claim, it is worth noting that average causal effects such as the ACE and ITT have been of great interest in public health, for example, for many years. These parameters can and have been used to address policy questions that are of great interest. Recall also that both the potential outcomes notation and the ACE (Neyman 1923) preceded randomization.\nOf course, Heckman is certainly correct to note that there are interestingestimandsthatdependonthejointdistributionandthathere, randomization is of considerably less help. In addition, as he and many othershavepointedout,whenitisimpossiblefortheinvestigatortoobtain a sufficiently rich set of covariates to condition on, other methods of identifying,andestimatingcausaleffects(includingtheusualeffectsthat donotdependonjointdistributionsofpotentialoutcomes)mustbeused.\nBut Heckman goes much further, arguing that statisticians have confounded the tasks of defining, identifying, and estimating causal parameters and, as above, even use randomization to define parameters of interest. By and large (except for some minor quibbles one might have about the way some authors have defined LATE), I would argue the opposite. One of the key contributions that statisti- cianshavemadeistounconfoundtheseissues,pavingthewayfor(1) the assessment of conditions under which valid causal inferences are permitted and (2) the development of appropriate methods for making valid causal inferences.\nConsider the claim that randomization is used to define causal parametersofinterest.Intheintroduction,Istressedtheimportanceof good notation. By using the potential outcomes notation, statisticians (recall Neyman 1923 and later Rubin) were able to define causal esti- mandsthatmirroredtheirthinkingonthecounterfactualnatureofthe causal relation and that were different from the usual descriptive (observable)parameters.\nOnce such estimands have been defined, it can then be asked under what conditions various observable parameters are equal to (identify) theseestimands.Randomizationisadeviceforassigningsub- jectstotreatmentsthatmakestheignorabilityassumptions(conditions) (8)and/or(11)plausible.Whentheseconditionshold,variousobservable parameters also equal the causal estimands. These conditions may also be met when randomization has not been used. This demonstrates the logical independence between the ignorability conditions and randomi- zation.Andclearly,theseconditionsarealsologicallyindependentofthe definitionsofcausalestimandssuchastheITT,ACE,andTT.(Readers mightalsowanttolookdirectlyatthedefinitionoftheseparametersand notethatnomentionofrandomizationismade.) More generally, defining causal estimands independently of the conditions that must be met in order to identify them allows for the development of appropriate procedures (including randomization, matching, IV, control functions, etc.) for identifying (and then estimating) the causal parameters. This is the approach taken in both the‘‘treatmenteffects’’literatureandrecenteconometricliteratures,and itisalsotheapproachthatHeckmantakes.Itisabigstepforward.\nAnother way to see the utility of making the definitions of causal effects logically independent of the conditions needed to iden- tify them is to consider the usual approach to regression analysis (or structural equation models) which is typically taken (both in the past and often even now) by many social scientists. The parameters of a regression are certainly interpretable in a descriptive sense, but social scientistsoftenimpartacausalinterpretationtooneormore(oftento all) parameters, which are typically interpreted as ‘‘effects’’ in this counterfactual sense (see Sobel [1990] for more on this point).\nJustifications for such interpretations have included the notion that the model is well specified and/or that important confounders have beencontrolledand/orthatthecausalorderingiscorrect.Allofthese justifications are extra-mathematical and virtually impossible to eval- uate, insofar as a target (i.e., a well-defined estimand) has not even been defined. Using an appropriate notation allows the researcher to clearly define the estimand of interest independently of the regression parameter(s), enabling the analyst to give conditions under which the regression parameter(s) actually identify the target(s) of interest.\nAlthough I disagree with him on this point and a number of others, Heckman, in conjunction with his collaborators, has made useful contributions to the literature on causal inference. I hope the next generation of researchers will cooperate and incorporate the various literatures on causal inference, including the statistical and econometric literatures, under one umbrella. Science will be better served when this is the case.",
    "crumbs": [
      "Data Science",
      "Discussion - The Scientific Model of Causality"
    ]
  },
  {
    "objectID": "extracted/Sobel.html#references",
    "href": "extracted/Sobel.html#references",
    "title": "Discussion - The Scientific Model of Causality",
    "section": "REFERENCES",
    "text": "REFERENCES\nAngrist, Joshua D., and Guido W. Imbens. 1995. ‘‘Two Stage Least squares Estimation of Average Causal Effects in Models with Variable Treatment Intensity.’’JournaloftheAmericanStatisticalAssociation90:431–42.\nAngrist,JoshuaD.,GuidoW.Imbens,andDonaldB.Rubin.1996.‘‘Identification ofCausalEffectsUsingInstrumentalVariables’’(withdiscussion).Journalof theAmericanStatisticalAssociation91:444–72.\nBarnow,BertS.,Cain,GlennC.,andArthurS.Goldberger.1980.‘‘Issuesinthe AnalysisofSelectivityBias.’’Pp.43–59inEvaluationStudiesReviewAnnual,5, editedbyE.StromsdorferandG.Farkas.BeverlyHills:Sage.\nBunge,Mario.1979.CausalityandModernScience.3ded.NewYork:Dover.\nCarneiro,Piedro,Hansen,KarstenT.,andJamesJ.Heckman.2003‘‘Estimating Distributions of Treatment Effects With an Application to the Returns to SchoolingandMeasurementoftheEffectsofUncertaintyonCollegeChoice.’’ InternationalEconomicReview44:361–432.\nCochran, William G. 1965. ‘‘The Planning of Observational Studies of Human Populations.’’JournaloftheRoyalStatisticalSociety,Series.A,128:234–55.\nCollingwood, Robin G. 1940: 1972. An Essay on Metaphysics. Chicago, IL.: HenreyRegneryCompany.\nCox,DavidR.1958.ThePlanningofExperiments.NewYork:Wiley.\nFisher, Franklin M. 1970. ‘‘A Correspondence Principle for Simultaneous EquationModels.’’Econometrica38:73–92.\nFisher, Ronald A. 1925. Statistical Methods for Research Workers. Edinburgh, Scotland:OliveandBoyd.\nHalloran, M. E., and C. J. Struchiner. 1995. ‘‘Causal Inference in Infectious Diseases.’’Epidemiology,6:142–51.\nHeckman, James J. 1997. ‘‘Instrumental Variables: A Study of Implicit Behavioral Assumptions Used in Making Program Evaluations.’’ Journal of HumanResources32:441–62.\n———. 2000. ‘‘Causal Parameters and Policy Analysis in Economics: A TwentiethCenturyRetrospective.’’QuarterlyJournalofEconomics115:45–97.\n———.2001.‘‘MicroData,Heterogeneity,andtheEvaluationofPublicPolicy: NobelLecture.’’JournalofPoliticalEconomy109:673–748.\nHeckman, James J., and Salvador Navarro-Lozano. 2004. ‘‘Using Matching, Instrumental Variables, and Control Functions to Estimate Economic ChoiceModels.’’ReviewofEconomicsandStatistics86:30–57.\nHolland, Paul W. 1986. ‘‘Statistics and Causal Inference’’ (with discussion).\nJournaloftheAmericanStatisticalAssociation81:941–70.\n———.1988.‘‘CausalInference,PathAnalysis,andRecursiveStructuralEquations Models.’’(withdiscussion).Pp.449–493inSociologicalMethodology,editedby C.C.Clogg.Washington,D.C:AmericanSociologicalAssociation.\nImbens,GuidoW.2000.‘‘TheRoleofthePropensityScoreinEstimatingDose- ResponseFunctions.’’Biometrika87:706–10.\n———. 2004. ‘‘Nonparametric Estimation of Average Treatment Effects Under Exogeneity:AReview.’’ReviewofEconomicsandStatistics86:4–29.\nImai, Kosuke, and David A. van Dyk. 2004. ‘‘Causal Inference with General TreatmentRegimes:GeneralizingthePropensityScore.’’JournaloftheAmerican StatisticalAssociation99:854–66.\nJo, Booil. 2002. ‘‘Estimation of Intervention Effects with Noncompliane: Alternative Model Specifications’’ (with discussion). Journal of Educational andBehavioralStatistics27:385–420.\nKempthorne,Oscar.1952.TheDesignandAnalysisofExperiments.NewYork:Wiley.\nManski, Charles F. 1990. ‘‘Nonparametric Bounds on Treatment Effects.’’ AmericanEconomicReviewPapersandProceedings80:319–23.\n———. 2000. ‘‘Identification Problems and Decisions Under Ambiguity: Empirical Analysis of Treatment Response and Normative Choice of TreatmentChoice.’’JournalofEconometrics95:415–42.\n———. 2004. ‘‘Statistical Treatment Rules for Heterogeneous Populations.’’ Econometrica72:1221–46.\nNeyman,JerzyS.1923:1990.‘‘OntheApplicationofProbabilityTheorytoAgri- Cultural Experiments. Essay on Principles. Section 9’’ (with discussion).\nStatisticalScience4:465–80.\nPearl,Judea.2000.Causality.Cambridge,England:CambridgeUniversityPress.\nRobins, James M. 1989. ‘‘The Analysis of Randomized and Non-Randomized AIDS Trials Using a New Approach to Causal Inference in Longitudinal Studies.’’ Pp. 113–59 in Health Service Research Methodology: A Focus on AIDS, edited by Lee Sechrest, Howard Freeman, and Albert Mulley.\nWashington, DC: U.S. Public Health Service, National Center for Health ServicesResearch.\nRobins,JamesM.,andSanderGreenland.2000.‘‘Commenton‘CausalInference without Counterfactuals,’ by A. Philip Dawid.’’ Journal of the American StatisticalAssociation95:431–35.\nRosenbaum,PaulR.2002.ObservationalStudies.2ded.NewYork:Springer.\nRosenbaum, Paul R., and Donald B. Rubin. 1983. ‘‘The Central Role of the Propensity Score in Observational Studies for Causal Effects.’’ Biometrika 70:41–55.\nRosenzweig, Mark R., and Kenneth I. Wolpin. 2000. ‘‘Natural ‘Natural Experiments’inEconomics.’’JournalofEconomicLiterature38:827–874.\nRubin,D.B.1974.‘‘EstimatingCausalEffectsofTreatmentsinRandomizedand NonrandomizedStudies.’’JournalofEducationalPsychology66:688–701.\n———. 1977. ‘‘Assignment to Treatment Groups on the Basis of a Covariate.’’ JournalofEducationalStatistics2:1–26.\n———. 1978. ‘‘Bayesian Inference for Causal Effects: The Role of Randomization.’’AnnalsofStatistics6:34–58.\n———. 1980. ‘‘Comment on ‘Randomization Analysis of Experimental Data: The Fisher Randomization Test,’ by D. Basu.’’ Journal of the American StatisticalAssociation75:591–93.\nSmith, Herbert L. 1997. ‘‘Matching with Multiple Controls to Estimate Treatment Effects in Observational Studies.’’ Pp. 325–53 in Sociological Methodology, vol. 27, edited by Adrian E. Raftery. Boston, MA: Blackwell Publishing.\nSobel, Michael E. 1990. ‘‘Effect Analysis and Causation in Linear Structural EquationModels.’’Psychometrika55:495–515.\n———.1995.‘‘CausalInferenceintheSocialandBehavioralSciences.’’Pp.1–38 in Handbook of Statistical Modeling for the Social and Behavioral Sciences, edited by G. Arminger, C. C. Clogg, and M. E. Sobel. New York: Plenum Press.\n———. 2001. ‘‘Spatial Concentration and Social Stratification. Does the Clustering of Disadvantage ‘Beget’ Bad Outcomes?’’ Forthcoming in Poverty Traps, edited by S. Bowles, S. N. Durlauf, and K. Hoff. New York: Russel SageFoundation.\n———.2003.‘‘WhatDoRandomizedStudiesofHousingMobilityDemonstrate: Causal Inference in the Face of Interference.’’ Unpublished manuscript, ColumbiaUniversity.\nStrotz, Robert H., and Herman O. A. Wold. 1960. ‘‘Recursive vs. Nonrecursive Systems:AnAttemptatSynthesis(Part1).’’Econometrica28:417–27.\nVella,Francis.1998.‘‘EstimatingModelswithSampleSelectionBias:ASurvey.’’ JournalofHumanResources33:127–169.\nVytlacil,Edward.2002.‘‘Independence,Monotonicity,andLatentIndexModels: AnEquivalenceResult.’’Econometrica70:331–41.\nWhitehead, Alfred N. [1911] 1958. An Introduction to Mathematics. New York: OxfordUniversityPress.",
    "crumbs": [
      "Data Science",
      "Discussion - The Scientific Model of Causality"
    ]
  },
  {
    "objectID": "extracted/VERGARAY.html",
    "href": "extracted/VERGARAY.html",
    "title": "Constructive Forms of Uncertainty in Spinoza’s Theological Political Treatise",
    "section": "",
    "text": "CONSTRUCTIVE FORMS OF UNCERTAINTY IN SPINOZA’S THEOLOGICAL POLITICAL TREATISE 1\nALFONSO R. VERGARAY\nTexas A&M International University alfonso.vergaray@tamiu.edu ABSTRACT In the preface to the Theological Political Treatise Spinoza presents uncertainty as an intractable problem in political and social life. Scholars have indirectly examined uncertainty’s role in TTP, focusing on fear, hope, and superstition. This article takes a comprehensive view of the multiple parts of uncertainty, ultimately showing uncertainty to be both a problem and a source of social vitality. It argues that Spinoza’s central means of addressing destructive forms of uncertainty is through the advancement of what I call constructive forms of uncertainty. Instead of recognizing only the poten- tial dangers and pitfalls accompanying uncertainty, this paper argues that uncertainty can construc- tively support political stability and a free state. This interpretation presents a fresh reading of the role of uncertainty in the TTP and points toward Spinoza’s abiding concern with uncertainty through- out his oeuvre.\nKEYWORDS Spinoza; uncertainty; hope; fear; superstition; devotion; democracy.\nQuestions about uncertainty are at the heart of Spinoza’s philosophy. Can certain knowledge be attained? How certain are the workings of the natural world? How do experiences of uncertainty influence political and social life? Before applying his mind to those questions, Spinoza experienced harrowing forms of uncertainty in his early life. At the age of six, he lost his mother. His sister died when he was nineteen; his stepmother and father died when he was twenty-one. At the age of twenty-three, Spi- noza was excommunicated from the Jewish community of Amsterdam. Moreover, dur- ing those periods and in later life Spinoza struggled with health issues, survived multiple plagues, and lived in a society with persistent religious and political turmoil (Nadler 2018, Steenbakkers 2021).\n1 Earlier drafts of this paper benefited from comments and support by Joe Pitt, Ben Sax, and Eric Schliesser.\nSave his excommunication, the kinds of life events highlighted above were shared by those living in the 17th-century Dutch republic of Spinoza’s day. Indeed, life expec- tancy was low, political and religious disputes the norm, and public-health crises an inescapable life obstacle. Spinoza’s response to the tumultuous sea of uncertainties he experienced, however, was distinct. Through a religious-like devotion to philosophy, Spinoza embraced “an ideal of intellectual rest,” applying his mind to what I call the problem of uncertainty (Carlisle 2021, 23). Life is experienced as uncertain (i.e., as an open question) and as such demands a response. When philosophy becomes the tool used to diagnose the problem of uncertainty, it becomes apparent that uncertainty is also a metaphysical, epistemological, and political problem. The problem of uncer- tainty, while not named as such by Spinoza—much like the “principle of sufficient rea- son” and “necessitarianism”—can nonetheless be discerned throughout his philosophy.\nWhile I cannot defend the entirety of that claim here, I limit what follows to Spinoza’s thoughts on uncertainty as they relate to political and social life.\nIn particular, I reconstruct Spinoza’s argument for constructive forms of uncertainty in the Tractatus Theologico-Politicus (TTP). By constructive uncertainty, I refer to so- cially beneficent forms of uncertainty that help sustain social order and/or promote human flourishing. In the preface to the TTP, Spinoza shows in dramatic fashion the ways that uncertainty creates upheavals of thought that are central to the origin and maintenance of superstition. In all, uncertainty is presented as an intractable political and social problem. Although uncertainty is an intractable problem, Spinoza does not suggest eliminating it, nor is restraining its effects sufficient; rather, I argue, Spinoza’s main means of addressing the uncertainty underlying superstition is to promote con- structive forms of uncertainty. Spinoza prefers hope as a constructive form of uncer- tainty, as it aligns with the active affects. Fear, by contrast, while useful under certain circumstances, is presented as a largely destructive form of uncertainty.2 The salutary effects of a hope-filled society are insufficient, however, if not accompanied by devotion to the state. A devotion to the state anchors hope, solidifying it, which distinguishes it from the reckless and wavering hopes pursued by those gripped by fear.\nThis article comprises three sections. The first section lays the groundwork for un- derstanding constructive forms of uncertainty by providing an overview of the problem of uncertainty in the preface of the TTP. The second section turns to chapter V of the TTP to introduce both a pre-democratic use of constructive uncertainty in the Hebrew republic as well as devotion’s stabilizing function. The third section ties together what 2 In Steinberg’s framing, Spinoza “privileges hope over fear” (83). I use “preference” instead of “priv- ilege” in order not to lose sight that, for Spinoza, prioritizing one emotion over another is “dependent on the specific circumstances that make obedience possible” (Vardoulakis 2020, 238).\nfollowed in its examination of democratic hope. While not exhaustive, I hope that what follows encourages readers of Spinoza to understand his philosophy as an attempt to come to terms with the problem of uncertainty.\nMore generally, this paper goes against the grain of conventional thinking regarding uncertainty. On the whole, uncertainty is presented as a problem in both popular cul- ture and academic literature. To deal with this problem, academics and risk managers transform uncertainty into risk in order to calculate risk probabilities empirically.3 Their aim is to control, reduce, and, in all, mitigate a danger. Spinoza understood that be- cause experiences of the future as uncertain are an inevitable feature of human life, uncertainty must be dealt with on its own terms. In addition to being a danger that needs to be restrained or avoided, uncertainty can be a constructive social force. In its optimal political form, the uncertainties supported and unleashed in a free state point their inhabitants toward joyful living.\nSUPERSTITION AND UNCERTAINTY IN THE PREFACE OF THE TTP This section provides an overview of uncertainty’s link to the origin and maintenance of superstition in the preface of the TTP. It highlights the relationship between the uncertain emotions and superstition, concluding with a preliminary reflection on Spi- noza’s preference for hope over fear. After completing this section we will be prepared to consider constructive forms of uncertainty in the TTP.\nDespite the many themes of uncertainty that run throughout the TTP, scholars have paid limited attention to its overarching significance. They either ignore uncertainty’s role in Spinoza’s political thought, or acknowledge it without giving it pride of place in their analysis.4 James (2012) uses the term uncertainty three times to connect it with hope, fear, and/or superstition, but does not develop the connection further. She notes, for example, that in order to relieve “the fear to which uncertainty exposes” individuals turn to superstition (18). Steinberg (2018) likewise uses the term uncertainty when dis- cussing Spinoza’s analysis of hope and fear in the preface of the TTP, but says little else about the role of uncertainty in his analysis of Spinoza (83). Yirimyahu Yovel (1989), in addition to acknowledging the presence of uncertainty in the TTP, makes 3 Consider, for example, Hacking, The Emergence of Probability; Modd, When All Else Fails; and Power, Organized Uncertainty.\n4 See James (‘Spinoza on Superstition’); Kaminsky (Spinoza, 61-64); Nadler (‘Hope, Fear, and the Politics of Immortality’). I use ‘emotion’ to refer to Spinoza’s use of affectus. Hope and fear are labeled as emotions in order to preserve the possibility that they may function as passive or active affects in different contexts.\nthe direct claim that uncertainty “breeds superstition” (131). I follow and develop his claim in what follows.\nThe first line in the TTP introduces readers to what I call the problem of uncer- tainty, or what is parallel when considering social life, the problem of superstition.\nIf men could manage all their affairs by a definite plan, or if fortune were always favorable to them, no one would be in the grip of superstition. (TTP 65) Spinoza’s requirements for preventing humans from falling prey to superstition can- not be met. Human’s lack control to direct their lives according to a definite plan, and good fortune cannot be relied on to consistently ward off the destabilizing blows of misfortune. The experience of the future as uncertain, consequently, makes humans susceptible to superstition. For Spinoza, then, uncertainty and superstition can be un- derstood as an inter-connected and self-sustaining problem that can be alleviated, but not resolved.\nThere are three steps to trace in Spinoza’s use of uncertainty when describing its connection with superstition. First, experiencing the future as uncertain is tied to the omnipresent problem of superstition, placing uncertainty at the core of our understand- ing of the origins and maintenance of superstition. Second, uncertainty about the future releases the uncertain and future-oriented emotions of hope and fear. Those emotions are both forms of uncertainty and responses to uncertainty. Third, those emotions can be used by political agents and/or embedded within institutional and legal frameworks to either constructively support the state, or destructively lead to the breakdown of civil order. Constructive here refers to (a) the basic political and social stability required to have a minimally functioning state and (b) the promotion of human flourishing. Notice, you can have (a) without (b), but necessarily will have (a) if you have (b). The uncertain emotions of hope or fear can constructively work to reach and sustain both these ends.\nConstructive need not be “good” in my rendering. For instance, a despot can use con- structive uncertainties for her devious ends, aiming for minimal social stability without a concern for the human flourishing of her subjects.\nBefore proceeding to examine Spinoza’s thoughts on constructive uncertainty, let’s first better understand how fear and hope are both forms and responses to uncertainty.\nThe animating force behind the problem of uncertainty are the fluctuating emotions that are unleashed due to a lack of certainty about the future.\nThen they vacillate [fluctuant] wretchedly between hope [spem] and fear [me- tumque]; desiring immoderately the uncertain [incerta] goods of fortune, and ready to believe anything whatever. While the mind is in doubt [in dubio], it’s easily driven this way or that—and all the more easily when, shaken by hope and fear, it comes to a stand- still. At other times, it’s over-confident, boastful and presumptuous. (TTP 65-6) The uncertain emotions dominate the emotive state of someone in the grip of un- certainty about the future. Even over-confidence, boastfulness or presumptiveness, which do not qualify as uncertain emotions, are momentary states on the pendulum of a life gripped by uncertainty. The uncertain emotions here refer to hope and fear.\nSpinoza gestures to his fuller account of hope and fear in the Ethics when he writes of the vacillating [flutuant] nature of those emotions, which reminds us of the vacillation of mind [fluctuatio animi] that he presents in that work. In the Ethics, Spinoza writes of hope and fear as follows: Hope is nothing but an inconstant [inconstans] Joy which has arisen from the image of a future or past thing whose outcome we doubt [dubitamus]; Fear, on the other hand, is an inconstant Sadness, which has also arisen from the image of a doubtful thing.\n(IIIP18S2) Hope and fear are uncertain emotions in two interrelated ways. First, they both are experienced as inconstant emotive states that are driven by doubt [dubitamus] regard- ing an outcome.5 The uncertain feelings that accompany doubt about a prospective outcome are necessarily linked to these emotions. Consequently, when doubt is re- moved, hope and fear transform into confidence and despair, respectively. Second, as Spinoza explains later, vacillations of the mind [fluctuatio animo] stem from hope and fear (IIIP49S). Vacillation of mind refers to a ‘constitution of the Mind which arises from two contrary affects’ and is closely linked to dubitamus (III P17 S). As hope and fear are interrelated—‘there is no Hope without Fear, and no Fear without Hope’—they have the potential to create simultaneous or fluctuating experiences (IIIP50S). For ex- ample, if a student is filled with hope that she performed well on an exam, she also fears, on some level, that she may have performed poorly. The student’s uncertain affects are activated, in other words, when there is uncertainty regarding the outcome of her final grade. While hope or fear may dominate her experience at certain mo- ments, they may also increase, decrease, or collide based on external causes. If she learns, for example, that the class average for the exam is low, her initial inclination towards hope might turn to fear. Once her final grade is revealed (i.e., when certain knowledge replaces uncertainty), hope and fear dissipate, and joy, grief, or another set- tled affect overtakes. It should now be understood that for Spinoza a state of emotive uncertainty is present in hope and fear, whether as doubt regarding an outcome accom- panying each or the vacillations of the mind that stem from both.\nReturning to the beginning of the preface, let us apply Spinoza’s ideas regarding the emotive uncertainty accompanying fear and hope to his account of the problem of 5 As Susan James puts it, “What ties the two [fear and hope] together is the fact that each is a response to doubt or uncertainty.” (2021) superstition. In what follows I restate Spinoza’s account of the destructive uncertainties underlying superstition and present inadequate responses to those uncertainties to highlight the need for constructive uncertainties.\nSpinoza follows a regular characterization of superstition as a response to fear found in classical writers, and reiterated all the way through the early-modern period (James, ‘Spinoza on Superstition’, 3). In particular, he writes in the TTP: ‘The reason, then, why superstition arises, lasts, and increases, is fear’ (TTP 67). Given Spinoza’s state- ments regarding the interconnected nature of hope and fear in the Ethics, his claim about fear’s relationship to superstition in the TTP appears one-sided.6 That intercon- nected view is suggested earlier in the preface where Spinoza describes the alternating hopes and fears that are the outgrowth of superstition. Spinoza’s reason for emphasiz- ing fear’s connection to superstition in the quote above is to highlight its destructive possibilities; possibilities borne from emotive uncertainty.\nSomeone in the grip of emotive uncertainty is liable to change superstitions on a whim,7 due to superstition being “necessarily very fluctuating and inconstant’ (TTP 68).\nIt is difficult, after all, to remain true and loyal to any one superstition when caught in a state of emotional unrest. Consequently, Spinoza writes, ‘This inconstancy [incon- stantia] has been the cause of many uprisings and bloody wars’ (TTP 68). The incon- stant nature of superstition is one form of what I call destructive uncertainty, as it leads to social and political unrest. Yet the ability to use superstition for constructive ends is immediately addressed by Spinoza in the next sentence: As is evident from what we have just said, and as Curtius aptly noted, “Nothing gov- erns the multitude more effectively than superstition.” (Quintus Curtius, IV, x, 7) (TTP 68) Political agents have attempted, in other words, to constructively use superstitions— read uncertainties—to create order and forms of governance.8 Those attempts, as Spi- 6 The immediate context before and after the quote above—on the crazed and tormenting rela- tionship between fear and superstition— sheds light on Spinoza’s emphasis on fear. In the Ethics Spinoza presents a more balanced account of superstition: ‘we are so constituted by nature that we easily believe the things we hope for, but believe only with difficulty those we fear, and that we regard them more or less highly than is just. This is the source of the Superstitions by which men are everywhere troubled’ (IIP50S).\n7 As Spinoza puts it, ‘The common people [vulgus] always remain equally wretched, so they are never satisfied for long’ (TTP 68).\n8 Curtius is using and reacting to uncertainty. See James (2012) “Mining its insights, Spinoza now focuses on Quintus Curtius’s claim that even the boldest rulers are liable to become superstitious when they confront great danger and uncertainty.” (19) noza makes clear, often fail, as it is easy to sway the common people from one super- stition to the next.9 Still, the attempt to use superstition for constructive ends (i.e., to govern) is highlighted here. The fluctuating nature of superstitions due to the ever pre- sent problem of uncertainty, however, makes attempts to govern with superstitions un- reliable. How, then, can the problem of uncertainty that underlies the types of super- stitions Spinoza presents in the preface be addressed? The first proposal Spinoza reviews is the attempt of ‘the Turks’ to instill religious prejudices to such an extent that it leaves ‘no room in the mind for sound reason, nor even for doubting [dubitandum]’ (TTP 68). In other words, one manner of addressing the uncertainty underlying superstition is to eliminate uncertainty by instilling dogma, a fixed superstition that bypasses doubt (uncertainty) with certain beliefs. In practice, that may temporarily produce results. Over time, however, competing superstitions are bound to arise, disrupting the temporary order produced by dogmatic belief. Further- more, the attempt to eliminate doubt through indoctrination enslaves the mind, inhib- iting the freedom of judgment necessary for the attainment of knowledge and freedom.\nInstead of enslaving the mind, perhaps a solution to the problem of uncertainty is educating the mind to not be swayed by the uncertain emotions. In the Ethics, Spinoza shows a path to a life of freedom, i.e., the way to escape a life of bondage to the passions.\nPart of that education entails striving to ‘depend less on Hope, to free ourselves from Fear, to conquer fortune as much as we can, and to direct our actions by the certain counsel of reason.’ (IIP47S). Indeed, leading a rational life is an option to prevent being subject to superstition. The difficulty of attaining that way of life, however, corre- sponds with its rarity.10 In other words, while striving for the knowledge necessary to free oneself from fear is a possibility for the few, it is not a realistic option for the many.11 Still, Spinoza argues it is possible to develop a society that points towards rational ways of being.12 That does not mean, however, that you can overcome superstition. The human inclination towards superstition is too interwoven with what it means to be hu- man to ever be eradicated on a collective scale. Hence Spinoza can unequivocally state in the preface of the TTP that ‘it’s as impossible to save the common people from superstition as it is from fear’ (TTP 75). Creating a society of philosophers is therefore 9 See the sentence following the Curtius quote, ‘That’s why they are easily led, under the pretext of religion, now to worship their Kings as Gods, now to curse and loathe them as the common plague of the human race.’ (TTP 68) 10 Consider Spinoza’s famous final line in the Ethics, ‘all things excellent are as difficult as they are rare.’ (VP42S) 11 ‘But only a very few (compared with the whole human race) acquire the habit of virtue from the guidance of reason alone’ (TTP 281-82).\n12 Susan James (2012) makes this case in her book Spinoza on Philosophy, Religion and Politics.\nnot a realistic option. At best, a society can incline individuals towards rational ways of being using constructive uncertainties—including superstitious like uncertainties—to point the way. In sum, neither instilling dogma, nor expecting most individuals to live a life of reason, effectively addresses the problem of uncertainty on a collective scale.\nSpinoza’s explicit response to the problem of uncertainty is on the surface puzzling.\nInstead of filling ‘the free judgment of each man with prejudices,’ Spinoza suggests that the complete freedom of judgment, already present in the Dutch Republic, is condu- cive to the piety and peace of the Republic (TTP 69).13 This is puzzling as promoting complete freedom of judgment would unleash a broad array of viewpoints. Those view- points would likely clash given that judgment is inherently fallible, resulting in “no nor- mative criteria for a correct practical judgement” (Vardoulakis 260). In such conditions uncertainties would be unleashed, resulting in more collective superstitions. Given the above, it is unclear how granting freedom of judgment addresses the problem of super- stition Spinoza carefully lays out in the preface.\nOne response to this puzzle might note that Spinoza later suggests ways to restrain the freedom of judgment, and therefore deals with the problem of uncertainty through mechanisms of restraint.14 While it is the case that Spinoza dedicates the latter section of the TTP to discuss the limitations to freedom of thought in a free state, restraining that freedom does not squarely deal with the fundamental problem of uncertainty.\nThus, the problem of uncertainty unleashed in a free state remains. Seeing that uncer- tainty cannot be eliminated, a better approach is to ask, what uncertainties should be unleashed in a free state? And how do those uncertainties combat destructive forms of superstitions /uncertainties? Briefly answering this question will take the first step to understand Spinoza’s means of addressing the problem of superstition. In what follows, I review his preference for hope over fear as a constructive form of uncertainty. I later work out those ideas in section III of this paper.\nHope is the emotion that flourishes in a democratic (free) state. Unlike its counter- part fear, hope, properly framed in a democratic society, is better equipped to guide people towards a life lived in common that increases the possibility of peace and stabil- ity over time. Hope contributes to the ‘foundation and end’ of democracy, which is to: avoid the absurdities of appetite, and to confine men within the limits of reason, as far as possible, so that they may live harmoniously and peacefully. (TTP 288) 13 It is a stretch to claim there was “complete freedom of judgment” in the Dutch republic at the time. See Curley 55-56.\n14 Spinoza’s stated purpose from chapter XVI onwards is to examine how far ‘freedom of thought, and of saying what you think, extends in the best Republic’ (TTP 282).\nHope does not alone achieve the fundamental purpose of democracy. It is a neces- sary, but not a sufficient condition. Devotion to a free state is another piece in the puz- zle. I later examine devotion and freedom as they relate to constructive uncertainty, especially devotion’s role in stabilizing the inconstant nature of superstition. The point here is that the hope unleashed in a democratic society produces a constructive form of uncertainty, which combats dangerous superstitions alongside devotion to a free state. Let us preview why using hope is a viable option to counter the problem of superstition.\nAs we have seen, using the intellect alone to deal with destructive passions on a social and political scale is not sufficient. Thus, any manner of addressing those passions will necessarily entail countering the destructive passions with other affects. That is to say, we should follow Spinoza when he writes: An affect cannot be restrained or taken away except by an affect opposite to, and stronger than, the affect to be restrained. (IVP7) Fear, as noted above, takes center stage in Spinoza’s description of the destructive effects of superstition in the TTP. It is so problematic that Spinoza writes: ‘men are tormented by superstition only so long as they are afraid’ (TTP 67). If fear is taken out of the equation, in other words, superstition can seriously be tempered. As eliminating fear is not an option, its counterpart, hope, offers a way to redirect its effects.\nHope is not without its defects, however. In the preface to the TTP, Spinoza notes that hope can be used to protect superstition (TTP 68). In the Ethics Spinoza writes that ‘Hope and Fear cannot be good of themselves’ and observes that they ‘show a defect of knowledge and lack of power in the Mind’ (IVP47S). Indeed, fear and hope are obstacles to our autonomy, freedom, and happiness. (Nadler 2005, 216). Yet be- cause humans rarely live from the dictates of reason, Spinoza further notes, ‘Hope and Fear, bring more advantage than disadvantage’ (IVP54S). In other words, there is a constructive role for hope and fear to play. Like Hobbes, Spinoza notes that fear can be used to foster order and serve as a form of restraint. Unlike Hobbes, however, he argues that relying on fear to govern cannot consistently be depended on to foster po- litical stability. Even when fear does manage to sustain a society, the damaging forms of superstition it unleashes stunts human development, seriously hampering individual and collective flourishing. Spinoza’s preference for hope in a free society, moreover, differs starkly from Hobbes who makes fear an all-encompassing feature of his author- ity-driven political theory.15 15 See chapter 7 in Vardoulakis for an excellent account of natural right and authorization in Spi- noza and Hobbes.\nBefore turning to introduce examples of constructive forms of uncertainty in the Hebrew republic, let us turn to a quote from Spinoza’s Political Treatise (TP) to frame the discussion that follows.\nFor a free multitude [multidudo] is guided [ducitur] by hope more than by fear, whereas a multitude which has been subjugated is guided more by fear than by hope. The first want to cultivate life; the second care only to avoid death. The first are eager to live for themselves; the second are forced to belong to the victor. So we say that the second are slaves, and the first free. (TP 530)16 This quote succinctly captures Spinoza’s position that the uncertain emotions lead [ducitur] people, as well as his preference for hope as the guiding form of uncertainty in a free state.\nCONSTRUCTIVE UNCERTAINTY IN THE HEBREW REPUBLIC Spinoza first addresses constructive forms of uncertainty in chapter five of the TTP, a chapter that begins discussing ceremonial rites in the Hebrew state. His discussion of the uncertain emotions is most prominently featured when he turns from the ‘authority of Scripture’ to ‘universal foundations’ to continue demonstrating how and why cere- monial rites have preserved and stabilized the Hebrew state (TTP 143). More broadly, this section in chapter V is a precursor to his later chapters on politics. I follow Spi- noza’s argument in this section as it relates to constructive uncertainty, taking a brief detour to chapter XVII to discuss devotion’s role in stabilizing the inconstant nature of superstitious beliefs.\nAfter arguing that social order is necessary for human security and flourishing, Spi- noza turns to demonstrate that laws are necessary due to the recalcitrant nature of hu- mans. He begins noting that a society without laws is not possible since humans are liable to disobey what true reason teaches. They instead are apt to follow their narrow self-interest (TTP 144). Considering that humans are inclined to be narrowly self-inter- ested, Spinoza notes that teaching ‘true moral lessons’ will not yield the desired result of individuals voluntarily choosing to live together in peace (TTP 144). Instead, hu- mans require authority, force, and laws to be moved towards peaceful living.17 16 I take Spinoza’s usage of multidudo here to refer to a large number of people. For notes on alternate uses of multidudo see Curley’s glossary entry, 644.\n17 Vardoulakis argues that for Spinoza utility comes prior to authority and a need for laws. See chapter 4. In his words, “reciprocity of utility does not require an established legal or political authority” (147).\nSpinoza observes that the emotive forces inclining humans towards self-interest are such that they ‘take no account of the future’ (TTP 144). A narrow presentism, in other words, coincides with immoderate desires. Instead of thinking about the future, a per- son gripped by self-indulgent desires is stuck in the present.18 One of the benefits of promoting constructive uncertainties, whether guided by hope or fear, is that it creates a future-oriented posture that combats the narrowing of horizons that occur without it.\nImmediately after claiming that force and authority are necessary for society, Spi- noza tempers a potential penchant for authoritarianism when he quotes Seneca’s ob- servation that ‘no one has sustained a violent rule for long; moderate ones last’ (TTP 144). Spinoza connects this insight with fear in the next sentence. He writes: For as long as men act only from fear, they act very unwillingly, and don’t recognize the advantage, even the necessity, of doing what they’re doing. All they care about is saving their necks, and avoiding punishment. (TTP 144) Spinoza in effect criticizes any form of ruling that attempts to rely solely on fear.\nWhile using fear of punishment to motivate subjects to obey can prove effective in the short term, relying solely on fear driven uncertainties is bound to be counterproductive, putting peace and social stability in peril. Spinoza then shows that finding a means to move people to willingly act in a way that encourages peace and stability is more effec- tive than attempting to achieve that end through threat of punishment and fear. This principle is stated in his second observation that follows from ‘universal foundations.’ It reads: in each state the laws must be so instituted that men are checked not so much by fear as by hope of some good they desire very much. For in this way everyone will do his duty eagerly. (TTP 144) Laws can be so instituted, in other words, that they become a form of uncertainty that inclines people to do their duty willingly. Rather than instating laws that heighten fear, Spinoza notes, laws that encourage future-oriented hopes are best suited to serve as a check. Hope checks socially deviant behavior, for example, not through a threat of punishment, but rather through a promise for a better future.\nHe then illustrates this principle by returning to the example of the Hebrew republic, whose leaders were in a position to ‘enact new laws or to establish new legislation’ (TTP 145). Considering the Hebrew people were ‘weakened by wretched bondage,’ Spinoza writes that they were not prepared for self-governance, and consequently they were 18 See also the Ethics ‘To this we may add that when we follow our affects, we value most the pleasures of the moment, and cannot appraise future things with an equal affect of mind’ (IV Appendix XXX).\nsubject to rule by a single sovereign (TTP 145). Moses was the most successful of these sovereigns for two reasons. First, he could distinguish himself from the people by con- vincing them of his divine power. Second, he took care to establish laws that were so framed that ‘the people should do their duty, not so much from fear, as voluntarily’ (TTP 145). The threat of an impending war and the inability to rule the Hebrews through force alone led Moses to use these strategies. Spinoza applies the second strat- egy when he observes that success in war depends on soldiers being led through en- couragement rather than through fear-laden threats of punishment. This is why, Spi- noza continues, ‘Moses introduced religion into the Republic, so that the people would do their duty not so much from fear as from devotion [devotione]’ (TTP 144-45).\nWhile fear is downplayed here as an effective means to enlist obedience, devotion takes its place as a motivating factor. How can devotion encourage obedience? How does devotion temper the dangerous uncertainties underlying superstition? Let us examine the power of devotion to enlist obedience and combat the inconstant nature of super- stition in chapter XVII, as doing so will help us better understand Spinoza’s claim in chapter V and set the stage for the next section.\nChapter XVII is focused on the causes behind the rise and fall of the Hebrew re- public. Devotion, described as a combination of love and wonder (TTP 316),19 takes center stage when Spinoza turns from an analysis of ways to restrain leaders to examine ways to restrain the people (TTP 313). Devotion, in one form or other, is prominently featured in this section, alongside ‘the principle of advantage’ and ‘extreme training in obedience,’ as a means to restrain people in such a way to create a peaceful and stable state (TTP 315, 316). In this context, devotion served as a form of restraint as it was used to create a pious loyalty to the Hebrew state. Spinoza describes how a ‘devotion [devotio] to their country’ was one of the factors that allowed the Hebrews ‘to bear everything with special constancy and virtue’ (TTP 314). This devotion ran deep. As Spinoza put it: ‘the love of the Hebrews for their country [patriam] was not a simple love, but piety [pietas]’ (TTP 314). This piety gave the Hebrews a clear sense of their enemies, which in turn strengthened their willingness to defend their country, thereby encouraging order and obedience in the state.\nMore to the present argument, devotion helps stabilize the inconstant nature of su- perstition outlined in the preface. It helps temper the swaying from one superstition to the next due to the emotive unrest that accompanies moments of uncertainty. De- votion cultivates inward stability, which helps weather outward uncertainties. More to Spinoza’s larger argument in the TTP, devotion to the state places a priority on the 19 See also Ethics IIIP52S collective good, thus facilitating peace and stability. Spinoza ends his discussion of de- votion in this section in the strongest terms. He notes: I don’t think anything more effective can be devised for steering people’s hearts in a certain direction. Nothing wins hearts more than the joy which arises from devotion.\n(TTP 316) Devotion encourages a kind of joyful obedience by cultivating subjects who are will- ingly loyal, obedient, and loving. Fear driven obedience, on the other hand, decreases the power of individuals, diminishing joy and amplifying sadness.\nIn conjunction with devotion, Moses also placed the Hebrews ‘under obligation with benefits, and in the name of God promised them many things in the future’ (TTP 146).\nIn other words, Moses created a future-oriented hope for the people in order to serve as a counterweight to fear driven forms of rule. Instead of fearing punishments, the Hebrews were inclined to follow orders based on uncertain promises. Those promises, enlivened through devotion, amount to a kind of civic hope (Steinberg, 90). This is another example of a constructive form of uncertainty in the TTP.\nThe usefulness of constructive forms of uncertainty for the Hebrews, however, was limited. As the Hebrew people were ‘weakened by wretched bondage,’ they were more effectively compelled by force (TTP 145). That fact is reflected in the object of the ceremonial observances, which were designed so that the Hebrews ‘were not their own master in anything, but they were completely subjected to someone else’s control’ (TTP 146). Consequently, fear and force, rather than hope, were the primary means of guiding the Hebrews. To see constructive forms of uncertainty in their full vigor, we need to turn to democratic hope.\nDEMOCRATIC HOPE AS A FORM OF CONSTRUCTIVE UNCERTAINTY Hope flourishes in abundance in a democratic state, contributing to its peace, stabil- ity and rational character. It generates, in other words, a form of uncertainty that is salutary. Hope alone does not contribute to the fundamental purpose of democracy.\nDevotion is also necessary. Devotion to a free state, by prioritizing a free state above other goods, sets boundaries to the uncertainties unleashed in a democratic state. In this section I will defend this first claim, and then turn to devotion as it relates to hope as a constructive form of uncertainty.\nChapter XVI begins a new section in the TTP. Spinoza announces that it is time to ask how far freedom of thought and speech can extend in ‘the best Republic’ (TTP 282). The rest of the TTP is dedicated towards that end. It also, in large part, seeks to work out the proper relationship between religion and the state. I first lay the founda- tion for that argument by examining the relationship between natural right and democ- racy. Doing so will show the limitations of relying on fear as a means to guide a free people.\nIn the first part of chapter XVI Spinoza sets out to discuss the relationship between natural right and the creation of social contracts. Natural right, for Spinoza, is coexten- sive with each person’s power. If someone is powerful enough to do something, natural right sets no boundaries and thus permits it. Consequently, a life lived by appetite alone, or a life lived by the dictates of reason, are on the same plane when it comes to natural right. In a state of nature, in other words, nothing can rightfully constrain indi- viduals from acting according to their own necessity. This natural right is so founda- tional it can never completely be transferred away. Nonetheless, Spinoza notes: ‘no one can doubt how much more advantageous it is to man to live according to the laws and certain dictates of reason’ (TTP 284). That is to say, in an environment where ‘everyone is permitted to do whatever he likes, and reason is granted no more right than hatred and anger,’ fear reigns supreme (TTP 284). Correspondingly, Spinoza notes: ‘There’s no one who does not desire to live securely, and as far as possible, without fear’ (TTP 284). Contracts are therefore formed that place limits on natural rights in exchange for peace, security, and a better life. There is always, however, a tension in such contracts. As any contract necessarily rubs up against natural right, there is the possibility of people rebelling from said contracts. Hence, Spinoza notes: ‘a con- tract can have no force except by reason of its utility’ (TTP 286). If a contract ceases to function in a way that corresponds with the nature of humans, in other words, it is ‘null and void’ (TTP 286).\nIf a ruler relied on a coercive form of rule that created perpetual fear in his subjects, for example, the contract would invariably fail because it goes against natural right. Spi- noza makes this point as follows: ‘The supreme power would act in vain if he com- manded a subject…not to desire to be freed from fear…which necessarily follow[s] from the laws of nature’ (TTP 296). The desire to be freed from fear, in other words, is so deeply inscribed in human nature that no ruler could sustain a peaceful and stable state relying solely on fear. While fear can serve as a constructive form of uncertainty, the problem to be avoided is a single-minded reliance on fear, which necessarily increases civically damaging forms of superstition and goes against the human desire to live free from fear. The broader point is that hope or fear can effectively be used as means to rule since they are deeply ingrained motivating factors. As Spinoza notes when discuss- ing the motivating factors to enter a contract: For it’s a universal law of human nature that no one neglects to pursue what he judges to be good, unless he hopes for a greater good, or fears a greater harm. Nor does anyone submit to any evil, except to avoid a greater one, or because he hopes for a greater good.\n(TTP 285) Consequently, any successful contract promises, and thus awakens hope for, peace and security absent from the state of nature. The best state makes the further promise of freedom. The promise of freedom is tantalizing as it mimics the freedom found in the natural state. Democratic freedom, in particular, creates conditions where no citi- zen is subject to the arbitrary rule of others. The problem, of course, is that democratic freedom cannot amount to citizens ‘living as one likes’ in the way found in the natural state. Otherwise, the problems found in the natural state would likewise plague democ- racies. Spinoza, in fact, characterizes as seditious the thought that each person “ought to live according to his own decision”. (TTP 348) Even in a free state, consequently, mechanisms of restraint need to be implemented—such as laws, customs, and the like.\nAs Spinoza writes: [a democratic state’s] foundation and end are precisely to avoid the absurdities of appe- tite, and to confine men within the limits of reason, so far as possible, so that they may live harmoniously and peacefully. (TTP 288) Notice that not all appetites need to be avoided in a democratic state. To the con- trary, an array of appetites will accompany a democratic state, as its freedoms allow them to flourish. Instead, absurd appetites are chastised, as they place the peace and harmony of the state at risk. Spinoza’s call to avoid absurd appetites corresponds with his thoughts on entering a contract from the natural state, which requires agreeing to restrain each person’s appetites ‘insofar as those appetites urge something harmful to someone else’ (TTP 285). In effect, Spinoza argues for a liberal state where freedom is extended to citizens as long as they do not interfere with others. The best state will stretch this liberal principle with the aim of extending freedom.20 In it, citizens will not be held in the grip of fear, but rather hopefully live towards the future. Spinoza explains the limited role fear should have in a free state when he discusses the ultimate end of a free state in the final chapter: its ultimate end is not to dominate, restraining men by fear, and making them subject to another’s control, but on the contrary to free each person from fear, so that he can live securely, as far as possible, i.e., so that he retains to the utmost his natural right to exist and operate without harm to himself or anyone else. (TTP 346) In addition to a free state not relying on fear as a form of restraint, it should also aim to free each person from fear. Since living beyond hope and fear is not possible for 20 Spinoza’s arguments for liberal like principles do not amount to him being a liberal in a com- prehensive sense. Other parts of his political thought do not fit a liberal mold.\nmost, and on the whole politically undesirable when individually attained, hope should instead flourish in a free state.21 Democracy facilitates a hopeful posture as it approaches ‘most nearly the freedom nature concedes to everyone’ (TTP 289). It fosters an envi- ronment where citizens hopefully look towards the future in their private and public lives.22 In public life democratic procedures allow hope to be maintained for both those who support and oppose decisions reached in common. In a democracy it is ‘agreed that the measure which had the most votes would have the force of a decree, but that meanwhile they’d retain the authority to repeal these decrees when they saw better ones’ (TTP 351). Democratic procedures do not solely reserve hope for citizens who agree with decisions reached in common, they also facilitate a hopeful posture for those that disagree with those decisions. In this way, democratic sovereignty approaches the sovereign right each individual has in a natural state. After all, it is only in a democracy where ‘no one so transfers his natural right to another that in the future there is no consultation with him’ (TTP 289). Consequently, if a citizen believes he has a better alternative to the current laws, he can remain hopeful that the laws might change in the future. Notice how this is different from other regimes that preclude the people from rule. In those regimes, if you disagree with a certain law you can grudgingly go along with the ruling power or you might revolt against the ruling authority. There is little else you can effectively accomplish considering you hold no political power to do otherwise.\nInstead of hope, frustration and fear of the unknown have a greater likelihood to be the norm in non-democratic regimes. Feeling powerless to alter the present and future, it is unsurprising that those living in non-democratic regimes would turn to otherworldly sources of hope.\nIn private life democratic freedoms allow citizens to look hopefully towards a future they fashion. The hope accompanying democratic freedom is not limited to its proce- dural means of instituting laws, in other words, but extends to the sphere of liberty it allows in private life. The liberty granted in a democracy, after all, is the greatest among regime types. As noted above, it is ‘the most natural’ in that it approximates the free- dom found in the natural state. Consequently, in a democracy individuals should be ‘so governed that they can openly hold different and contrary opinions, and still live in harmony’ (TTP 351). Formally allowing freedom of judgment without achieving har- monious living among a diversity of views and ways of life, in other words, falls short of 21 ‘So, because those who neither fear nor hope for anything are to that extent their [5] own mas- ters (by ii, 10), they are (by ii, 14) enemies of the state, whom it may rightly restrain.’ (PT 520-21).\n22 Parts of what follows are echoed in Vergaray 2019.\nthe democratic ideal.23 Hence, the reliance on laws to restrain behavior should be kept to a minimum. As Spinoza reminds, ‘Anyone who wants to limit everything by laws will provoke more vices than he’ll correct’ (TTP 348).24 Hence the extensive freedoms found in a democratic state generate hopes regarding private pursuits. Just as having a say in how you are ruled in public life provides citizens hope, having liberty to choose to think, speak, and behave in diverse ways facilitates hope in everyday life.\nBoth public and private democratic hopes generate forms of constructive uncer- tainty. The form of uncertainty sustained in public life keeps citizens from feeling des- pair at the current order of things, and thus facilitates political stability over time. In private life the hope generated by the freedoms found in a democracy allows citizens to seek their own advantage, which Spinoza calls ‘the mainstay and life of all human actions’ (TTP 315). That is to say, democratic freedoms appeal to individual self-in- terest by allowing individuals the space to flourish as they choose. That freedom, in turn, creates a salutary hope as it generates gratitude for the regime that makes those freedoms possible. That gratitude creates a loyalty to the state that, as we will see below, is necessary for political stability. More broadly, both kinds of democratic hope (con- structive uncertainties) keep citizens’ gaze oriented towards a better future. That orien- tation, in turn, helps temper the human inclination to follow the passions to the neglect of future goods. Instead, democratic hope creates an environment where the active affect of joy is likely to flourish, allowing the intellectual virtues to multiply, which in turn leads to the advancement of the arts and sciences (TTP 349).\nWhile the constructive forms of uncertainty found in a democracy facilitate human flourishing and support political and social stability, they are insufficient to temper the fear driven uncertainties that generate the worst forms of superstition. Consider that a hope-filled society cannot be maintained in perpetuity. Democracy may facilitate a hope-filled society, but fear, its ugly partner, is never far behind. When fear overtakes a democratic society, it opens itself to the worse forms of superstition that place political stability in peril. Given the multiplicity of beliefs and ways of life allowed in a democ- racy, illiberal hopes can rise to the surface when individuals or collectives are in the grip of fear. Moderate religious or secular beliefs can become extreme when they are used to deal with fearful uncertainty about the future. In short, it would seem Spinoza’s de- mocracy could easily revert to the world of religious conflict Spinoza tried to overcome.\n23 ‘The end of the Republic, I say, is not to change men from rational beings into beasts or autom- ata, but to enable their minds and bodies to perform their functions safely, to enable them to use their reason freely, and not to clash with one another in hatred, anger or deception, or deal inequitably with one another. So the end of the Republic is really freedom.’ (TTP 346) 24 For example, laws cannot effectively prohibit ‘extravagant living, envy, greed, drunkenness, and the like.’ (TTP 348) Another problem is the tendency to move towards a wholly private life at times of peace and stability. That is to say, what is to keep citizens from ignoring the public good when peace and stability can make the pursuit of private goods seem like an end in itself? This tendency towards private life can weaken public spiritedness and thereby leave the state unprepared to defend itself in moments of crisis. It can also weaken any sense of unity opening the state up to internal conflict that inflames superstitious beliefs.\nIn sum, the constructive hope-filled uncertainties unleashed in a democracy are insuf- ficient to deal with the conditions that generate the destructive uncertainties underlying superstition.\nIn order for the hope-filled uncertainties in a democracy to not devolve into a haven for superstitions, Spinoza argues that devotion to the state is necessary to create citizens that place loyalty to the state above their private interests. In the strongest terms, Spi- noza notes: ‘It’s certain that piety toward a person’s country is the supreme piety he can render’ (TTP 336).25 This claim must have startled his theologically minded contem- poraries. After all, supreme piety, from a monotheistic perspective, should be rendered to God alone. Yet, Spinoza insists that the preservation of the state needs to be at the center of people’s pious devotion. After all, he notes, ‘if the state is destroyed, nothing good can remain, but everything is at risk.’ In a democracy devotion to the state takes the form of devotion to freedom. Devotion to freedom resonates at a visceral level as it mimics the natural right all individuals possess. In a functioning democracy, moreo- ver, the benefits of living in a free state are manifest for all to appreciate. Notice, devo- tion to freedom is groundless if it is not accompanied by devotion to the state. Devotion to the state makes free subjects recognize their dependence on the state, softening the tendencies of free regimes to make individuals believe the fantasy that they are sover- eign individuals. They implicitly recognize, in other words, that only in a state can free- dom divorced from fear be protected.\nSpinoza hoped that devotion to freedom would eventually reach a point where citi- zens would be willing to make great sacrifices in the name of the state. Spinoza illus- trates the power accompanying devotion to a free state at the end of the TTP when he claims that martyrs for freedom are worth emulating and revering.26 Also, in chapter XVII Spinoza suggests that fighting for ‘peace and freedom’ is preferable to fighting for glory. If these examples weren’t enough, Spinoza upholds the example of Manlius Tor- quatus’ execution of his son for disobeying orders as an example to be honored (TTP 25 See also, ‘Both reason and experience teach, as clearly as can be, that the preservation of the state depends chiefly on the loyalty of its subjects, on their virtue, and on their constancy of heart in carrying out commands.’ (TTP 298) 26 Honorable individuals, Spinoza claims, ‘think it…glorious to die for freedom.’ (TTP 350) 337).27 Put differently, devotion to the state creates conditions where public goods take precedence over private ones. This is not to suggest that democratic citizens will obses- sively be preoccupied with public goods. Rather, devotion to a free state will cultivate citizens who are prepared and willing to make sacrifices when the freedoms prized in the state are threatened.\nMore specifically, democrat’s willingness to fight, die, and kill for the freedoms they enjoy leads them to defend the state against enemies both internal and external.28 En- emies, in this context, refer to individuals or collectives that threaten or violate the free- doms enjoyed in the state. Democratic peoples thus become the protectors of freedom, and thereby protectors of the state. This protection inevitably involves restraining any threat to the peace that is the precondition of that freedom, including devotion to reli- gious sects that supersede that of the state. Fervent religious devotion in this context appears as madness, a threat to the freedom of all.\nIn sum, devotion to the state protects the otherwise perilous condition that can result from the uncertainties unleashed in a free state. Specifically, by encouraging the placing of public goods above private interests, it protects against the damaging effects that re- sult when fear rears its head in a democracy, as well as the democratic tendency to indulge in private life. Together with the constructive hope-filled uncertainties un- leashed in a democracy, devotion to the state creates a self-sustaining system that com- bats destructive uncertainties that create and sustain the most socially pernicious forms of superstition.\nCONCLUSION This paper has argued that according to Spinoza in the TTP, it is preferable to con- front the socially debilitating uncertainties underlying superstition through the political and social promotion of hope, a constructive form of uncertainty. Uncertainty, in other words, is not simply a destructive force but potentially a constructive force that can facilitate political stability and peace. The uncertain emotions of hope and fear are Spi- noza’s prime examples of constructive forms of uncertainty. Hope, however, is a more 27 In this context, it is worth noting the next sentence, ‘it follows that the well-being of the people is the supreme law. All laws both human and divine, must be accommodated to this.’ (TTP 337) 28 Spinoza uses the language of ‘enemies’ when he notes that individuals in a natural state are ‘permitted to regard as an enemy anyone who wants to prevent him from doing what he intends.’ (TTP 284) effective means to lead, which finds its greatest expression in a democracy. A democ- racy, after all, mirrors the type of freedom found in a natural state but with the requisite safety and stability required for living in hope rather than fear.\nI have also argued that understanding devotion to the state in the TTP is necessary for understanding Spinoza’s recommendations for combating superstition. In particu- lar, devotion combats dangerous superstitions by stabilizing its inconstant nature. The foundational beliefs and loyalties that are part and parcel of devotion help cultivate inward stability, which helps one weather outward uncertainties. It also protects the sovereign power, as it enlists obedience and loyalty to the state. In a democracy, devo- tion to freedom translates to a devotion to the state, the protector of freedom. Devotion thereby encourages patriots who are willing to defend the freedoms enjoyed in the state.\nIn addition to devotion enlisting support for the state, reason also “urges us to defend the state with all our powers” (TTP 287).\nSpinoza’s emphasis on the motivating factors of loyalty and devotion to the state follows a tradition that goes back at least to Plato’s discussion of the necessity of political myths.29 Political myths are necessary for cultivating public-spirited citizens. Without that inducement, most people would place their personal loyalties and pursuits above public matters. Reason for most, in other words, takes a backseat to the passions and thus inclines humans toward private concerns. Consequently, Spinoza notes, if all hu- mans were led by reason, there would be no need for laws (TTP 144). Perhaps human frailty requires a superstitious belief in the special status of the state in order to foster political and social stability.30 Spinoza is silent on this matter.\nREFERENCES Carlisle, C. 2021. Spinoza’s Religion; A Reading of the Ethics. Princeton: Princeton University Press.\n29 See chapter 5 in Michael LeBuffe’s (2018) comments on the problems and benefits of using Plato’s noble lie when thinking about Spinoza. What I offer here is suggestive, not exhaustive.\n30 James (2006) observes that “the encouragement of devotion cannot be neatly separated from the production of superstition, nor is it clear that the first is invariably fruitful and the second destructive” (17). See also Curley’s thoughts on superstition in “Spinoza’s Exchange with Albert Burgh.” I do not mean to suggest that devotion to the state only, or even primarily, requires myth according to Spinoza in the TTP. It is a piece of a puzzle that was partially explored in this essay.\nCurley, E. 1990. “Notes on a Neglected Masterpiece (II): The Theologico-Political Treatise as a Prolegomenon to the Ethics.” In J. A. Cover and Mark Kulstad, eds., Central Themes in Early Modern Philosophy, Indianapolis: Hackett, 109–59.\nCurley, E. 2010. “Spinoza’s Exchange with Albert Burgh.” In Y. Melamed and M.\nRosenthal, eds., Spinoza’s Theological-Political Treatise; Cambridge: Cambridge University Press, 11-28.\nHacking, I. 2006. The Emergence of Probability: A Philosophical Study of Early Ideas About Probability, Induction and Statistical Inference. Cambridge: Cambridge University Press.\nJames, S. 2021. ‘The Interdependence of Hope and Fear,’ Contemporary Political The- ory 20: 200-231.\nJames, S. 2012. Spinoza on Philosophy, Religion, and Politics; The Theologico- Political Treatise. Oxford: Oxford University Press.\nJames, Susan. 2006. Spinoza on Superstition: Coming to Terms with Fear (Mededelingen Vanwege Het Spinozahuis) 88. Budel, The Netherlands: Uitgeverij Damon.\nKaminsky, G. 1990. Spinoza: La Politica de Las Pasiones. Barcelona, Spain: Gedisa.\nLeBuffe, M. 2018. Spinoza on Reason. Oxford: Oxford University Press.\nModd, D. 2002. When All Else Fails; Government as the Ultimate Risk Manager. Cam- bridge: Harvard University Press.\nNadler, S. Spinoza: A Life. Cambridge: Cambridge University Press, 2018.\nNadler, S. 2005. ‘Hope, Fear, and the Politics of Immortality.’ In Tom Sorrell and G. A.\nJ. Rogers, eds., Analytic Philosophy and History of Philosophy (Mind Association Occa- sional), New York, NY: Oxford University Press, USA. 201-217.\nPower, D. 2007. Organized Uncertainty; Designing a World of Risk Management. Ox- ford: Oxford University Press.\nSpinoza, Benedictus de. Spinoza Opera, vol. 3. Edited by Carl Gebhardt. Heidelberg: Winter.\nSpinoza, Benedictus de. (1677) 1985. The Ethics. In The Collected Works of Spinoza, vol 1, Edited and translated by Edwin Curley. Princeton, NJ: Princeton University Press.\nSpinoza, Benedictus de. (1670) 2016. Theological-Political Treatise. In The Collected Works of Spinoza, vol. 2, Edited and translated by Edwin Curley. Princeton, NJ: Princeton University Press.\nSteenbakkers, P. 2021. “Spinoza’s Life.” In Yitzhak Melamed, ed., A Companion to Spinoza, Hoboken: Wiley Blackwell, 3–14.\nSteinberg, J. 2018. Spinoza’s Political Psychology: The Taming of Fortune and Fear. Cambridge: Cambridge University Press.\nVardoulakis, D. 2020. Spinoza, the Epicurean: Authority and Utility in Materialism. Ed- inburgh: Edinburgh University Press.\nVergaray, A. 2019. ‘Thinking With Spinoza About Uncertainty Today; Preliminary Re- flections on Uncertainty in Spinoza’s Political and Social Thought,’ In Circolo 8: 119-129.\nYovel, Y. 1989. Spinoza and Other Heretics; The Marrano of Reason. Princeton: Princeton University Press.",
    "crumbs": [
      "General",
      "Constructive Forms of Uncertainty in Spinoza’s Theological Political Treatise"
    ]
  },
  {
    "objectID": "extracted/nun_study2.html#deborah-d.-danner-david-a.-s",
    "href": "extracted/nun_study2.html#deborah-d.-danner-david-a.-s",
    "title": "Positive Emotions in E",
    "section": "Deborah D. Danner, David A. S",
    "text": "Deborah D. Danner, David A. S\nUniversity\nHandwritten autobiographies from 180 Catholic n of 22 years, were scored for emotional content an inverse association was found between positive em in late life (p &lt; .001). As the quartile ranking of stepwise decrease in risk of mortality resulting in quartiles. Positive emotional content in early-life a ity 6 decades later. Underlying mechanisms of bal Longevity may be related to a variety of factors including heredity, gender, socioeconomic status, nutrition, social support, medical care, and personality and behavioral characteristics (Rob- ine, Vaupel, Jeune, & Allard, 1997). These factors might operate throughout life or at particular life stages. Recent findings from the Nun Study, a longitudinal study of older Catholic sisters, indicated that linguistic ability in early life is associated with survival in late life (Snowdon, Greiner, Kemper, Nanayakkara, & Mortimer, 1999). In that study, the idea density (proposition, information, and content) of autobiographies written at a mean age of 22 years was strongly related to survival and longevity 6 decades later. Because Deborah D. Danner and David A. Snowdon, Department of Preventive Medicine and Sanders-Brown Center on Aging, College of Medicine, University of Kentucky; Wallace V. Friesen, Sanders-Brown Center on Aging, College of Medicine, University of Kentucky.\nDavid A. Snowdon is now at the Department of Neurology and the Sanders-Brown Center on Aging, College of Medicine, University of Kentucky.\nThe study was funded by National Institute on Aging Grants R01AG09862, K04AG00553, and 5P50AG05144, and by a grant from the Kleberg Foundation.\nThis study would not have been possible without the spirited support of the members, leaders, and health care providers of the School Sisters of Notre Dame religious congregation. Archivists at each of the main con- vents were instrumental in the study. We also wish to recognize the help of Lydia Greiner in the conception of the study and Mark Desrosiers for his valuable scientific and programming assistance. Other staff members of the Nun Study who provided invaluable assistance on this project include Danice Creager, Gari-Anne Patzwald, Jeanne Ray, and Mary Roycraft.\nMore information on the Nun Study may be obtained at http://www.\nnunstudy.org.\nCorrespondence concerning this article should be addressed to Deborah D. Danner, Sanders-Brown Center on Aging, University of Kentucky, 800 South Limestone, Lexington, Kentucky 40536-0230. Electronic mail may be sent to dddann00@uky.edu.\nJournal of Personality and Social Psyc Copyright 2001 by the American Psychological Association, I # rly Life and Longevity:"
  },
  {
    "objectID": "extracted/nun_study2.html#owdon-and-wallace-v.-friesen",
    "href": "extracted/nun_study2.html#owdon-and-wallace-v.-friesen",
    "title": "Positive Emotions in E",
    "section": "owdon, and Wallace V. Friesen",
    "text": "owdon, and Wallace V. Friesen\nf Kentucky\nns, composed when participants were a mean age related to survival during ages 75 to 95. A strong tional content in these writings and risk of mortality ositive emotion in early life increased, there was a 2.5-fold difference between the lowest and highest tobiographies was strongly associated with longev- nced emotional states are discussed.\nthe autobiographies appeared to contain emotional content that might be associated with idea density (Snowdon et al., 1996), we investigated the relationship between emotional content in these early life writings and survival in late life.\nA growing body of literature has shown positive and negative emotion-related attitudes and states to be associated with physical health, mental health, and longevity. For example, in a longitudinal study of Harvard graduates, Peterson (Peterson, Seligman, & Vail- lant, 1988) found the ways in which young men explained bad events predicted health outcome decades later. Such studies appear to be based on assumptions that emotion-based constructs reflect patterns of coping with negative life events and stresses that can be harmful or beneficial to health. The assumptions of the current longitudinal investigation of emotions and longevity are very similar and evolved from what is known about the underlying relationships among emotion, temperament, and physiology that might influence longevity. This study builds on the knowledge that there are universal, patterned emotional responses that affect phys- iology in ways that are potentially damaging or beneficial.\nOver the past 30 years, emotion researchers have identified basic emotions such as happiness, sadness, anger, fear, and disgust (Ekman & Friesen, 1969). More recently, these basic emotions have been associated with differentially patterned autonomic nervous system (ANS) responses (Ekman, Levenson, & Friesen, 1983; Levenson, Carstensen, Friesen, & Ekman, 1991; Levenson, Ekman, & Friesen, 1990; Levenson, Ekman, Heider, & Friesen, 1992). The functional characteristics of the associated patterns of emotion and ANS activation (Levenson, in press) strongly suggest the potential for a lifelong pattern of emotional arousal affecting health and longevity. Furthermore, numerous studies have shown that complex emotional states, such as anxiety, produce elements of ANS patterns associated with specific negative emotions (Laza- rus, 1991). These same elements of elevated galvanic skin re- sponse, heart rate, and blood pressure are found in the patterned ology, 2001, Vol. 80, No. 5, 804-813 c. 0022-35I4/01/$5.00 DO): 10.1037//0022-3514.80.5.804 ANS responses to the arousal of basic emotions and potentially could affect health and longevity.\nLaboratory research also has found that the suppression of emotional states can exacerbate ANS responses (Gross & Leven- son, 1997). A lifelong pattern of suppressing the expression of emotion has the potential for adverse effects on essential body systems. Although no ANS pattern has been found to be associated with positive emotion that differentiates it from baseline (Leven- son et al., 1990), studies have demonstrated the potential muting effects of positive emotion on the bodily responses to negative emotion (Fredrickson & Levenson, 1998). This healing effect of positive emotion may have the potential to reduce stress on the cardiovascular system even in the face of inevitable negative life events. In other words, constructs such as optimism and positive attitude may imply the following sequence: Events arousing neg- ative affect are approached with confidence that the future holds something positive and better, thus internally generating a positive emotional state that mutes the adverse effects of the prolonged arousal of a negative emotion.\nThe basic research of Fredrickson, Gross, and Levenson cited above has laid the groundwork for the study of how sustained and repetitious patterns of emotional arousal might relate to physical health and survival and, more specifically, how the emotion sys- tem is intimately tied to the ANS, which activates cardiovascular responses that could have cumulative adverse or salutary effects on health (Krantz & Manuck, 1984). What is needed is an explanation for why a particular pattern of emotional and ANS responses would be repeated with sufficient frequency to produce such cumulative effects. As part of this explanation, it is necessary to examine the relationship among patterns of emotional responsive- ness, temperament, and the development of personality.\nTemperament, the biologically based propensity for individuals to respond to events in particular ways, is considered by some theorists to contribute to the development of personality (Izard, Libero, Putnam, & Haynes, 1993; Malatesta & Wilson, 1988).\nMoreover, temperament is proposed to reflect the degree to which emotions are generally expressed, as well as the differing frequen- cies with which specific emotions or patterns of emotions are displayed or suppressed (Izard et al., 1993). Early and continuing styles of emotional expression are proposed to constitute some characteristics of personality (Izard et al., 1993; Malatesta & Wilson, 1988). Supporting this line of reasoning, work by Headey (Headey & Wearing, 1992) suggests that individuals maintain levels of positive or negative affect that are determined by their personalities and that after emotional arousal or stress these levels return to individual baselines (Diener, 2000). When an individual’s response pattern is frequent or sustained negative emotional arousal with slow return to a tranquil baseline, the autonomic response could prompt cardiovascular activity that accelerates disease mechanisms such as atherosclerosis. In contrast, a pattern of relatively infrequent negative emotional arousal or one that rapidly returns to a calm baseline following negative arousal could have beneficial effects on health.\nSuch a balance of emotional states, either by avoiding suppres- sion of the expression of aroused emotion or by readily resolving negative arousal, is compatible with Vaillant’s proposal that ma- ture defenses work to promote a positive psychology that enhances the ability to work, love, and play (Vaillant, 2000). Vaillant provided evidence that earlier life manifestations of mature ego defenses that balance and attenuate multiple sources of conflict predict enhanced physical and mental health 20 years later and suggests that mature ego defenses may reflect inborn traits. If so, Vaillant’s proposition may offer yet another pathway for how potentially beneficial or harmful patterns of emotional responses may be expressed and balanced and may be mediated through patterns of problem solving throughout a lifetime, thereby influ- encing longevity.\nA pattern of emotional arousal and temperament may be dis- closed, in part, by the written expression of language. Research by Pennebaker and his colleagues has used written language as a means of understanding how emotion influences both physical and psychological health (Hughes, Uhlmann, & Pennebaker, 1994; Pennebaker, 1993; Pennebaker & King, 1999). The early-life au- tobiographies in our study afford another opportunity to examine emotional content in written language and its relationship to health. If the use of emotional content in these writings reflects reactions to inevitable stressful life events, then these writings may reveal characteristic responses to intense or sustained arousal that produces allostatic load—indicators of physiological response to stress (McEwen, 1998; Singer & Ryff, 1999; Sterling & Eyer, 1988). Furthermore, if the use of positive and negative emotional content in writing reflects a general readiness to express emotion, then these writings may indicate a pattern that avoids the adverse effects of suppressing the expression of emotions. On the other hand, if the use of positive emotional content in writing reflects a readiness to resolve negative arousal, then writings may be reveal- ing a pattern of balance in emotional response indicating allostasis, adaption to change while maintaining physiological systems within a normal range (Singer & Ryff, 1999; Sterling & Eyer, 1988; McEwen, 1998). Both the avoidance of suppression and the positive resolution of life’s stresses could have beneficial effects on health and longevity.\nSeligman emphasizes that an insightful, positive attitude in dealing with life events, an optimistic explanatory style in contrast to a pessimistic one, can lead to greater feelings of well-being and perhaps even to longer life (Seligman, 2000). In support, a recent study found optimism, as measured by a new optimism-pessimism scale of the Minnesota Multiphasic Personality Inventory (Swen- son, Pearson, & Osborne, 1973), was associated with a lower risk of death in 839 Mayo Clinic patients observed over a 30-year period (Maruta, Colligan, Malinchoc, & Offord, 2000). However, in another long-term study of more than a thousand bright Cali- fornia school children, cheerfulness (i.e., parental judgments of optimism and a sense of humor) had an inverse relationship with longevity during middle and old age (Friedman, 1999). In the latter study, the cheerful participants also were found to be more likely to engage in activities known to be risk factors for mortality. On the other hand, in another analysis of the California data, Peterson and colleagues used the Content Analysis of Verbatim Explana- tions technique (Peterson, Seligman, Yurko, Martin, & Friedman, 1998) to code questionnaires completed by the participants in early adulthood and found evidence of a negative relationship between pessimism and longevity.\nThe early-life autobiographies and mortality data available for participants in the Nun Study offer a unique opportunity to inves- tigate the possible association of written emotional expression to longevity. Participants in our study had the same reproductive and marital histories, had similar social activities and support, did not smoke or drink excessive amounts of alcohol, had similar occu- pations and socioeconomic status, and had comparable access to medical care. Therefore, even though it may be difficult to gener- alize from this unique population of Catholic sisters, many factors that confound most studies of longevity have been minimized or eliminated.\nMethod Study Population The Nun Study is a longitudinal study of aging and Alzheimer’s disease (Snowdon, 1997; Snowdon et al., 1996, 1999). Participants were members of the School Sisters of Notre Dame religious congregation who, before their retirement, lived and taught in the schools of cities and towns in the midwestern, eastern, and southern United States. In 1991 through 1993, all American School Sisters of Notre Dame born before 1917 were asked to join the Nun Study. Six hundred seventy-eight women agreed to participate in all phases of the study and gave informed written consent to allow access to their archived and active records, participate in annual assessments of cognitive and physical function, and donate their brains at death. At the first annual exam, the 678 participants were 75 to 102 years old (M = 83).\nA search of the convents’ archives revealed that the Mother Superior of the North American sisters, who resided in Milwaukee, Wisconsin, had sent a letter on September 22, 1930, requesting that each sister write an autobiography. A mix of handwritten and typed autobiographies for many of the 678 sisters in the study was found and these autobiographies became an invaluable research source. Criteria used to select autobiographies for intensive study were that the writers were born and raised in the United States and thus had the opportunity to master the English language and that the autobiographies were handwritten and therefore could be authenticated as unaltered by clerical staff.\nWe found that the number of available handwritten autobiographies was related to the convent in which the sister lived and the year she wrote her life story. A large number of autobiographies meeting criteria were found for participants from the Milwaukee, Wisconsin, and the Baltimore, Mary- land, convents who took their religious vows and formally joined the religious congregation during 1931 to 1943 (Snowdon et al., 1999). Of the 678 sisters in the Nun Study, 218 took their vows in these two convents during that time period and handwritten autobiographies were found for 180 (83%) of these participants; that is, 101 participants from the Milwau- kee, Wisconsin, convent and 79 from the Baltimore, Maryland, convent.\nThese 180 autobiographies were written some time between the ages of 18 and 32 (M = 22) depending on the age at which the sister joined the congregation. At the time of writing the autobiographies, 82% of the sisters had earned a high school diploma. By the beginning of the mortality follow-up period in 1991, 91% had earned at least a bachelors degree.\nDuring the mortality follow-up period of November 13, 1991, to Septem- ber 1, 2000, the participants ranged in age from 75 to 95 years and 76 I had died (Milwaukee sample = 43%, Baltimore sample = 42%).\nAutobiographies Beginning in 1930, each sister who took her final vows was asked to write a short sketch of [her] life. This account should not contain more than two to three hundred words and should be written on a single sheet of paper . . . include place of birth, parentage, interesting and edifying events of childhood, schools attended, influences that led to the convent, religious life, and outstanding events.\nClearly, the instructions were not intended to influence the manner in which these life events were described nor were they intended for the study of emotional content, coping styles, or patterns of reasoning. Rather, we suspect that the autobiographies may have been used in part by the convent leaders to gather information that might help to determine future educa- tional and occupational paths, as well as to provide information useful for creating obituaries.\nDespite uniformity in the events that were described, the manner in which the life facts were told in the autobiographies reflected individual style and ranged from simply stating that these life events happened and when they occurred to elaborations of the simple facts that included the emotions experienced by the writer or others involved in the life event. The following sentences, from the beginning and ending of two autobiogra- phies, demonstrate differences in emotional content: Sister 1 (low positive emotion): I was born on September 26, 1909, the eldest of seven children, five girls and two boys …. My candidate year was spent in the Motherhouse, teaching Chemistry and Second Year Latin at Notre Dame Institute. With God’s grace, I intend to do my best for our Order, for the spread of religion and for my personal sanctification.\nSister 2 (high positive emotion): God started my life off well by bestowing upon me a grace of inestimable value… . The past year which I have spent as a candidate studying at Notre Dame College has been a very happy one. Now I look forward with eager joy to receiving the Holy Habit of Our Lady and to a life of union with Love Divine.\nCoding the Autobiographies and Generating Scores The coding system used in classifying the written autobiographies was designed specifically for this study (Danner, Friesen, & Snowdon, 2000).\nAll coding and review of the autobiographies were done without knowl- edge of the health or functional status of the study participants. Two coders identified all words in thel80 autobiographies that reflected an emotional experience and classified them as positive, negative, or neutral. Later, a third coder verified each coded word for accuracy and determined the specific type of emotional experience or state referenced by each word.\nCoders were instructed on the distinctions between descriptions of possible elicitors of emotion (e.g., death of a family member), the emotion that was experienced (e.g., sadness), subsequent behaviors (e.g., crying), and attempts to control the overt expression of the emotion. They were instructed not to code descriptions of possible elicitors, but to code only words that in context described the emotion that was experienced and behaviors subsequent to emotional arousal. Further, they were instructed not to code words such as good and bad that have positive or negative connotations or might imply an emotional reaction but do not directly describe an emotional experience.\nThe coders were provided with examples of words related to the expe- rience of the positive emotions of accomplishment, amusement, content- ment, gratitude, happiness, hope, interest, love, and relief; the negative emotions of anger, contempt, disgust, disinterest, fear, sadness, and shame; and the neutral emotion of surprise. The two coders, one with a background in psychology and the other with training in education, then independently read the autobiographies. They marked words that conveyed emotion as experienced by the writer or others and classified the valence of the emotional content as positive, negative, or neutral. When necessary for comprehension, the coders were instructed to identify and code phrases rather than single words.\nTwo procedures were used to generate scores for the primary analysis on the basis of the positive, negative, and neutral scoring. The first procedure simply used the raw count of positive, negative, and neutral emotion words for each autobiography. The second procedure used these coded emotion words to classify each sentence as containing one or more positive, negative, or neutral words or as containing no emotion words. The first two columns of Table 1 show the number of positive, negative, and neutral emotional words and sentences as determined by each individual coder.\nThe table shows that the two coders identified very similar numbers of positive, negative, and neutral emotional words.\nTable 1 Reliability of the Emotion Coding as Indicated b Scored by Two Coders for Autobiographies Writ by 180 Participants in the Nun Study Count Unit of analysis and emotion Coder A Coder B Words Positive 1,243 1,242 Negative 206 192 Neutral 16 17 Sentences Positive 1,006 1,017 Negative 196 179 Neutral 16 17 Note. For all correlations, p &lt; .0001.\na 95% confidence intervals appear in parentheses.\nIn the verification phase of the coding, the words scored by the two coders were extracted from the autobiographies and a nonredundant list of words was reviewed by a third person (Wallace V. Friesen) for accuracy.\nThis review was done without knowledge of whether one or both coders had scored the word or how frequently the word was scored. Words that did not meet the original criteria for an emotional experience were removed from the list. The 1,598 words retained in the final scoring constituted 1.8% of the total words in the autobiographies and 95% of the words scored by one or both coders. Of these emotional words, 84% were classified as positive, 14% as negative, and 1% as neutral. As described above for the single coders, the verified coding of emotion words was used to determine the number of sentences with one or more positive, negative, and neutral emotion words.\nAs a part of the verification process, each unique emotion word was classified as referring to a specific type of positive or negative emotions (only one emotion, surprise, was scored in the neutral category). Initially, the purpose of the categorization was to aid in the verification of the positive, negative, and neutral scoring of Coders A and B. If a word could not be categorized, its validity as an emotion word was questionable. We carefully reviewed this categorization of the emotion words and disagree- ments were discussed and arbitrated. The final list of subcategories and the number and percentage of sentences containing one or more words in each category is presented in Table 2.\nIntercoder Reliability Two types of intercoder reliability were assessed: the overall agreement in selecting and classifying the valence of emotional words and the degree to which the coders’ scoring and the verified scoring of the autobiographies were correlated. Kappa coefficients were used to assess overall agreement between the two coders on the selection and classification of emotion words. The coefficient values were .83 and .84, .85, and .79 for all emotion, positive, negative, and neutral words respectively, indicating a satisfactory level of intercoder reliability both overall and for the individual types of emotion words. Additional analyses indicated that most differences be- tween the two coders were due to one coder identifying a word that the other failed to detect and that this occurred with similar frequencies for the two coders. Examination of these disagreements indicated that the coder who failed to code apparently simply did not see the word because the same word was identified and classified identically by the errant coder in different places in the autobiographies. In other words, had the errant coder the Number of Emotion Words and Sentences en in Early Life Correlation of counts Final coding andeach codera Coders A and Ba Coder A Coder B 96 (.95, .97) .99 (.98, .99) .98 (.98, .99) 89 (.85, .94) .97 (.94, .99) .94 (.91, .97) 78 (.64, .93) .97 (.90, 1.00) .82 (.69, .95) 97 (.96, .98) .99 (.98, .99) .99 (.98, .99) 90 (.85, .95) .97 (.96, .99) .94 (.91, .97) 78 (.64, .93) .97 (.90, 1.00) .82 (.69, .95) noticed the word when reading the autobiography, it almost certainly would have been scored in agreement with the accurate coder.\nIn addition to the kappa coefficients of agreement, each coder’s scoring and the verified scoring were used to generate positive, negative, and neutral counts for both words and sentences for each autobiography.\nCorrelations were used to test the comparability of the three sets of coding.\nThe resulting correlations are shown in the three columns on the right of Table I. It can be seen here that the correlations between Coders A and B and verified counts of the numbers of emotional words and sentences were very high, indicating that virtually identical results would have been obtained in subsequent survival analysis had either Coder A’s or Coder B’s scoring been used in place of the final verified scores.\nLinguistic Measures Recent findings from studies of the same 180 autobiographies indicated that linguistic ability in early life was associated with survival in late life (Snowdon et al., 1999). In that study, the idea density (proposition, infor- mation, and content) of these autobiographies was associated with survival and longevity 6 decades later. Idea density of the early-life autobiographies also had a strong inverse association with Alzheimer’s disease (Snowdon et al., 1996; Snowdon, Greiner, & Markesbery, 2000). Because idea-dense sentences of the autobiographies were observed to contain emotional words (Snowdon et al., 1996), idea density and grammatical complexity were used as control variables in one of the analyses in the current study. The following is a brief description of how idea density and grammatical complexity were measured.\nWithout the linguistic coders’ knowledge of the age or cognitive func- tion of each sister during late life, each autobiography was scored for two indicators of linguistic ability: idea density (Kintsch & Keenan, 1973; Turner & Greene, 1977) and grammatical complexity (Cheung & Kemper, 1992). Mean idea-density and grammatical-complexity scores were com- puted from the last ten sentences of each autobiography. Idea density was defined as the average number of ideas expressed per ten words. Ideas corresponded to elementary propositions, typically a verb, adjective, ad- verb, or prepositional phrase. Complex propositions that stated or inferred causal, temporal, or other relationships between ideas also were counted.\nGrammatical complexity was computed using the Developmental Level metric originally developed by Rosenberg and Abbeduto (Rosenberg & Abbeduto, 1987) and modified by Cheung and Kemper (1992). The De- velopmental Level metric classifies sentences according to eight levels of Table 2 Distribution of the Different Types of Emotion Sentences in the Autobiographies Written in Early Life by 180 Participants in the Nun Study No. (and %) of sentences Milwaukee Baltimore Both Type of emotion convent convent convents Positive Happiness 109(6.10) 341 (12.51) 450 (9.97) Interest 160(8.95) 281 (10.31) 441 (9.77) Love 36(2.01) 131 (4.81) 167(3.70) Hope 21 (1.17) 30(1.10) 51(1.13) Gratefulness 6 (0.34) 41 (1.50) 47(1.04) Contentment 19(1.06) 21 (0.77) 40 (0.89) Unspecified 11(0.62) 14(0.51) 25 (0.55) Accomplishment 7 (0.39) 15(0.55) 22 (0.49) Relief 2(0.11) 4(0.15) 6(0.13) Amusement 0 (0.00) 1 (0.04) 1 (0.02) Negative Unspecified 19(1.06) 36(1.32) 55 (1.22) Sadness 8 (0.45) 46(1.69) 54(1.20) Afraid 4 (0.22) 18(0.66) 22 (0.49) Disinterest 7 (0.39) 13 (0.48) 20 (0.44) Confused 5 (0.28) 13 (0.48) 18(0.40) Anxiety 1 (0.06) 16(0.59) 17 (0.38) Suffering 8 (0.45) 9 (0.33) 17 (0.38) Shame 4 (0.22) 6 (0.22) 10 (0.22) Hopelessness 2(0.11) 2 (0.07) 4 (0.09) Frustration 1 (0.06) 1 (0.04) 2 (0.04) Disgust 1 (0.06) 1 (0.04) 2 (0.04) Anger 0 (0.00) 2 (0.07) 2 (0.04) Contempt 0 (0.00) 1 (0.04) 1 (0.02) Neutral Surprise 3(0.17) 14(0.51) 17 (0.38) Note. A small percentage of sentences contained more than one type of emotion word. Nonspecific positive and negative emotion words were classified as unspecified (e.g., words such as liked and filled with emotion).\nThese are words that definitely refer to an emotional experience but might refer to several different basic or complex emotional states.\ngrammatical complexity, ranging from 0 (simple one-clause sentences) to 7 (complex sentences with multiple forms of embedding and subordination).\nData Analysis The dependent variables in the analyses were simple measures of all- cause mortality such as the percent who died by the end of an approxi- mately 9-year follow-up period and the mortality rate (i.e., deaths per person-years of observation) for that same period of time. The primary multivariate method used to investigate mortality was Cox proportional hazards regression (Allison, 1995). This regression yielded the relative risk of death, which refers to the ratio of mortality rates (or, more exactly, to the ratio of hazard functions). Age was adjusted in these analyses by using age as the time scale for the regression (Allison, 1995). Educational level at the time the autobiographies were written in early life was adjusted by includ- ing it as an ordinal variable in the regression. Age- and education-adjusted survival curves (the probability of a 75-year-old surviving to different advanced ages) were created using the baseline feature of the Cox regres- sion procedure in the SAS statistical program (Allison, 1995).\nIn the regression analyses, ordinal variables were used to characterize the percentile ranking of each type of emotional expression; that is, the number of positive emotional words. Binary variables were used in the regression to characterize the quartile rankings of each type of emotional expression. These percentile and quartile rankings of emotional-word us- age were derived using the distribution within each of the two convents.\nThis was done to obtain comparable scales of emotional expression across convents because the distribution of emotion-word usage differed between convents (see Table 2). The primary analyses used three measures of emotion word usage: (a) the percentile or quartile rankings derived from the number of sentences containing one or more positive or negative emotion words or no emotion words; (b) percentile and quartile ranks derived from the simple counts of positive emotion words; and (c) percen- tile and quartile ranks of a diversity score generated by counting the number of different positive emotion categories (see Table 2) scored in each autobiography.\nResults The current study included 180 participants from the Milwau- kee, Wisconsin, and Baltimore, Maryland, convents of the School Sisters of Notre Dame. Handwritten autobiographies composed when the sisters were a mean age of 22 years were scored for positive, negative, and neutral emotional content. When these autobiographies were written in early life, 82% of the participants had earned a high school diploma. At the beginning of the Nun Study in 1991, approximately 58 years later, 91% of them had earned at least a bachelors degree. During the 9-year mortality surveillance period, the 180 participants ranged in age from 75 to 95 years and 76 (42%) of them had died (Milwaukee sample = 43%, Baltimore sample = 42%).\nCompared with the Baltimore participants, the Milwaukee par- ticipants had a lower mean number of positive emotion sentences (Milwaukee = 3.2, Baltimore = 9.7; p &lt; .001), negative emotion sentences (Milwaukee = 0.6, Baltimore = 2.0; p &lt; .001), and nonemotion sentences (Milwaukee = 14.1, Baltimore = 23.5;/? &lt; .001). (Given the very low frequency of neutral emotions, shown in Tables 1 and 2, their possible relationship to mortality was not examined.) Although the exact reasons for the differences between convents in written emotional expression is not known, the differ- ences in lengths of the autobiographies could simply reflect more time allowed for the Baltimore sisters to complete the task. Be- cause of differences in the distribution of these measures between convents, all analyses were based on percentile and quartile rank- ings within each convent.\nFour basic types of analyses were conducted and all were age and education adjusted. The first examined the relationship be- tween risk of mortality and the percentile ranking of the number of positive emotion sentences, negative emotion sentences, and non- emotion sentences in the autobiographies from early life. The second examined the relationships between the risk of mortality and the quartile ranking of the number of positive emotion sen- tences, positive emotion words, and different types of positive emotion words (i.e., categories). The third analysis examined the age-adjusted survival curves (length of life) as a function of the quartile rankings of positive-emotion sentences, positive-emotion words, and different categories of positive emotion words. A fourth analysis examined the relationships between positive emo- tion usage and survival after controlling for linguistic ability demonstrated in the early-life autobiographies, the level of educa- tion attained at the time the autobiographies were written, and the lifetime occupation of the participants.\nThe first Cox regression model we used to investigate mortality used the percentile ranking of positive emotion sentences, negative emotion sentences, or no emotion sentences and was adjusted for age and education. The results of these analyses are presented in Table 3 (Model I). Statistically significant inverse associations were found between the percentile ranking of the number of positive sentences in the early-life autobiographies and the risk of mortality in late-life within each of the convents and in both convents combined. For example, for every 1.0% increase in the number of positive-emotion sentences there was a 1.4% decrease in the mortality rate (i.e., the hazard function from the Cox regression model). In contrast, there were no statistically signifi- cant associations between the risk of mortality and the percentile rankings of the number of negative emotion sentences or the number of nonemotion sentences.\nIn another regression model that included age, education, and the percentile rankings of all three types of sentences (Model II; see Table 3), the strength of the associations with mortality were statistically unchanged from those above (Model I). Overall, the findings from these regressions suggest that positive and negative content reflected different aspects of written emotional expression.\nBecause of these findings, the remaining analyses focused on positive emotions.\nWe further explored the association between positive emotion content and survival using quartile rankings of positive emotion sentences. Both the percent who had died and the mortality rate had inverse associations with the quartile rankings of the number of positive-emotion sentences (see Table 4). Findings from age- and education-adjusted Cox regression analyses also indicated that the relative risk of death increased in a stepwise fashion as the quartile ranking of positive emotion sentences decreased, with a 2.5-fold difference in mortality between the lowest and highest quartiles of positive emotional expression. Two other methods of characterizing positive-emotion content, the number of positive- emotion words and the number of different positive emotions, also had strong inverse associations with mortality (see Table 4).\nCox regression also was used to create age- and education- adjusted survival curves, that is, probabilities of a 75-year-old surviving to different advanced ages. Figure 1 shows a strong association between the quartile rankings of the number of positive emotion sentences and survival: The median age at death was 86.6 years for those in the lowest quartile for the number of positive emotion sentences, 86.8 for the second quartile, 90.0 for the third Table 3 Percent Change in the All-Cause Mortality Rate in the Ranking of the Number of Sentences Mode Sentence type Milwaukee convent Baltimore c Positive emotion -1.4 (-2.5,-0.2)* -1.4 (-2.7,- Negative emotion -0.7 (-1.9, 0.6) -0.7 (-1.9, Noemotion 0.5 (-0.6, 1.6) -0.6 (-1.9, Note. 95% confidence intervals appear in parenthese Cox regression. Both Models I and II were adjusted for level of education achieved at the time in early life ordinal variable in both Model I and II regressions.\nincluded only one sentence-type variable, as well as a that is, it included each of the three sentence-type vari p£.05. p&lt;.01. /?&lt;. 001.\nquartile, and 93.5 for those in the highest quartile, that is, a difference of 6.9 years between the highest and lowest quartiles of positive emotion sentences. Survival curves for the other two measures of positive emotion content (not shown) indicated even stronger associations with survival; in other words, the difference in the median age at death between the highest and lowest quartiles was 9.4 years for the number of positive emotion words and 10.7 years for the number of different positive emotions.\nOther analyses indicated that there were no material changes in the association between positive emotion content and survival after controlling for measures of linguistic ability as demonstrated in the autobiographies; that is, the 2.5-fold difference in risk of mortality between the lowest and highest positive emotion sentence quartiles in Table 4 was a 2.2-fold difference in risk when adjusted for idea density. Furthermore, the relationship between positive-emotion content and survival was still apparent after limiting the analyses to 162 college-educated, lifetime teachers.\nDiscussion This study found a very strong association between positive emotional content in autobiographies written in early adulthood and longevity 6 decades later. Such a finding is congruent with other studies by investigators that have found relationships be- tween longevity and emotion-related concepts. Features of the current study differ from other studies that have investigated relationships between emotion-relevant behaviors and longevity or mortality and may account for the strength of the relationship observed in the current study: the population sample and the technique used to measure emotion.\nOur findings are compatible with recent longitudinal studies that suggest that optimism is associated with longer life (Maruta et al., 2000; Peterson et al., 1998), but incompatible with another study indicating that cheerfulness measured in early life was not asso- ciated with longer survival (Friedman, 1999). In the latter study, the investigators reported that there were behaviors related to risk and substance abuse in late-life activities of the more cheerful participants that may account for their findings (Friedman, 1999).\nThese types of behaviors should be less of an issue in our study of Catholic sisters given the relative homogeneity of their adult lifestyles and environments.\nPer Single Percentile Change I Model II, both nvent Both convents convents 0.1)* -1.4 (-2.3,-0.6)*** -1.4 (-2.3,-0.5)** .6) -0.7 (-1.5, 0.2) -0.2 (-1.2, 0.8) .7) -0.1 (-0.9,0.7) 0.3 (-0.6, 1.2) . The mortality rate refers to the hazard function from age by using age as the time scale in the regression. The hen the autobiography was written was included as an hree regressions were used for Model I, that is, each e and education. One regression was used in Model II, bles, as well as age and education.\nTable 4 Positive Emotion Expression in Autobiographies Written in Early in Late Life for 180 Participants in the Nun Study No. of participants Categories and quartiles Age at follow-up Dead At-risk Positive emotion sentences I (low) 80.1 25 46 II 81.1 23 40 III 80.1 18 52 IV (high) 79.4 10 42 Positive emotion words I (low) 79.9 23 42 II 81.1 30 51 III 79.7 13 40 IV (high) 79.9 10 47 Different positive emotions I (low) 81.3 11 17 II 80.4 26 58 III 80.2 29 65 IV (high) 79.4 10 40 Note. CI = confidence interval. The relative risks were adjusted for age regression analyses, and the level of education achieved at the time in early in regressions). The quartiles are not equal size groups because of the distrib sentences, and different positive emotions refer to up to 10 different types ” In person-years. b Deaths per 100 person-years.\n*/7&lt;.05. **/&gt;&lt;.01.\nThere were, however, other important differences between the studies of Maruta et al. (2000), Peterson et al. (1988), and Fried- man (1999) and the current study in addition to the sample pop- ulations. Maruta used items from the first Minnesota Multiphasic Personality Inventory to develop a scale of optimism. Peterson measured globality of explanatory style (a tendency to ascribe a single cause across negative life events) in samples of writing.\nFriedman, studying the same population as Peterson, used parental reports of children’s degree of cheerfulness as a measure of pos- itive affect. Thus, there were notable differences in the sources of information and the constructs that were measured as predictor variables in previous research. The current study used a different source of data and an emotion-specific measurement technique.\nGiven the unique lifestyle and culture of our study population of Catholic sisters and the fact that the autobiographies were written 6 decades ago, we created a coding system appropriate for this sample of writings. It has face validity and good reliability. Based on knowledge of emotion research and theory, it was designed to identify positive and negative emotional content in writings and requires little or no inference to apply. However, such coding does not attempt to measure more complex reactions to life events such as long-term positive or negative attitudes, forward thinking, types of explanatory style, mature ego defenses, pessimism, or opti- mism. Further research is required to discover how the use of emotion words in written text is related to other constructs that have been found to be related to better health and longevity.\nAlthough the scoring tool used in this study was designed to measure both positive and negative emotion, the emotional content of the writings describing the early lives of the participants in our study was overwhelmingly positive. This finding does not differ substantially from what other research studies using similar mea- ife and the Risk of All-Cause Mortality Relative risk of mortality Survival” % died Mortality rateb (and 95% CI) 253.3 54 10 2.5(1.2,5.3)** 221.8 58 10 2.4(1.1,5.2)* 333.4 35 5 1.4(0.6,3.0) 296.9 24 3 1.0 233.0 55 10 3.2(1.5,6.8) 279.5 59 11 3.1 (1.5,6.4) 255.6 33 5 1.6(0.7,3.7) 337.3 21 3 1.0 91.0 65 12 4.3(1.7, 10.4)** 331.0 45 8 2.3(1.1,4.7) 388.0 45 7 2.2(1.1,4.6) 295.5 25 3 1.0 d education (i.e., age was adjusted by using it as the time scale in the Cox life when the autobiography was written was included as an ordinal variable tion of the variables. Positive emotion sentences refer to the number of such f positive emotions.\nsurement tools have found (Pennebaker & Francis, 1999). More- over, an examination of cross-cultural and developmental data for 13 cultures by Boucher and Osgood (1969) found a universal tendency to learn positive words earlier than negative words in the acquisition of language, to more readily retain positive words in tests of memory, and to use more positive than negative words when communicating.\nContextual factors also may have influenced the use of positive emotion words in this set of writings. For example, the Catholic sisters in our study may have been aware, or at least believed, that the content of the autobiographies would be used by their superiors to determine their careers in the religious congregation, and there- fore they may have been cautious about revealing memories of negative emotion. Even more likely to have influenced the tone of these autobiographies was that they were written during a period of time when the sisters would be expected to feel happy and positive about the future; namely, when they were about to leave the convent and begin working (mainly teaching) in the community.\nHaving completed years of study and preparation for entry into the religious order, the sisters wrote these autobiographies just prior to taking their final vows. A goal toward which they had worked was being realized. Yet, despite the forces that may have resulted in predominantly positive content that was relatively constant for all of the authors of the autobiographies, there were individual dif- ferences in the use of positive emotion words that predicted longevity.\nBecause there was relatively little negative emotional content in the autobiographies, it was not possible to address directly ques- tions related to the underlying mechanisms responsible for the current findings. Whether a generalized suppression of emotional expressiveness presented a risk factor for longevity (Gross & 1.0 0.9 0.8 m 0.7 iivrjytilibbor 0.6 0) “5 0.5 0.4 n Quartile 1 0.3 Quartile 2 a.\nQuartile 3 0.2 Quartile 4 0.1 0.0 75 80 Figure 1. Quartile rankings of the number of positive and the probability of survival in late life for 180 parti for Quartiles 1 and 2 are virtually overlaid on each ot Levenson, 1997), or, conversely, whether those persons using more positive emotion words were in fact more expressive of all emotions and thereby reduced allostatic load by avoiding the detrimental effects of suppression could not be tested. Although negative life events were sometimes mentioned in the autobiogra- phies, the participants had not been instructed to include such events or to elaborate on their resolution. The absence of negative emotion words in relating negative incidents did not allow a direct test of whether positive emotion might have been a factor in muting the adverse effects of negative emotional arousal (Fredrickson & Levenson, 1998). Finally, the relative absence of negative emotional content limited the statistical power to detect associations with mortality. However, the analysis that we could perform indicated that in this context written negative emotional content is not the opposite of positive emotional content but, rather, is a reflection of something different. This finding that positive emotion may be a different phenomenon from negative emotion (depression) also was reported by Ostir and colleagues (Ostir, Markides, Black, & Goodwin, 2000).\nOur investigation raises questions about why the positive emo- tional content in early-life writings might have such a powerful relationship to longevity. Unfortunately we had no independent measures of temperament, personality, or emotional tendencies for participants, and we can only speculate that individual differences in emotional content in the autobiographies reflect life-long pat- terns of emotional response to life events.\nA pattern of emotional expression that accentuates positive affect undoubtedly has behavioral correlates that could enhance or disrupt the positive effects on physiology and health. One behav- ioral pathway is suggested by the study by Friedman (1999) in 85 90 95 ge motion sentences in autobiographies written in early life ipants in the Nun Study. (Note that the survival curves er.) which cheerful participants were more likely to engage in behav- iors that are health risks such as excessive drinking and smoking.\nSuch a pathway would be expected to disrupt the potential phys- iological benefits of a pervading pattern of positive emotional responsiveness. In contrast, all participants in the current study had lived a lifestyle in which such health-risk behaviors were improb- able and therefore the physiological impact of a positive emotional style was almost certainly enhanced. Because many alternative paths that might be the consequence of a positive style were not a part of this study, generalization of the current findings is limited.\nMany of the limitations of our study also could be considered strengths. As mentioned earlier, participants in our study were all female, had the same reproductive and marital histories, had sim- ilar social activities and support, did not smoke or drink excessive amounts of alcohol, had virtually the same occupation and socio- economic status, and had comparable access to medical care.\nFurthermore, the 180 participants had successfully completed a lifetime within their careers and living situations and many had lived beyond average life expectancy for their generation by the time they were enrolled in this study. Although it may be difficult to generalize from this unique population of Catholic sisters, the findings of the study should not be minimized. Despite factors in these sisters’ lives that are known to extend life and that might have overwhelmed any contribution of the mechanisms underlying our findings, the phenomenon represented by the use of positive emotion words in early-life writings effectively added to longevity.\nIt could be argued that the results of this study may not apply to a sample of participants less than 75 years of age. We are in the process of searching the convent archives for the autobiographies of sisters who died prior to the beginning of the study and in particular those who died before age 75. This information will allow us to examine the possibility that what was found in this study was the late stages of a relationship between the use of positive emotion words and longevity that was evident years earlier. Furthermore, increasing the sample size will increase the statistical power of future analyses and allow the investigation of relationships between survival and different types of positive emo- tional words, such as interest, love, and hope. Finally, our contin- ued follow-up of the population will allow us to determine whether this association continues beyond age 95.\nFinding such a strong association of written positive emotional expression to longevity indicates a need for research that sheds light on the underlying mechanisms and mediators responsible for and associated with this relationship. Within the context of the Nun Study, evidence that the expressive patterns observed in the early- life autobiographies were stable over time would help substantiate a relationship between emotional expression and temperament and personality. In future research, we will study late-life writings and spoken speech samples from the sisters for consistency of the expressive patterns found in early life.\nArchived records of medical history and career path will be examined for evidence of social and health-related patterns asso- ciated with what has been observed in the autobiographical writ- ings and that might suggest pathways taken by participants differ- ing in their use of positive emotional words that might have contributed to their longevity or mortality. Considering the poten- tial impact of positive expressiveness on relationships, we feel that research is needed to examine possible differences in social and professional behaviors that may have amplified the effects of a positive style on longevity.\nGiven that there have been annual examinations of cognitive and physical functioning, it will be possible to study relationships between the emotional content of the early-life writings and late- life capacities. Also, the results of neurological examinations will allow study of relationships with neurological functioning and related disease and disability. Finally, because there will be brain autopsies on all participants, it will be possible to study relation- ships between written emotional expressions and neuropathology and brain structure. These future studies hold promise for identi- fying underlying mechanisms and mediators that may account for the findings of the current study.\nReferences Allison, P. D. (1995). Survival analysis using the SAS system: A practical guide. Cary, NC: SAS Institute.\nBoucher, J., & Osgood, C. E. (1969). The Pollyanna Hypothesis. Journal of Verbal Learning and Verbal Behavior, 8, 1-8.\nCheung, H., & Kemper, S. (1992). Competing complexity metrics and adults’ production of complex sentences. Applied Psycholinguistics, 13, 53-76.\nDanner, D. D., Friesen, W. V., & Snowdon, D. A. (2000). Written emotion expression code. Unpublished manuscript, University of Kentucky, Lex- ington.\nDiener, E. (2000). Subjective well-being: The science of happiness and a proposal for a national index. American Psychologist, 55, 34-43.\nEkman, P., & Friesen, W. V. (1969). The repertoire of nonverbal behavior: Cite%OTO4, CK%,, \\4Age,, ra& eoAmg. Semiotica, ], 49-9%.\nEkman, P., Levenson, R. W., & Friesen, W. V. (1983). Autonomic nervous system activity distinguishes among emotions. Science, 221, 1208- 1210.\nFredrickson, B. L., & Levenson, R. W. (1998). Positive emotions speed recovery from the cardiovascular sequelae of negative emotions. Cog- nition and Emotion, 12, 191-220.\nFriedman, H. S. (1999). Personality and longevity: Paradoxes. In J. -M.\nRobine, B. Forette, C. Franceschi, & M. Allard (Eds.), The paradoxes of longevity (pp. 115-122). Berlin, Germany: Springer-Verlag.\nGross, J. J., & Levenson, R. W. (1997). Hiding feelings: The acute effects of inhibiting negative and positive emotion. Journal of Abnormal Psy- chology, 106, 95-103.\nHeadey, B., & Wearing, A. J. (1992). Understanding happiness: A theory of subjective well-being. Melbourne, Australia: Longman Cheshire.\nHughes, C. F., Uhlmann, C, & Pennebaker, J. W. (1994). The body’s response to processing emotional trauma: Linking verbal text with autonomic activity. Journal of Personality, 62, 565-585.\nIzard, C. E., Libero, D. Z., Putnam, P., & Haynes, O. M. (1993). Stability of emotion experiences and their relations to traits of personality. Jour- nal of Personality and Social Psychology, 64, 847- 860.\nKintsch, W., & Keenan, J. (1973). Reading rate and retention as a function of the number of propositions in the base structure of sentences. Cog- nitive Psychology, 5, 257-274.\nKrantz, D. S., & Manuck, S. B. (1984). Acute psychophysiologic reactivity and risk of cardiovascular disease: A review and methodologic critique.\nPsychological Bulletin, 96, 435-464.\nLazarus, R. S. (1991). Emotion and adaptation. New York: Oxford Uni- versity Press.\nLevenson, R. W. (in press). Autonomic specificity and emotion. In R. J.\nDavidson, K. Scherer, & H. H. Goldsmith (Eds.), Handbook of affective sciences. New York: Oxford University Press.\nLevenson, R. W., Carstensen, L. L., Friesen, W. V., & Ekman, P. (1991).\nEmotion, physiology, and expression in old age. Psychology and Aging, 6, 28-35.\nLevenson, R. W., Ekman, P., & Friesen, W. V. (1990). Voluntary facial action generates emotion-specific autonomic nervous system activity.\nPsychophysiology, 27, 363-384.\nLevenson, R. W., Ekman, P., Heider, K., & Friesen, W. V. (1992). Emotion and autonomic nervous system activity in the Minangkabau of West Sumatra. Journal of Personality and Social Psychology, 62, 972-988.\nMalatesta, C. Z., & Wilson, A. (1988). Emotion cognition interaction in personality development: A discrete emotions, functionalist analysis.\nBritish Journal of Social Psychology, 27, 91-112.\nMaruta, T., Colligan, R. C, Malinchoc, M., & Offord, K. P. (2000).\nOptimists vs pessimists: Survival rate among medical patients over a 30-year period. Mayo Clinic Proceedings, 75, 140-143.\nMcEwen, B. S. (1998). Stress, adaptation, and disease: Allostasis and allostatic load. Annals of the New York Academy of Sciences, 840, 33-44.\nOstir, G. V., Markides, K. S., Black, S. A., & Goodwin, J. S. (2000).\nEmotional well-being predicts subsequent functional independence and survival. Journal of the American Geriatrics Society, 48, 473-478.\nPennebaker, J. W. (1993). Putting stress into words: Health, linguistic and therapeutic implications. Behaviour Research and Therapy, 31, 539- 548.\nPennebaker, J. W., & Francis, M. E. (1999). Linguistic Inquiry and Word Count (LIWC). Mahwah, NJ: LEA Software and Alternative Media/ Erlbaum.\nPennebaker, J. W., & King, L. A. (1999). Linguistic styles: Language use as an individual difference. Journal of Personality and Social Psychol- ogy, 77, 1296-1312.\nPeterson, C, Seligman, M. E. P., & Vaillant, G. E. (1988). Pessimistic e*psty« a risk factor fox pYi^sVcaX fflness-. A ftnrty-fwe year longitudinal study. Journal of Personality and Social Psychology, 55, 23-27.\nPeterson, C, Seligman, M. E. P., Yurko, K. H., Martin, L. R., & Friedman, H. S. (1998). Catastrophizing and untimely death. Psychological Sci- ence, 9, 127-130.\nRobine, J. -M, Vaupel, J. W., Jeune, B., & Allard, M. (1997). Longevity: To the limits and beyond. Berlin, Germany: Springer-Verlag.\nRosenberg, S., & Abbeduto, L. (1987). Indicators of linguistic competence in the peer group conversational behavior of mildly retarded adults.\nApplied Psycholinguistics, 8, 19-32.\nSeligman, M. E. P. (2000). Optimism, pessimism, and mortality. Mayo Clinic Proceedings, 75, 133-134.\nSinger, B., & Ryff, C. D. (1999). Hierarchies of life histories and associ- ated health risks. Annals of the New York Academy of Sciences, 896, 96-115.\nSnowdon, D. A. (1997). Aging and Alzheimer’s disease: Lessons from the Nun Study. Gerontologist, 37, 150-156.\nSnowdon, D. A., Greiner, L. H., Kemper, S. J., Nanayakkara, N., & Mortimer, J. A. (1999). Linguistic ability in early life and longevity: Findings from the Nun Study. In J. -M. Robine, B. Forette, C. Franches- chi, & M. Allard (Eds.), The paradoxes of longevity (pp. 103-113).\nBerlin, Germany: Springer-Verlag.\nSnowdon, D. A., Greiner, L. H., & Markesbery, W. R. (2000). Linguistic ability in early life and the neuropathology of Alzheimer’s disease and ## Low Publication Prices for\nKeeping you up-to-date. All APA Fello\nreceive—as part of their annual dues—sub APA Monitor. High School Teacher and In the APA Monitor, and they may subscribe t reduced rate. In addition, all Members and to 60% (plus a journal credit) on all other A subscriptions from cooperating societies and Counseling and Development, Academic Pr Essential resources. APA members and APA books, including the Publication Manu and on dozens of new topical books each y Other benefits Of membership. Mem competitive insurance plans, continuing edu and specialty divisions.\nMore information. Write to American Psy 750 First Street, NE, Washington, DC 2000 cerebrovascular disease: Findings from the Nun Study. Annals of the New York Academy of Sciences, 903, 34-38.\nSnowdon, D. A., Kemper, S. J., Mortimer, J. A., Greiner, L. H., Wekstein, D. R., & Markesbery, W. R. (1996). Linguistic ability in early life and cognitive function and Alzheimer’s disease in late life: Findings from the Nun Study. Journal of the American Medical Association, 275, 528-532.\nSterling, P., & Eyer, J. (1988). Allostasis: A new paradigm to explain arousal pathology. In S. Fisher & J. Reason (Eds.), Handbook of life stress, cognition, and health (pp. 629-649). New York: Wiley.\nSwenson, W. M., Pearson, J. S., & Osborne, D. (1973). An MMPI source book: Basic item, scale, and pattern data on 50,000 medical patients.\nMinneapolis: University of Minnesota Press.\nTurner, A., & Greene, E. (1977). The construction and use of a proposi- tional text base. Boulder: Institute for the Study of Intellectual Behavior, University of Colorado.\nVaillant, G. E. (2000). Adaptive mental mechanisms: Their role in a positive psychology. American Psychologist, 55, 89-98.\nReceived October 6, 2000 Accepted October 30, 2000 • ## PA Members and Affiliates\ns, Members, Associates, and Student Affiliates\ncriptions to the American Psychologist and ernational Affiliates receive subscriptions to the American Psychologist at a significantly tudent Affiliates are eligible for savings of up A journals, as well as significant discounts on publishers (e.g., the American Association for ss, and Human Sciences Press).\nffiliates receive special rates for purchases of l of the American Psychological Association, ar.\nership in APA also provides eligibility for ation programs, reduced APA convention fees, hological Association, Membership Services, -4242."
  }
]