---
title: COUNTERFACTUALS AND CAUSAL INFERENCE
---
SecondEdition

In this completely revised and expanded second edition of Counterfactuals and Causal
Inference, the essential features of the counterfactual approach to observational data analy-
sisarepresentedwithexamplesfromthesocial,demographic,andhealthsciences.Alternative
estimationtechniquesarefirstintroducedusingboththepotentialoutcomemodelandcausal
graphs;afterwhichconditioningtechniques,suchasmatchingandregression, arepresented
fromapotentialoutcomesperspective. Forresearch scenarios inwhichimportant determi-
nantsofcausalexposureareunobserved,alternativetechniques,suchasinstrumentalvariable
estimators,longitudinalmethods,andestimationviacausalmechanisms,arethenpresented.

Theimportanceofcausaleffectheterogeneityisstressed throughoutthebook,andtheneed
fordeepcausalexplanationviamechanismsisdiscussed.

StephenL.MorganistheBloombergDistinguishedProfessorofSociologyandEducationat
JohnsHopkinsUniversity.HewaspreviouslytheJanRockZubrow’77ProfessorintheSocial
SciencesandthedirectoroftheCenterfortheStudyofInequalityatCornellUniversity. His
currentareasofinterestincludesocialstratification, thesociologyofeducation,andquanti-
tativemethodology. HehaspublishedOntheEdge ofCommitment: EducationalAttainment
andRaceintheUnitedStates(2005)and,aseditor,theHandbookofCausalAnalysisforSocial
Research(2013).

ChristopherWinshipistheDiker-TishmanProfessorofSociologyandamemberofthesenior
facultyofHarvard’sKennedySchoolofGovernment. PriortocomingtoHarvardin1992,he
wasProfessorofSociologyandStatisticsandbycourtesyEconomicsatNorthwesternUniver-
sity.Hisresearchfocusesonstatisticalmodelsforcausalinference,mostrecentlymechanisms
and endogenous selection; how black clergy in Boston have worked with police to reduce
youthviolence;theeffectsofeducationonmentalability;pragmatismasthebasisforatheory
ofaction;theimplicationsofadvancesincognitivepsychologyforsociology;andsociological
approachestohowindividualsunderstandjustice.Since1995hehasbeeneditorofSociological
MethodsandResearch.

Analytical Methods for Social Research
AnalyticalMethodsforSocialResearchpresentstextsonempiricalandformalmethodsforthe
socialsciences. Volumesintheseriesaddressboththetheoreticalunderpinningsofanalyti-
caltechniquesaswellastheirapplicationinsocialresearch. Someseriesvolumesarebroadin
scope,cuttingacrossanumberofdisciplines.Othersfocusmainlyonmethodologicalapplica-
tionswithinspecificfieldssuchaspoliticalscience,sociology,demography,andpublichealth.

Theseriesservesamixofstudentsandresearchersinthesocialsciencesandstatistics.

SeriesEditors:
R.MichaelAlvarez,CaliforniaInstituteofTechnology
NathanielL.Beck,NewYorkUniversity
LawrenceL.Wu,NewYorkUniversity
OtherTitlesintheSeries:
TimeSeriesAnalysis fortheSocialSciences, byJanet M.Box-Steffensmeier, JohnR.Freeman,
MatthewPerryHitt,andJonC.W.Pevehouse
EventHistoryModeling:AGuideforSocialScientists,byJanetM.Box-Steffensmeierand
BradfordS.Jones
EcologicalInference: NewMethodologicalStrategies,editedbyGaryKing,OriRosen,and
MartinA.Tanner
SpatialModelsofParliamentaryVoting,byKeithT.Poole
EssentialMathematicsforPoliticalandSocialResearch,byJeffGill
PoliticalGameTheory:AnIntroduction,byNolanMcCartyandAdamMeirowitz
Data Analysis Using Regression and Multilevel/Hierarchical Models, by Andrew Gelman and
JenniferHill
# Counterfactuals and Causal Inference: Methods and Principles for Social Research

SecondEdition

STEPHEN L. MORGAN
JohnsHopkinsUniversity
CHRISTOPHER WINSHIP
HarvardUniversity
32AvenueoftheAmericas,NewYork,NY10013-2473,USA
CambridgeUniversityPressispartoftheUniversityofCambridge.

ItfurtherstheUniversity’smissionbydisseminatingknowledgeinthepursuitof
education,learning,andresearchatthehighestinternationallevelsofexcellence.

www.cambridge.org
Informationonthistitle:www.cambridge.org/9781107065079
(cid:2)c StephenL.MorganandChristopherWinship2007,2015
Thispublicationisincopyright.Subjecttostatutoryexception
andtotheprovisionsofrelevantcollectivelicensingagreements,
noreproductionofanypartmaytakeplacewithoutthewritten
permissionofCambridgeUniversityPress.

Firstpublished2007
Secondedition2015
PrintedintheUnitedStatesofAmerica
AcatalogrecordforthispublicationisavailablefromtheBritishLibrary.

LibraryofCongressCataloginginPublicationData
Morgan,StephenL.(StephenLawrence),1971–
Counterfactualsandcausalinference:methodsandprinciplesforsocialresearch/
StephenL.Morgan,ChristopherWinship.

pages cm.–(Analyticalmethodsforsocialresearch)
Revisededitionoftheauthors’Counterfactualsandcausalinference,publishedin2007.

Includesbibliographicalreferencesandindex.

ISBN978-1-107-06507-9(hardback)–ISBN978-1-107-69416-3(paperback)
1. Socialsciences–Research. 2. Socialsciences–Methodology.

3. Causation. I.Winship,Christopher. II.Title.

H62.M6462015
300.72–dc23 2014033205
ISBN978-1-107-06507-9Hardback
ISBN978-1-107-69416-3Paperback
CambridgeUniversityPresshasnoresponsibilityforthepersistenceoraccuracyof
URLsforexternalorthird-partyInternetWebsitesreferredtointhispublication
anddoesnotguaranteethatanycontentonsuchWebsitesis,orwillremain,
accurateorappropriate.

Tomywife,Sydney,myson,Vinny,andmydaughter,Beatrix
–SteveMorgan
Tomywife,Nancy,andmysons,DavidandMichael
–ChrisWinship
## Contents

ListofFigures page xiii

ListofTables xvii
AcknowledgmentsforFirstEdition xxi
AcknowledgmentsforSecondEdition xxiii
I CausalityandEmpiricalResearchintheSocialSciences
1 Introduction 3
1.1 ThePotentialOutcomeModelofCausalInference 4
1.2 CausalAnalysisandObservationalSocialScience 6
1.3 ExamplesUsedThroughouttheBook 14
1.4 ObservationalDataandRandom-SampleSurveys 27
1.5 CausalGraphsasanIntroductiontotheRemainderoftheBook 29
II Counterfactuals,PotentialOutcomes,andCausalGraphs
2 CounterfactualsandthePotentialOutcomeModel 37
2.1 DefiningtheCausalStates 37
2.2 PotentialOutcomesandIndividual-LevelTreatmentEffects 43
2.3 TreatmentGroupsandObservedOutcomes 44
2.4 TheAverageTreatmentEffect 46
2.5 TheStableUnitTreatmentValueAssumption 48
2.6 TreatmentAssignmentandObservationalStudies 53
2.7 AverageCausalEffectsandNaiveEstimation 54
2.8 Over-TimePotentialOutcomesandCausalEffects 62
2.9 ThePotentialOutcomeModelforMany-ValuedTreatments 70
2.10 Conclusions 73
2.11 AppendixtoChapter2:PopulationandDataGenerationModels 74
3 CausalGraphs 77
3.1 Identification 78
3.2 BasicElementsofCausalGraphs 79
3.3 GraphsandStructuralEquations 84
3.4 CausalGraphsandthePotentialOutcomeModel 90
ix
3.5 Conclusions 94
3.6 AppendixtoChapter3:Graphs,Interventions,andPotentialOutcomes 95
III EstimatingCausalEffectsbyConditioningonObservedVariablestoBlock
Back-DoorPaths
4 ModelsofCausalExposureandIdentificationCriteria
forConditioningEstimators 105
4.1 ConditioningandDirectedGraphs 105
4.2 TheBack-DoorCriterion 109
4.3 ModelsofCausalExposureandPointIdentificationBasedonthePotential
OutcomeModel 118
4.4 ConditioningtoBalanceandConditioningtoAdjust 128
4.5 Conclusions 130
4.6 AppendixtoChapter4:TheBack-DoorandAdjustmentCriteria,
Descendants,andCollidersUnderMagnification 130
5 MatchingEstimatorsofCausalEffects 140
5.1 OriginsofandMotivationsforMatching 141
5.2 MatchingasConditioningviaStratification 143
5.3 MatchingasWeighting 150
5.4 MatchingasaDataAnalysisAlgorithm 158
5.5 RemainingPracticalIssuesinMatchingAnalysis 181
5.6 Conclusions 187
6 RegressionEstimatorsofCausalEffects 188
6.1 RegressionasaDescriptiveTool 188
6.2 RegressionAdjustmentasaStrategytoEstimateCausalEffects 194
6.3 RegressionasConditional-Variance-WeightedMatching 206
6.4 RegressionasanImplementationofaPerfectStratification 214
6.5 RegressionasSupplementalAdjustmentWhenMatching 215
6.6 ExtensionsandOtherPerspectives 217
6.7 Conclusions 224
7 WeightedRegressionEstimatorsofCausalEffects 226
7.1 WeightedRegressionEstimatorsoftheATE 227
7.2 WeightedRegressionEstimatorsoftheATTandtheATC 231
7.3 DoublyRobustWeightedRegressionEstimators 234
7.4 RemainingPracticalIssuesinWeightedRegressionAnalysis 238
7.5 AnExtendedExample 243
7.6 Conclusions 262
IV EstimatingCausalEffectsWhenBack-DoorConditioningIsIneffective
8 Self-Selection,Heterogeneity,andCausalGraphs 267
8.1 NonignorabilityandSelectionontheUnobservablesRevisited 268
8.2 SelectionontheUnobservablesandtheUtilityofAdditional
PosttreatmentMeasuresoftheOutcome 269
8.3 CausalGraphsforComplexPatternsofSelf-Selection
andHeterogeneity 278
8.4 Conclusions 290
9 InstrumentalVariableEstimatorsofCausalEffects 291
9.1 CausalEffectEstimationwithaBinaryIV 291
9.2 TraditionalIVEstimators 296
9.3 InstrumentalVariableEstimatorsinthePresenceofIndividual-Level
Heterogeneity 305
9.4 Conclusions 324
10 MechanismsandCausalExplanation 325
10.1 TheDangersofInsufficientlyDeepExplanations 326
10.2 TheFront-DoorCriterionandIdentificationofCausalEffectsby
Mechanisms 330
10.3 TheAppealforGenerativeMechanisms 338
10.4 ThePursuitofExplanationwithMechanismsThatBottomOut 346
10.5 Conclusions 352
11 RepeatedObservationsandtheEstimationofCausalEffects 354
11.1 InterruptedTimeSeriesModels 355
11.2 RegressionDiscontinuityDesigns 360
11.3 PanelData 363
11.4 Conclusions 392
11.5 AppendixtoChapter11:Time-VaryingTreatmentRegimes 392
V EstimationWhenCausalEffectsAreNotPoint-IdentifiedbyObservables
12 DistributionalAssumptions,SetIdentification,andSensitivityAnalysis 419
12.1 DistributionalAssumptionsandLatentVariableSelection-BiasModels 420
12.2 SetIdentificationwithMinimalAssumptions 422
12.3 SensitivityAnalysisforProvisionalCausalEffectEstimates 429
12.4 Conclusions 434
VI Conclusions
13 CounterfactualsandtheFutureofEmpiricalResearchinObservational
SocialScience 437
13.1 ObjectionstoAdoptionoftheCounterfactualApproach 438
13.2 ModesofCausalInquiryintheSocialSciences 446
References 451
Index 497
## Figures

1.1 Acausalgraphinwhichback-doorpathsfromDtoY canbeblockedby

observablevariablesandinwhichCisaninstrumentalvariableforD page 30
1.2 AcausalgraphinwhichCisnolongeraninstrumentalvariableforD 32
1.3 AcausaldiagraminwhichM andN representanisolatedandexhaustive
mechanismforthecausaleffectofDonY 32
2.1 CrudebirthratesinJapan,1951–1980 65
3.1 Adirectedgraphthatincludesacycle 80
3.2 TworepresentationsofthejointdependenceofAandBonunobserved
commoncauses 81
3.3 Basicpatternsofcausalrelationshipsforthreevariables 82
3.4 TwographsinwhichthecausaleffectofDonY isconfoundedbyC 83
3.5 Acausalgraphinwhichtheeffectofeducation(E)onearnings(Y)is
confoundedbyobservedvariables(C)andbyunobservedability(A) 84
3.6 Atraditionallinearadditivepathdiagramfortheeffectsofparental
background(P),charterschools(D),andneighborhoods(N)ontestscores(Y) 86
3.7 Equivalentdirectedgraphrepresentationsoftheeffectsofparentalbackground
(P),charterschools(D),andneighborhoods(N)ontestscores(Y) 88
3.8 Twoalternativerepresentationsofassumedinterventionsincausalgraphs
wheretheeffectofDonY isconfoundedbyC 96
3.9 Alternativegraphsforthejointdependenceofatwo-valuedcausalvariablefor
education(E)andpotentialoutcomesforearnings(Y0andY1)onobserved
confounders(C)andonanunobservedconfounderforability(A) 101
4.1 AgraphinwhichthecausaleffectofDonY isconfoundedbytheback-door
pathD ←C →O →Y 106
4.2 Simulationofconditionaldependencewithinvaluesofacollidervariable 108
4.3 AcausaldiagraminwhichYt−1isacollideralongaback-doorpath 111
4.4 AcausaldiagraminwhichAisacollideronaback-doorpath 112
4.5 AcausaldiagraminwhichYt−2isacollideronaback-doorpathandYt−1is
itsdescendant 114
4.6 Aconfoundedcausaleffectexpressedasanindirecteffectandanetdirecteffect 114
4.7 AgraphwheretheeffectofDonY isnotidentifiedbyconditioningonOand
BbecauseOisadescendantofD 115
4.8 Causaldiagramsinwhichtreatmentassignmentis(a)nonignorableand
(b)ignorable 121
xiii
4.9 Causaldiagramsfortheterminologyfromeconometricmodelingoftreatment
selection 125
4.10 Acausaldiagraminwhichsufficientconditioningcanbeperformedwith
respecttoSorX 129
4.11 Acausalgraphwithaconfoundedcausaleffectandwherethevariablesalong
theback-doorpathareviewedundermagnification 131
4.12 AdiagramwherethecausaleffectofDonY isnotconfoundedandwherethe
observedvariableOontheback-doorpathisadescendantofboth
DandY 133
4.13 AgraphwheretheeffectofDonY isnotidentifiedbyconditioningonOand
BbecauseOisadescendantofD 135
4.14 Adirectedgraphthatrevealsthedifferencesbetweentheback-doorcriterion
andtheadjustmentcriterion 137
5.1 ThepropensityscorespecificationforMatchingDemonstration3 154
5.2 Thedirectedgraphimpliedbytheunderlyingdatagenerationmodelfor
MatchingDemonstration4 174
6.1 GraphsforaregressionequationofthecausaleffectofDonY 196
6.2 AcausalgraphforaregressionequationinwhichthecausaleffectofDonY is
identifiedbyconditioningonX 201
7.1 Kerneldensityestimatesoftheestimatedpropensityscore,calculated
separatelyforpublicschoolstudents(blacksolidline)andCatholicschool
students(graydashedline) 249
8.1 Coleman’sstrategyfortheidentificationofthecausaleffectofCatholic
schoolingonachievement 269
8.2 CriticismofColeman’sestimatesoftheeffectofCatholicschoolingonlearning 272
8.3 Separatecausalgraphsfortwogroupsofindividuals(G=1andG=2)
wheretheeffectsofparentalbackground(P)andcharterschools(D)ontest
scores(Y)maydifferforthetwogroups 279
8.4 Agraphwheregroupsarerepresentedbyanunobservedlatentclassvariable
(G)inasinglegraph 281
8.5 Twographswhereselectionintocharterschools(D)isdeterminedbygroup
(G)andwhereselectionrenderstheeffectofDonY unidentifiedaslongasG
remainsunobserved 282
8.6 Twographswhereselectionontheunobservablesisgivenanexplicit
representationasself-selectiononsubjectiveexpectationsofvariationinthe
causaleffectofDonY.Forpanel(b),theseexpectationsaredeterminedby
information(I)thatisdifferentiallyavailabletofamilieswithparticular
parentalbackgrounds(P) 283
8.7 Agraphwhereself-selectiononthecausaleffectofcharterschoolingalso
triggersself-selectionintoconsequentialandinteractiveneighborhood
contexts(N) 285
9.1 TwographsinwhichZisapotentialinstrumentalvariable 292
9.2 TwographsinwhichZisavalidIV 298
9.3 Agraphwithanunblockedback-doorpathandavalidIV 302
9.4 Instrumentalvariableidentificationofthecausaleffectofcharterschools(D)
ontestscores(Y),whereZ istheinstrument 318
9.5 Instrumentalvariableidentificationofthecausaleffectofcharterschools(D)
ontestscores(Y),whereseparategraphsaredrawnforcompliersand
noncompliers 320
9.6 AcombinedgraphforFigures9.5(a)–(b),whereZ istheinstrumentand
complianceisrepresentedasanunobservedlatentclassvariable(C) 321
9.7 IdentificationoftheLATEusinganinstrument(Z)forthecharterschool
graphpresentedearlierinFigure8.7.TheunobservedvariableV isa
compositeforthecausalchainthatgeneratesself-selectioninFigure8.7
throughinformationaccessandselectiononthesubjectiveevaluationofthe
individual-levelcausaleffect 322
10.1 AdirectedgraphforcomplierswithquarterofbirthasanIVfor
yearsofschooling 327
10.2 AdirectedgraphforcomplierswiththeVietnamdraftlotteryas
anIVformilitaryservice 328
10.3 AdirectedgraphinwhichM andN representanexhaustiveandisolated
identifyingmechanismforthecausaleffectofDonY 332
10.4 AdirectedgraphinwhichM isnotanisolatedmechanismforthecausaleffect
ofDonY 335
10.5 Directedgraphsinwhichonepathwayinanexhaustiveandisolated
mechanismisunobserved 336
11.1 Trajectoriesoftheobservedoutcomeaswellasthetrueandassumed
counterfactualoutcomesforafaultyITSmodel 357
11.2 MonthlyyouthhomicideratesinBoston,1991–1999 358
11.3 ForeseeabilityofalayoffasanexampleofanRDdesign 361
11.4 AnexampleofafuzzyRDdesign 362
11.5 AdirectedgraphfortheeffectofCatholicschoolingontenthgrade
achievementwhenameasureofeighthgradeachievementisalsoavailable 367
11.6 ExamplesofpossibletrajectoriesforE[Y0]forthetreatmentgroup(theupper
it
lineofeachpair)andthecontrolgroup(thelowerlineofeachpair)wherethe
correctadjustmentfavor,α,varies 377
11.7 Depictionsofpossibletrajectories,asspecifiedbythemodelsinTable11.3,for
E[Y0|D∗ =1](theupperlineofeachpair,correspondingtothetreatment
it i
group)andE[Y0|D∗ =0](thelowerlineofeachpair,correspondingtothe
it i
controlgroup) 382
11.8 Amodelofendogenoustreatmentassignmentinwhichselectionisonthe
pretreatmentoutcome,Yt−1 383
11.9 Amodelofendogenoustreatmentassignmentinwhichselectionisonafixed
effectthatalsodeterminestheoutcome 384
11.10 TheCatholicschooleffectinthetenthandtwelfthgradesasadynamic
treatmentregime 395
11.11 AnillustrativedirectedgraphforG-computation 408
11.12 Adirectedgraphforapseudo-populationproducedusinginverseprobability
oftreatmentweighting 412
12.1 AgraphinwhichthecausaleffectofDonY isconfoundedbyanobserved
variableCandanunobservedvariableU 431
## Tables

2.1 TheFundamentalProblemofCausalInference page 46

2.2 AHypotheticalExampleinWhichSUTVAIsViolated 49
2.3 AnExampleofInconsistencyandBiasoftheNaiveEstimatorWhentheATEIs
theCausalEffectofInterest 60
2.4 TheFundamentalProblemofCausalInferenceforMany-ValuedTreatments 71
2.5 TheObservabilityTableforEstimatingHowEducationIncreases
Earnings 72
5.1 TheJointProbabilityDistributionandConditionalPopulationExpectations
forMatchingDemonstration1 146
5.2 EstimatedConditionalExpectationsandProbabilitiesforMatching
Demonstration1 146
5.3 TheJointProbabilityDistributionandConditionalPopulationExpectations
forMatchingDemonstration2 149
5.4 EstimatedConditionalExpectationsandProbabilitiesforMatching
Demonstration2 149
5.5 MonteCarloMeansandStandardDeviationsofTrueandEstimatedTreatment
EffectsforMatchingDemonstration3 155
5.6 MatchingEstimatesoftheATT,CatholicSchoolingonAchievementforOne
SimulatedDataset 176
5.7 BiasforMatchingEstimatesoftheATT,CatholicSchoolingonAchievement
Across10SimulatedDatasets 178
6.1 TheJointProbabilityDistributionandConditionalPopulationExpectations
forRegressionDemonstration1 190
6.2 ExamplesoftheTwoBasicFormsofBiasforLeastSquaresRegression 198
6.3 Two-PersonExamplesinWhichLeastSquaresRegressionEstimatesAre
Unbiased 200
6.4 TwoSix-PersonExamplesinWhichRegressionAdjustmentIs
DifferentiallyEffective 203
6.5 ARearrangementoftheExampleinTable6.4ThatShowsHowRegression
AdjustmentIsDifferentiallyEffective 204
6.6 TheJointProbabilityDistributionforTwoVariantsoftheStratifyingand
TreatmentVariablesinPriorRegressionDemonstration1 210
6.7 TheJointProbabilityDistributionandConditionalPopulationExpectations
forRegressionDemonstration3 213
xvii
6.8 AverageBiasComparisonsforSelectedMatchingEstimatesoftheATTfrom
MatchingDemonstration4,WithandWithoutSupplementalRegression
AdjustmentfortheAssumedDeterminantsofTreatmentAssignment 216
7.1 WeightedRegressionEstimatesoftheATE,UsingandExtendingtheData
SetupforMatchingDemonstration3 230
7.2 WeightedRegressionEstimatesoftheATTandATC,UsingandExtendingthe
DataSetupforMatchingDemonstration3 233
7.3 BiasforWeightedRegressionEstimatesoftheATT,CatholicSchoolingon
AchievementAcross10SimulatedDatasetsUtilizedforMatching
Demonstration4andRegressionDemonstration4 237
7.4 MeansandStandardDeviationsofthePrimaryVariablesUsedinthe
Demonstration 245
7.5 CatholicSchoolCoefficientsfromBaselineRegressionModelsPredicting
TenthGradeMathTestScores,TwelfthGradeMathTestScores,andMath
TestGains 246
7.6 MeansandStandardDeviationsofPrimaryVariables,WeightedbytheATT
WeightfromtheFinalEstimationoftheTreatmentAssignmentModel 250
7.7 MeansandStandardDeviationsofPrimaryVariables,WeightedbytheATC
WeightfromtheFinalEstimationoftheTreatmentAssignmentModel 251
7.8 CatholicSchoolCoefficientsfromATT-WeightedandATC-Weighted
RegressionModelsPredictingTenthGradeMathTestScores,TwelfthGrade
MathTestScores,andMathTestGains 253
7.9 CatholicSchoolCoefficientsfromWeightedRegressionModelsRestrictedto
theRegionofOverlapintheEstimatedPropensityScores 254
7.10 CatholicSchoolCoefficientsfromDoublyRobustWeightedRegression
Models 255
7.11 CatholicSchoolCoefficientsfromWeightedRegressionModels,Including
AdditionalCovariates 257
8.1 SimulatedResultsfortheIdentificationApproachAdoptedbyColemanand
Colleagues 276
9.1 TheDistributionofVoucherWinnersbySchoolSectorfor
IVDemonstration1 295
9.2 TheJointProbabilityDistributionandConditionalExpectationsoftheTest
ScoreforVoucherWinnerbySchoolSectorforIVDemonstrations1and2 310
9.3 TheDistributionofNeverTakers,Compliers,andAlwaysTakersforIV
Demonstration2 311
11.1 ChangeScoreandAnalysisofCovarianceEstimatesoftheCatholicSchool
EffectintheTenthGrade 370
11.2 EstimatedAverageTreatmentEffectsforDifferentCombinationsofCorrect
andAssumedAdjustmentFactors,WheretheTrueEffectIsEqualto1 379
11.3 AlternativeTrajectoriesoftheOutcomeUndertheControlStateforDifferent
AssumptionsAboutItsDynamicStructure 381
11.4 SpecificationTestsfromtheAnalysisofHeckmanandHotz(1989)oftheEffect
oftheNationalSupportedWorkProgramontheEarningsofHighSchool
Dropouts 391
11.5 ExpectedValuesfortheEndogenousVariablesintheDirectedGraphin
Figure11.10 399
11.6 IdentificationStatusoftheTotalCausalEffectsinFigure11.10 400
11.7 Pseudo-PopulationProportionsfortheDirectedGraphinFigure11.12 414
12.1 AHypotheticalExampleoftheCalculationofBoundsfortheATE 423
## AcknowledgmentsforFirstEdition

Withoutyetknowingit,webegantowritethisbookin1997whencollaboratingonapaper

forthe1999volumeoftheAnnualReviewofSociology,titled“TheEstimationofCausalEffects
fromObservationalData.” Webenefitedfrommanyhelpfulcommentsinthepreparationof
thatmanuscript,andwewerepleasedthatmanyofourcolleaguesfoundittobeausefulintro-
ductiontoaliteraturethatwewere,atthetime,stillworkingtounderstandourselves. Since
then,considerableprogressinthepotentialoutcomesandcounterfactualmodelingliterature
hasbeenachieved,whichledusintolongdiscussionsoftheutilityofwritingamorecompre-
hensiveintroduction. Intheend,ourmotivationtolearnevenmoreoftheliteraturewasthe
decisivefactor.

We thank Richard Berk, Felix Elwert, George Farkas, Glenn Firebaugh, Jeremy Freese,
Andrew Gelman, Gary King, Trond Petersen, David Weakliem, and Kim Weeden for read-
ingsomeorallofthepenultimatedraftofthebook. Wealsothanktheanonymousreviewer
recruited by Cambridge University Press. The insightful comments of all of these readers
helped tremendously. We also thank our students at Cornell and Harvard, from whom we
havelearnedmuchinthecourseoflearningandthenpresentingthismaterialtothem. Their
commentsandquestionsweremorevaluablethantheyareprobablyaware.

Finally, we thank Kelly Andronicos and Jenny Todd at Cornell University for assistance
with the preparation of the manuscript, as well as Larry Wu and Ed Parsons at Cambridge
UniversityPress,ProjectManagerPeterKatsirubasatAptara,Inc.,andVictoriaDanahyatIn
OtherWords.

xxi
## AcknowledgmentsforSecondEdition

WethankallofthestudentsinourclassesatCornellandatHarvard,aswellasthosewhohave

attendedpresentationsofthenewmaterial inthissecondeditionatotheruniversities. Your
excellentquestionsovertheyearshaveshapedthisbookmorethanyoumayrealize.

Fortheirgenerosityandwillingnesstoreadandcommentonsubstantialportionsofthis
secondedition,wethankWeihuaAn,NealBeck,RichardBerk,DavidBills,KenBollen(and
hisstudents),AndyCherlin,TomDiPrete,FelixElwert,MarkusGangl,GuangleiHong,Mike
Hout,TimLiao,ScottLynch,IsaacReed,MattSalganik,JasjeetSekhon,PeterSteiner,Jessica
Su,SteveVaisey,TylerVanderWeele,DavidWeakliem,andHuiZheng. Inaddition,wethank
JohnCawleyandDanLichterforpointing ustorelevantliteratureinhealtheconomicsand
demography.

WealsothankCornellUniversityandHarvardUniversityforthesabbaticalsupportthat
allowedustobeginthewritingofthissecondedition. MorganthanksCollegioCarloAlberto
forprovidingarestfulandstimulatingenvironmentforworkfromJanuarythroughJune2013.

xxiii
# Part I: Causality and Empirical Research in the Social Sciences

# Chapter 1

# Introduction

Do charter schools increase the test scores of elementary school students? If so, how

largearethegainsincomparisontothosethatcouldberealizedbyimplementingalter-
native educational reforms? Does obtaining a college degree increase an individual’s
labormarketearnings?Ifso,isthisparticulareffectlargerelativetotheearningsgains
that could be achieved only through on-the-job training? Did the use of a butterfly
ballot in some Florida counties in the 2000 presidential election cost Al Gore votes?
If so, was the number of miscast votes sufficiently large to have altered the election
outcome?
At their core, these types of questions are simple cause-and-effect questions of the
form, Does X cause Y? If X causes Y, how large is the effect of X on Y? Is the size
of this effect large relative to the effects of other causes of Y?
Simple cause-and-effect questions are the motivation for much research in the
social, demographic, and health sciences, even though definitive answers to cause-
and-effect questions may not always be possible to formulate given the constraints
that researchers face in collecting data and evaluating alternative explanations. Even
so, there is reason for optimism about our current and future abilities to effectively
addresscause-and-effectquestions.Overthepastfourdecades,acounterfactualmodel
ofcausalityhasbeendevelopedandrefined,andasaresultaunifiedframeworkforthe
prosecution of causal questions is now available. With this book, we aim to convince
more social scientists to apply this model to the core empirical questions of the social
sciences and to applied researchquestions of public importance.

In this introductory chapter, we provide a skeletal pr´ecis of the main features of
the potential outcome model, which is a core piece of the more general counterfactual
approach to observational data analysis that we present in this book. We then offer
a brief and selective history of causal analysis in quantitatively orientedobservational
social science. We develop some background on the examples that we will draw on
throughout the book, and we conclude with an introduction to directed graphs for
systems of causal relationships.

3
## 1.1 The Potential Outcome Model of Causal Inference

With its origins in early work on experimental design by Neyman (1990[1923],1935),

Fisher (1935), Cochran and Cox (1950), Kempthorne (1952), and Cox (1958), the
potential outcome model of causal inference was formalized in a series of papers by
the statistician Donald Rubin (1974, 1977, 1978, 1980a, 1981, 1986, 1990). The name
“potential outcome” is a reference to the potential yields from Neyman’s work in
agricultural statistics (see Gelman and Meng 2004; Rubin 2005). The model also has
rootsintheeconomicsliterature(Roy1951;Quandt1972),withimportantsubsequent
workbyJamesHeckman(see Heckman1974,1978,1979,1989,1992),CharlesManski
(1995),andothers.Themodelisnowdominantinbothstatisticsandeconomics,andit
is being used with increasing frequency acrossthe basic and applied socialand health
sciences.

Thecoreofthepotentialoutcomemodelissimple.Supposethateachindividualin
apopulationofinterestcanbeexposedtotwoalternativestatesofacause.Eachstate
is characterized by a distinct set of conditions, exposure to which potentially affects
an outcome of interest, such as labor market earnings or scores on a standardized
mathematicstest.Iftheoutcomeisearnings,thepopulationofinterestcouldbeadults
betweentheagesof30and50,andthetwostatescouldbewhetherornotanindividual
hasobtainedacollegedegree.Alternatively,iftheoutcomeisamathematicstestscore,
the population of interest could be high school seniors, and the two states could be
whetherornotastudenthastakenacourseintrigonometry.Forthepotentialoutcome
model, these alternative causal states are referred to as alternative treatments. When
only two treatments are considered, they are referred to as treatment and control.

Throughout this book, we will conform to this convention.

Thekeyassumptionofthemodelisthateachindividualinthepopulationofinter-
est has a potential outcome under each treatment state, even though each individual
can be observed in only one treatment state at any point in time. For example, for
the causal effect of having a college degree rather than only a high school diploma
on subsequent earnings, adults who have completed only high school diplomas have
theoretical what-if earnings under the state “have a college degree,” and adults who
havecompletedcollegedegreeshavetheoreticalwhat-ifearningsunderthestate“have
only a high school diploma.” These what-if potential outcomes are counterfactual in
the sense that they exist in theory but are not observed.

Formalizing this conceptualization for a two-state treatment, the potential out-
comes of eachindividual are defined as the true values of the outcome of interestthat
wouldresultfromexposuretothe alternativecausalstates.The potentialoutcomesof
each individual i are y1 and y0, where the superscript 1 signifies the treatment state
i i
andthesuperscript0signifiesthecontrolstate.Becausebothy1 andy0 existintheory
i i
for each individual, an individual-level causal effect can be defined as some contrast
between y1 and y0, usually the simple difference y1−y0. Because it is impossible to
i i i i
observebothy1 andy0 foranyindividual,causaleffectscannotbeobservedordirectly
i i
calculated at the individual level.1
1The only generally effective strategy for estimating individual-level causal effects is a crossover
design,inwhichindividualsareexposedtotwoalternativetreatmentsinsuccessionandwithenough
Bynecessity,aresearchermustanalyzeanobservedoutcomevariableY thattakes
on values yi for each individual i that are equal to y i1 for those in the treatment state
andy0 forthoseinthecontrolstate.Weusuallyrefertothoseinthetreatmentstateas
i
the treatmentgroupandthoseinthe controlstateasthe controlgroup.2 Accordingly,
y0 is an unobservable counterfactual outcome for each individual i in the treatment
i
group, and y1 is an unobservable counterfactual outcome for each individual i in the
i
control group.

In the potential outcome modeling tradition, attention is focused on estimating
various average causal effects, by analysis of the values yi, for groups of individuals
defined by specific characteristics. To do so effectively, the process by which individ-
uals of different types are exposed to the cause of interest must be modeled. Doing
so involves introducing defendable assumptions that allow for the estimation of the
average unobservable counterfactual values for specific groups of individuals. If the
assumptions are defendable, and a suitable method for constructing an average con-
trast from the data is chosen, then the resulting average difference in the values of yi
can be given a causal interpretation.

The potential outcome model is one core piece of the more general counterfactual
approachtocausalanalysisthatwewillpresentinthisbook.Anothercorepiece,which
we will introduce at the end of this chapter, is the directed graph approach to causal
analysis,most closely associatedwith the work of the computer scientist Judea Pearl.

We will use Pearl’s work extensively in our presentation, drawing on his 2000 book,
Causality: Models, Reasoning, and Inference (2nd edition, 2009), as well as related
literature.

A counterfactual account of causation also exists in philosophy, which began with
the seminal 1973article by David Lewis, titled “Causation.”It is related to the coun-
terfactual model of causal analysis that we will present in this book, but the philo-
sophical version, as implied by the title of Lewis’ original article, aims to be a general
model of causation.3 As noted by the philosopher James Woodwardin his 2003book,
time elapsed in between exposures such that the effects of the cause have had time to dissipate
(see Rothman, Greenland, and Lash 2008). Obviously, such a design can be attempted only when
a researcher has control over the allocation of the treatments and only when the treatment effects
are sufficiently ephemeral. These conditions rarelyexist for the causal questions that interest social
scientists.

2Weassumethat,forobservationaldataanalysis,anunderlyingcausalexposuremechanismexists
in the population, and thus the distribution of individuals across the treatment and control states
existsseparatelyfromtheobservationandsamplingprocess.Accordingly,thetreatmentandcontrol
groupsexistinthepopulation,eventhoughwetypicallyobserveonlysamplesofthemintheobserved
data. We will not require that the labels “treatment group” and “control group” refer only to the
observedtreatment andcontrolgroups.

3In this tradition, causation is defined with reference to counterfactual dependence (or, as is
sometimes written, the “ancestral” to counterfactual dependence). Accordingly, and at the risk of
a great deal of oversimplification, the counterfactual account inphilosophy maintains that (in most
cases)itispropertodeclarethat,foreventscande,ccauseseif(1)candebothoccurand(2)ifchad
notoccurredandallelseremainedthesame,thenewouldnothaveoccurred.Theprimarychallenge
of the approach is to define the counterfactual scenario in which c does not occur (which Lewis
didby imaginingalimited“divergence miracle”that prevents c fromoccurringinaclosest possible
hypothetical world where all else is the same except that c does not occur). The approach differs
substantially from the regularity-based theories of causality that dominated metaphysics through
the 1960s, based on relations of entailment from covering law models. For a collection of essays in
Making Things Happen: A Theory of Causal Explanation, the counterfactual account
of causation championed by Lewis and his students has not been influenced to any
substantial degree by the potential outcomes version of counterfactual modeling used
bystatisticians,socialscientists,andotherempiricalresearchers.However,Woodward
and other philosophers have engaged the directed graph approach to causality with
considerable energy in the past decade. We will discuss the broader philosophical lit-
erature in Chapters 2, 10, and 13, as it does have some implications for social science
practice and the pursuit of explanation more generally.

## 1.2 Causal Analysis and Observational Social Science

Thechallengesofusingobservationaldatatojustify causalclaimsareconsiderable.In

thissection,wepresentaselectivehistoryoftheliteratureonthesechallenges,focusing
on the varied usage of experimental language in observational social science. We will
also consider the growth of survey research and the shift toward outcome-equation-
based motivations of causal analysis that led to the widespread usage of regression
estimators.Many useful discussions of these developments exist, andour presentation
here is not meant to be complete.4 We review only the literature that is relevant for
explaining the connections between the counterfactual approach and other traditions
of quantitatively oriented analysis that are of interest to us here.

1.2.1 Experimental Language in Observational Social Science
Althoughthecommondefinitionofthewordexperimentisbroad,inthesocialsciences
itismostcloselyassociatedwithrandomizedexperimentaldesigns,suchasthedouble-
blind clinical trials that have revolutionized the biomedical sciences and the routine
small-scale experiments that psychology professors perform on their own students.5
philosophy on counterfactuals and causation, see Collins, Hall, and Paul (2004). For a penetrating
examination of thecounterfactual model inphilosophyand itsrivals,seePaul andHall (2013). The
counterfactual model that weconsider inthis book isclose to what Paul and Hall label the “causal
model”approachtocausation, whichtheyconsideroneoffourvariantsofcounterfactual modeling.

4Togainamorecompleteappreciationoftheexpansiveliteratureoncausalityinthesocialsciences,
see, for sociology, Barringer, Leahey, and Eliason (2013), Berk (1988, 2004, 2008), Blossfeld (2009),
Bollen (1989), Bollen and Pearl (2013), Firebaugh (2008), Fox (2008), Gangl (2010), Goldthorpe
(2007), Harding and Seefeldt (2013), Lieberson (1985), Marini and Singer (1988), Morgan (2013),
Rohwer (2010), Singer and Marini (1987), Smith (1990, 2003, 2013), Sobel (1995, 1996, 2000), and
Treiman (2009). For economics, see Angrist and Krueger (1999), Angrist and Pischke (2009, 2010),
Heckman(2000,2005,2008b,2010),ImbensandWooldridge(2009),Keane(2010),Lee(2005),Manski
(1994, 1995, 2003), Moffitt (2003), Pratt and Schlaifer (1984), and Rosenzweig and Wolpin (2000).

Forpoliticalscience,seeBradyandCollier(2010),Druckman,Kuklinski,andLupia(2011),Dunning
(2012), GerberandGreen(2012), Gerring(2007), GoertzandMahoney(2012), King,Keohane, and
Verba (1994), Morton and Williams (2010), and Sekhon (2009). For applied evaluation and policy
analysis,seeShadish,Cook,andCampbell(2001),andespeciallyforeducationresearch,seeMurnane
andWillett(2011)
5The Oxford English Dictionary provides the scientific definition of experiment: “An action or
operation undertaken in order to discover something unknown, to test a hypothesis, or establish or
illustratesomeknowntruth”andalsoprovidessourcereferencesfromasearlyas1362.

RandomizedexperimentshavetheiroriginsintheworkofstatisticianRonaldA.Fisher
duringthe1920s,whichthendiffusedthroughoutvariousresearchcommunitiesviahis
widely read 1935 book, The Design of Experiments.

Statisticians David Cox and Nancy Reid (2000) offer a definition of an experi-
ment that focuses on the investigator’s deliberate control and that allows for a clear
juxtaposition with an observational study:
The wordexperiment isusedina quiteprecisesenseto meananinvestiga-
tionwherethe systemunderstudy is underthe controlofthe investigator.

This means that the individuals or material investigated, the nature of
the treatments or manipulations under study and the measurement pro-
cedures used are all selected, in their important features at least, by the
investigator.

By contrast in an observational study some of these features, and in
particular the allocation of individuals to treatment groups, are outside
the investigator’s control. (Cox and Reid 2000:1)
We will maintain this basic distinction throughout this book. We will argue in this
sectionthatthepotentialoutcomemodelofcausalitythatweintroducedinthelastsec-
tionisvaluablepreciselybecauseithelpsresearcherstostipulateassumptions,evaluate
alternative data analysis techniques, and think carefully about the process of causal
exposure. Its success is a direct result of the language of potential outcomes, which
permitstheanalysttoconceptualizeobservationalstudiesasiftheywereexperimental
designs controlledby someone other than the researcher– quite often, the subjects of
the research. In this section, we offer a brief discussion of other important attempts
to use experimental language in observational social science and that succeeded to
varying degrees.

Samuel A. Stouffer, the sociologist and pioneering public opinion survey analyst,
argued that “the progress of social science depends on the development of limited
theories – of considerable but still limited generality – from which prediction can be
made to new concrete instances” (Stouffer 1962[1948]:5). Stouffer argued that, when
testing alternative ideas, “it is essential that we always keep in mind the model of a
controlledexperiment,evenifinpracticewemayhavetodeviatefromanidealmodel”
(Stouffer1950:356).Hefollowedthispracticeoverhiscareer,fromhis1930dissertation
thatcomparedexperimentalwithcasestudymethodsofinvestigatingattitudes,tohis
leadershipofthe teamthatproducedThe American Soldier duringWorldWarII (see
Stouffer 1949), and in his 1955 classic Communism, Conformity, and Civil Liberties.

On his death, and in celebration of a posthumous collection of his essays, Stouffer
was praised for his career of survey research and attendant explanatory success. The
demographerPhilipHausernotedthatStouffer“hadahandinmajordevelopmentsin
virtuallyeveryaspectofthe samplesurvey–samplingprocedures,problemdefinition,
questionnaire design, field and operating procedures, and analytic methods” (Hauser
1962:333).ArnoldRose(1962:720)declared,“Probablynosociologistwassoingenious
in manipulating data statistically to determine whether one hypothesis or another
could be considered as verified.” And Herbert Hyman portrayed Stouffer’s method of
tabular analysis in charming detail:
While the vitality with which he attacked a table had to be observed in
action, the characteristic strategy he employed was so calculating that
one can sense it from reading the many printed examples....Multivariate
analysis for him was almost a way of life. Starting with a simple cross-
tabulation, the relationship observed was elaborated by the introduction
of a third variable or test factor, leading to a clarification of the original
relationship....But there was a special flavor to the way Sam handled it.

Withhim,theloveofatablewasundying.Threevariablesweren’tenough.

Four,five,six,evensevenvariableswereintroduced,untilthatsimplething
of beauty, that original little table, became one of those monstrous crea-
tures at the first sight of which a timid student would fall out of love with
our profession forever. (Hyman 1962:324–25)
Stouffer’s method was to conceive of the experiment that he wished he could have
conducted and then to work backwards by stratifying a sample of the population
of interest into subgroups until he felt comfortable that the remaining differences in
the outcome could no longer be easily attributed to systematic differences within the
subgroups. He never lost sight of the population of interest, and he appears to have
always regarded his straightforwardconclusions as the best among plausible answers.

Thus,ashesaid,“Thoughwecannotalwaysdesignneatexperimentswhenwewantto,
wecanatleastkeeptheexperimentalmodelinfrontofoureyesandbehavecautiously”
(Stouffer 1950:359).

Not all attempts to incorporate experimental language into observational social
science were as well received. Most notably in sociology,F. Stuart Chapin had earlier
arguedexplicitly for an experimental orientationto nearly all of sociologicalresearch,
but while turning the definition of an experiment in a direction that agitated others.

ForChapin,avalidexperimentdidnotrequirethatthe researcherobtaincontrolover
the treatmentto be evaluated,only that observationof a causalprocess be conducted
in controlled conditions (see Chapin 1932, 1947). He thus considered what he called
“expostfactoexperiments”tobe thesolutiontotheinferentialproblemsofthesocial
sciences, and he advocated matching designs to select subsets of seemingly equivalent
individuals from those who were and were not exposed to the treatment of interest.

Insodoing,however,he proposedtoignorethe incomparable,unmatchedindividuals,
thereby losing sight of the population that Stouffer, the survey analyst, always kept
in the foreground.

Chapin thereby ran afoul of emergent techniques of statistical inference, and he
sufferedattacks fromhis naturalallies in quantitative analysis.The statisticianOscar
Kempthorne, whose 1952 book The Design and Analysis of Experiments would later
become a classic, dismissed Chapin’s work completely. In a review of Chapin’s 1947
book, Experimental Designs in Sociological Research, Kempthorne wrote:
The usage of the word “experimental design” is well established by now
to mean a plan for performing a comparative experiment. This implies
that various treatments are actually applied by the investigator and are
notjusttreatmentsthathappenedtohavebeenappliedtoparticularunits
forsomereason,knownorunknown,beforethe“experiment”wasplanned.

Thisconditionrulesoutpracticallyalloftheexperimentsandexperimental
designs discussed by the author. (Kempthorne 1948:491)
Chapin’scolleaguesinsociologyanddemographywereoftenjustasunforgiving.Nathan
Keyfitz(1948:260),forexample,chastisedChapinforignoringthepopulationofinter-
estandaccusedhim ofusingterms suchas“experimentaldesign”merelyto “lendthe
support of their prestige.”
In spite of the backlashagainstChapin, in the end he has a recognizable legacy in
observationaldataanalysis.Thematchingtechniquesheadvocatedwillbediscussedin
Chapter5.Theyhavebeenreborninthenewliterature,inpartbecausethepopulation
of interest has been brought back to the foreground.But there is an even more direct
legacy. Many of Chapin’s so-called experiments were soon taken up, elaborated, and
analyzedby the psychologistDonaldT. Campbell andhiscolleaguesunder the milder
and more general name of “quasi-experiments.”6
The first widely read presentation of Campbell’s perspective emerged in 1963 (see
Campbell and Stanley 1966[1963]), in which quasi-experiments were discussed along-
side randomized and fully controlled experimental trials, with an evaluation of their
relative strengths and weaknesses in alternative settings. In the subsequent decade,
Campbell’s work with his colleagues moved closer toward observational research, cul-
minatinginthevolumebyCookandCampbell(1979),Quasi-Experimentation:Design
& Analysis Issues for Field Settings, wherein a whole menu of quasi-experiments was
described and analyzed: from the sort of ex post case-control matching studies advo-
catedbyChapin(butrelabeledmoregenerallyasnonequivalentgroupdesigns)tonovel
proposals for regression discontinuity and interrupted time series designs (which we
will discussinChapter11). For CookandCampbell, the termquasi-experimentrefers
to “experiments that have treatments, outcome measures, and experimental units,
but do not use random assignment to create the comparisons from which treatment-
caused change is inferred” (Cook and Campbell 1979:6).7 And, rather than advocate
for a reorientation of a whole discipline as Chapin had, they pitched the approach as
a guide for field studies, especially program evaluation studies of controlled interven-
tions. Nonetheless, the ideas were widely influential throughoutthe social sciences, as
they succeededin bringinga tamedexperimental languageto the foregroundina way
thatpermittedbroadassessmentsofthestrengthsandweaknessesofalternativestudy
designs and data analysis techniques.

1.2.2 “The Age of Regression”
Even though the quasi-experiment tradition swept through the program evaluation
community and gained many readers elsewhere, it lost out in the core social science
disciplines to regression-equation-based motivations of observational data analysis,
6In his first publication on quasi-experiments, Campbell (1957) aligned himself with Stouffer’s
perspective on the utility of experimental language, and in particular Stouffer (1950). Chapin is
treated roughly by Campbell and Stanley (1966[1963]:70), even though his ex post facto design is
identifiedas“oneofthemostextended effortstowardquasi-experimentaldesign.”
7NoticethatCookandCampbell’sdefinitionofquasi-experimentshereis,infact,consistentwith
the definition of an experiment laid out by Cox and Reid, which we cited earlier in this section.

Forthat definitionofanexperiment, controlisessentialbutrandomizationisnot. ThetextofCook
and Campbell (1979) equivocates somewhat on these issues, but it is clear that their intent was
to discuss controlled experiments for which randomization is infeasible and which they then label
quasi-experiments.

under the influence at first of researchers who promoted regression modeling from
a path-modeling orientation. In sociology, Hubert Blalock and Otis Dudley Duncan
are usually credited with introducing the techniques, first via Blalock’s 1964[1961]
book Causal Inferences in Nonexperimental Research and then later via Duncan’s
1966article, “PathAnalysis:SociologicalExamples,”whichwaspublished asthe lead
article in that year’s American Journal of Sociology.8 In both presentations, caution
was stressed. Blalock discussed carefully the differences between randomized experi-
mentsandobservationalsurveyresearch.Duncanstatedexplicitlyinhisabstractthat
“path analysis focuses on the problem of interpretation and does not purport to be
a method for discovering causes,” and he concluded his article with a long quotation
from Sewall Wright attesting to the same point.

A confluence of developments then pushed path models toward widespread usage
and then basic regressionmodeling toward near complete dominance of observational
research in some areas of social science.9 In sociology, the most important impetus
was the immediate substantive payoff to the techniques. The American Occupational
Structure, which Duncan cowrote with Peter Blau and published in 1967, offered new
decompositions of the putative causal effects of parental background and individuals’
own characteristics on later educational and occupational attainment. By pushing
socialstratificationresearchintonewterrain,theirbooktransformedacoresubfieldof
thedisciplineofsociology,leadingtomajortheoreticalandmethodologicalredirections
of many existing lines of scholarship.10
Researchers seemed to then ignore many of the cautionary statements of Blalock,
Duncan, and others. In their defense, it should be noted that Blalock’s guidance was
confusing at times. When introducing regressionequations in his 1961 book, specified
as Yi=a+bXi+ei, where X is the causal variable of interest and Y is the outcome
variable of interest, Blalock stated the matter correctly and clearly:
What if there existed a major determinant of Y, not explicitly contained
in the regression equation, which was in fact correlated with some of the
8Goldberger(1972)andHeckman(2000)offerahistoryofusageineconomics,whichbeginsbefore
the history we offer for sociology. The biologist Sewall Wright (1925, 1934) deserves credit for the
earliestdevelopments (seeBollenandPearl2013;Pearl2009).

9Regression estimation of systems of linear causal models with observed variables should be
regardedasarestrictedformofthemoregeneralstructuralequationmodelingapproachthatBlalock,
Duncan,andothersintroducedintosociology(seeBollenandPearl2013foranexplanation,especially
their debunking of the myth“SEM andRegressionAreEssentiallyEquivalent”). In these earlyand
veryinfluentialpieces,BlalockandDuncanconsideredonlylinearcausalmodelswithobservedvari-
ables. Duncan(1966:7) clarified:“Asastatistical technique, therefore, neither pathanalysis northe
Blalock-Simonprocedureadds anything toconventional regressionanalysis asappliedrecursivelyto
generateasystemofequations.Asapatternofinterpretation,however,pathanalysisisinvaluablein
makingexplicittherationaleforasetofregressioncalculations.”Theliteraturemovedquicklyfrom
the late 1960s to consider overidentified models (see Duncan, Haller, and Portes 1968; Hauser and
Goldberger1971),afterwhichagenerallatentvariablestructuralequationmodelwasdeveloped(see
Bollen 1989). Nonetheless, the pattern of practice that elevated regressionto its dominant position,
we maintain, was shaped by these early pieces, as well as later work on interpreting the regression
coefficients estimated for basic linear path models with observed variables (e.g., Alwin and Hauser
1975).

10Forexample,comparethemethods(andsubstantivemotivations)inSewell(1964),withitsnon-
parametrictablestandardizationtechniques,toSewell,Haller,andPortes(1969),withitspathmodel
oftheentirestratificationprocess.

independent variables Xi? Clearly, it would be contributing to the error
term in a manner so as to make the errors systematically related to these
particular Xi. If we were in a position to bring this unknown variable into
the regressionequation, we would find that at least some of the regression
coefficients (slopes) would be changed. This is obviously an unsatisfactory
state of affairs, making it nearly impossible to state accurate scientific
generalizations. (Blalock 1964[1961]:47)
At other points in his book, however, Blalock characterized the same issue in ways
that encouragedmore permissive practice. He wrote at several points that the goal of
causal inference should not be too easily sacrificed:
Sinceitwillalwaysbepossiblethatsomeunknownforcesmaybeoperating
todisturbagivencausalrelationship,ortoleadustobelieveacausalrela-
tionship exists when in fact it does not, the only way we can make causal
inferences at all is to make simplifying assumptions about such disturbing
influences. (Blalock 1964[1961]:13)
We shall assume that error terms are uncorrelated with each other and
with any of the independent variables in a given equation....In non-
experimental studies involving nonisolated systems, this kind of assump-
tion is likely to be unrealistic. This means that disturbing influences must
be explicitly brought into the model. But at some point one must stop
and make the simplifying assumption that variables left out do not pro-
duceconfoundinginfluences.Otherwise,causalinferencescannotbe made.

(Blalock 1964[1961]:176)
And,eventhoughBlalockwasclearthatregressioncoefficientsareestimatedquantities
(and more fundamentally that the causal models that give regression equations their
specifications are subject to simplifying assumptions that may be unrealistic), he still
wrote about the resulting coefficients and equations in ways that would surely have
excited readers interested in powerful new ways to gain insight from observational
data:
It is the regression coefficients which give us the laws of science. (Blalock
1964[1961]:51)
In causal analyses our aim is to focus on causal laws as represented by
regressionequations and their coefficients. (Blalock 1964[1961]:177)11
Finally, in the concluding section of his book, he suggested,
The method for making causal inferences may be applied to models based
on a priori reasoning,or it may be used in exploratoryfashion to arriveat
models which give closer and closer approximations to the data. (Blalock
1964[1961]:179)
11Whenusingthislanguageofcausallaws,Blalockwasarguingforthecomparativevalueofmetric
regression coefficients, in contrast to standardized regression coefficients, and probably using this
causallawlanguagewithimplicitreferencetothecoveringlawmodelofexplanationthatwasdominant
inphilosophyofscienceatthetime.Hewasnotclaimingthatregressionisamethodforthediscovery
of causal laws. We maintain, nonetheless, that this sort of language had the potential to mislead
readers.

Given this type of guidance, it is not hard to imagine practitioners offering up
exploration-enhanced causal models, enabled by unrealistic simplifying assumptions,
and then writing about their regression coefficients as if causal laws had been uncov-
ered.

Duncan never failed to mention that assumptions about causal relationships must
begroundedintheoryandcannotberevealedbydata.Yet,asAbbott(2001[1998]:115)
notes, “Duncan was explicit in [The American Occupational Structure] ... about the
extreme assumptions necessary for the analysis, but repeatedly urged the reader to
bear with him while he tried something out to see what could be learned.” What
Duncan learned transformed the field, and it was thus hard to ignore the potential
power of the techniques to move the literature.

Duncan’s 1975 methodological text, Introduction to Structural Equation Models,
is appropriately restrained, with many fine discussions that echo the caution in the
abstract of his 1966 article. Yet he also encouraged widespread application of regres-
sion techniques to estimate causal effects, and at times he gave the impression that
researchersshould just get onwith it, as he did in The American Occupational Struc-
ture. For example, in his chapter 8, titled “Specification Error,” Duncan noted that
“it would require no elaborate sophistry to show that we will never have the ‘right’
model in any absolute sense” (Duncan 1975:101). But he then continued:
As the term will be used here, analysis of specification error relates to a
rhetoricalstrategy in which we suggest a model as the “true” one for sake
of argument, determine how our working model [the model that has been
estimated] differs from it and what the consequences of the difference(s)
are, and thereby get some sense of how important the mistakes we will
inevitablymakemaybe.Sometimesitispossibletosecuregenuinecomfort
by this route. (Duncan 1975:101–2)
Asiswidelyknown,Duncanlatercriticizedthewidespreadusageofregressionanalysis,
both in his 1984 book Notes on Social Measurement: Historical and Critical and in
private communication,in which he reminded many inside and outside of sociologyof
his long-standing cautionary perspective (see Xie 2007).

Finally, the emergent ease with which regression models could be estimated with
newcomputingpowerwasimportantaswell.NolongerwouldStoufferhaveneededto
concentrate on a seven-way cross-tabulation. Researchers could instead estimate and
then interpret only a few estimated regression slopes, rather than attempt to make
sense of the hundred or so cells that Stouffer often generated by subdivision of the
sample.Aage Sørensenhas giventhe most memorableindictment of the consequences
of this revolution in computing power:
With the adventof the high-speed computer,we certainly could study the
relationships among many more variables than before. More importantly,
we could compute precise quantitative measures of the strength of these
relationships. The revolution in quantitative sociology was a revolution in
statistical productivity. Social scientists could now calculate almost every-
thing with little manual labor and in very short periods of time. Unfor-
tunately, the sociological workers involved in this revolution lost control
of their ability to see the relationship between theory and evidence. Soci-
ologists became alienated from their sociological species being. (Sørensen
1998:241)
As this quotation intimates, enthusiasm for regression approaches to causal inference
had declined dramatically by the mid-1990s. Naive usage of regression modeling was
blamed for nearly all the ills of sociology, everything from stripping temporality and
context from the mainstream (see Abbott 2001 for a collections of essays), the sup-
pression of attention to explanatory mechanisms (see Goldthorpe 2001 and Hedstrm
2005), the denial of causal complexity (see Ragin 1987, 2008), and the destruction of
mathematical sociology (Sørensen 1998).

It is unfair to lay so much at the feet of least squares formulas, and we will argue
laterthatregressioncanbeputtoworkquitesensiblyinthepursuitofcausalquestions.

However, the critique of regression-based practice was largely on target. For causal
analysis, the rise of regression led to a focus on estimated equations for outcomes,
rather than careful thinking about how the data in hand differ from what would
have been generated by the ideal experiments one might wish to have conducted.

This sacrifice of attention to experimental thinking might have been reasonable if the
outcome-equationtraditionhadledresearcherstospecifyandthencarefullyinvestigate
the plausibility of alternative explanatory mechanisms that generate the outcomes of
theequations.But,instead,itseemsthatresearchersalltoooftenchosenottodevelop
fully articulated mechanisms that generate outcomes and chose to simply act as if
estimated regression equations somehow mimic appreciably well (by a process not
amenable to much analysis) the experiments that researchers might otherwise have
wished to undertake.

Largely independent of these critiques, the potential outcome model for observa-
tionaldata analysishas achievedsuccessinthe pasttwodecades inthe socialsciences
because it brings experimental language back into observational data analysis. But it
does soin the waythat Stouffer used it: asa frameworkin whichto ask carefully con-
structed what-if questions that lay bare the limitations of observational data and the
need to clearly articulate assumptions that are believable because they are grounded
in theory that is defendable.

Consider the motivating questions in the opening paragraph of this book, which
weposedto drawinreaderswho arenotyetutilizing the counterfactualmodel.These
questions are stated in the traditional style of
Does X cause Y?
If X causes Y, how large is the effect of X on Y?
Thecounterfactualmodelencouragesthe formulationofmoreprecisecausalquestions
with clear counterfactual contrasts, such as
If individuals with X=x(cid:2) had instead had X=x(cid:2)(cid:2), how much would their
value for Y have changed?
Forexample,ratherthanaskthequestion“Doesobtainingacollegedegreeincreasean
individual’slabormarketearnings?,”the counterfactualmodelencouragesresearchers
to ask two questions:
1.Ifhighschoolgraduateshadinsteadobtainedcollegedegrees,howmuch
would their labor market earnings have changed?
2. If college graduates had only obtained high school diplomas, how much
would their labor market earnings have changed?
For these two particular questions, the empirical literature suggests that the answers
differ in magnitude, suggesting that important heterogeneity exists in the individual-
level causal effects that underlie them. Such differences are of theoretical interest to
researchers and of practical value to policymakers, and they are obscured by gen-
eral cause-and-effect questions without clear and specific counterfactual states. This
book is grounded on the position that social scientists ought to use a conceptual and
methodological framework that encourages the asking and answering of rigorously
posed questions such as these.

## 1.3 Examples Used Throughout the Book

In this section, we offer background on the main substantive examples that we will

draw on throughout the book when discussing the methods and approach abstractly
andthenwhendemonstratingparticularempiricalanalysisstrategies.Wefirstpresent
five broad foundational examples that have guided empirical research in the social,
demographic,andhealthsciencesfordecades.Wethenpresenteightnarrowerexamples
that are at the frontier of current research, all of which can be addressed using the
counterfactual model.

1.3.1 Broad Examples from the Social, Demographic,
and Health Sciences
We first outline three prominent classic examples that, in spite of their distinct disci-
plinaryorigins,arerelatedtoeachother:(1)thecausaleffectsoffamilybackgroundand
mental ability on educational attainment, (2) the causal effects of educational attain-
ment and mental ability on earnings, and (3) the causal effects of family background,
educational attainment, and earnings on political participation. These examples are
classic and wide-ranging, having been developed, respectively, in the formative years
of observational data analysis in sociology, economics, and political science. We then
presenttwobroadexamplesfromtheinterdisciplinarysocial,demographic,andhealth
sciences: (4) the causal effects of family backgroundand life course events on fertility
patterns and (5) the causal effects of socioeconomic status on health and mortality.

The Causal Effects of Family Background and Intelligence on
Educational Attainment
In the status attainment tradition in sociology, as pioneered by Blau and Duncan
(1967), family background and mental ability are considered to be ultimate causes of
educationalattainment.Thisclaimisgroundedonthepurportedexistenceofaspecific
causalmechanismthat relates individuals’expectations and aspirationsfor the future
to the social contexts that generate them. This particular explanation is most often
identified with the Wisconsin model of status attainment, which was based on early
analyses of the Wisconsin Longitudinal Survey (see Sewell, Haller, and Portes 1969;
Sewell, Haller, and Ohlendorf 1970).

According to the original Wisconsin model, the joint effects of high school stu-
dents’ family backgrounds and mental abilities on their eventual educational attain-
ments can be completely explained by the expectations that others hold of them. In
particular,significantothers–parents,teachers,andpeers–defineexpectationsbased
on students’ family backgroundand observable academic performance. Students then
internalize the expectations crafted by their significant others. In the process, the
expectations become individuals’ own aspirations, which then compel achievement
motivation.

The implicit theory of the Wisconsin model maintains that students are com-
pelled to follow their own aspirations. Accordingly, the model is powerfully simple,
as it implies that significant others can increase high school students’ future educa-
tional attainments merely by increasing their own expectations of them.12 Critics of
thisstatusattainmentperspectivearguedthatstructuralconstraintsembeddedinthe
opportunity structure of society should be at the center of all models of educational
attainment, and hence that concepts such as aspirations and expectations offer little
or no explanatory power. Pierre Bourdieu (1973) dismissed all work that asserts that
associations between aspirations and attainments are causal. Rather, for Bourdieu,
the unequal opportunity structures of society “determine aspirations by determining
the extent to which they can be satisfied” (Bourdieu 1973:83). And, as such, aspi-
rations have no autonomous explanatory power because they are nothing other than
alternative indicators of structural opportunities and resulting attainment.

Research on the relationships between family background and educational attain-
ment is now vast, especially in economics and sociology (see Ehrenberg 2004; Morgan
2005; Stevens, Armstrong, and Arum 2008). Scholars disagree on the effects of the
resource constraints imposed by disadvantaged family backgrounds, the role of indi-
vidual choices in response to incentives, the importance of beliefs about the oppor-
tunity structure, and features of the institutions that must be navigated (see Breen
and Johnson 2005; Heckman 2008a; Holmlund, Lindahl, and Plug 2011; Hoxby 2004;
Jackson2013; Morgan, Leenman, Todd, and Weeden 2013).

The Causal Effects of Educational Attainment and Mental Ability on
Earnings
The economic theory of human capital maintains that education has a causal effect
on the subsequent labor market earnings of individuals. The theory presupposes that
educationaltrainingprovidesskillsthatincreasethepotentialproductivityofworkers.

Because productivity is prized in the labor market, firms are willing to pay educated
workers more.

Theseclaimsarelargelyacceptedwithineconomics,butconsiderabledebateremains
over the size of the causal effect of education. In reflecting on the first edition of his
12See Hauser, Warren, Huang, and Carter (2000) for the latest update of the original model and
Sewell,Hauser,Warren,andHauser(2004) forareviewoftheentireresearchtradition.

bookHuman Capital, whichwaspublishedin1964,GaryBeckerwrotenearly30years
later:
Educationandtrainingarethemostimportantinvestmentsinhumancap-
ital.Mybookshowed,andsohavemanyotherstudiessincethen,thathigh
school and college education in the United States greatly raise a person’s
income, even after netting out direct and indirect costs of schooling, and
after adjusting for the better family backgrounds and greater abilities of
moreeducatedpeople.Similarevidenceisnowavailableformanypointsin
timefromoveronehundredcountrieswithdifferentculturesandeconomic
systems. (Becker 1993[1964]:17)
The complication, hinted at in this quotation, is that economists also accept that
mental ability enhances productivity. Thus, because those with relatively high ability
areassumedtobemorelikelytoobtainhighereducationaldegrees,thehighlyeducated
are presumed to have higher innate ability and higher natural rates of productivity.

As a result, some portion of the purported causal effect of education on earnings may
instead reflect innate ability rather than any productivity-enhancing skills provided
by educational institutions (see Willis and Rosen 1979).

The degreeof “ability bias” in standardestimates of the causal effect of education
on earnings has remained one of the largest causal controversiesin the social sciences
since the 1970s (see Card 1999). Scholars continue to disagree on the magnitude of
biases in traditional estimates, and debate has also developed on the variability of
returns that may be related to underlying cognitive ability and other individual char-
acteristics (see Cunha and Heckman 2007; Brand and Xie 2010; Carneiro, Heckman,
and Vytlacil 2011; Hout 2012).

The Causal Effects of Family Background, Educational Attainment, and
Earnings on Political Participation
Thesocioeconomicstatusmodelofpoliticalparticipationassertsthateducation,occu-
pational attainment, and income predict strongly most measures of political partici-
pation (see Verba and Nie 1972). Critics of this model maintain instead that political
interests and engagement determine political participation, and these are merely cor-
relatedwiththemaindimensionsofsocioeconomicstatus.13 Inotherwords,thosewho
have a predilection to participate in politics are likely to show commitment to other
institutions, such as the educational system.

Verba, Schlozman, and Brady (1995) later elaborated the socioeconomic status
model, focusing on the contingent causal processes that they argue generate patterns
ofparticipationthroughtheresourcesconferredbysocioeconomicposition.Theyclaim
that
interest, information, efficacy, and partisan intensity provide the desire,
knowledge, and self-assurance that impel people to be engaged by poli-
tics. But time, money, and skills provide the wherewithal without which
13Thisinterestmodelofparticipationhasanequallylonglineage.Lazarsfeld,Berelson,andGaudet
(1955[1948]:157) write that, in their local sample, “the difference in deliberate non-voting between
peoplewithmoreorlesseducation canbecompletelyaccounted forbythenotionofinterest.”
engagementismeaningless.Itisnotsufficienttoknowandcareaboutpoli-
tics.Ifwisheswereresources,thenbeggarswouldparticipate.(Verbaetal.

1995:355–56)
They reachthis conclusionthrough a series of regressionmodels that predict political
participation. They use temporal order to specify causal order, and they then claim
to eliminate alternativetheories that emphasize political interests andengagementby
showing that these variables have relatively weak predictive power in their models.

Moreover, they identify education as the single strongest cause of political par-
ticipation. Beyond generating the crucial resources of time, money, and civic skills,
educationshapes preadultexperiences andtransmits differences infamily background
(see Verba et al. 1995, figure 15.1). Education emerges as the most powerful cause
of engagement because it has the largest net association with measures of political
participation.

Nie, Junn, and Stehlik-Barry (1996) then built on the models of Verba and his
colleagues, specifying in detail the causal pathways linking education to political par-
ticipation. For this work, the effects of education, family income, and occupational
prominence (again, the three basic dimensions of socioeconomic status) on voting
frequency are mediated by verbal proficiency, organizational membership, and social
network centrality.Nie et al. (1996:76)note that these variables “almostfully explain
the original bivariate relationship between education and frequency of voting.”
Currentresearchcontinuestoinvestigatetheserelationships,especiallytheeffectof
educationon participation.Some studies havefocused attention on relativeeducation
(e.g., Tenn 2005), while others have questioned whether the effect is genuine at all
(Berinsky and Lenz 2011; Highton 2009; Kam and Palmer 2008, 2011). As often hap-
pens in causal controversies, the latter research prompted additional effort to restore
theoriginalclaim(HendersonandChatfield2011;Mayer2011;SondheimerandGreen
2010).14
The Causal Effects of Family Background and Life Course Events on
Fertility Patterns
Through the analysis of population trends in the nineteenth and early twentieth cen-
turies, demographers developed the concept of a “demographic transition,” during
which countries move in comparativelyshort periods of time from population regimes
ofhighfertility andhighmortalitytowardthoseoflowfertility andlowmortality(see
Davis1945;Thompson1949;Notestein1950).RonaldLeecharacterizestheworldwide
march of country-specific transitions as “Three Centuries of Fundamental Change”:
Before the start of the demographic transition, life was short, births were
many, growth was slow and the population was young. During the transi-
tion, first mortality and then fertility declined, causing population growth
14Perhapsthemostwidelyknownrecentpoliticalparticipationstudiesarethosethatdonotfocuson
theeffectsofstablebackgroundcharacteristicsofindividuals.Researchon“GetOuttheVote”oper-
ations shows, for example, that social pressureissurprisinglyeffective (Gerber, Green, and Larimer
2008;Davenport,Gerber,Greenetal.2010),whileattackadvertisementsbroadcastontelevisionare
lesseffectivethanmanyhaveassumed(KrasnoandGreen2008).

rates first to accelerate and then to slow again, moving toward low fertil-
ity,longlifeandanoldpopulation.Thetransitionbeganaround1800with
declining mortality in Europe. It has now spread to all parts of the world
and is projected to be completed by 2100. (Lee 2003:167)
Althoughthesetrendshaveinspiredmanystrandsofliteratureindemography,wewill
use as our broad example the interconnected causes that are typically examined for
differences in fertility rates, both over time and across groups, focusing mostly on the
literature on fertility in the first group of industrializing countries to experience the
demographic transition.15
Early studies document differences in fertility rates by immigrant status, geo-
graphicregion,urban–rurallocation,andsocialclass(seeDinkel1952;Karpinos1938;
Notestein 1933; Rose 1942; Thompson 1948; Whelpton 1932), often using causal lan-
guage, for example, “the birth rate for married couples not separating during the
migration was higher after they came to the United States than it would have been
hadthey remainedinItaly”(Rose1942:621).Mostofthis literatureisconcernedwith
how fertility differences varywith family background,typically acrosssocialclassesas
measured by the occupations of husbands. Analyzing trends during a time when the
eugenics movement had not yet fully receded, Notestein (1933:22)concludes:
At present the white collar classes are not reproducing rapidly enough to
maintainequalpermanentreplacement,buttheunskilledlaborerclassand
the agricultural populationappear to be reproducing more rapidly than is
required to maintain their numbers. (Notestein 1933:33)
Notesteinoffersempiricalmodelstosupportthepositionthatsomeofthesedifferences
can be attributed to the effects of age at marriage, but he also notes the possibility
that “in the young marriages of the professional class fertility was purposefully and
effectively controlled even prior to 1910” (Notestein 1933:25).

Although this early literature considers the timing of marriage and the possibility
of differential patterns of overt birth control, it does not consider the full range of
gender-related mechanisms that with hindsight were obviously at play. After correc-
tives were offered in subsequent literature, newly available individual-level data have
allowed demographers to model the consequences of changing rates of female labor
force participation (see Brewster and Rindfuss 2000 for a review), changes in birth
controlpractices(WestoffandBumpass1973;GoldinandKatz2002),andsomeofthe
deeper contingencies of related life course events, such as how age and marital status
at first birth structure later fertility (Bumpass, Rindfuss, and Janosik 1978; see also
Morgan and Rindfuss 1999).

Studiesthatexaminefamilybackgrounddifferencesinfertility,asindexedbysocial
class, are less common in current research, having been supplanted by the study of
therelationshipbetweeneducationalattainmentandfertility,asconditionedbyfamily
15Although there is considerable debate on the role of causal analysis in demographic research
(see Duncan 2008; Engelhardt, Kohler,and Prskawetz 2009; Moffitt2005; N´ıBhrolcha´inandDyson
2007; Smith1989, 2009, 2013; Xie2011), wedonotseedemographyas inherentlydifferentthanthe
other domains of observational research considered in this book. However, it may be the case that
demography has a special additional burden of documenting social and demographic patterns that
donotdependonanyparticularcausal assumptions.

background of origin (see Brand and Davis 2011; Musick, England, Edgington, and
Kangas 2009). This more contemporary literature also takes full account of the dis-
tinct patterns of marital and nonmarital fertility (see Musick 2002; Musick, England,
Edgington, and Kangas 2009; Seltzer, Bachrach, Bianchi et al. 2005; Wu 1996, 2008;
Wu and Wolfe 2001).

The Causal Effects of Socioeconomic Status on Health and Mortality
In reaction to the traditional focus of epidemiology on the proximate direct causes of
disease and mortality, a group of social epidemiologists has advanced the case that
socioeconomic status should be considered a fundamental cause of health disparities
across the life course, generating robust and recurrent associations between socioeco-
nomic status and both health and mortality (Link and Phelan 1995; Phelan, Link,
Diez-Rouxet al.2004;Phelan,Link, andTehranifar2010).Here,the three traditional
dimensionsofsocioeconomicstatus–education,income,andoccupation–areallcon-
sideredtobe active(see AdlerandNewman2002).Lutfey andFreesecharacterizethe
nature of the posited causal relationship:
If an explanatory variable is a fundamental cause of an outcome, then
the associationcannot be successfully reduced to a set of more proximate,
intervening causes because the association persists even while the relative
influence of various proximate mechanisms changes. (Lutfey and Freese
2005:1328)
Socioeconomic status is therefore a fundamental cause, according to this perspective,
because it is a paramount distal determinant of health that activates alternative and
replaceable causal pathways, such as those that arise through differential access to
quality health care, knowledge about health innovations, and propensity to engage
in risky health behaviors (see Cawley and Ruhm 2012; Fiscella, Franks, Gold, and
Clancy 2000; Pampel, Krueger, and Denney 2010). Thus, while health may improve
on average for all, socioeconomic disparities may persist, or even grow, because those
who are disadvantaged by low education, low income, or lack of employment are less
able to take advantage of improvements in health care.

Eachofthese fivebroadexamples,asnotedearlier,isconcernedwithrelationships
that unfold over the life course of the majority of individuals in most industrialized
societies. As such, these examples encompass some of the most important early sub-
stantive scholarship in sociology, economics, and political science as well as the latest
frontiers of research at the interdisciplinary nexus of social, demographic, and health
science.Atthe sametime, however,theseexamplesposesomefundamentalchallenges
forcausalanalysis:measurementcomplicationsandpotentialnonmanipulabilityofthe
causes of interest. Each of these deserves some comment before the narrowerand less
complicated examples that follow are introduced.

First, the purported causal and outcome variables in these models are sometimes
highly abstract and internally differentiated. Consider the political science example.

Political participation takes many forms, from volunteer work to financial giving and
voting. Each of these, in turn, is itself heterogeneous, given that individuals can con-
tribute episodically and vote in only some elections. Furthermore, family background
andsocioeconomicstatusincludeatleastthreeunderlyingdimensions:family income,
parental education, and occupational position. But other dimensions of advantage,
such as wealth and family structure, must also be considered, as these are thought to
be determinantsofbothanindividual’seducationalattainmentandalsothe resources
that supposedly enable political participation.16
Scholars who pursue analysis of these causal effects must therefore devote sub-
stantial energy to the development of measurement scales. Although very important
to consider, in this book we will not discuss measurement issues so that we can focus
closelyoncausaleffectestimationstrategies.But,ofcourse,itshouldalwaysberemem-
bered that, in the absence of agreement on issues of how to measure causes and their
outcomes,fewcausalcontroversiescanberesolved,nomatterwhatestimationstrategy
seems best to adopt.

Second,mostoftheseexamplesexaminecausaleffectsforindividualcharacteristics
that are not easily manipulable through external intervention. Or, more to the point,
evenwhentheyaremanipulable,anysuchinducedvariationmaydifferfundamentally
fromthe naturallyoccurring(orsociallydetermined)variationwithwhichthe models
aremostdirectlyconcerned.Forexample,familybackgroundcouldbemanipulatedby
somehow convincing a sample of middle-class and working-class parents to exchange
their children at particular well-chosen ages, but the subsequent outcomes of this
induced variation may not correspond to the family background differences that the
original models attempt to use as explanatory differences.

Aswe will discusslater,whethernonmanipulability ofa causepresentsa challenge
to an observationaldata analystis a topic of continuing debate in the methodological
andphilosophicalliterature.We will discussthis complicationatseveralpoints inthis
book,including a section inthe concluding Chapter 13(see pages439–441), where we
arguethatcriticshaveoveremphasizedthis concern.But,giventhatthe measurement
andmanipulability concernsofthese broadexamplespresentchallengesatsome level,
wealsodrawonmorenarrowexamplesthroughoutthebook,aswediscussinthenext
section. For these examples, measurement is generally less controversialand potential
manipulability is more plausible (and in some cases is completely straightforward).

1.3.2 Narrow and Specific Examples
In this section, we present additional examples that we will use at multiple points
throughoutthebook:thecausaleffectsofneighborhoodofresidenceandfatherabsence
on child development, educational performance, and deviance in adolescence; the
causal effects of Catholic schooling, school vouchers, and charter schools on learn-
ing; the causal effect of worker training on earnings; the causal effects of risky health
behaviors and peer relationships on obesity and mortality; and the causal effects of
alternative voting technology on valid voting and election outcomes.These additional
16Moreover,education asacauseissomewhatungainlyaswell.Foreconomists whowishtostudy
the effects of learned skills on labor market earnings, simple variables measuring years of education
obtainedareoversimplifiedrepresentations ofhumancapital.

examplesaremorespecific, andoftenmorerecent,versionsofthe fivebroadexamples
presented in the last section.

The Causal Effects of Neighborhood of Residence on Educational
Performance, Deviance, and Youth Development
Working within the broad tradition of research on educational attainment and the
transitionto adulthood, social scientists have investigatedthe effects of neighborhood
of residence since at least the 1980s (see Jencks and Mayer 1990 for a review of the
early research). Reflecting on his four decades of research on neighborhoods, William
Julius Wilson writes of one such possible effect:
[O]ne of the significant arguments in When Work Disappears is that a
neighborhood in which people are poor and working is significantly dif-
ferent from a neighborhood in which people are poor and jobless. Jobless
neighborhoods create special problems, exacerbating conditions that rein-
force racial stereotypes and prejudices. High rates of joblessness trigger
other problems in the neighborhood ranging from crime, gang violence,
and drug trafficking to family breakups and other disruptions in the orga-
nization of family life. (Wilson 2011:10)
Theeffectsofneighborhoodshaveprovenpersistentlydifficulttoestimate.Individuals
make systematic but constrained residential choices, and analysts rarely have suffi-
cient information to model their choices effectively. Furthermore, neighborhoods have
many characteristics,and individuals living within them can be influenced to varying
degrees by circumstances only partly under their own control. For young residents of
neighborhoods, these effects may be even more complex:
Neighborhoods are not static features of a child’s life; instead, neighbor-
hoodschangeovertimeaschildrenmovethroughdifferentperiodsofdevel-
opment, providing unique risks and opportunities at each stage. It follows
that neighborhoods have the potential to alter developmentaltrajectories,
and that their influence may be laggedor cumulative. (Sampson, Sharkey,
and Raudenbush 2008:851–52)
Researchers have considered the effects of neighborhoods on a range of outcomes for
children and adolescents (see Harding, Gennetian, Winship et al. 2011 for a review).

The ensuing debates have not been settled by first-rate observational data analysis
(e.g., Harding 2003; Sharkey and Elwert 2011; Sampson 2012) or by large-scale social
experimentation(seeGennetian,Sanbonmatsu,Katzetal.2012;Kling,Liebman,Katz
2007; Kling, Ludwig, and Katz 2005; Sampson 2008).

The Causal Effects of Father Absence on Child and Adolescent
Development
Bridging work on family background effects with work in family demography, social
scientistshaveconsideredtheconsequencesoffamilystructureforchildandadolescent
development (see McLanahan 2004, 2009; McLanahan and Percheski 2008; Wu and
Wolfe 2001). The most prominent strand of this research began as an effort to assess
the effect of growing up as the child of a single parent (McLanahan and Sandefur
1994), during a period when single parenthood was on the rise and the subject of
intense political debate.

Recently,the literature has come to focus more specifically on father absence.In a
review of the latest research, McLanahan and her colleagues conclude:
We find strong evidence that father absence negatively affects children’s
social-emotional development, particularly by increasing externalizing
behavior. These effects may be more pronounced if father absence occurs
duringearlychildhoodthanmiddle childhood, andthey maybe morepro-
nounced for boys than for girls. There is weaker evidence of an effect of
father absence on children’s cognitive ability.

Effects on social-emotional development persist into adolescence, for
which we find strong evidence that father absence increases adolescents’
risky behavior, such as smoking or early childbearing. The evidence of
an effect on adolescent cognitive ability continues to be weaker, but we
do find strong and consistent negative effects of father absence on high
school graduation. The latter finding suggests that the effects on educa-
tional attainment operate by increasing problem behaviors rather than by
impairing cognitive ability. (McLanahan, Tach, and Schneider 2013:422)
A rich array of models has been used to generate estimates of these effects, and yet
some controversy remains over how substantial these effects are and whether they
should instead be attributed to unmeasured environmental characteristics of families,
schools, and neighborhoods, including the complexity of events that often co-occur
with father absence.

The Causal Effect of Catholic Schooling on Learning
James S. Coleman and his colleagues presented evidence that Catholic schools are
more effective than public schools in teaching mathematics and reading to equivalent
high school students (see Coleman and Hoffer 1987; Coleman, Hoffer, and Kilgore
1982; Hoffer, Greeley, and Coleman 1985). Their findings were challenged vigorously
by other researchers, who argued that public school students and Catholic school
students are insufficiently comparable, even after adjustments for family background
and measured motivation to learn (see Alexander and Pallas 1983, 1985; Murnane,
Newstead, andOlsen1985;Noell 1982;Willms 1985;see Bryk,Lee,and Holland1993
for a summary of the debate). Although the challenges were wide ranging, the most
compellingargumentraised(andthatwasforeseenbyColemanandhiscolleagues)was
that students who are most likely to benefit from Catholic schooling are more likely
to enroll in Catholic schools net of all observable characteristics. Thus, self-selection
on the causal effect itself may generate a mistakenly large apparent Catholic school
effect.IfstudentsinsteadwereassignedrandomlytoCatholicandpublicschools,both
types of schools would be shown to be equally effective on average.

To address the possibility that self-selection dynamics create an illusory Catholic
school effect, a later wave of studies then assessedwhether or not naturally occurring
experimentswereavailablethatcouldbeusedtomoreeffectivelyestimatetheCatholic
school effect. Using a variety of variables that predict Catholic school attendance
(e.g., share of the local population that is Catholic) and putting forth arguments for
whythese variablesdonotdirectlydetermineachievement,EvansandSchwab(1995),
Hoxby(1996),andNeal(1997)generatedsupportforColeman’soriginalconclusions.17
More recent research has considered whether the Catholic school effect still exists
inthe twenty-firstcentury,generatingsimilarresultswithalternativeandmorerecent
data sources (see Carbonaro and Covay 2010; Morgan and Todd 2008; West and
Woessmann 2010). Similar recent research demonstrates that the case for a Catholic
schooleffect at the primary and middle school levels is considerably weaker (Hallinan
and Kubitschek 2012; Jepsen 2003; Reardon, Cheadle, and Robinson 2009).

The Causal Effect of School Vouchers on Learning
InresponsetoaperceivedcrisisinpubliceducationintheUnitedStates,policymakers
haveintroduced publicly funded schoolchoice programsinto some metropolitan areas
inanefforttoincreasecompetitionamongschoolsontheassumptionthatcompetition
will improve school performance and resulting student achievement (see Chubb and
Moe 1990; see also Fuller and Elmore 1996). Although these school choice programs
differbyschooldistrict,theprototypicaldesignisthefollowing.Asetnumberof$3,000
tuitionvouchersredeemable atprivate schoolsaremade availabletostudents resident
in the public school district, and all parents are encouraged to apply for one of these
vouchers.The vouchersare then randomlyassignedamong those who apply. Students
who receive a voucher remain eligible to enroll in the public school to which their
residence status entitles them. But they can choose to enroll in a private school. If
they choose to do so, they hand over their $3,000 voucher but may then be required
to pay top-up tuition and fees.

Thecausaleffectsofinterestresultingfromtheseprogramsarenumerous.Typically,
evaluators are interested in the achievement differences between those who attend
privateschoolsusingvouchersandothersuitablecomparisongroups.Mostcommonly,
thecomparisongroupisthegroupofvoucherapplicantswholostoutinthelotteryand
endedupinpublicschools(seeHowellandPeterson2002;Hoxby2003;Ladd2002;Neal
2002).And,eventhoughthesesortsofcomparisonsmayseementirelystraightforward,
the published literature shows that considerable controversy surrounds how best to
estimate these effects, especially given the real-world complexity that confronts the
implementationofrandomizationschemes(seeJin,Barnard,andRubin2010;Krueger
and Zhu 2004; Peterson and Howell 2004).

For this example, other effects are of interest as well. A researcher might wish to
know how the achievement of students who applied for vouchers but did not receive
them changed in comparison with those who never applied for vouchers in the first
place(asthiswouldbecrucialforunderstandinghowtheself-selectinggroupofvoucher
applicants may differ from other public school students). More broadly, a researcher
mightwishtoknowtheexpectedachievementgainthatwouldbeobservedforapublic
17See Cohen-Zada and Elder (2009) for a similar instrumental variable approach that is less sup-
portiveofColemanandcolleagues’ resultsfortestscores.SeealsoAltonji,Elder,andTaber(2005a,
2005b).

school student who was randomly assigned a voucher irrespective of the application
process. This goal would necessitate altering the voucher assignment mechanism, and
thusithasnotbeenanobjectofresearch.Finally,themarketcompetitionjustification
forcreatingtheseschoolchoicepoliciesimpliesthattheachievementdifferencesofpri-
mary interest are those among public school students who attend voucher-threatened
public schools (i.e., public schools that feel as if they are in competition with private
schoolsbutthatdidnotfeel asifthey wereincompetitionwith privateschoolsbefore
the voucher program was introduced).

The Causal Effect of Charter Schools on Learning
Complementing the school voucher example, we will also consider as an additional
example the contentious research on charter schooling in the United States. In an
excellent book on recent academic and public debates on the effectiveness of charter
schools, Henig (2008:2) introduces and defines charter schools in the following way:
Justa little morethanfifteen yearssince the firstcharterschoolopenedin
Minnesota,therearenownearly4,000nationwide,servinganestimated1.1
million students....The laws governing charter schools differ – sometimes
substantially–fromstatetostate,ofcourse,butsomegeneralcharacteris-
tics haveemerged.Charterschoolsreceivepublic funding onaper-student
basis, are often responsible for achieving educational outcomes defined by
their government chartering entity, and are subject to at least nominal
public oversight. They typically are barred from charging tuition on top
of the public per-pupil allocation, but are free to pursue other forms of
supplementary support from donors, foundations, or corporate sponsors.

Although they must observe certain baseline regulations, such as prohibi-
tions on discrimination and the provision of safe environments, they are
exempt from many of the rules and regulations that bind regular pub-
lic schools to specific standards and procedures. This hybrid status...has
made charter schools a special focus of attention and helped draw them
into ideological whirlpools that raise the stakes surrounding the research
into their actual form and consequences.

At their core,the centralresearchquestions inthe charterschooldebate aresimple to
state(andidenticalinstructuretothoseoftheothertwoschoolingexamplespresented
above): Do students who attend charter schools perform better on standardized tests
than they would have performed if they had instead attended regular public schools?
Wouldstudentswhoattendregularpublicschoolsperformbetteronstandardizedtests
if they had instead attended charter schools?
The contentious research that has addressed these questions is distinguished in
many respects (see Abdulkadiroglu, Angrist, Dynarski et al. 2011; Angrist, Dynarski,
Kaneetal.2010;CenterforResearchonEducationalOutcomes2009;Hoxby,Murarka,
and Kang 2009; Tuttle, Gill, Gleason et al. 2013). Not only are some of its combat-
ants leading researchers at the nation’s top universities, many of them are unusually
ideological (as Henig shows brilliantly in his book). Their scholarly energy and policy
advocacyis amplifiedby the public attentionthat hasbeen paidto charterschoolsby
the national press, which is related to the support that charter schools have received
from celebrity donors and from recent presidential aspirants. At the same time, the
researchthatinforms the debate is cutting-edge inthe bestsense.Carefulattentionis
paidtodetailsofmeasurement,andtheresearchdesignsthathavebeenadoptedarea
healthy mixture of basic comparisonsofachievementlevels as well as daring attempts
to leverage quasi-experimental variation from the ways in which charter school pro-
gramsareadministered(e.g.,usinglotteried-outstudentsforcomparisongroups,when
such groups exist).

What makes estimating the effects of charter schools complex, perhaps even more
so than for the Catholic schooleffect and the school voucherseffect, is the underlying
heterogeneityoftherealworld.Theprocessbywhichsomestudentsbecomeenrolledin
charterschoolsisonlypartlyobserved.Atthesametime,charterschoolsdiffergreatly
from each other, such that the effect of charter schooling must surely vary because of
qualitydifferences,aswellasthe matchbetweeneachstudentandthe unique features
of each charter school.

The Causal Effect of Worker Training on Earnings
The United States federal government has supported worker training programs for
economicallydisadvantagedcitizens fordecades (see LaLonde1995).Througha series
oflegislative renewals, these programshave evolvedsubstantially, and programevalu-
ations have become an important areaof applied work in labor and public economics.

The services provided to trainees differ and include classroom-based vocational edu-
cation, remedial high school instruction leading to a general equivalency degree, and
on-the-job training (or retraining) for those program participants who have substan-
tial prior work experience. The types of individuals served by these programs are
heterogeneous,including ex-felons,welfarerecipients,andworkersdisplacedfromjobs
by foreign competition. Accordingly, the causal effects of interest are heterogeneous,
varying with individual characteristics and the particular form of training provided.

Evenso, some common challengeshave emergedacrossmost programevaluations.

Ashenfelter (1978) discovered what has become known as “Ashenfelter’s dip,” con-
cluding after his analysis of training-programdata that
all of the trainee groups suffered unpredicted earnings declines in the year
prior to training....This suggests that simple before and after compar-
isonsoftraineeearningsmaybeseriouslymisleadingevidence.(Ashenfelter
1978:55)
Because trainees tend to have experienced a downward spiral in earnings just before
receivingtraining,the wagesoftraineeswouldrisetosomedegreeeveninthe absence
ofanytraining.AshenfelterandCard(1985)thenpursuedmodelsofthese“meanrever-
sion”dynamics,demonstratingthatthesizeoftreatmenteffectestimatesisafunction
ofalternativeassumptionsaboutpre-trainingearningstrajectories.Theycalledforthe
construction of randomized field trials to improve programevaluation.

LaLonde (1986) then used results from program outcomes for the National Sup-
ported Work (NSW) Demonstration, a program from the mid-1970s that randomly
assigned subjects to alternative treatment conditions. LaLonde argued that most of
the econometric techniques used for similar program evaluations failed to match the
experimental estimates generated by the NSW data. Since LaLonde’s 1986 paper,
economists and statisticians have continued to refine procedures for evaluating both
experimental and nonexperimentaldata from training programs,focusing in detail on
how to model the training selection mechanism (see Frumento, Mealli, Pacini, and
Rubin 2012; Heckman, LaLonde, and Smith 1999; Heckman and Vytlacil 2005, 2007;
Smith and Todd 2005; Zhang, Rubin, and Mealli 2008, 2009).

The Causal Effects of Risky Health Behaviors and Peer Relationships
on Obesity and Mortality
Health scientists are increasingly concerned with the worldwide increase in obesity
rates (see Swinburn, Sacks, Hall et al. 2011). In the United States, social scientists
havedevotedconsiderableenergytounderstandingtheinterrelationshipsbetweenrisky
healthbehaviorsthataresometimesreferredtoasmodifiableriskfactorsformortality
(see Cawley and Ruhm 2012; Pampel, Krueger,and Denney 2010). Although declines
inmostriskybehaviorsareevidentsince the 1970s,especially inratesofsmoking,the
gains to health from these trends have been mitigated by a concomitant increase in
obesity over the same time period (see Stewart, Cutler, and Rosen 2009).

Many causal controversies exist in efforts to assess the causes and consequences
of obesity (see Cawley 2011), but the most vigorously debated has been the claim
that obesity is contagious. In a large study of a networked community over 32 years,
Christakis and Fowler conclude:
Our study suggests that obesity may spread in social networks in a quan-
tifiable and discernable pattern that depends on the nature of social ties.

Moreover, social distance appears to be more important than geographic
distance within these networks. Although connected persons might share
an exposure to common environmental factors, the experience of simulta-
neous events, or other common features (e.g., genes) that cause them to
gain or lose weight simultaneously, our observations suggest an important
role for a process involving the induction and person-to-person spread of
obesity....Obesity in alters might influence obesity in egosby diverse psy-
chosocialmeans,suchas changingthe ego’snorms about the acceptability
of being overweight, more directly influencing the ego’s behaviors (e.g.,
affecting food consumption), or both. Other mechanisms are alsopossible.

(Christakis and Fowler 2007:377)
Many other scholars have objected to these claims (e.g., Shalizi and Thomas 2011),
andtheirobjectionshavebeenaddressedbycounterargumentsandadditionalanalyses
(e.g., Christakis and Fowler 2013; VanderWeele 2011b).

The Causal Effect of Voting Technology on Valid Voting and Election
Outcomes
For specific causal effects embedded in the larger political participation debates, we
could focus on particular decision points – the effect of education on campaign con-
tributions, net of income, and so on. However, the politics literature is appealing in
another respect: outcomes in the form of actual votes cast and subsequent election
victories. These generate finely articulated counterfactual scenarios.

Althoughrecentresearchhasconsideredabroadrangeofvotingtechnologyeffects
(see Card and Moretti 2007; Hanmer, Park, Traugott et al. 2010), the most famous
example remains the contested 2000 presidential election in the United States, where
considerable attention was focused on the effect of voting technology on the election
outcome in Florida. Wand, Shotts, Sekhon et al. (2001) published a refined version
of their analysis that spread like wildfire on the Internet in the week following the
presidential election. They asserted that
the butterfly ballot used in PalmBeachCounty, Florida,in the 2000pres-
idential election caused more than 2,000 Democratic voters to vote by
mistakeforReformcandidatePatBuchanan,anumberlargerthanGeorge
W. Bush’s certified margin of victory in Florida. (Wand et al. 2001:793)
Reflecting on efforts to recount votes undertakenby various media outlets, Wand and
his colleagues identify the crucial contribution of their analysis:
Ouranalysisanswersacounterfactualquestionaboutvoterintentionsthat
such investigations [by media outlets of votes cast] cannot resolve. The
inspections may clarify the number of voters who marked their ballot in
support of the various candidates, but the inspections cannot tell us how
many voters marked their ballot for a candidate they did not intend to
choose. (Wand et al. 2001:804)
Herron and Sekhon (2003) then examined invalid votes that resulted from overvotes
(i.e., voting for more than one candidate), arguing that such overvotes further hurt
Gore’s vote tally in two crucial Florida counties. Finally, Mebane (2004) then consid-
eredstatewidevotingpatterns,arguingthatifvoters’intentionshadnotbeenthwarted
by technology,Gore wouldhave wonthe Florida presidentialelectionby 30,000votes.

One particularly interesting feature of this example is that the precise causal effect
of voting technology on votes is not of interest, only the extent to which such causal
effects aggregate to produce an election outcome inconsistent with the preferences of
those who voted (see also Yamamoto 2012 for a related point).

## 1.4 Observational Data and Random-Sample Surveys

Whenwediscussmethodsandexamplesthroughoutthisbook,wewillusuallyassume

thatthedatahavebeengeneratedbyarelativelylargerandom-samplesurveyofawell-
definedpopulation.Wewillalsoassumethattheproportionandpatternofindividuals
whoareexposedtothecausearefixedinthepopulationbywhateverprocessgenerates
causal exposure.

We rely on the random-sample perspective because we feel it is the most natural
framing of these methods for the typical social scientist, even though many of the
classic applications and early methodological pieces in this literature do not reference
random-sample surveys. For the examples just summarized, the first three have been
examined primarily with random-sample survey data, but many of the others have
not. Some, such as the worker training example, depart substantially from this sort
of setup, as the study subjects for the treatment in that example are a heterogeneous
collection of welfare recipients, displaced workers, and others.18
Pinning downthe exactconsequences of the data generationand sampling scheme
of each application is important for developing estimates of the expected variability
of a causal effect estimate. We will therefore sometimes modify the random-sampling
backgroundwhendiscussingwhatisknownabouttheexpectedvariabilityofthealter-
native estimators we will present. Nonetheless, our primary focus in this book is on
strategies to estimate parameters that can be interpreted as warranted causal effects,
andaccordinglywewillgivefarlessattentiontoproceduresforestimatingthestandard
errors of these parameter estimates. In fact, as the reader will notice in subsequent
chapters, we will often assume that the sample is infinite. This preposterous assump-
tion is useful for presentation purposes because it simplifies matters greatly; we can
thenassumethatsamplingerroriszeroandassert,forexample,thatthesamplemean
ofanobservedvariableisequaltothepopulationexpectationofthatvariable.Butthis
assumption also signals a critical note of caution: It is meant to appear preposterous
and unreasonable in order to reinforce the point that the consequences of sampling
error must always be considered in any empirical analysis.19 Our assumption is that
our readersknow how to estimate and utilize standarderrorsfor many analysissitua-
tions, and so we will discuss these issues only when additional guidance is needed for
the particular estimators presented in this book.

Moreover, we will also assume for our presentation that the variables in the data
are measured without error. This perfect measurement assumption is, of course, also
entirely unreasonable. But it is commonly invoked in discussions of causality and in
many, if not most, other methodological pieces. We will indicate in various places
throughout the book when random measurement error is especially problematic for
themethodsthatwepresent.Weleaveitasself-evidentthatnonrandommeasurement
error can be debilitating for all methods.

18Partly for this reason, some of the literature (e.g., Imbens 2004) has made careful distinctions
between the sample average treatment effect (SATE) and the population average treatment effect
(PATE). In this book, we will focus most of our attention on the PATE (and other conditional
PATEs). We will generally assume that a well-defined population exists (usually a superpopulation
withexplicitcharacteristics) andthat theavailabledata arearandomsamplefromthis population.

However,muchofourtreatmentofthesetopicscouldberewrittenwithoutthelargerandom-sample
perspective and focusing only on the average treatment effect within the sample in hand. Many
articlesinthistraditionofanalysisadoptthisalternativestartingpoint(especiallythoserelevantfor
small-scale studies in epidemiology and biostatistics for which the “sample” is generated in such a
way that aformal connection to a well-defined population is impossible). We discuss these issues in
substantial detailinChapter2,especiallyinitsappendixonalternativepopulationmodels.

19Becausewewillassumeinthesecasesthatthesampleisinfinite,wemustthenalsoassumethat
thepopulationisinfinite.Thisassumptionentailsadoptionofthesuperpopulation perspectivefrom
statistics(whereinthefinitepopulationfromwhichthesampleisdrawnisregardedasonerealization
ofastochasticsuperpopulation).Evenso,andaswewillexplaininChapter2,wewillnotclutterthe
text of the book by making fine distinctions between the observable finite population and its more
encompassingsuperpopulation.

## 1.5 Causal Graphs as an Introduction to the Remainder of the Book

In Chapters 2 and 3, we will introduce what we regard as the two main pieces of the

counterfactualapproachtocausalanalysisforobservationalsocialscience–thepoten-
tial outcome model and the directed graph approach to causal analysis. In Chapter
4, we will present the basic conditioning strategy for the estimation of causal effects,
afterwhichwewillthenexplain–inChapters5through7–whymatching,regression,
and weighted regression estimators are complementary implementations of the more
general conditioning strategy.

We will then make the transition from “easy” to “hard” instances of causal effect
estimation, for which simple conditioning will not suffice because relevant variables
that are related to causal exposure are not observed. After presenting the general
predicament in Chapter 8, we will then offer Chapters 9 through 11 on instrumental
variable techniques, mechanism-based estimation of causal effects, and the usage of
over-time data to estimate causal effects. Finally, we will consider in Chapter 12 how
toproceedwhennoestimatorsareavailabletoofferwarrantedpointestimatesofcausal
effects, considering both the literature on set identification and sensitivity analysis.

In conclusion, in Chapter 13 we will provide a summary of some of the objections
thatothershavedevelopedagainstthecounterfactualmodel.Wewillalsoofferabroad
discussion of the complementary modes of causal inquiry that comprise causal effect
estimation in observationalsocial science.

InpartbecauseourdetailedTableofContentsalreadygivesanaccurateaccounting
of the material that we will present in the remaining chapters, we will not provide a
set of detailed chapter summaries here. Instead, we will conclude this introductory
chapter with three causal diagrams and the causal effect estimation strategies that
they suggest. These graphs allow us to foreshadow some of the specific causal effect
estimation strategies that we will present later.

Because the remainder of the material in this chapter will be reintroduced and
more fully explained later (primarily in Chapters 3, 4, 8, and 10), it can be skipped
now without consequence. However, our experience in teaching this material suggests
that many readers may benefit from a quick graphical introduction to the basic esti-
mation techniques before considering the details of the counterfactual framework for
observationaldata analysis.

Graphical Representations of Causal Relationships
JudeaPearl(2000,2009)andothershavedevelopedageneralsetofrulesforrepresent-
ing causal relationships with graphs.20 We will provide a more complete introduction
to directed graph representations of causal effects in Chapter 3, and for now we use
the most intuitive pieces of Pearl’s graphical apparatus with only minimal discussion
of technical details.

20Thesegraphs canbeinterpreted as the mostrecent incarnation ofthe path diagramsdeveloped
bySewallWright(1925, 1934;seeBollenandPearl2013).

G
A F
B D Y
C
Figure1.1 A causal graphin which back-doorpaths from D to Y can be blocked by
observable variables and in which C is an instrumental variable for D.

Consider the causal relationships depicted in the graph in Figure 1.1 and suppose
that these relationships are derived from a set of theoretical propositions that have
achievedconsensusintherelevantscholarlycommunity.Forthisgraph,eachnoderep-
resents an observable random variable. Each directed edge (i.e., single-headed arrow)
from one node to another signifies that the variable at the origin of the directed edge
causesthe variableatthe terminusofthe directededge.Eachcurvedanddashedbidi-
rected edge (i.e., double-headed arrow) signifies the existence of common unobserved
nodesthatcausebothterminalnodes.Bidirectededgesrepresentcommoncausesonly,
not mere correlations with unknown sources and not relationships of direct causation
between the two variables that they connect.

Now,suppose that the causalvariableof primaryinterestis D andthat the causal
effect thatwe wishto estimate is the effect ofD onY. The questionto consideris the
following: Given the structure of causal relationships represented in the graph, which
variables must we observeand then use in a data analysis routine to estimate the size
of the causal effect of D on Y?
Three Strategies to Estimate Causal Effects
Althoughwewillconsidermanystrategiesforestimatingcausaleffectsinthisbook,we
will give our most sustained attention to the following three strategies. First, one can
condition on variables (with procedures such as stratification, matching, and regres-
sion) to eliminate the noncausal portion of an association between a causal variable
andanoutcomevariable.This strategyisoftenreferredto asconditioningto blockall
“back-door”pathsfromthecausalvariabletotheoutcomevariable,whereaback-door
pathisdefinedasanypathbetweenthe causalvariableandthe outcomevariablethat
beginswithanarrowthatpointstothecausalvariable.Second,onecanuseexogenous
variation in an appropriate instrumental variable to isolate covariation in the causal
andoutcomevariables.Third,onecanestablishanexhaustiveandisolatedmechanism
that relates the causal variable to the outcome variable and then calculate the causal
effect as it propagates through the mechanism.

Consider the graph in Figure 1.1 and the opportunities it presents to estimate
the causal effect of D on Y with the conditioning estimation strategy. First note
that there are two back-door paths from D to Y in the graph that generate a sup-
plemental noncausal association between D and Y: (1) D ←A(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)F →Y and
(2) D←B(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)A(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)F →Y.21 Both of these back-door paths can be blocked
in order to eliminate the supplemental noncausal association between D and Y by
observing and then conditioning on A and B or by observing and then conditioning
on F. These two conditioning strategies are general in the sense that they will suc-
ceed in producing consistent estimates of the causal effect of D on Y under a variety
of conditioning techniques and in the presence of nonlinear effects. They are mini-
mally sufficient in the sense that one can observe and then condition on any subset of
the observed variables in {A,B,C,F,G} as long as the subset includes either {A,B}
or {F}.22
Now, consider the second estimation strategy, which is to use an instrumental
variable for D to estimate the effect of D on Y. This strategy is completely different
from the conditioning strategy just summarized. The goal is not to block back-door
paths from the causal variable to the outcome variable but rather to use a localized
exogenous shock to both the causal variable and the outcome variable in order to
estimate indirectly the relationship between the two. For the graph in Figure 1.1, the
variableC is a valid instrumentfor D because it causesD but does nothavean effect
on Y except through its effect on D. As a result, one can estimate consistently the
causal effect of D on Y by taking the ratio of the relationship between C and Y and
between C and D.23 For this estimation strategy, A, B, F, and G do not need to be
observed if the only interest of a researcher is the causal effect of D on Y.

To further considerthe differences betweenthese firsttwo strategies,now consider
the alternative graph presented in Figure 1.2. There are five possible strategies for
estimating the causal effect of D on Y for this graph, and they differ from those
21As we note later in Chapter 4 when more formally defining back-door paths, the two paths
labeled “back-door paths” in the main text here may represent many back-door paths because the
bidirected edges may represent more than one common cause of the variables they point to. Even
so, the conclusions stated in the main text are unaffected by this possibility because the minimally
sufficientconditioningstrategiesapplytoallsuchadditionalback-doorpaths aswell.

22For the graph in Figure 1.1, one cannot effectively estimate the effect of D on Y by simply
conditioning only on A. We explain this more completely in Chapters 3 and 4, where we introduce
theconcept ofa collidervariable. Thebasic ideaisthat conditioning onlyon A,whichis acollider,
createsdependencebetweenBandF withinthestrataofA.Asaresult,conditioningonlyonAdoes
noteliminatethenoncausal associationbetween D andY.

23Although all other claims in this section hold for all distributions of the random variables and
all types of nonlinearity of causal relationships, one must assume for instrumental variable (IV)
estimation what Pearl labels a linearity assumption. What this assumption means depends on the
assumeddistributionofthevariables.ItwouldbesatisfiedifthecausaleffectofC onDislinearand
thecausaleffectofDonY islinear.Bothofthesewouldbetrue,forexample,ifbothC andDwere
binaryvariablesandY wereaninterval-scaledvariable,andthisisthemostcommonscenariowewill
considerinthisbook.

G
A F
B D Y
C H
Figure 1.2 A causal graph in which C is no longer an instrumental variable for D.

G
A F
M
B D Y
N
C
Figure1.3 AcausaldiagraminwhichM andN representanisolatedandexhaustive
mechanism for the causal effect of D on Y.

for the set of causal relationships in Figure 1.1 because a third back-door path is
now present: D←C→H→Y. For the first four strategies, all back-door paths can
be blocked by conditioning on {A,B,C}, {A,B,H}, {F,C}, or {F,H}. For the fifth
strategy,the causaleffect canbe estimatedby conditioningonH andthenusing C as
an instrumental variable for D.

Finally,toseehowthethirdmechanisticestimationstrategycanbeusedeffectively,
consider the alternative graph presented in Figure 1.3. For this graph, four feasible
strategies are available as well. The same three strategies proposed for the graph in
Figure 1.1 can be used. But, because the variables M and N completely account for
the causal effect of D on Y, and because M and N are not determined by anything
other than D, the causal effect of D on Y can also be calculated by estimation of the
causal effect of D on M and N and then subsequently the causal effects of M and N
on Y. And, because this strategy is available, if the goal is to obtain the causal effect
of D on Y, then the variables A, B, C, F, and G can be ignored.24
In an ideal scenario, all three of these forms of causal effect estimation could be
used to obtain estimates, and all three would generate equivalent estimates (subject
to the expected variation produced by a finite sample from a population). If a causal
effect estimate generated by conditioning on variables that block all back-door paths
is similar to a causal effect estimate generated by a valid instrumental variable esti-
mator,theneachestimateisbolstered.Betteryet,ifamechanism-basedstrategythen
generates a third equivalent estimate, all three causal effect estimates would be even
moreconvincing.And, in this case,anelaboratedexplanationofhow the causaleffect
comesaboutisalsoavailable,asaresearchercouldthendescribehowthecausaleffect
is propagated through the intermediate mechanistic variables M and N.

Implications
The foregoing skeletalpresentation of causal effect estimation is, of course,inherently
misleading.Rarelydoesastateofknowledgeprevailinafieldthatallowsaresearcherto
specifycausesascleanlyasinthegraphsinthesefigures.Writingdownafullgraphthat
representsaconsensusposition,orasetofgraphsthatrepresentalternativepositions,
can be very difficult, especially if the arguments put forward in alternative pieces of
researchare open to multiple interpretations. Yet, little progresson estimating causal
effects is possible until such graphs are drawn, or at least some framework consistent
with them is brought to bear on the questions of central interest.

Beyondintroducing the basic estimation strategies,these graphs convey two addi-
tional points that are relevant for the material that follows. First, there is often more
than one way to estimate a causal effect, and simple rules such as “control for all
other causes of the outcome variable” can be poor guides for practice. For example,
forFigure1.1,therearetwocompletelydifferentandplausibleconditioningstrategies:
either condition on F or on A and B. The strategy to “control for all other causes of
the outcome variable” is misleading because (1) it suggests that one should condition
on G as well, which is unnecessary if all one wants to obtain is the causal effect of D
on Y, and (2) it does not suggest that one can estimate the causal effect of D on Y
by conditioning on a subset of the variables that cause the causal variable of interest.

In this case, one can estimate the causal effect of D on Y without conditioning on
any of the other direct causes of Y, but instead by conditioning on the variables that
cause D. Even so, this last conditioning strategy should not be taken too far. One
24Note that, for the graph in Figure 1.3, both M and N must be observed. If, instead, only M
were observed, then this mechanistic estimation strategy would not allow for estimation of the full
causaleffectofDonY.However,ifM andN areisolatedfromeachother,astheyareinFigure1.3,
thentheportionofthecausal effectthat passesthroughM orN canbeeffectively estimatedinthe
absenceofobservationoftheother.WediscusstheseissuesindetailinChapter 10.

need not condition on C when also conditioning on both A and B. Not only is this
unnecessary (just as for G with the other conditioning strategy), but in doing so one
failstouseC inits(possibly)mostusefulway:asaninstrumentalvariablethatcanbe
used to consistently estimate the causal effect of D on Y, ignoring completely A, B,
F, and G.

Second, the methods we will present, as we believe is the case with all estimation
strategiesinthesocialsciences,arebestsuitedtothetargetedestimationoftheeffects
of focal causes. As we will discuss at severalpoints throughoutthe book, especially in
Chapters 6 and 13, the counterfactual approach can also be used to pursue the more
ambitiousgoalofestimatingtheeffectsofall causesofanoutcomeofinterest.Evenso,
thismoreambitiousgoalisrarelypursuedbecauseofhowdifficultitistoachieve.The
way in which we have presented these graphs is telling on this point. Consider again
the questionthatweposedafterintroducingFigure1.1.We askedasimplerversionof
thefollowingquestion:GiventhestructureofcausalrelationshipsthatrelateA,B,C,
D, F, G, and Y to each other (represented by presupposed edges that signify causal
effects of unknown magnitude), which variables must we observe and then use in a
data analysis routine to estimate the size of the causal effect of D on Y? This sort of
constrainedquestion(i.e.,beginningwiththeconditional“given”clause)isquiteabit
differentfromseekingtoanswerthemoregeneralquestions:Whatareallofthecauses
ofY, andhowlargearetheir effects relativeto eachother? The methods that wewill
present in this book are not irrelevantto this broaderquestion, but they are designed
to first answer more targeted questions about the effects of subsets of all causes of an
outcome.

The limited nature of the methods that we will present implies two important
features of causal effect estimation from the perspective of counterfactual modeling.

Toofferapreciseanddefendablecausaleffectestimate,awell-specifiedtheoryisneeded
to justify assumptions about underlying causal relationships. And, if theory is poorly
specified, or divergenttheories exist in the relevantscholarlycommunity that support
alternativeassumptionsaboutunderlyingcausalrelationships,thenalternativecausal
effect estimates may be considered valid conditional on the validity of alternative
maintained assumptions. We discuss these issues in depth across the chapters of the
book, while presenting the framework and the methods that generate estimates that
must then be placed in their proper context.

# Part II: Counterfactuals, Potential Outcomes, and Causal Graphs

# Chapter 2

# Counterfactuals and the Potential Outcome Model

In this chapter, we introduce the foundational components of the potential outcome

model. We first discuss causal states, the relationshipbetween potential and observed
outcome variables, and the usage of the label “counterfactual” to refer to unobserved
potential outcomes. We introduce averagecausal effects and then discuss the assump-
tion of causal effect stability, which is maintained explicitly in most applications that
usethepotentialoutcomemodel.Wediscusssimpleestimationtechniquesanddemon-
strate the importance of considering the relationship between the potential outcomes
and the process of causal exposure. We conclude by extending our presentation to
over-time potential outcome variables for one or more units of analysis, as well as
causal variables that take on more than two values.

## 2.1 Defining the Causal States

The counterfactual framework for observational data analysis presupposes the exis-

tence of well-defined causal states to which all members of the population of interest
couldbe exposed.1 As we willshow in the next section,causaleffects are then defined
based on comparisons of outcomes that would result from exposure to alternative
causal states. For a binary cause, the two states are usually labeled treatment and
control.Whenamany-valuedcauseisanalyzed,the conventionistorefertothe alter-
native states as alternative treatments.

Although these labels are simple, the assumed underlying states must be very
carefully defined so that the contribution of an empirical analysis based upon them
is clear. Some of the relevant issues can only be discussed as we introduce additional
1Wejustifytheimportanceofcarefullydefiningtheboundariesofthepopulationofinterestwhen
presenting average causal effects later inthis chapter. We also provide an appendix to this chapter,
in which we explain the general superpopulation model that we will adopt when the boundaries of
the population can be clearlydefined and when wehave the good fortuneof having a largerandom
samplefromthepopulation.

37
piecesofthefull counterfactualframeworkinthischapterandthenext–movingfrom
the definition of individual-level causal effects, through average causal effects, and
then to causal graphs and the underlying structural equations that they represent.

Nonetheless, some initial clarificationof core definitional issues for these causalstates
is essential.

FineArticulation.Toappreciatethevalueoffinelyarticulatedcausalstates,con-
siderthe examplesintroducedinSection 1.3. The workertrainingexampleis straight-
forward, and the two states are “entered a training program” (the treatment state)
and“didnotenteratrainingprogram”(thecontrolstate).Thecharterschoolexample
issimilar.Here,thealternativestatesare“enrolledinacharterschool”(thetreatment
state) and “enrolled in a regular public school” (the control state, although possibly
referred to as an alternative treatment state). One possible complication with these
examples is the possibility of inherent differences across training programs, charter
schools, and regular public schools. If any such treatment-site heterogeneity exists,
then stratified analyses may be necessary, perhaps by regions of the country, size of
the program or school, or whatever other dimension suggests that variability of the
causal states deserves explicit modeling.2
Otherexamples,atleastasexecutedintheextantresearch,havecausalstatesthat
are not finely articulated. Consider the classic political participation line of inquiry.

For the relationship between socioeconomic status and political participation, there
are many underlying causal effects, such as the effect of having obtained at least a
college degree on the frequency of voting in local elections and the effect of having
a family income greater than some cutoff value on the amount of money donated to
political campaigns. Well-defined causal states exist for these narrow causal effects,
but it is not clear at all that well-defined causal states exist for the internally dif-
ferentiated concept of socioeconomic status, which social scientists have created for
their own analytic purposes. It is therefore unsurprising that some of the most recent
literature (e.g., Henderson and Chatfield 2011; Kam and Palmer 2008) has specified
more finely articulatedcausalstates for this line of research,suchas “enteredcollege”
(the treatment state) in comparison to “did not enter college” (the control state).

Thefatherabsenceexampleisanintermediatecase.Theoriginalresearchattempted
toestimatethebroadeffectsofsingleparenthoodontheoutcomesofchildrenandado-
lescents (see McLanahan and Sandefur 1994; Wu and Wolfe 2001). The more recent
literaturehasfocusedonthe narrowlydefinedtreatmentstateoffatherabsence.Even
so, much variationremains in both the definition of this treatment state and the rele-
vant comparison(or control) state, as noted in a review piece:
Studies in this field measured father absence in several ways, which the
readershouldkeepinmindwheninterpretingandcomparingresultsacross
studies. Some studies compared children of divorced parents with children
of stably married parents; others compared children whose parents mar-
riedafter their childs birth with those parents who never married....More
recently, researchers have started to use even more nuanced categories to
2For example, Hong and Raudenbush (2006) provide a careful analysis of retention policies in
primaryeducation,implementingthistypeoftreatment-sitestratificationbasedontheaveragelevel
ofretentionindifferentpublicschools.Wewilldiscussthesetypes ofstudiesinSection2.5.

measure family structure – including married biological-parent families,
cohabiting biological-parent families, married stepparent families, cohab-
iting stepparent families, and single parents by divorce and nonmarital
birth – reflecting the growing diversity of family forms in society....We
did not identify any studies that used causal methods to study the effects
of same-sex unions. (McLanahan et al. 2013:408)
In general, research that takes account of heterogeneity by splitting treatment states
into mutually exclusive component states will break new ground if sufficient data are
available to estimate the more narrowly defined treatment effects.

Nominal States from Constitutive Features.Wetakeapragmaticbutprinci-
pled positionon the characteristicsof causalstates, and in this subsectionwe wantto
clarifyourpositionforreaderswhoareinterestedindebatesonthenatureofcausation
in philosophy and how those debates are relevant for social science research. Readers
whoareuninterestedinthesedebatesmaywishtoskimthis subsectionnowandreen-
gageit afterreadingChapter 10oncausalmechanisms andSection13.1onobjections
tothecounterfactualapproachtoobservationaldataanalysis(pages438–446).Infact,
most scholars who work with counterfactual models in social science research do not
take any positions on the issues that we raise in this subsection, and their research
shows that much useful work can proceed by taking and using the causal states as
measured,withoutconsideringthefeaturesthatgivethemtheircapacitiestogenerate
effects.

Having offered these warnings, we will now explain why we take the position that
each state of each treatment should be regarded as a nominal state with constitutive
features (e.g., entities, activities, and relations) that are jointly capable of producing
the outcome of interest. Consider the Catholic school example, where the nominal
states are “enrolledin a Catholic school” and “enrolledin a public school”and where
the outcome is “learning.” Each type of school has teachers, classrooms, curricula,
administrators, normative environments, affiliated institutions, and networks of peers
and parents. The literature on the differences between Catholic schools and public
schoolssuggeststhattheseconstitutive featuresoftheschoolsareinterrelatedinways
that differ by type of school. Accordingly, while Catholic schools and public schools
bothproducestudentlearning,the particularwaysinwhichthey dosoarethoughtto
differ meaningfully acrosstype of school, and in ways that have notbeen documented
comprehensivelywithavailabledata.Nonetheless,wecanstillconceiveofeachstudent
in the populationof interest being exposedto eachtype ofschool,and we can assume
that each student would then experience the learning generated in toto by the joint
capacities of the constituent features of each type of school.

Takingthisposition,whileatthesametimeembracingcounterfactualdependence,
implies thatwe seevalue inmounting causalanalysisinthe socialsciences ontopofa
foundation that conjoins a metaphysics of causal powers with a metaphysics of coun-
terfactual dependence (see Collins, Hall, and Paul 2004; Mumford and Anjum 2011).

The price for such an inclusive pragmatism is an elaborate metaphysics, which most
philosophers would likely regard as insufficiently elegant and insufficiently reductive.

With reference to Hume’s example of billiard balls (Hume 1977[1772]), our position
requiresthatweadoptthefollowingspecific(butperhapspainfullyelaborate)account
ofthe natureofcausation:The cue ballcausesthe secondbilliardballtorollapartic-
ular observeddistance because billiard balls are spheres and because the cue ball was
struckbytheplayer’spoolcueinsuchawaythatitthenstruckthesecondbilliardball
at a particular angle and with a particular force. Furthermore, the cue ball would not
have caused the second billiard ball to roll the same observed distance if the billiard
ballshadinsteadnotbeenspheresorifthecueballhadnotbeenstruckbytheplayer’s
pool cue in the exact same way. Thus, the causal effect of the cue ball on the second
billiard ball is a joint product of the spherical feature of the billiard balls as well as
the external intervention of the pool player.3
For the sorts of social science examples we consider in this book, we will express
the effects of causal states using contrasts between observed exposure to one state
and what-if counterfactual exposure to another state. However, we will also take the
position that any such claims about the effects of exposure to alternative states are
incompleteuntilthoseclaimsareaccompaniedbyaccountsoftheconstitutivefeatures
ofthecausalstatesandhowthosefeaturesarethoughttograntthestatesthepowerto
generate outcomes.4 The most complete accounts point to evidence that mechanisms
exist that are capable of generating the outcomes of interest (and, better yet, that it
is reasonable to believe that these mechanisms will be able to explain why exposure
to alternative causal states generates differences).

Consideranexamplewheremanyoftheseissuesaresettled.FortheCatholicschool
effect, analysis can proceed within a guiding framework shaped by a rich background
literature. The historical events that generated public schools and Catholic schools as
coherentinstitutions suggeststhatthey canbe meaningfullycomparedwhenstudying
student achievement because they each aim to produce learning for core academic
subjects, even though they each pursue additional distinct goals (see Tyack 1974 for
one of the most widely read accounts). In addition, each type of school has a rich set
of literature that has examined the mechanisms that generate learning. For Catholic
3With the goal of reducing the complexity of such an account, philosophers seem inclined to
take positions on whether the spherical characteristic of the cue ball (its “causal power”) is more
fundamental than the striking(i.e.,the “counterfactual dependence” induced by the intervention of
theplayer), whether “striking”canbedefined intheabsence ofanintervening poolplayer,whether
avalidexplanationcansimplybededucedfromlawsofmotioninspaceandtime,whetheranything
is transferredbetween the two billiardballs at the moment of impact, and so on. We see no reason
totakeapositiononthesematters inthisbook, andwethereforequiteconsciouslyviolaterule4of
PaulandHall(2013:40), “Thoushallnotbeanontological wimp.”
4We see little value in placing restrictions on what types of origination accounts are admissible
andshouldbereliedupon.Forsomecausalclaims,historicalnarrativesareappropriate,totheextent
that they focus on especially salient institutional histories while pushing into the background the
multitudeofspecificdecisionsofallindividualsthathavegivenshapetotheconstitutive features of
thealternative states (seeReed2011 forexamples ofsuch“forming”narratives). Inother cases,the
origins of the states can be explained as contrasting values for built concepts, based on underlying
analyticdimensionsdrawnfromtheextantsocialscienceliterature,wheretheseunderlyingdimensions
have been chosen precisely because background evidence exists that they are sources of productive
causalpowerofthenominalcausalstatesofinterest(seeGoertz2006forexamples).However,wesee
onecomplicationforthissecondtypeofaccount,asforeshadowedbyourdiscussionofsocioeconomic
status above. Causal states drawn from values for a built concept may be real only in the minds of
researchers. As a result, explanations based upon them may appear nonsensical to individuals who
arepurportedtobeproducingtheeffects ofinterest.Whether suchbehind-the-backaccounts areto
be regarded as powerful or not is almost certainly a domain-specific consideration, which will also
varywiththegoalsofastudy.

schools, several complementary narratives exist that provide arguments that suggest
whyCatholicschoolshavethecapacitytobemoreeffectivethanpublicschools.These
narratives include those that emphasize the relations embedded in parental network
structurealongsideanappropriatedideologyoftheCatholicchurch(seeColemanand
Hoffer1987),those thatemphasize the extentto whichCatholic schoolsare especially
responsive to parental feedback and the threat of exit (Chubb and Moe 1990), and
those that emphasize the trusting relationships between teachers and administrators
that flow from a shared purpose (Bryk, Lee, and Holland 1993).

Of course, the existence of such lower-level claims about the specific mechanis-
tic capacities of features of Catholic schools begs the question: When is it advis-
able to decompose nominal causal states into component causal states with their own
capacitiesforproducingtheoutcomeofinterest?Weseetheanswertothisquestionas
subject- and domain-specific. Accordingly, we see little value in making general argu-
ments about when such decomposition is feasible because of the inherent separability
oftheproductivecapacitiesattachedtoparticularconstitutivefeaturesorisinfeasible
becauseofthedeeplyentangledcomplementaritiesamongthem.And,aswewillargue
later in Chapter 10, it is generallyimpossible to take a position onthese issues in any
given study without first stipulating the causal structure of the mechanisms that are
presumed to produce the outcome. Fortunately, as we will demonstrate in the inter-
veningchapters,causaleffectsdefinedonlybynominalcausalstatescanbesufficiently
precise so that their estimation is itself feasible and very much worthwhile.

Local and Reasonable. Consider the literature on socioeconomic status as a
fundamental cause of health and mortality, which takes as its defining feature the
argument that it is only occasionally useful to identify causal states for the mea-
surable dimensions underneath the fundamental cause of socioeconomic status (see
page 19). For these scholars, it is the abundant causal pathways that link socioe-
conomic status with health and mortality that are most noteworthy because of the
robust, total associations that they generate. Isolating a particular causal effect that
is attributable to a contrast defined by two clearly defined underlying causal states
embedded within socioeconomic status could still be useful, such as for the estima-
tion of a health disparity attributable to a family income difference of $25,000. The
claim of this literature is that this narrow exercise could become counterproductive if
it detracted from the broader claim of fundamental causality, as would be the case if
the analyst were to imply that any such narrow effect is as robust as the total causal
effect that socioeconomic status exerts on health and mortality.

A fundamental-cause orientation may be useful in challenging the status quo in
research areas that have become too narrowly focused on only a few relevant causal
pathways, but widespread adoption of the fundamental-cause orientation to causal
analysis would not be productive. In many areas of research, it would not be hard to
takecollectionsofnarrowlyandcarefullydefinedcausalcontrasts,lumpthemtogether
into latent constructs, and then assert that, over sufficiently long intervals, the latent
construct is a fundamental cause because the mechanisms that are activated by com-
ponent causes switch on and off over time. Indeed, considering our other examples in
Section1.3,onecouldarguequiteeasilythatthesocioeconomicstatusofone’sparents
is a fundamental cause of educational attainment, subsequent labor market earnings,
political participation,and fertility decisions. We doubt many scholarswoulddisagree
with such broad claims, and most would likely interpret them as consistent with con-
clusions drawn by scholars working with comparatively coarse data more than six
decadesago.Moreimportantly,wethink itunlikelythat the reassertionofsuchbroad
claims would encourage researchers to move in productive new directions. Instead,
we see the counterfactual perspective, and the potential outcome model in particu-
lar, as enabling the pursuit of a more ambitious goal: the careful delineation of the
relevant causal states that lie within any purported fundamental causes and then the
estimation of the specific effects generated by contrasts between them. Should there
be reason to expect that any such effects vary in time, then their estimation across
time demands empiricalanalysis,not simply the assertionthat sucheffects,by nature
of their variability in time, can only be regarded as specialized instantiations of more
fundamental causes.

For a related reasonableness concern, consider a specific political participation
example. To what extent do restrictions on who can vote determine who wins elec-
tions?Ahighlypublicizedvariantofthisquestionisthis:Whatistheeffectonelection
outcomes of laws that forbid individuals with felony convictions from voting?5 Uggen
and Manza (2002) make the straightforward claim that the 2000 presidential elec-
tion would have gone in favor of Al Gore if felons and ex-felons had been permitted
to vote:
Although the outcome of the extraordinarily close 2000 presidential elec-
tion could have been altered by a largenumber of factors, it would almost
certainly have been reversed had voting rights been extended to any cate-
gory of disenfranchised felons. (Uggen and Manza 2002:792)
Uggen and Manza (2002) then note an important limitation of their conclusion:
ourcounterfactualexamplesrely upona ceterisparibusassumption– that
nothingelseaboutthecandidatesorelectionwouldchangesavethevoting
rights of felons and ex-felons. (Uggen and Manza 2002:795)
When thinking about this important qualification, one might surmise that a possible
world in which felons had the right to vote would probably also be a world in which
the issues(andprobablycandidates)ofthe electionwouldbe verydifferent.Thus,the
mostchallenging definitional issue here is not who counts as a felon orwhether or not
an individual is disenfranchised, but rather how well the alternative causal states can
be characterized.

A relevant criterion, although necessarily subjective, is whether it “stretches the
mind”toomuchtoimagineconceivablealternativeworldsinwhichallelseremainsthe
same, except for the instantiation of the alternative causal states. For this particular
example,the“toomuch”criterionwasnotlikelycrossed.Scholarsinpoliticalsociology
and criminology supported publication through blind peer review in the discipline’s
highestprestigejournal,theAmerican Sociological Review.Reviewerspresumablysaw
this particular line of research as an important contribution to our knowledge on
howchanginglawstoallowfelonsandex-felonsto votecouldhavepotentialeffects on
5Behrens,Uggen, andManza(2003), ManzaandUggen(2004), andUggen, Behrens,andManza
(2005) givehistoricalperspectiveonthisquestion.

electionoutcomes,andtheymusthaveconcludedthattherewasvalueinunderstanding
sucheffectsinhypotheticalisolationfromotherchangesthatwouldalsolikelyco-occur
in the real world along with the contemplated legislative changes.

Themoregeneralpoint,however,isthatitisimportantthatthe“whatwouldhave
been” nature of the conditionals that define the causal states of interest be carefully
considered. When a facile ceteris paribus assumption is invoked to relieve the analyst
from having to discuss other contrasts that are nearly certain to occur at the same
time,thepositedcausalstatesmaybeopentothechargethattheyaretooimprobable
or ill-defined to justify the pursuit of a causal analysis based on them.6
## 2.2 Potential Outcomes and Individual-Level Treatment Effects

Giventheexistenceofwell-definedcausalstates,causalinferenceinthecounterfactual

traditionproceeds by stipulating the existence of potential outcome randomvariables
that are defined over all individuals in the population of interest. For a binary cause,
we will denote potential outcome random variables as Y1 and Y0.

Wewillalsoadoptthenotationalconventionfromstatisticsinwhichrealizedvalues
for randomvariables aredenoted by lowercaseletters. Accordingly, y1 is the potential
i
outcome in the treatment state for individual i, and y0 is the potential outcome in
i
the control state for individual i.7 The individual-level causal effect of the treatment
6ThephilosopherNancyCartwright(2007a,2007b)wouldrefertoananalysisthatdefinespotential
outcomes (see next section) in terms of ill-conceived causal states as generating “impostor counter-
factuals.”She stresses the need for fullcausal models of all interrelated causes of outcomes, so that
theeffects ofcausesarenottoonarrowlyassessed.Shewrites:
Toevaluatecounterfactuals...weneedacausalmodel;andthecausalmodelmustcon-
tain all the information relevant to the consequent about all the changes presumed in
theantecedent. Thereisnoother reasonablemethodonoffertoassesscounterfactuals.

We may not always produce a model explicitly, but for any grounded evaluation there
must be a causal model implicit; and our degree of certainty about our counterfactual
judgmentscanbenohigherthanourdegreeofcertaintythatourcausalmodeliscorrect.

(Cartwright2007a:193)
We agree with the value of having a causal model, as will become clear in subsequent chapters.

However, Cartwright takes this position to an extreme that is counterproductive for practice; see
Pearl(2009:362–65).

7Thereisawidevarietyofnotationinthepotentialoutcomeandcounterfactualsliterature,andwe
haveadoptedthenotationthatwefeelistheeasiesttograsp.However,weshouldnotethatEquation
(2.1)anditselementsareoftenwrittenasoneofthefollowingalternatives,
Δi=Y 1i−Y 0i,
δ i=Y it−Y ic,
τ i=y i(1)−y i(0),
and variants thereof. We use the right-hand superscript to denote the potential treatment state
of the corresponding potential outcome variable, but other authors use the right-hand subscript or
parentheticalnotation.Wealsousenumericalvaluestorefertothetreatmentstates,butotherauthors
(includingus,seeMorgan2001,WinshipandMorgan1999,andWinshipandSobel2004)usevalues
suchastandcforthetreatmentandcontrolstates,respectively.Thereisalsovariationintheusage
ofuppercaseandlowercaseletters.Wedonotclaimthateveryonewillagreethatournotationisthe
easiest to grasp, and it is certainly not as general as, for example, the parenthetic notation. But it
is then defined as
δi=y i1−y i0. (2.1)
Before proceeding, two caveats on this definition of individual-level causal effects
should be noted. First, the individual-level causal effect can be defined in ways other
thanasthelineardifferencebetweenthetworelevantpotentialoutcomes.8Oneobvious
possibility is the ratio of one individual-level potential outcome to another, y1/y0. In
i i
someresearchareas,alternativedefinitionsattheindividuallevelmayhaveadvantages.

The mostprominentcaseisepidemiology,wherethe goalofestimatingriskfactorsfor
health outcomes continuesto dominate practice andleads to a frequentpreference for
ratio-based rather than difference-based comparisons. Nonetheless, the overwhelming
majorityoftheliteraturerepresentsindividual-levelcausaleffectsaslineardifferences,
as in Equation (2.1).

Second,theindividual-levelcausaleffectcouldbedefinedasthedifferencebetween
the expectations of individual-specific random variables, as in E[Y1]−E[Y0], where
i i
E[.]istheexpectationoperatorfromprobabilitytheory(see,foraclearexampleofthis
alternative setup, King et al. 1994:76–82).In thinking about individuals self-selecting
intoalternativetreatmentstates,itcanbeusefultosetupthetreatmenteffectsinthis
way.Inmanyapplications,individualsarethoughttoconsiderpotentialoutcomeswith
somerecognitionoftheinherentuncertaintyoftheirbeliefs,whichmayproperlyreflect
true variability in their individual-level potential outcomes. But, with data for which
a potential outcome is necessarily observed for any individual as a scalar value (via
an observed outcome variable, defined later), this individual-level, random-variable
definition is largely redundant. Accordingly, we will denote individual-level potential
outcomes as values such as y1 and y0, regarding these as realizations of population-
i i
levelrandomvariablesY1 andY0 whilerecognizing,atleastimplicitly,thattheycould
also be regardedas realizations of individual-specific random variables Y1 and Y0.

i i
## 2.3 Treatment Groups and Observed Outcomes

For a binary cause with two causal states and associated potential outcome variables

Y1 and Y0, a corresponding causal exposure variable, D, is specified that takes on
two values: D is equal to 1 for members of the population who are exposed to the
treatment state and equal to 0 for members of the population who are exposed to the
control state. Exposure to the alternative causal states is determined by a particular
process, typically an individual’s decision to enter one state or another, an outside
actor’s decision to allocate individuals to one state or another, a planned random
allocation carried out by an investigator,or some combination of these alternatives.

Byconvention,thosewho areexposedto the treatmentstate arereferredto asthe
treatmentgroup,whereasthosewhoareexposedtothecontrolstatearereferredtoas
thecontrolgroup.BecauseD isdefinedasapopulation-levelrandomvariable(atleast
doesseem tohaveprovenitselfinourownclasses,offeringtherightbalancebetween specificityand
compactness.

8Rubin(2005,figure1)usesthegeneralnotation“v.”for“versus”todepictindividual-leveleffects
intheirmostgeneralform.

in most cases in observational data analysis), the treatment group and control group
existinthepopulationaswellastheobserveddata.Throughoutthisbook,wewilluse
this standard terminology, referring to treatment and control groups when discussing
those who areexposedto alternative states ofa binary cause.If more thantwo causal
states areofinterest, then we will shift to the semantics ofalternativetreatments and
correspondingtreatmentgroups,therebydiscardingthebaselinelabelsofcontrolstate
and control group.

Despite our adoptionof this convention,we could rewrite all that follows referring
tomembersofthe populationaswhatthey are–those whoareexposedtoalternative
causalstates–andnotusethewordstreatmentandcontrolatall.Indeed,werecognize
thatforsomereaderstheusageoftreatmentandcontrollanguagemayfeelsufficiently
heterodox relative to the semantics of the areas in which they work that avoidance of
these terms seems prudent. If so, it is perfectly acceptable to adopt parallel language
without using the words treatment and control.

When we refer to individuals in the observed treatment and control groups, we
will again adopt the notational convention from statistics in which realized values for
random variables are denoted by lowercase letters. Accordingly, the random variable
D takes on values of di=1 for each individual i who is an observed member of the
treatment group and di=0 for each individual i who is an observed member of the
control group.

Given these definitions of Y1, Y0, and D (as well as their realizations y i1, y i0, di),
we cannowdefine the observedoutcomevariableY interms ofthem. We canobserve
valuesforavariableY asyi=y i1forindividualswithdi=1andasyi=y i0forindividuals
with di=0. The observable outcome variable Y is therefore defined as
Y =Y1 if D=1,
Y =Y0 if D=0.

This paired definition is often written compactly as
Y =DY1+(1−D)Y0. (2.2)
Equation(2.2)impliesthatonecanneverobservethepotentialoutcomeunderthe
treatmentstate for those observedin the control state, and one can never observe the
potential outcome under the control state for those observed in the treatment state.

This impossibility implies that one can never calculate individual-level causal effects.

Holland(1986)describesthischallengeasthefundamentalproblemofcausalinfer-
ence in his widely readintroduction to the potential outcome model of counterfactual
causality. Table 2.1 depicts the “problem,” which one might alternatively refer to as
the “fundamental reality of causal analysis.” Causal effects are defined by contrasts
within rows, which refer to groups of individuals observed in the treatment state or
in the control state. However, only the diagonal of the table is observable, thereby
rendering impossible the direct calculation of individual-level causal effects merely by
means of observation and then subtraction.9
9AsTable2.1shows,wearemorecomfortablethansomewritersinusingthelabel“counterfactual”
whendiscussingpotentialoutcomes.Rubin(2005),forexample,avoidsthetermcounterfactual,under
the argument that potential outcomes become counterfactual only after treatment assignment has
occurred.Thus,nopotentialoutcomeiseverexantecounterfactual.Weagree,ofcourse.But,because
Table 2.1 The Fundamental Problem of Causal Inference
Group Y1 Y0
Treatment group (D=1) Observableas Y Counterfactual
Control group (D=0) Counterfactual Observableas Y
As shown clearly in Equation (2.2), the outcome variable Y, even if we could enu-
merate all of its individual-level values yi in the population, reveals only half of the
information containedin the underlying potential outcome variables.Individuals con-
tributeoutcomeinformationonlyfromthetreatmentstateinwhichtheyareobserved.

This is another way of thinking about Holland’s fundamental problem of causalinfer-
ence. The outcome variables we must analyze – labor market earnings, test scores,
and so on – contain only a portion of the information that would allow us to directly
calculate causal effects for all individuals.

## 2.4 The Average Treatment Effect

Becauseitistypicallyimpossibletocalculateindividual-levelcausaleffects,weusually

focus attention on the estimation of carefully defined aggregate causal effects. When
weadoptthelineardifferenceinpotentialoutcomesasthedefinitionoftheindividual-
level causal effect, we typically define aggregate causal effects as averages of these
individual-level effects. These average causal effects can de defined for any subset of
the population, and throughout this book we will consider many different average
effects. In this section, we introduce the broadest possible average effect, which is the
average treatment effect (ATE) in the population as a whole.

With E[.] denoting the expectation operator from probability theory, the average
treatment effect in the population is
E[δ]=E[Y1−Y0] (2.3)
=E[Y1]−E[Y0].

ThesecondlineofEquation(2.3)followsfromthelinearityoftheexpectationoperator:
The expectation of a difference is equal to the difference of the two expectations.10
For Equation (2.3), the expectation is defined with reference to the population of
interest. For the fertility pattern example introduced in Section 1.3, the population
wouldbe one or more birth cohortsof womenina particularcountry. For the election
outcome examples, the population would be “all eligible voters”or “all eligible voters
in Florida.” For other examples, such as the worker training example, the population
ourfocus isonobservational dataanalysis,wefindthecounterfactual labelusefulforcharacterizing
potential outcomes that are rendered unobservable ex post to the treatment assignment/selection
mechanism.

10However,atadeeperlevel,italsofollowsfromtheassumptionthatthecausaleffectisdefinedas
alineardifferenceattheindividuallevel,whichallowstheapplicationofexpectations inthissimple
waytocharacterize population-levelaverageeffects.

would be “all adults eligible for training,” and eligibility would need to be defined
carefully. Thus, to define average causal effects and then interpret estimates of them,
it is crucial that researchersclearly define the characteristics of the individuals in the
assumed population of interest.11
Note also that the subscripting on i for the individual-level causal effect, δi, has
been dropped for Equation (2.3). Even so, the definition of the ATE should not be
interpreted to suggest that we now must assume that the treatment effect is constant
in the population in any fundamental sense. Rather, we can drop the subscript i in
Equation (2.3) because the expected causal effect of a randomly selected individual
from the population is equal to the average causal effect across individuals in the
population.Wewillattimesthroughoutthisbookreintroduceredundantsubscripting
on i in order to reinforce the inherent individual-level heterogeneity of the potential
outcomes and the causal effects they define.12
To see all of these pieces put together, consider the Catholic school example.

The potential outcome under the treatment, y1, is the what-if achievement outcome
i
of individual i if he or she were enrolled in a Catholic school. The potential out-
come under the control, y0, is the what-if achievement outcome of individual i if
i
he or she were enrolled in a public school. Accordingly, the individual-level causal
effect, δi, is the what-if difference in achievement that could be calculated if we could
simultaneouslyeducateindividualiinbothaCatholicschoolandapublicschool.The
ATE, E[δ], is then the average value among all students in the population of these
what-if differences in test scores. The ATE is also equal to the expected value of the
what-if difference in test scores for a randomly selected student from the population.

Analternativegroup-levelcausaleffectthatwewillnotconsidermuchinthisbook
is the causal risk ratio,
Pr[Y1=1]
, (2.4)
Pr[Y0=1]
wherenowtheoutcomesY1 andY0 areindicatorvariablesequalto1iftheoutcomeof
interest is present and 0 if not. This group-leveleffect is the analog to the individual-
level ratio of potential outcomes, y1/y0, noted earlier in Section 2.2. The causal risk
i i
ratio is most frequently analyzedin epidemiology and the health sciences, where risk-
factor analysis remains dominant and the outcomes are typically onset of a disease or
a troubling symptom thereof (see Herna´n and Robins 2006a). For our purposes, most
outcomesmodeledas causalrisk ratioscanbe translatedto averagetreatmenteffects,
interpreting E[Y1]−E[Y0] as Pr(Y1 =1)−Pr(Y0 =1). Expectations of indicator
variables are equivalent to probabilities of indicator variables, and an interval metric
11And,regardlessofthecharacterizationofthefeaturesofthepopulation,wewillassumethrough-
out this book that the population is a realization of an infinite superpopulation. We discuss our
decision to adopt this underlying population model in an appendix to this chapter. Although not
essentialtounderstandingmostofthematerialinthisbook,somereadersmayfindithelpfultoread
that appendix now in order to understand how these definitional issues are typically settled in this
literature.

12For example, at many times in the book, we willstress that quantities such as the ATE should
not be assumed to be equal to the individual-level causal effect for any individual i, which we will
expressasδ i(cid:2)=E[δ i]=E[δ]foralli.Inwords,whenindividual-levelheterogeneity ofcausaleffectsis
present,individual-levelcausaleffects,δ i,willnotallbeequaltotheaverageoftheseindividual-level
causaleffects,E[δ i],whichis,bythedefinitionoftheexpectation operator,equal toE[δ].

isatleastassensibleasaratiometricforalloftheexampleswewillconsider.(Theratio
metric might be preferable if we were attempting to make effect comparisons across
outcomes with very different base rates, such as the effect of the same treatment on
pancreatic cancer and hypertension.)
## 2.5 The Stable Unit Treatment Value Assumption

In most applications,the potential outcome model retains its tractability throughthe

maintenanceofastrongassumptionknownasthestableunittreatmentvalueassump-
tion or SUTVA (see Rubin 1980b, 1986). In economics, a version of this assumption
is sometimes referred to as a no-macro-effect or partial equilibrium assumption (see
Garfinkel, Manski, and Michalopoulos 1992, Heckman 2000, 2005, for the history of
these ideas, and Manski and Garfinkel 1992 for examples).13
SUTVA, as implied by its name, is a basic assumption of causal effect stability
that requires that the potential outcomes of individuals be unaffected by changes in
the treatment exposures of all other individuals. In the words of Rubin (1986:961),
who developed the term,
SUTVA is simply the a priori assumption that the value of Y for unit u
when exposed to treatment t will be the same no matter what mechanism
is used to assigntreatment t to unit u andno matter what treatments the
other units receive.

Consider the idealized example in Table 2.2, in which SUTVA is violated because the
treatmenteffectvarieswithtreatmentassignmentpatterns.Fortheidealizedexample,
therearethreerandomlydrawnsubjectsfromapopulationofinterest,andthestudyis
designedsuchthatat leastone ofthe three study subjects mustreceivethe treatment
and at least one must receive the control. The first column of the table gives the six
possible treatmentassignmentpatterns.14 The firstrowofTable 2.2presents allthree
ways to assign one individual to the treatment and the other two to the control, as
well as the potential outcomes for each of the three subjects. Subtraction within the
last column shows that the individual-level causal effect is 2 for all three individuals.

The second row of Table 2.2 presents all three ways to assign two individuals to
the treatment and one to the control. As shown in the last column of the row, the
individual-level causal effects implied by the potential outcomes are now 1 instead of
2. Thus, for this idealized example, the underlying causal effects are a function of the
treatment assignment patterns, such that the treatment is less effective when more
individuals areassignedtoit. ForSUTVA to hold, the potential outcomeswouldneed
to be identical for both rows of the table.

13SUTVAisamuchmalignedacronym,andmanyothersusedifferentlabels.Manski(2013a:S1),for
example,hasrecentlylabeledthesameassumptionthe“individualistictreatmentresponse”assump-
tioninorder“tomarkitasanassumptionthatrestrictstheformoftreatment responsefunctions.”
14Forthisexample,assumethatthevaluesofy1andy0foreachindividualiareeitherdeterministic
i i
potentialoutcomesorexactlyequaltoE[Y1]andE[Y0]foreachindividuali.Also,assumethatthese
i i
threesubjects compriseaperfectlyrepresentativesampleofthepopulation.

Table 2.2 A Hypothetical ExampleinWhich SUTVAIs Violated
Treatment assignment patterns Potential outcomes
⎡ ⎤ ⎡ ⎤ ⎡ ⎤
y1=3 y0=1
d =1 d =0 d =0 1 1
1 1 1
⎣ d 2=0 ⎦ or ⎣ d 2=1 ⎦ or ⎣ d 2=0 ⎦ y 21=3 y 20=1
d =0 d =0 d =1
3 3 3 y1=3 y0=1
3 3
⎡ ⎤ ⎡ ⎤ ⎡ ⎤
y1=2 y0=1
d =1 d =0 d =1 1 1
1 1 1
⎣ d 2=1 ⎦ or ⎣ d 2=1 ⎦ or ⎣ d 2=0 ⎦ y 21=2 y 20=1
d =0 d =1 d =1
3 3 3 y1=2 y0=1
3 3
This type of treatment effect dilution is only one way in which SUTVA can be
violated. More generally, suppose that d is an N × 1 vector of treatment indicator
variablesforN individuals(analogoustothe treatmentassignmentvectorsinthe first
column of Table 2.2), and define potential outcomes of each individual as functions
acrossallpotentialconfigurationsoftheelementsofvectord.Accordingly,theoutcome
for individual i under the treatment is y1(d), and the outcome for individual i under
i
the control is y0(d). The treatment effect for each individual i is then
i
δi(d)=y i1(d)−y i0(d). (2.5)
With this more general setup, individual-level treatment effects could be different for
every possible pattern of treatment exposure.

SUTVA is what allows us to declare y1(d)=y1 and y0(d)=y0 and, as a result,
i i i i
assert that individual-level causal effects δi exist that are independent of the overall
configurationofcausalexposure.IfSUTVA cannotbe maintained,thenthe simplified
definitioninEquation(2.1)isinvalid,andtheindividual-leveltreatmenteffectmustbe
writteninitsmostgeneralforminEquation(2.5),withallensuinganalysisproceeding
conditional on alternative vectors d.

Sometimes it is argued that SUTVA is so restrictive that we need an alternative
conception of causality for the social sciences. Our position is that SUTVA reveals
the limitations of social science data and the perils of immodest causal modeling
ratherthanthelimitationsofthepotentialoutcomemodelitself.Ratherthanconsider
SUTVA as overly restrictive, researchers should always reflect on the plausibility of
SUTVAineachapplicationandusesuchreflectiontomotivateacleardiscussionofthe
meaning and scope of all causal effect estimates offered. Such reflection may lead one
to determine that only the more general case of the potential outcome frameworkcan
be justified, and this may necessitate building the analysis on top of the individual-
level treatment effect defined in Equation (2.5) rather than the SUTVA-simplified
variant in Equation (2.1). In some cases, however, analysis can proceed assuming
SUTVA, as long as all resulting estimates are given restricted interpretations, as we
now explain.

Typical SUTVA violations share two interrelated features: (1) influence patterns
that result from contact across individuals in social or physical space and (2) dilu-
tion/concentration patterns that one can assume would result from changes in the
prevalence of the treatment. Neither feature is entirely distinct from the other, andin
manycasesdilution/concentrationeffects arisebecauseinfluence patternsarepresent.

Yet, ifthe violationcanbeinterpretedasadilution/concentrationpattern,evenwhen
generatedinpartby anunderlyinginfluence pattern, then the analystcanproceedby
scalingbacktheassertedrelevanceofanyestimatestosituationswheretheprevalence
of the treatment is not substantially different.

For a simple example, consider the worker training example. Here, the plausibil-
ity of SUTVA may depend on the particular training program. For small training
programs situated in large labor markets, the structure of wage offers to retrained
workers may be entirely unaffected by the existence of the training program. How-
ever, for a sizable training program in a small labor market, it is possible that the
wages on offer to retrained workers would be a function of the way in which the price
of labor in the local labor market responds to the movement of trainees in and out
of the program (as might be the case in a small company town after the company
has just gone out of business and a training program is established). As a result,
SUTVA may be reasonable only for a subset of the training sites for which data have
been collected.

For an example of where influence patterns are more of a threat to SUTVA, con-
sider the example of the Catholic school effect. For SUTVA to hold, the effectiveness
of Catholic schooling cannot be a function of the number (and/or composition) of
students who enter the Catholic school sector. For a variety of reasons – endogenous
peer effects, capacity constraints, and so on – most school effects researchers would
probablyexpect that the Catholic schooleffect wouldchangeif largenumbers ofpub-
lic school students entered the Catholic school sector. As a result, because there are
goodtheoreticalreasonstobelievethatthepatternofeffects wouldchangeifCatholic
schoolenrollmentsballooned,itmaybethatresearcherscanestimatethecausaleffect
of Catholic schooling only for those who would typically choose to attend Catholic
schools, but also subject to the constraint that the proportion of students educated
in Catholic schools remains constant. Accordingly, it may be impossible to determine
from any data that could be collected what the Catholic school effect on achievement
would be under a new distribution of students across school sectors that would result
froma largeandeffective policy intervention.As a result, the implications of research
on the Catholic school effect for research on school voucher programs may be quite
limited, and this has not been clearly enough recognized by some (see Howell and
Peterson 2002, chapter 6). A similar argument applies to research on charter school
effects.

Consider a SUTVA violationfor a related example: the evaluationof the effective-
ness of mandatory school desegregationplans in the 1970son the subsequent achieve-
ment of black students. Gathering together the results of a decade of research, Crain
andMahard(1983)conductedameta-analysisof93studiesofthedesegregationeffect
on achievement. They argued that the evidence suggests an increase of .3 standard
deviations in the test scores of black students across all studies.15 It seems undeni-
able that SUTVA is violatedfor this example, as the effect of moving fromone school
to another must be a function of relative shifts in racial composition across schools.

Breakingthe analysisintosubsetsofcitieswherethe compositionalshiftsweresimilar
could yield conditional average treatment effect estimates that can be more clearly
interpreted. In this case, SUTVA would be abandoned in the collection of all deseg-
regation events, but it could then be maintained for some groups (perhaps in cities
where the compositional shift was comparatively small).

In general, if SUTVA is maintained but there is some doubt about its validity
because dilution or concentration patterns would emerge under shifts in treatment
prevalence,thencertaintypesofmarginaleffectestimatescanusuallystillbedefended.

The idea here is to state that the estimates of average causal effects hold only for
what-if movements of relatively small numbers of individuals from one hypothetical
treatment state to another.

If,however,influencepatternsareinherenttothecausalprocessofinterest,andthe
SUTVA violation cannot be considered as a type of dilution or concentration, then it
will generally not be possible to circumvent the SUTVA violation by proceeding with
thesameanalysisandonlyofferingcautiousandconditionalinterpretations.Themost
well-developed literature on situations such as these is the literature on the effects of
vaccine programs (see Hudgens and Halloran 2008). Here, additional causal effects of
interest using the potential outcome framework have been defined, conditional on the
overallpattern of treatment assignment:
The indirect effect of a vaccination program or strategy on an individual
is the difference between what the outcome is in the individual not being
vaccinated in a community with the vaccination program and what the
outcome would have been in the individual, again not being vaccinated,
but in a comparable community with no vaccination program. It is, then,
the effect of the vaccination program on an individual who was not vacci-
nated. The combined total effect in an individual of being vaccinated and
the vaccination program in the community is the difference between the
outcomeintheindividualbeingvaccinatedinacommunitywiththevacci-
nationprogramand whatthe outcomewouldbe if the individual werenot
vaccinatedand the community did not havethe vaccinationprogram.The
total effect, then, is the effect of the vaccination program combined with
theeffectofthepersonhavingbeenvaccinated.Theoverall effect ofavac-
cination programis the difference in the outcome in an averageindividual
15As reviewed by Schofield (1995) and noted in Clotfelter (2004), most scholars now accept that
the evidence suggests that black students who were bused to predominantly white schools experi-
encedsmallpositivereadinggainsbutnosubstantialmathematicsgains.CookandEvans(2000:792)
conclude that “it is unlikely that efforts at integrating schools have been an important part of the
convergenceinacademicperformance[betweenwhitesandblacks],atleastsincetheearly1970s”(see
also Armor 1995; Rossell, Armor, and Walberg 2002). Even so, others have argued that the focus
ontest scoregains hasobscured someofthe trueeffectiveness ofdesegregation. Inareview ofthese
longer-termeffects,WellsandCrain(1994:552) concludethat“interracialcontactinelementaryand
secondaryschoolcanhelpblacksovercomeperpetualsegregation.”
inacommunitywiththevaccinationprogramcomparedtoanaverageindi-
vidualinacomparablepopulationwithnovaccinationprogram.(Halloran,
Longini, and Struchiner 2010:272;italics in the original)
Effectively estimating these types of effects generally requires a nested randomization
structure, wherein (1) vaccine programs are randomly assigned to a subset of par-
ticipating groups and then (2) vaccinations are randomly given to individuals within
groups enrolled in vaccine programs. These particular study designs are not possible
for most social science applications, but the basic interpretive framework has been
adopted to clarify what can be learned from social experiments, in particular, the
Moving to Opportunity neighborhood experiment (see Sobel 2006).16
Much observational researchon social influence patterns proceeds without consid-
erationofthese sortsofcomplications.Considerthe contentiousliteratureonwhether
peer effects have accelerated the obesity epidemic, as presented in Section 1.3 (see
page 26). As we noted there, the basic claim of Christakis and Fowler (2007) is that
having a friend who becomes obese increases one’s own odds of becoming obese. Yet,
theirfullsetofclaimsissubstantiallymoredetailed,suggestingthatthesepeereffects
travelacrossnetwork paths of length three before dying out. In particular,one’s odds
of becoming obese also increase if friends of friends become obese and if friends of
friends of friends become obese. The sizes of these three effects diminish with the
length of friendship distance.

Now consider whether SUTVA is reasonable for such a schedule of effects across
network ties. Holding the social network structure fixed, if obesity increases in the
population,then,onaverage,individualshavemoreobesefriends,moreobesefriendsof
friends,andmoreobesefriendsoffriendsoffriends.Mosttheoreticalpredictionswould
suggest that the effects on one’s own odds of becoming obese that result from having
friends of friends of friends who become obese should decline with the proportion of
one’s own friends who are already obese or who have just become obese.17 Effects
that cascade in these conditional ways, because they are defined across a pattern of
interpersonal contact between units, nearly always violate SUTVA.18
16Suitablemodelsforobservationaldataareanactivefrontierofresearch(seeHongandRaudenbush
2013; Manski 2013a). Tchetgen Tchetgen and VanderWeele (2010) show that some estimators may
be effective for applications withobservational data if allrelevant patterns of treatment assignment
(i.e.,d)canbeattributed tomeasuredtreatment-level variables.

17Thismeansthat,eveniftheissuesraisedbycriticsontheseverityofhomophilybiasareinvalid
(seeVanderWeele2011bforaconvincingcasethattheyhavebeenexaggerated),thepatternofeffects
only holds under the prevalence of obesity in the data analyzed, which is the pattern of obesity in
Framingham, Massachusetts, among adults bornin1948 forwhom data wascollected between 1971
and 1999 (and for a social network structure elicited by an unconventional name generator). The
overall pattern of declining effects may be valid, but the relation of the various lagged regression
coefficients offeredtowell-definedcausaleffects ofgeneralinterestmayberatherthin.

18Whenwehaveconveyedthispointtonetworkanalysisresearchers,acommonreactionisthatthe
potential outcome model must not, therefore, be suitable for studying causal effects that propagate
across networks. The logic of this position eludes us for two reasons. First, the potential outcome
model cannot bedeemed inappropriatebecause itmakes clearhow harditistodefine andestimate
theeffects that analysts claimthatthey wishtoestimate. Second, thepotential outcome model can
accommodate SUTVA violations, although not without considerable additional effort. Weihua An
(2013) demonstrates the value of counterfactual thinking for modeling peer effects, fully embedded
withinasocialnetworkperspective(seealsoVanderWeeleandAn2013).

## 2.6 Treatment Assignment and Observational Studies

A researcher who wishes to estimate the effect of a treatment that he or she can con-

trol on an outcome of interest typically designs an experiment in which subjects are
randomly assignedto alternativetreatment and controlgroups.Other types of exper-
iments are possible, as we described in Chapter 1, but randomized experiments are
the most common research design when researchers have control over the assignment
of the treatment.

After randomizationofthe treatment,the experimentis run,andthe values ofthe
observed outcome, yi, are recorded for those in the treatment group and for those in
thecontrolgroup.Themeandifferenceintheobservedoutcomesacrossthetwogroups
is then anointed the estimated average causal effect, and discussion (and any ensuing
debate)then movesonto the particularfeatures of the experimentalprotocoland the
degree to which the pool of study participants reflects the population of interest for
which one would wish to know the average treatment effect.

Considerthisrandomizationresearchdesignwithreferencetotheunderlyingpoten-
tial outcomes defined earlier. For randomized experiments, the treatment indicator
variable D is forced by design to be independent of the potential outcome variables
Y1 and Y0. (However, for any single experiment with a finite set of subjects, the
values of di will be related to the values of y i1 and y i0 because of chance variability.)
Knowingwhether ornotasubjectis assignedto the treatmentgroupin arandomized
experimentyieldsnoinformationwhatsoeveraboutasubject’swhat-ifoutcomeunder
the treatment state, y1, or, equivalently, about a subject’s what-if outcome under the
i
controlstate,y0.Treatmentstatusisthereforeindependentofthepotentialoutcomes,
i
andthetreatmentassignmentmechanismissaidtobeignorable.19 Thisindependence
assumption is usually written as
(Y0,Y1)⊥⊥ D, (2.6)
where the symbol ⊥⊥ denotes independence and where the parentheses enclosing Y0
and Y1 stipulate that D must be jointly independent of all functions of the potential
outcomes (such as δ). For a properly run randomized experiment, learning the treat-
ment to which a subject has been exposedgives no informationwhatsoever about the
size of the treatment effect.

This way of thinking about randomized experiments and potential outcomes can
be confusing to social scientists who work primarily with observational data. The
independence relationships represented by Equation (2.6) seem to imply that even
a well-designed randomized experiment cannot tell us about the causal effect of the
treatment on the outcome of interest. But, of course, this is not so, because Equation
(2.6) does not imply that D is independent of Y.Equation ( 2.6) implies only that in
the full population, ex ante to any patternoftreatmentassignment,D is independent
ofY0, Y1, andany causaleffects defined fromthem. Only after a study is undertaken
19Aswewilldiscussindetailinlaterchapters,theword“ignorability”hasaveryspecificmeaning
thatisbroaderthanimpliedinthisparagraph.Inshort,ignorabilityalsoholdsintheweakersituation
in which S is a set of observed variables that characterize treatment assignment patterns and in
which(Y0,Y1)⊥⊥ D | S.Thus, treatment assignment is ignorablewhen the potential outcomes are
independentofD,conditionalonS.

do values for Y emerge, from Y =DY1+(1−D)Y0 in Equation (2.2). If individuals
are randomly assigned to both the treatment and the control states, and individual
causal effects are nonzero, then Y and D will be dependent because the averagevalue
of DY1 will not be equal to the average value of (1−D)Y0.

Nowconsidertheadditionalchallengesposedbyobservationaldataanalysis.These
challenges to causal inference are the defining features of an observational study,
according to Rosenbaum (2002:vii):
An observational study is an empiric investigation of treatments, policies,
or exposures and the effects they cause, but it differs from an experiment
in that the investigator cannot control the assignment of treatments to
subjects.20 (Italics in the original)
Observational data analysis in the counterfactual tradition is thus defined by a lack
of control over the treatment – and often more narrowly by the infeasibility of ran-
domizationdesignsthatallowforthestraightforwardmaintenanceoftheindependence
assumptioninEquation(2.6).Anobservationalresearcher,hopingtoestimateacausal
{yi,di}N
effect, begins with observed data in the form of values for an observed out-
i
comevariable,Y,andatreatmentstatusvariable,D.Todeterminethecausalofeffect
ofDonY,thefirststepinanalysisistoinvestigatethetreatmentselectionmechanism.

Noticetheswitchinlanguagefromassignmenttoselection.Becauseobservationaldata
analysisisdefinedasempiricalinquiryinwhichtheresearcherdoesnothavethecapac-
itytoassignindividualstotreatments(or,asRosenbaumstatesequivalently,toassign
treatments to individuals), researchers must instead investigate how individuals are
selected into alternative treatment states.

And herein lies the challenge of much scholarship in the social sciences. Although
someoftheprocessbywhichindividualsselectalternativetreatmentscanbeexamined
empirically, a full accounting of treatment selection is sometimes impossible (e.g., if
subjects are motivated to select on the causal effect itself and a researcher does not
have a valid measure of the expectations that determine their choices). As much as
this challenge may be depressing to a dispassionate policy designer/evaluator, this
predicamentshould not be depressingfor social scientists in general.On the contrary,
our existential justification rests on the pervasive need to deduce theoretically from a
setofbasicprinciplesorinferfromexperienceandknowledgeofrelatedstudiestheset
of defendable assumptions about the missing components of the treatment selection
mechanism. Only through such effort can it be determined whether causal analysis
can proceed or whether further data collection and preliminary theoretical analysis
are necessary.

## 2.7 Average Causal Effects and Naive Estimation

Thefundamentalproblemofcausalinferencerequiresthatwefocusonnon–individual-

level causal effects, maintaining assumptions about treatment assignment and treat-
mentstabilitythatwillallowustogivecausalinterpretationstodifferencesinaverage
20NotethatRosenbaum’sdefinitionisconsistentwiththeCoxandReiddefinitionquotedinChapter
1(seepage7).

valuesofobservedoutcomes.Intheremainderofthischapter,wedefineaveragetreat-
ment effects of varying sorts and then lay out the complications of estimating them.

Inparticular,we considerhow averagetreatmenteffects varyacrossthose whoreceive
the treatment and those who do not.

2.7.1 Conditional Average Treatment Effects
The unconditional average treatment effect, which is typically labeled the ATE in
the counterfactual tradition, wasdefined in Equation(2.3) as E[δ]=E[Y1−Y0]. This
averageeffectisthemostcommonsubjectofinvestigationinthesocialsciences,andit
is the causaleffect thatis closestto the sortsof effects investigatedinthe broadfoun-
dationalexamplesintroducedinSection1.3.1,suchastheeffectsoffamilybackground
and mental ability on educational attainment, the effects of educational attainment
and mental ability on earnings, and the effects of socioeconomic status on political
participation. More narrowly defined average causal effects are of interest as well in
virtually all of the other examples introduced in Chapter 1.

Two conditional average treatment effects are of particular interest. The average
treatment effect for those who typically take the treatment is
E[δ|D=1]=E[Y1−Y0|D=1] (2.7)
=E[Y1|D=1]−E[Y0|D=1],
and the average treatment effect for those who typically do not take the treatment is
E[δ|D=0]=E[Y1−Y0|D=0] (2.8)
=E[Y1|D=0]−E[Y0|D=0],
where, as for the ATE in Equation (2.3), the second line of each definition follows
from the linearity of the expectation operator. These two conditional average causal
effectsareoftenreferredtoby theacronymsATT andATC,whichsignifythe average
treatment effect for the treated and the average treatment effect for the controls,
respectively.

Consider the examples again. For the Catholic school example, the ATT is the
average effect of Catholic schooling on the achievement of those who typically attend
Catholicschoolsratherthanacrossallstudents who couldpotentially attendCatholic
schools. The difference between the ATE and the ATT can also be understood with
reference to individuals. From this perspective, the average treatment effect in Equa-
tion (2.3) is the expected what-if difference in achievement that would be observed if
we could educate a randomly selected student in both a public school and a Catholic
school. In contrast, the ATT in Equation (2.7) is the expected what-if difference in
achievementthatwouldbe observedif we couldeducate a randomlyselected Catholic
school student in both a public school and a Catholic school.

For this example, the ATT is a theoretically important quantity, for if there is no
Catholic school effect for Catholic school students, then most reasonable theoretical
arguments would maintain that it is unlikely that there would be a Catholic school
effect for students who typically attend public schools (at least after adjustments for
observable differences between Catholic and public school students). And, if policy
interest were focused on whether or not Catholic schooling is beneficial for Catholic
schoolstudents(andthuswhetherpublicsupportoftransportationtoCatholicschools
is a benevolent government expenditure, etc.), then the Catholic school effect for
Catholic school students is the only quantity we would want to estimate. The ATC
would be of interestas well if the goalof analysis is ultimately to determine the effect
of a potential policy intervention, such as a new school voucher program, designed to
move more students out of public schools and into Catholic schools. In fact, an even
narrower conditional average treatment effect might be of interest: E[δ|D=0, Cur-
rentSchool = Struggling], where of course the definition of being currently educated
in a struggling school would have to be clearly specified.

The worker training example is similar, in that the subject of first investigation
is surely the ATT (as discussed in detail in Heckman et al. 1999). If a cost-benefit
analysis of a program is desired, then a comparison of the aggregate net benefits for
thetreatedtotheoverallcostsoftheprogramtothefundersisneeded.Thetreatment
effect for other potential enrollees in the treatment program could be of interest as
well, but this effect is secondary (and may be impossible to estimate for groups of
individuals completely unlike those who have enrolled in the program in the past).

The butterfly ballot example is somewhat different. Here, the treatment effect of
interest is bound by a narrow question that was shaped by media attention. The
investigatorswereinterestedonly inwhatactually happenedinthe 2000election,and
they focused very narrowly on whether the effect of having had a butterfly ballot
rather than an optical scan ballot caused some individuals to miscast their votes.

And, in fact, they were most interested in narrow subsets of the treated, for whom
specific assumptions were more easily asserted and defended (e.g., those who voted
for Democrats in all other races on the ballot but who voted for Pat Buchanan or Al
Gore for president). In this case, the ATC, and hence the all-encompassingATE, was
of little interest to the investigators (or to the contestants and the media).

As these examples demonstrate, more specific averagecausal effects (or more gen-
eral properties of the distribution of causal effects) are often of greater interest than
simply the average causal effect in the population. In this book, we will focus mostly
on the three types of averagecausal effects representedby Equations (2.3), (2.7), and
(2.8), as well as simple conditional variants of them. But, especially when presenting
instrumental variable estimators later and discussing general heterogeneity issues, we
willalsofocusonmorenarrowlydefinedcausaleffects.Heckman(2000),Manski(1995),
andRosenbaum(2002)allgivefulldiscussionsofthevarietyofcausaleffectsthatmay
be relevant for different types of applications, such as quantiles of the distribution of
individual-levelcausaleffectsinsubpopulationsofinterestandtheprobabilitythatthe
individual-levelcausaleffectisgreaterthanzeroamongthetreated(seealsoHeckman,
Smith, and Clements 1997).

2.7.2 Naive Estimation of Average Treatment Effects
Suppose again that randomization of the treatment is infeasible and thus that only
an observational study is possible. Instead, an autonomous fixed treatment selection
regime prevails, where π is the proportion of the population of interest that takes
the treatment instead of the control. In this scenario, the value of π is fixed in the
populationbythebehaviorofindividuals,anditisunknown.Suppose furtherthatwe
haveobservedsurvey data from a relativelylarge randomsample of the population of
interest.

Becausewearenowshifting fromthepopulationtodatageneratedfromarandom
sample of the population, we must use appropriate notation to distinguish sample-
based quantities from the population-based quantities that we have considered until
now. For the sample expectation of a quantity in a sample of size N, we will use a
subscript on the expectation operator, as in EN[.]. With this notation, EN[di] is the
sample mean of the dummy treatment variable, EN[yi|di=1] is the sample mean of
theoutcomeforthoseobservedinthetreatmentgroup,andEN[yi|di=0]isthesample
mean of the outcome for those observed in the control group.21 The naive estimator
is then defined as
δˆ NAIVE≡EN[yi|di=1]−EN[yi|di=0], (2.9)
which is simply the difference in the sample means of the observed outcome variable
Y for the observed treatment and control groups.

In observational studies, the naive estimator rarely yields consistent or unbiased
estimates of the ATE because it converges to a contrast, E[Y|D=1]−E[Y|D=0],
that is not equivalent to (and usually not equal to) any of the average causal effects
defined above. To see why, first decompose the ATE in Equation (2.3) as
E[δ]={πE[Y1|D=1]+(1−π)E[Y1|D=0]} (2.10)
−{πE[Y0|D=1]+(1−π)E[Y0|D=0]}.

Equation(2.10)revealsthattheATEisafunctionoffiveunknowns:theproportionof
the population that is assigned to (or self-selects into) the treatment along with four
conditional expectations of the potential outcomes.

With observational data from a random sample of the population and without
introducing additional assumptions, we can compute estimates that are consistent
and unbiased for only three of the five unknowns on the right-hand side of Equation
(2.10). Consider π first, which we have defined as equal to E[D], and which is the
fixedproportionofthe populationthatwouldbe assignedto(orwouldselectinto)the
treatment. The sample-mean estimator, EN[di], is consistent for π, which we write as
p
EN[di]−→π. (2.11)
Equation(2.11)representstheclaimthat,asthesamplesizeN increasestoinfinity,the
sample mean of the values for di convergesto the true value of π, which we assume is
p
afixedpopulationparameterequalexactlyto E[D].22 Thus,thenotation−→denotes
convergencein probability for a sequence of estimates overa set of samples where the
sample size N is increasing to infinity. (Estimators with this property are defined as
21In other words, the subscript N serves the same basic notational function as an overbar on y i,
asiny¯i.Weusethissub-N notationbecauseitallowsforgreaterclarityinaligningsample-leveland
population-levelconditional expectations forsubsequentexpressions.

22Again,seeourappendixtothischapteronourassumedsuperpopulationmodel.Weareimplicitly
assuming that these sequences are well defined because conditions are such that the law of large
numbersisapplicable.

“consistent” in the statistical literature on estimation. We can also state that EN[di]
is unbiased for π because the expected value of EN[di] over repeated samples of size
N from the same population is equal to π as well. However, in this book we focus
primarily on the consistency of estimators.)23
We can offer similar claims for consistent estimators of two other unknowns in
Equation (2.10):
p
EN[yi|di=1]−→E[Y1|D=1], (2.12)
p
EN[yi|di=0]−→E[Y0|D=0], (2.13)
which indicate that the sample mean of the observedoutcome in the treatment group
converges to the true average outcome under the treatment state for those in the
treatment group (and analogously for the control group and control state).

Unfortunately, however, there is no assumption-free way to compute consistent
or unbiased estimates of the two remaining unknowns in Equation (2.10): E[Y1|D=
0] and E[Y0|D=1]. These are counterfactual conditional expectations: the average
outcome under the treatment for those in the control group and the averageoutcome
under the control for those in the treatment group. Without further assumptions, no
estimatedquantitybasedonobserveddatafromarandomsampleofthepopulationof
interestwouldconvergetothetruevaluesfortheseunknowncounterfactualconditional
expectations. For the Catholic school example, these are the average achievement of
public school students if they had instead been educated in Catholic schools and the
average achievement of Catholic school students if they had instead been educated in
public schools.

2.7.3 The Typical Inconsistency and Bias of the
Naive Estimator
In the last section, we concluded that the naive estimator δˆ , which is defined
NAIVE
as EN[yi|di=1]−EN[yi|di=0], converges to a contrast, E[Y1|D=1]−E[Y0|D=0],
that does not necessarily equal the ATE. In this section, we show why this contrast
can be uninformative about the causal effect of interest in an observational study
by analyzing the typical inconsistency and bias in the naive estimator as an esti-
mator of the ATE.24 Consider the following rearrangement of the decomposition in
23Nonetheless, we willoften label estimators as “consistent and unbiased” when this is true, even
though we will not state the case for unbiasedness. On the one hand, estimators of fixed, finite
values in the population that are consistent are necessarily also asymptotically unbiased. On the
otherhand,someconsistentestimatorsarenotunbiasedinfinitesamples(mostprominently,forthis
book,theinstrumentalvariableestimatorsthatwewillpresentinChapter9).Aswiththestatistical
literatureonpointestimation,wetypicallyinterpretunbiasednessasadesirablepropertyamongthe
consistentestimatorsthatwewillpresent.Ifanestimatorisnotconsistent(i.e.,isinconsistent),then
inpractice thereislittlereasontofurther considerit(as unbiased, etc.), especiallywheninvokinga
superpopulationperspectiveandassumingthatadataset foralargerandomsampleisavailable.

24Animportantpointofthisliteratureisthattheinconsistencyandbiasofanestimatorisafunction
of the target parameter that has been selected for analysis. Because there are many causal effects
that can be estimated, general statements about the inconsistency andbias of particular estimators
arealwaysconditionalonaclearindicationofthecausaleffectofinterest.

Equation (2.10):
E[Y1|D=1]−E[Y0|D=0]=E[δ]+{E[Y0|D=1]−E[Y0|D=0]} (2.14)
+ (1−π){E[δ|D=1]−E[δ|D=0]}.

The naive estimator converges to the difference on the left-hand side of this equa-
tion, and the right-hand side shows that this difference is equal to the true ATE,
E[δ], plus the expectations of two potential sources of inconsistency and bias in
the naive estimator.25 The first source, {E[Y0|D=1]−E[Y0|D=0]}, is a baseline
bias equal to the difference in the expected outcome in the absence of the treat-
ment between those in the treatment group and those in the control group. The sec-
ond source, (1−π){E[δ|D=1]−E[δ|D=0]}, is a differential treatment effect bias
equal to the expected difference in the treatment effect between those in the treat-
ment group and those in the control group (multiplied by the proportion of the
population under the fixed treatment selection regime that does not select into the
treatment).

Toclarifythisdecomposition,considerasubstantiveexample–theeffectofeduca-
tiononanindividual’smentalability.Assumethatthetreatmentiscollegeattendance.

After administering a test to a group of young adults, we find that individuals who
have attended college score higher than individuals who have not attended college.

There are three possible reasons that we might observe this finding. First, attending
collegemightmakeindividualssmarteronaverage.ThiseffectistheATE,represented
by E[δ] in Equations (2.3) and (2.14). Second, individuals who attend college might
have been been smarter in the first place. This source of inconsistency and bias is
the baseline difference represented by E[Y0|D=1]−E[Y0|D=0]. Third, the mental
ability of those who attend college may increase more than would the mental abil-
ity of those who did not attend college if they had instead attended college. This
source of inconsistency and bias is the differential effect of the treatment represented
by E[δ|D=1]−E[δ|D=0].

Tofurtherclarifythelastterminthedecomposition,considerthealternativehypo-
thetical example depicted in Table 2.3. Suppose, for context, that the potential out-
comesarenowsomeformoflabormarketoutcome,andthatthetreatmentiswhether
ornotanindividualhasobtainedabachelor’sdegree.Suppose furtherthat30percent
of the population obtains a bachelor’s degree, such that π is equal to .3. As shown on
themaindiagonalofTable2.3,theaverage(orexpected)potentialoutcomeunderthe
treatmentis10forthoseinthetreatmentgroup,andtheaverage(orexpected)poten-
tial outcome under the control for those in the control group is 5. Now, consider the
off-diagonalelementsofthetable,whichrepresentthecounterfactualaveragepotential
outcomes. According to these values, those who have bachelor’s degrees would have
done better in the labor marketthan those without bachelor’sdegrees in the counter-
factual state in which they did not in fact obtain bachelor’s degrees (i.e., on average
theywouldhavereceived6insteadof5).Likewise,thosewhodonotobtainbachelor’s
25The referenced rearrangement is simply a matter of algebra. Let E[δ]=e, E[Y1|D=1]=a,
E[Y1|D=0]=b,E[Y0|D=1]=c,andE[Y0|D=0]=dsothatEquation(2.10)canbewrittenmore
compactlyase={πa+(1−π)b}−{πc+(1−π)d}. Rearrangingthisexpressionasa−d=e+a−b−
πa+πb+πc−πdthen simplifiesto a−d=e+{c−d}+{(1−π)[(a−c)−(b−d)]}.Substituting for
a,b,c,d,andethenyieldsEquation(2.14).

Table 2.3 An Example of Inconsistency and
Bias of the Naive Estimator When the ATE Is
the Causal Effect of Interest
Group E[Y1|D] E[Y0|D]
Treatment group (D=1) 10 6
Control group (D=0) 8 5
degreeswould not havedone as wellas those who did obtain bachelor’sdegreesin the
counterfactual state in which they did in fact obtain bachelor’s degrees (i.e., on aver-
age they would have received 8 rather than 10). Accordingly, the ATT is 4, whereas
the ATC is only 3.26 Finally, if the proportionof the population that has a bachelor’s
degree is .3, then the ATE is 3.3, which is equal to .3(10−6)+(1−.3)(8−5).

Consider now the inconsistency and bias of the naive estimator. For this exam-
ple, the naive estimator, as defined in Equation (2.9), would be equal to 5 for an
infinite sample (or equal to 5, on average, across repeated samples). Thus, the naive
estimator is inconsistent and upwardly biased for the ATE (i.e., yielding 5 rather
than 3.3), the ATT (i.e., yielding 5 rather than 4), and the ATC (i.e., yielding 5
rather than 3). Equation (2.14) gives the components of the total expected bias of
1.7 for the naive estimator as an estimate of the ATE. The term {E[Y0|D=1]−
E[Y0|D=0]},whichwe labeledthe expected baselinebias, is 6−5=1.The term(1−
π){E[δ|D=1]−E[δ|D=0]},whichistheexpecteddifferentialtreatmenteffectbias,is
(1−.3)(4−3)=.7.27
2.7.4 Estimating Causal Effects Under Maintained
Assumptions About Potential Outcomes
What assumptions suffice to enable consistent and unbiased estimation of the ATE
withthe naiveestimator?Therearetwobasicclassesofassumptions:(1)assumptions
about potential outcomes for subsets of the population defined by treatment status
and (2) assumptions about the treatment assignment/selection process in relation to
thepotentialoutcomes.Thesetwotypesofassumptionsarevariantsofeachother,and
eachmayhaveaparticularadvantageinmotivatinganalysisinaparticularapplication.

In this section, we discuss only the first type of assumption, as it suffices for the
presentexaminationofthefallibilityofthenaiveestimator.Andourpointinintroduc-
ingtheseassumptionsissimplytoexplaininonefinalwaywhythenaiveestimatorwill
fail in most social science applications to generate a consistent and unbiased estimate
of the ATE when randomization of the treatment is infeasible.

26Forthecausaleffectofeducationonearnings,thereisdebateintherecentliteratureonwhether
theATTislargerthan theATC.CunhaandHeckman(2007) andCarneiro,Heckman, andVytlacil
(2011) offer results in support of this pattern, but Brand and Xie (2010) offer results in opposition
toit.

27In general, the size of this expected differential treatment effect bias declines as more of the
populationischaracterizedbytheATTthanbytheATC(i.e.,asπ approaches 1).

Consider the following two assumptions:
Assumption 1: E[Y1|D=1]=E[Y1|D=0], (2.15)
Assumption 2: E[Y0|D=1]=E[Y0|D=0]. (2.16)
Ifone assertsthese twoequalities andthensubstitutes intoEquation(2.10), the num-
ber of unknowns is reduced from the original five parameters to the three parameters
that we know from Equations (2.11)–(2.13) can be consistently estimated with data
generated from a random sample of the population. If both Assumptions 1 and 2
are maintained, then the ATE, ATT, and ATC in Equations (2.3), (2.7), and (2.8),
respectively, are all equal. And the naive estimator is consistent and unbiased for all
of them.

When would Assumptions 1 and 2 in Equations (2.15) and (2.16) be reasonable?
Clearly, if the independence of potential outcomes, as expressed in Equation (2.6), is
valid because the treatment has been randomly assigned, then Assumptions 1 and 2
in Equations (2.15) and (2.16) are implied. But, for observational data analysis, for
which random assignment is infeasible, these assumptions would rarely be justified.

ConsidertheCatholicschoolexample.Ifonewerewillingtoassumethatthosewho
choosetoattendCatholicschoolsdosoforcompletelyrandomreasons,thenthesetwo
assumptions could be asserted. We know from the applied literature that this char-
acterization of treatment selection is false. Nonetheless, one might be able to assert
insteadaweakernarrativetowarrantthesetwoassumptions.Onecouldmaintainthat
studentsandtheir parentsmakeenrollmentdecisionsbasedontastesforaneducation
with a religious foundation and that this taste is unrelated to the two potential out-
comes, such that those with a taste for education with a religious foundation would
not be expected to score higher on math and reading tests if educated in Catholic
schoolsratherthanpublicschools.Thispossibilityalsoseemsunlikely,inpartbecause
it implies that those with a distaste for education with a religious foundation do not
attendCatholicschools.It seemsreasonabletoassumethatthese students wouldper-
form substantially worse in Catholic schools than the typical students who do attend
Catholic schools.

Thus, at least for the Catholic school example, there seems no way to justify the
naiveestimator as a consistentandunbiasedestimator of the ATE. We encouragethe
readerto consider all of the examples presentedin Chapter 1, and we suspect that all
will agree that Assumptions 1 and 2 in Equations (2.15) and (2.16) cannot both be
sustained for any of them.

Finally,itisimportanttorecognizethatassumptionssuchasthesecanbeevaluated
separately. Consider the two relevant cases for Assumptions 1 and 2:
1. If Assumption 1 is true but Assumption 2 is not, then E[Y1|D=1]=E[Y1|
D=0], whereas E[Y0|D=1](cid:6)=E[Y0|D=0]. In this case, the naive estimator
remains inconsistent and biased for the ATE, but it is now consistent and unbi-
ased for the ATC. This result is true because of the same sort of substitution
we notedearlier.We know thatthe naiveestimatorEN[yi|di=1]−EN[yi|di=0]
converges to E[Y1|D=1]−E[Y0|D=0]. If Assumption 1 is true, then one can
substitute E[Y1|D=0]for E[Y1|D=1]. Then, one canstate thatthe naiveesti-
mator convergesto the contrastE[Y1|D=0]−E[Y0|D=0]when Assumption 1
is true. This contrast is defined in Equation (2.8) as the ATC.

2. IfAssumption2istruebutAssumption1isnot,thenE[Y0|D=1]=E[Y0|D=0],
whereasE[Y1|D=1](cid:6)=E[Y1|D=0].Theoppositeresulttothepriorcasefollows.

One can substitute E[Y0|D=1] for E[Y0|D=0] in the contrast E[Y1|D=1]−
E[Y0|D =0]. Then, one can state that the naive estimator converges to the
contrastE[Y1|D=1]−E[Y0|D=1]whenAssumption 2is true. This contrastis
defined in Equation (2.7) as the ATT.

Considering the validity of Assumptions 1 and 2 separately shows that the naive esti-
mator may be inconsistent and biased for the ATE and yet may be consistent and
unbiasedforeithertheATTortheATC.Thesepossibilitiescanbe importantinprac-
tice. For some applications, it may be the case that we have good theoretical reason
to believe that (1) Assumption 2 is validbecause those in the treatmentgroupwould,
on average, do no better or no worse in the counterfactual control state than those
in the control group, and (2) Assumption 1 is invalid because those in the control
group would not do nearly as well in the counterfactual treatment state as those in
the treatment group. Or, stated more simply, we may have goodtheoretical reasonto
believe that the treatment is more effective for the treatment group than it would be
forthecontrolgroup.Underthisscenario,the naiveestimatorwilldeliveraconsistent
and unbiased estimate of the ATT, even though it is still inconsistent and biased for
both the ATC and the unconditional ATE.

Now,returntothecaseinwhichneitherAssumption1norAssumption2istrue.If
the naive estimator is therefore inconsistent and biased for the typical average causal
effects of interest, what can be done? The first recourse is to attempt to partition
the sample into subgroups within whichassumptions suchas Assumptions 1 and/or2
canbe defended. This strategyamounts toconditioning ononeormore variablesthat
identifysuchstrataandthenassertingthatthenaiveestimatorisconsistentandunbi-
asedwithinthesestrataforoneoftheaveragetreatmenteffects.Onecanthenaverage
estimates from these strata in a reasonable way to generate the average causal effect
estimate of interest. We will explain this strategy in great detail in subsequent chap-
ters.Next, weintroduceover-timepotentialoutcomesandthenextendthe framework
to many-valued causes.

## 2.8 Over-Time Potential Outcomes and Causal Effects

Having shown in the last section that the cross-sectional naive estimator will rarely

deliver consistent and unbiased estimates of average causal effects of interest when
analyzing observational data, it is natural to then wonder whether observing individ-
uals across time and then estimating similar unconditional differences may be more
promising. We will take the position in this book that the power of over-time obser-
vationis considerablebut that it is also too oftenoversoldand misunderstood. Inthis
section,welayoutthebasicpotentialoutcomemodelwhenobservationsoccurinmore
than one time period, moving from the case of a single individual or unit to multiple
individuals or units. We reserve our full treatment of the strengths and weaknesses of
alternative estimators using repeated observations for Chapter 11.

2.8.1 A Single Unit Over Time
Consider the analysis of a single unit, observed during time intervals indexed by a
discrete counter t that increases from 1 to T. The outcome variable is Yt, which has
observed values {y 1,y 2,y 3,...,yT}. Suppose that we have a two-state causal variable,
Dt, that is equal to 1 if the treatment is in place during a time period t and is equal
to 0 otherwise.

Because we are considering only one unit of analysis – possibly an individual but
morelikely aschool,organization,city,state,country,orotheraggregateunit –wedo
not have either a control group or a treatment group. Instead, we have a single unit
thatisexposedtothetreatmentstateandthecontrolstateatdifferentpointsintime.

The fundamental problem/reality of causal inference now is that we cannot observe
the same unit at the same time in both the treatment state and the control state.

For an analysis of a single unit, it only makes sense to consider designs where we
have at least some pretreatment data and where the unit under consideration spends
at least one time period in the treatment state. In particular, we will label the time
period in which the treatment is initiated as t∗, and our restriction to situations in
which pretreatment data are available requires that 1<t∗ ≤T. We will allow the
treatment to persist for one or more time periods, from t∗ through t∗+k, where
k≥0.Oncethe treatmentends, followingt∗+k, wewill notallowthe treatmentto be
reintroduced before the full observation window terminates at T.

We can set up the potential outcome model in the following way to capture the
basic features of before-and-after designs for a single unit of analysis:
1. Before the treatment is introduced (for t<t∗):28
Dt=0
Yt=Y t0
2. While the treatment is in place (from t∗ through t∗+k):
Dt=1
Yt=Y t1
Y0existsbutiscounterfactual
t
28AlthoughintheorycounterfactualvaluesY t1 existinpretreatmenttimeperiods,thesevaluesare
nottypicallyconsidered.Ifonewereinterestedinaskingwhatthetreatmenteffectwouldhavebeenif
thetreatment hadbeenintroducedinanearliertimeperiod,thenthesecounterfactual values would
needtobeintroducedintotheanalysis.

3. After the treatment ends (for time periods t>(t∗+k)):29
Dt=0
Yt=Y t1
Y0existsbutiscounterfactual.

t
For a single unit, the causal effect of the treatment is
δt=Y t1−Y t0, (2.17)
andtheseeffectsmayexistinmorethanonetimeperiodt,dependingonthedurationof
thetreatmentandwhetherthetreatmentisassumedtobeareversibletreatmentstate
orapermanentchangethatcannotbeundone.Studiesareoftenunclearonmaintained
assumptionssuchasthese,aswellasonthedistinctionsbetweentimeperiodsoftypes
2 and 3. Our setup is very general and can accommodate many alternative types of
studies withonly minormodifications,including thosefor whichtime periods oftypes
2 or 3 are unobserved.30 Because suchassumptions and designfeatures will alwaysbe
application-specific, we offer a worked example next.

The Year of the Fire Horse
Foraconcreteexamplethatrevealsthepossiblepowerofover-timeanalysisforasingle
unit, consider a variant of the demography example on the determinants of fertility
introduced in Section 1.3 (see page 17). In addition to the individual-level effects of
family backgroundandother life course events onfertility decisions,the causaleffects
ofreligion,values,andmoregeneralculturalbeliefshavebeenoflong-standinginterest
aswell(seeMayerandMarx1957;WestoffandJones1979;HayfordandMorgan2008;
Thornton, Binstock, Yount et al. 2012).

Supposethattheunitofanalysisisthebirthrateinasinglecountry,estimatedfrom
aggregate census data and vital statistics. The example we will consider is presented
in Figure 2.1, which displays birth rates in Japan between 1951 and 1980. Following
a post-war baby boom, birth rates in Japan were comparatively stable from the late
1950s through the early 1960s. However, in 1966, the birth rate fell precipitously,
after whichit reboundedin1967andthenstabilized.Fromthe 1970sonward,Japan’s
birth rate then resumed its decline, as its population aged and it continued with its
demographic transition to a low mortality and low fertility country, as discussed in
general in Chapter 1.31
29Below we will consider an example where k≤(T−t∗), but we do not mean to imply that the
treatmentcannotremaininplaceaftertheobservationwindowendsatT.Infact,weplacenoupper
boundonvaluesfork.If(t∗+k)>T,thennoneofthetimeperiodsoftype3areobserved.

30Insomeapplications,thetreatmentisstipulatedtooccurbetweenobservationintervals.Inthese
cases,timeperiodsoftype2areassumedtobeunobserved.Typically,inthiscase Dt isassumedto
be equal to 1 forat least the firsttimeperiodof type 3inorder to indicate that the treatment was
initiatedintheunobservedtimeperiodsoftype2.Othersstudiesimplythatt∗+k=T,suchthatthe
treatmentispresentthroughthefullposttreatmentobservationwindow.Inthesecases,timeperiods
oftype3areunobserved.

31For a comprehensive consideration of the post-1973 “baby bust” in Japan, see Retherford and
Ogawa(2006).

One could ask many causal questions about the trend in Japan’s birth rate in
Figure 2.1, but the natural first question is, What caused the dramatic decline in the
birth rate in 1966? The demographic consensus is the following. Every 60 years, two
cycles within the Asian zodiac calendar – one over twelve animals and one over five
elements – generate a year of the “fire horse.” A folk belief exists that families who
give birth to babies designated as fire horses will suffer untold miseries, particularly
soifthe babyis a girl.Enoughcouples supposedlyheld this belief inthe yearsaround
1966 that they adjusted their fertility behavior accordingly (see Hodge and Ogawa
1991).

In their discussion of causal analysis in demography, N´ı Bhrolch´ain and Dyson
(2007:8) consider this example and write that “demographers naturally interpret this
event in a causal way, without worrying about the formalities of causal inference.”
Although we agree that the assertion of a fire-horse causal effect on Japanese birth
rates in 1966 does not require a formal treatment to convince most demographers,
we will nonetheless use this example to demonstrate an over-time analysis of a causal
effect for a single unit of analysis.

The first issue to consider is measurement of the outcome. The outcome for
Figure 2.1 is known as the crude birth rate, which is the number of live births per
1,000 persons alive in the same year. A more refined outcome could be constructed,
26.0
25.3
24.0
23.4
)snosrep 22.0
21.5
000,1 20.0 19.4
20.0
rep( 19.4 18.6 19.2 19.319.4
etar 18.0 18.4 18.6 18.518.8 18.6
18.0 17.7
htriB 17.2 17.5 17.2 16.917.017.3 17.1
16.0
16.3
15.5
14.9
14.0
14.2
13.7 13.6
12.0
1951 1956 1961 1966 1971 1976
Year
Figure2.1 Crude birth rates in Japan, 1951–1980.

Source: Table 2-24, Live Births by Sex and Sex Ratio of Live Births, Bureau of Statistics of
Japan.Accessedathttp://www.stat.go.jp/data/chouki/zuhyou/02-24.xls onMarch11,2013.

standardizing for cohort sizes of women of childbearing age. An analogous drop in
standardized birth rates would still be present for 1966.32
What are the causal states that generate the seemingly obvious causal effect? At
the individual level,the causalstates couldbe quite specific (“believing that having a
fire-horse baby is less desirable than having a baby in another year”) or considerably
more broad (“believing in the relevance of zodiac calendars”). For our purposes here,
the particular individual-level causal states do not matter because the causal states
are at the national levelfor this analysis.The states are “fire-horse year in the zodiac
calendar” and “not,” and they are aligned, not with observed treatment and control
groups,butwiththeobservedyears,D 1966=1versusDt(cid:4)=1966=0.Intheyear1966,the
treatment generates two corresponding potential outcome variables, Y1 and Y0 ,
1966 1966
which define the effect of interest for the birth rate in Japan in 1966:
δ =y1 −y0 .

1966 1966 1966
We can estimate this effect as
δˆ =y −yˆ0
1966 1966 1966
=13.7−yˆ0 .

1966
The estimate δˆ is the observed birth rate in 1966, 13.7, minus an estimate of the
1966
counterfactual birth rate, yˆ0 , that would have been observed if 1966 had not been
1966
the year of the fire horse.

What is a reasonable estimated value for the true counterfactual outcome, y0 ?
1966
How about 18.6,which is the birth rate for 1965?N´ı Bhrolch´ainand Dyson (2007:30)
reasonthat“somebirthsthatmighthavetakenplacein1966weretransferred–either
infact,orviatheyearofoccurrencereportedbytheparentsatthetimeofregistration
– to the adjacent years.” Such a possibility is evident in 1965, where the birth rate
appears elevated in comparison to prior years. In fact, the birth rate appears to be
slightlyhigherin1964aswell,relativetotheprevailingtrendintheearly1960s.What
about the value for 1967, 19.4? Again, the birth rate appears to be higher here too,
and possibly again in 1968. Following N´ı Bhrolcha´in and Dyson’s reasoning (and also
Hodge and Ogawa 1991), these higher rates in 1964, 1965, 1967, and 1968 could be
presentbecause parents wereespecially eagerto have childrenbefore or after the year
of the fire horse and adjusted their behavior accordingly. Given the uncertainties of
conception, at least some of these parents started their avoidance early or failed to
conceive a child until after the year of the fire horse.

Inourexperiencediscussingthisexamplewithotherresearchers,mostwillsettleon
theaverageofthe twovaluesfor1963and1969,(17.3+18.5)/2=17.9,asareasonable
estimate of the counterfactualvalue,y0 . The resultof sucha choiceis anestimated
1966
causal effect,
δˆ =13.7−17.9=−4.2,
1966
32At least some of the overall downward trend would disappear because the trend in Figure 2.1
is produced inpart by the aging of the population (which itself is a function of the return to peace
following World War II and continuing declines in mortality). Hodge and Ogawa (1991) document
thesetrendsandconsideralternativeadjustments forotherdemographictrajectories.

that implies a decline in the crude birth rate of 31 percent. At the individual level,
and ignoring rates of twins and so on, this estimate suggests that nearly 1 out of 3
mothers who would have given birth in 1966 did not do so because 1966 was the year
of the fire horse. Notice also that, in selecting the average of the birth rates in 1963
and 1969 as the most reasonable estimate of the counterfactual value, one is thereby
assuming positive fire-horse-year effects in 1964, 1965, 1967, and 1968, which were
non–fire-horse years. As a result, in order to estimate the overall effect of the year
of the fire horse on the population structure of Japan, as determined by the year-by-
year evolution of what is known as the total fertility rate, one would need to model
andthenappropriatelycombinefiveyear-specificeffects,δ throughδ ,basedon
1964 1968
additional corresponding treatment states for the specific years.

Nowconsiderwhathasbeenlearnedandwhathasnot.VisualinspectionofFigure
2.1 is probably convincing on its own that something causal happened in 1966 that
altered birth rates in Japan. However, the specific explanation that is accepted in
demography is based on substantive knowledge of Asian zodiac calendars, as well as
cultural beliefs based upon them that were sufficiently widespread in 1966. The over-
time design did not generate this knowledge,even though it providedthe incentive to
uncover it.

Has anything deeper been learned from this effect? Certainly the effect supports
themoregeneralconclusionthatculturalbeliefshavebeenacauseoffertilitydecisions
in Japanin the past. This conclusionmay then further bolster the overallperspective
in empirical demography that fertility decisions across the world are likely shaped by
cultural beliefs and cannot be reduced to a cold rational calculus of the direct costs
and psychic benefits of producing offspring.

With a little extra work, we have been able to generate the reasonable estimate
that the effect in 1966 was a reduction of the birth rate of 31 percent, and we also
took the position that there were very likely positive near-fire-horse-year effects in
the two years on either side of 1966. Notwithstanding these successes, our analysis
yields no information on which types of couples changed their fertility behavior. The
relevance of the zodiac calendar surely varies across couples in nonrandom ways, and
such patterns would be useful to know in order to develop additional perspective on
the broader consequences of the effect. We have also not learned how many women,
or which women, had fewer children or instead simply had children who were one or
two yearsyounger or older than they would have been if their children had been born
in 1966.

We will return to this type of example in Chapter 11, where we will consider the
deeper modeling issues that accompany the estimation of these types of effects. Often
referredtoasinterruptedtimeseries(ITS)designs,thereareformaltimeseriesanalysis
procedures for generating best estimates of counterfactual values, and these may be
easier to defend than our ad hoc choice of 17.9 as the most reasonable estimate of
the crucial counterfactual value that determines the size of the casual effect. As we
will discuss in detail in Chapter 11, the main weakness of these designs is their rarity.

In the observational social sciences, few examples are as clear-cut as the year of the
firehorse.Morecommonly,the causalshocksto outcomesunfolding overtime areless
dramatic, and, as a result, they are more difficult to separate from underlying trends.

Notice also that we have chosen in this section an aggregateunit – a country – as
our example of the analysis of a causal effect for a “single unit.” In part, this decision
reflectsourpositiononwhatcanbelearnedbystudyingindividualsinisolation.Surely
there are genuine individual-level causal effects, some of which can be discerned from
examiningthelivesofparticularindividualsovertime.Thechallengeiswhatingeneral
can be learned from documenting such apparent effects, and whether analyses can be
strengthenedbyconsideringindividualsingroups,especiallyinrepresentativesamples.

This is the focus ofour nextsection,wherewe introducethe potentialoutcomemodel
for many units over time.

2.8.2 Many Units Over Time
Suppose now that we have a collection of individuals observed at multiple points in
time.Generallyreferredtoaspaneldataorlongitudinaldata,outcomesandcausesnow
vary over both individuals and time. Consider two examples. First, researchers who
study the charter school effect often have access to samples of students observed over
multiplegradesinbothcharterschoolsandregularpublic schools.Second,researchers
who study the effects of father absence that results from divorce typically have access
to data from random samples of families. These data often include measures of child
development outcomes before and after the divorce that triggers father absence.

Wewillnowextendthe potentialoutcomeframeworktoconsidertheestimationof
causaleffects withsuchover-timedataonsamplesofindividuals.Inearliersections of
this chapter, we dropped subscripting on i for brevity when discussing causal effects.

For this section, in which we must deal now with some quantities that vary only
over individuals, others that vary only over time, and others that vary over both, we
subscriptwithiforindividualsandwithtfortime.Foratwo-statecause,thepotential
outcome variablesare Y i1 t, Y i0 t, and the observedvariablesare Dit and Yit.33 As in the
last section, we will allow the observation window to run from t=1 to T. Unlike the
last section, we will not utilize notation for a focal time interval, t∗, in which the
treatment is introduced. Here, we want to preserve the possibility that the treatment
is introduced at different times for different individuals.

We will also now distinguish between two different treatment indicator variables.

Ditisatime-varyingvariablethatindicateswhetherindividualireceivesthetreatment
in time period t. In contrast, D∗ is a time-constant variable that indicates whether
i
individual i ever receives the treatment at any point in time during the observation
window of the study (i.e., in any time period from t=1 to T). Dit is best thought
of as a treatment exposure indicator, and D∗ is best thought of as a treatment group
i
indicator.

The setup for the potential outcome model with panel data follows directly from
thesedefinitions.Formembersofthecontrolgroup,Yit=Y i0 foralltimeperiodst.For
t
members of the treatment group, Yit=Y i0 before treatment exposure, and Yit=Y i1
t t
33Insomecases,thesubscriptingisredundant.Forexample,inSections2.4and2.7,werepresented
the causal effect as δ, recognizing that this effect can vary over individuals. In this section, we will
represent the individual-level causal effect always as δ i, so that it is clear that in this form we are
assumingthatitdoesnotvarywithtime.Foratime-varyingcausaleffect,wewouldinsteadneedto
subscriptitasδ it.

after treatment exposure begins. Altogether, Yit is defined with reference to Dit, such
that
Yit=DitY i1 t+(1−Dit)Y i0 t, (2.18)
where Dit remains equal to 0 over time for all members of the control group(D i∗=0)
but varies between 0 and 1 for all members of the treatment group (D∗=1).

i
Consideraconcreteapplicationofthisnotationusingboththetreatmentexposure
indicator and the treatment group indicator. If no one is exposed to the treatment in
time period t=1 or t=2, then Di1=0, Di2=0, Yi1=Y i0 1, and Yi2=Y i0 for those in
2
the control group (D∗=0) and for those in the treatment group (D∗=1). But, if the
i i
treatment is then introduced to all members of the treatment group in time period
t=3, then the values of Dit and Yit diverge across the treatment and control groups
in time period 3. Now, for those in the control group (D i∗=0), Di3=0 and Yi3=Y i0 3.

But, for those in the treatment group (D i∗=1), Di3=1 and Yi3=Y i1 3.

ThedistinctionbetweenDit andD i∗ revealsthepotentialvalueofpaneldata.Fora
cross-sectionalstudy inwhichall observationoccursinasingle time period,Dit=D i∗.

However, a panel dataset over multiple time periods allows a researcher to consider
how treatment exposure (Dit) can be separated from treatment group membership
(D∗) and then exploitthis difference to estimate the causaleffect. Considertwo types
i
of analysis.

First, when individuals receive the treatment at different times or do not receive
the treatment at all, it is possible to observe how Y0 changes over time for some
it
individualsafter othershavereceivedthe treatment.Asa result,itmay be possibleto
makereasonablepredictionsabouthowY0wouldhaveevolvedovertimeforindividuals
it
in the treatment group during the posttreatment time period. If predictions of these
counterfactual trajectories are reasonable, inferences about the causal effect of the
treatment,δit,intimeperiodt,canbemadebycomparisonoftheobservedYit intime
period t for those who are treated (D∗=1) with predictions of their corresponding
i
counterfactualvalues ofY0 in time periodt. The crux ofthe matter,ofcourse,is how
it
to use observed values of Yit=Y i0 in time period t among those in the control group
t
(D∗=0)to makereasonablepredictionsabout posttreatmentcounterfactualvalues of
i
Y0 for those in the treatment group (D∗=1).

it i
Second, in situations where it is reasonable to assume that E[Y0] is evolving in
it
parallelfashionacrossthetreatmentandcontrolgroupsandthattreatmentassignment
is unrelated to the values of the outcome prior to the treatment, it is possible to
estimate the ATT by offering a model that (1) calculates the averagedifference in the
outcome in the treatment group between the pretreatment and posttreatment time
periods and (2) subtracts from this difference the average difference in the outcome
for the control group between the same two time periods.34 In this case, the most
important issue to consider is whether it is reasonable to assume parallel trajectories
and that treatment assignment is unrelated to pretreatment values of the outcome.

The latter assumption would be unreasonable if individuals with comparatively low
or comparatively high values of the pretreatment outcome, net of other determinants
34Moreover, if it is reasonable to assume that self-selection on the causal effect is absent, then
the ATT is equal to the ATE and ATC. A consistent and unbiased estimate of the ATT from a
difference-basedestimatoristhenalsoconsistentandunbiasedforboththeATEandATC.

of the outcome, select into the treatment, either under the assumption that they are
especially suited to the treatment because of their recent strong performance or that
they areespeciallyinneedofthe treatmentbecauseoftheirrecentweakperformance.

We will discuss a variety ofpaneldata estimation strategiesinChapter 11, but we
wanttoforeshadowtwobasicconclusionsheretotempertheoptimismthatmanymay
feelafterconsideringourpriortwoparagraphs.First,paneldataestimatorsbasedonly
onposttreatmentobservationsdonotusuallyimproveonthecross-sectionalestimators
we will present in this book. In our experience, analysts are often too sanguine about
the clarifying power of observing the evolution of outcome variables for those who
arealwaysobservedunder exposureto the treatmentofinterest(e.g., students always
enrolled in Catholic high schools relative to students always enrolled in public high
schools,withnodataoneithergroupavailablepriortohighschool).Second,oneneeds
data from multiple pretreatment time periods and/or very well-developed theory to
justify required assumptions before the gains to panel data are clear, especially given
the other ancillary patterns, such as panel attrition, that must also often be modeled.

## 2.9 The Potential Outcome Model for Many-Valued Treatments

So far in this chapter, we have focused our presentation of the potential outcome

model on binary causal variables, conceptualized as dichotomous variables that indi-
cate whether individuals are observed in treatment and control states. As we show
in this section, the counterfactual framework can be used to analyze causal variables
with more than two categories.

Consider the more general setup, in which we replace the two-valued causal expo-
sure variable, D, and the two potential outcomes Y1 and Y0 with
1. a set of J treatment states,
2. a corresponding set of J causal exposure dummy variables, {Dj}J , and
j=1
3. a corresponding set of J potential outcome random variables, {YDj}J .

j=1
Each individual receives only one treatment, which we denote Dj(cid:2). Accordingly, the
Dj(cid:2)
observed outcome variable for individual i, yi, is then equal to y . For the other
i
J−1 treatments, the potential outcomes of individual i exist in theory as J−1 other
potential outcomes yDj for j(cid:6)=j(cid:2), but they are counterfactual.

i
Consider the fundamental problemof causalinference for many-valuedtreatments
presented in Table 2.4 (which is simply an expansion of Table 2.1 to many-valued
treatments). Groups exposed to alternative treatments are represented by rows with,
for example, those who take treatmentD2 in the secondrow.For a binary treatment,
we showed earlier that the observed variable Y contains exactly half of the informa-
tion contained in the underlying potential outcome random variables. In general,
for a treatment with J values, Table 2.4 shows that the observed outcome variable
Y contains only 1/J of the total amount of information contained in the underlying
Table 2.4 The Fundamental Problem of Causal Inference for
Many-Valued Treatments
Group YD1 YD2 ··· YDJ
Takes D1 Observableas Y Counterfactual ··· Counterfactual
Takes D2 Counterfactual Observableas Y ··· Counterfactual
. . . . . . . . . . . . . . .

Takes DJ Counterfactual Counterfactual ··· Observableas Y
potentialoutcome randomvariables.Thus,the proportionofunknownandinherently
unobservable information increases as the number of treatment values, J, increases.

Foranexperimentalist,thisdeclineintherelativeamountofinformationinY isrel-
atively unproblematic. Consider anexample in which a researcherwishes to know the
relative effectiveness of three pain relievers for curing headaches. The four treatments
are “Take nothing,” “Take aspirin,” “Take ibuprofen,” and “Take acetaminophen.”
Suppose that the researcherrules out an observationalstudy, in part because individ-
ualshaveconstrainedchoices(i.e.,pregnantwomenmaytakeacetaminophenbutmay
not take ibuprofen; many individuals take a daily aspirin for general health reasons).

Instead, she gains access to a large pool of subjects not currently taking any medi-
cation and not prevented from taking any of the three medicines.35 She divides the
poolrandomlyintofourgroups,andthedrugtrialisrun.Assumingallindividualsfol-
low the experimental protocol, at the end of the data-collection period the researcher
calculates the mean length and severity of headaches for each of the four groups.

Even though three quarters of the cells in a 4× 4 observability table analogous
to Table 2.4 are counterfactual, she can easily estimate the relative effectiveness
of each of the drugs in comparison with each other and in comparison with the
take-nothing control group. Subject to random error, contrasts such as EN[yi|Take
aspirin]−EN[yi|Take ibuprofen] reveal all of the average treatment effects of inter-
est. The experimental design allows her to ignore the counterfactual cells in the
observability table by assumption. In other words, she can assume that the aver-
age counterfactual value of YAspirin for those who took nothing, took ibuprofen, and
took acetaminophen (i.e., E[YAspirin|Take nothing], E[YAspirin|Take ibuprofen], and
E[YAspirin|Takeacetaminophen])canallbeassumedtobeequaltotheaverageobserv-
able value of Y for those who take the treatment aspirin, E[Y|Take aspirin]. She can
thereforecomparesampleanalogsoftheexpectationsinthecellsofthediagonalofthe
observability table, and she does not have to build contrasts within its rows. Accord-
ingly, for this type ofexample, comparingthe effects ofmultiple treatments with each
otherisnomorecomplicatedthanthebivariatecase,exceptinsofarasonenonetheless
has more treatments to assign and resulting causal effect estimates to calculate.

35Notethat,inselectingthisgroup,shehasadoptedadefinitionofthepopulationofinterestthat
does not include those who (1) take one of these pain relievers regularlyfor another reason and (2)
do not have a reason to refuse to take one of the pain relievers. We will discuss the importance of
consideringsuchgroupsof“alwaystakers”and“nevertakers”whenwepresentinstrumentalvariable
estimatorsinChapter9.

Table 2.5 The Observability Table for Estimating How Education Increases Earnings
Education YHS YAA YBA YMA
Obtains HS Observableas Y Counterfactual Counterfactual Counterfactual
Obtains AA Counterfactual Observable as Y Counterfactual Counterfactual
Obtains BA Counterfactual Counterfactual Observableas Y Counterfactual
Obtains MA Counterfactual Counterfactual Counterfactual Observableas Y
Nowconsideravariantontheeducation-earningsexample.Supposethataresearcher
hopes to estimate the causal effect of different educational degrees on labor market
earnings, and further that only four degrees are under consideration: a high school
diploma (HS), an associate’s degree (AA), a bachelor’s degree (BA), and a master’s
degree (MA). For this problem, we therefore have four dummy treatment variables
corresponding to each of the treatment states: HS, AA, BA, and MA. Table 2.5 has
the samestructure as Table 2.4. Unlike the pain relieverexample, randomassignment
to the four treatments is impossible. Consider the most important causal effect of
interest for policy purposes, E[YBA−YHS], which is the average effect of obtaining a
bachelor’s degree instead of a high school diploma.

Suppose that an analyst has survey data on a set of middle-aged individuals for
whomearningsatthemostrecentjobandhighesteducationaldegreearerecorded.To
estimate this effect without asserting any further assumptions, the researcher would
need to be able to consistently estimate population-level analogs to the expectations
of allof the cells ofTable 2.5 in columns 1 and3, including six counterfactualcells off
of the diagonal of the table. The goal would be to formulate consistent estimates of
E[YBA−YHS] for all four groupsof differentially educatedadults. To obtaina consis-
tent estimate of E[YBA−YHS], the researcher would need to be able to consistently
estimate E[YBA−YHS|HS=1], E[YBA−YHS|AA=1], E[YBA−YHS|BA=1], and
E[YBA−YHS|MA=1], after which these estimates would be averagedacrossthe dis-
tributionofeducationalattainment.Noticethatthisrequirestheconsistentestimation
ofsomedoublycounterfactualcontrasts,suchastheeffectonearningsofshiftingfrom
ahighschooldiplomatoabachelor’sdegreeforthosewhoareobservedwithamaster’s
degree.The researchermightboldly assertthatthe wagesofall highschoolgraduates
are,onaverage,equalto whatallindividuals wouldobtainin the labor marketifthey
instead had high school diplomas. But this is very likely to be a mistaken assumption
if it is the case that those who carryon to higher levels of education would have been
judgedmoreproductiveworkersbyemployerseveniftheyhadnotattainedmorethan
high school diplomas.

As this example shows, a many-valued treatment creates substantial additional
burden on an analyst when randomization is infeasible. For any two-treatment com-
parison, one must find some way to estimate a corresponding 2(J−1) counterfactual
conditionalexpectations,becausetreatmentcontrastsexistforindividualsinthepopu-
lationwhoseobservedtreatmentsplacethemfarfromthediagonaloftheobservability
table.

If estimating all of these counterfactual average outcomes is impossible, analysis
can still proceed in a more limited fashion. One might simply define the parameter of
interestverynarrowly,suchasthe averagecausaleffect ofa bachelor’sdegreeonly for
those who typically attain high school diplomas: E[YBA−YHS|HS=1]. In this case,
thecausaleffectofattainingabachelor’sdegreeforthosewhotypicallyattaindegrees
other than a high school diploma are of no interest for the analyst.

Alternatively, there may be reasonable assumptions that one can invoke to sim-
plify the complications of estimating all possible counterfactualexpectations. For this
example, many theories of the relationship between education and earnings suggest
that, for each individual i, yHS≤yAA≤yBA≤yMA. In other words, earnings never
i i i i
decrease as one obtains a higher educational degree. Asserting this assumption (i.e.,
taking a theoretical position that implies it) may allowone to ignore some cells of the
observabilitytablethatarefarthestfromthedirectcomparisononehopestoestimate.

We will discuss these sorts of assumptions in Chapter 12.

Aside from the expansion of the number of causal states, potential outcomes, and
treatmenteffects, all other features of the potential outcome model remainessentially
the same. SUTVA is typically still maintained, and, if it is unreasonable, then more
general methods must again be used to model treatment effects that may vary with
patterns of treatment assignment. Modeling treatment selection remains the same,
eventhough the added complexity of havingto model movementinto andout of mul-
tiple potential treatment states can be taxing. And the same sources of inconsistency
and bias in standard estimators must be considered, only here again the complexity
can be considerable when there are multiple states beneath each contrast of interest.

To avoidall of this complexity, one temptation is to assume that treatment effects
are linear additive in an ordered set of treatment states. For the effect of education
onearnings,a researchermight insteadchooseto move forwardunder the assumption
that the effect of education on earnings is linear additive in the years of education
attained. For this example, the empirical literature has demonstrated that this is a
particularly poor idea. For the years in which educational degrees are typically con-
ferred, individuals appear to receive an extra boost in earnings. When discussing the
estimation of treatment effects using linear regression for many-valued treatments in
Section 6.6.1, we will consider a piece by Angrist and Krueger(1999)that shows very
clearly how far off the mark these methods can be when motivated by unreasonable
linearity and additivity assumptions.

## 2.10 Conclusions

In this chapter, we have introduced the main components of the potential outcome

model,whichisafoundationalpieceofthecounterfactualmodelofcausalityforobser-
vationalresearch.Wedefinedindividual-levelcausaleffectsasthewhat-ifdifferencesin
potential outcomes that would result from being exposed to alternative causal states.

We then presented the assumption of causal effect stability – the stable unit treat-
ment value assumption – that is frequently relied on when estimating effects defined
by potential outcomes. We defined averagecausal effects at the population level, con-
sidered how ineffective the simple mean-difference estimator is for estimating average
causaleffects with observationaldata, and concluded with extensions of the potential
outcomemodelforeffectsobservedovertimeandforeffectsdefinedacrossmanyvalues
of the cause. In the next chapter, we introduce the directed graph approachto causal
analysis,whichwe see as the secondfoundationalpiece ofthe counterfactualmodel of
causality for observationalresearch.

## 2.11 Appendix to Chapter 2: Population and Data Generation Models

Inthecounterfactualtradition,nosingleagreed-onwaytodefinethepopulationexists.


Inarecentpiece,forexample,Rubin(2005:323)introducestheprimaryelementsofthe
potential outcome model without taking any particular position on the nature of the
population, writing that “‘summary’ causal effects can also be defined at the level of
collectionsofunits,suchasthe meanunit-levelcausaleffectforallunits.”As aresult,
avarietyofpossiblepopulation-based(and“collection”-based)definitionsofpotential
outcomes,treatmentassignmentpatterns,andobservedoutcomescanbe used.Inthis
appendix, we explain the choice of population model that we will use throughout the
book (and implicitly, unless otherwise specified).

Becauseweintroducepopulations,samples,andconvergenceclaimsinthischapter,
we have placed this appendix here. Nonetheless, because we have not yet introduced
modelsofcausalexposure,someofthe finepointsinthe followingdiscussionmaywell
appear confusing (notably, how “nature” performs randomized experiments behind
our backs). For readers who wish to have a full understanding of the implicit super-
population model we will adopt, we recommend a quick reading of this appendix now
and then a second more careful reading after completing Chapters 5 through 7.

Our Implicit Superpopulation Model. The most expedient population and
data generation model to adopt is one in which the population is regarded as a real-
izationofaninfinitesuperpopulation.Thissetupisthestandardperspectiveinmathe-
maticalstatistics,inwhichrandomvariablesareassumedtoexistwithfixedmoments
for an uncountable and unspecified universe of events. For example, a coin can be
flipped an infinite number of times, but it is always a Bernoulli distributed random
variableforwhichthe expectationofa faircoinis equalto .5 forbothheads andtails.

For this example, the universe of events is infinite because the coin can be flipped
forever.

Many presentations of the potential outcome framework adopt this basic setup,
followingRubin(1977)andRosenbaumandRubin(1983b,1985a).Forabinarycause,
potentialoutcomesY1 andY0 areimplicitly assumedtohaveexpectationsE[Y1] and
E[Y0] in an infinite superpopulation. Individual realizations of Y1 and Y0 are then
denoted y1 and y0. These realizations are usually regarded as fixed characteristics of
i i
each individual i.

Thisperspectiveistantamounttoassumingapopulationmachinethatspawnsindi-
viduals forever(i.e., the analogto a coin that can be flipped forever).Eachindividual
is born as a set of random draws from the distributions of Y1, Y0, and additional
variables collectively denoted by S. These realized values y1, y0, and s are then given
individual identifiers i, which then become y i1, y i0, and si.

The challenge of causal inference is that nature also performs randomized exper-
iments in the superpopulation. In particular, nature randomizes a causal variable D
within strata defined by the values of S and then sets the value of Y as yi equal to y i1
or y0, depending on the treatment state that is assigned to each individual. If nature
i
assigns an individual to the state D=1, nature then sets yi equal to y i1. If nature
assignsan individual to the state D=0, nature then sets yi equal to y i0. The differen-
tial probability of being assigned to D=1 instead of D=0 may be a function in S,
depending onthe experiment that nature has decided to conduct (see Chapters 4 and
5). Most important, nature then deceives us by throwing away y1 and y0 and giving
i i
us only yi.

In our examples, a researcherwith good fortune obtains data froma randomsam-
{yi,di,si}N
ple of size N from a population, which is in the form of a dataset i=1. The
sample that generates these data is drawn from a finite population that is itself only
onerealizationofatheoreticalsuperpopulation.Basedonthis set-up,the jointproba-
bilitydistributioninthe samplePrN(Y,D,S) mustconvergeinprobabilitytothe true
joint probability distribution in the superpopulation Pr(Y,D,S) as the sample size
approachesinfinity.Themaintaskforanalysisistomodelthe relationshipbetweenD
and S that nature has generated in order use observed data on Y to estimate causal
effects defined by Y1 and Y0. [Many researchers do not have such good fortune and
instead must analyze a dataset with measures of only a subset of the variables in S,
whichwewilltypicallylabelX.Theseresearchershaveaccesstoadataset{yi,di,xi}N
i=1
and model PrN(Y,D,X), which does not converge to Pr(Y,D,S).]
Becauseofitsexpediency,wewillusuallywritewiththissuperpopulationmodelin
thebackground,eventhoughthenotionsofinfinitesuperpopulationsandsequencesof
sample sizes approaching infinity are manifestly unrealistic. We leave the population
and data generation model largely in the background in the main text, so as not to
distract the reader from the central goals of our book.

Alternative Perspectives. There are two main alternative models of the pop-
ulation that we could adopt. The first, which is consistent with the most common
starting point of the survey sampling literature (e.g., Kish 1965), is one in which the
finite population is recognized as such but treated as so large that it is convenient
to regard it as infinite. Here, values of a sample statistic (such as a sample mean)
are said to equal population values in expectation, but now the expectation is taken
over repeated samples from the population (see Thompson 2002 for an up-to-date
accounting of this perspective). Were we to adopt this perspective, rather than our
superpopulationmodel, muchofwhatwe writewouldbe the same.However,this per-
spective tends to restrict attention to large survey populations (such as all members
of a country’s population older than 18) and makes it cumbersome to discuss some
of the estimators we will consider (e.g., in Chapter 5, where we will sometimes define
causal effects only across the common support of some random variables, thereby
necessitating a redefinition of the target population).

The second alternative is almost certainly much less familiar to many empirical
social scientists but is a common approach within the counterfactual causality litera-
ture. It is used often when no clearly defined population exists from which the data
can be said to be a random sample (such as when a collection of data of some form is
availableandananalystwishestoestimatethecausaleffectforthoseappearinginthe
data).Inthissituation,adatasetexistsasacollectionofindividuals,andtheobserved
individuals are assumed to have fixed potential outcomes y1 and y0. The fixed poten-
i i
tial outcomes have average values for those in the study, but these averagevalues are
not typically defined with reference to a population-level expectation. Instead, analy-
sis proceeds by comparison of the average values of yi for those in the treatment and
control groups with all other possible average values that could have emerged under
all possible permutations of treatment assignment. This perspective then leads to a
form of randomization inference, which has connections to exact statistical tests of
null hypotheses most commonly associated with Fisher (1935).As Rosenbaum (2002)
shows,manyofthe resultswepresentinthis book canbe expressedinthis framework
(see also Rubin 1990, 1991). But the combinatoric apparatus required for doing so
canbe cumbersome(andoftenrequiresconstraints,suchashomogeneityoftreatment
effects, that are too restrictive). Nonetheless, because the randomization inference
perspective has some distinct advantages in some situations, we will refer to it at sev-
eral points throughout the book. And we strongly recommend that readers consult
Rosenbaum (2002, 2010) if the data under consideration arise from a sample that
hasnostraightforwardandsystematicconnectiontoawell-definedpopulation.Inthis
case,sampleaveragetreatmenteffectsmaybetheonlywell-definedcausaleffects,and,
if so, then the randomization inference tradition is a clear choice.

# Chapter 3

# Causal Graphs

In his 2009 book titled Causality: Models, Reasoning, and Inference, Judea Pearllays

out a powerful and extensive graphical theory of causality.1 Pearl’s work provides a
language and a framework for thinking about causality that differs from the poten-
tial outcome model presented in Chapter 2. Beyond the alternative terminology and
notation, Pearl (2009, section 7.3) shows that the fundamental concepts underlying
the potential outcome perspective and his causal graph perspective are equivalent,
primarily because they both encode counterfactual causal states to define causality.

Yet, each framework has value in elucidating different features of causal analysis, and
we will explain these differences in this and subsequent chapters, aiming to convince
thereaderthatthesearecomplementaryperspectivesonthesamefundamentalissues.

Eventhoughwehaveshowninthelastchapterthatthepotentialoutcomemodelis
simpleandhasgreatconceptualvalue,Pearlhasshownthatgraphsnonethelessprovide
adirectandpowerfulwayofthinkingaboutfullcausalsystemsandthestrategiesthat
can be used to estimate the effects within them. Some of the advantage of the causal
graph framework is precisely that it permits suppression of what could be a dizzying
amount of notation to reference all patterns of potential outcomes for a system of
causal relationships. In this sense, Pearl’s perspective is a reaffirmation of the utility
ofgraphicalmodelsingeneral,anditsappealtousissimilartotheappealoftraditional
path diagrams in an earlier era of social science research. Indeed, to readers familiar
with path models, the directed graphs that we will present in this chapter will look
familiar.Thereare,however,importantandsubtledifferencesbetweentraditionalpath
diagrams and Pearl’s usage of directed graphs, which we will explain.

1Ourreferencesthroughoutwillbetothe2009secondeditionofPearl’soriginal2000book.Pearl
recognizesthathisinfluentialworkwasdevelopedindialoguewithmanyothers(seePearl2009:104–
5). In focusing heavily on his development of causal graphs in this book, we regrettably do not
give enough credit to the active group of researchers who have participated in developing graphical
representationsofcausality.Werecommendthatinterestedreadersturntothisbroaderliteratureto
learn the interconnections between the many complementary perspectives that exist, starting with
piecessuchasBerzuini,Dawid,andBernardinelli(2012);Dawid(2002);Dechter,Geffner,andHalpern
(2010);Elwert(2013);Glymour,Scheines,andSpirtes(2001);KollerandFriedman(2009);Lauritzen
(1996); and Robins and Richardson (2010). For readers from philosophy who wish to know why we
donotuseneurondiagramsatall,wetakethesamebasicpositionasHitchcock(2007).

77
Forourpurposesinthisbook,Pearl’sworkisimportantforthreedifferentreasons.

First, directed graphs encode causal relationships that are completely nonparametric
and fully interactive, and as a result when considering feasible analysis strategies it is
usuallyunnecessarytospecifythenatureofthefunctionaldependenceofanoutcomeY
onthevariablesthatcauseit.AgraphthatincludesthecausaleffectsX→Y andW→
Y simplyimpliesthatX andW bothcauseY,withoutspecifyingwhethertheireffects
arelinear,quadratic,interactive,oranyotherhighlynonlinearfunctioninthevaluesof
bothX andW.Thisgeneralityallowsforamodelofcausalitywithoutsideassumptions
aboutfunctionalform,suchasassumptionsoflinearadditivity.Second,directedgraphs
show clearly the critical importance of what Pearl labels collider variables, which are
endogenous variables that must be treated with caution in many research scenarios.

Finally, Pearl uses directed graphs to develop transparent and clear justifications for
the three basic methods for estimating causaleffects thatwe will feature inthis book:
conditioning on variables to eliminate noncausal associations by blocking all relevant
back-door paths from the causal variable, conditioning on variables that allow for
estimation by a mechanism, and using an instrumental variable that is an exogenous
shock to the causal variable in order to consistently estimate its effect.

In this chapter, we provide the foundations of the directed graph approach to
causalanalysisanddiscusstherelationshipsbetweendirectedgraphsandthepotential
outcome model. In the course of this presentation, we provide a brief introduction to
conditioning techniques, but we will hold off on the full presentation of conditioning,
as well as Pearl’s back-door criterion for conditioning strategies, until Chapter 4.

## 3.1 Identification

To set the stage for our introduction to directed graph representations of causal rela-

tionships, it is helpful to define the concept of identification. In Chapter2, we defined
causaleffectsascontrastsbetweenwell-definedpotentialoutcomesandthenproceeded
to consider some of the conditions under which consistent and unbiased estimators of
average causal effects are available. A complementary approach, and the one which
motivates the usage of the directed graphs that we will present in this chapter, is to
performanidentification analysis.Here,thechallengestoinferencethatarisefromthe
finitenatureoftheavailablesampleareheldasidewhiletheanalystconsiderswhether
acausaleffectcouldbecomputedifdataonthefullpopulationwereinsteadavailable.

In his 1995 book Identification Problems in the Social Sciences, Manski writes,
itisusefultoseparatetheinferentialproblemintostatisticalandidentifica-
tion components. Studies of identification seek to characterize the conclu-
sions that could be drawn if one could use the sampling process to obtain
an unlimited number of observations. (Manski 1995:4)
He continues,
Empirical research must, of course, contend with statistical issues as well
as with identification problems. Nevertheless, the two types of inferen-
tial difficulties are sufficiently distinct for it to be fruitful to study them
separately.The study of identification logically comes first. Negative iden-
tification findings imply that statistical inference is fruitless: it makes no
sense to try to use a sample of finite size to infer something thatcouldnot
be learned even if a sample of infinite size were available. Positive iden-
tification findings imply that one should go on to study the feasibility of
statistical inference. (Manski 1995:5)
The two most crucial ingredients for an identification analysis are these:
1. The set of assumptions about causal relationships that the analyst is willing to
assertbased on theory and past research,including assumptions about relation-
shipsbetweenvariablesthathavenotbeenobservedbutthatarerelatedtoboth
the cause and the outcome of interest.

2. The pattern of information that one can assume would be contained in the
joint distribution of the variables in the observed dataset if all members of the
population had been included in the sample that generated the dataset.

As we will begin to explain in this chapter, causal graphs can represent these ingre-
dients effectively and efficiently and are therefore valuable tools for conducting iden-
tification analyses.2 We will use the concept of identification frequently in this book,
and we will expand upon this brief introduction as we introduce additional strategies
for analysis.

## 3.2 Basic Elements of Causal Graphs

3.2.1 Nodes, Edges, Paths, and Cycles

The primary goal when drawing a causal system as a directed graph is to represent
explicitly all causes of the outcome of interest, based on past empirical research and
assumptions groundedin theory. As we discussedin Section 1.5, eachnode of a graph
represents a random variable and is labeled by a letter, such as A, B, or C. Nodes
that are represented by a solid circle • are observed random variables, whereas nodes
that are represented by a hollow circle ◦ are unobserved random variables.

Causaleffectsarerepresentedbydirectededges→(i.e.,single-headedarrows),such
that an edge from one node to another signifies that the variable at the origin of the
2Nonetheless, an identification analysis can be conducted, and typically is within the economet-
ric tradition, without utilizing directed graphs. Consider our discussion of the naive estimator in
Chapter2.TheequalitiesacrosstheexpectedvaluesofpotentialoutcomesthatwestatedasAssump-
tions 1 and 2 in Equations (2.15) and (2.16) are identification assumptions. Maintenance of these
particular assumptions would allow an analyst to assert that the naive estimator in Equation (2.9)
is consistent and unbiased for the true average treatment effect in Equation (2.3), as explained by
the decompositions offered there. As such, the average treatment effect is “identified” or is “iden-
tifiable” when these assumptions can be maintained, even though an estimate from a finite sample
may, because of sampling error, depart substantially from the true average treatment effect in the
population. The value of causal graphs, as we will show in this chapter and the next, is that they
allow for an efficient representation of full systems of causal relationships, which can be helpful for
determiningwhetheridentification assumptionsarereasonable.

A
B
C
Figure3.1 A directed graph that includes a cycle.

directed edge causes the variable at the terminus.3 These “directed” edges are what
givegraphscomposedofnodesandsingle-headedarrowsthegenerallabelof“directed
graphs.”
Apath isanysequenceofedgespointinginanydirectionthatconnectsonevariable
to another. A directed path is a path in which all edges point in the same direction.

A variable is a descendant of another variable if it can be reached by a directed path.

All kinship terms are then duly appropriated. Most importantly, for directed paths of
length one, as inA→B, the variableA is the parent while the variable B is the child.

In this book, we will consider only a subset of directed graphs known as directed
acyclic graphs or DAGs. For these graphs,no directed paths emanating from a causal
variable also terminate at the same causal variable. In other words, no variable can
be its own descendant. Figure 3.1 presents a graph that includes a directed path that
forms a cycle, and as a result it is not a DAG (even though it is a directed graph
because it includes only directed edges). Unlike some graphical models from the past,
the prohibition of cycles in DAGs rules out representations of simultaneous causation
andfeedbackloops.4Allofourstatementsaboutgraphsfromthispointonwardassume
that only acyclic graphs are under consideration.

Under some circumstances it is useful to use a curved and dashed bidirected edge
(as in Figures 1.1–1.3) as a shorthand device to indicate that two variables are mutu-
allydependent onone ormoreunobservedcommoncauses.Inthis shorthand,the two
graphspresentedinFigures3.2(a)and(b)areequivalent.Suchshorthandcanbehelp-
ful in suppressinga complex setof backgroundcausalrelationships thatare irrelevant
3InPearl’sframework,eachrandomvariableisassumedtohaveanimplicitprobabilitydistribution
netofthecausaleffectsrepresentedbythedirectededgesthatpointtoit.Thispositionisequivalent
toassumingthatbackgroundcausesofeachvariableexistthatareindependentofthecausesexplicitly
representedinthegraphbydirectededges.WewilldiscussthisassumptioninmoredetailinSection
3.3.2,whereweintroducethestructuralequations thatcorrespondtodirectedgraphs.

4AsshowninWhiteandChalak(2009),abroaderframeworkthataccommodatescyclesispossible
(a position acknowledged by Pearl and colleagues for some time, and which has its origins in the
interest in reconciling recursive and nonrecursive models since the 1960s). However, the additional
detailsofthebroadersetupcanbedaunting,andwerecommendthatinterestedreadersfirstcarefully
consider how much their research questions reallydo requirethe full specification of feedback loops
thatgeneratecycles.Inourexperience,mostsuchpurportedlynecessaryloopsresultfromamisplaced
unwillingnesstoconsidermoretractableempiricalresearchquestionsthatcanbeconfinedtoshorter
spans of analytic time. We do not mean to imply, however, that theory should not attend to such
feedbackloops,onlythatmostempiricalprojectscanbenefit fromrecursionpragmatism.

U
A B A B
(a) (b)
Figure3.2 Two representations of the joint dependence of A and B on unobserved
common causes.

to the empirical analysis at hand. Nonetheless, these bidirected edges should not be
interpreted in any way other than as we have just stated. They are not indicators of
mereassociationsorcorrelationsbetweenthevariablesthattheyconnect,andtheydo
notsignifythateitherofthetwovariableshasadirectcauseontheotherone.Rather,
they represent an unspecified set of unobserved common causes of the two variables
that they connect.

3.2.2 Causal Graphs for Three Variables
Figure 3.3 presents the three basic patterns of causal relationships that would be
observedforanythreevariablesthatareconnectedtoeachotherby onlytwodirected
edges: a chain of mediation, a fork of mutual dependence, and an inverted fork of
mutualcausation.Pearl’sanalysisofthefirsttwotypesofrelationshipisconventional.

For the graph in panel (a), A affects B through A’s causal effect on C and C’s causal
effect on B. This type of a causal chain renders the variables A and B uncondition-
ally associated. For the graph in panel (b), A and B are both caused by C. Here,
A and B are also unconditionally associated, but now it is because they mutually
depend on C.5
For the third graph in panel (c), A and B are again connected by a path through
C.ButnowAandB arebothcausesofC.PearllabelsC acollider variable. Formally,
a variable is a collider along a particular path if it has two arrowspointing directly at
it. Figuratively,the causal effects of A and B “collide” with each other at C. Collider
variablesarecommoninsocialscienceapplications:Anyendogenousvariablethathas
two or more causes is a collider along some path.

A path that is connected by a collider variable does notgenerate anunconditional
association between the variables that cause the collider variable. For the mutual
causationgraphinpanel (c) ofFigure3.3, the path betweenA andB throughC does
not generate an unconditional associationbetween A and B. As a result, if nothing is
knownaboutthe valuethatC takeson,thenknowingthevaluethatAtakesonyields
noinformationaboutthevaluethat B takeson.Pearl’slanguageisquitehelpful here.

5The unconditional associations between A and B for both graphs mean that knowing the value
that A takes ongives one some informationonthe likelyvalue that B takes on. Thisunconditional
associationbetweenAandB,however,iscompletelyindirect,asneitherAnorB hasadirectcausal
effectoneachother.

A C B
(a) Mediation
C
A B
(b) Mutual dependence
A B
C
(c) Mutual causation
Figure 3.3 Basic patterns of causal relationships for three variables.

The pathA→ C ←B does not generateanassociationbetween A andB because the
collider variable C “blocks” the possible causal effects of A and B on each other.

Eventhough collider variables do not generateunconditional associationsbetween
the variables that determine them, we will show in the next chapter that incautious
handling of colliders can create conditional dependence that can sabotage a causal
analysis. The importance of considering collider variables is a key insight of Pearl’s
framework,and it is closely relatedto the familiar concernsof selecting onthe depen-
dent variable and conditioning on an endogenous variable (see Elwert and Winship
2014). Before turning to these issues in detail in Chapter 4, we first need to continue
ourpresentationofthebasicfeaturesofthedirectedgraphapproachtocausalanalysis.

3.2.3 A First Look at Confounding and Conditioning
The most common concern of a researcher seeking to estimate a causal effect with
observational data is that a causal variable D and an outcome variable Y are deter-
mined,inpart,byathirdvariable,C.Thiscommonbutsimplescenarioisrepresented
by the two graphs in Figure 3.4, where for panel (a) the variable C is observed and
for panel (b) it is not.

Forboth graphsin Figure 3.4,the totalassociationbetween D andY is composed
of two pieces: (1) the genuine causal effect of D on Y, representedby D→Y, and (2)
the common dependence of D and Y on C, represented by both C→D and C→Y.

C C
D Y D Y
(a) (b)
Figure3.4 Two graphs in which the causal effect of D on Y is confounded by C.

In such cases, it is often said that the causal effect of D on Y is “confounded” by C
or, even more simply, that C is a “confounder.” Regardless of the label given to C,
the causal effects C→D and C→Y render the total association between D and Y
unequal to the causal effect D→Y.

The frequency of basic confounding has established subgroup analysis as perhaps
the most common modeling strategy to prosecute causal questions in social science
research. Whether referred to as subclassification, stratification, tabular decomposi-
tion, or simply adjustment for a third variable, the data are analyzed after “condi-
tioning”onmembershipingroupsdefinedby valuesofthe confoundervariable.Usage
of the word “conditioning” is a reference to the “ | ” operator, already used exten-
sivelyinChapter2, todefine conditionalexpectations(see,inparticular,Section2.7).

Fromagraphicalperspective,thismodelingstrategyisanalogoustodisconnectingthe
conditioning variable from all other variables that it points to in the original graph,
rewriting the graph without the edges from the conditioning variable for each value
for the conditioning variable, analyzing the data that apply to each of these graphs
separately, and then combining the results across graphs to form an overall estimate.

For Figure 3.4(a), but not for Figure 3.4(b), consistentand unbiased estimators of
the causal effect of D on Y are available (with a large enough dataset generated by a
suitably random sample) because the analyst can condition on the observed variable
C and eliminate the portion of the association between D and Y that is generated
by their common dependence on C. We will explain this claim more formally and
more generally in Chapter 4, where we introduce Pearl’s back-door criterion for the
identification of a causal effect.

Fornow,considertheessentialoperationaldataanalysisroutine.ForFigure3.4(a),
the effectofD onY canbe estimatedbyconditioning onC intwosteps: (1)calculate
the association between D and Y for each subgroup with C equal to c and then
(2) average these c-specific associations over the distribution of the values c that the
variable C takes on in the sample (which we assume is, again, a large random sample
from the population of interest). The resulting weighted average is a consistent and
unbiasedestimatorofthecausaleffectofDonY inPearl’sframework,whichwouldbe
labeledtheaveragetreatmenteffect(ATE)inthepotentialoutcomemodelintroduced
in Chapter 2. For Figure 3.4(b), no such data analysis routine is feasible because the
analyst has no observed variable C with which to begin.

To make this example more concrete, and to begin to build connections to the
examples utilized for Chapter 2, consider the graph in Figure 3.5, where we revisit
C A
E Y
Figure3.5 A causal graph in which the effect of education (E) on earnings (Y) is
confounded by observed variables (C) and by unobserved ability (A).

the research question on ability bias in estimates of the earning returns attributable
to completed years of education. Here, education, E, is a cause of earnings, Y, but
this causal effect is confounded by two sources: (1) observed variables, C, such as
demographic characteristics and family background, and (2) an unobserved variable
forability,A.6 ForFigure3.5,wehavemovedonestepbeyondtheanalysisofthenaive
estimator in Chapter 2 (see Tables 2.3 and 2.5), because now we are considering the
moretypicalscenarioinwhichtheanalystincludesinthedirectedgraphsomeobserved
variablesinC thatpastresearchhasestablishedalmostcertainlyhavecausaleffectson
both yearsof completed educationand subsequent labor marketearnings. The ability
bias literature asserts that, even if we were to condition on a rich parameterizationof
allvaluesofthevariablesinC, westillwouldnotbeabletoeliminatetheconfounding
generated by A.

Notice also that we have not asserted that the education variable, E, in Figure
3.5 is a two-valued cause, as was the case for the discussion of Table 2.3. Unless
specified otherwise, graphs of this type do not place restrictions on the numbers of
values taken on by any of their variables. This particular graph, for example, would
apply to either the two-valued education variable discussed in Section 2.7.3 or the
four-valued education variable introduced in Section 2.9.

## 3.3 Graphs and Structural Equations

Having introduced the basic elements of directed graphs, the next step is to intro-

duce the structural equations that lie beneath them. As noted in the introduction to
thischapter,directedgraphsencodecausalrelationshipsthatarecompletelynonpara-
metric and fully interactive. This generality allows for a model of causality without
assumptions about functional form, which is a major advantage over traditional path
diagrams. An appreciation for this advantage requires first understanding the con-
straints imposed by the parametric assumptions that were common in the equations
associated with these path diagrams and why many researchers had good reason to
object to them.

6Inthelaboreconomicsliterature,itwouldgenerallybeassumedthatbothC andAdependona
commonunobservedcauseU thatgeneratesanunconditionalassociationbetweenCandA.Weleave
out this dependence in this diagram for simplicity. Its inclusion would not change the fact that the
effectofD onY isnotidentified.

3.3.1 The Appeal and Critique of Traditional Path Diagrams
To explainboth the appeal andsubsequentcritique of traditionallinear additive path
models, we will use the charter schools example introduced in Section 1.3.2.7 Con-
sider the path diagram presented in Figure 3.6, and suppose that we have data on
all sixth graders in a large metropolitan area. For this path diagram, Y is a stan-
dardized test taken at the end of the sixth grade, and D indicates whether or not
a student attended a charter school for the past year. The variable P represents an
omnibus parentalbackgroundmeasure that captures differences in economic standing
and other basic dimensions of resources that predict both charter school attendance
andschoolperformance. The variable N is neighborhoodof residence, and we assume
that there are meaningful differences in the extent to which neighborhood environ-
ments are conducive to engagement with schooling. Thus, D is the cause of primary
interest,P representsindividualdeterminantsofD thatalsohavedirectcausesonthe
outcome Y, and N is a measure of the social context in which the effect of D on Y
occurs.8
ThepathdiagrampresentedinFigure3.6isassociatedwithtwoimplicitstructural
equations for the two endogenous variables:
D=aD+bPP+eD, (3.1)
Y =aY +bDD+bPP+bNN+eY. (3.2)
These structural equations are linear and additive in the variables P, D, and N, and
each equation has terms, eD and eY, that are represented in the path diagram as all
other determinants of D and Y other than P, D, and N.9 The structure of the path
diagramanditsequationsimplythattheproperempiricalregressionspecificationforY
is the same as Equation (3.2). Under the implicit assumption that eY is uncorrelated
with D, P, and N, the path-model interpretation of least squares estimates of the
coefficients bD, bP, and bN is that they are consistent and unbiased estimates of the
genuine causal effects of P, D, and N on Y.10
How would such a path diagram have been presented and then discussed in a
typicalresearchmethods classinthe 1970s(assumingthatthe charterschoolresearch
questionwasunderdiscussion)?Followinganintroductiontographicalrepresentations
of causal relationships via path diagrams, at least one student would invariably ask
the instructor:
7ThissectiondrawsonmaterialpreviouslypublishedinMorganandWinship(2012).

8Mostpathmodelsassumedtheexistenceofunexplainedcorrelationsbetweenall“predetermined”
or“exogenous”variables,whichareP andN forFigure3.6.Inmanypathdiagrams,curveddouble-
headed arrows wouldbe drawn to represent such correlations. To avoid confusion with our usage of
bidirectededgesthroughoutthisbook,wehavenotaddedsuchadouble-headedarrowtoFigure3.6.

9Thestandardapproachintheearlydaysofpathmodelinginthesocialscienceswouldhavebeen
to assume that e D is uncorrelated with P and that e Y is uncorrelated with P, D, and N. More
complete approaches, asexemplified byDuncan (1975), wouldnot necessarilyhave maintainedsuch
assumptions.

10The estimated effects are presumed to be constant across individuals, as specified in Equation
(3.2).However,mostanalystsregardedtheestimatesassimpleaverageeffectsacrossindividuals.We
will return to this issue in detail when we discuss how regression models do not in general deliver
simple average effect estimates (see Chapter 6) and when we then introduce explicit heterogeneity
intocausalgraphs(seeChapter 8).

e
D
D N
e
Y
P Y
Figure3.6 Atraditionallinearadditivepathdiagramfortheeffectsofparentalback-
ground (P), charter schools (D), and neighborhoods (N) on test scores (Y).

Can the effect of D on Y vary across P? That seems reasonable, since it
wouldseemthattheeffectofacharterschoolwoulddependonfamilyback-
ground.Parentswithcollegedegreesprobablyhelptheir kidsgetmoreout
of school. Actually, now that I think about it, since N captures neighbor-
hood characteristics, don’t we think that there are better schools in some
neighborhoods?Infact,charterschoolsaremorelikelytobeestablishedin
areas with troubled neighborhood-basedschools. And neighborhoods with
weaker schools also tend to have stronger deviant subcultures with gangs
and such. So the effect of charter schooling probably also depends on the
neighborhood in which one lives. How do we represent such variation in
effects in the path model?11
Inresponse,aninstructorwouldtypicallyexplainthatonecanthink ofsucheffects as
supplemental arrowsfromavariableinto the middle ofanotherarrowinthe pathdia-
gram,suchthatthevariableitselfmodifiesthearrowunderdiscussion.Yet,sincethese
sorts of arrows are not formally justified in traditional path diagrams, the instructor
wouldalmostsurelyhavethenrecommendedashifttowardamorecomplexregression
specification, such as
Y =aY +bCC+bPP+bC×P(C×P)+bNN+bC×N(C×N)+eY. (3.3)
Inthiscase,thepathdiagramceasestorepresentanunderlyingsetofstructuralcausal
relationships and is instead best interpreted as only a simplified reflection of a more
specific regressionmodel. After all, the interaction between the effects of D and P on
Y (as well as the interaction between the effects of D and N on Y) can be estimated
withlittletrouble.Oneneedonlycalculateeffectsofinterest,forexample,byplugging
in values for ˆbCC+ˆbPP +ˆbC×P(C×P), after producing standard regression output
fromestimation ofEquation(3.3). The differences then producedcanbe imbued with
causal interpretations based on the same justification as for Equation (3.2), assuming
that no other variables that are common causes of P and Y, D and Y, or N and Y
have been mistakenly omitted from Equation (3.3).

We see two related outcomes of the rise and then demise of traditional linear path
models conceived and estimated in this fashion in the social sciences. First, when it
became clear that there was no agreed upon way to represent within path diagrams
11Werethisexchangeoccurringinthesubstanceoftheday,apathmodelfromthestatusattainment
traditionwouldbethefocusoftheexchange.TheoutcomevariableY wouldbecareersuccess,andD
wouldbeeducation. Allofthesameinteractions notedforthe charter schoolcase wouldthen apply
inthiscase,althoughbasedondifferentnarrativesofcausation.

the interactions that could be specified in regression equations to capture variability
and context, path diagrams came to seem much less useful.12 Researchers interested
in such variability and context may have continued to draw path diagrams on yellow
pads in their offices, but rarely did their drawings turn up in published articles.13
Estimation and reporting became a word and number affair, often with too much
of each.

Second, and far more troubling, many scholars apparently chose to retain a linear
additive orientation, even while no longer using path diagrams. For some, empirical
research could be fruitfully advanced by ignoring the genuine interactive nonlinearity
of the real world, in pursuit of a first-approximation, linear pragmatism. This stance
might have been an acceptable form of pragmatism if the approximation spirit had
carriedovertomodelinterpretation.Toofrequentlyitdidnot,andmanycausalasser-
tions can be found in the literature based on linear additive models that are overly
reductionist.

Overall, the traditional path-modeling literature, and then the more general “age
of regression” that we described in Section 1.2.2, opened up quantitative research to
theclaimsofcriticsthattoomanypractitionershadfallenpreytothebeliefthatlinear
regression modeling reveals strong causal laws in which variability and context play
minor roles. A particularly cogent presentation of this criticism is Abbott’s oft-cited
“Transcending General Linear Reality” (Abbott 1988). Although its straw-man style
is irksome to methodologists who knew of these problems all along, and who urged
better practice, it was a reasonable critique of much practice at the time.14
3.3.2 The Shift to Nonparametric Structural Equations
ForthesamesubstantiveexampledepictedinthepathdiagraminFigure3.6,consider
now its representation by a directed graph in the new causal graph tradition. Two
variants are offered in Figure 3.7. The standard representation that is depicted in
panel (a) is then shown again under “magnification” in panel (b).15 For the latter,
each variable is seen, under close examination, to have its own structural “error” or
“disturbance”term:eP, eD, eN, andeY. Analogousterms are implicitly presentinall
directedgraphs,but they aretypicallysuppressedin their standardrepresentation,as
in panel (a), for visual simplicity.

12Wedonotmeantoimplythat methodologists havenotproposed solutions.Bollen(1995) offers
the elegant proposal of including functions of other variables as separate entities in diagrams and
using sawtooth arrows, (cid:5), in order to represent functional assignment relations. For example, an
interactiveeffectofC andP onY canberepresentedaltogether bythreepathsC→Y,P→Y,and
(C×P)→Y.Theentity(C×P)isnotanewsourceofvariationwithanexogenous component but
rather isadeterministicfunction defined inC andP.This functional dependence issignifiedinthe
diagrambyincludingbothC(cid:5)(C×P)andP(cid:5)(C×P).

13FreeseandKevern(2013:27) labelsuchcausal doodlingas“arrowsalad.”
14For similar critiques in sociology in the same time period, see also Lieberson (1985) and Ragin
(1987). Abbott (2001), Lieberson and Lynn (2002), and Ragin (2008) offer updates on these earlier
critiques.Leamer (1983) isthe analogineconomics, although writteninacompletely differentstyle
andwithalternativesuggested remedies.

15SeePearl(2009:339)forusageoftheword“magnification”torevealthedisturbance/errorterms
thatareimplicitinalldirectedgraphs.

e D e N
D N e D N e
P Y
P Y P Y
(a) Standard representation (b) Under magnification
Figure3.7 Equivalent directed graph representations of the effects of parental back-
ground (P), charter schools (D), and neighborhoods (N) on test scores (Y).

What are these terms, eP, eD, eN, and eY? Pearl(2009:27)states that such terms
“representerrors(or‘disturbances’)duetoomittedfactors”andarealwaysassumedto
beindependentofeachotherandofallothervariablesinthegraph.ForFigure3.7(b),
the terms eP, eD, eN, and eY represent all causes of P, D, N, and Y, respectively,
that can be regarded as “idiosyncratic” causes of each variable. They are assumed to
be independentofeachotherandofP,D,N, andY. Assuch,they canbesuppressed
in the standard representationof a directed graph, as in Figure 3.7(a).16
In general,all directed graphs in the new causal graphtradition must be drawnin
sufficientdetailsothatanysuchdisturbancetermscanbepushedintothebackground.

Pearl cautions,
The disturbance terms represent independent backgroundfactors that the
investigator chooses not to include in the analysis. If any of these fac-
tors is judged to be influencing two or more variables (thus violating the
independence assumption), then that factor must enter the analysis as an
unmeasured (or latent) variable and be represented in the causal graph as
a hollow node. (Pearl 2009:68)
In other words, one must be able to assume that these structural error terms are
mutually independent of each other and of all of the other variables in the graph,
such that no pair is mutually dependent on a common third variable that has been
mistakenly omitted from the graph. If this assumption is dubious, then one must re-
drawthegraphincludinghollownodesforanymistakenlyomittedunobservedcommon
causes. These unobserved variables must then be given directed edges that point to
thevariablesthattheycause.Thenewerrortermsforthere-drawngraphcanthenbe
redefined so that they can be pushed into the background (but still rendered visible
under magnification).

16Thereisconsiderabledebateovertheontologicalstatusoftheseidiosyncraticcauses.Theirexis-
tence implies to some scholars that causality is fundamentally probabilistic. By our reading, Pearl
wouldmaintain,forexample,thatthevariablesembeddedine P aresimplyimplicitstructuralcauses
of P.Under this interpretation, causalitycan stillbeconsidered astructural, deterministicrelation.

Freedman(2010,esp.chapter15)discussessomeofthedrawbacksforstatisticalinferenceofassuming
determinismofthisform.Althoughconvincingtosomedegree,hiscritiquedoesnotaltertheutility
ofthesesortsofcausalgraphsforclarifyingwhencausaleffectsareidentified,whichisPearl’sprimary
contribution.

In fact, for the graphs in Figure 3.7, the existing literature on the charter school
effect suggests that these graphs are incomplete. Most importantly, it is almost cer-
tainly the case that the terms eD and eY in Figure 3.7(b) are mutually dependent on
a common cause that has been mistakenly omitted from the graph, analogous to the
unobserved ability confounder, A, in Figure 3.5. We will therefore extend this graph
in Chapter 8, bringing it more into line with assumptions that analysts have been
willingtomaintaininexistingempiricalresearch.Fornow,weproceedasifthegraphs
in Figure 3.7 represent the true causal model, accepted hypothetically (but counter-
factually!) by a clear consensus of researchers who have studied the charter school
effect.

Mindful ofthis specificdefinitionofthedisturbance/errortermindirectedgraphs,
and supposing for now that the two causal graphs in Figure 3.7 represent a valid
and accepted causal model for the charter school effect, the corresponding structural
equationscannowbeintroduced.Unlikepathdiagramsintraditionalform,wherethe
structuralequationsarelinearandadditiveandcorrespondonlytothetheendogenous
variables in the diagram (e.g., D and Y in Figure 3.6), for the new directed graph
traditionthestructuralequationsarewrittenforallvariablesandinunrestrictedform
(i.e.,possiblynonlinearandinteractive,asexplainedbelow).ThetwographsinFigure
3.7 have the same set of structural equations:
P =fP(eP), (3.4)
D=fD(P,eD), (3.5)
N=fN(eN), (3.6)
Y =fY(P,D,N,eY). (3.7)
Reading from left to right in the graphs and top to bottom in these equations, P is
generated as an unspecified function, fP(.), with eP as its sole argument. The next
three equations then represent analogous unrestricted functions with inputs that rep-
resent all causes of the variables on the left-hand sides of the equations. The last is
the most elaborate, in that Y is a function of the three observed variables P, D, and
N, as well as eY, all of which transmit their effects on Y via the function fY(.).

WhenwesaythatfP(.),fD(.),fN(.),orfY(.)areunrestrictedandhavenoassumed
functional form, we mean that a value is produced for the outcome variable of each
equation for every combination of the values in the corresponding function on the
right-hand sides of these equations. For example, Y takes on a distinct value for each
combination of values, P =p, D=d, and N =n (typically then with the assump-
tion that values of eY are drawn at random from some common distribution that is
presumed to have finite moments; see Freedman 2010, chapter 15 for discussion of
alternative approaches).17
An implication of this flexibility deserves particular emphasis, and preexisting
knowledge of traditional path models and their implicit linear additive structural
17Restrictionsarenottypicallyplacedonhowthedrawnvalueofthedisturbance/errortermisthen
transmitted by f(.) to the outcome. However, because these terms are independent (by definition)
of all other inputs in f(.), their realization in the outcome variable does not typically require any
assumption,atleastwhenidentificationisthefocus.

equations can hinder full recognition of its importance. Consider the nonparamet-
ric structuralequationfor Y in Equation(3.7). All interactions between the effects of
P,D, andN onY areimplicitly permitted bythe lackofrestrictionsplacedonfY(.).

Importantly, this property of the structural equations means that the causal graphs
in Figure 3.7 are consistent with all such interactions because the directed edges only
signifyinclusioninthefunctionssuchasfY(.).Nonewarrows,noranynotationofany
kind, are needed to represent interactions for more specific parameterizations where,
for example, the effect of D on Y varies with the level of P or N.

Asaresult,eventhoughitmayfeelnaturaltowantto“see”aspecificarrowpresent
in the causal graph to represent an interaction effect that corresponds to a cross-
product term in a regression equation, one must learn to suppress such a desire. The
key point, in considering an analysis that utilizes causal graphs, is to drop regression
modelsfromone’smindwhenthinkingaboutidentificationissues.Instead,ifonemust
useadataanalyticmachinetoconceptualizehowtoperformanappropriateempirical
analysis of the puzzle under consideration, one should default to simple conditioning,
as introduced in the last section.

As we will explain in far greater detail in the next part of the book, if the graphs
in Figure 3.7 were the true causal system that generates the effects of charter schools
on test scores, the effect of D on Y would be confounded by the observed parental
background variables in P. In addition, the effect of D on Y may vary across the
contexts defined by neighborhoods. With a dataset of sufficient size, the analyst can
estimatetheeffectofDonY foreverycombinationofthevaluesinP andN,adopting
a conditioning strategy for identification and estimation. These within-P-and-within-
N differences are not confounded and represent average causal effects for students
within strata defined by P and N (again, under the assumption that the directed
graphisacompleterepresentationofthetruecausalsystem).Toobtainaveragecausal
effects for largergroupsof individuals, suchas those living within a particulartype of
neighborhood defined by N, the analyst can combine the strata-specific estimates by
forming a weighted average where the weights are proportional to the sample sizes of
all strata that correspond to the type of neighborhood chosen.

In this way, causal analysis guided by the specification of directed graphs is an
inherently flexible enterprise. Losing sight of the lack of functional form assumed for
causal analysis with unrestricted structural equations may still lead one to fail to
transcend “general linear reality.” If so, the fault lies with the analyst, not the graph
or the possibly highly nonlinear structural equations that it represents.

## 3.4 Causal Graphs and the Potential Outcome Model

Whatarethe connectionsbetweenthe directedgraphapproachto causalanalysisand

the potential outcome model introduced in Chapter 2? In short, they are intimately
related but very distinct frameworks for considering the same issues, each of which
offersuniqueinsightinparticularsituations.We willreturntothis basicpointrepeat-
edly throughout this book. In this section, we begin to explain their complementary
value and then offer a brief examination of the most important formal connection
between the two frameworks: how each encodes (potentially counterfactual) causal
states.

3.4.1 Complementary Value
We already have shown through our presentation in Chapter 2 that the potential
outcome model can be understood and utilized without reference to causal graphs.

Individual-levelpotentialoutcomesallowonetothinkindependentlyabouttheobserved
data as well as what data would have been observed if individuals had experienced
alternative causal states. From these simple pieces, the model allows for transparent
definitions of causal effects and encourages the analyst to consider individual-level
heterogeneity as a first principle.

WealsodemonstratedinChapter2howpotentialoutcomerandomvariablesenable
clear definitions of conditional average causal effects and provide ways to usefully
decomposesourcesofinconsistencyandbiasinestimators–intounaccounted-forbase-
line differences between individuals and the differential responsiveness of individuals
to the cause of interest. Many other advantages of thinking through causal analysis
with potential outcomes will be demonstrated in the remaining chapters of this book.

However,wealsobegantoshowinChapter2thatthetransparencyofthepotential
outcome model begins to cloud overwhen more than two causal states are considered
andwhenimportantassumptions,suchas the stable unittreatmentvalue assumption
(SUTVA) (see Section 2.5), are asserted without considerable reflection. The latter is
a specific instance of the complications of maintaining the full notational framework
of the potential outcome model when many other causal variables of interest begin to
enter the scientific problem.

In this chapter, we have shown that the basic elements of causal graphs do not
includepotentialoutcomerandomvariables,suchY1 andY0.Theremainingchapters
of the book will demonstrate how useful causal graphs can be for empirical research.

As we will begin to show in the next chapter, graphs offer a disciplined framework
for expressing causal assumptions for entire systems of causal relationships. In many
cases, their economy of presentation cannot be matched by potential-outcome-based
presentations of the same material, even though equivalent expressions are available.

Thisadvantageisespeciallyapparentwhentheanalystmustconsiderthemanycausal
pathways that may be present in the real applications of observational research. Yet,
aswewillthenalsodetaillater,thepricepaidforsucheconomyofpresentationisthen
that individuals, and individual-level causal effects, which are so usefully revealed in
thepotentialoutcomemodel,canbecoveredoverbycausalgraphs,eveniftheproblem
is not the causal graphs per se but the shallow interpretations that analysts can too
easily attach to them.

Havingstatedourpositionontheusefulcomplementarityofthesetwoframeworks,
we now lay out the most important point of connection between them. In the next
section, we show how each framework encodes causal states in analogous fashion,
thereby defining causal effects using counterfactuals.

3.4.2 Potential Outcomes and the do(.) Operator
InChapter2,weintroducedpotentialoutcomesafterfirstdiscussingtheneedtoclearly
define the states of the causal variables of primary interest. We then moved directly
to the definition of potential outcomes defined by the instantiation of particular well-
defined causal states, focusing for the most part on the canonical potential outcomes
Y1 and Y0 for a two-valuedcause.Only thereafter did we back out a definition of the
corresponding observed variable Y, and only by way of Equation (2.2), Y =DY1+
(1−D)Y0.

When we then introduced directed graphs in this chapter, we skipped right over
causal states and potential outcomes. We moved straight from the representation of
observed random variables A, B, and C to discussions of causal effects invoking the
same observed variables utilized earlier in Chapter 2, the observed variables D and
Y. Corresponding potential outcomes, Y1 and Y0, were not incorporated into our
presentation.Todemonstratetheconnectionsbetweenpotentialoutcomesanddirected
graphs, we need to introduce how causal states are represented in Pearl’s variant of
causal analysis.

Pearl introduces causal states in a different way, using the semantics of an ideal
experimentalinterventionandwhathelabelsthedo(.)operator.Recallthebasicstruc-
ture of the directed graph in Figure 3.4(a). For this graph, the causal effect of D on
Y is represented by D→Y, and the directed edge indicates that D is an input in
the function, fY(.). The do(.) operator, which we present in this section, is what pro-
vides the bridge to quantities such as the ATE, E[δ]=E[Y1−Y0], defined earlier in
Equation (2.3).

For Figure 3.4(a), consider the case where D takes on two values, 0 and 1. For
Pearl,therearetworegimesbywhichD takesonvaluesof0or1:pre-interventionand
under-intervention. In the pre-intervention regime, the value that D takes on for any
given unit in the population is determined by the structural equation D=fD(C,eD).

In the under-intervention regime, the value that D takes on is set by what Pearl
sometimescallsan“idealexperiment”(e.g.,Pearl2009:358)andatothertimescallsan
“atomicintervention”(e.g.,Pearl2009:70).Notationally,thisinterventionisdo(D=1)
or do(D=0).18
For Pearl, all causal quantities are defined by under-intervention distributions,
not pre-intervention distributions (Pearl 2009, definitions 3.2.1 and 7.1.2-5). For D
and Y in Figure 3.4(a), the two probability distributions that define causal effects are
Pr[Y|do(D=1)]andPr[Y|do(D=0)],notPr[Y|D=1]andPr[Y|D=0].Inparticular,
theaveragecausaleffectisE[Y|do(D=1)]−E[Y|do(D=0)],undertheassumptionthat
18As we will explain in more detail in the appendix to this chapter, Pearl typically also assumes
“modularity,” which is the assumption that an intervention on a variable can be carried out with-
out simultaneously altering anything else about the causal relationships encoded in the graph. The
atomic intervention is assumed not to generate other interventions onother variables or to open up
new causal pathways inconsistent withthe structure ofthe pre-intervention graph. Althoughmodu-
larityistypicallyassumed,compoundinterventionsareeasilyaccommodated.Moredifficult,butnot
impossible, are cases where the assumed intervention generates initially unforeseen counterfactuals.

Inthiscase,thepre-interventioncausalgraphmustberedrawntorepresentallpatternsofunfolding
counterfactuals thatmayfollowfrompriorevents.

the individual-level causal effect is defined by the individual-level difference induced
by the hypothetical intervention, [yi|do(di=1)]−[yi|do(di=0)]).19
Under this setup, observable associational quantities, based on Pr[Y|D], do not
necessarilyequalcausalquantities,basedonPr[Y|do(D)].Mostimportantly,forgraphs
such as Figure 3.4(a), the associational difference E[Y|D=1]−E[Y|D=0] does not
equal the average causal effect defined by the atomic intervention on D, E[Y|do
(D=1)]−E[Y|do(D=0)]. The confounding from C generates additional dependence
between D and Y that enters into the average associational difference, E[Y|
D=1]−E[Y|D=0], but not the average causal difference, E[Y|do(D=1)]−E[Y|do
(D=0)]. The reason that C does not enter the under-intervention difference is that
D is determined by a hypothetical ideal experiment in this regime. In contrast,in the
pre-intervention regime, D is determined by the structural equation D=fD(C,eD)
that has C as one of its inputs.

Consider now the connection with potential outcomes. The do(.) operator is the
exact analog to the superscripts given to potential outcomes in order to designate
the underlying causal states that define them. In particular, Pearl states that the
do(.) operator “is a mathematical device that helps us specify explicitly and formally
what is held constant, and what is free to vary” (Pearl2009:358).The semantics that
accompany the do(.) operator – “ideal experiment” and “atomic intervention” – are
Pearl’schosenwaytoexpresstheideathatallunitsinthepopulationcouldbeassigned
to the causal states in which they are observed (the “factual” ones) or to the causal
states in which they are not observed (the “counterfactual” ones) and that causal
effects are defined by differences attributable to movement between these alternative
states. In this sense, E[Y1]−E[Y0] is equivalent to E[Y|do(D=1)]−E[Y|do(D=0)]
for the graph in Figure 3.4(a), differing only in how the causal states are signified.20
Even though the do(.) operator is a crucial piece of Pearl’s variant of the directed
graph approach to causal analysis, we introduced and discussed causal graphs in this
chapterwithoutanyreferencetoit.Infact,weassertedthatadirectededgesignifiesa
causaleffect,andthatrepresentationssuchasA→B areequivalenttotheassumption
that A is a cause of B. Yet, only here, at the end of this chapter, do we note that it
is the do(.) operatorthat defines the causaleffects that are signified by these directed
edges.

Aslongasonemaintainsthatitisthedo(.)operatorthatdefinescausaleffects,not
associational contrasts such as E[Y|D=1]−E[Y|D=0], the do(.) operator does not
needtoberepresentedinthecausalgraphinanyexplicitway.Theprimarypurposeof
thegraphistoencodethefullsetofcausalrelationshipsthatoneassumescharacterize
a causaleffect ofinterest, so that those causal relationshipscan be consideredin both
the pre-intervention regime and the under-intervention regime. The do(.) operator is
19Othercausalquantities,basedoncomparisonsofPr[Y|do(D=1)]andPr[Y|do(D=0)]couldalso
bedefined,analogoustochoosingsomethingotherthanthesimpledifferencetodefineindividual-level
causal effects in the potential outcome model or selecting something other than the comparison of
populationexpectationsofindividual-levelpotentialoutcomes.Infact,Pearlpreferstoavoidselecting
any particular comparison, emphasizing that all such comparisons are less general than focusing on
thefullunder-interventiondistribution,Pr[Y|do(D)].

20Whenweintroducedourchosennotationforthepotentialoutcomes,wealsonotedthatevenfor
thepotential outcomemodelthereisawidevarietyofnotation adopted tosignifycausalstates (see
footnote7onpage43).

therefore a piece of the underlying structure of the graphical approach, such as the
error terms of nonparametric structural equations, which can be brought into the
foreground when necessary to explain an identification result.21
And, even though we have not done so, the do(.) operator can be represented in
graphical fashion. For each causal graph of the type presented in this chapter, two
types of graphs can be drawn to show the associated under-intervention regime. For
“mutilated” graphs, the directed edges that point to the causal variable of interest
are deleted, leaving a causal variable with no parents because it is set by the atomic
intervention. For “augmented” graphs, the original pre-intervention graph is drawn
with an additional “forcing” variable that represents the atomic intervention.

For readers who wish to have an introduction to these additional types of graphs,
as well as a slightly more formal presentationofthe do(.) operator(and its associated
modularity condition within an overall definition of a Markovian causal graph), the
appendix to this chapter offers an introduction to the primary literature where com-
plete explanations can be found. The appendix also explains why potential outcome
variablesarerarelydepictedindirectedgraphs.Readerswhoareuninterestedinthese
details can skip the appendix and will be able to understand all of the material that
follows.

## 3.5 Conclusions

Inthischapter,wehaveintroducedthedirectedgraphapproachtocausalanalysis.We

first introduced the basic elements of causal graphs and then presented the canonical
causal graph for a confounded causal effect. We explained the nonparametric nature
of these graphs, as represented by the structural equations that assume no functional
form for the effects of causes on outcomes. We concluded by noting the equivalence
between causal effects defined by directed edges in a causal graph and causal effects
definedbypotentialoutcomes,demonstratingthattheequivalenceliesintheircommon
invocation of what-if causal states grounded in counterfactual reasoning.

Along the way, we have noted that one goal of writing down a causal graph is
to represent the set of causal relationships implied by past research and maintained
theories. In all remaining parts of this book, we will enrich our discussion of this first
goal, when, for example, we discuss whether simple graphs – such as Figure 3.7(a)
for the charter school effect – are sufficiently rich to adequately represent the causal
relationships that generate effects in real applications.

Anothergoalofwritingdownacausalgraphistoassessthefeasibilityofalternative
estimationstrategiesinlightofthedatathathavebeenobserved.Followinguponthis
second goal, in the next part of the book we offer a full presentation of the rationale
for conditioning as a causal effect estimation strategy. We then present three related
methods for enacting conditioning estimators – matching, regression, and weighted
regression– in three separate chapters.

21This is similar to the implementation of particular estimation strategies that are motivated by
the potential outcome model. In this case, the researcher analyzes data using observed variables Y
andD.Potentialoutcomes,Y1 andY0,arebroughtout,typicallyatthebeginningofananalysis,to
definethecausal effects ofinterestandtheassumptionsthatwillbemaintainedtoestimatethem.

Insubsequentpartsofthe book,wethen furtherdemonstratehow directedgraphs
canbeusedtorepresentheterogeneityandselectiononunobservedvariablesinorderto
considerhowoneshouldanalyzecausaleffectswhenconditioningonobservedvariables
does not identify the causal effect. We will consider mechanistic and instrumental
variable approaches and conclude with estimators that use both pretreatment and
posttreatment observations on the outcome variable.

## 3.6 Appendix to Chapter 3: Graphs, Interventions, and Potential Outcomes

In this appendix, we first explain the intervention foundation of Pearl’s variant of

causalgraph methodology, and we then explain why potential outcomes are not com-
monly depicted as outcome variables in causal graphs. This appendix is written for
curious readers who wish to have an introduction to formal details before consulting
the primary literature for more complete explanations.

Graphs ThatRepresentAtomicInterventions.AsnotedinSection 3.4.2,the
key linkage between the potential outcome model and the directed graph approachto
causalanalysisisPearl’sconceptofanatomicintervention,asrepresentedbythedo(.)
operator.Althoughthedo(.)operatorisnotvisibleinthestandardrepresentationofa
causal graph, additional related graphs can be offered to demonstrate the connection
more explicitly.

ThegraphinFigure3.8(a)isknownasan“augmented”graphbecauseitisthepre-
intervention causal graph from Figure 3.4(a), augmented with a representationof the
atomic intervention on D.22 The augmentation takes the from of a special “forcing”
variable, FD, which is placed within (cid:6) to denote its special status as an assumed
outside force that can produce a hypothetical atomic intervention. Accordingly, this
forcing variable takes on three values in this case: do(D=0), do(D=1), and idle.

Augmented graphs have accompanying structural equations that represent both
the pre-intervention and the under-intervention regimes for the setting of variables
subject to the atomic intervention (see Pearl 2009, section 3.2.2). For this graph, the
structural equation for Figure 3.4(a), D=fD(C,εD), is replaced with
D=Int[fD(.),C,εD],
where the Int[.] function is defined so that it reduces to 1 if FD=do(D=1), to 0 if
FD=do(D=0), and to fD(C,εD) if FD=idle. In other words, the pre-intervention
structural equation fD(C,εD) that generates D becomes the value of FD when the
forcing variable is idle because the hypothetical atomic intervention has not been
enacted.

Figure 3.8(b) then shows how to think about the graph in Figure 3.8(a) when
FD =do(D =0) and FD =do(D=1). The two graphs in Figure 3.8(b) are known
as the mutilated graphs under an atomic intervention. The mutilation refers to the
removal of all edges pointing to the variable that is intervened upon. In this case, the
22Little would be gained by adding forcing variables for either C or Y, since the former has no
causes other than ε C and the latter causes nothing else specified in the graph. Even so, no formal
rulespreventtheinclusionofbothF C andF Y inafullyaugmented graph.

C
F
D D Y
(a) Augmented casual graph with a “forcing”
variable that represents an intervention
C C
do(D=0) Y do(D=1) Y
(b) “Mutilated” graphs that demonstrate the
do(.) operator for the two values of D
Figure3.8 Twoalternativerepresentationsofassumedinterventionsincausalgraphs
where the effect of D on Y is confounded by C.

observed variable for D, represented in Figure 3.4(a) by •, is replaced by (cid:7)’s in two
separate graphs that correspond to the two values of do(D=0) and do(D=1) that
are determined by the intervention. Because D is no longer determined by C, having
been set by a hypothetical atomic intervention,there is no directed edge fromC to D
in either graph in Figure 3.8(b).

Now, compare the standard representation of the canonical confounding graph in
Figure 3.4(a) with its augmented variant in Figure 3.8(a). The latter shows the inter-
ventionexplicitly,andthe formerleavesit implicit.Dawid(2010:75)claimsthatPearl
onceregardedtheinclusionofforcingvariablesascrucialcomponentsofcausalgraphs.

Dawid argues that “he [Pearl], and most of those following him, have [recently] been
usingonlytheimplicitversion,inwhichtheinterventionvariablesFV arenotexplicitly
included in the diagram,but (to comply with the Pearlianinterpretation)the DAG is
neverthelesstobeinterpretedasiftheywere.”Dawidregardsthesuppressionofinter-
vention variables as a “retrograde move” that entails a “loss of transparency.”23 For
simple graphs,Dawidis surelycorrectthatforcingvariablesdoincreasetransparency.

Formorecomplexdiagrams,forcingvariablescanbeavisualdistraction.Accordingly,
in this book, we will generally follow Pearl and not offer such representations. As we
explain in the next section, however, Pearl builds very precise definitions of causal
graphs, which, when kept in mind while interpreting a causal graph in its standard
representation,leavelittledoubtaboutthecrucialroleofatomicinterventionsandthe
do(.) operator.

23Dawidprefersamoregeneral influencediagramforcausal graphs,restingontopofthedecision
theoreticapproachhehaslongchampioned(seeDawid2002,2012).

Criteria for Causal Graphs. For the canonical confounding graph in Figure
3.4(a), only three observable variables are present: C, D, and Y. No reference to the
do(.) operator that defines causal effects is visible in the graph. Yet, we wrote in this
chapterthatthis directedgraphis alsoa“causalgraph.”Thecarefulreadermayhave
noticed that we have presented other directed graphs in this chapter from which we
have withheld the label “causal graph.” We now explain.

Pearlhas specific requirementsfor whenadirectedgraphcanbe anointedacausal
graph(Pearl2009,definitions1.3.1-3,2.2.2,and7.1.1),basedonwhetherthecandidate
graph and its implied joint probability distribution satisfy “Markovian” conditions
(Pearl2009,theorem1.4.1).Thesecriteriaaredifficulttoconveyindirectformwithout
introducing all aspects of Pearl’s approach. We offer the following simplified criteria
and strongly encourage readers to consult Pearl (2009) for their more complete and
original expression.24 Accordingly, and at the risk of too much oversimplification, a
directed graph can be considered a causal graph by Pearl’s definitions if
1. All variables in the graph,{V},are observed(other than those variables implic-
itly included in the error terms, {eV}, that are only revealed under magnifica-
tion).

2. All variables in the graph, {V}, have errorterms, {eV}, that areindependent of
allvariablesinthegraph,{V},andthataremutuallyindependentofeachother.

3. It is reasonable to assume that each variable in the graph, V, can be subjected
to a hypothetical intervention, do(V =v), that
(a) replaces the pre-intervention probability distribution of V, Pr(V), with a
single intervention value v,
(b) removes the directed edges in the graph that terminate at V, and
(c) changesnothingelseinthegraph(eventhoughthe settingofV tov propa-
gates through the probability distributions of the descendants of V via the
directed paths that remain in the graph).

Criteria 1 and 2 should be clear to those familiar with path models; they are stronger
versions of the standard linear path model identifying assumptions that “all causal
variables are uncorrelated with the error terms of all endogenous variables” and “all
error terms on endogenous variables are uncorrelated with each other.” Criterion 3 is
typically considered to be unique to Pearl’s framework, but Pearl himself makes the
case that versions of criterion 3 were essential to early motivations of path-modeling
techniques and were subsequently forgotten by their inheritors (see Bollen and Pearl
2013).25
24Wewillnot,forexample,discussthebasicrequirementthatthegraph,anditsassociatedstruc-
turalequations,fullydeterminesthejointprobabilitydistributionacrossallvariablesdepictedinthe
graph. Using our simplified notation, this criterion is “All variables in the graph, {V}, have proba-
bilitydistributions,{Pr(V)},thataregeneratedbyassociatedstructuralequations{f V(.)}thatare
functionsonlyin(a)thevariablesthatpointdirectlytotheminthegraph(i.e,their“parents”)and
(b)theirownerrorterms,e V.”
25In the broader literature on causal graphs beyond Pearl’s work, criterion 3 is required only for
the subset of the variables in the graph that are immediately relevant for identification of the focal
causaleffect(seeDawid2002;Glymouretal.2001;RobinsandRichardson2010).

Beforeaddressingcriterion3,weshouldclarifyoneaspectofcriteria1and2.Figure
3.4(a) can be anointed a causal graph because its meets criteria 1 and 2 and because
we have implicitly assumed up until now that criterion 3 is met as well. If criterion 1
is not met, but criteria 2 and 3 are, then the directed graph is “semi-Markovian”and
typically thought of as if it is a causal graph (because what is observable and what is
unobservable is subject to change).

Now consider criterion 3. The lead in – “It is reasonable to assume ...” – is our
own writing, but it is consistent with Pearl’s presentation of the same material. The
key idea is that, by placing such a structure on the graph through a series of finely
articulateddefinitionsthatareadoptedasassumptions,causaleffectscanberigorously
defined. The payoffto adopting such structure is twofold. First, a directed graphthat
is a causal graph does not require that forcing variables be displayed to represent
the atomic interventions that define all of the causal effects in the graph. Second, if a
directedgraphisacausalgraphthatsatisfiescriteria1,2,and3,thentheobserveddata
canbe manipulatedto deliverestimatedcausalcontraststhatareequal to true causal
contrastsdefined by the applicationofthe do(.) operatorseparatelyto allvariablesin
the graph.26 (Weakervariantsofthisimplicationareavailable,andshouldbe obvious.

Evenifthefullcausalgraphdoesnotmeetthesecriteria,itisoftenpossibletoidentify
specific causal effects while other effects in the graph remain unidentified.)
We will demonstrate more fully the second implication in the next chapter, where
we introduce the back-door criterion for sufficient conditioning to identify a causal
effect.27 To get a handle on this implication now, it may be helpful to consider it in
reverse for the simplest estimators we have considered so far in this book. Whenever
conditioning estimators, or simple naive estimators, can be used to recover all causal
contrasts in a graph from observed associational contrasts, the directed graph is a
causal graph. For example, for Figure 3.4(a) a conditioning estimator (described in
brief in Section 3.2.3) can be used to generate a consistent estimate of the average
causal effect of D on Y, defined as E[Y|do(D=1)]−E[Y|do(D=0)].28 This result is
true because the graph in Figure 3.4(a) is a causal graph: All variables are observed;
the error terms that are viewable under magnification are defined to be independent
of all else in the graph; and we have no reason to believe that it is unreasonable to
assumethat criterion3 applies (becausewe havenoreasonto believethat intervening
on D would alter C, etc.).

For anotherexample that alsoservesas a substantive bridge to the finalsection of
this appendix, recall the graph in Figure 3.5 that includes an unobservedconfounder,
26Writteninthisform,thisimplicationholdsonlyforaninfinitesample,soastorendersampling
error unable to destroy the “equal to” within it. The estimates are therefore best interpreted as
consistentestimates ofthetruecausaleffects.

27More generally, Pearl (2009, section 3.4) presents three rules that can be applied to candidate
directed graphs and their associated structural equations to assess whether all effects in the graph
canbeidentified.Hecharacterizes suchassessmentastheapplicationof“docalculus”withthegoal
of reducing do-defined probability distributions to equivalent probability distributions based only
on observable variables (or, more specifically, the joint probability distribution of all variables, as
structuredbythepre-interventionregimeencoded inthegraph).

28In addition, because the effects of C on both D and Y are unconfounded, assuming criterion 2
holds,thenaiveestimator(orvariantsofitifChasmorethantwovalues)canbeusedtoconsistently
estimatethesetwoeffects.

A,fortheeffectofeducation,E,onearnings,Y.Assumingcriteria2and3aremet,this
graphis stillnotfully Markovian,andhence notacausalgraph,becausecriterion1 is
notmet. Accordingly,no conditioning estimatorcan be undertakenwith the observed
datato generatevalues thatwouldcorrespondto E[Y|do(E=e)]for allvaluese ofE.

ConditioningonlyontheobservedconfounderC doesnoteliminatetheconfoundingby
the unobserved variable A. However, for Pearl, this graph would be semi-Markovian
because observation of A would then render it a fully Markovian causal graph, for
which an effective conditioning estimator would then become available. Thus, if we
can assume that criteria 2 and 3 are met, then we can state that Figure 3.5 would be
a causal graph if A were observed.

The Absence of Potential Outcome Variables from Causal Graphs.Imag-
ineagraphthatincludedarrowsbetweenDandY0 andbetweenDandY1,suggesting
purported causal effects such as D→Y0 and D→Y1. Such causal relationships are
inherentlynonsensicalbecauseY1 andY0 aredefinedinrelationtoeachother,asthey
jointlydeterminetheobservedvariableY ininteractionwiththecausalstatesindexed
by D.

Recall the definition offered in Equation (2.2):
Y =DY1+(1−D)Y0. (3.8)
OnetrivialwaytoexplainwhycausaleffectssuchasD→Y1 arenonsensicalistotake
Equation (3.8) and rewrite Y1 in individual realizations as
y1=yi−(1−di)y i0
. (3.9)
i
di
If we think of the supposed causaleffect D→Y1 as being the theoretical difference in
y i1 that would result from the action of switching di from 0 to 1, we can alternatively
substitute 0 and 1 into Equation (3.9) and generate the result that the supposed
causal effect of di on y i1 is the difference between “undefined” and yi. Doing the same
operationfor y i0 delivers a supposedcausaleffect of di ony i0 as the difference between
yi and “undefined.”
In other words, it does not make any sense to seek the causal effect of D on Y1
or of D on Y0, even though we have already offered examples where, empirically and
theoretically,theremaybegoodreasontobelievethatwithinthepopulationofinterest
there may be an association between values of D and Y1 and/or between D and Y0
because of the ways individuals enter into the observed causal states (see Section
2.7).Fromacausalgraphperspective,if such associationsexist,they areproducedby
causalrelationsthatconnectDandY butthatdonottravelthroughD→Y.Theseare
exactly the sorts of relationships that we earlier argued, with reference to Equation
(2.14), generate inconsistency and bias in the the naive estimator. Individuals with
di=1 may have higher values, on average,for y i0 and/or y i1 than those with di=0. If
so, such average differences must arise because D and Y both mutually depend on a
third variable, such as C in Figure 3.4(a).29
29Pearl(2009:342)wouldstatesuchdependenceas“{Y0,Y1}representsthesumtotalofallexoge-
nousvariables,latent aswellasobserved, whichcaninfluenceY throughpathsthat avoidD”(with
notation changes from the original to match our example). The only point which differs from our
Can one represent the same basic insight using causal graphs? Pearl, in his own
writing, has largely chosen not to do so (but see Pearl 2009, section 11.3.2).30 The
broader literature in causal graph methodology shows that it is possible to express
the same ideas using directed graphs, although these are not graphs that are to be
used in the same way as other graphs in this book. (A recent usage similar to ours in
this section can be found in de Luna, Waernbaum, and Richardson (2011). See their
citations to precursors.)
Recall Figure 3.5, which was used to bridge our first presentation of conditioning
in causal graphs with our earlier presentation of the ability bias example used to
introducethepotentialoutcomemodelinChapter2.Inthatgraph,conditioningonC
will not generate a consistent and unbiased estimate of the effect of education, E, on
earnings,Y,becauseofthepresenceoftheunobservedabilityconfounder,A.However,
inChapter2wediscussedsuchconfoundingbyabilityinsteadasinconsistencyandbias
inthenaiveestimator.InSection2.7.3,wedefinedtwotypesofinconsistencyandbias,
aided by the potential outcome definitions. Baseline bias in the naive estimator was
presentwhen E[Y0|D=1](cid:6)=E[Y0|D=0], and treatment effect bias was presentwhen
E[δ|D=1](cid:6)=E[δ|D=0](whichwouldbepresentwheneverE[Y1|D=1](cid:6)=E[Y1|D=0],
assuming no highly unlikely canceling produced by the joint distribution of Y0 and
Y1).

Figure3.9presentspairsofdirectedgraphsthatexpressthe mutualdependence of
potential outcomes and causal variables on exogenous confounders in three different
scenarios.Notice first that none of the graphs in Figure3.9 include either nonsensical
causal effects, such as E→Y0 or E→Y1, or the observedoutcome variable earnings,
Y. Instead, these graphs are drawn solely to represent the mutual dependence of the
potential outcomes for earnings, Y0 and Y1, and the focal causal variable, E, on
observed confounders, C, and the unobserved ability confounder, A.

Recall that for the representation in Figure 3.5, it was not necessary to stipulate
that E took on any particular values because the graph holds under a many-valued
version of E. For simplicity of representation, and to match our earlier discussion in
Section 2.7.3, we will now consider the case where E takes on only two values: 0 for
those who do not obtain a bachelor’s degree and 1 for those who do.

For Figure 3.9(a), confounding by C generates noncausal associations between E
and both Y0 and Y1. Baseline confounding by ability, A, generates a noncausal asso-
ciationbetweenonlyeducationandY0.Thisisthecase,notedearlierinSection2.7.3,
where those who have college degrees would have higher earnings than those without
explanationhereisthatPearlusesthe{.,.}notationtoemphasize,asinignorability,thattheexoge-
nous variables can structure a function defined in Y1 and Y0, such as the difference between these
two.Wemakethesamepointinthegraphsthatfollow.

30Although Pearl has not devoted a great deal of attention to developing graphical models that
includepotentialoutcomes,heandhiscolleagueshavedevotedconsiderableattentiontotherepresen-
tation of counterfactuals in causal graphs. Shpitser and Pearl (2007) develop a powerful framework
for counterfactual graphs, following on Pearl’s earlier work on twinned network graphs; see Pearl
(2000:213–14) and citations therein to earlierwork; Shpitser (2012a, 2012b) offers particularlyclear
expositionsofthesegraphs.Counterfactualgraphsarebeyondthescopeofthisbook,inpartbecause
they requireamorethorough understanding ofPearl’sdocalculus and fullstructural causal models
than we have space to provide and than is necessary to understand the relevance of his framework
formostformsofobservationalresearchinthesocialsciences.

A Y0 Y1
C E C E
(a) Unobserved baseline confounding by A
Y0 A Y1
C E C E
(b) Unobserved effect confounding by A
A Y0 A Y1
C E C E
(c) Unobserved baseline and effect confounding by A
Figure3.9 Alternative graphs for the joint dependence of a two-valued causal vari-
able for education (E) and potential outcomes for earnings (Y0 and Y1) on observed
confounders (C) and on an unobserved confounder for ability (A).

college degrees in the counterfactualstate in which they did not in fact obtain college
degrees(evenafter adjustment for C). Inother words,being “smarter”paysoffin the
labor market, even if one does not carry on to earn a bachelor’s degree.

Incontrast,forFigure 3.9(b), confoundingby ability generatesa noncausalassoci-
ationbetween educationand Y1 but not between education and Y0. This is a formof
treatment effect confounding, wherein those who do not obtain college degrees would
nothaveearningsas highasthose whodo obtaincollegedegreesinthe counterfactual
state in which they did in fact obtain college degrees (again, after adjustments for
C). Here, being smarter helps one get more of an earnings payoff from obtaining a
bachelor’sdegree,eventhough,contraryto Figure3.9(a),being smarterdoesnotlead
to higher earnings in the absence of a college degree.

ForFigure3.9(c),bothtypesofconfoundingbyabilityarepresent,asinthepattern
presentedearlierinSection2.7.3.Inthiscase,however,thereislittleadvantageinusing
the pairedgraphrepresentationinsteadof the single directed graphin Figure 3.5. For
Figures 3.9(a), (b), and (c), the separate graphs for Y0 and Y1 allow for distinct
patterns of confounding, and such clarity may be useful in some situations.

# Part III: Estimating Causal Effects by Conditioning on Observed Variables to Block Back-Door Paths

# Chapter 4

# Models of Causal Exposure and Identification Criteria for Conditioning Estimators

Inthis chapter,wepresentthe basicconditioningstrategyforthe estimationofcausal

effects. We first provide an account of the two basic implementations of conditioning
– balancingthe determinants ofthe cause ofinterestandadjusting for other causesof
the outcome – using the language of “back-door paths.” After explaining the unique
role that collider variables play in systems of causal relationships, we present what
has become known as the back-door criterion for sufficient conditioning to identify a
causal effect. To bring the back-door criterion into alignment with related guidance
based on the potential outcome model, we then present models of causal exposure,
introducingthetreatmentassignmentandtreatmentselectionliteraturefromstatistics
and econometrics. We conclude with a discussion of the identification and estimation
of conditional average causal effects by conditioning.

## 4.1 Conditioning and Directed Graphs

InSection1.5,weintroducedthethreemostcommonapproachesfortheestimationof

causal effects, using language from the directed graph literature: (1) conditioning on
variables that block all back-door paths from the causal variable to the outcome vari-
able, (2) using exogenous variation in an appropriate instrumental variable to isolate
covariation in the causal variable and the outcome variable, and (3) establishing the
exhaustive and isolated mechanism that intercepts the effect of the causal variable on
the outcome variable and then calculating the causal effect as it propagates through
the mechanism. In this chapter, we consider the first of these strategies, which moti-
vates the basic matching, regression, and weighted regression techniques that we will
present in Chapters 5, 6, and 7.

105
C O
D Y
Figure4.1 A graph in which the causal effect of D on Y is confounded by the back-
door path D←C→O→Y.

In Chapter 3, we explained the motivation for and execution of very simple con-
ditioning estimators (see Section 3.2.3). In this chapter, we provide a more complete
explanation of when, why, and how conditioning estimators will succeed in delivering
estimates that can be given causal interpretations. We first reintroduce conditioning
in a way that will reorient our perspective away from the “confounder variable” per-
spective ofChapter3to the more complete“back-doorpath”perspective thatwewill
use in the remainder of this book.

4.1.1 From Confounders to Back-Door Paths
Consider Figure 4.1, which is an elaboration of the canonical confounding graph pre-
sented earlier in Figure 3.4(a). For this figure, the intermediate observed variable, O,
expands the single-edge causal effect C →Y in Figure 3.4(a) to the directed path
C→O→Y in Figure 4.1. We noted in our prior discussion of Figure 3.4(a) that con-
ditioning on C would allow us to generate a consistent and unbiased estimate of the
causal effect of D on Y. This result holds for Figure 4.1 as well. However, for Figure
4.1, one could instead condition on O and achieve the same result. In fact, one could
condition on both C and O as a third alternative.

The key goal of a conditioning strategy is not to adjust for any particular con-
founder but rather to remove the portion of the total association between D and Y
that is noncausal. For Figure 4.1, the strategy to adjust for C is often referred to as
“balancingthe determinants oftreatmentassignment,”andit is the standardmotiva-
tion for matching estimators of causal effects. The alternative strategy to adjust for
O is often referred to as “adjusting for all other causes of the outcome,” and it is the
standard motivation for regressionestimators of causal effects.

Pearlcharacterizesboth strategiesin a novelway,using the languageof back-door
paths. As defined in Section 3.2.1, a path is any sequence of edges pointing in any
direction that connects one variable to another. We now formally define a particular
type of path that we have invoked informally already: A back-door path is a path
between any causally ordered sequence of two variables that begins with a directed
edge that points to the firstvariable.1 For the directed graphin Figure 4.1, two paths
connect D and Y: D←C →O→Y and D→Y. The path D←C →O→Y is a
1“Causallyordered”meansthatthefirstvariablecausesthesecondvariablebyadirectedpathof
some length. For the example discussed in this paragraph, D and Yare causally ordered because D
causesY byD→Y.C andYarealsocausallyorderedbecauseC causesY byC→O→Y.D andO
arenot causallyorderedbecausetheonlytwopathsthatconnectthem(D←C→OandD→Y ←O)
arenotdirectedpaths.Bothofthesepathshaveedgespointingintwodirections.Recallalsothatwe
back-door path because it begins with a directed edge pointing to D. Likewise, the
path D→Y is not a back-door path because it does not begin with a directed edge
pointing to D.2
In Pearl’s language, the observed association between D and Y does not identify
the causal effect of D on Y in Figure 4.1 because the total association between D
and Y is an unknown composite of the true causal effect D→Y and a noncausal
associationbetween D and Y that is generated by the back-door path D←C→O→
Y. Fortunately, conditioning on C, O, or both C and O will block the back-door
path, leaving within-stratum associations between D and Y that can be given causal
interpretations (and can also be suitably averaged to obtain consistent and unbiased
estimates of average causal effects of various types). The remainder of this chapter
explains this result, as well as many others that are more complex.

4.1.2 Conditioning and Collider Variables
As a technique for estimating causal effects, conditioning is a very powerful and very
general strategy. But, it is a much more complicated procedure in general than is
suggested by our discussion of the simple directed graphs in Figures 3.4(a) and 4.1.

Many of the complications arise when collider variables are present, and Pearl has
explained systematically how to resolve these complications.

Recallthatavariableis acollideralongaparticularpathifithastwoedgespoint-
ing directly to it, suchas C in the path A→C←B in Figure 3.3(c). For conditioning
estimators of causal effects, collider variables must be handled with caution. Condi-
tioning on a collider variable that lies along a back-door path does not help to block
the back-door path but instead creates new associations.

Thereasoninghereisnotintuitive,butitcanbeconveyedbyasimpleexamplewith
the mutual causation graph in Figure 3.3(c). Suppose that the population of interest
is a set of applicants to a particular selective college and that C indicates whether
applicants are admitted or rejected (i.e., C=1 for admitted applicants and C=0 for
rejected applicants). Admissions decisions at this hypothetical college are determined
entirely by two characteristics of students that are known to be independent within
the population of applicants: SAT scores and a general rating of motivation based on
an interview. These two factors are represented by A and B in Figure 3.3(c). Even
thoughSATscoresandmotivationareunrelatedamongapplicantsingeneral,theyare
not unrelated when the population is divided into admitted and rejected applicants.

Amongadmittedapplicants,themostmotivatedstudentswillhavelowerthanaverage
SATscores,andtheleastmotivatedstudentswillhavehigherthanaverageSATscores.

Thus, the college’s sorting of applicants generates a pool of admitted students within
which SAT scores and motivation are negatively related.3
stipulatedinChapter3thatwewillonlyconsideracyclicgraphsinthisbook.Withoutcycles,causal
orderiseasilydiscernedbyinspectingthedirectedpaths inthegraph.

2Recall that a directed path is a path in which all edges point in the same direction. Because
all back-door paths have edges pointing in two directions, back-door paths are not directed paths.

However,theycancontaindirectedpaths,suchasthedirectedpathC→O→Y thatisembeddedin
theback-door pathD←C→O→Y.

3Anegativecorrelationwillemergeforrejectedstudents aswellif(1)SATscoresandmotivation
havesimilarlyshapeddistributionsand(2)bothcontributeequallytoadmissionsdecisions.Asthese
noitavitoM
SAT
Applicants to a Hypothetical College
Rejected Admitted
Figure4.2 Simulation of conditional dependence within values of a collider variable.

This example is depicted in Figure 4.2 for 250 simulated applicants to this hypo-
thetical college. For this set of applicants, SAT and motivation have a very small
positive correlation of .035.4 Offers of admission are then determined by the sum of
SAT and motivation and grantedto the top 15 percent of applicants (as shown in the
upper right-handportion of Figure 4.2).5 Among admitted applicants, the correlation
between SAT and motivation is −.641, whereas among rejected applicants the corre-
lation between SAT and motivation is −.232. Thus, within values of the collider (the
admissions decision), SAT and motivation are negatively related.

As Pearl documents comprehensively with a wide range of hypothetical examples,
this is a very general feature of causal relationships and is present in many real-world
applications.ElwertandWinship(2014)presentmanyexamplesfromthesocialscience
literature. In the next section, we show that care must be taken when attempting to
estimateacausaleffectbyconditioningbecauseconditioningonacollidervariablecan
spoil an analysis.

conditionsarealtered,otherpatternscanemergeforrejectedstudents,suchasifadmissionsdecisions
areanonlinearfunctionofSATandmotivation.

4Thevalues forSAT and motivation are250 independent drawsfromstandard normal variables.

ThedrawsresultinanSATvariablewithmeanof.007andastandarddeviationof1.01aswellasa
motivation variable with mean of −.053 and a standard deviation of 1.02. Although the correlation
betweenSATandmotivationisasmallpositivevalueforthissimulation,wecoulddrivethecorrelation
arbitrarilycloseto0byincreasingthenumberofapplicants forthesimulation.

5Admissionisoffered tothe37of250students (14.8percent) whosesum ofSATandmotivation
isgreaterthanorequalto1.5.

## 4.2 The Back-Door Criterion

Withhis languageofback-doorpaths, colliders,anddescendants,Pearlhasdeveloped

what he labels the back-door criterion for determining whether or not conditioning
on a given set of observed variables will identify the causal effect of interest.6 The
overall goal of a conditioning strategy guided by the back-door criterion is to block
all paths that generate noncausal associations between the causal variable and the
outcome variable without inadvertently blocking any of the paths that generate the
causal effect itself. In practice, a conditioning strategy that utilizes the back-door
criterion is implemented in two steps:
Step 1: Write down the back-door paths from the causal variable to the
outcomevariable,determinewhichonesareunblocked,andthensearch
foracandidateconditioningsetofobservedvariablesthatwillblockall
unblocked back-door paths.

Step 2: If a candidate conditioning set is found that blocks all back-door
paths, inspect the patterns of descent in the graph in order to verify
that the variables in the candidate conditioning set do not block or
otherwise adjust away any portion of the causal effect of interest.

This two-step procedure is justified by the following reasoning, which constitutes
Pearl’s back-door criterion:
Back-Door Criterion
If oneormore back-doorpaths connectthe causalvariableto the outcome
variable, the causaleffect is identified by conditioning ona setof variables
Z if
Condition1.Allback-doorpathsbetweenthecausalvariableand
the outcome variable areblockedafter conditioning onZ, which
will always be the case if each back-door path
(a)containsachainofmediationA→C→B,wherethe
middle variable C is in Z, or
(b) contains a fork of mutual dependence A←C→B,
where the middle variable C is in Z, or
(c) contains an inverted fork of mutual causation A→
C←B, where the middle variable C and all of C’s
descendants are not in Z;
6The back-door criterion is meant to be used only when the causal effect of interest is specified
asacomponentofagraphthatisaMarkoviancausalmodel,orwouldbeifallvariablesrepresented
inthe graph were observed; see Pearl’s causal Markovcondition for the existence of a causal model
(Pearl 2009, section 1.4.2, theorem 1.4.1), as well as our discussion in the appendix to Chapter 3.

ThisrequirementcanbeweakenedwhenthegraphisonlyalocallyMarkoviancausalmodel,aslong
astheunderspecifiedcausalrelationsareirrelevanttoanevaluationoftheback-doorcriterionforthe
particular causal effect under consideration. All of the examples we utilize in this book meet these
conditions.

and
Condition 2. No variables in Z are descendants of the causal
variable that lie on (or descend from other variables that lie on)
any of the directed paths that begin at the causal variable and
reach the outcome variable.7
To explainthe back-doorcriterion,wewillfirstconsiderConditions1(a),(b),and(c),
using examples where Condition 2 is met by default because the only descendant of
the causal variable D in the graph is the outcome variable Y (and where we assume
that the analyst does not consider conditioning on Y itself).

Conditions 1(a) and 1(b) of the back-door criterion should be clear as stated.

Return one last time to the simple example in Figure 4.1. Here, there is a single
back-door path, D←C →O→Y, which includes within it both a fork of mutual
dependence (D←C→O) and a chain of mediation (C→O→Y). By the back-door
criterion,conditioning onC blocksthe path D←C→O→Y because C is the middle
variable in a fork of mutual dependence. Likewise, conditioning on O blocks the path
D←C→O→Y becauseO isthe middle variableinachainofmediation.As aresult,
the candidate conditioning set meets Pearl’s back-door criterion if Z is C, O, or both
C and O.

Condition1(c),however,isquitedifferentthanConditions1(a)and1(b)andisnot
intuitive. It states instead that the set of candidate conditioning variables Z cannot
includecollidervariablesthatlieonback-doorpaths.8 Considerthefollowingexample.

Acommonbut poorlyjustifiedpracticeinthe socialsciencesis tosalvagearegression
model from suspected omitted-variable bias by adjusting for an endogenous variable
thatcanberepresentedasaproxyfortheomittedvariablethatisunobserved.Inmany
cases, this strategy will fail because the endogenous variable is usually a collider.

Suppose that an analyst is confronted with a directed graph similar to the one
in Figure 3.4(b), in which the causal effect of D on Y is confounded by an unob-
served variable, such as C. When in this situation, researchers often argue that the
effectsoftheunobservedconfoundercanbedecomposedinprincipleintoalaggedpro-
cess, using a prior variable for the outcome, Yt−1, and two separate unobserved vari-
ables, U and V, as in Figure 4.3. For this graph, there are two back-door paths from
D to Y:
1. D←V →Yt−1→Y and
2. D←V →Yt−1←U→Y.

7Thisrepresentationoftheback-doorcriterionisacombinationofPearl’sdefinitionofd-separation
(Pearl2009:16–17), hisoriginalspecificationoftheback-doorcriterion(Pearl2009:79), andthegen-
eralization of the back-door criterionthat was developed and labeled the “adjustment criterion” by
Shpitser, VanderWeele, and Robins (2010). In an appendix to this chapter, we clarify our specifi-
cation of Condition 2, as incorporated from the adjustment criterion. In brief, for Pearl’s original
back-door criterion, Condition 2 requires more simply (but overly strongly) that no variables in Z
canbedescendants ofthecausalvariable.

8Because the “or” in the Conditions 1(a), (b), and (c) of the back-door criterion is inclusive,
one can condition on colliders and still satisfy the back-door criterion if the back-door paths along
whichthecolliderslieareotherwiseblockedbecauseZsatisfiesCondition1(a)orCondition1(b)with
respecttoanother variableonthesameback-doorpath.

U
Y
t–1
V Y
D
Figure4.3 A causal diagram in which Yt−1 is a collider along a back-door path.

The lagged outcome variable Yt−1 lies on both of these back-door paths, but Yt−1
does not satisfy the back-door criterion. Notice first that Yt−1 blocks the first back-
door path because, for this path, Yt−1 is the middle variable in a chain of mediation,
V →Yt−1→Y. But, for the second path, D←V →Yt−1←U →Y, Yt−1 is a collider
becauseitisthemiddlevariableinaninvertedforkofmutualcausation,V →Yt−1←U.

Accordingly, conditioning on Yt−1 would eliminate part of the back-door association
between D and Y because Yt−1 blocks the first back-door path D←V →Yt−1→Y.

But,atthesametime, conditioningonYt−1 wouldcreateanew back-doorassociation
between D and Y because conditioning on Yt−1 unblocks the second back-door path
D←V →Yt−1←U→Y.

Howcanconditioningonacolliderunblockaback-doorpath?Toseetheanswerto
thisquestion,recallthediscussionofconditioninginreferencetoFigure3.3(c)andthen
asdemonstratedinFigure4.2. There,withthe exampleofSATandmotivationeffects
on a hypothetical admissions decision to a college, we explained why conditioning on
a collider variable induces an association between those variables that the collider is
dependent on. That point applies here as well, when the causal effect of D on Y in
Figure 4.3 is considered. Conditioning on a collider that lies along a back-door path
unblockstheback-doorpathinthe sensethatitcreatesanassociationbetweenD and
Y within at least one of the subgroups enumerated by the collider.

Considerthe slightlymorecomplexexamplethatis presentedinFigure4.4(which
issimilarto Figure1.1, exceptthat the bidirectededgesthatsignifiedunspecifiedand
unobservedcommoncauseshavebeenreplacedwithtwospecificunobservedvariables,
U and V). Suppose, again, that we wish to estimate the causal effect of D on Y. For
this directed graph, there are two back-door paths between D and Y:
1. D←A←V →F →Y and
2. D←B←U→A←V →F →Y.

Notice that A is a collider variable in the second back-door path but not in the first
back-doorpath.Asaresult,thefirstback-doorpathgeneratesanoncausalassociation
betweenDandY,butthesecondback-doorpathdoesnot.Wethereforewanttoblock
the first path without unblocking the second path.

V
G
U A F
B D Y
C
Figure 4.4 A causal diagram in which A is a collider on a back-door path.

For this example, there are two entirely different and effective conditioning strate-
giesavailablethatwillidentifythe causaleffect(numbers1and3inthefollowinglist)
and a third one that may appear to workbut that will fail (number 2 in the following
list):
1. F isthemiddle variableinachainofmediation,V →F→Y,forbothback-door
paths. As a result, F satisfies the back-door criterion, and conditioning on F
identifies the causal effect of D on Y.

2. Aisamiddlevariableinachainofmediation,D←A←V,forthefirstback-door
path. However, A is a collider variable for the second back-doorpath because it
is the middle variable in a fork of mutual causation, U →A←V. As a result,
A alone does not satisfy the back-door criterion. Conditioning on A does not
identify the causal effect of D on Y, even though A lies along both back-door
paths.ConditioningonAwouldunblockthe secondback-doorpathandthereby
create a new, noncausal, back-door association between D and Y.

3. A is a middle variable in a chain of mediation, D←A←V, for the first back-
doorpath.Likewise,B isamiddlevariableinachainofmediation,D ←B←U,
for the second back-door path. Thus, even though A blocks only the first back-
doorpath(and, infact, conditioning onitunblocks the secondback-doorpath),
conditioning on B blocks the second back-door path. As a result, A and B
together (but not alone) satisfy the back-door criterion, and conditioning on
them together identifies the causal effect of D on Y.

In sum, for this example the causal effect can be identified by conditioning in one of
two minimally sufficient ways: either condition on F or condition on both A and B.9
Now, we need to consider the complications introduced by descendants, as stipu-
lated in both Condition 1(c) and Condition 2. Notice that Condition 1(c) states that
neither C nor the descendants of C can be in Z. In words, conditioning on a collider
or the descendant of a collider that lies on a back-door path will unblock the back-
door path. Consider an extension of our prior analysis of Figure 4.3. For the graph in
Figure 4.5, there are again two back-door paths from D to Y:
1. D←V →Yt−2→Yt−1→Y and
2. D←V →Yt−2←U→Y.

The firstpathdoes not containany collidersandtherefore confounds the causaleffect
of D on Y. The second back-door path, however, is blocked without any conditioning
because Yt−2 is a collider on it. One might think, therefore, that conditioning on Yt−1
will block the first path without unblocking the second path. Condition 1(c) rules out
this possibility because Yt−1 is a descendant of Yt−2, and the latter is a collider on an
already blocked path. The reasoning here is straightforward. The descendant Yt−1 is
simply a noisy version of Yt−2 because its structural equation is
Yt−1=fYt−1(Yt−2,eYt−1),
where the error term, eYt−1, is (as usual) assumed to be independent of all else in the
graph. As a result, conditioning on Yt−1 has the same consequences for the second
back-door path as conditioning on Yt−2.10
Having explained Conditions 1(a), (b), and (c) of the back-door criterion, we can
now consider Condition 2, which states that none of the variables in the possible
conditioning set Z can be descendants of the causal variable that block the causal
effect of interest by lying on or descending from any of the directed paths that begin
atthe causal variableandreachthe outcome variable.Recall that a directedpathis a
path in which all edges point in the same direction. In all prior examples discussed in
thissection,the onlydescendantofD hasbeenY,andthusCondition2hasbeenmet
by default (under the assumptionthat the analysthas notconsideredconditioning on
the outcome variable Y itself).

We now consider two examples where additional descendants of D are present.

Figure4.6presentsagraphthatelaboratesFigure4.1,wherenowthetotaleffectofD
onY isseparatedintoanindirectpathwaythroughamediatingvariable,D→N→Y,
and a remaining direct effect, D→Y. We will discuss models with such mediating
9 One can of course condition in three additional ways that also satisfy the back-door criterion:
F and A, F and B, and F, A, and B. These conditioning sets include unnecessary and redundant
conditioning.

10Hernn,Hernandez-Diaz, andRobins(2004) offeranexcellent discussionofexamples inepidemi-
ology for which such descendants of colliders are a primary focus. For their types of examples, the
outcomeis“death,”thecolliderontheback-doorpath(orelsewhereinthecausalgraph)is“getting
sick enough to be admitted to a hospital for treatment,” and the variable that is conditioned on is
“inahospital.”Conditioningon“inahospital”(byundertakingastudyofhospitalpatients)induces
associationsbetweenthedeterminantsofsicknessthatcanspoilstandardanalyses.Elwert(2013)and
Elwert and Winship (2014) cover many of the same issues from a social science perspective. In an
appendixtothischapter, wealsoprovideadditionaldiscussionandexamples.

U
Y
t–2
Y
t–1
Y
V
D
Figure4.5 AcausaldiagraminwhichYt−2 isacollideronaback-doorpathandYt−1
is its descendant.

C O
D Y
N
Figure4.6 Aconfoundedcausaleffectexpressedasanindirecteffectandanetdirect
effect.

mechanisms in substantial detail in Chapter 10, and for now we will use this graph
only to introduce a discussion of Condition 2 of the back-door criterion.

Aswehavenotedinthissectionandelsewhere(and,assumingnow,withoutlossof
generality that D is a two-valued treatment), conditioning on either C or O identifies
thetotalaveragecausaleffectofDonY,whichwedefinedinSection3.4asE[Y|do(D=
1)]−E[Y|do(D=0)].Theback-doorcriterionstatesthatif,inadditiontoC and/orO,
we also conditioned on N, the resulting estimate would no longer identify the casual
effectofDonY.TheconditioningsetofC,O,andN violatesCondition2oftheback-
doorcriterionbecauseN isadescendantofDthatliesonadirectedpath,D→N→Y,
that reaches Y. As a result, the back-door criterion indicates that the analyst should
not condition on N.

We suspect that this conclusion would be clear to readers without consulting the
back-door criterion (by reasoning that adjustment for N would rob the total causal
effect of D on Y of some of its magnitude, leaving only a partial direct effect that
is not equal to E[Y|do(D=1)]−E[Y|do(D=0)]).11 Such reasoning is correct, and
Condition 2 of the back-door criterion is, in part, a formalization of this intuition.

11Inthissection,weareconsideringonlyhowtoapplytheback-doorcriterionwhenthegoalisto
estimate the total effect of the cause D on the outcome Y. If, instead, the analyst is interested in
estimatingthedirecteffectofDonY,netoftheindirecteffectofDonY throughN,thenadjustment
for N is necessary. VanderWeele (in press) provides a comprehensive treatment of the identification
andestimationofdirecteffects. WewillreturntotheseissuesinChapter10,wherewewillconsider
howtoidentifycausaleffects usinggenerativemechanisms.

C O
M
D Y
N
B U
Figure4.7 A graph where the effect of D on Y is not identified by conditioning on
O and B because O is a descendant of D.

However,Condition2ismorefinelyarticulatedthanthisintuitionalone.Itinvalidates
conditioningsets that adjustawayanyportionofthe causaleffectofinterest,notjust
those portions that are carried by variables that mediate the causal effect. Just as
conditioningonthedescendantofacolliderhasthesameconsequencesasconditioning
onthe collider itself,conditioning ona descendantofa variablethatlies ona directed
path from the causal variable to the outcome variable has the same consequences for
identificationresultsasconditioningdirectlyonthevariablefromwhichitdescends.12
ConsiderFigure4.7,whereweareagaininterestedintheeffectofDonY andwhere
wehavenowspecifiedtwomediatingvariables,M andN,thatcompletelycharacterize
the total effect of D on Y. For this graph, three back-door paths connect D to Y:
1. D←C→O→Y,
2. D←C→O←M→Y, and
3. D←B→U→Y.

Inaddition,thevariablesC,M,andU areunobserved,andthustheyarenotavailable
to use in a conditioning estimator.

Suppose that one decides to condition on both O and B. First, note that these
two variables do not satisfy Conditions 1(a), (b), and (c) of the back-door criterion.

12Notice further that Condition 2 applies to descendants of the cause that lieon or descend from
variablesondirectedpathsthatbeginatthecausalvariableand“reachtheoutcomevariable”rather
than “end at the outcome variable.”The word “reach” has been chosen to allow for Condition 2 to
invalidate conditioning sets that include descendants of the cause that are also descendants of the
outcome.SupposethatanadditionalobservedvariableW isaddedtoFigure4.6alongwithadirected
edgefromY toW,asinY →W.ThenewvariableW isadescendant ofbothD andY viathetwo
directed paths D→Y →W and D→N→Y →W that begin at D and reach Y (and, in this case,
carry on to W). There is, of course, no reason to condition on W in an attempt to estimate the
causal effect of D and Y because W does not lie on a back-door path from D to Y that confounds
thecausaleffectofinterest.Ifananalystdoesdoso,byaddingW toaconditioningsetthatincludes
C and/or O, then Conditions 1(a), (b), and (c) of the back-door criterion are met but Condition 2
is not. The variable W is simply a noisy version of Y, and the causal effect of D on Y is therefore
embeddedwithinit.Conditioningon W will,infact,mistakenlysuggestthatD hasnocasualeffect
onY becausewithinstratadefinedbyW,DandY areindependent(assumingnomeasurementerror
andaninfinitesamplethatenables fullynonparametricestimation).

ConditioningonOwillblockpath1,andconditioningonB willblockpath3.However,
conditioning on O will unblock path 2 because it is a collider on an already blocked
back-door path.

WhatwewanttostressnowisthatthecandidateconditioningsetofO andB also
does not satisfy Condition 2 of the back-door criterion. O is a descendant of D on a
directed path, D→M →O→Y, that reaches Y. Furthermore, O is a descendant of
M, via M→O, and M is a variable that lies on another directed path, D→M→Y,
that begins at D and reaches Y.

NoticealsothatthegraphinFigure4.7isrealisticandnotcontrived.Ifaresearcher
follows the (sometimes wrong)conditioning strategy of “adjusting for all other causes
of the outcome,” and the researcher has not drawn the full causal graph in Figure
4.7, then the researcherwould almost certainly condition on O (even if the researcher
wisely decides not to condition on the clearly endogenous observed variable N but
does decide to condition on the second-order cause B in place of the unobserved
direct cause U). In practice, other causes of an outcome that are observed are hard
to resist conditioning on, even though many of them are descendants of the cause
along directed paths that reach the outcome and thereby violate Condition 2 of the
back-doorcriterion.IfaresearcherdoesnotobserveamechanisticvariablelikeM,the
analyst may not recognize the endogeneity of O with respect to D (especially if the
analyst comes to believe that the only mechanistic variable has been observed as N
and that the remaining effect of D on Y is an unmediated direct effect).

Condition2ofthe back-doorcriterionisageneralrequirementforsufficientcondi-
tioningsets,anditiseasytoapply.Oneneedonlyexamineeachcandidateconditioning
variable to determine whether it lies on (or descends from a variable that lies on) the
directed paths that begin at the causal variable and reach the outcome variable.

Although Condition 2 is easy to apply, we discuss additional examples in an
appendixtothischapterthataremorechallengingtoexplain.Inparticular,werecon-
sider the graphs just presented, building toward a full reexamination of the graph
in Figure 4.7, which is even more complex than our presentation here reveals. In
the appendix, we show that a full assessment of the consequences of conditioning on
descendantsofthecauseisenabledbydrawingthegraphsundermagnificationsothat
itiseasiertorecognizeallsuchdescendantsascolliders.Althoughthesemorecomplex
cases are interesting to examine, so as to understand the full range of identification
challenges that graphical models help to explain, one need not fully understand them
or absorb them to effectively adhere to conditioning strategies that are warranted by
the back-door criterion.

Thetwokeypointsofthissectionarethefollowing.First,conditioningonvariables
thatlieonback-doorpathscanbeaneffectivestrategytoidentifyacausaleffect.Ifall
back-doorpathsbetweenthecausalvariableandtheoutcomevariableareblockedafter
the conditioning isenacted,thenback-doorpaths donotcontributeto the association
betweenthecausalvariableandtheoutcomevariable.However,itmustbekeptinmind
that conditioning on a collider (or a descendant of a collider) has the opposite effect.

Any such conditioning unblocks already blocked back-door paths. And thus, when a
conditioning strategy is evaluated, each back-door path must be assessed carefully
because a variable can be a collider on one back-door path but not a collider on
another.

Second, if a set of conditioning variables blocks all back-door paths, the analyst
mustthenverifythatnovariableswithintheconditioningsetblockthecausaleffectof
interest or otherwise mistakenly adjust it away. If none of the candidate conditioning
variables are also descendants of the cause that lie on or descend from directed paths
thatbeginatthecausalvariableandreachtheoutcomevariable,thenthecausaleffect
is identified and a conditioning estimator is consistent and unbiased for the average
causal effect.

Pearl’sback-doorcriterionforevaluatingconditioningstrategiesisageneralization
(and therefore a unification) of various traditions for how to solve problems that are
frequently attributed to omitted-variable bias. From our perspective, Pearl’s frame-
work is particularly helpful in two respects. First, it shows clearly that researchersdo
not need to condition on all omitted direct causes of an outcome variable in order
to solve an omitted-variable bias problem. This claim is not new, of course, but
Pearl’s back-door criterion shows clearly why researchers need to condition on only
a minimally sufficient set of variables that (a) renders all back-door paths blocked
and (b) does not block the causal effect itself. Second, Pearl’s framework shows how
to think clearly about the appropriateness of conditioning on endogenous variables.

Writingdowneachback-doorpathandthen determiningwhether ornoteachendoge-
nous variable is a collider along any of the back-door paths is a much simpler way
to begin to consider the full complications of a conditioning strategy than other
approaches.13
In the next section, we consider models of causal exposure that have been used in
thecounterfactualtradition,startingfirstwiththestatisticsliteratureandcarryingon
to the econometrics literature. We will showthat the assumptions often introduced in
thesetwotraditionstojustifyconditioningestimationstrategies–namely,ignorability
and selection on the observables – have close connections to the back-door criterion
presented in this section.

13Theback-doorcriterionisnottheonlyavailablegraphicalguidefortheselectionofconditioning
variables.Elwert(2013:256–61) offersacrispsummaryofthealternatives.Amongthese, theadjust-
mentcriterion isthemostgeneralandisguaranteedtoselectallpossiblesufficientconditioningsets.

Nonetheless, we make the case in the appendix to this chapter that the version of the back-door
criterionthatwepresentinthemaintextofthischapterhasadvantagesrelativetothecompleteness
oftheadjustmentcriterion.Amongtheothercriteria,thedisjunctivecausecriterion ofVanderWeele
and Shpitser (2011) is also particularly useful because it can serve as a guide to conditioning when
the analyst is unwilling to commit to a set of assumptions that enable a full directed graph to be
drawn for the generation of the outcome. The disjunctive cause criterion instructs the analyst to
adjustforallvariablesthatarecausesofthetreatmentortheoutcome, butnotthosevariablesthat
arecauses neither of thetreatment nor ofthe outcome. Theanalyst thereforedoes notneedto con-
structadirectedgraph,onlytakeapositiononwhether thecandidate conditioningvariablesshould
beassumedtobecauses ofthe treatment, causes oftheoutcome, orneither.Ofcourse, thepriceto
bepaidforthesimplicityofthedisjunctivecausecriterionisthatitwillnotnecessarilyidentifythe
causal effect (because one cannot know about all sources of confounding ifone cannot draw the full
directed graphforthe generation of the outcome) and can suggest redundant conditioning (because
one does not need to condition on variables that lie on back-door paths that are already blocked
bycolliders,variablesthat lieonback-door paths thatarealreadyblocked byconditioningonother
variables, or variables that do not lie on any back-door paths). Nonetheless, the disjunctive cause
criterion will prevent the analyst from inducing noncausal associations between the treatment and
outcome that would result from conditioning on the relevant colliders that already block back-door
paths.

## 4.3 Models of Causal Exposure and Point Identification Based on the Potential Outcome Model

With this general presentation of the conditioning strategy in mind, return to the

familiarcaseofabinarycauseD andanobservedoutcomevariableY.Asdiscussedin
Chapter2,forthepotentialoutcomemodelweconsiderY tohavebeengeneratedbya
switchingprocessbetweentwopotentialoutcomevariables,asinY =DY1+(1−D)Y0,
where the causal variable D is the switch. To model variation in Y and relate it to
the individual-level causal effects defined by the potential outcome variables Y1 and
Y0, a model for the variation in D must be adopted. This is typically known in the
statistics literature as “modeling the treatment assignment mechanism” and in the
econometrics literature as “modeling the treatment selection mechanism.”
In this section, we first consider the notation and language developed by statisti-
cians, andwe then turn to the alternative notationand language developedby econo-
metricians. Although both sets of ideas are equivalent, they each have some distinct
conceptualadvantages.Inshowingboth,wehopetodeepentheunderstandingofeach.

4.3.1 Treatment Assignment Modeling in Statistics
The statistics literature on modeling the treatment assignment mechanism is an out-
growthofexperimentalmethodologyandtheimplementationofrandomizationresearch
designs. Accordingly, we begin by considering a randomized experiment for which the
phrase “treatment assignment” remains entirely appropriate.

As discussed in Chapter 2, if treatment assignment is completely randomized by
design,thenthetreatmentindicatorvariableDiscompletelyindependentofthepoten-
tial outcomes Y0 and Y1 as well as any function of them, such as the distribution of
δ; see the earlier discussion of Equation (2.6). In this case, the treatment assignment
mechanismisknownbecauseitissetbytheresearcherwhoundertakestherandomiza-
tion. If the researcherwants treatment and control groups of approximately the same
size, then Pr[D=1] is set to .5. Individual realized values ofD for those in the study,
denoteddi generically,arethen equalto1or0 andaredeterminedbythe flipofafair
coin(orby acomputer thatruns Bernoullitrialsfor the randomvariableD with .5as
the probability).

Tofacilitatethe transitionto designsforobservationalresearch,consideraslightly
more elaborate design where study subjects are stratified first by gender and then
assigned with disproportionate probability to the treatment group if female. In this
case, the treatment assignment protocol would instead be represented by two condi-
tional probabilities, such as
Pr[D=1|Gender=Female]=.7, (4.1)
Pr[D=1|Gender=Male]=.5. (4.2)
These conditional probabilities are typically referred to as “propensity scores” in the
literaturebecausetheyindicatethepropensitythatanindividualwithspecificcharac-
teristics will be observed in the treatment group. Although labeled propensity scores
intheliterature,theyarenonethelessnothingmorethanconditionalprobabilitiesthat
lie within anintervalbounded by 0 and 1.For this example,the propensity score is .7
for female subjects and .5 for male subjects. The general point is that for randomized
experiments, the propensity scores are known to the researcher.

Incontrast,aresearcherwithobservationaldatadoesnotpossessaprioriknowledge
of the exact propensity scores that apply to all individuals. However, the researcher
may know all of the characteristics of individuals that systematically determine their
propensityscores,eveniftheresearcherdoesnotknowthespecificvaluesofthepropen-
sity scores.14 In this case, treatmentassignmentpatterns are representedby a general
conditional probability distribution,
Pr[D=1|S], (4.3)
where S now denotes all variables that systematically determine all treatment assign-
mentpatterns.CompleteobservationofS thenallowsaresearchertoassertthattreat-
ment assignment is “ignorable” and then consistently estimate the averagetreatment
effect (ATE), as we now explain.

The general idea here is that, within strata defined by S, the remaining variation
in the treatment D is completely random and hence the process that generates this
remaining variation is labeled “ignorable.” The core of the concept of ignorability is
the independence assumption that was introduced in Equation (2.6),
(Y0,Y1) ⊥⊥ D,
where the symbol ⊥⊥ denotes independence. As defined by Rubin (1978), ignorability
of treatment assignment holds when the potential outcomes are independent of the
treatment dummy indicator variable, as in this case all variation in D is completely
random. Ignorability also holds in the weaker case where
(Y0,Y1) ⊥⊥ D | S (4.4)
and
all variables in S are observed.

In words, the treatment assignment mechanism is ignorable when the potential out-
comes(andanyfunctionofthem,suchasδ)areindependentofthetreatmentvariable,
D, within strata defined by all combinations of values on all variables, S, that sys-
tematicallydetermine alltreatmentassignmentpatterns.IfsomecomponentsofS are
unobserved, the conditional independence condition in Equation (4.4) may still hold,
buttreatmentassignmentcannotbeconsideredignorablewithrespecttotheobserved
data. In this case, treatment assignment must be regarded as nonignorable, even if it
is known that it would be ignorable if all variables in S had instead been observed.15
14This would be the situation for the randomized experiment represented by Equations (4.1) and
(4.2)ifthe experimentalistknew that the probabilityofbeingassigned tothe treatment differedby
gender(andonlybygender)buthadforgottenthevalues of.7and.5.

15Rosenbaum and Rubin (1983a) defined strong ignorability to develop the matching literature,
which we will discuss later. To Rubin’s ignorability assumption, Rosenbaum and Rubin (1983a)
required for strong ignorability that each subject have a nonzero probability of being assigned to
both the treatment and the control groups. Despite these clear definitions, the term ignorability is
In practice, in order to assertthat treatment assignment is ignorable for an obser-
vational study, a researcher would
1. determinefromrelatedstudies andsupportableassumptionsgroundedintheory
what the components of S are,
2. measure each of the component variables in S, and
3. collect enough data to be able to consistently estimate outcome differences on
the observed variable Y within strata defined by S.

This thirdstepcanbe weakenedifthe dataaremerelysparse,aswe willdiscusswhen
presenting models based on estimate propensity scores in Chapters 5 and 7. The key
pointisthataresearcherdoesnotneedtoknowtheexactpropensityscores(i.e.,what
Pr[D=1|S=s] is equal to for all s), only that the systematic features of treatment
assignmentcanbeexhaustivelyaccountedforbythedatainhandonthecharacteristics
of individuals. The naive estimator can then be calculated within strata defined by
values of the variables in S, and a weighted average of these stratified estimates can
be formed as a consistent estimate of the ATE.16
Consider the Catholic school example. It is well known that students whose par-
ents self-identify as Catholic are more likely to be enrolled in Catholic schools than
students whose parents self-identify as non-Catholic. Suppose that parents’ religious
identity is the only characteristic of students that systematically determines whether
they attend Catholic schools instead of public schools. In this case, a researcher can
consistentlyestimatetheATEbycollectingdataontestscores,students’schoolsector
attendance,andparent’sreligiousidentification.Aresearcherwouldthenestimatethe
effect of Catholic schooling separately by using the naive estimator within groups of
students defined by parents’ religious identification and then take a weighted average
ofthese estimatesbasedonthe proportionofthe populationofinterestwhose parents
self-identify as Catholic and as non-Catholic. In the words of the prior section, the
researchercangenerateconsistentandunbiasedestimatesofthe ATE byconditioning
on parents’ religious identification.

Assumptions of ignorability have a close connection to the back-door criterion of
Pearl, given the shared centrality of the conditioning operation. Even so, it is impor-
tant to recognize some differences. Suppose that we are confronted with the graph in
Figure 4.8(a), which includes the causal effect D→Y but also the bidirected edge
D(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)Y. The most common solution is to build an explicit causal model that rep-
resents the variables that generate the bidirected edge between D and Y in Figure
4.8(a). The simplest such model is presented in Figure 4.8(b), where D(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)Y has
been replaced with the back-door path D← S→Y. If S is observed, then condition-
ing on S will solve the causal inference problem, according to the back-door criterion
oftendefinedindifferentwaysintheliterature.Wesuspectthatthisvariedhistoryofusageexplains
why Rosenbaum (2002) rarely uses the term in his monograph on observational data analysis, even
thoughheisgenerallycredited,alongwithRubin,withdevelopingtheignorabilitysemanticsinthis
literature. And it also explains why some of the most recent econometrics literature uses the words
unconfoundedness and exogeneity for the same set of independence and conditional-independence
assumptions(seeImbens2004).

16Again,weassumethatmeasurementerrordoesnotexist,whichrequiresthatstep2beundertaken
withouterror.

S
D Y D Y
(a) (b)
Figure4.8 Causal diagrams in which treatment assignment is (a) nonignorable and
(b) ignorable.

presentedintheprevioussection.Inthestatisticsliterature,thesameresultisexplained
by noting that treatment assignment is ignorable when S is observed, which is then
written asEquation ( 4.4).

When identification by back-door conditioning is feasible with the observed data,
then treatment selection is ignorable with respect to the observed data. However, we
do not mean to imply with this statement that the assertion of a valid ignorability
assumptionwillleadtheresearchertoconditionontheexactsamevariablessuggested
by the back-door criterion. Recall that the back-door criterion guides the researcher
in selecting minimally sufficient conditioning sets. Ignorability can be asserted with
respect to these sets or with respect to broader sets of conditioning variables. For
an example, let S in Figure 4.8(b) be a set of variables. Suppose that, upon reflec-
tion, a researcher decides that one of the variables in S, S(cid:2), has a direct effect on
D but no direct effect on Y. Accordingly, it is appropriate to separate S(cid:2) from the
other variables in S and assert that S(cid:2) is a cause of D that causes Y only indirectly
throughD.17Inthiscase,S(cid:2)doesnotgenerateanyconfoundingbecauseS(cid:2)doesnotlie
onaback-doorpathbetweenD andY.Theminimallysufficientconditioningsetsthat
are judged admissible by the back-door criterion would not include S(cid:2), even though
treatment assignment is ignorable with respect to S(cid:2) and the remaining variables in
S.Thus,whenassertingignorabilitywith respectto the observeddata,the researcher
maydecidetoconditiononS(cid:2),eventhoughsuchconditioningisunnecessary.Afterall,
S(cid:2) does determine treatment assignment and, hence, does structure the true propen-
sityscore.AnditispossiblethatthestrongassumptionthatS(cid:2) doesnothaveadirect
effect on Y is incorrect.

We will begin to discuss specific techniques for conditioning estimators in
Chapter5,wherewefirstpresentmatchingestimatorsofcausaleffects.Buttheimme-
diate complications of undertaking a conditioning analysis strategy for the Catholic
school example should be clear. How do we determine all of the factors that system-
atically determine whether a student enrolls in a Catholic school instead of a public
school? And can we obtain measures of all of these factors? Attendance at a Catholic
school is determined by more than just parents’ religious self-identification, and some
of these determinants are likely unmeasured. If this is the case, then the treatment
assignment mechanism is likely to be nonignorable, as treatment selection is then a
function of unobserved characteristics of students that generate confounding. These
17S(cid:3) isaninstrumentalvariable,aswewillexplaininfulldetailinChapter 9.

issues are best approached by first drawing a directed graph. It may be that some
of the unobserved determinants of treatment assignment do not generate confound-
ing because (a) they do not lie on back-door paths, (b) they lie on back-door paths
that are already blocked by colliders, or (c) they lie on back-door paths that can be
blockedbyconditioning onothervariablesthatlie onthe sameback-doorpaths.Ifso,
the researchermaybe able toassertanignorabilityassumptionwithrespecttoonly a
subsetofthevariableswehavedesignatedasS forthissection.However,inmostcases,
the opposite challenge will dominate: The directed graph will show clearly that only
a subset of the variables in S that generate confounding are observed, and the con-
founding that they generate cannot be eliminated by conditioning with the observed
data. Treatment assignment is then nonignorable with respect to the observed data.

4.3.2 Treatment Selection Modeling in Econometrics
The econometrics literature also has a long tradition of analyzing causal effects, and
this literature may be more familiar to social scientists. Whereas concepts such as
ignorability are used somewhat infrequently in the social sciences, the language of
selection bias is commonly used throughout the social sciences. This usage is due, in
large part,to the energy that economists have devoted to exploring the complications
of self-selection bias.

The selection-bias literature in econometrics is vast, but the most relevant piece
thatwefocusonhereisJamesHeckman’sspecificationoftherandom-coefficientmodel
for the treatment effects of training programs, which he attributes, despite the differ-
enceinsubstance,toRoy(1951).Theclearestspecificationofthismodelwaspresented
in aseries ofpapersthat Heckmanwrotewith RichardRobb (see Heckmanand Robb
1985, 1986, 1989), but Heckman worked out many of these ideas in the 1970s. Using
the notation we have adopted in this book, take Equation (2.2),
Y =DY1+(1−D)Y0,
and then rearrangeand relabel terms as follows:
Y =Y0+(Y1−Y0)D (4.5)
=Y0+δD
=μ0+δD+υ0,
where μ0≡E[Y0] andυ0≡Y0−E[Y0].The standardoutcome modelfromthe econo-
metrics of treatment evaluation simply reexpresses Equation (4.5) so that potential
variability of δ across individuals in the treatment and control groups is relegated to
the error term, as in
Y =μ0+(μ1−μ0)D+{υ0+D(υ1−υ0)}, (4.6)
where μ1≡E[Y1], υ1≡Y1−E[Y1], and all else is as defined for Equation (4.5).18
Note that, in evolving from Equation (2.2) to Equation (4.6), the definition of the
18The original notation is a bit different, but the ideas are the same. Without much usage of the
languageofpotentialoutcomes,HeckmanandRobb(1985,section1.4)offeredthefollowingsetupfor
therandomcoefficientmodeloftreatmenteffects toanalyzeposttreatment earningsdifferencesfora
fictitious workertrainingexample.Foreachindividuali,theearningsofindividualiiftrainedare
observed outcome variable Y has taken on the look and feel of a regression model.19
The firstμ0 termis akinto anintercept,eventhoughitis definedas E[Y0]. The term
(μ1−μ0)thatprecedesthefirstappearanceofD isakintoacoefficientontheprimary
causal variable of interest D, even though (μ1−μ0) is defined as the true ATE, E[δ].

Finally,the terminbraces,{υ0+D(υ1−υ0)}, isakinto anerrorterm,eventhoughit
represents both heterogeneity of the baseline no-treatment potential outcome and of
the causal effect, δ, and even though it includes within it the observed variable D.20
Heckman and Robb use the specification of the treatment evaluation problem in
Equation(4.6),andmanyotherssimilartoit,todemonstrateallofthemajorproblems
createdbyselectionbiasinprogramevaluationcontextswhensimpleregressionestima-
torsareused.HeckmanandRobbshowwhyaregressionofY onDdoesnotingeneral
identifytheATE,inthiscase(μ1−μ0),whenD iscorrelatedwiththepopulation-level
variant of the error term in braces in Equation (4.6), as would be the case when the
size of the individual-leveltreatmenteffect, in this case (μ1−μ0)+{υ i0+di(υ i1−υ i0)},
differs among those who select the treatment and those who do not.

Thestandardregressionstrategythatprevailedintheliteratureatthetimewasto
includeadditionalvariablesinaregressionmodeloftheformofEquation(4.6),hoping
y i1=β1+U i1,
andtheearningsofindividualiintheabsenceoftrainingare
y i0=β0+U i0,
(wherewehavesuppressedsubscriptingontfortimefromtheoriginalpresentationandalsoshifted
thetreatmentstatedescriptorsfromsubscripttosuperscriptposition).Withobservedtrainingstatus
representedbyabinaryvariable,d i,HeckmanandRobbthensubstitutetheright-handsidesofthese
equationsintothedefinitionoftheobservedoutcomeinEquation(2.2)andrearrangetermstoobtain
y i=β0+(β1−β0)d i+U i0+(U i1−U i0)d i,
whichtheythencollapseinto
y i=β0+α¯d i+{U i0+ε id i},
whereα¯≡β1−β0 andε i≡U i1−U i0 (see Heckman andRobb1985, equation 1.13). Asaresult, α¯ is
the ATE, which we defined as E[δ] in Equation (2.3), and ε i is the individual-level departure of δ i
fromtheATE,E[δ].AlthoughthenotationinthislastequationdiffersfromthenotationinEquation
(4.6),thetwoequationsareequivalent.HeckmanandVytlacil(2005,2007)giveafullynonparametric
versionofthistreatment selectionframework,whichwedrawonbelow.

19Sometimes,Equation(4.6)iswrittenas
Y =μ0+[(μ1−μ0)+(υ1−υ0)]D+υ0
in order to preserve its random-coefficient interpretation. This alternative representation is nothing
otherthanamorefullyarticulatedversionofEquation(4.5).

20Statisticianssometimesobjecttothespecificationof“errorterms”because,amongotherthings,
they are said to represent a hidden assumption of linearity. In this case, however, the specification
ofthis errorterm isnothing other than anexpression of the definition of the individual-levelcausal
effectasthelineardifferencebetweeny1 andy0.

i i
to break the correlation between D and the error term.21 Heckman and Robb show
that this strategy is generally ineffective with the data available on worker training
programs because (1) some individuals are thought to enter the programs based on
anticipation of the treatment effect itself and (2) none of the available data sources
have measures of such anticipation. We will return to this case in detail in Chapter 6,
where we discuss regression models.

To explain these complications, Heckman and Robb explore how effectively the
dependence between D and the error term in Equation (4.6) can be broken. They
proceed by proposing that treatment selection be modeled by specifying a latent con-
tinuous variable D˜ as
D˜=Zφ+U, (4.7)
where Z represents all observed variables that determine treatment selection, φ is a
coefficient (or a vector of coefficients if Z includes more than one variable), and U
represents both systematic unobserved determinants of treatment selection and com-
pletely random idiosyncratic determinants of treatment selection. The latent contin-
uous variable D˜ in Equation (4.7) is then related to the treatment selection dummy,
D, by
D=1 if D˜≥0,
D=0 if D˜<0,
wherethethreshold0isarbitrarybecausethetermU hasnoinherentmetric(because
it is composed of unobserved and possibly unknown variables).

To see the connectionbetween this econometricspecificationandthe one fromthe
statistics literature introduced in the last section, first recall that statisticians typi-
cally specify the treatmentselectionmechanismas the generalconditional probability
distribution Pr[D=1|S], where S is a vector of all systematic observed determinants
oftreatmentselection.22 This is showninthe graphin Figure4.8(b). The correspond-
ing causaldiagramforthe econometricselectionequationis presentedintwodifferent
graphs in Figure 4.9, as there are two scenarios corresponding to whether or not all
elements of S have been observed as Z.

For the case in which Z in Equation (4.7) is equivalent to the set of variables in
S in Equation (4.3), treatment selection is ignorable, as defined in Equation (4.4),
because conditioning on Z is exactly equivalent to conditioning on S. In the econo-
metric tradition, this situation would not, however, be referred to as a case for which
treatment assignment/selection is ignorable. Rather, treatment selection would be
characterized as “selection on the observables” because all systematic determinants
of treatment selection are included in the observed treatment selection variables Z.

This phrase is widely used by socialscientists because it conveysthe essential content
21Barnow,Cain,andGoldberger(1980:52) notedthat“themostcommonapproach”isto“simply
assumeawaytheselectionbiasafteradiligentattempttoincludealargenumberofvariables”inthe
regressionequation.

22When more specific, the basic model is usually a Bernoulli trial, inwhich Pr[D=1|S=s] gives
thespecificprobabilityofdrawinga1andthecomplementofdrawinga0forindividualswithSequal
tos.

Z Z
D Y D Y
U U
(a) Selection on the observables (b) Selection on the unobservables
Figure4.9 Causaldiagramsfor the terminologyfromeconometricmodeling oftreat-
ment selection.

oftheignorabilityassumption:Allsystematicdeterminantsoftreatmentselectionhave
been observed.23
The scenarioof selection on the observables is depicted in Figure 4.9(a). The vari-
able S in Figure 4.8(b) is simply relabeled Z, and there are no back-door paths from
D to Y other than the one that is blocked by Z. The remaining idiosyncratic random
variation in D is attributed in the econometric tradition to a variable U, which is
presented in Figure 4.9(a) as a cause of D that is conditionally independent of both
Z and Y. This error term U represents nothing other than completely idiosyncratic
determinantsoftreatmentselection.It couldthereforebe suppressedinFigure 4.9(a),
which would render this graph the same as the one in Figure 4.8(b).24
Now consider the case in which the observed treatment selection variables in Z
are only a subset of the variables in S. In this particular case, some components of
S enter into the treatment selection latent variable D˜ through the error term, U,
of Equation (4.7). In this case, treatment selection is nonignorable. In the words of
econometricians, “selection is on the unobservables” (or, more completely, “selection
is on the observables Z and the unobservables U”). The scenario of selection on the
unobservablesis depicted in Figure 4.9(b), where there are now back-doorpaths from
D to Y represented by D←U (cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)Y. Conditioning on Z for this graph does not
block all back-door paths.

In spite of differences in language and notation, there is little that differentiates
the statistics and econometrics models of treatment selection, especially now that the
outcomeequationsusedbyeconomistsareoftencompletelygeneralnonparametricver-
sionsofEquation(4.6)(seeHeckmanandVytlacil2005,whichwewilldiscussinafew
differentplaceslaterinthebook,suchasChapters9and12).Fornow,thekeypointis
that both the statistics and econometric specifications consider the treatment indica-
tor variable, D, to be determined by a set of systematic treatment selection variables
23And,as withignorability, the variables inZ arenotnecessarily equivalent to those inthe mini-
mallysufficientconditioningsetssuggestedbytheback-doorcriterion.Theadmissiblesetsaccording
to the back-door criterion may be subsets of the variables in Z or even variables not in Z that are
proximatedeterminantsofY andthat,whenconditionedon,blockallback-doorpathsgeneratedby
thevariablesinZ.

24The latent variable specification in the econometric tradition can be made equivalent to almost
all particular specifications of the statement Pr[D=1|S] in the statistics tradition by the choice of
an explicit probability distribution for U. The full nonparametric equivalence in the causal graph
traditionwouldbeD=f D(S,e D)=f D(Z,U).

in S. When all of these variables are observed, the treatment selection mechanism is
ignorable and selection is on the observables only. When some of the variables in S
areunobserved,the treatmentselectionmechanismisnonignorableandselectionison
the unobservables.

Finally,thequalificationswenotedinthepriorsectionaboutthedifferencesbetween
ignorability assumptions and the back-door criterion apply in analogous fashion to
assumptions of selection on the observables. Minimally sufficient conditioning sets
suggested by the back-door criterion may be subsets of the variables in Z or entirely
different variables that, when conditioned on, eliminate the confounding generatedby
Z. Variables of the latter type would typically be proximate determinants of Y that
intercept the effects of the variables in Z on Y, such as the variable F in Figure 4.4.

4.3.3 Point Identification of Conditional Average
Treatment Effects by Conditioning
At the beginning of this chapter, we indicated that we would implicitly focus our pre-
sentation of directed graphs and identification issues on the estimation of the uncon-
ditional ATE. This narrow focus is entirely consistent with the graphical tradition,
in which parameters such as the average treatment effect for the treated (ATT) in
Equation (2.7) and the average treatment effect for the controls (ATC) in Equation
(2.8) are given considerably less attention than in the potential outcome modeling
traditioninbothstatisticsandeconometrics.Somecommentsonthe connectionsmay
be helpful at this point to foreshadow some of the specific material on causal effect
heterogeneity that we will present in the next three chapters.

Identification When the Unconditional ATE Is Identified
Ifonecanidentify andconsistentlyestimatethe unconditionalATEwithconditioning
techniques, then one can usually estimate some of the conditional average treatment
effects that may be of interest as well. As we will show in the next three chapters,
consistent estimates of conditional average treatment effects can usually be formed
by specification of alternative weighted averages of the average treatment effects for
subgroups defined by values of the conditioning variables. Thus, calculating average
effects other than the unconditional ATE may be no more complicated than simply
adding one step to the more general conditioning strategy we have presented in this
chapter.

ConsideragainthegraphpresentedinFigure4.8(b).Theback-doorpathfromDto
Y is blockedbyS. Asa result,aconsistentestimate ofthe ATE inEquation(2.3)can
beobtainedbyconditioningonS.But,inaddition,consistentestimatesoftheATTin
Equation(2.7) and the ATC in Equation(2.8) can be obtained by properly weighting
conditional differences in the observed values of Y. In particular, first calculate the
sample analogsto the differences E[Y|D=1,S=s]−E[Y|D=0,S=s] for allvalues s
of S. Then, weight these differences by the conditional distributions Pr[S|D=1] and
Pr[S|D=0] to calculate the ATT and the ATC, respectively.

Identification When the Unconditional ATE Is Not Identified
Ifselectionisontheunobservables,conditioningstrategieswilltypicallyfailtoidentify
unconditional ATEs. Nonetheless, weaker assumptions may still allow for the iden-
tification and subsequent estimation by conditioning of various conditional average
treatment effects. We will present these specific weaker assumptions in the course of
explainingmatchingandregressiontechniquesin the nextthree chapters,butfor now
we give a brief overviewof the identification issues in relationto the graphicalmodels
presentedinthischapter.(SeealsothediscussioninSection2.7.4ofsimilarissueswith
regardto the inconsistency and bias of the naive estimator.)
Suppose,forexample,thatthegraphinFigure4.9(b)nowobtains,andhence that
a back-door path from D to Y exists via unobserved determinants of the cause, U.

In this case, conditioning on Z will not identify the unconditional ATE. Nonetheless,
conditioning on Z may still identify a conditionalaveragetreatment effect of interest,
as narrower effects can be identified if weaker assumptions can be maintained even
though unblocked back-door paths may still exist between D and Y.

Consideracaseforwhichpartialignorabilityholds,suchthatY0 ⊥⊥D|S istruebut
(Y0,Y1)⊥⊥D |S isnot.Here,conditioningonS generatesaconsistentestimateofthe
ATTeventhoughS doesnotblocktheback-doorpathfromDtoY.Theoppositeis,of
course,alsotrue.Ifpartialignorabilityholdsintheotherdirection,suchthatY1⊥⊥D|S
holds but (Y0,Y1) ⊥⊥ D|S does not, then the ATC can be estimated consistently.25
Considerthefirstcase,inwhichonlyY0 ⊥⊥D |S holds.Evenafterconditioningon
S, a back-door path remains between D and Y because Y1 still differs systematically
betweenthoseinthetreatmentandcontrolgroupsandY isdeterminedinpartbyY1;
seeEquation(2.2).Nonetheless,if,afterconditioningonS,theoutcomeundertheno-
treatment-state, Y0, is independent of exposure to the treatment, then the ATT can
be estimated consistently. The average values of Y, conditional on S, can be used to
consistently estimate the averagewhat-if values for the treatedif they wereinstead in
thecontrolstate.ThistypeofpartialignorabilityisakintoAssumption2inEquation
(2.16), except that it is conditional on S. We will give a full explanation of the utility
of such assumptions when discussing matching estimates of the ATT and the ATC in
the next chapter.

Graphs Do Not Clearly Reveal the Identification Possibilities for
the ATT and ATC When the ATE Is Not Also Identified
In the prior section, we noted in our presentations of ignorability and selection on
the observables that graphs help guide researchers toward minimally sufficient con-
ditioning sets that may differ from the conditioning sets suggested by the statistics
andeconometricsliterature.Theback-doorcriterionisespeciallyhelpfulinthisregard
because of its targeted focus on back-door paths that generate noncausal associations
betweenthecausalvariableandtheoutcomevariable.However,itmustalsobestated,
asimpliedbythissection,thatdirectedgraphswillnotclearlyrevealeffectiveanalysis
25And,aswewillshowinthenextchapter,therequiredassumptionsareevensimplerbecausethe
entiredistributionsofY0 andY1 neednotbeconditionallyindependent ofD.Aslongasthestable
unittreatmentvalueassumption(SUTVA)holds,onlymeanindependence mustbemaintained.

strategies to identify either the ATT or the ATC in situations where the ATE cannot
also be identified by conditioning.

The overall implication of this point is that researchers should learn all three
frameworks for approaching causal identification challenges. Graphs help immensely
inselectingconditioningsetswhenthetargetparameteristheATE.WhentheATEis
not identified by any feasible conditioning sets, the potential outcome model – either
as deployed in statistics or econometrics – can still guide the researcher to identifica-
tion strategies for narrower conditional average effects, most commonly the ATT or
the ATC. Directed graphs remain a useful tool in these situations, as they help to
organizeone’s thinking about the full systemofcausalrelationshipsthat arerelevant.

But, the identification strategy that is then selected to estimate either the ATT or
the ATC is likely to emerge from thinking through the possibilities from within the
potential outcome model.

## 4.4 Conditioning to Balance and Conditioning to Adjust

When presenting Pearl’s back-door criterion for determining a sufficient set of condi-

tioningvariables,wenotedthatforsomeapplicationsmorethanonesetofconditioning
variables is sufficient. In this section, we return to this point as a bridge to the fol-
lowing three chapters that present both matching and regression implementations of
conditioning. Although we will show that matching and regression can be considered
variants of each other, here we point to the different ways in which they are usually
invoked in applied research. Matching is most often considered a technique to bal-
ance the determinants of the causal variable, and regression is most often considered
a technique to adjust for other causes of the outcome.

To frame this discussion, consider first the origins of the balancing approach in
the randomized experiment tradition. Here, the most familiar approach is a random-
ized experiment that ensures that treatment status is unassociated with all observed
and unobservedvariables that determine the outcome (although only in expectation).

When treatment status is unassociated with an observed set of variables W, the data
are balanced with respect to W. More formally, the data are balanced if
Pr[W|D=1]=Pr[W|D=0], (4.8)
whichrequiresthattheprobabilitydistributionofW bethesamewithinthetreatment
and control groups.

NowconsiderthegraphpresentedinFigure4.10.Back-doorpathsarepresentfrom
D to Y, representedby D←S(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)X→Y, whereS is the complete setofvariables
that are direct causes of treatment assignment/selection, X is the complete set of
variables other than D that are direct causes of Y, and the bidirected edge between
S and X signifies that they are mutually caused by some set of common unobserved
causes.26
26Forthisexample,wecouldhavemotivatedthesamesetofconclusionswithothertypesofcausal
graphs.ThesamebasicconclusionswouldholdevenifX andSincludeseveralvariableswithinthem
in which some members of X cause D directly and some members of S cause Y directly. In other
S X
D Y
Figure4.10 Acausaldiagraminwhichsufficientconditioningcanbeperformedwith
respect to S or X.

Because neither S nor X is a collider, all back-door paths in the graph can be
blockedbyconditioningoneitherS orX (andwewrite“paths”becausetheremaybe
many back-door paths through the bidirected edge between S and X). Conditioning
on S is considered a balancing conditioning strategy, whereas conditioning on X is
considered an adjustment-for-other-causes conditioning strategy. If one observes and
then conditions on S, the variables in S and D are no longer associated within the
subgroups defined by the conditioning. The treatment and control groups are thereby
balanced with respect to the distribution of S. Alternatively, if one conditions on X,
the resulting subgroup differences in Y across D within X can be attributed to D
alone. Inthis case,the goalis notto balanceX but rather to partialoutits effects on
Y in order to isolate the net effect of D on Y.

The distinction between balancing and adjustment for other causes is somewhat
artificial (see Hansen 2008). For the graph in Figure 4.10, balancing X identifies the
causal effect. Thus, it is technically valid to say that one can identify a causal effect
by balancing a sufficient set of other causes of Y. Nonetheless, the graph in Figure
4.10 demonstrates why the distinction is important. The ultimate set of systematic
causesthatgeneratesthe relationshipbetweenS andX isunobserved,asitoftenisin
many applied research situations. Because one cannot condition on these unobserved
variables, one must condition on either S or X in order to identify the causal effect.

These two alternatives may be quite different in their practical implementation.27
Should one balance the determinants of a cause, or should one adjust for other
causesoftheoutcome?Theanswertothisquestionissituationspecific,anditdepends
on the quality of our knowledge and measurement of the determinants of D and Y.

words, all that we need to make the distinction between balancing and adjustment for other direct
causesistwosetsofvariablesthatarerelatedtoeachother,withatleastonevariableinonesetthat
causesD butnotY andatleastonevariableintheothersetthatcauses Y butnotD.

27Note also that the ingredients utilized to estimate the ATE (as well as the ATT and the ATC)
willdifferbasedontheparticularconditioningroutine,andthiswillallowalternative expressionsof
underlyingheterogeneity.IfSisobserved,thenconditionalaveragetreatmenteffectscanbecalculated
forthosewhoaresubjecttothecausefordifferentreasons,basedonthevaluesofSthatdetermineD.

IfX isobserved,thenconditionalaveragetreatmenteffectscanbecalculatedholdingothercausesof
Y atchosenvaluesofX.Eachofthesesetsofconditionalaveragetreatmenteffectshasitsownappeal,
with the relative appeal of each depending on the application. In the potential outcome tradition,
average treatment effects conditional on S would likely be of more interest than average treatment
effectsconditionalonX.Butforthosewhoareaccustomedtoworkingwithinanall-causeregression
tradition,thenaveragetreatments effects conditional onX mightbemoreappealing.

One answer is that the researcher should do both.28 Nonetheless, there is a specific
advantageofbalancingthatmaytipthescalesinitsfavorifbothstrategiesarefeasible:
Balancing diminishes the inferential problems that can be induced by data-driven
specification searches, as we will explain in Chapter 6.29
## 4.5 Conclusions

In this chapter, we have used the causal graphs introduced in Chapter 3 to explain

the rationale for conditioning estimators of causal effects, focusing on the back-door
criterion for selecting sufficient sets of conditioning variables that identify the ATE.

We then introduced models of treatment assignment and treatment selection from
statistics and econometrics that are used to assert similar claims about conditioning
estimators, focusing also on the ATT and ATC.

In the next three chapters, we present details and connections between the three
main types ofconditioning estimation strategiesutilized in the socialsciences:match-
ing, regression, and weighted regression. We show how they typically succeed when
selection is on the observables and fail when selection is on the unobservables. We lay
out the specific assumptions that allow for the identification of unconditional average
treatment effects, as well as the weaker assumptions that allow for the identification
of narrowerconditionalaveragetreatment effects, suchas the ATT and ATC. In later
chapters, we then present additional methods for identifying and estimating causal
effects when conditioning methods do not suffice because crucial variables on back-
door paths are unobserved.

## 4.6 Appendix to Chapter 4: The Back-Door and Adjustment Criteria, Descendants, and Colliders Under Magnification

In order to properly utilize the back-door criterion when evaluating alternative con-

ditioning sets, an analyst does not need to understand all details of all scenarios in
which its violation will prevent a conditioning estimator from generating consistent
and unbiased estimates of causal effects of interest. However, a deeper examination
of additionalscenariosprovides insightinto commonmethodologicalchallenges,while
also demonstrating the powerful contribution that graphical methods are likely to
make to social science research in the coming decades.

In this appendix, we offer additional examples where colliders and descendants
must be carefully considered in order to understand the fine points of why the back-
door criterion warrants causal inference. We show how Condition 2 of the back-door
28As we discuss in later chapters, many scholars have argued for conditioning on both S and X.

Robins,forexample,arguesforthisoptionasadoubleprotectionstrategythatofferstwochancesto
effectivelyblocktheback-door pathsbetween D andY (seeRobinsandRotnitzky2001).

29We phrase this guidance with “may” because it must be evaluated alongside another concern.

BalancingallvariablesthatdetermineD,includingthosethatdonotgenerateconfounding,isunnec-
essaryandinefficient.Asaresult,itmayrenderconditioninginfeasibleindatasetsofthesizetypically
availabletosocialscientists.

e e
c o
C O
D Y
Figure4.11 A causal graph with a confounded causal effect and where the variables
along the back-door path are viewed under magnification.

criterion, which appears only to prevent the analyst from inadvertently conditioning
onvariablesthat adjustawaythe causaleffectofinterest, alsoplaysa rolein blocking
hidden as-if back-door paths that also result from conditioning on endogenous vari-
ables.Weshowthatthisresultcanonlybeseenwhenendogenousvariablesareviewed
under magnification, so that it becomes clear that these variables are also colliders.

We conclude with an examination of the connections between Pearl’s original back-
doorcriterion,itsgeneralizationastheadjustmentcriterionofShpitser,VanderWeele,
and Robins (2010), and our blended alternative, which retains the targeted spirit and
inherent practicality of Pearl’s original back-door criterion while also incorporating
some of the insight furnished by the admirably broad adjustment criterion.

Like the appendix to Chapter 3, nothing in this appendix is necessary for under-
standing the next three chapters thatfollow.We offer it for curiousreaderswho crave
a deeper understanding of the back-door criterionand who wish to dive into the orig-
inal literature after reading this book. We also offer it to explain to the community of
causalgraphmethodologistswhywehavechosentheversionoftheback-doorcriterion
that we have.

The Back-Door Criterion Explained with Causal Graphs Viewed Under
Selective Magnification. The first step in fully considering why violations of the
back-door criterion prevent conditioning estimators from delivering consistent and
unbiasedestimatesistorepeatsomeofthematerialfromthemainbodyofthechapter,
after redrawing the causal graphs under magnification. As we introduced in Section
3.3.2 using Figure 3.7, under magnification the unobserved structural error terms of
the associated structural equations are brought into view. For Figure 4.11, we have
redrawnFigure 4.1 under what we will call “selective magnification.” In this case, we
magnify the nodes ofall variablesthat we might considerconditioning on,leaving the
errortermsonthe causalvariableandthe outcome variablehiddenasin the standard
representation for visual simplicity. Accordingly, Figure 4.11 shows two additional
causal effects, eC→C and eO→O, that were only implicit in Figure 4.1.

Now,reconsiderourexplanationoftheback-doorcriterionforthisgraph.Wewrote
earlierthatconditioningonC and/orOwouldidentifythecausaleffect.Asatransition
totheadditionalexamplesinthisappendix,wewillnowpresentthesameexplanation
considering how the inclusion of eC →C and eO→O in the graph does not change
this claim.

In the directed graph tradition, C is a “root” variable because it has no causes
other than those embedded in its structural error term. Root variables do not need
to be considered in any other way when viewed under magnification because their
structural error terms are nothing more than the source of the variation observed for
these variables. Accordingly, it is still the case that conditioning on C blocks the sole
back-door path D←C→O→Y because C is the middle variable of a fork of mutual
dependence that lies within the path. Because C is also not a descendant of D, it
satisfies the back-door criterion.

For O, an additional complication should be clear. Under magnification, it is
revealed that O is a collider variable because C→O is now accompanied by eO→O.

In general, all variables in a causal graph that are not root variables will appear
as colliders when viewed under magnification. We have urged caution when handling
colliders, and yet only now do we reveal that all variables such as O are, in fact, col-
liders as well. Accordingly, conditioning on O will induce an association between C
and eO. Fortunately, this conditioning does not invalidate the back-door criterion by
unblocking an already blocked back-door path, as we will now explain.

Recall our prior discussions of colliders in Sections 3.2.2 and 4.1.2. We have said
that for a blockedpath, A→C←B, where C is the collider, conditioning onC opens
upthispath.Wenowintroduceapieceofnotationtoconveythisresult:aconditioning
“button,” (cid:10), that can be deployed to show the genesis of a new induced association,
···(cid:10)···.30 Forexample,forthe blockedpathA→C←B, conditioningonC generates
a new association, A···(cid:10)···B, where the conditioning action itself, (cid:10), generates the
association between A and B. For our hypothetical college admissions example in
4.1.2,the notationrepresentsthe followingaction:Abuttonispushedfor“admissions
decisions,” and the population of applicants is then divided into those admitted and
those rejected. Within both groups, A and B are now associated, as shown in Figure
4.2. The only way to eliminate the induced association is to undo the conditioning
that generates it (i.e., release the conditioning button).

Return to Figure 4.11 so that we can demonstrate this new notation when consid-
ering the conclusions suggested by an evaluation of the back-door criterion. Suppose
again that O is our candidate conditioning variable, and we know that conditioning
on O will block the back-door path D ←C →O →Y. When seen under magnifi-
cation, it should be clear that now conditioning on O also generates a new associ-
ation, C···(cid:10)···eO. In fact, conditioning on O also generates a second association,
eC···(cid:10)···eO.31 Pearl (2009:339) explains, for examples such as this one, that these
induced associations create two as-if back-door paths:
1. D←C···(cid:10)···eO→O→Y and
2. D←C←eC···(cid:10)···eO→O→Y.

30Pearl and other authors often use alternative notation to convey the same associations, most
commonlyA—B.Wepreferourmoreactive“button,”whichcanalsobedirectlyextendedtoactual
operator status, asin···(cid:8)(.)···. Ifone wanted toshow conditioning onmorethanone variable,we
wouldhave···(cid:8)(C,O)···,etc.

31Conditioningonacollider,oradescendantofacollider,inducesassociationsbetweenallancestors
ofthecollideronseparatedirectedpaths thatreachthecollider.

eC eO
C O
D Y
Figure4.12 A diagram where the causal effect of D on Y is not confounded and
where the observed variable O on the back-door path is a descendant of both
D and Y.

Fortunately,bothoftheseas-ifback-doorpathsarealsoblockedwhenOisconditioned
on because O is the middle variable in a chain of mediation, eO→O→Y, for both
of them. Thus, O satisfies the back-doorcriterionbecause O is not a descendant of D
and because conditioning on O eliminates all back-door associations between D and
Y, including two associations created by as-if back-door paths that are only revealed
under magnification.

Ofcourse,wealreadyknewthatOsatisfiedtheback-doorcriterionfromourconsid-
erationofFigure4.1.Viewingthe graphunderselectivemagnificationhasforcedusto
reckonwith the unobserved structural error terms, and little insight has been gained.

We will now consider two additional examples where consideration of the structural
errorterms leadsto additionalinsightthatwill convincethe readerofhowsimple and
effective the back-door criterion is.

Consider Figure 4.12, where again we have four variables, and where all variables
but D and Y are displayed under magnification. The only back-door path between
D and Y, which is D←C→O←Y, is blocked by the collider O. Although it may
seem awkward to refer to D←C→O←Y as a back-door path between D and Y
(because it does not end with →Y), it satisfies our definition because it is a path
betweentwo causallyorderedvariablesD andY thatbegins with D←. As a result, it
isstillaback-doorpath,eventhoughitdoesnotterminatewith →Y (unlikeall other
back-doorpaths displayed so far in our examples).32 Because the sole back-door path
between D and Y does not generate a noncausal association between D and Y, there
is no need to adjust for any variables in order to generate a consistent and unbiased
estimate of the causal effect of D on Y.

In fact, all that one can do is make the situation worse. Suppose that an analyst
believesmistakenlythatthepathD←C→O←Y isanunblockedback-doorpaththat
must be blocked in order to generate a consistent and unbiased estimate of the effect
of D on Y. Because C is unobserved, suppose that the analyst decides to condition
onO instead, under the rationalethat it is the only observedvariable that lies on the
back-door path.

32We could bring this graph in line with prior ones by replacing Y →O with O←U→Y. The
explanationwouldthenchangeabitbecauseOwouldnolongerbeadescendantofD viaadirected
path,buttheanalysiswithrespecttoCondition1oftheback-doorcriterionwouldbethesame.

The variable O violates both conditions of the back-door criterion. Consider Con-
dition 1 first. Because O is a collider variable, conditioning on O generates many new
associations,includingC···(cid:10)···Y,eC···(cid:10)···Y,C···(cid:10)···eO,andeO···(cid:10)···Y.These
induced associations generate three as-if back-door paths:
1. D←C···(cid:10)···Y,
2. D←C←eC···(cid:10)···Y, and
3. D←C···(cid:10)···eO···(cid:10)···Y.

Because C is unobserved, these as-if back-door paths remain unblocked after condi-
tioning on O, and therefore O does not satisfy Condition 1 of the back-doorcriterion.

Now consider Condition 2, and notice that O lies on a directed path, D→Y →O,
that begins at D and reaches Y. As we noted earlier, we chose to specify Condition 2
of the back-door criterion with the words “reaches the outcome variable” rather than
“ends at at the outcome variable” in order to capture cases such as this one. In this
case, O lies on the directed path that represents the causal effect of interest, even
though O does notmediate the casualeffect itself. The intuition ofCondition 2 ofthe
back-doorcriterionshouldnonetheless still be clear. Becausethe causaleffect ofD on
Y isfullyembeddedwithinthevariationinO,adjustingforO wouldexplainawaythe
causal effect itself.33
Overall,then, conditioning on O in this graph would make the situation consider-
ablyworse.Nounblockedback-doorpathsneededto be blockedinthe firstplace,and
conditioning on O would generate as-if back-door paths that induce new noncausal
associations between D and Y while at the same time robbing the causal effect of
(possibly all) of its magnitude.

Tonow transitionto amore complicatedcase,pause to considerhowourlanguage
in this appendix differs from the language used in the main body of the chapter. Up
until now, we have expressed similar results to those for Figure 4.12 on the perils
of conditioning on colliders using more brief language. For this graph, the simpler
language would be the following:
ConditioningonthecollidervariableO unblocksthealreadyblockedback-
door path, D←C→O←Y.

This explanatorysyntax is concise andcorrect.Evenso,it should now be clear that a
more laborious way to understand this result is the following:
ConditioningonthevariableOthatisacolliderontheback-doorpathD←
C → O ← Y creates additional as-if back-door paths such as
D←C···(cid:10)···Y, D←C←eC···(cid:10)···Y, and D←C···(cid:10)···eO···(cid:10)···Y.

These as-if back-door paths are unblocked when conditioning on O.

33Inaninfinitesample,whereinonecouldstratifythe dataonallvalues ofO,D andY wouldbe
independent within the strata of O. In a finite sample, possibly necessitating the use of a different
type of conditioning estimator, the conditional association between D and Y might not equal zero
butwouldstillnotbeaconsistentestimateofthecausaleffect.

eC eO
C O
M
eN
D Y
eM
N
B U
eB eU
Figure4.13 A graph where the effect of D on Y is not identified by conditioning on
O and B because O is a descendant of D.

Forthegraphsconsideredinthemainbodyofthischapter,thismoretorturedlanguage
would not have been helpful and therefore was not used. However, for this particular
graph, the more tortured language may offer a clearer explanation. The brief expla-
nation does not make clear why conditioning on O generates a back-door association
by unblocking D←C →O←Y, given that this back-door path does not end with
→Y. The more tortured language, which uses the conditioning button, does provide
the proper imagery because the as-if back-door path, D←C···(cid:10)···Y, does not end
with ←Y.

For an additional example, which draws many of these issues together, consider
Figure 4.13. This graph is a redrawn version Figure 4.7, but now with all variables
other than D and Y displayed under magnification. As noted earlier for Figure 4.7,
there are three back-door paths from D to Y:
1. D←C→O→Y,
2. D←C→O←M→Y, and
3. D←B→U→Y.

Again, suppose that one decides to condition on both O and B. Using the condi-
tioning button to reveal all of the associations generated by the conditioning action
itself wouldgeneratemany new as-ifback-doorpaths. Considerjust two ofthese. The
inducedassociationC···(cid:10)···M createstheas-ifback-doorpathD←C···(cid:10)···M→Y
that remains unblocked after conditioning on O and B. This as-if back-door path is
similar to those considered for Figure 4.12. But now consider how the induced associ-
ationD···(cid:10)···eM createsthe as-ifback-doorpathD···(cid:10)···eM→M→Y. This path
is also unblocked after conditioning on O and B. But, most importantly, this as-if
back-door path only comes to the foreground when the causal graph is viewed under
magnification. Except under magnification, it is all too easy to fail to recognize that
M is a collider andthat conditioning ona descendantofM will induce anassociation
between D and eM. For all but the most experienced causal graph practitioners, this
as-if back-door path would be hidden by the standard representation of the graph.

As a result, the conditioning set of O and B does not satisfy Conditions 1(a),
(b), and (c) of the back-door criterion. As we used this graph to show in the main
body of the chapter, this graph also does not satisfy Condition 2 of the back-door
criterion either. This result does not need to be explained in any different fashion
whenthe graphis viewedunder selectivemagnification.Overall,the adjustedeffect of
D on Y, which results from conditioning on O and B, would steal some of the total
effect of D on Y. Yet, as we show here, the conditioning action also generates new
back-door associations, one through the unobserved mediating variable M. This last
as-if back-door path is completely hidden from view in the standard representation
of a causal graph. Fortunately, all such hidden as-if back-door paths that emerge
underconditioningwillnevercreepintoanempiricalanalysisaslongasthe back-door
criterion is properly evaluated.

Andthisisthekeypointofthislastexample:Condition2oftheback-doorcriterion
must be heeded for two reasons. First, as was also presented in the main body of the
chapter,conditioningondescendantsofthecausethatlieon(ordescendfrom)directed
paths that begin at D and that reach Y will always mistakenly adjust away some of
thecausaleffectthe analystisinterestedinestimating.Second,aswehavenowshown
in this appendix, conditioning on the descendants of the cause (such as O) that are
also descendants of unobserved colliders that are are themselves descendants of the
cause (such as M) will always generate unblocked back-door associations that spoil
the analysis. Fortunately, if one uses to the back-door criterion to select conditioning
sets, then the threat of such hidden unblockedback-doorassociationscan be avoided.

The Back-Door and Adjustment Criteria Considered.As we noted earlier,
ourversionoftheback-doorcriterionincorporatesinsightgainedfromthemorerecent
developmentoftheadjustment criterion byShpitseretal.(2010).Figure4.14presents
a graph that reveals the differences between Pearl’s original back-door criterion and
the morerecentgeneralizationthatis the adjustmentcriterion.Wewilluse this graph
to explain why we havemodified Pearl’soriginalback-doorcriterionto a small degree
but also why we have not adopted the adjustment criterion as a whole.

As we have specifiedit in the mainbody of this chapter,the back-doorcriterionis
evaluatedinthefollowingtwosteps.Thefirststepistowritedowntheback-doorpaths
from D to Y, determine which ones are unblocked, andthen searchfor a conditioning
set that will block all unblocked back-door paths. For Figure 4.14, the two back-door
paths are
1. D←A→B←C→Y and
2. D←E→Y.

Path 1 is already blocked by the collider B, and so only path 2 must be blocked by
conditioning. Here, the solution is simple: Condition on E because it is the middle
variable of a fork of mutual dependence.

The second step is to verify that the variables in the candidate conditioning set
are not descendants of the causal variable that lie along, or descend from, all directed
paths from the causal variable that reach the outcome variable. For Figure 4.14, it
A B C
E
M
N
D Y
O
Q
P
R S T
Figure4.14 A directed graphthat reveals the differences between the back-doorcri-
terion and the adjustment criterion.

is easy to see that E is a root variable and as such is not a descendant of any other
variable in the graph.

However,to understandthe differencesbetweenthe back-doorcriterioninits orig-
inal form and the adjustment criterion, we need to consider this step in more detail.

For more elaborate causal graphs, in order to evaluate Condition 2 of the back-door
criteriononeneedstoascendthefamilytreebylooking“upstream”throughthearrows
thatpointtoeachcandidateconditioningvariable(i.e.,fromtheparent,tothegrand-
parent,to the greatgrandparent,andso on)to determine whether the causalvariable
is a direct ancestor of any of the candidate conditioning variables. If the causal vari-
able is not found to be an ancestor of any of the candidate conditioning variables
in the set under consideration, then by definition none of the candidate conditioning
variableslies onordescends fromdirectedpaths that beginatthe causalvariableand
that reach the outcome variable. In this case, a conditioning estimator that uses the
variables under consideration will generate consistent and unbiased estimates of the
causal effect of interest.

Ifthe causalvariableisdiscoveredto be anancestorofanyofthe candidate condi-
tioning variables in the set under consideration, then for our versionof the back-door
criterion(which incorporatesinsightfrom the adjustment criterion), one has to deter-
mine whether the directed paths from the causal variable that establish the descent
of the conditioning variable(s) also reach the outcome variable. If not, then one can
still condition on any such variables and generate consistent and unbiased estimates.

If, instead, any of the candidate conditioning variables are descendants of the causal
variable and lie on or descend from directed paths that begin at the causal variable
and reach the outcome variable, then the conditioning set will block or adjust away
someofthecausaleffect.Inthiscase,the conditioningsetwillnotgenerateconsistent
and unbiased estimates of the causal effect of interest.

To now transition to a parallel considerationof the adjustment criterion, and why
we have not adopted it in whole, return to the case of Figure 4.14 and consider how
the back-doorcriterionmightbe utilized inpractice by anexperiencedanalyst.As we
notedaboveinthisappendix,conditioningonE alonesatisfiestheback-doorcriterion.

Notice,however,that,inadditiontoE,onecouldalsoconditiononA,onC,onAand
B, on B and C, or on A, B, and C. The back-door criterion does not rule out these
possibilities, but it does not encourage the analyst to consider A and C as members
ofthe candidateconditioning setbecausethe back-doorpathonwhichthese variables
lie is already blocked in the absence of any conditioning by B. Instead, the back-door
criterion guides the analystto the essentialinformation: (1) path 1 is already blocked
by B and can be left alone; (2) path 2 must be blocked by conditioning on E.

Nonetheless, an experienced analyst might reason that, although one should not
condition only on B, one could condition on B as long as either A or C is also condi-
tionedon. The experiencedanalystmightthenchooseto offer twoestimates, onethat
conditions only on E and one that conditions on B and C as well (perhaps because a
fair critic has a theory says that the B←C in Figure 4.14 should instead be B→C).

The experienced analystmight reachthis positioneven thoughshe regardscondition-
ing on B and C as unnecessary and inefficient, given that she truly does believe that
her theoretical assumptions represented by the original graph are beyond reproach.

Nevertheless, she might reason that it is prudent to show a fair critic that even if his
alternativeassumptions arecorrect,the mainresults ofthe ensuing empiricalanalysis
remain the same.

Once one begins to allow supplementary but unnecessary conditioning variables
intotheconditioningset,aquestionarisesastowhethertheback-doorcriterioncovers
all cases. This is the inspiration for the adjustment criterion, developed by Shpitser
etal.(2010).Itisdesignedtoallowthe analysttoidentify allpermissibleconditioning
sets, including those that include unnecessary andredundant conditioning,as we now
explain.

Theadjustmentcriterionalsohastwosteps.Forthefirststep,theanalystconsiders
all paths in the graph that begin at the causal variable and then categorizesall paths
into(1)“causalpaths,”whicharedefinedasalldirectedpathsfromthecausalvariable
totheoutcomevariable,and(2)“noncausalpaths,”whicharedefinedasallpathsfrom
the causal variable that are not causal paths. For Figure 4.14, one would enumerate
the following paths, categorizing them as follows:
1. D←A→B←C→D (noncausal),
2. D←E→Y (noncausal),
3. D→M→Y (causal),
4. D→N→Y (causal),
5. D→N→O (noncausal),
6. D→P (noncausal),
7. D→Q←Y (noncausal),
8. D→R←S→T ←Y (noncausal).

Notice that paths 1 and 2 are back-door paths for the back-door criterion but, for
the adjustment criterion, are classified as members of the more encompassing set of
noncausal paths. The first step of the adjustment criterion then requires that the
analyst search for variables that, when conditioned on, will ensure that all noncausal
paths betweenD andY areblocked. This is analogousto the back-doorcriterion,but
nowallnoncausalpaths,notjustback-doorpaths,mustbeconsidered.ForFigure4.14,
thispartofthefirststeprequiresthe analysttosearchforallpermissibleconditioning
setsthatwillblockthenoncausalpaths1,2,5,6,7,and8.ForthecaseofFigure4.14,
moresetsthanwewishtoenumeratewouldbeselected.Inbrief,allsetswouldinclude
E and exclude Q. Yet, these sets would include many combinations of additional
unnecessary conditioning variables, including appropriate combinations of A, B, C,
N, O, P, R, S, and T, such as the maximal blocking set {A,B,C,E,N,O,P,R,S,T}.

For the second step of the adjustment criterion, one then implements the same
secondstepastheversionoftheback-doorcriterionwehavespecifiedinthemainbody
ofthe chapter.For Figure4.14,this steprequiresthat the candidateconditioning sets
notinclude the variablesM,N,orO. PresumablyM wouldnothavebeenconsidered
as a conditioning variable in the first place because it is not a variable that lies on
any of the noncausal paths that the analyst is attempting to block. Nonetheless, the
analystmustalsostrikeallconditioningsetsthatincludeN andO,andthisconclusion
has to be discerned from the graph, not the list of the paths that does not reveal full
patterns of descent. (This is also the case for the back-door criterion.)
Theadvantageoftheadjustmentcriteriaisthatitwillrevealallpermissiblecondi-
tioning sets, such as the maximal permissible conditioning set {A,B,C,E,P,R,S,T},
assuming that the analyst devotes the necessary energy to delineating all patterns of
permissible conditioning. The disadvantage is that, for graphs such as the one in Fig-
ure4.14,the adjustmentcriterionis laboriousandis likelyto leadone to conditionon
more variables than is necessary to identify the causal effect.

We have therefore chosen to stick with the back-door criterion in the main body
of the chapter, with only one substantial modification to Pearl’s originalspecification
in deference to the completeness of the adjustment criterion. As we noted earlier in
our footnote on Condition 2 of our version of the back-door criterion, Pearl’s original
back-door criterion requires more simply (but overly strongly) that no variables in
the conditioning set Z can be descendants of the causal variable. For our version of
the back-door criterion, we weaken Pearl’s original no-descendants condition to allow
conditioning on variables, such as P in Figure 4.14, that are descendants of the cause
D but that do not lie on or descend from directed paths that begin at D and reach
Y. We doubt an analyst would think to condition on P when evaluating the back-
door criterion for this graph (because the back-door criterion focuses attention more
narrowlyonback-doorpaths,ratherthanallnoncausalpaths).Still,this modification
oftheback-doorcriterionallowsittoidentifymoreofthepermissibleconditioningsets
thatareidentifiedbythemorelaboriousbutadmirablycompleteadjustmentcriterion.

# Chapter 5

# Matching Estimators of Causal Effects

The rise of the counterfactual model to prominence has increased the popularity of

data analysisroutines that are most clearly useful for estimating the effects of causes.

The matching estimators that we will review andexplain in this chapter1 are perhaps
thebestexampleofaclassictechniquethathasreemergedinthepastthreedecadesas
a promising procedure for estimating causaleffects.2 Matching represents an intuitive
method for addressing causal questions, primarily because it pushes the analyst to
confront the process of causal exposure as well as the limitations of available data.

Accordingly,amongsocialscientistswhoadoptacounterfactualperspective,matching
methodsarefastbecominganindispensabletechniqueforprosecutingcausalquestions,
even though they usually prove to be the beginning rather than the end of causal
analysis on any particular topic.

We begin with a brief discussion of the past use of matching methods. Then, we
present the fundamental concepts underlying matching, including stratificationof the
data, weighting to achieve balance, and propensity scores. Thereafter, we discuss how
matching isusually undertakeninpractice,including anoverviewofvariousmatching
algorithms.

Inthe courseofpresentation,wewillofferfourhypotheticalexamplesthatdemon-
stratesomeoftheessentialclaimsofthematchingliterature,progressingfromidealized
examples of stratification and weighting to the implementation of alternative match-
ingalgorithmsonsimulateddataforwhich thetreatmenteffects ofinterestareknown
by construction. As we offer these examples, we add real-world complexity in order
to demonstrate how such complexity can overwhelm the power of the techniques. In
1This chapter has its origins in Morgan and Harding (2006), and David Harding’s contributions
aregratefullyacknowledged.

2Matching techniques can be motivated as estimators without invoking causality. Just as with
regressionmodeling,whichwediscussindetailinChapters6and7,matchingcanbeusedtoadjust
thedatainsearchofameaningfuldescriptivefittothedatainhand.Giventhenatureofthisbook,
wewillfocusonmatchingasanestimatorofcausaleffects. Wewill,however,discussthedescriptive
motivationforregressionestimatorsinChapter 6.

140
the nexttwochapters,we buildonthe sameexamples whenpresentingregressionand
weightedregressionestimators.TheoverallgoalsofChapters5,6,and7aretoexplain
the interconnections between the most prominent techniques for implementing condi-
tioning estimators that are justified by the back-door criterion presented in Chapter
4, but that arealsotypically motivated inthe socialscience literature by assumptions
of ignorability of treatment assignment or selection on the observables.

## 5.1 Origins of and Motivations for Matching

Matchingtechniqueshaveoriginsinexperimentalworkfromthe firsthalfofthe twen-

tieth century. Relatively sophisticated discussions of matching as a research design
can be found in early methodological texts in the social sciences (e.g., Greenwood
1945) and also in attempts to adjudicate between competing explanatory accounts in
applieddemography(Freedman andHawley 1949).This early workcontinued in soci-
ology (e.g., Althauser and Rubin 1970, 1971; Yinger, Ikeda, and Laycock 1967) right
up to the key foundational literature in statistics (Rubin 1973a, 1973b, 1976, 1977,
1979, 1980a) that provided the conceptual foundation for the new wave of matching
techniques that we will present in this chapter.

Intheearly1980s,matchingtechniques,asweconceiveofthemnow,wereadvanced
in a set of papers by Rosenbaum and Rubin (1983a, 1984, 1985a, 1985b) that offered
solutions to a variety of practical problems that had limited matching techniques to
very simple applications in the past.3 Variants of these new techniques found some
use immediately in sociology (Berk and Newton 1985; Berk, Newton, and Berk 1986;
Hoffer,Greeley,and Coleman1985),continuing with work by Smith (1997).Since the
late 1990s, economists and political scientists have contributed to the development
of new matching techniques (e.g., Heckman et al. 1999; Heckman, Ichimura, Smith,
andTodd 1998;Heckman,Ichimura,andTodd1997,1998in economicsandHo, Imai,
King, and Stuart 2007 and Diamond and Sekhon 2013in political science). Given the
growth of this literature, and the applications that are accumulating, we expect that
matching will complement other types of modeling in the social sciences with greater
frequency in the future.

In the methodological literature, matching is usually introduced in one of two
ways: (1) as a method to form quasi-experimental contrasts by sampling comparable
treatment and control cases from among two larger pools of such cases or (2) as a
nonparametric method of adjustment for treatment assignment patterns when it is
feared that ostensibly simple parametric regression estimators cannot be trusted.

For the first motivation, the archetypical example is an observational biomedical
studyinwhicharesearcheriscalledontoassesswhatcanbelearnedaboutaparticular
treatment.Theinvestigatorisgivenaccesstotwosetsofdata,oneforindividualswho
have been treated and one for individuals who have not. Each dataset includes a
measurement of current symptoms, Y, and a set of characteristicsof individuals, as a
vector of variables X, that are drawn from demographic profiles and health histories.

3See Rubin (2006) for a compendium. See Guo and Fraser (2010), Sekhon (2009), and Stuart
(2010)forreviewsthatconnecttheearlyliteraturetothecurrentstateofpractice,butwithdifferent
pointsofemphasisthanweofferinthischapter.

Typically, the treatment cases are not drawn from a population by means of any
known sampling scheme. Instead, they emerge as a result of the distribution of initial
symptoms, patterns of access to the health clinic, and then decisions to take the
treatment. The control cases, however, may represent a subsample of health histories
from some known dataset. Often, the treatment is scarce, and the control dataset is
much larger than the treatment dataset.

Inthisscenario,matchingisamethodofstrategicsubsamplingfromamongtreated
and control cases. The investigator selects a nontreated control case for each treated
casebasedonthecharacteristicsobservedasxi.Alltreatedcasesandmatchedcontrol
cases are retained, and all nonmatched control cases are discarded. Differences in
the observed yi are then calculated for treated and matched cases, with the average
difference serving as the treatment effect estimate for the group of individuals given
the treatment.4
The second motivation has no archetypical substantive example, as it is similar
in form to any attempt to use regression to estimate causal effects with survey data.

Suppose, for a general example, that an investigator is interested in the causal effect
of an observed dummy variable, D, on an observed outcome, Y. For this example,
it is assumed that a simple bivariate regression, Y =α+δD+ε, will yield an esti-
mated coefficient δˆthat is an inconsistent and biased estimate of the causal effect of
interestbecausethecausalvariableDisassociatedwithvariablesincludedintheerror
term,ε.Foraparticularexample,ifDisthereceiptofacollegedegreeandY isamea-
sureofeconomicsuccess,thentheestimateofinterestisthecausaleffectofobtaininga
college degree on subsequent economic success. However, family backgroundvariables
are present in ε that are correlated with D, and this relationship produces omitted-
variable bias for a college-degree coefficient estimated from a bivariate ordinary least
squares (OLS) regressionof Y on D.

In comparison with the biomedical example just presented, this motivation differs
intwoways:(1)inmostapplicationsofthistype,thedatarepresentarandomsample
from a well-defined population and (2) the common practice in the applied literature
is to use regression to estimate effects. For the education example, a set of family
backgroundvariables in X is assumedto predictboth D andY. The standardregres-
sion solution is to estimate an expanded regression equation: Y =α+δD+Xβ+ε∗.

With this strategy (which we will discuss in detail in the next chapter), the goal is to
estimate simultaneously the causal effects of X and D on the outcome, Y.

In contrast, a matching estimator nonparametrically balances the variables in X
acrossDsolelyintheserviceofobtainingthebestpossibleestimateofthecausaleffect
of D on Y. The most popular technique is to estimate the probability of D for each
individualiasafunctionofX andthentoselectforfurtheranalysisonlymatchedsets
oftreatmentandcontrolcasesthatcontainindividualswithequivalentvaluesforthese
predicted probabilities. This procedure results in a subsampling of cases, comparable
with the matching procedure described for the biomedical example, but for a single
4Avirtueofmatching, as developed inthistradition,iscost-effectiveness forprospectivestudies.

Ifthegoalofastudyistomeasuretheevolutionofacausaleffectovertimebymeasuringsymptoms
at several points in the future, then discarding nontreated cases unlike any treated cases can cut
expenses without substantially affecting the quality of causal inferences that a study can yield. See
StuartandIalongo(2010).

dimensionthatis a function ofthe variablesinX. Inessence, the matching procedure
throws away information from the joint distribution of X and Y that is unrelated to
variationinthetreatmentvariableDuntiltheremainingdistributionofX isequivalent
for both the treatment and control cases.When this equivalence is achieved, the data
aresaidtobebalancedwithrespecttoX.5 Underspecificassumptions,theremaining
differences inthe observedoutcome betweenthe treatmentandmatchedcontrolcases
can then be regarded as attributable solely to the effect of the treatment.6
Atmostpoints inthe remainderofthis chapter,wewilladoptthis secondscenario
because research designs in which data are drawn from random-sample surveys are
much more common in the social sciences.7 Thus, we will assume that the data in
hand were generated by a relatively large random-sample survey (in some cases an
infinite sample to entirely remove sampling error from consideration), in which the
proportion and pattern of individuals who are exposed to the cause are fixed in the
population by whatever process generates causal exposure.

## 5.2 Matching as Conditioning via Stratification

Inthissectionweintroducematchingestimatorsinidealizedresearchconditions,draw-

ing connections with the broad perspective on conditioning introduced in Chapter 4.

Thereafter, we proceed to a discussion of matching in more realistic scenarios, which
iswhere we explainthe developmentsofmatching techniquesthat havebeenachieved
in the past three decades.

5.2.1 Estimating Causal Effects by Stratification
Supposethatthosewhotakethetreatmentandthosewhodonotareverymuchunlike
eachother,andyetthe waysinwhichthey differarecapturedexhaustivelybya setof
observed treatment assignment/selection variables S. For the language we will adopt
in this chapter, knowledge and observation of S allow for a “perfect stratification”of
the data. By “perfect,”we mean precisely that individuals within groups defined by
values on the variables in S are entirely indistinguishable from each other in all ways
exceptfor (1) observedtreatment status and (2) differences in the potential outcomes
that are independent of treatment status. Under such a perfect stratification of the
data, even though we would not be able to assert Assumptions 1 and 2 in Equations
5As we will discuss later, in many applications balance can be hard to achieve without some
subsampling from among the treatment cases. In this case, the causal parameter that is identified
is narrower even than the ATT (and is usually a type of marginal treatment effect pinned to the
commonsupportoftreatment andcontrolcases).

6A third motivation, which is due to Ho et al. (2007; see also Iacus and King 2012), has now
emerged. Matching can be used as a data preprocessor that prepares a dataset for further causal
modeling with a parametric model. We discuss this perspective along with others when we intro-
duceparticularmatchingtechniques thatarecurrentlyinuseintheappliedliterature,includingthe
“coarsenedexactmatching”ofIacus, King,andPorro(2011, 2012a).

7SeeourearlierdiscussioninSection1.4ofthisrandom-samplesetup.

(2.15)and(2.16),wewouldbeabletoassertconditionalvariantsofthoseassumptions:
Assumption 1-S: E[Y1|D=1,S]=E[Y1|D=0,S], (5.1)
Assumption 2-S: E[Y0|D=1,S]=E[Y0|D=0,S]. (5.2)
These assumptions would suffice to enable consistent and unbiased estimation of the
average treatment effect (ATE) because the treatment can be considered randomly
assigned within groups defined by values on the variables in S.

Wheninthissituation,researchersoftenassertthatthenaiveestimatorinEquation
(2.9) is subject to bias (either generic omitted-variable bias or individually generated
selection bias). But, because a perfect stratification of the data can be formulated,
treatment assignment is ignorable – see the earlier discussion of Equation (4.3) – or
treatment selection is on the observable variables only – see the earlier discussion of
Equation(4.7). Thisis abitimprecise,however,becauseAssumptions 1-Sand2-Sare
implied by ignorabilityandselectiononthe observables(assuming S is observed).For
ignorability and selection on the observables to hold more generally, the full distribu-
tionsofY1 andY0 (andanyfunctions ofthem)mustbe independentofD conditional
on S; see the discussion of Equation (4.4). Thus Assumptions 1-S and 2-S are weaker
than assumptions of ignorability and selection on the observables, but they are suffi-
cient to identify the three averagecausal effects of primary interest.

RecallthedirectedgraphinFigure4.8(b),whereS liesontheonlyback-doorpath
fromD to Y. Asdiscussedthere,conditioningonS allowsforconsistentandunbiased
estimation of the unconditional ATE, as well as the average treatment effect for the
treated (ATT) and the average treatment effect for the controls (ATC). Although we
gave a conceptual discussion in Chapter 4 of why conditioning works in this scenario,
we will now explain more specifically with a demonstration. First note why every-
thing works out so cleanly when a set of perfect stratifying variables is available. If
Assumption 1-S is valid, then
E[δ|D=0,S]=E[Y1−Y0|D=0,S]
=E[Y1|D=0,S]−E[Y0|D=0,S]
(5.3)
=E[Y1|D=1,S]−E[Y0|D=0,S]
=E[Y|D=1,S]−E[Y|D=0,S].

If Assumption 2-S is valid, then
E[δ|D=1,S]=E[Y1−Y0|D=1,S]
=E[Y1|D=1,S]−E[Y0|D=1,S]
(5.4)
=E[Y1|D=1,S]−E[Y0|D=0,S]
=E[Y|D=1,S]−E[Y|D=0,S].

ThelastlineofEquation(5.3)isidenticaltothelastlineofEquation(5.4),andneither
lineincludescounterfactualconditionalexpectations.Accordingly,onecanconsistently
estimate the difference in the last line of Equation (5.3) and the last line of Equation
(5.4) for each value of S. To then form consistent estimates of alternative average
treatment effects, one simply averagesthe stratified estimates over the distribution of
S, as we show in the following demonstration.

Matching Demonstration 1
Consider a completely hypothetical example in which Assumptions 1 and 2 in Equa-
tions(2.15)and(2.16)cannotbeassertedbecausepositiveselectionensuresthatthose
whoareobservedinthetreatmentgrouparemorelikelytobenefitfromthetreatment
than those who are not. But assume that a three-categoryperfect stratifying variable
S is available that allows one to assert Assumptions 1-S and 2-S in Equations (5.1)
and(5.2). Moreover,suppose for simplicity of expositionthat our sample is infinite so
that sampling error is zero. In this case, we can assume that the sample moments in
our data equal the population moments (i.e., EN[yi|di=1]=E[Y|D=1] and so on).

If it is helpful, think of Y as a measure of an individual’s economic success at age
40,Dasanindicatorofreceiptofacollegedegree,andS asamixedfamily-background
and preparedness-for-collegevariable that completely accounts for the pattern of self-
selectionintocollegethatisrelevantforlifetimeeconomicsuccess.Note,however,that
no one has ever discoveredsuch a variable as S for this particular causal effect.

Suppose that, for our infinite sample, the sample mean of the outcome for those
observedin the treatment groupis 10.2, whereas the sample mean of the outcome for
those observed in the control group is 4.4. In other words, we have data that yield
EN[yi|di=1]=10.2 and EN[yi|di=0]=4.4, and for which the naive estimator would
yield a value of 5.8 (i.e., 10.2−4.4).

Consider, now, an underlying set of potential outcome variables and treatment
assignmentpatterns that could give rise to a naive estimate of 5.8. Table 5.1 presents
the joint probability distribution of the treatment variable D and the stratifying vari-
able S in its first panel as well as expectations, conditional on S, of the potential
outcomes under the treatment and control states. The joint distribution in the first
panel shows that individuals with S equal to 1 are more likely to be observed in the
control group, individuals with S equal to 2 are equally likely to be observed in the
control group and the treatment group, and individuals with S equal to 3 are more
likely to be observed in the treatment group.

As shown in the second panel of Table 5.1, the average potential outcomes condi-
tional on S and D imply that the average causal effect is 2 for those with S equal to
1 or S equal to 2, but 4 for those with S equal to 3 (see the last column). Moreover,
as shown in the last row of the table, where the potential outcomes are averagedover
the within-D distributionofS,E[Y|D=0]=4.4andE[Y|D=1]=10.2,matching the
initial setup of the example based on a naive estimate of 5.8 from an infinite sample.

Table 5.2 shows what can be calculated from the data, assuming that S offers a
perfect stratification of the data. The first panel presents the sample expectations of
the observedoutcome variable conditionalon D andS. The secondpanel of Table 5.2
presentscorrespondingsample estimatesofthe conditionalprobabilitiesofS givenD.

Theexistenceofaperfectstratification(andthesupposedavailabilityofdatafrom
an infinite sample) ensures that the estimated conditional expectations in the first
panel of Table 5.2 equal the population-level conditional expectations of the second
panel of Table 5.1. When stratifying by S, the average observed outcome for those
in the control/treatment group with a particular value of S is equal to the average
potential outcome under the control/treatmentstate for those with a particular value
Table 5.1 The Joint Probability Distribution and Conditional Population
Expectations for Matching Demonstration 1
Joint probability distribution of S and D
D=0 D=1
S=1 Pr[S=1,D=0]=.36 Pr[S=1,D=1]=.08 Pr[S=1]=.44
S=2 Pr[S=2,D=0]=.12 Pr[S=2,D=1]=.12 Pr[S=2]=.24
S=3 Pr[S=3,D=0]=.12 Pr[S=3,D=1]=.2 Pr[S=3]=.32
Pr[D=0]=.6 Pr[D=1]=.4
Potential outcomes
Underthecontrol state Underthetreatment state
S=1 E[Y0|S=1]=2 E[Y1|S=1]=4 E[Y1−Y0|S=1]=2
S=2 E[Y0|S=2]=6 E[Y1|S=2]=8 E[Y1−Y0|S=2]=2
S=3 E[Y0|S=3]=10 E[Y1|S=3]=14 E[Y1−Y0|S=3]=4
E[Y0|D=0] E[Y1|D=1]
=.36(2)+.12(6) =.08(4)+.12(8)
.6 .6 .4 .4
+.12(10) +.2(14)
.6 .4
=4.4 =10.2
Table 5.2 Estimated Conditional Expectations and Probabilities
for Matching Demonstration 1
Estimated mean observed outcome conditional on si and di
Control group Treatment group
si=1 EN[y i|s i=1,d i=0]=2 EN[y i|s i=1,d i=1]=4
si=2 EN[y i|s i=2,d i=0]=6 EN[y i|s i=2,d i=1]=8
si=3 EN[y i|s i=3,d i=0]=10 EN[y i|s i=3,d i=1]=14
Estimated probability of S conditional on D
si=1 PrN[s i=1|d i=0]=.6 PrN[s i=1|d i=1]=.2
si=2 PrN[s i=2|d i=0]=.2 PrN[s i=2|d i=1]=.3
si=3 PrN[s i=3|d i=0]=.2 PrN[s i=3|d i=1]=.5
ofS.Conversely,ifS werenotaperfectstratifyingvariable,thenthesamplemeansin
thefirstpanelofTable5.2wouldnotequalthe expectationsofthepotentialoutcomes
in the secondpanel of Table 5.1. The sample means would be based onheterogeneous
groups of individuals who differ systematically within the strata defined by S in ways
that are related with individual-level treatment effects.

If S offers a perfect stratification of the data, then one can estimate from the
numbers in the cells of the two panels of Table 5.2 both the ATT as
(4−2)(.2)+(8−6)(.3)+(14−10)(.5)=3
and the ATC as
(4−2)(.6)+(8−6)(.2)+(14−10)(.2)=2.4.

Finally, if one calculates the appropriate marginal distributions of S and D (using
sampleanalogsforthemarginaldistributionfromthefirstpanelofTable5.1),onecan
estimate the unconditional ATE either as
(4−2)(.44)+(8−6)(.24)+(14−10)(.32)=2.64
or as
3(.4)+2.4(.6)=2.64.

Thus, for this hypothetical example, the naive estimator would be inconsistent and
(asymptotically)upwardlybiasedfor the ATT, ATC, andthe ATE. But, by appropri-
ately weighting stratified estimates of the treatment effect, one can obtain consistent
and unbiased estimates of all three of these average treatment effects.

In general, if a stratifying variable S completely accounts for all systematic differ-
ences between those who take the treatment and those who do not, then conditional-
on-S estimatorsyieldconsistentandunbiasedestimatesoftheaveragetreatmenteffect
conditional on a particular value s of S:
{EN[yi|di=1,si=s]−EN[yi|di=0,si=s]}
(5.5)
p
−→E[Y1−Y0|S=s]=E[δ|S=s].

Weighted sums of these stratified estimates can then be taken, such as for the uncon-
ditional ATE:
(cid:6)
p
{EN[yi|di=1,si=s]−EN[yi|di=0,si=s]}PrN[si=s]−→E[δ]. (5.6)
s
Substituting into this last expression the distributions of S conditional on the two
possible values of D (i.e., PrN[si=s|di=1] or PrN[si=s|di=0]), one can obtain
consistent and unbiased estimates of the ATT and ATC.

The key to using stratification to solve the causal inference problem for all three
causal effects of primary interest is twofold: finding the stratifying variable and then
obtaining the marginal probability distribution Pr[S] as well as the conditional prob-
ability distribution Pr[S|D]. Once these steps are accomplished, obtaining consistent
andunbiasedestimatesofthewithin-stratatreatmenteffectsisstraightforward.There-
after,estimatesofotheraveragetreatmenteffectscanbeformedbytakingappropriate
weighted averages of the stratified estimates.

This simple example shows all of the basic principles of matching estimators that
wewillpresentingreaterdetailintheremainderofthischapter.Treatmentandcontrol
subjects arematchedtogetherinthe sensethat they aregroupedtogetherinto strata.

Then,anaveragedifferencebetweentheoutcomesoftreatmentandcontrolsubjectsis
estimated, based on a weighting of the strata (and thus the individuals within them)
by a common distribution.

5.2.2 Overlap Conditions for Estimation of the ATE
Suppose again that a perfect stratification of the data is available, such that within
values of a stratifying variable S individuals are indistinguishable from each other as
defined in the lastsection. But now suppose that there is a stratum of the population
(andhence ofthe observeddata)inwhichnomember ofthe stratumeverreceivesthe
treatment. In this case, the ATE is ill-defined, and the analyst will only be able to
generate a consistent and unbiased estimate of the ATT, as we show in the following
demonstration.8
Matching Demonstration 2
For the example depicted in Tables 5.3 and 5.4, S again offers a perfect stratification
of the data. The setup of these two tables is exactly equivalent to that of the prior
Tables 5.1 and 5.2 for Matching Demonstration 1. We again assume that the data
are generated by a random sample of a well-defined population, and for simplicity
of exposition that the sample is infinite. The major difference is evident in the joint
distribution ofS andD presentedinthe first panel of Table 5.3. As shownin the first
cell of the second column, no individual in the population with S equal to 1 would
ever be observed in the treatment group of a dataset of any size because the joint
probability of S equal to 1 and D equal to 1 is zero. Corresponding to this structural
zero in the joint distribution of S and D, the second panel of Table 5.3 shows that
there is no corresponding conditional expectation of the potential outcome under the
treatment state for those with S=1. And, thus, as shown in the last column of the
second panel, no average causal effect is presented for individuals with S=1 because
this particular average causal effect is ill-defined.9
Adopting the same framing as for the college-degree example used in Matching
Demonstration 1, this hypothetical example asserts that there is a subpopulation of
individuals from suchdisadvantagedbackgroundsthat no individuals with S=1 have
ever graduated from college. For this group of individuals, we assume in this example
thatthereissimplynojustificationforusingthewagesofthosefrommoreadvantaged
social backgrounds to extrapolate to the what-if wages of the most disadvantaged
individuals if they had somehow overcome the obstacles that prevented them from
obtaining college degrees.

8In this section, we focus on the lack of overlap that may exist in a population (or super-
population). Fornow, weignorethelackofoverlapthatcanemergeinobserved datasolelybecause
ofthefinitesizeofadataset. Weturntotheseissuesinthenextsection,wherewediscusssolutions
tosparseness.

9By “ill-defined,” we mean the following. No information about E[Y|S=1,D=1] or E[Y1|S=
1,D=1]existsinthepopulation(and,asaresult,thedatawillnevergiveusavalueforE N[y i|s i=
1,d i=1]becausenoindividualsinthedatawilleverhaveboths i=1andd i=1).

Table 5.3 The Joint Probability Distribution and Conditional Population
Expectations for Matching Demonstration 2
Joint probability distribution of S and D
D=0 D=1
S=1 Pr[S=1,D=0]=.4 Pr[S=1,D=1]=0 Pr[S=1]=.4
S=2 Pr[S=2,D=0]=.1 Pr[S=2,D=1]=.13 Pr[S=2]=.23
S=3 Pr[S=3,D=0]=.1 Pr[S=3,D=1]=.27 Pr[S=3]=.37
Pr[D=0]=.6 Pr[D=1]=.4
Potential outcomes
Underthe control state Underthetreatment state
S=1 E[Y0|S=1]=2
S=2 E[Y0|S=2]=6 E[Y1|S=2]=8 E[Y1−Y0|S=2]=2
S=3 E[Y0|S=3]=10 E[Y1|S=3]=14 E[Y1−Y0|S=3]=4
E[Y0|D=0] E[Y1|D=1]
=.4(2)+.1(6) =.13(8)+.27(14)
.6 .6 .4 .4
+.1(10)
.6
=4 =12.05
Table 5.4 Estimated Conditional Expectations and Probabilities
for Matching Demonstration 2
Estimated mean observed outcome conditional on si and di
Control group Treatment group
si=1 EN[y i|s i=1,d i=0]=2
si=2 EN[y i|s i=2,d i=0]=6 EN[y i|s i=2,d i=1]=8
si=3 EN[y i|s i=3,d i=0]=10 EN[y i|s i=3,d i=1]=14
Estimated probability of S conditional on D
si=1 PrN[s i=1|d i=0]=.667 PrN[s i=1|d i=1]=0
si=2 PrN[s i=2|d i=0]=.167 PrN[s i=2|d i=1]=.325
si=3 PrN[s i=3|d i=0]=.167 PrN[s i=3|d i=1]=.675
Table 5.4showswhatcanbe estimatedconsistently forthis example. Eventhough
S offers a perfect stratification of the data, the fact that Pr[S=1,D=1]=0 prevents
theanalystfromusingthe dataforthe stratumwith S=1toestimateastratum-level
causal effect. No value exists for EN[yi|si=1,di=1].

Fortunately, the analyst can consistently estimate the average effect of the treat-
mentseparately for the two stratawith S=2and S=3.And, because all members of
the treatment groupbelong to these two strata,the analystcantherefore consistently
estimate the ATT as
(8−6)(.325)+(14−10)(.675)=3.35.

Still, no consistent and unbiased estimates of the ATC or the ATE are available.10
Areexamples suchasthis one everfoundin practice?For anexample thatis more
realistic than the causal effect of a college degree on economic success, consider the
evaluation of a generic program in which there is an eligibility rule. The benefits of
enrolling in the program for those who are ineligible cannot be estimated from the
data, even though, if some of those individuals were enrolled in the program, they
would likely be affected by the treatment in some way. Developing such estimates
would require going well beyond the data, introducing assumptions that allow for
extrapolation off of the joint distribution of S and D.

More generally, even in best-case data availability scenarios where the sample size
is infinite, it may not be possible to consistently estimate all average causal effects
of theoretical or practical interest because the distribution of the treatment across
all segments of the population is incomplete. However, at other times, the data may
appear to suggest that no causal inference is possible for some group of individuals
even though the problem is simply a small sample size. There is a clever solution to
sparsenessofdataforthislattertypeofsituation,whichwediscussinthenextsection.

## 5.3 Matching as Weighting

As shown in the last section, if all of the variables in S have been observed such that

a perfect stratification of the data would be possible with an infinitely large random
sample from the population, then a consistent and unbiased estimator is available in
theory for each of the average causal effects of interest defined in Equations (2.3),
(2.7), and (2.8) as the ATE, ATT, and ATC, respectively. Unfortunately, in many (if
not most) datasets of finite size, it may not be possible to use the simple estimation
methods of the last section to generate consistent and unbiased estimates. Treatment
and control cases may be missing at random within some of the strata defined by S,
such that some strata contain only treatment or only control cases. In this situation,
some within-stratum causal effect estimates cannot be calculated with the available
data.Wenowintroduceasetofweightingestimatorsthatrelyonestimatedpropensity
scores to solve the sparseness problems that afflict samples of finite size.

10The naive estimate can be calculated for this example, and it would equal 8.05 for an infinite
sample because [8(.325)+14(.675)]−[2(.667)+6(.167)+10(.167)] is equal to 8.05. See the last row
of Table 5.3 for the population analogs to the two pieces of the naive estimator. This means that,
withoutdeterminingthelackofoverlapbystratifyingthedata,anincautiousanalystmightofferthe
naiveestimateandthendiscussitsrelationshiptotheATE,whichisitselfatargetparameterthatis
ill-defined.

5.3.1 The Utility of Known Propensity Scores
An estimated propensity score is the estimated probability of taking the treatment
as a function of variables that predict treatment assignment. Before the attraction of
estimated propensity scores is explained, there is value in understanding why known
propensityscoreswouldbeusefulinanidealizedcontextsuchasaperfectstratification
of the data. (See also our prior discussion of propensity scores in Section 4.3.1.)
Within a perfect stratification, the true propensity score is nothing other than
the within-stratum probability of receiving the treatment, or Pr[D=1|S]. For the
hypothetical example in Matching Demonstration 1, the propensity scores are
.08
Pr[D=1|S=1]= =.182,
.44
.12
Pr[D=1|S=2]= =.5,
.24
.2
Pr[D=1|S=3]= =.625.

.32
Why is the propensity score useful? As shown earlier for Matching Demonstration 1,
ifa perfect stratificationofthe data is available,then the finalingredientfor calculat-
ing estimates of the ATT and ATC is the conditional distribution Pr[S|D]. One can
recoverPr[S|D]fromthepropensityscoresbyapplyingBayes’ruleusingthemarginal
distributions of D and S. For example, for the first stratum,
Pr[D=1|S=1]Pr[S=1] (.182)(.44)
Pr[S=1|D=1]= = =.2.

Pr[D=1] (.4)
Thus,thetruepropensityscoresencodeallofthenecessaryinformationaboutthejoint
dependence ofS andD that isneeded toestimate andthencombine conditional-on-S
treatmenteffectestimatesintoestimatesofthe ATTandthe ATC.Knownpropensity
scores are thus useful for unpacking the inherent heterogeneity of causal effects and
then averagingover such heterogeneity to calculate average treatment effects.

Ofcourse,knownpropensityscoresarealmostneveravailableto researcherswork-
ingwithobservationalratherthanexperimentaldata.Thus,theliteratureonmatching
more often recognizes the utility of propensity scores for addressing an entirely dif-
ferent concern: solving comparison problems created by the sparseness of data in any
finite sample. These methods rely on estimated propensity scores, as we discuss next.

5.3.2 Weighting with Estimated Propensity Scores to
Address Sparseness
Supposeagainthataperfectstratificationofthe dataexists andis known.Inparticu-
lar,Assumptions1-Sand2-SinEquations(5.1)and(5.2)arevalid,andS isobserved.

But, suppose now that (1) there are multiple variables in S, (2) some of the variables
in S take on many values, and (3) the true propensity score is greater than 0 and less
than 1 for every stratum defined by S. In this scenario, there may be many strata
in the available data from a finite sample in which no treatment and/or no control
casesareobserved,eventhoughthe true propensityscoreis between0and1forevery
stratum in the population (i.e., every population-level stratum includes individuals in
both the treatment and control states).

Can average treatment effects be consistently estimated in this scenario?
RosenbaumandRubin(1983a)answerthisquestionaffirmatively.Theessentialpoints
of their argument are the following (see the original article for a formal proof): First,
the sparseness that results from the finiteness of a sample is random, conditional on
thejointdistributionofS andD.Asaresult,withineachstratumforaperfectstratifi-
cationofthe data,the probabilityofhavingazerocellinthe treatmentorthe control
state is solely a function of the propensity score. Because such sparseness is condi-
tionallyrandom,stratawithidenticalpropensityscores(i.e.,differentcombinationsof
values for the variables in S but the same within-stratum probability of treatment)
can be combined into more coarse strata. Over repeated samples from the same pop-
ulation, zero cells would emerge with equal frequency across all strata within these
coarse propensity-score-definedstrata.

Because sparseness emerges in this predictable fashion, stratifying on the propen-
sity score itself (rather than more finely on all values of the variables in S) solves the
sparseness problem because the propensity score can be treated as a single stratify-
ing variable. In fact, as we show in the next hypothetical example, one can obtain
consistent estimates of treatment effects by weighting the individual-level data by an
appropriately chosen function of the estimated propensity score, without ever having
to compute any stratum-specific causal effect estimates.

Buthowdoesoneobtainthepropensityscoresfordatafromarandomsampleofthe
populationofinterest?RosenbaumandRubin (1983a)arguethat, if onehas observed
thevariablesinS,thenthepropensityscorecanbeestimatedusingstandardmethods,
such as logit modeling. That is, one can estimate the propensity score, assuming a
logistic distribution,
exp(Sφ)
Pr[D=1|S]= , (5.7)
1+exp(Sφ)
and invoke maximum likelihood to estimate a vector of coefficientsφˆ. One can then
stratify on the index of the estimated propensity score, e(si)=siφˆ, or appropriately
weight the data, and all of the results established for known propensity scores then
obtain.11Considerthefollowinghypotheticalexample,inwhichweightingisperformed
only with respect to the estimated propensity score, resulting in consistent and unbi-
asedestimatesofaveragetreatmenteffectseventhoughsparsenessproblemsaresevere.

11AsRosenbaum(1987)laterclarified(seealsoRubinandThomas1996),theestimatedpropensity
scoresdoabetterjobofbalancingtheobservedvariablesinS thanthetruepropensityscoreswould
inanyactual application,becausetheestimatedpropensityscorescorrectforthechance imbalances
in S that characterize any finite sample. This insight has led to a growing literature that seeks to
balancetheobservedvariablesinSbyvariouscomputationallyintensivebutpowerfulnonparametric
techniques(e.g.,DiamondandSekhon2013;Lee,Lessler,andStuart2009;McCaffrey,Ridgeway,and
Morral 2004). We discuss this literature later, and for now we use only parametric models for the
estimationofpropensityscores,astheydominatethefoundational literatureonmatching.

Matching Demonstration 3
Consider the following Monte Carlo simulation, which is an expanded version of the
hypothetical example in Matching Demonstration 1 in two respects. First, for this
example, there are two stratifying variables,A and B, each of which has 100 separate
values.AsforMatchingDemonstration1,thesetwovariablesrepresentaperfectstrat-
ification of the data and, as such, represent all of the variables in the set of perfect
stratifying variables, defined earlier as S. Second, to demonstrate the properties of
alternativeestimators,this example utilizes 50,000samplesofdata,eachofwhichis a
randomrealizationof the same set of definitions for the constructedvariables and the
stipulated joint distributions between them.

Generation of the 50,000 Datasets. For the simulation, we gave the variables A
andB valuesof.01,.02,.03,andupwardto1.Wethencross-classifiedthetwovariables
to form a 100×100grid and stipulated a propensity score, as displayed in Figure 5.1,
that is a positive, nonlinear function in both A and B.12 We then populated the
resulting 20,000 constructed cells (100×100 for the A×B grid multiplied by the two
values of D) using a Poisson random-number generator with the relevant propensity
score as the Poisson parameter for the 10,000 cells for the treatment group and one
minusthepropensityscoreasthePoissonparameterforthe10,000cellsforthecontrol
group. This sampling scheme generates (on average across simulated datasets) the
equivalentof10,000sample members,assignedtothe treatmentinsteadofthe control
as a function of the probabilities plotted in Figure 5.1.

Acrossthe 50,000simulateddatasets,onaverage7,728ofthe 10,000possible com-
binationsofvaluesforbothAandB hadnoindividualsassignedtothetreatment,and
4,813hadnoindividualsassignedtothecontrol.Nomattertheactualrealizedpattern
of sparseness for each simulated dataset, all of the 50,000 datasets are afflicted, such
that a perfect stratification on all values for the variables A and B would result in
manystratawithineachdatasetforwhichonlytreatmentorcontrolcasesarepresent.

To define treatment effects for each dataset, two potential outcomes were defined
as linear functions of individual values for A and B:
y i0=100+3ai+2bi+υ i0, (5.8)
y i1=102+6ai+4bi+υ i1, (5.9)
where both υ0 and υ1 are independent random draws from a normal distribution
i i
with expectation 0 and standard deviation of 5. Then, as in Equation (2.2), individ-
uals from the treatment group were given an observed yi equal to their simulated
y i1, and individuals from the control group were given an observed yi equal to their
simulated y0.

i
With this setup, the simulation makes available 50,000 datasets for which the
individual treatment effects can be calculated exactly (because true values of y1 and
i
12Theparameterizationofthepropensityscoreisaconstrainedtensorproductsplineregressionfor
theindexfunctionofalogit.SeeRuppert,Wand,andCarroll(2003)forexamplesofsuchparameter-
izations.Here,SφinEquation(5.7)isequal to−2+3(A)−3(A−.1)+2(A−.3)−2(A−.5)+4(A−
.7)−4(A−.9)+1(B)−1(B−.1)+2(B−.7)−2(B−.9)+3(A−.5)(B−.5)−3(A−.7)(B−.7).

00..88
00..66
eerrooccSS
yyttiissnneeppoorrPP 00..44
00..22
00
11
00..88
11
00..66 00..88
00..44 00..66
00..44
00..22
00..22
BB 00 00
AA
Figure5.1 The propensity score specification for Matching Demonstration 3.

y0 are available for all simulated individuals). As a result, the true ATE, ATT, and
i
ATC areknownforeachsimulateddataset, andthese knownaverageeffects canserve
as baselines against which alternative estimators that use data only on yi, di, ai, and
bi can be compared.

ThefirstrowofTable5.5presentstrueMonteCarlomeansandstandarddeviations
ofthethreeaveragetreatmentseffects,calculatedacrossthe50,000simulateddatasets.

The mean of the true ATE acrossall datasets is 4.525,whereas the means of the true
ATT and ATC are 4.892 and 4.395, respectively. Similar to the hypothetical example
in Matching Demonstration 1, this example represents a form of positive selection, in
whichthosewhoaremostlikelytobeinthetreatmentgrouparealsothosemostlikely
to benefit from the treatment. Accordingly, the ATT is larger than the ATC.

Methods for Treatment Effect Estimation. The last three rows of Table 5.5
present results for three propensity-score-based weighting estimators. For the esti-
mates in the second row, it is (incorrectly) assumed that the propensity score can be
estimatedconsistentlywithalogitmodelwithlineartermsforAandB (i.e.,assuming
that, for Equation (5.7), a logit with Sφ specified as α+φAA+φBB will yield con-
sistent estimates of the propensity score surface plotted in Figure5.1). After the logit
model was estimated for each of the 50,000 datasets with the wrong specification, the
Table 5.5 Monte Carlo Means and Standard
Deviations of True and Estimated Treatment Effects
for Matching Demonstration 3
ATE ATT ATC
True treatment effects 4.525 4.892 4.395
(.071) (.139) (.083)
Propensity-score-based
weighting estimators:
Misspecified propensity 4.456 4.913 4.293
score estimates (.122) (.119) (.128)
Perfectly specified 4.526 4.892 4.396
propensity score estimates (.120) (.127) (.125)
True propensity scores 4.527 4.892 4.396
(.127) (.127) (.132)
estimated propensity score for each individual was then calculated,
exp(αˆ+φˆ Aai+φˆ Bbi)
pˆi= , (5.10)
1+exp(αˆ+φˆ Aai+φˆ Bbi)
along with the estimated odds of the propensity of being assigned to the treatment
pˆi
rˆi= 1−pˆi, (5.11)
where pˆi is as constructed in Equation (5.10).

To estimate the ATT, we then implemented a weighting estimator by calculating
the average outcome for the treated and subtracting from this average outcome a
counterfactualaverageoutcome using weighted data on those from the controlgroup:
⎛ (cid:12) ⎞
(cid:7) (cid:8)
rˆiyi
(cid:6)
δˆ ATT,weight≡ n1 yi −⎜ ⎝i:di(cid:12)=0 ⎟ ⎠, (5.12)
1 rˆi
i:di=1
i:di=0
where n1 is the number of individuals in the treatment group and rˆi is the estimated
odds for each individual i of being in the treatment group instead of in the control
group, as constructed in Equations (5.10) and (5.11). The weighting operation in the
second term gives more weight to control group individuals equivalent to those in the
treatmentgroup;seeRosenbaum(1987,2002);seealsoImbens(2004)andHainmueller
(2012).13 To estimate the ATC, we then implemented a weighting estimator that is
13AswewilldescribeinChapter 7whendiscussingtheconnections betweenmatchingandregres-
sion,theweightingestimatorinEquation(5.12)canbewrittenasaweightedregressionestimator.

the mirror image of the one in Equation (5.12):
⎛ (cid:12) ⎞
(cid:7) (cid:8)
yi/rˆi
(cid:6)
δˆ ATC,weight≡⎜ ⎝i:(cid:12)di=1 n1/rˆi⎟ ⎠− n1 yi , (5.13)
0
i:di=0
i:di=1
where n0 is the number of individuals in the controlgroup.Finally, the corresponding
estimator of the unconditional ATE is
(cid:7) (cid:8) (cid:18)(cid:7) (cid:8)(cid:19)
(cid:6) (cid:16) (cid:17) (cid:6) (cid:16) (cid:17)
1 1
δˆ ATE,weight≡ di δˆ ATT,weight + 1− di δˆ ATC,weight , (5.14)
n n
i i
whereδˆ ATT,weight andδˆ ATC,weight areasdefinedinEquations(5.12)and(5.13),respec-
tively.

The same basic weighting scheme is implemented for the third row of Table 5.5,
buttheestimatedpropensityscoresutilizedtodefinetheestimatedoddsoftreatment,
rˆi, are instead based on results from a flawlessly estimated propensity score equation
(i.e., one that uses the exact same specification that was fed to the random-number
generator that assigned individuals to the treatment; see footnote on page 153 for
the specification). Finally, for the last row of Table 5.5, the same weighting scheme is
implemented, but, in this case, the estimated odds of treatment, rˆi, are replaced with
the true odds of treatment, ri, as calculated with reference to the exact function that
generated the propensity score for Figure 5.1.

Monte Carlo Results. On average across all 50,000 simulated datasets, the naive
estimator yields a value of 5.388, which is substantially larger than all three of the
average values for the true ATE, ATT, and ATC presented in the first row of Table
5.5. The reason is simple. The two variables A and B mutually cause both D and Y
(in a structure analogous to Figure 3.5). The two back-door paths, D←A→Y and
D←B→Y, generate noncausal associations between D and Y. These paths must be
blocked, and this is the motivation for the weighting estimators.

The second row of the table presents three estimates from the weighting estima-
tors in Equations (5.12), (5.13), and (5.14), using weights based on the misspecified
logit described above. These estimates are closer to the true average values presented
in the first row (and much closer than the average value of the naive estimate), but
the misspecification of the propensity-score-estimating equation appears to generate
systematicbiasintheestimates,suggestingthattheyareunlikelytobeconsistentesti-
mates. The third row of the table presents another three weighting estimates, using
a perfect specification of the propensity-score-estimating equation, and now the esti-
matesappeartobe consistentandunbiasedforthe ATE,ATT,andATC.Finally,the
lastrowpresents weightingestimatesthat utilize the true propensity scores,whichwe
know by construction are consistent and asymptotically unbiased (but, as shown by
Rosenbaum 1987,more variable than those based on the flawlessly estimated propen-
sity score; see also Hahn 1998; Hirano, Imbens, and Ridder 2003; Rosenbaum 2002).

The last two rows demonstrate the most important claim of the literature: If one can
obtain consistent estimates of the true propensity scores, one can solve the problems
created by sparseness of data.

This example shows the potential power of propensity-score-based modeling. If
treatmentassignmentcanbemodeledperfectly,onecansolvethesparsenessproblems
that afflict finite datasets.At the same time, this simulation also develops two impor-
tantqualificationsofthispotentialpower.First,thissolutiononlyholdsinexpectation
overrepeatedsamples(orinthe limitasthe samplesizeincreasestoinfinity).Forany
single dataset, any resulting point estimate of a treatment effect will differ from the
true target parameter to some degree because of sampling variability.

Second, without a perfect specification of the propensity-score-estimating equa-
tion, one cannotrest assuredthat consistentand unbiased estimates can be obtained.

Because propensity scores achieve their success by “undoing” the treatment assign-
ment patterns, analogous to weighting a stratified sample so that it is representative
of the population, systematically incorrect estimated propensity scores can generate
systematicallyincorrectweightingschemesthatyieldinconsistentandbiasedestimates
of treatment effects.

There are two common sources of inconsistency and bias that can be considered
separately. As discussed at length in Chapter 4, if the conditioning set leaves one
or more back-door paths unblocked, then Assumption 1-S and/or Assumption 2-S
in Equations (5.1) and (5.2) are/is invalid. We avoided this problem in Matching
Demonstration 3 because we used A and B to estimate the propensity scores, and we
know by construction that S is defined as the set {A,B}. Had we mistakenly used
only A or only B, then we would not have conditioned fully on S, thereby leaving
a back-door path unblocked. We will have much more to say about this source of
inconsistency and bias in the remainder of this chapter.

Thesecondsourceofinconsistencyandbiasismisspecificationoftheequationthat
estimatesthepropensityscores,andthisisespeciallyimportanttoconsiderforthesort
ofpropensity-score-basedweightingestimatorsutilizedforMatchingDemonstration3.

For the results reported in the second row of Table 5.5, we included both A and B in
the propensity-scoreestimating equation. But, we did not do so while also choosing a
flexible enough parameterizationof A and B that would allow the data to generate a
sufficiently accurate set of estimated propensity scores (which, in expectation, would
match the shape of the surface in Figure 5.1, when plotted in three dimensions). As a
result,the estimated effects in the Monte Carlo simulationwere systematically biased
when the weights based on these estimated propensity scores were used. Only when
the correct specification was used to generate the weights were we able to generate
unbiased estimates of the ATE, ATT, and ATC.

These possible weaknesses aside, one concluding question should be answered: In
what sense are the individual-level weighting estimators of the hypothetical example
in Matching Demonstration 3 equivalent to matching estimators? For the hypothet-
ical examples in Matching Demonstrations 1 and 2, we explained how stratification
estimatorshaveastraightforwardconnectiontomatching.The stratathatareformed
represent matched sets, and a weighting procedure is then used to average stratified
treatment effect estimates in order to obtain the average treatment effects of inter-
est. The propensity-score weighting estimators presented in this section have a less
straightforwardconnection.Here,thedataare,ineffect,stratifiedcoarselybytheesti-
mation of the propensity score, and then the weighting is performed directly across
individuals instead of across the strata. This individual-level weighting is made nec-
essary by sparseness, since some of the fine strata for which propensity scores are
estimated necessarily contain only treatment or control cases, thereby preventing the
direct calculation of stratified treatment effect estimates.

## 5.4 Matching as a Data Analysis Algorithm

Algorithmic matching estimators differ primarily in (1) the number of matched cases

designatedforeachto-be-matchedtargetcaseand(2)howmultiple matchedcasesare
weighted if more than one is utilized for each target case. In this section, we describe
the four main types of matching estimators as well as recent extensions to them.

Heckman, Ichimura, and Todd (1997, 1998) and Smith and Todd (2005) outline
a general framework for representing alternative matching estimators, and we follow
their lead.With ourvariantoftheir notation,allmatchingestimatorsofthe ATT can
be expressed as some variation of
⎡ ⎤
(cid:6) (cid:6)
δˆ ATT,match= n1 ⎣ (yi|di=1)− ωi,j(yj|dj=0)⎦ , (5.15)
1
i j
wheren1 isthenumberoftreatmentcases,iistheindexovertreatmentcases,j isthe
index over control cases, and ωi,j represents a set of scaled weights that measure the
distance between eachcontrolcase and the targettreatment case.In Equation(5.15),
the weights are entirely unspecified. For the ATC, an opposite expressionis available,
with alternative weights ωj,i instead attached to the control cases
(cid:18) (cid:19)
(cid:6) (cid:6)
1
δˆ ATC,match= (yj|dj=0)− ωj,i(yi|di=1) , (5.16)
n0
j i
and where n0 is the number of control cases.

Alternative matching estimators can be represented as different procedures for
deriving the weights represented by ωi,j and ωj,i in these two expressions. As we will
describe next, the weights can take on many values, indeed as many n1×n0 different
values, because alternative weights can be used when constructing the counterfactual
value for each target case. The difference in the propensity score between the target
case and each potential matched case is the most common distance measure used to
construct weights. Other measures of distance are available, including the estimated
oddsofthepropensityscore,theindexofanestimatedlogit,probit,orotherparametric
binary outcome model, and the Mahalanobis metric.14
Beforedescribingthefourmaintypesofmatchingalgorithms,andtheirextensions,
we note three important points. First, for simplicity of presentation, in the remainder
ofthis sectionwe willfocus onmatching estimatorsofthe ATT.Eachofthe following
matching algorithms could be described in reverse, explaining how treatment cases
canbe matched to control casesin orderto constructanestimate ofthe ATC, relying
on Equation (5.16) rather than Equation (5.15). We mention this, in part, because it
14The Mahalanobis metric is (S i−S j)(cid:3)Σ−1(S i−S j), where Σ is the covariance matrix of the
variablesinS(usuallycalculatedforthetargetcasesonly).Thereisalongtraditioninthisliterature
ofusingMahalanobismatching,sometimesincombinationwithpropensity-scorematching.

is sometimes implied in the applied literature that the matching techniques that we
areaboutto summarizeareuseful forestimating onlythe ATT. This isfalse. If(1)all
variables in S are known and observed, such that a perfect stratification of the data
could be formed with a suitably large dataset because both Assumptions 1-S and 2-S
in Equations (5.1) and (5.2) are valid and (2) the ranges of all of the variables in S
are the same for the treatment group and the control group, then simple variants of
the matching estimators that we will present in this section can be formed that are
consistent for both the ATT and ATC (and, as a result, for the ATE as a weighted
average).

Second,ifitisthecasethatoneonlywantstoestimatetheATT,onedoesnotneed
toassumefull ignorabilityoftreatmentassignmentorthatbothAssumptions 1-Sand
2-SinEquations(5.1)and(5.2)arevalid.Instead,onlyAssumption2-S(i.e.,E[Y0|D=
1,S]=E[Y0|D=0,S])must hold. In other words,to estimate the ATT, it is sufficient
to assume that, conditional on S, the average level of the outcome under the control
for those in the treatment is equal, on average, to the average level of the outcome
under the control for those in the control group.15 This assumption is still rather
stringent, in that it asserts that those in the control group do not disproportionately
gainfromexposuretothe controlstatemorethanwouldthoseinthe treatmentgroup
ifthey wereinsteadin the controlgroup.Butit is surelyweakerthanhavingto assert
Assumptions 1-S and 2-S together.16
Third, the matching algorithms we summarize next are data analysis procedures
that can be used more generally when ignorability, or related assumptions, cannot be
assumed to hold because some of the variables in the perfect stratification set S are
unobserved. Matching routines are still useful, according to Rosenbaum (2002) and
others, as techniques that generate provisional estimates that can then be subjected
to further analysis in pursuit of warrantedcausal inferences.

5.4.1 Basic Variants of Matching Algorithms
Exact Matching
Exact matching for the ATT constructs the counterfactual for each treatment case
usingthecontrolcaseswithidenticalvaluesonallofthevariablesinS.Inthenotation
ofEquation(5.15), exactmatching uses weightsequal to 1/ki forthe matchedcontrol
cases, where ki is the number of exact matches identified for each target treatment
case i. Weights of 0 are given to all unmatched control cases. If only one exact match
is chosen at random from among available exact matches, then ωi,j is set to 1 for the
randomly selected match and to 0 for all other control cases.

15Thereis anignorabilityvariant of this mean-independence assumption: D isindependent of Y0
conditional on S.One would always prefer a study design inwhichthis moreencompassing formof
independenceholds.Resultingcausalestimateswouldthenholdundertransformationsofthepotential
outcomes.ThiswouldbeparticularlyhelpfulifthedirectlymappedY –definedasDY1+(1−D)Y0–
isnotobservedbutsomemonotonictransformationofY isobserved(ascouldperhapsbegenerated
byafeatureofmeasurement).

16Andthisisagainweakerthanhavingtoassertanassumptionofignorabilityoftreatmentassign-
ment.

IfS includesmorethanoneortwovariablesand/orthesamplesizeoftheavailable
dataislimited,thenexactmatchingistypicallyinfeasible,sincemanytreatmentcases
will remain unmatched. As a result, exact matching is rarely used on its own and is
instead most commonly used in combination with one of the other matching methods
describedinthefollowingsections.Theanalystperformsanexactmatchononeortwo
of the variables in S and then utilizes another matching algorithm for the remaining
variables in S.

Nearest-Neighbor, Caliper, and Radius Matching
Nearest-neighbor matching for the ATT constructs the counterfactual for each treat-
ment case using the control cases that are closest to the treatment case on a unidi-
mensional distance measure constructed from the variables in S, most commonly an
estimated propensity score (see Althauser and Rubin 1970;Cochran and Rubin 1973;
RosenbaumandRubin1983a,1985a,1985b;Rubin1973a,1973b,1976,1980a,1980b).

As noted in our discussion of Equation (5.15), other distance metrics are sometimes
used.

Thetraditionalalgorithmrandomlyordersthetreatmentcasesandthenselectsfor
each treatment case the single control case with the smallest distance on the chosen
metric. The algorithm can be run with or without replacement. With replacement, a
controlcaseisreturnedtothepoolafteramatchandcanbematchedlatertoanother
treatment case. Without replacement, a control case is taken out of the pool once it
is matched.

One weakness of the traditional algorithm when used without replacement is that
the estimate will vary depending on the order in which the the treatment cases are
passed to the matching algorithm. Moreover, any single estimate may not be based
on the minimum aggregate distance between all treatment cases and their matched
controlcases.Aformofoptimalmatching,whichwediscussbelow,hasbeendeveloped
to remedy these weakness in the traditional algorithm by selecting the best overall
match of the data from among all of those that are possible.

An analyst can also match on a fixed number of multiple nearest neighbors for
each target treatment case, such as 5 nearest neighbors for each target treatment
case. The decision of whether to set the algorithm to select more than one nearest
neighbor represents a subtle trade-off.Matching more controlcases to each treatment
case results in lower expected variance of the treatment effect estimate but also tends
to increase bias because the probability of making more poor matches increases with
the number of matches.

Ifonlyonenearestneighborisselectedforeachtreatmentcase,asinthetraditional
algorithm, then ωi,j is set equal to 1 for the matched control case. If multiple nearest
neighbors are selected, the weights ωi,j are set equal to 1/ki for each matchednearest
neighbor, whereki is the number of matches selectedfor eachtargettreatmentcase i.

As with exact matching, the weights are set to 0 for all unmatched control cases.

A danger with nearest-neighbor matching, especially when the algorithm is forced
to find a fixed multiple of matches such as 5, is that it may result in some very poor
matches for some treatment cases. A version of nearest-neighbor matching, known
as caliper matching, is designed to remedy this drawback by restricting matches to
a chosen maximum distance, such as .25 standard deviations of the distance metric
whencalculatedonlyforthetreatmentcases.Thisdistancerestrictionthenalsoallows
for variable numbers of multiple nearest neighbors (e.g., ≤5 nearest neighbors within
thecaliperforeachtargettreatmentcase).However,withthis typeofmatching,some
treatment cases may not receive matches, since for some of these cases no control
cases will fall within their caliper. If this occurs, the resulting effect estimate then
applies only to the subset of the treatment cases that have received matches (even if
ignorability holds and there is simply sparseness in the data). Because such a data-
inducedshiftoffocus inthe targetparametermaybe undesirable,acommonstrategy
is to then use a hybrid approach, where in a second step all treatment cases without
any caliper-based matches are then matched to a single nearest neighbor outside of
the caliper.

Finally,forradiusmatching,thereisvariationinterminologyanddefinitionsinthe
literature.Mostcommonly,allcontrolcaseswithinaparticulardistanceofeachtarget
treatment case are matched, and as a result the “radius” is functionally equivalent to
thecaliperincalipermatching.And,again,theweightsωi,j aresetequalto1/kiforthe
matchednearestneighbors,whereki isthe numberofmatchesselectedforeachtarget
treatment case i. The difference from caliper matching is simply that all potential
matcheswithinthecaliperofeachtreatmentcaseareanointedasmatchesforthetarget
treatment case, which means that the matching is performed with replacement.17 As
with caliper matching, supplemental single nearest-neighbormatching may be needed
if the analystwishes to keep all treatment cases in the analysis.For some researchers,
such additional forced matching is an essential component of radius matching, unlike
caliper matching.

Interval Matching
Intervalmatching(alsoreferredtoassubclassificationandstratificationmatching)for
the ATT sorts the treatment and controlcases into segments of a unidimensional dis-
tance metric, usually the estimated propensity score (see Cochran 1968; Rosenbaum
and Rubin 1983a, 1984; Rubin 1977). For the traditional estimator of the ATT, the
intervalsaredefinedby cutpoints onthe distancemetric thatsubdivide the treatment
casesintoa chosennumber ofequal-sizedsubgroups(e.g.,the intervalsthatsubdivide
1,000treatment casesinto five groupsof 200). Morerecentvariants ofinterval match-
ing, sometimes referred to as full matching, use an optimization step to first generate
intervals of variable size that minimize the within-subgroup average difference in the
distance metric.

No matter how defined, for each interval a variant of the matching estimator in
Equation(5.15)isthenestimatedseparately.Theweightsωi,j aresettogivethe same
amount of weight to the treatment cases and control cases within each interval. The
ATTisthencalculatedasthe meanofthe interval-specifictreatmenteffects,weighted
by the number of treatment cases in each interval.

17In contrast, caliper matching can be performed without replacement, although it is most com-
monlyperformedwithreplacement.

Kernel Matching
Kernel matching for the ATT constructs the counterfactual for each treatment case
using all control cases but weights each control case based on its distance from the
treatment case (see Heckman, Ichimura, and Todd 1997, 1998). The weights repre-
sented by ωi,j in Equation (5.15) are calculated with a kernel function, G(.), that
transforms the distance between the selected target treatment case and all control
cases in the study. When the estimated propensity score is used to measure the dis-
tance, kernel-matching estimators define the weight as
G(pˆj−pˆi)
ωi,j=(cid:12) G(a pˆn j−pˆi), (5.17)
j an
wherean isabandwidthparameterthatscalesthe differenceintheestimatedpropen-
sity scores based on the sample size and pˆ is the estimated propensity score.18 The
numerator of this expression yields a transformed distance between each control case
and the target treatment case. The denominator is a scaling factor equal to the sum
of all the transformed distances across control cases, which is needed so that the sum
of ωi,j is equal to 1 across all control cases when matched to each target treatment
case.

Although kernel-matching estimators appear complex, they are a natural exten-
sion of nearest-neighbor caliper and radius matching: All control cases are matched
to each treatment case but weighted so that those closest to the treatment case are
given the greatest weight. Smith and Todd (2005) offer an excellent intuitive discus-
sionofkernelmatchingalongwith generalizationstolocallinearmatching (Heckman,
Ichimura,Smith,andTodd1998)andlocalquadraticmatching(Ham,Li,andReagan
2011).

5.4.2 Recent Matching Routines That Seek Optimal Balance
In the description of the matching algorithms above, we have given no indication
of which algorithm will work best. We will defer this question until after we offer
a demonstration of a variety of matching techniques below. Instead, in this section
we will shift the motivation of matching slightly in order to present the most recent
matching estimators that we will discuss in this section.

Consider our order of presentation of the main issues so far in this chapter. We
offered Matching Demonstrations 1 and 2 to explain the basic conditioning strategy
thatunderliesmatchingandtoclarifywhyconsistentestimatesoftheATT,ATC,and
ATE are all available when the set of perfect stratifying variables S is observed. We
then turnedto MatchingDemonstration3 to explainhow estimatedpropensityscores
can address the problems posed by finite sample sizes, under the recognition that a
full stratification of the data on all of the variables in S will rarely be feasible if S
includes many variables and/or those variables take on many values.

The recentmethodologicalliteratureonmatching assumes thatthe readeralready
knows these points and instead moves directly to the consideration of an omnibus
18Increasing the bandwidth increases bias but lowers variance. Smith and Todd (2005) find that
estimates arefairlyinsensitivetothesizeofthebandwidth.

performance criterion that motivates most recent matching routines: the capacity of
matchingestimatorstobalancethevariablesthathavebeenmatchedon.Wetherefore
need to explain the concept of balance in more detail, first in an abstract sense and
theninrelationtotheparticularmatchingestimatorsconsideredsofarinthischapter.

(See also our earlier brief discussion of balance in Section 4.4.)
Consider a case where we have many variables in the perfect stratification set S,
whereallofthesevariablesareobserved,butwherewehaveafinitesampleafflictedby
rampant sparseness. In such a dataset, many combinations of values on the variables
inS willnotbe present,eventhoughindividuals with thesepatterns ofvaluesexistin
thepopulation.Tocapturethispointformally,letPrN[si]representtheobservedjoint
distribution acrossthe realizedvalues s of all variables in S for a particular sample of
size N. For a dataset with substantial sparseness, the joint distribution PrN[si] will
not in general be equal to the population distribution of S, denoted Pr[S]. Generic
sampling variation will lead to over-representation and under-representation of most
combinations of values on the variables in S, and many of the rarest combinations in
the population will not be present in the sample.

To now consider within-sample balance with respect to a treatment effect param-
eter, we must consider the observed joint distribution of S conditional on member-
ship in the observed treatment and control groups, PrN[si|di=1] and PrN[si|di=0],
respectively. For all examples considered so far in this chapter, the observed data are
imbalanced with respect to treatment effect estimates for D because
PrN[si|di=1](cid:6)=PrN[si|di=0]. (5.18)
Inwords,thejointdistributionsfortheobservedversionsofthevariablesintheperfect
stratification set S are not the same in the treatment and control groups.

The underlying goal of all matching estimators is to transform the data in such a
way that they can be analyzed as if they are balanced with respect to the treatment
effect of interest, which will be the case if
PrN[si|di=1]=PrN[si|di=0] (5.19)
inthematcheddataset.IftheATTistheparameterofinterest,thenthedatawillonly
be balanced when matching has yielded a set of matched control cases that have the
same joint distribution for the observed variables in S that the treatment cases have
in the originalobserveddataset. If the ATC and ATE are also parameters of interest,
then the data will only be balanced with respect to these additional parametersif the
same routine also yields a set of matched treatment cases that have the same joint
distribution for the observed variables in S that the control cases have in the original
observed dataset.

Consider classic exact matching in a scenario where all treatment cases have one
available exact match among the control cases, and where by exact we mean again
that the resulting matched pairs have the same values on all of the variables in S.

In this case, optimal balance is achieved for estimation of the ATT. In particular,
all unmatched cases are tossed out of the dataset, and the remaining treatment and
control cases have the exact same observedjoint distribution acrossall variablesin S.

These data are not, however,balanced with respect to either the ATC or the ATE.19
For a closely related example, where the data are balanced with respect to the
ATT, ATC, and ATE, consider our hypothetical stratification example in Matching
Demonstration1.Forthatexample,weassumedaninfinitesamplewherethedistribu-
tionofS (see Table5.1)differsacrossthetreatmentandcontrolgroups,suchthatthe
populationandsamplehavetreatmentgroupswithdisproportionatelylownumbersof
individualswithsi=1anddisproportionatelyhighnumbersofindividualswithsi=3.

Accordingly, the observeddata are imbalanced. However,when the data are analyzed
within the strata of S, the average values for the outcome Y are generated from bal-
ancedcomparisonswithrespecttoS because,withineachstratum,allindividualshave
the samevalue for S.20 Togenerateestimates ofthe ATT, ATC,andATE,a common
distributionofS is thenpassedbacktothe estimatoras stratum-levelweights.Inthis
sense,astratificationestimator,ifavailable,isageneralizationofexactmatchingthat
allows one to optimally balance the data for all average treatment effects that can be
defined as functions in the underlying strata, including the ATT, ATC, and ATE.

As we noted above, finite datasets generallyrender exact matching and full strati-
fication infeasible. Indeed, this was the impetus for the developmentof matching esti-
mators, such as propensity-score matching, that utilize distance metrics for matching
that are lower-dimensionalthan the full joint distribution of the perfect stratification
set S. In these cases, perfect balance is generally impossible to achieve, as we now
explain.

ConsiderourhypotheticalexampleinMatchingDemonstration3.Fortheassumed
data there, the distributions of A and B (which jointly represent the perfect strat-
ification set S) differ across the treatment and control groups, such that the 50,000
simulated samples, on average, have treatment groups with disproportionately high
values for A and B. Similar to Matching Demonstration 1, individuals are grouped
into strata, but now only implicitly by estimation of the propensity score and only
coarsely (i.e., not based on the full stratification defined by the full joint distribu-
tion of A and B). Individuals are then weightedwithin these propensity-score-defined
strata, although indirectly by individual-level weights, in order to ensure that the
expected distribution of S is the same within the treatment and controlcases that are
then used to estimate the ATT, ATC, and ATE.

Notice the inclusion of the word “expected” in the last sentence. Unlike exact
matching and our full stratification example in Matching Demonstration 1, the data
19They wouldbe balanced withrespect to the ATC andATE ifthe unmatched control cases also
had the same observed joint distribution for S as the treatment cases. This would be the case if
(1)alltreatmentcaseshavetwoexactmatchesamongthecontrolcases,(2)therearenoothercontrol
cases that are exact matches, and (3) for each treatment case the exact match that is chosen from
amongtheavailabletwoisdeterminedbythetoss offaircoin.Weimplicitlyassumethatthisisnot
the case for this example because, if itwere, then the original dataset would have been balanced in
thefirstplaceandnomatchingwouldhavebeenperformed.

20In other words, the stratification match allows the unbalanced data to be analyzed in a trans-
formed fashion (i.e., within strata) where the data are balanced. In particular, the probability dis-
tribution of S collapses to a single value and becomes degenerate within each stratum, at which
point stratum-level effects are calculated. The distribution of S is then reanimated with stratum-
levelweightsthatgenerateaveragetreatmentseffectsweightedbyadistributionofS commontothe
treatmentandcontrolcases.

for this example are only balanced in expectation. For any single sample among the
50,000 samples in the simulation, imbalance in the observed joint distribution of A
and B will almost certainly exist within some of the coarse strata defined by the
estimated propensity scores. Any imbalance that resides within these coarse strata
then cumulates to the sample level.21
Now, consider the traditional matching algorithms presented in the last section.

Because nearest-neighbor, caliper, radius, interval, and kernel matching also utilize a
unidimensional distance metric to form matches, they have the same basic features
as the weighting estimators for Matching Demonstration 3. For a single dataset, a
setof perfect matches onthe estimated propensity score,or any other unidimensional
metric, does not guarantee balance on the observed joint distribution of S. In fact, if
such optimal balance were possible, then exact matching or a full stratification of the
datacouldhavebeen usedinthe firstplace.Althoughthe appliedmatching literature
isrepletewithmisleadingclaimsthatpropensity-scorematchingisacompleteremedy
forcovariateimbalanceinasinglesample(and,evenmoredistressing,evenforselection
onthe unobservables!),the coremethodologicalliterature is clear onthese points (see
Rubin 2006).

The most recent literature has focused on developing estimators that optimize
within-sample balance, typically by more closely tying the estimation steps to bal-
ance assessment. Ongoing research on matching methods can be grouped into four
non-mutually exclusive streams: new methods for balance assessment, more flexible
estimationofthedistancemetric onwhichmatchingis performed,optimizationofthe
matching step that follows the estimation of the distance metric, and coarsening the
stratification variables before matching is performed.

Enhancing Routines for Balance Assessment
Assessing the balance of the variables on which the cases have been matched can be
difficult for two reasons.First, if exact matching or full stratificationare not possible,
thenitwillnotingeneralbepossibletoachieveperfectbalance.Yet,therearenoclear
standards,noranysensethattheremustbecommonstandardsacrossallapplications,
in what features of balance can be traded off against others. Surely it is correct that
one should attempt to match the mean values of variables that strongly predict both
the treatment and the outcome, as opposed to the mean values of variables that only
strongly predict one or the other. But, beyond this obvious point, there is no clear
consensus on the relative importance of alternative components of overall balance.

Second,theuseofanyhypothesistestofsimilarityforthefeaturesoftwodistributions
has two inherent associated dangers: (a) with small samples, a null hypothesis of no
difference may be accepted when in fact the data are far from balanced; (b) with
very large samples, almost any difference, however small, is likely to be statistically
significant,leadingto the possibilitythatnoamountofbalancewouldeverbe deemed
21More formally, the foundational propensity-score literature claims only that the observed data
will be balanced after propensity-score matching on average over repeated sampling from the same
population. For any single finite sample, either Equation (5.18) or( 5.19) could be true. And, unfor-
tunately,exceptforthesimpleststratificationsetsS,itisfarmorelikelythattheobserveddatawill
remainunbalancedtosomedegree.

acceptable. As such, hypothesis tests are generally less useful for assessing balance
than measures that focus on differences in magnitude.22
Against the backdrop of these acknowledged challenges, substantial attention has
been devoted to the creation of new methods for balance assessment. The favorite
measureofbalance,followingthe soleconsensuspositionjustoutlined, isthatbalance
should first be assessed based on the standardized difference in sample means,
|EN[xi|di=1]−EN[xi|di=0]|
(cid:20) , (5.20)
1VarN[xi|di=1]+1VarN[xi|di=0]
2 2
which is calculated twice for every variable X that is matched on: (1) before any
matching is performed in order to establish the baseline level of imbalance in the
originaldataand(2)acrossthematchedtreatmentandcontrolcasestodeterminehow
muchofthe initial imbalancehas beenremovedby matching. Becausethis measureof
balance is a scaled absolute difference in the means of each X across treatment and
control cases, variable-specific measures can be compared between alternative Xs. In
addition, one can take the mean of these standardized differences across all variables
that have been matched on, and this single value then summarizes the quality of the
balance in means across all variables.

Equation (5.20) is but the tip of the iceberg among all possible balance measures
that one could construct. Most of the matching software in use has improved tremen-
douslyinthepastdecade,offeringresearchersmorewaystoexaminehowmuchbalance
has been achieved by particular matching routines, based on analogs to standardized
differencesforhighermomentsofthedistributionsofthematchingvariables,aswellas
indices based on differences between full distributions and between quantile-quantile
plots (see Austin 2009a;Hansen and Bowers 2008; Iacus et al. 2011; Imai et al. 2008;
Sekhon 2007).

With these new tools for balance assessmentin hand, ananalystcanoptimize bal-
ance by pursuing two different strategies: reestimating the distance metric on which
matching is performed and optimizing the matching algorithm that uses these dis-
tances.Insomeofthemostrecentmatchingroutines,thesetwostepsareblended,but
for clarity we present them next with some artificial separation.

Reestimating the Distance Metric
If the covariates remain substantially imbalanced after a particular matching routine
has been performed, the first recourse is to return to the model that estimates the
distances between the treatment and control cases. Typically, this involves respecify-
ing the propensity-score-estimatingequationprogressivelyin pursuitofimprovements
in balance (which, of course, can only be measured after the analyst then passes the
reestimated distance metric through to the matching algorithm of choice). The ana-
lyst can try adding interaction terms, quadratic terms, and other higher-order terms,
22Forafulldiscussionoftheseissues,andsomewhatdifferentconclusions,seeHansenandBowers
(2008),Heller,Rosenbaum,andSmall(2010),Iacusetal.(2011),Imai,King,andStuart(2008),and
RubinandThomas(1992, 1996).

guidedbythebalanceindicesthatarenowonoffer.23 Suchrespecificationcanbelabor
intensive and frustrating because alternative respecifications can improve balance in
some variables while simultaneously eroding balance in others. In the end, there is no
guarantee that through such a respecification loop the analyst will find the specifica-
tion that will deliver the best possible balance for the single sample under analysis.

For this reason, some of the most recent literature has moved toward more flexible
ways of estimating the difference metric, attempting to remove the analyst from the
initialspecification,andthenanyresultingrespecificationloop,byharnessingavailable
computational power through data mining protocols. We will discuss this literature
next.

Asecond,notmutuallyexclusive,optionistoassesswhetherbalanceimprovement
may result from the relaxation or alteration of the parametric assumptions one may
have implicitly adopted in estimating the unidimensional distance metric. Estimated
propensityscoresareonlyonedistance metricthatcanbe adoptedbefore matchingis
performed,andfromitsoriginsthematchingliteraturehasbeenespeciallyenamoredof
onealternative,theMahalanobismetric,whichreducesthe datainadifferentfashion,
preserving more of the multidimensional content of the matching variables (but in a
way that makes verbal description difficult; see the note on page 158). Even for the
propensity score, the preference for a default logit specification is rarely justified in
any formal sense and rather is typically adopted because the literature suggests that
it has worked well enough in the past.

Recently,multiplearticleshavetestedforthesensitivityofthelogitfunctionalform
in simulationstudies andwith realdata (e.g., Harder,Stuart, andAnthony 2010;Hill
et al. 2011). Our reading of this literature is that logit specifications have performed
moderately well. Still, in some head-to-head competitions, nonparametric estimation
has performed comparatively well (e.g., Harder et al. 2010), and these results may
portendthat the future of propensity scoreestimation lies in regressiontree modeling
(e.g, McCaffrey et al. 2004).24
Such a trajectory may be appealing because a case can be made that the whole
businessofassertinga parametricmodel andthensearchingfora balance-maximizing
specificationby trying out one after another is the sortof error-pronesausagemaking
thatitwouldbebesttoavoid.JasjeetSekhon’spositioniscommon,evenifinfrequently
expressed in writing:
The literature on matching, particularly the debate over the LaLonde
(1986)data,makescleartheneedtofindalgorithmswhichproducematched
datasets with high levels of covariate balance. The fact that so many tal-
ented researchers over several years failed to produce a propensity score
23Because this type ofrespecification does not involve examiningthe effects of the matching vari-
ablesontheoutcomeofinterest,itisnotconsideredoneoftheperniciousformsofdatamining(e.g.,
wherefalseeffectsareclaimedwhenvariablessneakthroughspecificationscreensasafunctionsolely
ofsamplingerror;seeourdiscussionlaterinSection6.6.2).

24As we willshow in a later demonstration, the maindanger to effect estimates is still unblocked
back-door paths that exist because some variables in S have either been left out of the estimating
equation or unobserved. This position has been reinforced by a related set of evaluations, this time
witha“yokedexperiment,”wheremodeofdataanalysiswasfarlessimportantthattheselectionof
the variables with which to balance or adjust the data (see Cook, Steiner, and Pohl 2009; Steiner,
Cook,Shadish,andClark2010).

model which had a high degree of covariate balance is a cautionary tale.

In situations like these, machine learning can come to the rescue. There
is little reason for a human to try all of the multitude of models possible
to achieve balance when a computer can do this more systematically and
much faster. Even talented and well trained researchersneed aid. (Sekhon
2007:8)
From this orientation, Diamond and Sekhon (2013) have proposed a general multi-
variate matching method that uses a genetic algorithm to search for the match that
achieves the best possible balance. Although their algorithm can be used to carry out
matching after the estimation of a propensity score, their technique is more general
and can almost entirely remove the analyst from having to make any specification
choices other than designating the matching variables. Diamond and Sekhon (2013)
show that their matching algorithms provide superior balance in both Monte Carlo
simulations and a test with genuine data.25 Imai and Ratkovic (2014) offer a related
approach, but it is one that integrates covariate balancing into the estimation of the
propensity score.

Optimizing the Matching Algorithm
Suppose that an analyst eschews methods such as those proposed by Diamond and
Sekhon (2013) and instead decides to preserve the traditional two-step estimation
strategy.Evenwith a distance metric in handfromaniterativefirststep that delivers
the bestobservedbalance(ascertainedbyrunningcandidatedistancemetricsthrough
the intended matching algorithm), there is no guarantee that the chosen matching
algorithm will then optimize the balance that the distance metric may be able to
deliver.

For example, as we noted above, nearest-neighbor matching without replacement
cangeneratesuboptimalmatchingpatternsbecauseofordereffectsthatemergeinthe
matching process. Although these problems are not large when the pool of available
control cases includes many good matches for each treatment case, they can be sub-
stantial for even moderate-sized datasets and/or when the number of control cases is
comparatively small. Considerationof these effects has led to the more generalrecog-
nitionthatanyserialmatchingofpairsthatpassesoverthetargetcasesonlyoncewill
notnecessarilyguaranteethattheoverallaveragedistanceontheunidimensionalmet-
ric within matched pairs is minimized. If this averagedistance is not minimized, then
there is little chance that the underlying joint distribution of the matching variables
will be balanced as completely as the distance metric may allow.

To address the weaknesses of nearest-neighbor matching, and other related algo-
rithms, Rosenbaum(1989)began a literature on optimal matching that has now fully
matured.The keyadvancesareto (1)considerthe closenessofamatchpatternacross
all treatment and control cases using a global metric that is a function in all pairwise
differencesinthechosenunidimensionaldistancemetricand(2)useacomputationally
25Anaturalend-stateofthisorientationisthefullnonparametricestimationoftheeffects,dispens-
ingwiththeintermediateestimationofapropensityscore(seeHill2011; Hilletal.2011).

rich algorithm to search through possible matching patterns for the one that delivers
the smallest averagewithin-pair distance.

Although optimal matching algorithms vary and allow the user to specify many
additional constraints on the match patterns searched (see Hansen 2004; Rosenbaum
2002, 2010; Zubizarreta 2012), optimal matching routines are based on the idea of
minimizing the average distance between the estimated propensity scores (or some
other unidimensional distance metric) for the cases that are matched together. The
most recent literature combines optimal pair matching with attempts to achieve near
exact matching on the variables deemed most crucial to balance (see Yang, Small,
Silber, and Rosenbaum 2012;Rosenbaum 2012; Zubizarreta 2012).

Direct Coarsening of the Stratification Variables
One way to improve balance is to ask less of the matching variables, while invoking
a theoretical justification for doing so. Consider a political participation example. If
one seeks to estimate the average effect of receiving a college degree on participation
(according to some index of participatory acts; see Section 1.3.1, page 16), theory
may suggest that one can block all back-door paths by conditioning on five variables:
self-reported racial-ethnic identity, gender, state of residence, household income, and
marital status.26 For datasets of finite size, it may be difficult to balance these five
variables if they are measured in full detail. Accordingly, an analyst might consider
conditioningonacoarserepresentationofstateofresidence(reliableredstate,reliable
blue state, and swing state), marital status (collapsing widows and widowers with
those currently married, but leaving never married and formerly married as separate
categories),self-reportedrace(collapsingHispanicethnicityintotwocategories,Cuban
and non-Cuban), and household income (using quintiles of household income rather
than the full interval scale). One suspects that researchers have been making such
decisionsfordecades,usingreasonedtheoreticaljudgmentandbackgroundknowledge
for doing so.

Iacus et al. (2012a; see also Iacus and King 2012) have refined this approach into
a new matching strategy that they label “coarsened exact matching.” As suggested
by the label, the key idea is to perform only exact matching, but after the matching
variableshavebeencoarsenedinsomeprincipledfashion.Theysituatethisnewmethod
within a broader class of “monotone imbalance bounding” (MIB) matching methods
that they propose (see Iacus et al. 2011), all of which have the attractive property of
allowing the analyst to avoid setbacks in variable-specific balance when respecifying
the routine by altering the specifications for other variables.27
The primary trade-off of using exact matching, even with coarsened data, is that
cases will typically be dropped from both the treatment and control groups in the
observed data. Such a narrowing of the dataset shifts the target parameter to some-
thing narrowerthan the population-basedATT, ATC, andATE thatwe havefocused
26For a recent debate on these issues for this particular example, see the discussionof alternative
matching estimates in Henderson and Chatfield (2011), Kam and Palmer (2008, 2011), and Mayer
(2011).

27Becausethematchingisexact, nopropensityscoreisestimated.Rather,heretherespecification
involves coarsening thematching variablesinalternative ways, whichmaythen alsoshiftthe target
parameter,aswediscussinthemaintext.

oninthisbook.Iacusetal.(2012a:5)implythatthemostcommontargetparameterof
coarsened exact matching is the local sample average treatment effect for the treated
(localSATT),whichtheydefineas“thetreatmenteffectaveragedoveronlythesubset
oftreatedunitsforwhichgoodmatchesexistamongavailablecontrols.”Thisisawell-
defined parameter in theory, but in practice it moves with each coarsening decision
because these decisions recalibrate what counts as a good match.28
When are such methods likely to lead to improvements in estimation relative to
other matching methods? Iacus et al. (2012a:1) write that “the key goal of matching
is to prune observationsfromthe data sothatthe remainingdatahavebetter balance
betweenthetreatedandcontrolgroup.”Assuch,coarsenedexactmatchingisanatural
endpoint forthe datapreprocessingperspective onmatching methods introducedinto
the literature by Ho et al. (2007). Overall, coarsened exact matching is likely to work
quite well for analysts who can accept that the key goal of matching is to “prune”
the data in pursuit of an estimate of a local SATT. And this will often be a very
reasonable position when there is no clear correspondence between the data and a
well-defined population, such as for non-random collections of individuals who have
received a treatment in a biomedical study or for collections of aggregate units that
are defined by social processes, such as nation states or congressional districts.

This book reflects our tastes for target parameters anchored in well-defined pop-
ulations and random samples of them, and our tastes are grounded in the tradition
ofrandom-samplesurveyanalysisthatdominates sociologyanddemography.Yet, the
overallmatchingliterature,especiallythestreamsthathavealwaysseenmatchingasa
type of practical sampling in the service of best estimates of hard-to-estimateaverage
treatment effects, is closer to the motivation of coarsened exact matching than is our
treatment of matching in this book.29
5.4.3 Which of These Matching Algorithms Works Best?
Very little specific guidance exists in the literature on which of these matching algo-
rithms works best. We have givensome indication of the relative strengths and weak-
nessesinourintroductionofeachtechnique,butthe strengthsandweaknessesofeach
will necessarily vary in their relevance for alternative applications.

We do not mean to imply that no one advocates for the superiority of particu-
lar matching estimators. On the contrary, the strongest advocates for any particular
estimators would appear to be those who have had a hand in developing them. Heck-
man,Ichimura,andTodd(1997,1998),forexample,arguefortheadvantagesofkernel
matching. Diamond and Sekhon (2013)prefer genetic matching for similar situations.

Rosenbaum (2010) defends optimal matching, and now Iacus et al. (2011) advocate
for coarsened exact matching. We could continue.

28Inparticular,ascoarseningproceedsvariablebyvariable,moreofthecasesareexactlymatched,
untilthelocalSATTbecomestheSATT.Atthesametime,theabilitytodefendtheexactmatching
estimateasunbiasedfortheSATTdeclinesascoarseningispursued.

29FromtheperspectiveofIacus etal.(2012a), wearewillingtoaccept somemodeldependence in
finalestimates,soastopreservethecorrespondencebetweensampleandpopulation-basedquantities.

Ourorientationwillbecomeclearoverthenexttwochapters,whereweendorsemodelingstrategies,
suchas weighted regression,that blendmatching methods withmoretraditional formsof regression
analysis.

Thesescholarsareverylikelycorrectthatthematchingestimatorstheyhavedevel-
oped are the best for the applications they have been developed to model. This does
not mean that it is easy to choose from among the alternatives, as we showed in
the first edition of this book, and as others have since also documented (e.g., Austin
2009b; Harder et al. 2010; Hill et al. 2011). Because there is no clear guidance on
which of these matching estimators is “best,” we offer a fourth hypothetical example
to give a sense of how often alternative matching estimators yield appreciably similar
estimates.

Matching Demonstration 4
The debate overthe size ofthe causaleffect ofCatholic schoolingonthe testscoresof
highschoolstudentshasspannedmorethanthreedecades(seeSection1.3.2,page22).

The example we offer here is basedon Morgan(2001),althoughwe will use simulated
data for which we have defined the potential outcomes and treatment assignment
patterns so that we can explore (a) the relative performance of alternative matching
estimators and (b) the consequences of conditioning on only a subset of the variables
in the set of perfect stratification variables S. Similar to Matching Demonstration 3,
wewillrepeatthe simulationfor multiple samples,but formany fewerofthemfor the
reasons we explain below.

Generation of the Data. The simulated datasets that we constructed mimic the
real dataset from the National Education Longitudinal Study (NELS) analyzed by
Morgan(2001).Forthatapplication,regressionandmatchingestimatorswereusedto
estimatethe effectofCatholicschoolingonthe achievementofhighschoolstudents in
theUnitedStates.Foroursimulationhere,wegenerateddatasetsof10,000individuals
with values for baseline variables that resemble closely the joint distribution of the
similar variables in Morgan (2001). The variables for respondents include variables
for race, region, urbanicity, whether they have their own bedrooms, whether they live
withtwoparents,anordinalvariablefornumberofsiblings,andacontinuousvariable
for socioeconomic status. Departing from Morgan (2001), we also created a cognitive
skill variable, assumed to reflect innate and acquired skills in unknown proportions,
that we assume was measured just prior to the decision of whether or not to enroll in
a Catholic school.30
30To be precise, each sample, with a fixed N of 10,000, was generated using a multinomial dis-
tribution with parameters calibrated by a 40-cell cross-tabulation of race (five categories of white,
Asian, Hispanic, black, and Native American), region (four categories), and urbanicity (two cate-
gories),basedonthedata inMorgan(2001). Values forsocioeconomic status werethendrawnfrom
normal distributions with means and standard deviations estimated separately for each of the race-
by-region-by-urbanicitycellsusingtheNELSdatawithrespecttosocioeconomic status. Thereafter,
allothervariablesweregeneratedfromsocioeconomicstatus,usingparametervaluesforsuitableran-
dom distributions basedon auxiliaryestimates fromthe NELSdata. Because wereliedonstandard
parametric distributions, and did not build interactions between these additional variables into the
simulationroutine,thedatafortheseadditionalvariablesaresmootherthantheoriginalNELSdata.

But,becausethesamplingcross-tabulationhas40cells,forwhichsocioeconomicstatusisthenparam-
eterized differently for each, the simulation is initiated as a mixture distribution for socioeconomic
status that is itself rather lumpy, given the pronounced differences insocioeconomic status between
racialgroupsandacrossgeographicspaceinthereferentNELSdata.

We definedpotentialoutcomesforall10,000individuals ofeachdataset,assuming
that the observed outcome of interest is a standardized test taken at the end of high
school. For the potential outcome under the control (i.e., a public school education),
we generated what-if test scores as
y i0=100+2(Asiani)−3(Hispanici)−4(Blacki)
−5(NativeAmericani)−1(Urbani)+.5(Northeasti)
+.5(NorthCentrali)−.5(Southi)+.02(NumberofSiblingsi) (5.21)
+.05(OwnBedroomi)+1(TwoParentHouseholdi)
+2(SocioeconomicStatusi)+4(CognitiveSkillsi)+υ i0,
where the values for υ0 are independent random draws from a normal distribution
i
with expectation 0 and standard deviation of 12.31
We then assumedthat the what-if testscoresunder the treatment(i.e., a Catholic
school education) would be equal to the outcome under the control plus a boosted
outcome under the treatment that is a function in race, region, and cognitive skills
(under the assumption, based on the dominant position in the extant literature, that
blackandHispanicrespondentsfromthenorth,aswellasallstudentswithhighpreex-
isting cognitive skills, are disproportionatelylikely to benefit fromCatholic secondary
schooling). Accordingly, we generated the potential outcomes under the treatment as
y1=y0+δ(cid:2) +δ(cid:2)(cid:2)
, (5.22)
i i i i
where the values for δ(cid:2) are independent random draws from a normal distribution
i
with expectation 6 and standard deviation of 0.5. To this common but stochastic
individual-leveltreatmenteffect,weaddedasecondcomponentwithvaluesforδ(cid:2)(cid:2) that
i
vary systematically over individuals. These values were constructed as draws from a
normal distribution with expectation equal to
0+1(Hispanici×Northeasti)+.5(Hispanici×NorthCentrali)
+1.5(Blacki×Northeasti)+.75(Blacki×NorthCentrali) (5.23)
+.5(CognitiveSkillsi)
and with a standard deviation of 2, after which we subtracted the mean of all drawn
values in the simulated sample (in order to center the draws for δ(cid:2)(cid:2) on 0). Taken
i
together, the values of δ(cid:2) and δ(cid:2)(cid:2) for each individual represent two additive compo-
i i
nents of their individual-level treatment effects, as is clear from a rearrangement of
Equation(5.22),withreferencetothedefinitionoftheindividual-leveltreatmenteffect
in Equation (2.1), as δi=y i1−y i0=δ i(cid:2)+δ i(cid:2)(cid:2).

We then defined the probability of attending a Catholic school using a logistic
distribution,
exp(Siφ)
Pr[Di=1|Si]= , (5.24)
1+exp(Siφ)
31Across simulated datasets, the standard deviations of socioeconomic status and cognitive skills
variedbutweretypicallycloseto1.

where
Siφ=−4.6−.69(Asiani)+.23(Hispanici)−.76(Blacki)
−.46(NativeAmericani)+2.7(Urbani)+1.5(Northeasti)
+1.3(NorthCentrali)+.35(Southi)−.02(NumberofSiblingsi)
−.018(OwnBedroomi)+.31(TwoParentHouseholdi)
+.39(SocioeconomicStatusi)+.33(CognitiveSkillsi)
−.032(SocioeconomicStatus2)−.32(CognitiveSkills2)
i i
(5.25)
−.084(SocioeconomicStatusi×CognitiveSkillsi)
−.37(TwoParentHouseholdi×Blacki)
+1.6(Northeasti×Blacki)−.38(NorthCentrali×Blacki)
+.72(Southi×Blacki)+.23(TwoParentHouseholdi×Hispanic)
−.74(Northeasti×Hispanici)−1.3(NorthCentrali×Hispanici)
−1.3(Southi×Hispanici)+.25δ i(cid:2)(cid:2) .

The specification for Equation (5.25) is based on the results of Morgan (2001), along
with an additional assumed self-selection dynamic in which individuals are slightly
more likely to select the treatment as a function of the relative size of the systematic
component of the individual-specific shock to their treatment effect, δ(cid:2)(cid:2).

i
The probabilities defined by Equation (5.24) were then specified as the parameter
for random draws from a binomial distribution, generating a treatment variable di
for each simulated student. Finally, following Equation (2.2), simulated students in
Catholic schools were given observed values for yi equal to their simulated y i1, while
all others were given an observed values for yi equal to their simulated y i0.

The ATT as the Target Parameter. The presence of the self-selection term, δ(cid:2)(cid:2),
i
inbothEquation(5.22)andEquation(5.25)createsanearlyinsurmountablechallenge
fortheestimationofthe ATE.We willconsidercasessuchasthisoneindetailinlater
chapters, but for now we will explain briefly why the only target parameter that can
be estimated with any degree of confidence is the ATT.

Consider the directed graph presented in Figure 5.2, and consider why this graph
indicates that the ATE cannotbe estimated with the availabledata. Equations (5.21)
and (5.25) imply that all of variables whose names are written out in this figure are
mutual causes of both D and Y. All of these variables are on the right-hand sides
of both of these equations, and the nonparametric nature of the directed graph also
represents the variety of higher-order and cross-productterms embedded in Equation
(5.25). If we observe and then condition on all of these variables, we will be able to
block many back-door paths that would otherwise confound the causal effect of D
on Y. Unfortunately, there is an additional back-door path, represented by the bidi-
rectededgeD(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)Y,thatwillremainunblockedaftersuchconditioning.Thisisthe
noncausalback-doorassociationthatisgeneratedbythe presenceofδ(cid:2)(cid:2) inbothEqua-
i
tion(5.22)andEquation(5.25).Aswithmanyreal-worldapplications,thissimulation
assumes that individuals (in this case students, although surely informed by parents
andothers)select fromamongalternativetreatments basedonaccurateexpectations,
Race, Urbancity, Region,
Number of Siblings, Have Own
Cognitive
Bedroom, Have Two Parents,
Skills
Socioeconomic Status
D Y
Figure5.2 The directed graph implied by the underlying data generation model for
Matching Demonstration 4.

unavailableasmeasurestoresearchers,oftheirlikelygainsfromalternativetreatment
regimes. Accordingly, prospective Catholic school students with comparatively high
values of δ(cid:2)(cid:2) are more likely to be in Catholic schools, according to Equation (5.25),
i
and are also more likely to benefit from Catholic schooling, according to Equations
(5.22)and(5.23).This patternisthe mostcommontype ofselectiononthe unobserv-
ables in the social sciences.

The directed graph reveals clearly why the ATE is not identified, and yet it does
not at all suggest that the ATT is, in fact, still identified in cases such as this one.

Here,itishelpful toconsultthe equationsagain.Thesetofvariablesthatwasusedto
generate y0 in Equation (5.21) does not include the individual-specific shock, δ(cid:2)(cid:2). We
i i
thereforedo notneedto observeδ(cid:2)(cid:2) in orderestimate reasonablecounterfactualvalues
i
fory0 amongsimulatedstudentsenrolledinCatholicschools.Asdiscussedearlier–see
i
Equations (2.16) and (5.2) – these are the only counterfactual values that are needed
in order to effectively estimate the ATT.32
The problem for the ATE is that the ATC is not identified. Because of the way in
which the generation of y i1 and di are entangled by their joint dependence on δ i(cid:2)(cid:2), we
cannotestimate reasonablecounterfactualvalues fory1 amongthose who areenrolled
i
in public schools. Net of all of the other observed variables, the students most likely
to benefit from Catholic schooling are in Catholic schools, and they therefore have
values for yi=y i1 that are too positive, even net of the observables, to enable effective
estimation of the counterfactual values of y1 for public school students.

i
(Although the directed graphs we have introduced so far do not make the identifi-
cation of the ATT particularly clear when the ATE is not also identified, in Chapter
8 we will offer elaborated directed graphs, which use latent classes and variables for
individuals’ own expectations, to communicate results such as these. Still, it is often
the case that targeted identification results are best conveyed by equations, whether
32Notice that we did not specify self-selection on the causal effect in both directions. If we had,
the ATT would not be identified either. We have builtthis simulationassuming that public schools
serveasabaselinestate,outofwhichstudentsmayexitinordertocaptureadditionallearninggains
thatmaybeavailabletothemfromCatholicschooling.Themorecomplicatedscenariowouldbeone
where Equation 5.21 alsoincluded δ(cid:3)(cid:3) but with a negative coefficient (such that, net of observables,
i
those who areleast likely to do well inCatholic schooling are those most likely to do well inpublic
schools).

theseareequationsfurnishedbythepotentialoutcomemodelorbasedonthenonpara-
metric structural equations that underlie all directed graphs. We will consider these
issues in substantial detail in the next part of the book.)
Methods for Treatment Effect Estimation. In Tables 5.6 and 5.7, we offer 19
separate matching estimates of the ATT, where we match the simulated controlcases
to the simulated treatment cases. These estimates are produced by routines written
for R and Stata by others (see the notes to Table 5.6 for citations to the software),
and the row labels we have chosen for the tables map onto the terminology that we
used to present the matching estimators in Sections 5.4.1 and 5.4.2.

We estimate all matching estimators under two basic scenarios. First, we offer a
set of estimates based on an incomplete specification of treatment assignment, where
we omit the cognitive skills variable. In addition, for routines that utilize estimated
propensityscores,wealsoomittedthehigher-orderandcross-productinteractionterms
presentinEquation(5.25).Theexclusionofthecognitiveskillsvariableisparticularly
important because it has correlations of 0.4 with the outcome variable and 0.2 with
the treatment variable, on average across the simulated datasets. For the second sce-
nario, which we label the complete specification scenario, we included the cognitive
skills variable, and, for those routines that utilize propensity scores, the higher-order
andcross-productinteractiontermspresentinEquation(5.25).Bothscenarioslackan
adjustment for the self-selection dynamic, in which individuals select into the treat-
ment partly as a function of an accurate expectation of their own individual-specific
treatment effect. In this sense, the complete specification is only complete enough to
deliveraconsistentandasymptoticallyunbiasedestimateoftheATT,notofthe ATC
or the ATE as explained above.

Regardingthespecificsettingsforthealternativematchingestimators,welistsome
relevant information in the row labels for each (i.e., caliper size, kernel specification).

Beyond these settings, we generally accepted the default options for all estimators as
specified in the relevant software, on the argument that this “horse race” between
estimators ought to be fair. As we will note below, each of the estimates we offer
could be tailored to this specific application more so than for the analysis that we
present, and perhaps some estimators could therefore get closer on average to the
target parameter and be shown to outperform all others. We have made the datasets
available,onthebook’sWebsite(www.cambridge.org/9781107065079),foranyreaders
whowishtotry.Weencourageinstructorsusingthisbooktosharethesedatasetswith
theirstudentsandtousethemtotryoutadditionalmatchingestimatorsbeyondthose
we have presented here, including any matching routines developed after publication
of this edition of the book.

We will not provideestimated standarderrorsin the tables, althoughwe will indi-
cate their range in the text. As we describe following the demonstration (see Section
5.5), there is no common methodology that allows the estimation of standard errors
in analogous ways across all estimators, which makes informative comparisons across
estimators difficult (in terms of relative efficiency or expected mean-squared error).

Nonetheless, the literature agrees that estimators that use more of the data, such as
interval matching and kernel matching, have smaller estimated standard errors than
Table 5.6 Matching Estimates of the ATT, Catholic Schooling on Achievement for
One Simulated Dataset
Specification of treatment
assignment variables: Numberof treatment cases
retained for the
Method Incomplete Complete estimate of the ATT
Nearest-neighbor match:
1 without replacement (ps2) 7.37 7.03 1052
1 without replacement (MI) 7.55 7.09 1052
1 with replacement (ps2/psc) 7.77 7.17 1052
1 with replacement (MI) 7.96 7.38 1052
1 with replacement and
caliper = .05 SD (ps2) 7.77 7.15 1051
1 with replacement and
caliper = .05 SD (MI) 7.27 6.43 1051
5 with replacement (ps2) 7.51 6.42 1052
5 with replacement (MI) 8.06 7.29 1052
5 with replacement and
caliper = .05 SD (ps2) 7.55 6.37 1051
5 with replacement and
caliper = .05 SD (MI) 8.00 7.12 1051
Radius match:
Caliper = .05 SD (ps2) 7.61 6.36 1051
Caliper = .05 SD (psc) 8.23 7.84 1051
Intervalmatch:
10 fixed blocks (MI) 8.71 8.71 1052
Variable blocks (ps2) 7.50 6.60 1052
Kernel match:
Epanechnikov(ps2/psc) 7.57 6.58 1052
Gaussian (ps2/psc) 7.70 6.82 1052
Optimal match (MI-opt) 6.84 6.78 1052
Genetic match (MI-gen) 7.80 6.46 1052
Coarsened exact match (cem) 7.54 6.59 1015/973
Notes:Thesoftwareutilizedisdenoted “ps2”forLeuvenandSianesi(2012), “MI”for
Hoetal.(2011), “psc”forBeckerandIchino(2005), “opt”forHansen,Fredrickson,andBuckner
(2013), “gen”forSekhon(2013), and“cem”forIacus etal.(2012b).

thosethatdiscardmoreofthedata,suchasnearest-neighbormatching.Thelatterhave
a claim to lower bias, since bad matches are thrown away, and yet also have greater
sampling variability. In this sense, comparisons of matching estimators represent a
classic trade-off between bias and variance.

Results. Table 5.6 presents matching estimates of the ATT for a single dataset, as
wouldbethecaseinnearlyallapplicationsofthemethodologypresentedinthisbook.

However, one important difference from the typical scenario is that we know for this
simulated dataset that the true ATT is equal to 6.92. And, even though we will not
estimate them here, we also know that the true ATE and ATC are equal to 6.00 and
5.90,respectively.Byconstruction,theATTislargerthantheATCbecausethosewho
aremost likely to benefit from Catholic schoolingare more likely to enrollin Catholic
schooling, both as a function of observed variables that lie on the back-door paths
in Figure 5.2 and because of the self-selection on the individual-level treatment effect
itself.

Estimates based on the incomplete specification are reported in the first column
ofTable 5.6. As expected, the estimates aregenerallymuch largerthan the true value
of the ATT, which is 6.92 (although the optimal match estimate yields a surprisingly
close value of 6.84 for this single dataset). Most of the positive bias of these estimates
is due to the mistaken exclusion of the variable for cognitive skills from the model for
treatment assignment.

Estimates based on the complete specification are then reported in the second
column of Table 5.6. On the whole, this second set of estimates is considerably closer
to the true ATT, oscillating on either side of the true value of 6.92 (i.e., 10 have
negativebiasforthe ATT,and9havepositivebiasforthe ATT). Thestandarderrors
fortheseestimates,whichallsoftwareroutinesprovide,fallwithinarangebetween.43
and .66, although using different estimation techniques. The point values reported in
the second column are consistent with what one would expect for variation produced
by sampling error alone. However, the variation across the point estimates does not
arise from sampling error, since all estimators use the same sample, but rather from
the different ways in which the estimators use the data. As such, it is unclear how
comforting is the claim that this level of variation is consistent with what would be
produced by sampling error alone.

Notice also that the third column reports the number of treatment cases retained
for the estimate of the ATT. For estimators that do not impose a nearness crite-
rion (i.e., a caliper or radius), all 1,052 treatment cases were retained for the esti-
mate. Even when quite narrow calipers are selected, only one treatment case is dis-
carded for the relevant estimates for this single dataset. This pattern indicates that
these data are therefore well suited for matching estimators that force the utiliza-
tion of all treatment cases, such as traditional nearest-neighbor matching without a
caliper, because there are many suitable control cases on the support of the match-
ing variables for the treatment cases. This will not always be the case for datasets
with more extreme patterns of treatment assignment and/or a more limited sample
size.

Much more could be said about each pair of estimates, but we will note only a
few additionalpatterns.First, insome casessoftwareprogramsthat utilized the same
routineyieldedestimatesthatwerequitedifferent.Thereasonsforthesedifferencesare
notobvious,buttheytendtooccurforestimatorsthatprocessthematchingalgorithm
in ways that could vary or that utilize difference calculations across propensity scores
within calipers that can be sensitive to rounding error. Second, although it may be
tempting to conclude that the optimal match is superior to all others, we will show
Table 5.7 Bias for Matching Estimates of the ATT, Catholic Schooling on
Achievement Across 10 Simulated Datasets
Specification of treatment assignment variables:
Incompletespecification Complete specification
Method Min, Max Average Min, Max Average
Nearest-neighbor match:
1 without replacement (ps2) −.37, 2.17 .79 −1.17, 0.68 −.04
1 without replacement (MI) −.23, 2.08 .75 −1.11, 0.56 .00
1 with replacement (ps2/psc) −.35, 2.00 .77 −1.18, 0.40 −.13
1 with replacement (MI) −.25, 2.22 .95 −.70, 0.84 .19
1 with replacement and
caliper = .05 SD (ps2) −.32, 2.04 .78 −1.21, 0.35 −.13
1 with replacement and
caliper = .05 SD (MI) −.16, 1.89 .98 −.99, 1.16 .07
5 with replacement (ps2) −.01, 1.77 .79 −.79, 0.83 −.04
5 with replacement (MI) .43, 2.29 1.17 −.44, 1.34 .50
5 with replacement and
caliper = .05 SD (ps2) −.01, 1.71 .77 −.81, 0.75 −.04
5 with replacement and
caliper = .05 SD (MI) .15, 2.43 1.19 −.49, 1.18 .39
Radiusmatch:
Caliper = .05 SD (ps2) −.18, 2.07 .81 −.82, 1.02 −.08
Caliper = .05 SD (psc) .36, 2.42 1.17 .10, 2.03 .89
Intervalmatch:
10 fixed blocks (MI) .84, 3.02 1.68 .84, 3.02 1.68
Variable blocks (ps2) .03, 2.18 .88 −.85, 1.12 −.03
Kernelmatch:
Epanechnikov(ps2/psc) .08, 2.25 .89 −.76, 1.25 .01
Gaussian (ps2/psc) .08, 2.34 1.00 −.59, 1.44 .19
Optimal match (MI-opt) .45, 2.89 1.28 −.36, 1.53 .54
Genetic match (MI-gen) .09, 1.66 .96 −.89, 1.55 .23
Coarsened exact match (cem) .58, 2.66 1.28 −.43, 1.59 .35
Notes:seenotes toTable 5.6forsoftwaredetails.

below that this is partly a chance result for this single sample (even though optimal
matching is designed to outperform traditional estimators and can be expected to do
so). Third, the interval match with fixed blocks does not improve for the complete
specification because the inclusion of the variable for cognitive skills does not have
consequencesfortheorderingofthedata,andhenceitdoesnotmovecasesinbetween
the 10 intervals that are used. For the alternative interval matching estimator that
uses variable blocks, selected in order to maximize within-interval mean balance on
the propensity score, the utilization of the variable for cognitive skills does improve
the estimate.

The only estimates that require more detailed explanation are those based on
coarsenedexact matching. For this estimator,we could have coarsenedthe data more
in order to retain all treatment cases. Or we could have coarsened the data less and
retained fewer cases. We chose a strategy that kept most of the treatment cases so
that the assumed local SATT is not too far from the target parameter for all other
matching estimators, the true ATT.

In particular, for the incomplete specification, we made coarsening decisions that,
collectively, defined 868 strata that contained either treatment or control cases, of
which244hadbothtreatmentandcontrolcasespresent.Overall,37of1,052treatment
cases fell into strata without any control cases and were therefore discarded from the
analysis. The specific coarsening decisions were to coarsen the variable for number of
siblings into three categories (0, 1 or 2, and 3 or more) and socioeconomic status into
five categories as equal-sized quintiles. No other variables were coarsened.

For the complete specification, we then included the variable for cognitive skills,
whichwe alsocoarsenedinto quintiles.This additionalvariableincreasedto 1,540the
number of strata that contained either treatment or control cases, of which 316 had
both treatment and control cases present. Because of the increasingly specific strata,
79 treatment cases fell into strata without any control cases and were discarded from
theanalysis.Intheend,thelocalSATT forthe completespecificationisestimatedfor
973 of the 1,052 treatment cases (or 92.5 percent). It is unclear, therefore, whether it
is sensible to compare the resulting estimate to the true ATT for this example, as we
dohere.Yet,itcouldalsobe unfairtocompareittoitsownimpliedtargetparameter,
the true local SATT, without similarly doing so for caliper and radius estimators, for
example, that also discard some treatment cases.

In sum, when we consider a single sample, and when we know the true value for
the ATT, it is clear that omitting a crucial variable, such as the variable for cognitive
skills in this application, will prevent matching estimators from effectively estimating
the ATT. When the complete specification is adopted, matching appears to perform
quitewell,althoughtheparticularmatchingestimatorsgivepointvalueestimatesthat
oscillate around the true target parameter.

Howgeneralaretheseresults?Inonesense,theyareverygeneral.Weknowfroma
richexistingliteraturethatmatchingestimatorscanbeaneffectivetoolforestimating
causaleffectsinthesesituations.Andwecould,therefore,withsuitablecomputational
power and investigator patience, perform a Monte Carlo version of this simulation
across50,000simulateddatasets,asforMatchingDemonstration3.33 Alessambitious
multiple-sample simulation will suffice to reveal the general results.

Table5.7presentsresultsfrom10simulatedsamples,ofwhichonewasusedforthe
estimates reported already in Table 5.6.34 Across all 10 samples, the true values for
the ATT vary only slightly, from a low of 6.87 to a high of 6.98. Rather than present
33Doing so for 50,000 datasets would require substantial time, since some estimators, such as the
geneticmatchingestimatorofSekhon(2013),takefarmoretimetoestimatethanthesimpleweighted
averagesanalyzedforMatchingDemonstration3.

34Infact, for the estimates reported inTable 5.6, wechose the samplefromamong these 10 that,
onaverageoverallestimators,deliveredestimates thatwereclosesttotheirrespectivetrueATT.In
thespecificpointestimatesoftheATTforall10samples(i.e.,anadditional9versions
ofTable 5.6),we instead offerthe minimum, maximum,and averagebias acrossall10
estimates of the true ATT for each matching estimator.

As shown in the first two columns, for the incomplete specification the average
bias of all estimators was positive and substantial, from a low of .75 to a high of 1.68.

Moreover, the minimum amount of bias was positive for many estimators, and the
maximum amount of bias was never less than 1.66. When the complete specification
was used, the average amount of bias was considerably smaller, and the minima and
maxima for each estimator were typically negative and positive, respectively.

Ifweweretorepeatthisexercisefor50,000simulateddatasets,wewouldhavemore
confidence that the average values for the bias inform us of how well these matching
estimators perform for this particular pattern of simulated data. We do not do so,
in part, because this could give a misleading impression that one of these estimators
should be more generally preferred, even for applications very much unlike this one.

Instead,wehopetohaveconvincedthereaderofamorebasicpoint.Evenforexamples
suchasthis one,wherethis is considerableoverlapbetweenthe treatmentandcontrol
groups, such that even the traditional estimators that have been around for decades
can be used with some confidence, the specific point values generated by matching
estimators can differ considerably. It is possible that some of the variability of these
estimates canbe reducedby routine-specificrespecificationsofthe matching variables
afterassessingthe achievedbalanceofeachestimator.Itisunlikelythatallvariability
can be eliminated, and therefore researchers who wish to use a matching strategy
should make sure that their conclusions hold across a reasonable range of matching
estimators.

We have demonstrated three general points with this example. First, the sort of
self-selection dynamic built into this example – in which individuals choose Catholic
schooling as a function of their expected gains from Catholic schooling – does not
prevent one from consistently estimating the ATT (because Assumption 2-S may still
hold),eventhoughitmakesestimationofboththeATCandATEimpossible(because
Assumption 1-S does not hold). If all variables in S other than anticipation of the
individual-level causal effects are observed, then the ATT can be estimated consis-
tently.35
Second, even when the ATT is formally identified by conditioning on S while
maintaining Assumption 2-S, matching estimators cannot compensate for a decision
to mistakenly exclude an observedcovariate in S. Failure to condition on the variable
contrast,Table5.7showsthatitwilloftenbethecasethatmatchingestimatorsperformsubstantially
worse.

35At the same time, this example shows that even our definition of a “perfect stratification” is
somewhat underspecified. According to the definition stated above, if self-selection on the causal
effectoccurs,aperfectstratificationisavailableonlyifvariablesthataccuratelymeasureanticipation
of the causal effect for each individual are also available and duly included in S. Thus, perhaps it
would be preferable to refer to three types of perfect stratification: ATC-perfect stratification for
whichAssumption1-Sisvalid(whichenablesestimationoftheATC),ATT-perfectstratificationfor
which Assumption 2-S is valid (which enables estimation of the average treatment for the treated),
and our unconditionally perfect stratification for which both are valid, enabling estimation of the
ATT,ATC,andATE.

for cognitive skills in this example would invalidate Assumption 2-S (in addition to
Assumption 1-S that is already invalidated by the self-section on the causal effect
itself). The matching routines will still attempt balance the matching variables, but
theresultingestimateswillremaininconsistentandbiasedfortheATT,ATC,andthe
ATE.

Third, in cases such as this one, where a researcherattempts to estimate the ATT
andwherethereisalargereservoirofsuitablecontrolcasestomatchtothetreatment
cases, many alternative specific matching estimators can be used. They will all tend
to offer slightly different point estimates, and there is no clear guidance for which
ones should be preferred. We therefore recommend that, in these situations, many
point estimates be offered and that conclusions not be selected that depend on only
a subset of all permissible estimates. However, for applications that depart from the
featuresofthisexample,someofthemorerecentlydevelopedmatchingestimatorsmay
have a clear advantage, particularly optimal matching when the sample size is small,
geneticmatchingwhenthereisverylittlepriorresearchtohelpestablishaspecification
for a propensity score, and coarsened exact matching when one wishes to eliminate
incomparable cases in a principled way and when one is comfortable narrowing the
analysis to a subset of the treatment cases.

## 5.5 Remaining Practical Issues in Matching Analysis

In this section, we discuss the remaining practical issues that analysts who consider

using matching estimators must confront. We first discuss the possibility of using
matching to estimate parameters when the ATE, ATT, and ATC are not identified.

We then consider the literature on when, why, and how an analyst may want to
estimate effects only after restricting the analysis to the rangeof common support for
the matching variables. We then discuss what is known about the sampling variance
of alternativematching estimators,and we conclude with some guidance on matching
estimators for causal variables with more than two values.

5.5.1 Matching When Treatment Assignment Is Nonignorable
WhatifneitherAssumption1-SnorAssumption2-Sisvalidbecauseweobserveonlya
subsetofthe variablesinS,whichwe willnowdenote byX?We canstillmatchon X
usingthetechniquesjustsummarized,aswedidfortheincompletespecificationinthe
hypotheticalexampleforMatchingDemonstration4.Inthatexample,weshowedthat
if the complete specification is available, one should of course use it. Yet, in practice
this will often not be possible, and yet matching can still be used as a data analysis
technique with substantial payoff, assuming that the results are properly interpreted.

Consider, for example, the paper of Sekhon (2004), in which a matching algo-
rithmis used to balancevarious predictorsofvotingat the county levelinanattempt
to determine whether or not John Kerry lost votes in the 2004 presidential election
campaign because optical scan voting machines were used instead of direct electronic
voting machines in many counties (see Section 1.3.2, page 26, on voting technology
effects in Florida for the 2000 election). Sekhon shows that it is unlikely that voting
technologycausedJohnKerrytolosevotes.Inhisanalysis,ignorabilityisnotasserted
in strict form, as it is quite clear that unobserved features of the counties may well
have been related to both the distribution of votes and voting technology decisions.

Nonetheless,theanalysisisconvincingbecausethepredictorsoftreatmentassignment
are quite rich, and Sekhon is cautious in his interpretations.

When in this position, however, it is important to concentrate on estimating only
one type of treatment effect (usually the ATT, although perhaps the ATE). Because
a crucial step must be added to the project – assessing the level of inconsistency
and bias that may arise from possible nonignorability of treatment – focusing on a
very specific treatment effect of primary interest helps to ground a discussion of an
estimate’s limitations. Then, after using one of the matching estimators of the last
section, one should use the data to minimize bias in the estimates and, if possible,
proceedthereaftertoasensitivityanalysis(whichwewill discusslaterinChapter12).

WewillreturntothisissueindepthinChapter7,wherewewillpresenttechniquesthat
combine matching and regressionestimators, often for examples wherein assumptions
of ignorability are knowingly suspect.

5.5.2 Matching Only on the Region of Common Support
Treatment cases may have no counterparts among the control cases in the observed
data because they are saidto be “off the support” of S, and vice versa for the control
cases.36 Typically, researchers will notice this situation when the distributions of the
estimated propensity scores for the treatment and control cases have substantially
different minimum and maximum values, and that is the situation we will consider in
this section.

In some cases, the lack of observed overlap in estimated propensity scores may
reflectgenericsparsenessbecauseunusualtreatmentandcontrolcaseswilloftenfailto
besampledforfinitedatasets.Inothercases,thereisgoodreasontobelievethatsome
ofthelackofobservedoverlapmayhaveemergedfromsystematicsources,oftenrelated
tothechoicebehaviorofindividuals.Inthesesituations,itisnotasparsenessproblem.

Instead, a more fundamental mismatch between the observed treatment and control
cases exists in the population, as in our earlier hypothetical example in Matching
Demonstration 2. In still other situations, unlike those that we focus on in this book,
the data exist for a collection of units that is either not drawn at random from a
well-defined population (as in many biomedical examples) or where the population
is not well-defined (as in many social science examples when administrative units, or
other socially defined units, are analyzed). In these cases, the treatment and control
cases may be off of the support of each other, and matching is invoked precisely to
takeaccountofthispredicament,usingavariantofthedatapreprocessingperspective
proposedby Ho et al. (2007)to define a useful comparisonthat canmovethe relevant
literature forward.

36Support is often given slightly different definitions depending on the context, although most
definitionsareconsistentwithastatement suchasthisone:Supportistheunionofallintervalsofa
probabilitydistributionthathavetruenonzeroprobabilitymass.

When in any of these situations, applied researcherswho use matching techniques
to estimate treatment effects may choose to estimate narrower treatment effects. For
example,analysismaybeconfinedonlytotreatmentcaseswhoseestimatedpropensity
scores fall between the minimum and maximum estimated propensity scores of the
control cases. Resulting estimates are then interpreted as estimates of a treatment
effectthatisnarrowereventhantheATTandistypicallylabeledthecommon-support
ATT (see Heckman, Ichimura, and Todd 1997, 1998; see also Crump, Hotz, Imbens,
and Mitnik 2009). Although using the estimated propensity score to find the region
of overlap may not capture all dimensions of the common support (as there may be
interiorspacesinthejointdistributiondefinedbythe matchingvariables),subsequent
matching is then expected to finish the job of eliminating incomparable cases.

Sometimesmatchingontheregionofcommonsupporthelpstoclarifyandsharpen
the contribution of a study. Even if imposing a common-support condition results in
throwing awaysome of the treatment cases,this can be considered an important sub-
stantive finding for some applications. Any resulting estimate is a conditional average
treatment effect that is informative only about those in the treatment and control
groupswhoaresubstantiallyequivalentwithrespecttoobservedtreatmentassignment
andselectionvariables.Insomeapplications,thisispreciselytheestimateneeded,such
as when evaluating whether a programshould be expanded in size in order to accom-
modatemoretreatmentcasesbutwithoutchangingeligibilitycriteria.(Wewilldiscuss
these marginal treatment effects in Chapter 9.)
Theliteratureonthesecommon-supportstrategiesisnowwelldeveloped.Heckman,
Ichimura, and Todd (1998; see also Smith and Todd 2005) recommend trimming the
region of common support to eliminate cases in regions of the common support with
extremelylowdensity(andnotjustwithrespecttotheestimatedpropensityscorebut
for the full distribution of the matching variables). This involvesselecting a minimum
density (labeled the “trimming level”) that is greater than zero. Heckman and his
colleagues have found that estimates are sensitive to the level of trimming in small
samples, with greater bias when the trimming level is lower. More recently, Crump
et al. (2009) have developed optimal weighting estimators that are more general but
designedtoachievethesamegoals.Coarsenedexactmatchingcanbeseenasmotivated
bythesamebasicstrategy,guideddirectlybythematchingvariablesratherthantheir
unidimensional reduction in the estimated propensity score. The common support
ATT may coincide with the local SATT of coarsened exact matching, but the latter
will always be at least as narrow if the underlying matching variables are the same at
the outset before any coarsening is applied.

5.5.3 The Expected Variance of Matching Estimates
Aftercomputingamatchingestimateofsomeform,mostresearchersnaturallydesirea
measureofitsexpectedvariabilityacrosssamplesofthesamesizefromthesamepopu-
lation,eithertoconducthypothesistestsortoofferaninformedposteriordistribution
forthecausaleffectthatcanguidesubsequentresearch.37 Wedidnot,however,report
37There is also a related set of randomization inference techniques, built up from consideration
ofallofthepossiblepermutations oftreatment assignmentpatterns that couldtheoreticallyemerge
fromalternativeenactmentsofthesametreatmentassignmentroutine(seeRosenbaum2002).These
standarderrorsfor the treatmenteffect estimates reportedin Tables 5.6 or5.7 for the
hypothetical example in Matching Demonstration 4 (although we did indicate in the
text the range of the estimates that are provided by the relevant software routines).

Althoughmostoftheavailablesoftwareroutinesprovideestimatedstandarderrors,
many rely on different methodologies for calculating them. Given their lack of agree-
ment, we caution against too strong of a reliance on the standard error estimates
producedbyanyonesoftwareroutine,atleastatpresent.Muchremainstobe worked
out before commonly accepted standards for calculating standard errors for all types
of matching estimators are available (see Abadie and Imbens 2009, 2012; Hill and
Reiter2006;ImbensandWooldridge2009).Fornow,ouradviceistoreportarangeof
standarderrorsproduced by alternativesoftwareroutines for correspondingmatching
estimates.38
We recommend caution for the following reasons. In some simple cases, there is
widespread agreementon how to properly estimate standard errorsfor matching esti-
mators. For example, if a perfect stratificationof the data can be found, the data can
be analyzed as if they are a stratified random sample with the treatment randomly
assignedwithin eachstratum.In this case,the varianceestimates fromstratifiedsam-
plingapply.Butrarelyisaperfectstratificationavailableinpracticewithoutsubstan-
tial sparseness in the data at hand. Once stratification is performed with reference
to an estimated propensity score, the independence that is assumed within strata for
standard error estimates from stratified sampling methodology is no longer present.

And, if one adopts a Bayesian perspective, the model uncertainty of the propensity-
score-estimatingequationmustberepresentedintheposterior(seeAbadieandImbens
2009; An 2010).

Even so, there is now also widespread agreement that convergence results from
nonparametricstatistics canbe usedtojustify standarderrorestimates forlargesam-
ples. A variety of scholarshavebegun to workout alternative methods for calculating
such asymptotic standard errors for matching estimators, after first rewriting match-
ing estimators as forms of nonparametric regression (see Abadie and Imbens 2006,
2011; Hahn 1998; Heckman, Ichimura, and Todd 1998; Hirano et al. 2003; Imbens
2004;Imbens andWooldridge2009).Forthese large-sampleapproaches,however,it is
permutationideasgenerateformulasforevaluatingspecificnullhypotheses,which,fromourperspec-
tive,arelargelyuncontroversial.Theyareespeciallyreasonablewhentheanalysthasdeepknowledge
of a relatively simpletreatment assignment regime and has reason to believe that treatment effects
areconstantinthepopulation.AlthoughRosenbaumprovideslarge-sampleapproximationsforthese
permutation-based tests, the connections to the recent econometrics literature that draws on non-
parametricconvergence resultshavenotyetbeenestablished.

38Many matching software routines allow one to calculate bootstrapped standard errors. This is
presumablybecausetheseeasy-to-implementmethodswereoncethoughttoprovideageneralframe-
workforestimatingthestandarderrorsofalternativematchingestimatorsandhencewereafairand
quite general way to compare the relative efficiency of alternative matching estimators (see Tu and
Zhou2002).Unfortunately,AbadieandImbens(2008)showthatconventionalbootstrappingwillnot
workfornearestneighbormatchingandrelatedestimators.Inessence,thesematchingestimatorsare
atypeoftwo-stagesamplinginwhichasetoftreatmentandcontrolcasesaresampledfirstandthen
the possible matching cases are subsampled again based on nearness to the target cases. Yet, there
istoomuchdependence between thefirstandsecondsamplingstages inthesingleobservedsample,
such that resampling within the first stage using the observed sample of target cases does not then
generatesuitablevariationamongmatchingcasesinthesecondstage.

generallyassumed that matching is performed directly with regardto the variables in
S, and the standard errors are appropriate only for large samples in which sparseness
is vanishing. Accordingly, the whole idea of using propensity scores to solve rampant
sparsenessproblemsisalmostentirelydispensedwith,andestimatedpropensityscores
thenservemerelytocleanupwhateverchancevariabilityinthedistributionofSacross
treatment and control cases remains in a finite sample.

Giventhattheliteratureonmethodstoestimatestandarderrorsformatchingesti-
mates is still developing, and that software developments lag the literature, it seems
prudent to (1) report the standard errors offered by the relevant software routines in
sufficient detail so that a reader can understand the method adopted but (2) avoid
drawingconclusionsthatdepend onacceptinganyoneparticularmethodforcalculat-
ing standard errors.

5.5.4 Matching Estimators for Many-Valued Causes
Given the prevalence of studies of many-valued causes, it is somewhat odd to place
thissectionunderthe moregeneralheadingofpracticalissues.Butthis isappropriate
because most of the complications of estimating many-valued treatment effects are
essentially practical, even though very challenging in some cases.

Recall the setup for many-valued causes from Section 2.9, where we have a set
of J treatment states, a set of J causal exposure dummy variables, {Dj}J , and a
j=1
correspondingsetofJ potentialoutcomerandomvariables,{YDj}J .Thetreatment
j=1
received by each individual is Dj(cid:2), and the outcome variable for individual i, yi, is
then equal to yDj(cid:2) . For j(cid:6)=j(cid:2), the potential outcomes of individual i exist as J−1
i
Dj
counterfactual outcomes y .

i
There are two basic approaches to matching with many-valued treatments (see
Rosenbaum 2002, section 10.2.4). The most straightforward and general approach is
to form a series of two-way comparisons between the multiple treatments, estimating
a separatepropensity scorefor eachcontrastbetweeneachpair oftreatments.39 After
theestimatedpropensityscoresareobtained,treatmenteffectestimatesarecalculated
pairwisebetweentreatments.Caremustbetaken,however,tomatchappropriatelyon
the correct estimated propensity scores. The observed outcomes for individuals with
equivalent values on alternative propensity scores cannot be meaningfully compared
(see Imbens 2000, section 5).

For example, for three treatments with J equal to 1, 2, and 3, one would first
estimate three separate propensity scores, corresponding to three contrasts for the
threecorrespondingdummyvariables:D1versusD2,D1versusD3,andD2versusD3.

39Somesimplificationofthepropensityscoreestimationispossible.Ratherthanestimatepropensity
scores separately for each pairwisecomparison, one can use multinomial probit and logit models to
estimate the set of propensity scores (see Lechner 2002a, 2002b; see also Hirano and Imbens 2004;
ImaiandvanDyk2004;Imbens2000;Zhao,vanDyk,andImai2012).Onemuststill,however,extract
the right contrasts from such a model in order to obtain an exhaustive set of estimated propensity
scores.

Onewouldobtainthreeestimatedpropensityscores:PrN[d1i=1|d1i=1ord2i=1,si],
PrN[d1i=1|d1i=1ord3i=1,si],andPrN[d2i=1|d2i=1ord3i=1,si].Onewouldthen
matchseparatelyforeachofthethreecontrastsleaving,forexample,thosewithd3i=1
unused and unmatched when matching on the propensity score for the comparison of
treatment1versustreatment2.Atnopointwouldonematchtogetherindividualswith
equivalent values for alternative estimated propensity scores.For example, there is no
meaningfulcausalcomparisonbetweentwoindividuals,inwhichforthefirstindividual
d2i=1andPrN[d1i=1|d1i=1ord2i=1,si]=.6andforthesecondindividuald3i=1
and PrN[d1i=1|d1i=1 or d3i=1,si]=.6.

When the number of treatments is of modest size, such as only four or five alter-
natives,thereismuchtorecommendinthis generalapproach.However,ifthe number
of treatments is considerably larger, then this fully general approach may be infeasi-
ble. One might then choose to simply consider only a subset of causal contrasts for
analysis, thereby reducing the aim of the causal analysis.

If the number of treatments can be ordered, then a second approachdeveloped by
Joffe and Rosenbaum (1999) and implemented in Lu, Zanutto, Hornik, and Rosen-
baum (2001) is possible. These models generally go by the name of dose-response
models because they are used to estimate the effects of many different dose sizes of
the same treatment, often in comparison with a base dosage of 0 that signifies no
treatment.

Rather than estimate separate propensity scores for each pairwise comparison,
an ordinal probability model is estimated and the propensity score is defined as a
single dimension of the predictors of the model (i.e., ignoring the discrete shifts in
the odds of increasing from one dosage level to the next that are parameterized by
the estimated cut-point parameters for each dosage level). Thereafter, one typically
performs a slightly different form of matching in which optimal matched sets are
formed by two criteria, which Lu et al. (2001:1249) refer to as “close on covariates;
far apart on doses.” The idea here is to form optimal contrasts between selected sets
of comparableindividuals to generate estimates of counterfactually defined responses.

The goal is to be able to offer a predicted response to any shift in a dosage level
from any k(cid:2) to k(cid:2)(cid:2), where both k(cid:2) and k(cid:2)(cid:2) are between the smallest and largest dosage
valuesobserved.Again,however,these methodsassumethatthe treatmentvaluescan
be ordered, and further that the propensity scores can be smoothed across dose sizes
after partialing out piecewise shifts. Even so, these assumptions are no more severe
than what is typically invoked implicitly in standard parametric regression modeling
approaches to causality, as we discuss in later chapters.

Some work has continued to examine how the rationale for propensity scores can
beusefullygeneralizedwithoutnecessarilyadoptingthefullstructureofdose-response
models. Ordered and nonordered multinomial probability models for modeling treat-
ment assignment are again the foundations of these models (see Hirano and Imbens
2004; Imai and van Dyk 2004; and Zhao et al. 2012 for further details). This litera-
ture has progressedslowly because analogs to balance checking across many values of
a treatment have not been developed, placing these particular approaches outside of
the balance-optimizing agenda that has driven the most recent research on matching
methods, as discussed in Section 5.4.2.

## 5.6 Conclusions

We conclude this chapter by discussing the strengths and weaknesses of matching as

a method for causal inference from observational data. Some of the advantages of
matching methods are not inherent or unique to matching itself but rather are the
result of the analytical framework in which most matching analyses are conducted.

Matching focuses attention on the heterogeneity of the causal effect, and it suggests
clearly why thinking separately about the ATT, ATC, and ATE is crucial. Matching
also forces the analyst to examine the alternative distributions of covariates across
those exposed to different levels of the causal variable, and it may suggest that for
someapplicationstheonlyestimatesworthinterpretationarethosethatarerestricted
to the regionof common support. Matching, as will become clear in the next chapter,
iscomparativelyconservativeinamodelingsensebecauseitdoesnotimplicitlyinvoke
the interpolation and extrapolation that characterize parametric regression models.

Althoughthesearetheadvantagesofmatching,itisimportantthatwenotoversell
the potential power of the techniques. In much of the applied literature on matching,
the propensity score is presented as a single predictive dimension that can be used to
balance the distribution of important covariates across treatment and control cases,
therebywarrantingcausalinference.Ifonedoesnotobserveandutilize variablesthat,
inaninfinitesample,wouldyieldaperfectstratification,thensimplypredictingtreat-
ment status from a more limited set of observed variables with a logit model and
then matching on the estimated propensity score does not solve the causal inference
problem.Theestimatedpropensityscoreswillbalancethosevariables(inexpectation)
across the treatment and control cases. But the study will remain open to the sort of
“hidden bias” explored by Rosenbaum (2002), which is often labeled selection on the
unobservables in the social sciences. Matching is thus a statistical method for analyz-
ingavailabledata,whichmayhavesomeadvantagesinsomesituations.Theregression
estimators that we will present in the next two chapters are complementary, and our
understanding of them has been enrichedby the matching literature presented in this
chapter.

# Chapter 6

# Regression Estimators of Causal Effects

Regressionmodels are perhaps the most commonform of data analysis used to evalu-

ate alternative explanations for outcomes of interest to quantitatively oriented social
scientists. In the past 50 years, a remarkable variety of regression models have been
developed by statisticians. Accordingly, most major data analysis software packages
allow for regression estimation of the relationships between interval and categorical
variables, in cross sections and longitudinal panels, and in nested and multilevel pat-
terns. In this chapter, however, we restrict our attention to ordinary least squares
(OLS) regression,focusing mostly onthe regressionofan interval-scaledvariable ona
binary causal variable. As we will show, the issues are complicated enough for these
models, and it is our knowledge of how least squares models work that allows us to
explain this complexity. In addition, nearly all of the insight that can be gained from
a deep examination of OLS models carries over to more complex regression models
becausetheidentificationandheterogeneityissuesthatgeneratethecomplexityapply
in analogous fashion to all regression-type models.

Inthischapter,wepresentleastsquaresregressionfromthreedifferentperspectives:
(1)regressionasadescriptivemodelingtool,(2)regressionasaparametricadjustment
technique for estimating causal effects, and (3) regression as a matching estimator of
causal effects. We give more attention to the third of these three perspectives on
regression than is customary in methodological texts because this perspective allows
one to understand the others from a counterfactual perspective. At the end of the
chapter, we will draw some of the connections between least squares regression and
more general models, and we will discuss the estimation of causal effects for many-
valued causes.

## 6.1 Regression as a Descriptive Tool

Least squares regressioncan be justified without reference to causality because it can

be considered nothing more than a method for obtaining a best-fitting descriptive
188
model under entailed linearity constraints. Goldberger (1991),for example, motivates
least squares regressionas a technique to estimate a best-fitting linear approximation
to a conditional expectation function that may be nonlinear in the population.

Consider this descriptive motivation of regression a bit more formally. If X is a
collectionof variablesthat are thought to be associatedwith Y in some way,then the
conditional expectation function of Y, viewed as a function in X, is denoted E[Y|X].

Each particular value of the conditional expectation for a specific realization x of X
is then denoted E[Y|X=x].

Least squares regressionyields a predicted surface Yˆ =Xβˆ, where βˆ is a vector of
estimatedcoefficientsfromtheregressionoftherealizedvaluesyi onxi.Thepredicted
surface, Xβˆ, does not necessarily run through the specific points of the conditional
expectation function, even for an infinite sample, because (1) the conditional expec-
tation function may be a nonlinear function in one or more of the variables in X and
(2) a regression model can be fit without parameterizing all nonlinearities in X. An
estimated regression surface simply represents a best-fitting linear approximation of
E[Y|X]under whateverlinearity constraintsareentailed by the chosenparameteriza-
tion of the estimated model.1
The following demonstration of this usage of regression is simple. Most readers
know this material well and can skip ahead to the next section. But, even so, it may
be worthwhile to read the demonstration quickly because we will build directly on it
when shifting to the consideration of regression as a causal effect estimator.

Regression Demonstration 1
Recall the stratificationexample presented as Matching Demonstration1 (see Section
5.2.1, page 145). Suppose that the same data are being analyzed, as generated by
the distributions presented in Tables 5.1 and 5.2; features of these distributions are
reproduced in Table 6.1 in more compact form. As before, assume that well-defined
causalstatescontinuetoexistandthatS servesasaperfectstratificationofthedata.2
Accordingly,theconditionalexpectationsinthelastthreepanelsofTable6.1areequal
as shown.

But, for this demonstration of regression as a descriptive tool, suppose that a
cautious researcher does not wish to rush ahead and attempt to estimate the specific
underlying causal effect of D on Y, either averaged across all individuals or averaged
across particular subsets of the population. Instead, the researcher is cautious and
is willing to assert only that the variables S, D, and Y constitute some portion of a
largersystemofcausalrelationships.Inparticular,theresearcherisunwillingtoassert
anything about the existence or nonexistence of other variables that may also lie on
the directed paths that reach D and Y. This is tantamount to doubting the claim
that S offers a perfect stratification of the data, even though that claim is true by
construction for this example.

1Onecanfitalargevarietyofnonlinearsurfaceswithregressionbyartfulparameterizationsofthe
variablesinX,butthesesurfacesarealwaysgeneratedbyalinearcombinationofacoefficientvector
andvaluesonsomewell-definedcodingofthevariablesinX.

2For this section, we will also stipulate that the conditional variances of the potential outcomes
areconstant acrossbothofthepotential outcomes andacrosslevelsofS.

Table 6.1 The Joint Probability Distribution and
Conditional Population Expectations for Regression
Demonstration 1
Joint probability distribution of S and D
Control group: D=0 Treatment group: D=1
S=1 Pr[S=1,D=0]=.36 Pr[S=1,D=1]=.08
S=2 Pr[S=2,D=0]=.12 Pr[S=2,D=1]=.12
S=3 Pr[S=3,D=0]=.12 Pr[S=3,D=1]=.2
Potential outcomes underthecontrol state
S=1 E[Y0|S=1,D=0]=2 E[Y0|S=1,D=1]=2
S=2 E[Y0|S=2,D=0]=6 E[Y0|S=2,D=1]=6
S=3 E[Y0|S=3,D=0]=10 E[Y0|S=3,D=1]=10
Potential outcomes underthe treatment state
S=1 E[Y1|S=1,D=0]=4 E[Y1|S=1,D=1]=4
S=2 E[Y1|S=2,D=0]=8 E[Y1|S=2,D=1]=8
S=3 E[Y1|S=3,D=0]=14 E[Y1|S=3,D=1]=14
Observed outcomes
S=1 E[Y|S=1,D=0]=2 E[Y|S=1,D=1]=4
S=2 E[Y|S=2,D=0]=6 E[Y|S=2,D=1]=8
S=3 E[Y|S=3,D=0]=10 E[Y|S=3,D=1]=14
Inthissituation,supposethattheresearchersimplywishestoestimatethebestlin-
earapproximationtotheconditionalexpectationE[Y|D,S]anddoesnotwishtothen
give a causal interpretation to any of the coefficients that define the linear approx-
imation. The six true values of E[Y|D,S] are given in the last panel of Table 6.1.

Notice that the linearity of E[Y|D,S] in D and S is present only when S≤2. The
value of14for E[Y|D=1,S=3]makesE[Y|D,S] nonlinearinD andS overtheir full
distributions.

Now consider the predicted surfaces that would result from the estimation of two
alternativeleastsquaresregressionmodels with data froma sample ofinfinite size (to
render sampling errorzero).A regressionof Y on D and S that treats D as a dummy
variable and S as an interval-scaled variable would yield a predictive surface of
Yˆ =−2.71+2.69(D)+4.45(S). (6.1)
This model constrains the partial association between Y and S to be linear. It rep-
resents a sensible predicted regression surface because it is a best-fitting, linear-in-
the-parameters model of the association between Y and the two variables D and S,
where “best” is defined as minimizing the average squared differences between the
fitted values and the true values of the conditional expectation function.

For this example, one can offer a better descriptive fit at little interpretive costby
usinga more flexible parameterizationofS. An alternativeregressionthattreats S as
a discrete variable represented in the estimation routine by dummy variables S2 and
S3(for S equalto 2 andS equal to 3, respectively)wouldyieldapredictive surfaceof
Yˆ =1.86+2.75(D)+3.76(S2)+8.92(S3). (6.2)
Like the predicted surface for the model in Equation (6.1), this model is also a best
linear approximation to the six values of the true conditional expectation E[Y|D,S].

The specific estimated values are
D=0,S=1: Yˆ =1.86,
D=0,S=2: Yˆ =5.62,
D=0,S=3: Yˆ =10.78,
D=1,S=1: Yˆ =4.61,
D=1,S=2: Yˆ =8.37,
D=1,S=3: Yˆ =13.53.

IncontrasttothemodelinEquation(6.1),forthismodelthevariableS isgivenafully
flexiblecoding.As aresult,parametersarefitthatuniquely representallvaluesof S.3
The predicted change in Y for a shift in S from 1 to 2 is 3.76 (i.e., 5.62−1.86=3.76
3The difference between a model in which a variable is given a fully flexible coding and one in
whichitisgivenamoreconstrainedcodingisclearerforasimplerconditional expectation function.

ForE[Y|S],considerthevaluesinthecellsofTable6.1.ThethreevaluesofE[Y|S]canbeobtained
fromthefirstandfourthpanelsofTable6.1asfollows:
.36 .08
E[Y|S=1]= (2)+ (4)=2.36,
(.36+.08) (.36+.08)
.12 .12
E[Y|S=2]= (6)+ (8)=7,
(.12+.12) (.12+.12)
.12 .2
E[Y|S=3]= (10)+ (14)=12.5.

(.12+.2) (.12+.2)
NoticethatthesethreevaluesofE[Y|S]donotfallonastraightline;themiddlevalueof7iscloser
to2.36thanitisto12.5.

For E[Y|S],a least squares regression of Y on S, treating S as an interval-scaled variable, would
yieldapredictivesurfaceof
Yˆ=−2.78+5.05(S).

Thethreevaluesofthisestimatedregressionsurfacelieonastraightline−2.27,7.32,and12.37–and
theydonotmatchthecorrespondingtruevaluesof2.36,7,and12.5.AregressionofY onS,treating
SasadiscretevariablewithdummyvariablesS2andS3,wouldyieldanalternativepredictivesurface
of
Yˆ=2.36+4.64(S2)+10.14(S3).

This second model uses a fully flexible coding of S, and each value of the conditional expectation
function is a unique function of the parameters in the model (that is, 2.36=2.36, 4.64+2.36=7,
and 10.14+2.36=12.5). Thus, in this case, the regression model would, in a suitably large sample,
estimatethethreevaluesofE[Y|S]exactly.

and 8.37−4.61=3.76), whereas the predicted change in Y for a shift in S from 2 to
3 is 5.16 (i.e., 10.78−5.62=5.16 and 13.53−8.37=5.16).

Even so, the model in Equation (6.2) constrains the parameter for D to be the
same without regard to the value of S. And, because the level of Y depends on the
interaction of S and D, specifying more than one parameter for the three values of S
does not bring the predicted regression surface into alignment with the six values of
E[Y|D,S] presented in the last panel of Table 6.1. Thus, even when S is given a fully
flexible coding (and evenfor aninfinitely largesample), the fitted values do not equal
the true values of E[Y|D,S].4 As we discuss later, a model that is saturated fully in
both S and D – that is, one that adds two additional parameters for the interactions
between D and both S2 and S3 – would yield predicted values that would exactly
match the six true values of E[Y|D,S] in a dataset of sufficient size.

Recallthe moregeneralstatement ofthe descriptivemotivationofregressionanal-
ysis presented above, in which the predicted surface Yˆ =Xβˆ is estimated for the sole
purposeofobtainingabest-fitting linearapproximationtothetrueconditionalexpec-
tation function E[Y|X]. When the purposes of regression are so narrowly restricted,
the outcomevariableofinterest,Y, isnotgenerallythoughttobeafunctionofpoten-
tial outcomes associated with well-defined causal states. Consequently, it would be
inappropriate to give a causal interpretation to any of the estimated coefficients in βˆ.

This perspective implies that if one were to add more variables to the predictors,
embedding X in a more encompassing set of variables W, then a new set of least
squares estimates γˆ could be obtained by regressing Y on W. The estimated surface
Wγˆ then represents a best-fitting, linear-in-the-parameters, descriptive fit to a more
encompassing conditional expectation function, E[Y|W]. Whether one then prefers
Wγˆ to Xβˆ as a description of the variation in Y depends on whether one finds it
more useful to approximate E[Y|W] than E[Y|X]. The former regressionapproxima-
tion is often referred to as the long regression, with the latter representing the short
regression.These labels are aptly chosen, when regressionis considered nothing more
than a descriptive tool, because there is no inherent reasonto prefer a short to a long
regression if neither is meant to be interpreted as anything other than a best-fitting
linear approximation to its respective true conditional expectation function.

In many applied regression textbooks, the descriptive motivation of regression
receives no direct explication. And, in fact, many textbooks state that the only cor-
rect specification of a regression model is one that includes all explanatory variables.

Goldberger (1991) admonishes such textbook writers, countering their claims:
4Why would one ever prefer a constrained regression model of this sort? Consider a conditional
expectation function,E[Y|X],whereY isearningsandX isyearsofeducation(with21valuesfrom
0to20).AfullyflexiblecodingofX wouldfit20dummyvariablesforthe21valuesofX.Thiswould
allow the predicted surface to change only modestly between some years (such as between 7 and 8
andbetween12and13)andmoredramaticallybetweenotheryears(suchasbetween11and12and
between 15 and 16). However, one might wish to treat X as an interval-scaled variable, smoothing
these increases from year to year by constraining them to a best-fitting line parameterized only by
anintercept andaconstant slope.Thisconstrained modelwouldnot fittheconditional expectation
functionascloselyasthemodelwith20dummyvariables,butitmightbepreferredinsomesituations
because it is easier to present and uses fewer degrees of freedom, which could be important if the
modelisestimatedwithasmallsample.

An alternative position is less stringent and is free of causal language.

Nothinginthe CR[classicalregression]modelitselfrequiresanexhaustive
list of explanatory variables, nor any assumption about the direction of
causality. (Goldberger 1991:173)
Goldberger is surely correct, but his perspective nonetheless begs an important ques-
tionontheultimateutilityofdescriptivelymotivatedregression.Clearly,ifonewishes
to know only predicted values of the outcome Y for those not originally studied but
whose variables in X are known, then being able to form the surface Xβˆ is a good
firststep (andperhaps a goodlaststep). And, if one wishes to build a moreelaborate
regressionmodel, allowing for an additional variable in W or explicitly accounting for
multilevel variability by modeling the nested structure of the data, then regression
results will be useful if the aim is to generate descriptive reductions of the data. But,
if one wishes to know the value of Y that would result for any individual in the pop-
ulation if a variable in X were shifted from a value k to a value k(cid:2), then regression
results may be uninformative.

Many researchers (perhaps a clear majority) who use regression models in their
research are very much interested in causal effects. Knowing the interests of their
readers, many textbook authors offer presentations of regression that sidestep these
issuesartfullyby,forexample,discussinghowbiasedregressioncoefficientsresultfrom
the omissionofimportant explanatoryvariables but without introducing explicit, for-
mal notions of causality into their presentations. Draper and Smith (1998:236), for
example,write of the bias that enters into estimated regressioncoefficients when only
a subset of the variables in the “true response relationship” are included in the fit-
ted model. Similarly, Greene (2000:334) writes of the same form of bias that results
from estimating coefficients for a subset of the variables from the “correctly specified
regressionmodel.”5 And, in his presentation of regressionmodels for social scientists,
Stolzenberg (2004:188)equivocates:
Philosophical arguments about the nature of causation notwithstanding
(see Holland, 1986), in most social science uses of regression, the effect of
anindependentvariableonadependentvariableistherate atwhichdiffer-
encesintheindependentvariableareassociatedwith(orcause)differences
or changes in the dependent variable. (italics in the original)
Weassumethatthereadersofourbookareinterestedincausaleffectestimators.And
thus,althoughwerecognizetheclassicalregressiontradition,perhapsbestdefendedby
Goldberger(1991)asinterpretablemerelyasadescriptivedatareductiontool,wewill
considerregressionasacausaleffectestimatorintheremainingsectionsofthischapter.

And we further note that, in spite of our reference to Goldberger (1991), in other
writingGoldbergerhasmadeitabsolutelyclearthathetoowasverymuchinterestedin
theproperusageofregressionmodelstoofferwarrantedcausalclaims.Thisisperhaps
most clear in work in which he criticized what he regarded as unwarranted causal
claims generated by others using regression techniques, such as in his robust critique
ofColeman’sCatholicschoolsresearch(seeGoldbergerandCain1982).Wewillreturn
5Thereare,ofcourse,othertextbooksthatdopresentamorecompleteperspective,suchasAngrist
andPischke(2009), Berk(2004), Freedman(2005), andGelmanandHill(2007).

toadiscussionofthe notionofacorrectspecificationofaregressionmodelinthefinal
section of the chapter, where we discuss the connections between theoretical models
and regressions as all-cause perfect specifications. Until then, however, we return to
the same basic scenario considered in our presentation of matching in Chapter 5: the
estimation of a single causal effect that may be confounded by other variables.

## 6.2 Regression Adjustment as a Strategy to Estimate Causal Effects

In this section, we consider the estimation of causal effects in which least squares

regressionisusedto adjustfor variablesthoughtto be relatedto boththe causalvari-
ableandtheoutcomevariable.Wefirstconsiderthetextbooktreatmentoftheconcept
ofomitted-variablebias,withwhichmostreadersareprobablywellacquainted.There-
after,weconsiderthesamesetofideasafterspecifyingthepotentialoutcomevariables
that the counterfactual tradition assumes lie beneath the observed data.

6.2.1 Regression Models and Omitted-Variable Bias
Suppose that one is interested in estimating the causal effect of a binary variable D
on an observed outcome Y. This goal can be motivated as an attempt to obtain a
consistent and unbiased estimate of a coefficient δ in a generic bivariate regression
equation,
Y =α+δD+ε, (6.3)
where α is an intercept and ε is a summary random variable that represents all other
causes of Y (some of which may be related to the causal variable of interest, D).

When Equation (6.3) is used to represent the causal effect of D on Y without any
reference to individual-varying potential outcomes, the parameter δ is implicitly cast
as an invariant, structural causal effect that applies to all members of the population
of interest.6
The OLS estimator of this bivariate regression coefficient is then
CovN(yi,di)
δˆ OLS,bivariate≡ , (6.4)
VarN(di)
whereCovN(.) andVarN(.)areconsistentandunbiased,sample-basedestimates from
a sample of size N of the population-level covariance and variance of the variables
that are their arguments.7 Because D is a binary variable, δˆ OLS,bivariate is exactly
equivalentto the naive estimator,EN[yi|di=1]−EN[yi|di=0],presentedin Equation
6Althoughthisisgenerallythecase,thereareofcourseintroductionstoregressionthatexplicitly
define δ as the mean effect of D on Y across units in the population of interest or, as was noted in
thelastsection, withoutregardtocausalityatall.

7Notice that we are again focusing on the essential features of the methods. When we present
least squares regression estimators in this chapter, we will maintain three implicit assumptions to
simplifyinferencecomplications inordertofocus onidentification issues.First,weignoredegree-of-
freedom adjustments because weassumethat the availablesampleis verylarge. Tobemoreprecise
in justifying unbiasedness for a finite sample, we would want to indicate that the sample variance
of D does not equal the population-level variance of D in the absence of such a degree-of-freedom
(2.9) (i.e., the sample mean of yi for those in the treatment group minus the sample
mean of yi for those in the control group). Our analysis thus follows quite closely the
discussion of the naive estimator in Section 2.7.3. The difference is that here we will
develop the same basic claims with reference to the relationship between D and ε
rather than the general implications of heterogeneity of the causal effect.

Consider first a case in which D is randomly assigned, as when individuals are
randomly assigned to the treatment and control groups. In this case, D would be
uncorrelatedwith ε in Equation(6.3), even though there may be a chance correlation
betweenDandεinanyfinitesetofstudysubjects.8Theliteratureonregression,when
presented as a causal effect estimator, maintains that, in this case, (1) the estimator
δˆ OLS,bivariate is consistent and unbiased for δ in Equation (6.3) and (2) δ can be
interpreted as the causal effect of D on Y.

To understand this claim, it is best to consider a counterexample in which D is
correlated with ε in the population because D is correlated with other causes of Y
that are implicitly embedded in ε. For a familiar example, consider again the effect
of education on earnings. Individuals are not randomly assigned to the treatment
“completed a bachelor’s degree.” It is generally thought that those who complete
college would be more likely to have had high levels of earnings in the absence of a
collegeeducation.Ifthisistrue,D andthepopulation-levelerrortermεarecorrelated
because those who have a 1 on D are more likely to have high values rather than low
values for ε. For this example, the least squares regression estimator δˆ OLS,bivariate in
Equation (6.4) would not yield an estimate of δ that can be regardedas consistent or
unbiased for the causal effect of D on Y. Instead, δˆ OLS,bivariate must be interpreted
as inconsistent and upwardly biased. In the substance of the college-degree example,
δˆ OLS,bivariate would be a poor estimate of the causal effect of a college degree on
adjustment,andsoon.WemerelylabelVarN(.)assignifyingsuchaconsistentandunbiasedestimate
ofthe population-level-variance of that whichisits argument. Thus,VarN(.)implicitlyincludes the
properdegree-of-freedomadjustment,whichwouldbeN/(N−1)andwhichwouldthenbemultiplied
bytheaverageofsquareddeviationsfromthesamplemean.Second,wewillassumethatthesampling-
errorcomponents oftheregressionerrortermshave“zeroconditional mean”; seeWooldridge(2010,
equation4.3);seealsothe“strictexogeneity”assumptionofHayashi(2000,equation1.1.7).Underthis
assumption,thefinitesamplebiasoftheOLSestimatorofeachcoefficienthasexpectationequalto0,
eventhoughweallowthepredictorstoberandomvariablesratherthanafixedfeatureofthedesign.

As will become clear, we will have a lot to say about assumptions regarding regression error terms
inthischapter, and fornow weinvokethis assumptiononlyinthe limitedsensethatitallowsusto
eliminatefinitesamplebiasfromourconsideration.Third,ourperfectmeasurementassumptionrules
out measurement error in predictors, which eliminates attenuation bias in all regression coefficient
estimates.

8WewillfrequentlyrefertoDandεasbeinguncorrelatedforthistypeofassumption,asthisisthe
semanticsthatmostsocialscientistsseemtouseandunderstandwhendiscussingtheseissues.Most
textbook presentations ofregressiondiscussveryspecificexogeneity assumptionsforD thatimplya
correlationof 0between D and ε.Usually,inthe social sciences the assumptionis defined either by
meanindependenceofDandεorasanassumedcovarianceof0betweenDandε.Bothoftheseimply
acorrelationbetweenDandεof0.Instatistics,oneoftenfindsastrongerassumption:Dandεmust
becompletelyindependentofeachother.Theargumentinfavorofthisstrongerassumption,whichis
convincingtostatisticians,isthataninferenceisstrongestwhenitholdsunderanytransformationof
Y (andthusanytransformationofε).WhenfullindependenceofDandεholds,meanindependence
ofD andε,acovarianceof0betweenD andε,anda0correlationbetweenD andεareallimplied.

ε
D Y D Y
(a) A graph in which the (b) An equivalent regression
casual effect is not identified representation of the same graph
Figure 6.1 Graphs for a regressionequation of the causal effect of D on Y.

earningsbecauseitwouldsuggestthatthe effectofobtainingacollegedegreeislarger
than it really is.9
Figure 6.1(a) presents a graph where D and Y are connected by two types of
paths, the direct causal effect D→Y and an unspecified number of back-door paths
representedby D(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)Y. (Recall that bidirectededges(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)representan unspec-
ified number of common causes of the two variables that they connect.) For Figure
6.1(a),the causaleffectofD onY isnotidentifiedbecausenoobservablevariablesare
available to block the back-door paths represented by D(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)Y.

Figure 6.1(b) is the regression analog to the graph in Figure 6.1(a). It contains
three edges: D→Y, ε→Y, and D(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)ε, where the node for ε is represented by a
hollow circle ◦ rather than a solidcircle • in orderto indicate that ε is an unobserved
variable.Theunblockedback-doorpathsfromD toY nowrunthroughtheerrorterm
ε, and the dependence represented by the bidirected edge confounds the causal effect
of D on Y. Bivariate regression results, when interpreted as warranted causal effect
estimates, assume that there are no such unblocked back-door paths from the causal
variable to the outcome variable.

For many applications in the social sciences, a correlation between D and ε is
conceptualized as a problem of omitted variables. For the example in this section,
a bivariate OLS estimate of the effect of a college degree on labor market earnings
would be said to be biased because intelligence is unobserved but is correlated with
both education and earnings. Its omission from Equation (6.3) leads the estimate of
the effectofacollegedegreeonearningsfromthatequationtobe largerthanitwould
have been if a variable for intelligence were instead included in the equation.

Thisperspective,however,hasledtomuchconfusion,especiallyincasesinwhicha
correlationbetweenDandεemergesbecausesubjectschoosedifferentlevelsofDbased
on their expectations about the variability of Y, and hence their own expectations of
the causal effect itself. For example, those who attend college may be more likely
to benefit from college than those who do not, even independent of the unobserved
ability factor. Although this latent form of anticipation can be labeled an omitted
9Consider for one last time the alternative and permissible descriptive interpretation: The least
squares regression estimator δˆ OLS,bivariate in Equation (6.4) could be interpreted as consistent and
unbiased for δ, where the regression surface generated by the estimation of δ in Equation (6.3)
is considered only a descriptively motivated, best linear prediction of the conditional expectation
function, E[Y|D] (i.e., where αˆ is a consistent and unbiased for E[Y|D=0] and αˆ+δˆis consistent
andunbiasedforE[Y|D=1]).Inthesubstanceofthecollege-degreeexample,theestimatecouldbe
regarded as an estimate of the mean difference between the earnings of those who have obtained a
collegedegreeandthosewhohavenot,withoutrequiringorwarrantinganycausalinterpretation.

variable, it is generally not. Instead, the language of research shifts toward notions
suchas self-selectionbias, and this is less comfortable territoryfor the typicalapplied
researcher.

To clarify the connections between omitted-variable bias and self-selection bias
within a more general presentation, we utilize the potential outcome model in the
nextsection.WebreaktheerrorterminEquation(6.3)intocomponentpiecesdefined
by underlying potential outcome variables and allow for the more general forms of
causaleffectheterogeneitythatareimplicitlyruledoutbyconstant-coefficientmodels.

6.2.2 Potential Outcomes and Omitted-Variable Bias
Considerthe same set of ideas but now use the potentialoutcome model to define the
observedvariables.Here,wewillbuilddirectlyonthevariantofthepotentialoutcome
modelpresentedinSection4.3.2.Fromthatpresentation,recallEquation(4.6),which
we reintroduce here as
Y =μ0+(μ1−μ0)D+{υ0+D(υ1−υ0)}, (6.5)
whereμ0≡E[Y0],μ1≡E[Y1],υ0≡Y0−E[Y0],andυ1≡Y1−E[Y1].Wecouldrewrite
this equation to bring it into closer alignment with Equation (6.3) by stipulating that
α=μ0, δ=(μ1−μ0), and ε= υ0+D(υ1−υ0). But note that these equalities would
redefine what is typically meant by the terms α, δ, and ε in Equation (6.3). The
parametersα and δ in Equation(6.3) are usually not consideredto be equal to E[Y0]
or E[δ] for two reasons: (1) models are usually asserted in the regression tradition
(e.g., in Draper and Smith 1998) without any reference to underlying causal states
tied to potential outcomes and (2) the parameters α and δ are usually implicitly held
to be constant structural effects that do not vary over individuals in the population.

Similarly,theerrorterm,ε,inEquation(6.3)isalmostneverseparatedintotwopieces
as a function of the definition of potential outcomes and their relationship to D. For
thesereasons,Equation(6.5)isquitedifferentfromthetraditionalbivariateregression
in Equation (6.3), in the sense that it is more finely articulated but also irretrievably
tied to a particular formalization of a causal effect that is allowed to vary across
individuals.

Suppose that we are interested in estimating the average treatment effect (ATE),
denoted(μ1−μ0)here.ThecausalvariableDcouldbecorrelatedwiththepopulation-
levelvariantoftheerrortermυ0+D(υ1−υ0)inEquation(6.5)intwoways.First,sup-
posethatthere is anetbaselinedifference inthe hypotheticalno-treatmentstate that
is correlated with membership in the treatment group, but the size of the individual-
leveltreatment effect does notdiffer on averagebetweenthose inthe treatmentgroup
andthoseinthecontrolgroup.Inthiscase,υ0 wouldbecorrelatedwithD,generating
a correlation between {υ0+D(υ1−υ0)} and D, even though the D(υ1−υ0) term in
{υ0+D(υ1−υ0)} would be equal to zero on average because υ1−υ0 does not vary
with D. Second, suppose there is a net treatment effect difference that is correlated
withmembershipinthe treatmentgroup,butthereisnonetbaselinedifferenceinthe
absence of treatment. Now, D(υ1−υ0) would be correlated with D, even though υ0
is not, because the average difference in υ1−υ0 varies across those in the treatment
Table 6.2 Examples of the Two Basic Forms of Bias for Least Squares
Regression
Differential baseline bias only
y i1 y i0 υ i1 υ i0 yi di υ i0+di(υ1 i−υ0 i)
In treatment group 20 10 0 5 20 1 0
In control group 20 0 0 −5 0 0 −5
Differential treatment effect bias only
y i1 y i0 υ i1 υ i0 yi di υ i0+di(υ1 i−υ0 i)
In treatment group 20 10 2.5 0 20 1 2.5
In control group 15 10 −2.5 0 10 0 0
Both typesof bias
y i1 y i0 υ i1 υ i0 yi di υ i0+di(υ1 i−υ0 i)
In treatment group 25 5 5 −2.5 25 1 5
In control group 15 10 −5 2.5 10 0 2.5
groupandthose in the controlgroup.In either case,anOLSregressionofthe realized
values of Y on D would yield an inconsistent and biased estimate of (μ1−μ0).

Itmaybehelpfultoseepreciselyhowthesesortsofbiascomeaboutwithreference
to the potential outcomes of individuals. Table 6.2 presents three simple two-person
examples in which the least squares bivariate regression estimator δˆ OLS,bivariate in
Equation (6.4) is biased. Each panel presents the potential outcome values for two
individuals and then the implied observed data and error term in the braces from
Equation(6.5).Assumeforconveniencethatthereareonlytwotypesofindividualsin
the population, both of which are homogeneous with respect to the outcomes under
study and both of which comprise one half of the population. For the three examples
in Table 6.2, we have sampled one of each of these two types of individuals for study.

For the example in the first panel, the true ATE is 15, because for the individual
in the treatment group δi is 10, whereas for the individual in the control group δi is
20. The values of υ1 and υ0 are deviations of the values of y1 and y0 from E[Y1] and
i i i i
E[Y0],respectively.Becausetheseexpectationsareequalto 20and5,the values ofυ1
i
are both equal to 0 because each individual’s value of y1 is equal to 20. In contrast,
i
the valuesofυ0 areequalto 5and−5fortheindividuals inthetreatmentandcontrol
i
groups, respectively, because their two values of y0 are 10 and 0.

i
As noted earlier, the bivariate regression estimate of the coefficient on D is equal
to the naive estimator, EN[yi|di=1]−EN[yi|di=0]. Accordingly, a regression of the
values for yi on di would yield a value of 0 for the intercept and a value of 20 for
the coefficientonD.Thisestimatedvalueof20is anupwardlybiasedestimateforthe
true average causal effect because the values of di are positively correlated with the
values of the error term υ i0+di(υ i1−υ i0). In this case, the individual with a value of 1
for di has a value of 0 for the error term, whereas the individual with a value of 0 for
di has a value of −5 for the error term.

Fortheexampleinthesecondpanel,therelevantdifferencebetweentheindividual
in the treatment group and the individual in the control group is in the value of y1
i
rather than y0. In this variant, both individuals would have had the same outcome if
i
they were both in the control state, but the individual in the treatment group would
benefit relatively more from being in the treatment state. Consequently, the values
of di are correlated with the values of the error term in the last column because the
true treatment effect is larger for the individual in the treatment group than for the
individual in the control group. A bivariate regression would yield an estimate of 10
for the ATE, even though the true ATE is only 7.5 in this case.10
Finally, in the third panel of the table, both forms of baseline and net treatment
effect bias are present, and in opposite directions. In combination, however, they still
generate a positive correlationbetween the values of di and the error term in the last
column.Thispatternresultsinabivariateregressionestimateof15,whichisupwardly
biased for the true ATE of 12.5.

Forsymmetry,andsomeadditionalinsight,nowconsidertwoadditionaltwo-person
examples in which regression gives an unbiased estimate of the average causal effect.

For the first panel of Table 6.3, the potential outcomes are independent of D, and as
a result a bivariate regressionof the values yi on di would yield an unbiased estimate
of 10 for the true ATE. But the example in the second panel is quite different. Here,
the values of υ i1 and υ i0 are each correlated with the values of di, but they cancel
each other out when they jointly constitute the error term in the final column. Thus,
a bivariate regression yields an unbiased estimate of 0 for the true ATE of 0. And,
yet, with knowledge of the values for y1 and y0, it is clear that these results mask
i i
important heterogeneity of the causal effect. Even though the average causal effect is
indeed0,the individual-levelcausaleffectsareequalto10and−10fortheindividuals
inthetreatmentgroupandcontrolgroup,respectively.Thus,regressiongivestheright
answer,butithidestheunderlyingheterogeneitythatonewouldalmostcertainlywish
to know.11
Having considered these examples, we are now in a position to answer, with refer-
ence to the potential outcome model, the question that so often challenges students
whenfirstintroducedtoregressionasacausaleffectestimator:Whatistheerrorterm
ofaregressionequation?Comparethethirdandfourthcolumnswiththefinalcolumn
in Tables 6.2 and 6.3. The regression error term, υ0+D(υ1−υ0), is equal to υ0 for
those in the control group and υ1 for those in the treatment group. This can be seen
without reference to the examples in the tables. Simply rearrange υ0+D(υ1−υ0) as
10Note,however,that10isthetrueaveragetreatmenteffectforthetreated(ATT),orinthiscase
the treatment effect for the treated for the sole individual inthe treatment group. This is the same
essentialpatternasforMatchingDemonstration4,wheretheATTisidentifiedbecause,inthiscase,
Assumption2inEquation(2.16)wouldholdbecause(y i0|d i=1)=(y i0|d i=0)=10.

11Assumptions1and2inEquations(2.15)and(2.16)arethereforesufficientbutnotnecessaryfor
thenaiveestimatorandbivariateOLSregressionestimatortoconsistentlyestimatetheATE.Wehave
notmentionedthisqualificationuntilnowbecausewedonotbelievethatperfectcancellationoccursin
socialscienceapplications.Thisassumptionissometimeslabeled“faithfulness”inthecounterfactuals
literature.

Table 6.3 Two-PersonExamples in Which Least Squares Regression
Estimates Are Unbiased
Independenceof (Y1,Y0) from D
y i1 y i0 υ i1 υ i0 yi di υ i0+di(υ1 i−υ0 i)
In treatment group 20 10 0 0 20 1 0
In control group 20 10 0 0 10 0 0
Offsetting dependenceof Y1and Y0 on D
y i1 y i0 υ i1 υ i0 yi di υ i0+di(υ1 i−υ0 i)
In treatment group 20 10 5 −5 20 1 5
In control group 10 20 −5 5 20 0 5
Dυ1+(1−D)υ0 and then rewrite Equation (6.5) as
Y =μ0+(μ1−μ0)D+{Dυ1+(1−D)υ0}. (6.6)
It should be clear that the error term now appears very much like the definition of Y
presentedearlierasDY1+(1−D)Y0inEquation(2.2).JustasY switchesbetweenY1
andY0asafunctionofD,theerrortermswitchesbetweenυ1andυ0asafunctionofD.

Giventhatυ1andυ0canbeinterpretedasY1andY0centeredaroundtheirrespective
population-level expectations E[Y1] and E[Y0], this should not be surprising.

Even so, few presentations of regression characterize the error term of a bivariate
regression in this way. Some notable exceptions do exist. The connection is made to
the counterfactual tradition by specifying Equation (6.3) as
Y =α+δD+ε (D), (6.7)
where the error term ε (D) is considered to be an entirely different random variable
for each value of D (see Pratt and Schlaifer 1988). Consequently, the error term ε in
Equation(6.3)switchesbetweenε andε inEquation(6.7)depending onwhether
(1) (0)
D is equal to 1 or 0.12
6.2.3 Regression as Adjustment for Otherwise
Omitted Variables
The basic strategy behind regressionanalysis as an adjustment technique to estimate
acausaleffectistoaddasufficientsetof“controlvariables”tothebivariateregression
in Equation (6.3). The goal is to break a correlation between the treatment variable
12This is the same approach taken by Freedman (see Berk 2004; Freedman 2005), and he refers
to Equation (6.7) as a response schedule. See also the discussion of Sobel (1995). For a continuous
variable,Garen(1984)notesthattherewouldbeaninfinitenumberoferrorterms(seehisdiscussion
ofhisequation10).

ε∗
X
D Y
Figure6.2 A causal graph for a regression equation in which the causal effect of D
on Y is identified by conditioning on X.

D and the error term ε, as in
∗
Y =α+δD+Xβ+ε , (6.8)
where X represents one or more variables, β is a coefficient (or a conformable vector
of coefficients if X represents more than one variable), ε∗ is a residualized version of
the original error term ε from Equation (6.3), and all else is as defined for Equation
(6.3).

Forthemultipleregressionanalogtotheleastsquaresbivariateregressionestimator
δˆ OLS,bivariate inEquation(6.4),theobserveddatavaluesdi andxi areembeddedinan
all-encompassing Q matrix, which is N × K, where N is the number of respondents
and K is the number of variables in X plus 2 (one for the constant and one for the
treatment variable D). The OLS estimator for the parameters in Equation (6.8) is
then written in matrix form as
δˆ OLS,multiple≡(Q(cid:2) Q)−1Q(cid:2) y, (6.9)
where y is an N × 1 vector for the observed outcomes yi. As all regressiontextbooks
show, there is nothing magical about these least squares computations, even though
the matrix representation may appear unfamiliar to some readers. OLS regression is
equivalentto the followingthree-stepregressionprocedurewith referenceto Equation
(6.8) – and without reference to the perhaps overly compact Equation (6.9):
1. Regress yi on xi and calculate y i∗=yi−yˆi;
2. Regress di on xi and calculate d∗ =di−dˆ i;
i
3. Regress y∗ on d∗.

i i
Theregressioncoefficientond∗ yieldedbystep3isthe OLSestimate ofδ inEquation
i
(6.8), which is typically declaredconsistent and unbiased for the true value of δ if the
correlation between D and ε∗ is assumed to be equal to zero. Thus, in this simple
example, OLS regression is equivalent to estimating the relationship between residu-
alized versions of Y and D from which their common dependence on other variables
in X has been “subtracted out.”
Even though the variables in X might be labeled control variables in a regression
analysis of a causal effect, this label expresses the intent rather than the outcome of
their utilization. The goalof such a regressionadjustment strategy is to find variables
in X that can be used to redraw the graph in Figure 6.1(b) as the causal graph in
Figure 6.2. If this can be done, then one can condition on X in order to consistently
estimatethecausaleffectofDonY becauseX blockstheonlyback-doorpathbetween
D and Y.

IfDisuncorrelatedwithε∗ (i.e.,theerrortermnetofadjustmentforX),thenleast
squares regression yields an estimate that is ostensibly freed of the bias generated by
the correlation of the treatment D with the error term ε in Equation (6.3). However,
even in this case some complications remain when one invokes the potential outcome
model.

First,if oneassumesthatδ is truly constantacrossindividuals (i.e.,that y1−y0 is
i i
equal to the same constant for all individuals i), then the OLS estimate is consistent
andunbiasedforδ andfor(μ1−μ0).If,however,y1−y0 isnotconstant,thentheOLS
i i
estimate represents a conditional-variance-weightedestimate of the underlying causal
effectsofindividuals,δi,inwhichtheweightsareafunctionoftheconditionalvariance
of D (see Angrist 1998 and Angrist and Pischke 2009, as well as our explanation of
thisresultinthe nextsection).Undertheseconditions,theOLSestimateisconsistent
and unbiased and for this particular weighted average, which is usually not a causal
parameter of primary interest.

Second,notethattheresidualizederrorterm,ε∗,inEquation(6.8)isnotequivalent
to either ε fromEquation(6.3) or to the multiparterror term {υ0+D(υ1−υ0)} from
Equation (6.5). Rather, it is defined by whatever adjustment occurs within Equation
(6.8), as represented by the term Xβ. Consequently, the residualized error term ε∗
cannot be interpreted independently of decisions about how to specify the vector of
adjustmentvariablesinX,andthiscanmakeitdifficulttodefinewhenanetcovariance
between D and ε∗ can be assumed to be zero.

Weexplainthesetwocomplicationsandtheirimportantimplicationsinthefollow-
ingsectionsofthis chapterandthenext, whereweconsideravarietyofexamplesthat
demonstrate the connections between matching and regression estimators of causal
effects. Before developing these explanations, however, we conclude this section with
two final small-N examples that demonstrate how the regressionadjustment strategy
does and does not work.

Table 6.4 presents two six-person examples. For both examples, a regression of Y
on D yields a biased estimate of the true ATE. And, in fact, both examples yield
the same biased estimate because the observedvalues yi and di are the same for both
examples.Moreover,anadjustmentvariableX isalsoavailableforbothexamples,and
its observed values xi have the same associations with the observed values yi and di
forbothexamples.Buttheunderlyingpotentialoutcomesdiffersubstantiallybetween
the two examples. These differences render regression adjustment by X effective for
only the first example.

For the example in the first panel, a regressionof Y on D would yield an estimate
of the coefficient for D of 11.67, which is an upwardly biased estimate of the true
average causal effect of 10. The bias arises because the correlation between the error
term in the last column and the realized values for di is not zero but is instead .33.

Fortheexampleinthesecondpanel,aregressionofY onDwouldyieldanestimate
of the coefficient for D of 11.67 because the values for yi and di are exactly the same
as for the example in the first panel. Moreover, this estimate is also upwardly biased
because the error term in the last column is positively correlated with the realized
Table 6.4 Two Six-PersonExamples in Which Regression Adjustment Is
Differentially Effective
Regression adjustment with X
generates an unbiased estimate for D
y i1 y i0 υ i1 υ i0 yi di xi υ i0+di(υ1 i−υ0 i)
In treatment group 20 10 2.5 2.5 20 1 1 2.5
In treatment group 20 10 2.5 2.5 20 1 1 2.5
In treatment group 15 5 −2.5 −2.5 15 1 0 −2.5
In control group 20 10 2.5 2.5 10 0 1 2.5
In control group 15 5 −2.5 −2.5 5 0 0 −2.5
In control group 15 5 −2.5 −2.5 5 0 0 −2.5
Regression adjustment with X
does not generate an unbiased estimate for D
y i1 y i0 υ i1 υ i0 yi di xi υ i0+di(υ1 i−υ0 i)
In treatment group 20 10 2.83 2.5 20 1 1 2.83
In treatment group 20 10 2.83 2.5 20 1 1 2.83
In treatment group 15 5 −2.17 −2.5 15 1 0 −2.17
In control group 18 10 .83 2.5 10 0 1 2.5
In control group 15 5 −2.17 −2.5 5 0 0 −2.5
In control group 15 5 −2.17 −2.5 5 0 0 −2.5
values of di. However, here the patterns are more complex. The underlying potential
outcomes are different, and individual-level heterogeneity of the causal effect is now
present. One member of the control group has an individual-level treatment effect of
only 8, and as a result the true ATE is only 9.67. Consequently, the same bivariate
regressioncoefficientof11.67hasalargerupwardbiasinthissecondexample,andthe
correlation between the values of di and the error term in the last column is now .39
rather than .33.

This underlying difference in potential outcomes also has consequences for the
capacity of regression adjustment to effectively generate unbiased estimates of the
ATE. This is easiest to see by rearranging the rows in Table 6.4 for each of the two
examples based on the values of X for each individual, as in Table 6.5. For the first
example,thevaluesofdiareuncorrelatedwiththeerrortermwithinsubsetsofindivid-
ualsdefinedbythetwovaluesofX.Incontrast,forthesecondexample,thevaluesofdi
remain positively correlated with the error term within subsets of individuals defined
by the two values of X. Thus, conditioning on X breaks the correlation between D
and the error term in the first example but not in the second example. Because the
observeddata are the same for both examples, this difference is entirely a function of
the underlying potential outcomes that generate the data.

Table 6.5 A Rearrangementof the Example in Table 6.4 That Shows How
RegressionAdjustment Is Differentially Effective
Regression adjustment with X
generates an unbiased estimate for D
y i1 y i0 υ i1 υ i0 yi di xi υ i0+di(υ1 i−υ0 i)
For thosewith X=1
In treatment group 20 10 2.5 2.5 20 1 1 2.5
In treatment group 20 10 2.5 2.5 20 1 1 2.5
In control group 20 10 2.5 2.5 10 0 1 2.5
For thosewith X=0
In treatment group 15 5 −2.5 −2.5 15 1 0 −2.5
In control group 15 5 −2.5 −2.5 5 0 0 −2.5
In control group 15 5 −2.5 −2.5 5 0 0 −2.5
Regression adjustment with X
does not generate an unbiased estimate for D
y i1 y i0 υ i1 υ i0 yi di xi υ i0+di(υ1 i−υ0 i)
For thosewith X=1
In treatment group 20 10 2.83 2.5 20 1 1 2.83
In treatment group 20 10 2.83 2.5 20 1 1 2.83
In control group 18 10 .83 2.5 10 0 1 2.5
For thosewith X=0
In treatment group 15 5 −2.17 −2.5 15 1 0 −2.17
In control group 15 5 −2.17 −2.5 5 0 0 −2.5
In control group 15 5 −2.17 −2.5 5 0 0 −2.5
This example demonstrates an important conceptual point. Recall that the basic
strategy behind regressionanalysis as an adjustment technique is to estimate
∗
Y =α+δD+Xβ+ε ,
where X represents one or more control variables, β is a coefficient (or a conformable
vector of coefficients if X represents more than one variable), and ε∗ is a residualized
versionofthe originalerrortermεfromEquation(6.3); seeourearlierpresentationof
Equation (6.8). The literature on regressionoften states that an estimated coefficient
δˆfromthis regressionequationis consistentandunbiasedfor the averagecausaleffect
if ε∗ is uncorrelated with D. But, because the specific definition of ε∗ is conditional
on the specification of X, many researchersfind this requirementof a zero correlation
difficult to interpret and hence difficult to evaluate.

The crux of the idea, however, can be understood without reference to the error
term ε∗ but rather with reference to the simpler and (as we have argued in Section
6.2.2)more clearly defined errorterm υ0+D(υ1−υ0) fromEquation(6.5) or, equiva-
lently,Dυ1+(1−D)υ0 fromEquation(6.6). RegressionadjustmentbyX inEquation
(6.8) will yield a consistent and unbiased estimate of the ATE when
1. D is mean independent of (and therefore uncorrelatedwith) υ0+D(υ1−υ0) for
each subset of respondents identified by distinct values on the variables in X,
2. the causal effect of D does not vary with X, and
3. a fully flexible parameterization of X is used.

ConsidertherelationshipbetweenthissetofconditionsandwhatwasdescribedinSec-
tion4.3.1asanassumptionthattreatmentassignmentisignorable.Switchingnotation
from S to X in Equation (4.4) results in
(Y0,Y1) ⊥⊥ D | X, (6.10)
where,again,thesymbol⊥⊥denotesindependence.Now,rewritetheassumption,devi-
ating Y0 and Y1 from their population-level expectations:
(υ0,υ1) ⊥⊥ D | X. (6.11)
This switch from(Y0,Y1) to (υ0,υ1) does not changethe assumption,at leastinsofar
as it is relevant here (because we have defined the individual-level causal effect as a
linear difference, because the expectation operator is linear, and because E[Y0] and
E[Y1] do not depend on who is in the treatment state and who is in the control
state). Consequently, ignorability of treatment assignment can be defined only with
respectto individual-leveldeparturesfromthe true averagepotential outcomesacross
all members of the population under the assumptions already introduced.

Given that an assumption of ignorable treatment assignment can be written as
Equation (6.11), the connections between this assumption and the set of conditions
thatwehavesaidjustifyaregressionestimatorasconsistentandunbiasedfortheATE
canbeexplored.Twoimportantpointsshouldbenoted.First,iftreatmentassignment
is ignorable, as defined in Equation (6.11), then an estimator that conditions fully on
allvaluesofX existsthatwillyieldaconsistentandunbiasedestimateoftheATE(and
that can be implemented in practice if the sample size is large enough). For reasons
we will explain in the next section, a regression estimator with dummy variables for
all but one categories of X will only be the appropriate estimator if, in addition, our
number 2 just above also holds: the causal effect of D does not vary with X. Second,
ignorabilitystipulatesfullindependence.Instead,foroursetofconditions,υ0 andυ1 –
aswellasfunctionsofthem,suchasυ0+D(υ1−υ0)–mustonlybemeanindependent
of D conditional on X, not fully independent of D conditional on X.

Finally, we shouldnote that our three conditions are not the only ones that would
establishleastsquaresestimatorsasconsistentandunbiasedfortheATE,buttheyare
the most common ones that would apply in most research situations.13 Our point in
13For example, the second condition can be dropped if the heterogeneity of the causal effect is
modeled as a function of X (i.e., the parameterization is fully saturated in both D and X). In this
case, however, regression then becomes a way of enacting a stratification of the data, as for the
matchingtechniques presentedinChapter 5.

layingoutthese conditionsis notto providea rigidguideline applicableto alltypes of
regressionmodels in all situations but instead to show why the earlier statement that
“ε∗ must be uncorrelated with D” is insufficiently articulated from a counterfactual
perspective.

A larger point of this section, however, is that much of the received wisdom on
regression modeling breaks down in the presence of individual-level heterogeneity of
a causal effect, as would be present in general when causal effects are defined with
reference to underlying potential outcomes tied to well-defined causal states. In the
nextsection,webegintoexplainthesecomplicationsmoresystematically,startingfrom
the assumption, as in prior chapters, that causal effects are inherently heterogeneous
and likely to vary systematically between those in the treatment and control groups.

BeginningwiththenextsectionandcontinuinginChapter7onweightedregression,we
then present the connections among regression, matching, and stratification, building
directly on our presentation of matching in Chapter 5.

## 6.3 Regression as Conditional-Variance-Weighted Matching

Inthissection,wereturntothedemonstrationsutilizedtoexplainmatchingestimators

in Chapter 5. Our goal is to show why matching routines and least squares regression
yield different results, even though a researcher is attempting to adjust for the same
set of variables.

We first show why least squares regression can yield misleading causal effect esti-
mates in the presence of individual-level heterogeneity of causal effects, even if the
only variable that needs to be adjusted for is given a fully flexible coding (i.e., when
the adjustment variable is parameterized with a dummy variable for each of its val-
ues, save one for the reference category).14 In these cases, least squares estimators
implicitly invokeconditional-varianceweighting ofindividual-level causal effects. This
weighting scheme generates a conditional-variance-weighted estimate of the average
causaleffect,whichisnotanaveragecausaleffectthatisoftenofanyinherentinterest
to a researcher.15 Angrist (1998) provides a more formal explanation of the following
results, which is then placed in the context of a larger class of models in Angrist and
Krueger (1999) and Angrist and Pischke (2009).

14Whenwewriteofafullyflexiblecodingofavariable,wearereferringtoadummyvariablecoding
ofthatvariableonly(i.e.,onedummyforatwo-categoryvariable,twodummiesforathree-category
variable, and so on). As we will discuss later, a saturated model entails a fully flexible coding of
each variableas well as all interactions between the dummy variables of each them. For the models
discussed in this section, a saturated model would include interactions between the causal variable
D andeachdummyvariableforallbutoneofthevaluesofS.Foramodelwithonlyafullyflexible
codingofS,theseinteractions areleftout.

15Itcouldbeofinteresttoaresearcherwhoseeksaminimum-varianceestimateandwhohasreason
tobelievethattheinconsistencyandbiasoftheregressionestimateismodest.Wediscussthispoint
later, but we hope to show that most applied researchers have good reason to want consistent and
unbiasedestimatesratherthanminimummean-squared-errorestimatesthatremaininconsistentand
biased.

Regression Demonstration 2
Reconsider Regression Demonstration 1 (see page 189), but now step back from the
cautious mindset of the fictitious descriptively oriented researcher. Suppose that a
causality-orientedresearcher had performed the same exercise and obtained the same
results for the regressionmodel reported above in Equation (6.2):
Yˆ =1.86+2.75(D)+3.76(S2)+8.92(S3). (6.12)
WeknowfromMatchingDemonstration1(seepage145),onwhichRegressionDemon-
stration1isbased,thatforthishypotheticalexamplethe ATTis3,the averagetreat-
ment effect for the controls (ATC) is 2.4, and the unconditional ATE is 2.64. If the
causality-orientedresearcherweretodeclarethatthe coefficienton D of2.75inEqua-
tion(6.12)isagoodestimateofthecausaleffectofD onY,thentheresearcherwould
be incautious but not appreciably incorrect. The value of 2.75 is indeed close to the
true ATE of 2.64, and we know from the setup of Regression Demonstration 1 that
the variable S continues to serve as a perfect stratifying variable, as defined earlier.16
Thus, if the researcher were to state that the regression model in Equation (6.12)
statistically controls for the common effect of S on both D and Y, as in Equation
(6.8), where S is specified as the sole element of X but as two dummy variables S2
andS3,thentheresearcheris nothorriblyoffthe mark.The researcherhasofferedan
adjustment for S and gotten close to the true ATE.

Unfortunately, the closeness of the estimate to the true ATE is not a general fea-
ture of this type of a regression estimator. Under this particular specification of the
regressionequation, the OLS estimator yields precisely the value of 2.75 in an infinite
sample as the sum of sample analogs to three terms:
Var[D|S=1]Pr[S=1]
(cid:12) {E[Y|D=1,S=1]−E[Y|D=0,S=1]} (6.13)
Var[D|S=s]Pr[S=s]
S
Var[D|S=2]Pr[S=2]
+ (cid:12) {E[Y|D=1,S=2]−E[Y|D=0,S=2]}
Var[D|S=s]Pr[S=s]
S
Var[D|S=3]Pr[S=3]
+ (cid:12) {E[Y|D=1,S=3]−E[Y|D=0,S=3]}.

Var[D|S=s]Pr[S=s]
S
Thesethreetermsarenotascomplicatedastheymayappear.First,notethatthe dif-
ferences in the braces on the right-hand side of each term are simply the
16Moreover,S satisfiestheback-door criterionbyconstruction. However, thisdoesnotimplythat
everyconditioningestimatorwilldeliverconsistentandunbiasedestimatesoftheATT,ATC,orATE
thatcouldbecalculatednonparametricallyinasufficientlylargesample.Inthiscase,asweshowin
thissection,theleastsquaresestimatorintroducesparametricconstraintsthatdeliveranalternative
averagecausaleffect. Theback-doorcriteriongivesacorrectresult–acausalinferenceofsometype
is indeed warranted by conditioning via a regression model on variables that satisfy the back-door
criterion – but the causal effect estimate that is produced by the regression estimator is not one of
theaveragecausaleffects thattheanalysttypicallywants.

stratum-specific differences in the outcomes, which in this case are
E[Y|D=1,S=1]−E[Y|D=0,S=1]=4−2, (6.14)
E[Y|D=1,S=2]−E[Y|D=0,S=2]=8−6, (6.15)
E[Y|D=1,S=3]−E[Y|D=0,S=3]=14−10. (6.16)
The left-hand portion of each term is then just a weight, exactly analogous to the
stratum-specific weights that were used for Matching Demonstration 1 to average
the stratum-specific causal effect estimates in various ways to obtain consistent and
unbiased estimates of the ATE, ATT, and ATC. But, rather than use the marginal
distribution of S, Pr[S], or the two conditional distributions of S, Pr[S|D=1] and
Pr[S|D=0], a different set of weights is implicitly invoked by the least squares oper-
ation. In this case, the weights are composed of three pieces: (1) the variance of the
treatment variable within each stratum, Var[D|S=s], (2) the marginal probability of
S for eachstratum, Pr[S=s], and (3) a summation of the product of these two terms
across S so that the three weights sum to 1.

Accordingly, the only new piece of this estimator that was not introduced and
examined for Matching Demonstration 1 is the conditional variance of the treatment,
Var[D|S =s]. Recall that the treatment variable is distributed within each stratum
solely as a function of the stratum-specific propensity score, Pr[D|S=s]. Thus, the
treatmentvariableis aBernoullidistributed randomvariablewithineachstratum.As
can be found in any handbook of statistics, the variance of a Bernoulli distributed
randomvariableisp(1−p),wherepistheBernoulliprobabilityofsuccess(inthiscase
D equal to 1) instead of failure (in this case D equal to 0). Accordingly, the expected
varianceofthewithin-stratumtreatmentvariableDis(Pr[D|S=s])(1−Pr[D|S=s]).

Forthisexample,theconditionalvariances,Var[D|S=s],contributetothenumer-
ator of each weight as follows:
(cid:21)(cid:22) (cid:23)(cid:22) (cid:23)(cid:24)
.08 .08
Var[D|S=1]Pr[S=1]= 1− (.08+.36), (6.17)
.08+.36 .08+.36
(cid:21)(cid:22) (cid:23)(cid:22) (cid:23)(cid:24)
.12 .12
Var[D|S=2]Pr[S=2]= 1− (.12+.12), (6.18)
.12+.12 .12+.12
(cid:21)(cid:22) (cid:23)(cid:22) (cid:23)(cid:24)
.2 .2
Var[D|S=3]Pr[S=3]= 1− (.2+.12). (6.19)
.2+.12 .2+.12
Thetermsinbracketsontheright-handsidesofEquations(6.17)–(6.19)areVar[D|S=
1], Var[D|S=2], and Var[D|S=3]. The terms in the last set of parentheses on the
right-hand sides of Equations (6.17)–(6.19) are the marginal probability of S for each
stratum, Pr[S=1],(cid:25)(cid:16)Pr[S=2(cid:17)],(cid:16)and Pr[S=(cid:17)(cid:26)3]. For example, for the stratum with S=
1, Var[D|S =1]= .08 1− .08 and Pr[S =1]= (.08+.36). Finally, the
.08+.36 .08+.36
denominator of each of the three stratum-specific weights in Equation (6.13) for this
exampleisthe sumofEquations(6.17)–(6.19).Thedenominatoris constantacrossall
three weights and scales the weights so that they sum to 1.

With an understanding of the implicit stratum-specific weights of least squares
regression, the regression estimator can be seen clearly as an estimator for the ATE
but with supplemental conditional-varianceweighting.Weighting is indeed performed
withrespecttothemarginaldistributionofindividualsacrossstrata,asfortheATEin
MatchingDemonstration1,butweightingisalso performedwithrespecttothecondi-
tionalvariance ofthe treatment variable acrossstrataas well. Thus, net of the weight
given to stratum-specific effects solely as a function of Pr[S], the conditional-variance
terms give more weight to stratum-specific causal effects in strata with propensity
scores close to .5 (where Var[D|S] approachesits maximum of .5×.5) and less weight
to stratum-specific causaleffects in stratawith propensity scoresclose to either 0 or1
(where Var[D|S] approaches its minimum of 0×1 or 1×0).

Why would the OLS estimator implicitly invoke conditional-variance weighting
as a supplement to weighting simply by the marginal distribution of S? OLS is a
minimum-variance-based estimator of the parameter of interest. As a result, it gives
more weight to stratum-specific effects with the lowest expected variance, and the
expectedvarianceof eachstratum-specificeffect is aninversefunction ofthe stratum-
specific variance of the treatment variable D. Thus, if the two pieces of the weight-
ing scheme are not aligned (i.e., the propensity score is close to 0 or 1 for strata
that have high total probability mass but close to .5 for strata with low probabil-
ity mass), then a regression estimator of this form, even under a fully flexible cod-
ing of S, can yield estimates that are far from the true ATE even in an infinite
sample.

To see the effects that supplemental weighting by the conditional variance of the
treatmentcanhaveonaregressionestimate,weconsideralternativejointdistributions
for S and D, which we then impose on the setup for Matching Demonstration 1 and
Regression Demonstration 1. In particular, the values of E[Y0|S,D], E[Y1|S,D], and
E[Y|S,D] in the final three panels of Table 6.1 again obtain, such that S continues
to offer a perfect stratification of the data. Now, however, we assume two different
joint distributions of S and D in two variants reported in Table 6.6. For these two
alternative joint distributions of S and D, the marginal distribution of S remains the
sameas for Table 6.1: Pr[S=1]=.44,Pr[S=2]=.24,and Pr[S=3]=.32.As a result,
the unconditional ATE is the same for both variants of the joint distribution of S
and D depicted in Table 6.6, and it matches the unconditional ATE for the original
demonstration represented fully in Table 6.1. In particular, the same distribution of
stratum-specific causal effects results in an unconditional ATE of 2.64. The difference
representedby each variant of the joint distributions in Table 6.6 is in the propensity
score for each stratum of S, which generates an alternative marginal distribution for
D and thus alternative true ATTs and ATCs (and, as we will soon see, alternative
regressionestimates from the same specification).

For Variant I in Table 6.6, those with S equal to 1 or 2 are much less likely to be
in the treatment group, and those with S equal to 3 are now only equally likely to be
in the treatment group and the control group. As a result, the marginal distribution
of D is now different, with Pr[D=0]=.76 and Pr[D=1]=.24. The ATT is now 3.33
whereas the ATC is 2.42. Both of these effects are larger than was the case for Table
6.1 because (1) a greater proportion of those in the control group have S =3 (i.e.,
.16 .12),
> (2) a greater proportion of those in the treatment group have S=3 (i.e.,
.76 .6
.16>.2), and (3) those with S=3 gain the most from the treatment.

.24 .4
Table 6.6 The Joint Probability Distribution for Two
Variants of the Stratifying and Treatment Variables in
Prior Regression Demonstration 1
Joint probability distribution of S and D
Control group: D=0 Treatment group: D=1
Variant I
S=1 Pr[S=1,D=0]=.40 Pr[S=1,D=1]=.04
S=2 Pr[S=2,D=0]=.20 Pr[S=2,D=1]=.04
S=3 Pr[S=3,D=0]=.16 Pr[S=3,D=1]=.16
Variant II
S=1 Pr[S=1,D=0]=.40 Pr[S=1,D=1]=.04
S=2 Pr[S=2,D=0]=.12 Pr[S=2,D=1]=.12
S=3 Pr[S=3,D=0]=.03 Pr[S=3,D=1]=.29
ForVariantII,thosewithS equalto1arestillveryunlikelytobeinthetreatment
group,butthosewithS equalto2areagainequallylikelytobeinthetreatmentgroup.

In addition, those with S equalto 3 are now very likely to be in the treatment group.

As aresult,the marginaldistributionof D isnowdifferentagain,withPr[D=0]=.55
andPr[D=1]=.45,andthe ATT isnow 3.29,whereasthe ATC is2.11.Bothofthese
are smaller than for Variant I because a smaller proportion of both the treatment
group and the control group have S=3.

For these two variants of the joint distribution of S and D, we have examples in
whichtheunconditionalATEisthesameasitwasforRegressionDemonstration1,but
the underlying ATT and ATC differ considerably. Does the reestimation of Equation
(6.12) for these variants of the example still generate an estimate for the coefficient
on D that is (1) relatively close to the true unconditional ATE and (2) closer to the
unconditional ATE than either the ATT or the ATC?
For Variant I, the regressionmodel yields
Yˆ =1.90+3.07(D)+3.92(S2)+8.56(S3) (6.20)
foraninfinite sample.Inthiscase,thecoefficientof3.07onD isnotparticularlyclose
to the unconditionalATE of2.64,andinfactitis closertothe ATT of3.33(although
still not particularly close). For Variant II, the regressionmodel yields
Yˆ =1.96+2.44(D)+3.82(S2)+9.45(S3). (6.21)
In this case, the coefficient of 2.44 on D is closer to the unconditional ATE of 2.64,
but not as close as was the case for Equation(6.12) when applied to the original data
specifiedforRegressionDemonstration1.ItisnowrelativelyclosertotheATC,which
is 2.11 (although, again, still not particularly close).

For Variant I, the regression estimator is weighted more toward the stratum with
S=3, for which the propensity score is .5. For this stratum, the causal effect is 4. For
Variant II, the regression estimator is weighted more toward the stratum with S=2,
for which the propensity score is .5. And, for this stratum, the causal effect is 2.17
What is the implication of these alternative setups of the same basic demonstra-
tion?Giventhat the unconditional ATE is the same for all three joint distributions of
S andD,itwouldbe unwisefortheincautiousresearchertobelievethatthis sortofa
regressionspecificationwillprovideareliablycloseestimatetotheunconditionalATE,
the ATT, or the ATC when there is reason to believe that these three average causal
effects differ because of individual-level heterogeneity. The regressionestimate will be
weightedtowardstratum-specificeffects forwhichthepropensityscoreisclosestto.5,
net of all else.

In general, regression models do not offer consistent or unbiased estimates of the
ATE when causal effect heterogeneity is present, even when a fully flexible coding is
given to the only necessary adjustment variable(s). Regression estimators with fully
flexible codings of the adjustment variables do provide consistent and unbiased esti-
matesoftheATEifeither(1)thetruepropensityscoredoesnotdifferbystrataor(2)
theaveragestratum-specificcausaleffectdoesnotvarybystrata.18Thefirstcondition
would almost never be true (because, if it were, one would not even think to adjust
for S because it is already independent of D). And the second condition is probably
not true in most applications, because rarely are investigators willing to assert that
all consequential heterogeneity of a causal effect has been explicitly modeled.

Instead, for this type of a regressionspecification, in which all elements of a set of
perfect stratifying variables S are given fully flexible codings (i.e., a dummy variable
coding for all but one of the possible combinations of the values for the variables in
S), the OLS estimator δˆ OLS,multiple in Equation (6.9) is equal to
(cid:6)
1
VarN[di|si=s] PrN[si=s]{EN[yi|di=1,si=s]−EN[yi|di=0,si=s]} (6.22)
c
s
in a sample of size N. Here, c is a scaling constant equal to the sum (over all combi-
nations of values s of S) of the terms VarN[di|si=s]PrN[si=s].

Therearetwoadditionalpointstoemphasize.First,theweightingschemeforstrat-
ifiedestimatesinEquation(6.22)appliesonlywhenthefullyflexibleparameterization
of S is specified. Under a constrained specification of S – e.g., in which some ele-
ments of S are constrained to have linear effects, as in Equation (6.1) – the weighting
scheme is more complex. The weights remain a function of the marginal distribution
of S and the stratum-specific conditional variance of D, but the specific form of each
of these components becomes conditional on the specification of the regression model
17Recallthat,becausebyconstructionthemarginaldistributionofS isthesameforallthreejoint
distributionsofSandD,thePr[S=s]piecesoftheweightsremainthesameforallthreealternatives.

Thus, the differences between the regression estimates are produced entirely by differences in the
Var[D|S=s]piecesoftheweights.

18Asaby-productofeithercondition,theATEmustbeequaltotheATTandtheATC.Thus,the
regressionestimatorwouldbeconsistentandunbiasedforbothoftheseaswell.

(seesection2.3.1ofAngristandKrueger1999).Thebasicintuitionhereisthatalinear
constraintona variablein S inaregressionmodelentailsanimplicit assumptionthat
the underlying propensity scores are also linear in the values of S.19
Second,regressioncanmakeitalltooeasytooverlookthesamesortoffundamental
overlap problems that were examined for Matching Demonstration 2 (see page 148).

Regression will implicitly drop strata for which the propensity score is either 0 or
1 in the course of forming its weighted average by Equation (6.22). As a result, a
researcherwhointerpretsaregressionresultasadecentestimateoftheATE,butwith
supplemental conditional-variance weighting, may be entirely wrong. No meaningful
averagecausal effect may exist in the population. This second point is best explained
by the following demonstration.

19For a binary causal variable D, a many-valued variable S that is treated as an interval-scaled
variable,andaregressionequation
Yˆ=αˆ+δˆ(D)+βˆ(S),
theOLSestimatorδˆisequalto
(cid:2)
1 V(cid:3) arN[dˆ i|s i=s]P(cid:4) rN[s i=s]{E N[y i|d i=1,s i=s]−E N[y i|d i=0,s i=s]}
l
s
in a sample of size N, where l is a scaling constant equal to the sum of V(cid:3) arN[dˆ i|s i=s] P(cid:4) rN[s i=s]
overallsofS.

The distinction between V(cid:3) arN[dˆ i|s i=s] P(cid:4) rN[s i=s] and VarN[d i|s i=s] PrN[s i=s] in the main
text results from a constraint on the propensity score that is implicit in the regression equation. In
specifyingS as aninterval-scaled variable, leastsquares implicitlyassumes that the true propensity
scorePr[D|S]islinearinS.Asaresult,thefirstportionofthestratum-specificweightis
V(cid:3) arN[dˆ i|s i=s]≡pˆs(1−pˆs),
wherepˆs isequaltothepredictedstratum-specificpropensityscorefromalinearregressionofd i on
s i: pˆs=ξˆ+φˆ ss.

Perhapssomewhatlessclear,thetermP(cid:4) rN[s i=s]isalsoafunctionoftheconstraintonS.P(cid:4) rN[s i=
s]isnotsimplythemarginaldistributionofS inthesample,asPrN[s i=s]is.Rather,onemustuse
Bayes’ rule to determine the implied marginal distribution of S, given the assumed linearity of the
propensityscoreacrosslevelsofS.Rearranging
i]=Pr[s i|d i= Pr1 [s] iP ]r[d i=1]
Pr[d i=1|s
as
Pr[s i]=Pr[s i P|d ri [d= i1 =]P 1|r s[d i]i=1] ,
andthensubstitutingpˆs forPr[d i=1|s i],wethenfindthat
P(cid:4) rN[s i=s]=PrN[s i=s|d i p= ˆs1]PrN[d i=1] .

ThetermsPrN[s i=s|d i=1]andPrN[d i=1]are,however, unaffected bythe linearityconstrainton
thepropensityscore.TheyaresimplythetrueconditionalprobabilityofS equaltosgivenD equal
todaswellasthemarginalprobabilityofD equaltodforasampleofsizeN.

Notethat, ifthetruepropensityscoreislinearinS,thenthe weightingschemehereisequivalent
totheoneinthemaintext.

Regression Demonstration 3
ReconsiderthehypotheticalexamplepresentedasMatchingDemonstration2(seepage
148), which is reproduced in Table 6.7. The assumed relationships that generate the
hypotheticaldataforthisdemonstrationareverysimilartothosewehavejustconsid-
ered.However,in this caseno individual for whomS is equalto 1in the populationis
everexposedtothetreatmentbecausePr[S=1,D=1]=0andPr[S=1,D=0]=.4.As
aresult,the population, andanysamplefromit, doesnotinclude anindividual inthe
treatmentgroupwith si=1.20 Because ofthis structuralzeroin the joint distribution
ofS andD,thethreeconditionalexpectations,E[Y0|S=1,D=0],E[Y1|S=1,D=0],
andE[Y|S=1,D=0],areproperlyregardedasill-definedandhenceareomittedfrom
the last three panels of Table 6.7.

AsshownforMatchingDemonstration2,thenaiveestimatorcanstillbecalculated
and will be equal to 8.05 in an infinite sample. Moreover, the ATT can be estimated
Table 6.7 The Joint Probability Distribution and
Conditional Population Expectations for Regression
Demonstration 3
Joint probability distribution of S and D
Control group: D=0 Treatment group: D=1
S=1 Pr[S=1,D=0]=.4 Pr[S=1,D=1]=0
S=2 Pr[S=2,D=0]=.1 Pr[S=2,D=1]=.13
S=3 Pr[S=3,D=0]=.1 Pr[S=3,D=1]=.27
Potential outcomes underthecontrol state
S=1 E[Y0|S=1,D=0]=2
S=2 E[Y0|S=2,D=0]=6 E[Y0|S=2,D=1]=6
S=3 E[Y0|S=3,D=0]=10 E[Y0|S=3,D=1]=10
Potential outcomes underthetreatment state
S=1 E[Y1|S=1,D=0]=4
S=2 E[Y1|S=2,D=0]=8 E[Y1|S=2,D=1]=8
S=3 E[Y1|S=3,D=0]=14 E[Y1|S=3,D=1]=14
Observed outcomes
S=1 E[Y|S=1,D=0]=2
S=2 E[Y|S=2,D=0]=6 E[Y|S=2,D=1]=8
S=3 E[Y|S=3,D=0]=10 E[Y|S=3,D=1]=14
20Again, recall that we assume no measurement error in general in this book. In the presence of
measurementerror,someindividualsmightbemisclassifiedandthereforemightshowupinthedata
withs i=1andd i=1.

consistently as 3.35 by considering only the values for those with S equal to 2 and 3.

ButthereisnowaytoconsistentlyestimatetheATC,andhencenowaytoconsistently
estimate the unconditional ATE.

Consider now the estimated values that would be obtained with data arising from
this joint distribution for a regression model specified equivalently as in Equations
(6.12), (6.20), and (6.21):
Yˆ =2.00+3.13(D)+3.36(S2)+8.64(S3). (6.23)
Inthiscase,theOLSestimatorisstillequivalenttoEquation(6.22),whichinaninfinite
samplewouldthenbeequaltoEquation(6.13).But,withreferencetoEquation(6.13),
note that the weight for the first term,
Var[D|S=1]Pr[S=1]
(cid:12) ,
Var[D|S=s]Pr[S=s]
S
is equal to 0 because Var[D|S=1] is equal to 0 in the population by construction.

Accordingly, the numerator of the stratum-specific weight is 0, and it enters into the
summation of the denominator of the other two stratum-specific weights as 0. As a
result, the regression estimator yields a coefficient on D that is 3.13, which is biased
downward as an estimate of the ATT and has no relationship with the ill-defined
ATE. If interpreted as an estimate of the ATT, but with supplemental conditional-
varianceweighting,thenthe coefficientof3.13isinterpretable.Butitcannotbe inter-
preted as a meaningful estimate of the ATE in the population once one commits to
the potential outcome framework and allows for individual-level heterogeneity of the
treatment effect.

The importance of this demonstration is only partly revealed in this way of pre-
{yi,di,si}N
senting the results. Imagine that a researcher simply observes and then
i=1
estimates the model in Equation(6.23)withoutfirstconsideringthe jointdistribution
ofS andD aspresentedinTable6.7. Itwouldbeentirelyuncleartosucharesearcher
thattherearenoindividualsinthesample(orinthepopulation)whosevaluesforboth
D and S are 1. Sucha researchermight therefore be led to believe that the coefficient
estimate for D is a meaningful estimate of the causal effect of D for all members of
the population.

Alltoooften,regressionmodeling,atleastaspracticedinthesocialsciences,makes
ittooeasyforananalysttooverlookfundamentalmismatchesbetweentreatmentand
control cases. And, thus, one can obtain ATE estimates with regression techniques
even when no meaningful ATE exists.

## 6.4 Regression as an Implementation of a Perfect Stratification

For completeness, in this sectionwe make the (perhaps obvious)point that regression

canbe usedasatechniquetoexecute aperfectstratification.Ifallcellsofthe implicit
full cross-tabulation of the adjustment variables and the causal variable are uniquely
parameterized, using a saturated coding of all variables, regression can be used to
carry out a perfect stratification of the data.

ConsiderhowtheestimatespresentedinMatchingDemonstration1(seepage145)
could have been generated by standard regression routines using a saturated coding
ofthe causalvariableandalladjustmentvariables.Alternatively,one couldeffectively
estimate the ATE for Regression Demonstrations 1 and 2 (see pages 189 and 207,
respectively)byenrichingtheparameterizationoftheregressionmodelthatweshowed
earlier does not generate a consistent and unbiased estimate of the ATE.

For the data common to these demonstrations, an analyst could specify S as two
dummy variables, D as one dummy variable, and include all two-way interactions
between S and D. In so doing, the analyst has enacted the same perfect stratification
of the data by fitting a model that is saturated in both S and D to all of the cells of
the first panel of Table 5.2:
Yˆ =2+2(D)+4(S2)+8(S3)+0(D×S2) +2(D×S3). (6.24)
Thevaluesofeachofthesixcellsofthepanelareuniquefunctionsofthesixestimated
coefficients from the regressionmodel.

Withthesecoefficients,theanalystcouldthenformdifferenceswithinstratadefined
by allvalues of S and then use the marginaldistribution ofS to generatea consistent
and unbiased estimate of the ATE (or use the conditional distribution of S given D
to obtain consistent and unbiased estimates of the ATT and ATC). Although this
last stratum-averaging step is not typically seen as part of a regression estimation
strategy,itisnonethelesscompatiblewithit(andnowquiteeasytoimplement,using,
for example, the command margins after the command regress in Stata).

Nevertheless, for many applications, such a saturated model may not be possible,
andinsomecasesthisimpossibilitymaybemisinterpreted.ForRegressionDemonstra-
tion3(seepage213), justpresentedinthelastsection,ifoneweretofittheseemingly
saturated model with the same six parameters as in Equation (6.24), the coefficient
on D would be dropped by standard software routines. One might then attribute this
to the size of the dataset and then instead use a more constrained parameterization,
that is, either enter S as a simple linear term interacted with D or instead specify
the model in Equation (6.23). These models must then be properly interpreted, and
in no case could they be interpreted as yielding consistent and unbiased estimates of
the ATE.

## 6.5 Regression as Supplemental Adjustment When Matching

Although we have separated our presentation of matching and regression estimators

across two chapters for didactic purposes, we have been gradually working our way
towardChapter7onweightedregressionwherewewillshowhowmatchingandregres-
sion can be used together very effectively. It is appropriate at this point to note that
the matching literature has long recognized the utility of parametric regression as a
supplemental adjustment technique that can be applied to traditional matching esti-
mators in attempts to eliminate remaining within-sample imbalance on the matching
variables. In this section, we offer a demonstration of how standard regression tech-
niques can be used to supplement matching estimators.

Regression Demonstration 4
RecallMatchingDemonstration4(seepage171)andconsidernowhowregressioncan
be used to supplement a matching algorithm. For Matching Demonstration4, we pre-
sented matching estimates of the Catholic school effect on achievement for simulated
data. We offered matching estimators under two basic scenarios, first using an incom-
plete specification of treatment assignment and then using a complete specification
thatincludesacognitiveskillsvariable.Becausebothscenarioslackanadjustmentfor
the self-selection dynamic, in which individuals select into the treatment partly as a
function of their expected treatment effect, we only attempted to estimate the ATT.

In the columns labeled “Unadjusted,” Table 6.8 redisplays the average bias for
selectedmatchingestimatorsfromTable5.7,underbothspecificationsofthetreatment
Table 6.8 Average Bias Comparisons for Selected Matching Estimates of the
ATT from Matching Demonstration 4, With and Without Supplemental
RegressionAdjustment for the Assumed Determinants of Treatment
Assignment
Specification of treatment assignment variables:
Incompletespecification Complete specification
Method Unadjusted Adjusted Unadjusted Adjusted
Nearest-neighbor match:
1 without replacement (MI) 0.75 0.72 0.00 −0.10
1 with replacement (MI) 0.95 0.81 0.19 −0.12
1 with replacement and
caliper = .05 SD (MI) 0.98 0.86 0.07 −0.11
5 with replacement (MI) 1.17 0.83 0.50 −0.05
5 with replacement and
caliper = .05 SD (MI) 1.19 0.80 0.39 −0.13
Intervalmatch:
10 fixedblocks (MI) 1.68 0.84 1.68 −0.11
Optimal match (MI-opt) 1.28 0.80 0.54 0.07
Genetic match (MI-gen) 0.96 0.80 0.23 −0.07
Coarsened exact match (cem) 1.28 0.86 0.35 −0.08
Notes:SeenotestoTable 5.6forsoftwaredetails.

assignment variables.21 For the two columns labeled “Adjusted,” the average bias is
reportedforthesamematchingestimatorsacrossthesame10datasets,butnowusing
a post-match regressionadjustment for the matching variables.

Overall,Table6.8showsthatsupplementalregressionadjustmentreducestheaver-
age bias for nearly all of the matching estimators, which is consistent with the litera-
ture. The reductions occur for both the incomplete and complete specifications. This
does not imply that for any single sample a supplemental regression adjustment will
necessarily reduce bias, but on average such adjustments will reduce the bias that
would remain if matching alone were utilized.

Thereasonforthereductionsinbiasshouldbeobvious.Anypost-matchimbalance
that remains in the matching variables is likely to have a component that exists as
differences in mean values of the matching variables across the treatment and con-
trol cases. If we then use a parametric regression model to adjust for the matching
variables in the matched datasets, the regression model yields a net estimate of the
ATT after a linear adjustment for these lingering mean differences. The conditional-
variance weighting property of least squares regression estimators remains, but the
consequences of this property for estimates is greatly diminished when regression is
usedinthis supplementaryway,after the data havealreadybeenalignedinpursuitof
the ATT.

We will discuss in Chapter 7 a variety of perspectives that suggest when and why
matching and regression should be pursued together. Moving beyond regression as
a supplementary procedure, we will show how weighted regression can be used to
implement matching estimators, picking up onthe weighting perspective on matching
already introduced in Section 5.3.2.

## 6.6 Extensions and Other Perspectives

Inthis chapter,we havefocusedalmostexclusivelyonthe estimationofthe effectofa

binarycauseonaninterval-scaledoutcome,andwehaveconsideredonlyleastsquares
adjustments. Before carrying on to discuss least squares estimation of the effects of
many-valuedcauses,weofcoursemustconcedewhatthereaderissurelyawareof:We
have considered only a tiny portion of what falls under the general topic of regression
modeling. We have not considered categoricaloutcome variables, time series analysis,
nested data structures, variance-component models, and so on. One can gain a full
perspective of the types of regression modeling used in just sociology and economics
by consulting Agresti(2002),Allison (2009),Arminger et al. (1995),Berk (2004),Fox
(2008), Hamilton (1994), Hayashi (2000), Hendry (1995), Long (1997), Powers and
Xie (2000), Raudenbush and Bryk (2002), Ruud (2000), Stock and Watson (2007),
Treiman (2009), and Wooldridge (2010).

In this section, we consider only one modest extension: least squares regression
models for many-valuedcauses.This presentationthen leads naturally to a discussion
21Weselected the subsetofthe matchingestimates fromTable5.7based onwhether the software
allowedforsupplemental regressionadjustment.

that follows of what might be labeled the “all-cause correctspecification” tradition of
regressionanalysis.Informedbythedemonstrationsofferedinthischapter,wediscuss
the attractiveness of the promise of this alternative perspective but also the implau-
sibility of the perspective as a general guide for either causal analysis or regression
practice in the social sciences.

6.6.1 Regression Estimators for Many-Valued Causes
We suspect that the vast majority of published regression estimates of causal effects
in the social sciences are for causes with more than two values. Accordingly, as in
Section 5.5.4 on matching estimators for many-valued causes, we must discuss the
additional complexities of analogous regression estimators. We will again, however,
restrict attention to an interval-scaled outcome.

First,againrecallthebasicsetupformany-valuedcausesfromSection2.9,inwhich
we have a set of J treatment states, a corresponding set of J causalexposure dummy
variables,{Dj}J , andacorrespondingsetofJ potentialoutcome randomvariables,
j=1
{YDj}J . The treatment received by each individual is Dj(cid:2).

j=1
How would one estimate the causal effect of such a J-valued cause with regression
methods? The first answer should be clear from our presentation in the last section:
Because regression can be seen as a form of matching, one can use the same basic
strategies outlined for matching estimators of many-valued causes in Section 5.5.4.

One could form a series of two-way comparisons between the values of the cause and
then model each pairwise causal effect.

If the number of causal states is relatively large, then this general strategy is
infeasible. Some smoothing acrosspairwise comparisonswould be necessary,either by
collapsingsomeoftheJ causalstatesorbyimposinganorderingonthedistributionof
the causal effect across the J causal states. The most common parametric restriction
would be to assume that the causal effect is linear in j for each individual i. For
example, for a set of causal states (such as years of schooling) enumerated by values
from1,2,3,toJ,thelinearityassumptionistheassumptionthaty iDj =y iD1+βi(j−1),
yDj−yDj−1
which requires that the difference for each individual i be equal to a
i i
constant βi. In this case, the individual-level causal effect is then a slope βi, rather
thanthesimpledifferenceinpotentialoutcomes,δi,specifiedearlierinEquation(2.1).

Thissetupisanalogoustothedose-responsemodelsformatchingestimatorsdiscussed
in Section 5.5.4, but it explicitly leaves open the possibility that the dose-response
relationship varies across individuals even though it remains linear.

Angrist and Krueger (1999) show in a very clear example how both a linearity
assumption on the individual-specific, dose-response relationship and a fully flexible
coding of adjustment variables results in an OLS weighting scheme for the average
value of βi in a sample that is even more complex than what we discussed earlier
for simple binary causes (see Regression Demonstration 2). A form of conditional-
variance weighting is present again, but now the weighting is in multiple dimensions
because least squares must calculate average derivatives across the linearly ordered
causalvariable(seeAngristandKrueger1999,equation34).Becauseonecannotintu-
itively grasp how these weights balance out across all the dimensions of the implicit
weighting scheme (at least we cannot do so), Angrist and Krueger help by offering a
familiarexample:anOLSestimateofthe averagecausaleffectofanadditionalyearof
schoolingonlabormarketearnings,assuminglinearityinyearsofschoolingandusinga
fullyflexiblecodingofadjustmentvariablesforage,race,andresidencelocation.They
show that, for this example, OLS implicitly gives more weight to the causal effect of
shifting from 13 to 14 years of schooling and from 14 to 15 years of schooling than
for much more common differences, such as the shift from 11 to 12 years of schooling
(primarilybecausethenetconditionalunexplainedvarianceofschoolingisgreatestfor
the contrasts between 13 and 14 years and between 14 and 15 years). They also show
that,forthisexample,thepiecewiseincreasesinaverageearningshappentobelargest
for the years of schooling that OLS systematically weights downward. The result is
a least squares estimate under the linearity constraint of .094, which is smaller than
the weightedaverageestimate of.144thatone cancalculate by droppingthe linearity
constraintandthenaveragingyear-specificestimatesoverthemarginaldistributionof
years of schooling.

For other examples, the weighting schemes may not generate sufficiently differ-
ent estimates because the overall weighting is a complex function of the relationship
betweentheunaccountedforvarianceofthecausalvariablewithinstrataoftheadjust-
ment variables and the level of nonlinearity of the conditional expectation function.

But the general point is clear and should be sobering: Linearity constraints across
causal states may lead OLS models to generate nonintuitive (and sometimes mislead-
ing) averages of otherwise easily interpretable stratum-specific causal effects.

6.6.2 The Challenge of Regression Specification
In this section, we discuss the considerableappeal ofwhat can be calledthe all-cause,
complete-specification tradition of regression analysis. We argue that this orientation
is impractical for most of the social sciences, for which theory is too weak and the
disciplines too contentious to furnish perfect specifications that can be agreed on. At
the same time, we argue that inductive approaches to discovering flawless regression
modelsthatrepresentallcausesaremostlyaformofself-deception,eventhoughsome
software routines now exist that can prevent the worst forms of abuse.

Consider first a scenario in which one has a theoretical model that one believes
is true. It suggests all of the inputs that determine the outcome of interest, as a set
of observable variables, and it is in the form of a specific function that relates all
inputs to the outcome. In this case, one can claim to have the correct specification
for a regression of the outcome on some function of the variables suggested by the
theoretical model. The only remaining challenges are then measurement, sampling,
and observation.

The weakness of this approach is that critics can claim that the model is not true
andhencethattheentailedregressionspecificationiswrong.Fightingoffanysuchcrit-
ics with empirical results can then be difficult, given that the regression specification
used to generate the empirical results has been called into question.

In general, if members of a community of competing researchers assert their own
true models and then offer up purportedly flawless regression models, the result may
beawarofattritioninwhichnoscientificprogressispossible.Itisthereforenaturalto
ask: Can the data generate an all-cause, complete-specification regression model that
all competing researchers can jointly adopt?
Thefirststepinansweringthisquestionistodeterminewhatanall-cause,complete
specification would be, which is sometimes simply labeled a “correct specification.”22
Inhis1978bookSpecification Searches: Ad HocInference with Nonexperimental Data,
Edward Leamer lays out the following components of what he labels “The Axiom of
Correct Specification”:
(a)Thesetofexplanatoryvariablesthatarethoughttodetermine(linearly)
the dependent variable must be
(1) unique,
(2) complete,
(3) small in number, and
(4) observable.

(b) Other determinants of the dependent variable must have a probability
distribution with at most a few unknown parameters.

(c) All unknown parameters must be constant. (Leamer 1978:4)
But Leamer then immediately undermines the axiom as it applies to observational
data analysis in the social sciences:
If this axiom were, in fact, accepted, we would find one equation esti-
mated for every phenomenon, and we would have books that compiled
these estimates published with the same scientific fanfare that accompa-
nies estimates of the speed of light or the gravitational constant. Quite
thecontrary,weareliterallydelugedwithregressionequations,alloffering
to “explain” the same event, and instead of a book of findings we have
volumes of competing estimates. (Leamer 1978:4)
OnecanquibblewithLeamer’saxiom(e.g.,thatcomponent(a)(3)isnotessentialand
so on), but the literature seems to provide abundant support for his conclusion. Few
examples of flawless regression models suggested by true theoretical models can be
found in the social science literature. One might hope for such success in the future,
but the past 50 years of researchdo not give much reason for optimism.

Leamerinsteadarguesthatmostregressionmodelsareproducedbywhathelabels
a data-instigated specification search, which he characterizes as a Sherlock Holmes
formofinferencewhereinonerefrainsfromdevelopingamodeloranyfirmhypotheses
before first considering extensively all the facts of a case. Leamer argues that this
approach to variable selection and specification is fraught with potential danger and
invalidates traditional notions of inference.

Consider the example of the Catholic school effect on learning, and in particular
the researchof James Colemanand his colleagues. In seeking to estimate the effect of
Catholicschoolingonachievement,Colemandidnotdrawacompletespecificationfor
22Theliteraturehasneverclearlysettledonadefinitionthathasachievedconsensus,butLeamer’s
is as good as any. Part of the confusion arises from the recognition that a descriptively motivated
regressionmodelcanalwaysbedeclaredcorrect,nomatterwhatitsspecificationhappens tobe.

hisregressionmodelsfromaspecifictheoreticalmodelofhumanlearning.Thisdecision
wasnotbecausenosuchmodelsexisted,norbecauseColemanhadnoappreciationfor
the needforsuchmodels.He was,incontrast,wellawareofclassicbehavioristmodels
of learning (see Bush and Mosteller 1955, 1959) that specified complex alternative
mechanisms for sequences of responses to learning trials. Although he appreciated
these models, he recognized (see Coleman 1964:38) that they could not be deployed
effectively in the complex environments of secondary schooling in the United States,
the context of which he had already studied extensively (see Coleman 1961).

As a result, Coleman did not specify a learning model that justified the regression
modelsthathe andhiscolleaguespresented(seeSørensen1998;SørensenandMorgan
2000).23 Their basic specification strategy was instead to attempt to adjust for a
sufficient subset of other causes of learning so that, net of these effects, it could be
claimed that Catholic and public school students were sufficiently equivalent. The
specific variables that Coleman and his colleagues chose to include in their models
were based in part on Coleman’s deep knowledge of what predicts learning in high
school(andonecouldarguethatColemanwasthemostknowledgeablesocialscientist
on the topic in the world at the time). But he and his colleagues also adopted an
empiricalapproach,asindicatedparentheticallyatthe endofthe followingaccountof
their selection of adjustment variables:
Inordertominimizetheeffectsofdifferencesininitialselectionmasquerad-
ing as effects ofdifferences in the sectorsthemselves,achievementsubtests
were regressed, by sector and grade, on a larger number of background
variables that measure both objective and subjective differences in the
home. Some of these subjective differences may not be prior to the stu-
dent’s achievement, but may in part be consequences of it, so that there
may be an overcompensationfor background differences. It was felt desir-
able to do this so as to compensate for possible unmeasured differences in
family background;but of course the results may be to artificially depress
the resulting levels of background-controlled achievement in Catholic and
other private schools. (A few additional background variables were ini-
tially included; those that showed no effects beyond the ones listed in the
following paragraph were eliminated from the analysis.) (Coleman et al.

1982:147)
Coleman and his colleagues then reported that the final list of variables included 10
they considered “clearly prior” to school sector – including family income, parents’
23When the 1982 data on seniors became available to supplement the 1980 data on sophomores,
Colemanandhiscolleaguesdidmovetowardastrongerfoundationfortheirspecifications,providing
an underlying model for the lagged achievement gain regression model that was an outgrowth of
Coleman’s early work on Markov chains and his proposals for longitudinal data analysis (Coleman
1964, 1981). InHoffer et al.(1985:89–91), he andhis colleagues showedthat (subject to restrictions
on individual heterogeneity) the lagged test score model is a linearized reduced-form model of two
underlying rates (learning and forgetting) for the movement between two states (know and don’t
know)foreachitemonthecognitivetest.Althoughthemodelisplausible,itisclearlyconstrainedso
thatitcanbeestimatedwithsimpleregressiontechniques(seeColeman1981:8–9foranexplanation
of his modus operandi in such situations), and this is of course not the sort of constraint that one
mustadoptifoneistrulyinterestedinlayingoutthecorrecttheoretical modeloflearning.

education, number of siblings, and number of rooms in the home – as well as 7 other
variables that they considered “not clearly prior” to school sector – including more
than 50 books in the home, owning a pocket calculator, and having a mother who
thinks the student should go to college after high school.

As so often occurs in causal controversies of public importance, critics found this
resulting list inadequate. From the perspective of their critics, Coleman and his col-
leagueshadnotprovidedaclearenoughaccountingofwhysomestudentswereobserved
in Catholic schools, whereas others were observed in public schools and why levels of
learning shouldbe considereda linearfunction of backgroundandthe specific charac-
teristics selected. After arguing that more would be known when follow-up data were
collectedandtestscoregainsfromsophomoretosenioryearcouldbeanalyzed,Alexan-
der and Pallas (1983) argued that Coleman and his colleagues should have searched
harder for additional adjustment variables:
Failing this [estimating models with pretest and posttest data], another
possibilitywouldbetoscoutaboutforadditionalcontrolsthatmightserve
as proxies for student input differences that remain after socioeconomic
adjustments. One candidate is the student’s curriculum placement in high
school. (Alexander and Pallas 1983:171)
AlexanderandPallasthenlaidoutarationaleforthisproxyapproach,andtheyoffered
modelsthatshowedthatthedifferencesbetweenpublicandprivateschoolsaresmaller
after conditioning on type of curriculum.

Asthisexampleshows,itisoftensimplyunclearhowoneshouldgoaboutselecting
asufficientsetofconditioningvariablestoincludeinaregressionequationwhenadopt-
ing the “adjustment for all other causes” approach to causal inference. Coleman and
colleaguesclearlyincludedsomevariablesthattheybelievedthatperhapstheyshould
not have included, and they presumably tossed out some variables that they thought
they should perhaps include but that proved to be insufficiently powerful predictors
oftestscores.Evenso,AlexanderandPallascriticizedColemanandhis colleaguesfor
too little scouting.24
Leamer,asmentionedearlier,wouldcharacterizesuchscoutingasaSherlockHolmes–
style, data-driven specification search. Leamer argues that this search strategy turns
classical inference on its head:
if theories are constructed after having studied the data, it is difficult to
establishbyhowmuch,ifatall,thedatafavorthedata-instigatedhypoth-
esis. For example, suppose I think that a certain coefficient ought to be
positive, and my reaction to the anomalous result of a negative estimate
is to find another variable to include in the equation so that the estimate
is positive. Have I found evidence that the coefficient is positive? (Leamer
1983:40)
24ContrarytotheforecastsofColemanandhiscritics,afterthe1982datawerereleased,thespecifi-
cationdebatedidnotend.Itsimplymovedontonewconcerns,primarilyhowtoadjustforsophomore
testscores(withorwithoutafamilybackgroundadjustment,withorwithoutcurriculumdifferences,
withonlyasubsetofsophomoretestscores,andwithorwithout adjustmentforattenuation thatis
duetomeasurementerror).

Takento its extreme, the Sherlock Holmes regressionapproachmay discoverrelation-
ships between candidate independent variables andthe outcome variable that are due
to sampling variability and nothing else. David Freedman showed this possibility in a
simple simulation exercise, in which he sought to demonstrate that “in a world with
a large number of unrelated variables and no clear a priori specifications, uncritical
use of standard [regression] methods will lead to models that appear to have a lot of
explanatorypower” (Freedman 1983:152).To show the plausibility of this conclusion,
Freedmanconstructedanartificial datasetwith 100individuals, one outcome variable
Y,and50othervariablesX throughX .The100valuesforeachofthese51variables
1 50
were then independent random draws from the standard normal distribution. Thus,
thedatarepresentcompletenoisewithonlychancedependenciesbetweenthevariables
that mimic what any real-world sampling procedure would produce. The data were
then subjected to regressionanalysis, with Y regressedon X through X . For these
1 50
50variables,1variableyieldedacoefficientwithapvalueoflessthan.05andanother
14hadpvaluesoflessthan.25.FreedmanthenranasecondregressionofY onthe 15
variables that had p values of less than .25, and in this second pass, 14 of them again
turned up with p values of less than .25. Most troubling, 6 of them now had p values
ofless than.05,andthe model asa whole hadan R2 of.36. Frompure noise andsim-
ulated sampling variability, Freedman produced a regressionmodel that looks similar
to any number of those published in social science articles. It had six coefficients that
passed conventional standards of statistical significance, and it explained a bit more
than one third of the variance of the outcome variable.25
The dangerofdata-drivenspecificationsearchesisimportanttorecognize,butnot
allproceduresaresimilarlyindanger,especiallygivendevelopmentssinceLeamerfirst
presentedhiscritiqueinthe1970sand1980s.Thereisanewliteratureondatamining
and statistical learning that has devised techniques to avoidthe problems highlighted
by Freedman’s simulation (see Hastie et al. 2001). For a very clear overview of these
methods, see Berk (2006, 2008). And, as we noted in Chapter 5, there are cases in
whichadata-drivenspecificationsearchisbothpermissiveandpotentiallyquiteuseful.

Consider again the causal graph in Figure 4.10 and suppose that one has a large
number of variables that may be associated with both D and Y in one’s dataset and
that one presumes may be members of either S or X. Accordingly, one has the choice
of conditioning on two different types of variables that lie along the back-door path
from D to Y: the variables in S that predict D or the variables in X that predict
Y. Engagingin a data-drivenspecification searchfor variables that predict Y will fall
preytoinferentialdifficulties aboutthecausaleffectofD onY forexactlythe reasons
just discussed. But a data-drivenspecification searchfor variables that predict D will
not fall prey to the same troubles, because in this search one does not use any direct
information about the outcome Y.

Evenso,data-instigatedspecificationsofregressionequationsremainaproblemin
practice, because few applied social scientists use the fair and disciplined algorithms
in the statistical learning literature. The Catholic school example is surely a case in
25Raftery (1995) repeated Freedman’s simulation experiment and obtained even more dramatic
results.

which scouting led to the inclusion of variables that may not have been selected by
a statistical learning algorithm. But, nonetheless, none of the scholars in the debate
dared to reason backwards from their regression models in order to declare that they
hadinductivelyconstructedatruemodeloflearning.And,ingeneral,itishardtofind
examplesofcompleteinductivemodelbuildinginthepublishedliterature;scholarsare
usuallydrivenbysometheoreticalpredilections,andthe resultsofmistakeninduction
are often fragile enough to be uncoveredin the peer review process.26 Milder forms of
misspecification are surely pervasive.

## 6.7 Conclusions

Regressionmodels,intheirmanyforms,remainoneofthemostpopulartechniquesfor

theevaluationofalternativeexplanationsinthesocialsciences.Inthischapter,wehave
restricted most of our attention to OLS regression of an interval-scaled variable on a
binarycausalvariable.And,althoughwehaveconsideredhowregressionmodelingcan
be used as a descriptive data reduction tool, we have focused mostly on regressionas
a parametric adjustment technique for estimating causal effects, while also presenting
someoftheconnectionsbetweenregressionandmatchingascomplementaryformsofa
moregeneralconditioningestimationstrategy.We concludethischapterbydiscussing
the strengths and weaknesses of regression as a method for causal inference from
observational data.

The main strengths of regression analysis are clearly its computational simplic-
ity, its myriad forms, its familiarity to a wide range of social scientists, and the ease
with which one can induce computer software to generate point estimates and stan-
dard errors. These are all distinct advantages over the matching techniques that we
summarized in Chapter 5.

But, as we have shown in this chapter, regressionmodels have some serious weak-
nesses. Their ease of estimation tends to suppress attention to features of the data
that matching techniques force researchers to consider, such as the potential hetero-
geneity of the causal effect and the alternative distributions of covariatesacross those
exposed to different levels of the cause. Moreover,the traditional exogeneity assump-
tion of regression (e.g., in the case of least squares regression that the independent
variablesmustbe uncorrelatedwiththe regressionerrorterm)oftenbefuddles applied
researchers who can otherwise easily grasp the stratification and conditioning per-
spective that undergirds matching. As a result, regressionpractitioners can too easily
accepttheirhopethatthespecificationofplausiblecontrolvariablesgeneratesanas-if
randomized experiment.

Focusing more narrowly on least squares models, we have shown through several
demonstrations that they generate causal effect estimates that are both nonintuitive
andinappropriatewhenconsequentialheterogeneityhasnotbeenfullyparameterized.

In this sense, the apparent simplicity of least squares regressionbelies the complexity
26However, predictions about the behavior of financial markets can come close. See Krueger and
Kennedy (1990) for discussion and interpretation of the apparent effect of Super Bowl victories on
thestockmarketindicesintheUnitedStates.

of how the data are reduced to a minimum mean-squared-errorlinear prediction. For
more complex regression models, the ways in which such heterogeneity is implicitly
averagedarecurrentlyunknown.Butnooneseemstosuspectthatthecomplicationsof
unparameterizedheterogeneityare less consequential for fancier maximum-likelihood-
based regressionmodels in the general linear modeling tradition.

# Chapter 7

# Weighted Regression Estimators of Causal EffectsWith an Extended Example of a Weighted Regression Alternative to Matching

In the last chapter, we argued that traditional regression estimators of casual effects

havesubstantialweaknesses,especiallywhenindividual-levelcausaleffects arehetero-
geneousinwaysthatarenotexplicitlyparameterized.Inthischapter,wewillintroduce
weighted regression estimators that solve these problems by appropriately averaging
individual-levelheterogeneityacrossthetreatmentandcontrolgroupsusingestimated
propensity scores. In part because of this capacity, weighted regressionestimators are
nowatthefrontierofcausaleffectestimation,alongsidethelatestmatchingestimators
that are also designed to properly handle such heterogeneity.

In the long run, we expect that weighted regression estimators will prove to be a
common choice among alternative conditioning procedures that are used to estimate
causal effects. In fact, we expect that weighted regression estimators will be used
more frequently than the matching estimators presented in Chapter 5 when there is
good overlap in the distributions of adjustment variables across the treatment and
control groups. We have four primary reasons for this prediction, each of which we
will explain in this chapter. First, weighted regression estimators allow the analyst
to adopt the spirit of matching, and the clear thinking that it promotes, within a
mode of data analysis that utilizes widely available software and that is familiar to
most social scientists. Second, in contrast to their traditional unweighted analogs,
weightedregressionestimatorscanbe usedto generatedirectestimates ofthe average
treatmenteffect,averagetreatmenteffectforthetreated,andaveragetreatmenteffect
226
forthecontrols(ATE,ATT,andATC)inthepresenceofindividual-levelheterogeneity.

Third,incontrasttomatchingestimators,thecalculationofstandarderrorsforaverage
causal effect estimates is straightforward. Fourth, weighted regression estimators can
be utilized when analyzing complex survey data of many types.

Nonetheless, caution is still warranted, and additional work is needed on a vari-
ety of crucial issues before our prediction can be evaluated. In addition to determin-
ing whether some advantages are real (e.g., the range of conditions under which the
straightforward standard errors are also correct), some special challenges remain for
determining the ultimate value of weighted regression estimators. Most importantly,
aswe will explainin detail below, the estimationof the weightsthat arepassedto the
regressionroutine is at least as difficult as the estimation of the propensity scores for
matching routines. And, at present, no consensus exists on how sensitive conclusions
are to variation in estimated weights, especially when some of the individual-specific
weights appear unduly large.

In the remainder of this chapter, we will first introduce weighted regression esti-
matorsfortheATE,ATT,andATC.Wewillthenpresent“doublyrobust”estimators
that use the conditioning variables twice – first to estimate the relevant weights and
then to adjust for remaining imbalance that is not eliminated by the weights. After a
discussionofpracticalissues,includingtheconcernoverestimatedweightsthatappear
extreme,wewillconcludethechapterwithanextendeddemonstrationthatshowsthe
value of weighted regressionfor direct estimation of the ATT and ATC.

Before offering this material, we should clarify that we will be writing narrowly
abouttheusageofmodel-basedweightstoestimateaveragetreatmenteffects.Weighted
regressionas a data analysis procedure is a much more general topic, and it has been
used frequently for two other distinct purposes. First, regression equations can be
weightedbyindividual-specificestimatesoftheinversevarianceofthe regressionerror
term,whichresultsinaweightedregressionformofafeasiblegeneralizedleastsquares
(FGLS) estimator.1 The goal of the weighted estimator in this case is to promote
efficiency of estimation, relative to unweighted ordinary least squares (OLS), in the
presence of heteroscedasticity. Second, sampling weights, when not solely a function
of the observed variables in the regression model, are used to weight regression equa-
tions in order to generate coefficients that can be interpreted as consistent estimates
of population-level parameters. Although we will not consider FGLS estimators here,
we will consider how sampling weights can be used along with the propensity-score-
based weights that we will present in this chapter. Nonetheless, the justification for
usingsamplingweightsisdistinctfromthegoalsofgeneratingconsistentandunbiased
estimates of the ATE, ATT, and ATC by using weights to adjust for confounding.

## 7.1 Weighted Regression Estimators of the ATE

In this section, we show how weighted regression estimators can be used to gener-

ate consistent and unbiased estimates of the ATE, as long as conditioning variables
that satisfy the back-door criterion have been observed and properly utilized. These
1Fordetails,seeanyregressiontextbook, suchasDraperandSmith(1998)orGreene(2000).

methods have diverse and overlapping origins – inverse probability weighting in sur-
vey statistics (see Kish 1965, 1987; Thompson 2002), missing data imputation and
survey nonresponse adjustment via weighted complete-case analysis (see Little 1982;
Little and Rubin 2002), weighting procedures in multiple regression analysis for data
from stratified samples (see DuMouchel and Duncan 1983), propensity-score mod-
els and general methods for modeling the probability of treatment assignment (see
Rosenbaum and Rubin 1983b; Rubin 2006; Rubin and Thomas 2000), direct adjust-
ment estimators (see Rosenbaum 1987, 2002), econometric evaluation estimators
(Imbens 2004; Imbens and Wooldridge 2009), and inverse probability of treatment
weighting in epidemiology (see Robins and Hernn 2009; Robins and Ritov 1997; van
der Laan and Robins 2003).

Recallfirstthe hypotheticalexampleinMatchingDemonstration3(seepage153),
where matching was considered a method to weight the data in order to balance
predictors of treatment assignment and thereby calculate contrasts that can be given
causalinterpretations.Inthissectionandthenext,weshowthatthethreepropensity-
score-weighting estimators presented there as Equations (5.12) through (5.14) can be
specified as three weighted regressionestimators.

To estimate the ATE with weighted regression, one first must estimate the pre-
dicted probability of treatment, pˆi, for units in the sample, which is again the esti-
mated propensity score. All of the methods discussed so far can be used to obtain
these estimated values. Once the values for pˆi are obtained, weights for the ATE are
constructed as
1
For di=1: wi,ATE= ,
pˆi
(7.1)
1
For di=0: wi,ATE= 1−pˆi.

These weights are equivalent in structure to survey weights that must be used to
weightcomplexsamples so thatthey arerepresentativeof their respectivetargetpop-
ulations. Here, the weights, wi,ATE, can be used to weight those in the treatment
group and those in the control group so that both of these groups have the same
weighted distribution on (observed) determinants of treatment assignment as the full
population(where,inthis case,the full populationofinterestiscomposedofboththe
population-level treatment group and the population-level control group).

To then estimate the ATE, a weighted bivariate regression model is estimated,
whereyiarethevaluesfortheoutcome,di arethevaluesforthesolepredictorvariable,
and wi,ATE are the weights. No specialized software is required, and the weights are
treatedexactlyasiftheyaresurveyweights(eventhoughtheyarenotsurveyweights,
but instead weights based on estimated propensity scores that are relevant only for
the estimation of the ATE).

For those accustomed to matrix representations of regression estimates, note first
that the naive estimator in Equation (2.9) can be written as an OLS estimator,
(Q(cid:2)Q)−1Q(cid:2)y, where (1) Q is an n×2 matrix that contains a vector of 1s in its first
column and a vector of the values of di for each individual in its second column and
(2)yisann×1columnvectorcontainingvaluesofyi foreachindividual.Toestimate
the ATE, a weighted regressionestimator is utilized,
δˆ OLS,weighted≡(Q(cid:2) PQ)−1Q(cid:2) Py, (7.2)
where P is an n × n diagonal matrix with the corresponding value of wi,ATE on the
diagonalforeachindividualandzeroelsewhere.Considerthefollowingdemonstration,
whichbuildsdirectlyonthepriorpresentationofmatchingasweightinginSection5.3.

Weighted Regression Demonstration 1
For Matching Demonstration 3 (see page 153), consistent and unbiased estimates of
the ATE were generated from averages of estimates of the ATT and the ATC. These
estimates of the ATT and ATC were differences in weighted averages of the values of
yi, constructed using weights defined by pˆi. In the demonstration we offer here, we
will show how the same estimates of the ATE can be generated directly by weighted
regression. We will dispense with the Monte Carlo setup from Matching Demonstra-
tion 3, which offers little additional insight, and we will instead shift to the simpler
scenariowe have used elsewhere in demonstrations, where we assume an infinite sam-
ple. We will, however,vary the setup for the potential outcomes in order to show how
weighted regressioncan easily handle nonlinearities in the relationships that generate
the propensity scores and the potential outcomes.

AsshownforMatchingDemonstration3inEquations(5.8)and(5.9),thepotential
outcomes were specified as functions of individual values for A and B:
y i1=102+6ai+4bi+υ i1, (7.3)
y i0=100+3ai+2bi+υ i0, (7.4)
whereA andB aredistributed asindependent uniformrandomvariableswith a mini-
mum of .1 and a maximum of 1, and where υ1 and υ0 are independent randomdraws
i i
fromanormaldistributionwith expectation0andastandarddeviationof5.Foreach
individual, yi is then equal to y i1(di)+(1−di)y i0, where the value of di is determined
by a Bernoulli distribution with the probability of 1 rather than 0 as the nonlinear
function in A and B that is presented in Figure 5.1 on page 154.

ThefirstpanelofTable7.1reproducesthetrueATEforthisexamplefromtheprior
Table 5.5, whichis 4.53. The secondpanel of Table 7.1 introduces a secondvarianton
the basic setup for Matching Demonstration 3. For this variant, Equations (7.3) and
(7.4) are replaced with
y i1=102+3ai+2bi+6(ai×bi)+υ i1, (7.5)
y i0=100+2ai+1bi−2(ai×bi)+υ i0, (7.6)
but everything else remains the same. These alternativepotential outcome definitions
resultin a slightly more dramatic pattern for the averagetreatment effects (in partic-
ular, for the ATT and ATC, as will be discussed in the next demonstration where we
willestimatethesedirectly).Fornow,thissecondvariantgeneratesaslightlydifferent
value for the true ATE, which is 5.05 rather than 4.53.

For each variant of this hypothetical example, we first offer three coefficients on
D from unweighted OLS regression models using three different specifications: (1) Y
Table 7.1 Weighted RegressionEstimates of the
ATE, Using and Extending the Data Setup for
Matching Demonstration 3
ATE
Variant I:Y1and Y0 linear in A and B
True treatment effect 4.53
OLS regression estimates:
Yregressed on D 5.39
Yregressed on D and linear A and B 4.75
Yregressed on D and quadratic A and B 4.74
ATE-weighted regression of Yon D 4.53
Variant II:Y1and Y0 nonlinear in A and B
True treatment effect 5.05
OLS regression estimates:
Yregressed on D 5.88
Yregressed on D and linear A and B 5.47
Yregressed on D and quadratic A and B 5.44
ATE-weighted regression of Yon D 5.05
regressedonD, (2) Y regressedonD,A, andB,and(3) Y regressedonD, A,A2,B,
andB2. NoneoftheseunweightedOLSestimates isparticularlycloseto itsrespective
trueATEforeithervariant,andthequadraticspecificationsofAandB helponlyvery
little. Unweighted regression has invoked the form of implicit weighting explained in
Section 6.3, and as a result even in an infinite sample the estimated parameter would
not equal to the true ATE, only a variant of it that invokes supplementary weighting
by the conditional variances of A and B.

Forthelastrowofeachpanel,wethenimplementedtheweightedregressionmodels
specified earlier in Equation(7.2). For these estimates, we take the estimated propen-
sity scores from the row labeled “Perfectly specified propensity score estimates” in
Table5.5,formwi,ATE,asinEquation(7.1),andestimateaweightedbivariateregres-
sionmodel, where we implicitly assemble Pby declaringthe values for wi,ATE assur-
vey weights in the weighted regression routine. Both resulting estimates land exactly
on the target true ATE, as will always be the case in a sufficiently large dataset if
the propensity scores are estimated flawlessly. No supplemental conditional-variance
weightingis introducedinto the estimatorbecause the informationonA andB enters
the model only through the values of pˆi that then structure the weights.

Several caveats should be mentioned before we proceed. First, as with nearly all
other estimatorswe haveconsideredsofar, these results holdonly inexpectationover
repeatedsamplesorintheprobabilitylimitasasinglesampleincreasestoinfinity.Sec-
ond,fortheresultstoemergeascleanlyasinthisdemonstration,thepropensityscores
mustbeestimatedflawlessly.Misspecificationofthepropensity-score-estimatingequa-
tionwillpushthepointestimateoffofthetargetATEparameter.Althoughthelitera-
ture has not yet systematically exploredhow sensitive point estimates are to different
types and degrees of misspecification, it is clear that a misspecified propensity-score-
estimating equation will not generate weights that will balance the underlying deter-
minantsoftreatmentassignmentforthesameargumentsdiscussedalreadyinChapter
5. Third, even if the weights are correct because the propensity scores are flawlessly
estimated,thepointestimateswillbeimpreciseacrosshypotheticalrepeatedsampling
for finite datasets if large weights result after estimated propensity scores are passed
toEquation(7.1).2 Largevaluesforwi,ATE willbepresentiftheestimatedpropensity
score, pˆi, is either very close to 0 or very close to 1, for treatment or control cases,
respectively. Nonetheless, Imbens and Wooldridge (2009:35) offer the somewhat com-
fortingpositionthat“theseconcernsarelessseriousthanthoseregarding[unweighted]
regressionestimators because at least the...[weighted regression]estimates will accu-
rately reflect uncertainty.” In Section 7.4 on practical issues that confront weighted
regressionanalysis,wewilldiscussaliteraturethatconsiderstheconsequencesoflarge
weights and that advocates truncation of the distribution of the weights in some situ-
ations. Next, however, we will present equivalent estimators for the ATT and ATC.

## 7.2 Weighted Regression Estimators of the ATT and the ATC

Toestimatethe ATTandATC, asimilarprocedurecanbeadoptedafterconstructing

appropriate weights, which are again functions of the estimated propensity scores, pˆi.

In particular, two sets of weights wi,ATT and wi,ATC are formed as
For di=1: wi,ATT=1, (7.7)
pˆi
For di=0: wi,ATT= 1−pˆi,
and
1−pˆi
For di=1: wi,ATC= , (7.8)
pˆi
For di=0: wi,ATC=1.

Again, these weights are analogs to survey weights, but the target population is no
longer the total population comprising the population-level treatment and control
groups together.3 Instead, when using the weight wi,ATT, the population-level treat-
mentgroupbecomesthetargetpopulation.Accordingly,theweightleavesthesampled
2Inthiscase,theestimatescanstillberegardedasconsistentfortheATE.But,foranysinglefinite
sample, the point estimate of the ATE may not be close to the true ATE because of consequential
samplingvariabilityinthetailsofthedistributionofthepropensityscore.

3However,theyarenotthesameanalogs.Theweightw i,ATEisanalogoustoasurveyweight,and
inparticularthesurveyweightsknownasHorvitz-Thompson(HT)weights.HTweightsareequalto
1/π i,whereπ istheprobabilitythatindividualifromthepopulationwillbeincludedinthesample
i
treatmentgroupunaltered(becausewi,ATT=1forthoseinthetreatmentgroup),but
it attempts to turn the control group into a representative sample of the population-
1−pˆi
level treatment group (because wi,ATT= for those in the control group). More
pˆi
specifically, there are two distinct pieces of the weight that is applied to the control
group. The denominator of wi,ATT, is the same as for wi,ATE, 1−pˆi, and it therefore
weights the distribution of the control cases toward the full population, giving rela-
tively more weight to cases with larger propensity scores. The numerator of wi,ATT,
pˆi, then accentuates the relative weighting induced by the denominator so that the
control cases are properly weighted toward the target treatment group, not the full
population.4 The weight wi,ATC works in the opposite direction.

As with the ATE, to estimate point values for the ATT and ATC, one estimates a
weightedbivariateregressionmodelofY onD,specifyingthecorrespondingweightfor
the parameter of interest. The same weighted estimator in Equation (7.2) is utilized,
but now the n × n diagonal matrix P is specified with either wi,ATT or wi,ATC
on its diagonal, as we show now for a continuation of the same weighted regression
demonstration.

Weighted Regression Demonstration 1 (Continued)
This demonstration is a continuation of Weighted Regression Demonstration 1 (see
page229)becausethe samesetupisutilized, andthe modelsdifferonlyintheweights
that are specified. However, the two variants of the data setup show their differences
moreclearlyinthiscontinuation,becausetheyweredesignedtoyielddifferentpatterns
of true values for the ATT and ATC.

As shown in the first panel of Table 7.2, the true ATT and ATC are 4.89 and
4.40,respectively,for VariantI. But, as shownin the secondpanel, the true ATT and
ATC are 5.77 and 4.79 for Variant II. For this second variant, the opposite-signed
parameters specified for the cross-product interactions of A and B in Equations (7.5)
(alsoknownasthesamplingprobabilityforindividuali).FortheATEweightsinEquation(7.1),the
values for pˆi and 1−pˆi are each treated as if they are the HT inclusion probabilities, and two HT
weights are used to standardize the treatment and control groups to the full population (as if the
treatment and control groups aresamples fromthe population based on different designs that must
then be weighted in different ways to be representative of the same original target population). In
contrast, the ATT and ATC weights, w i,ATT and w i,ATC in Equations (7.7) and (7.8), are either
equal to 1 or are the odds of values that correspond to HT sampling probabilities. The latter align
the treatment or control group with the group that receives uniform weights of 1 for each target
parameter. As such, the analog for the odds embedded within the weights w i,ATT and w i,ATC are
ratioadjustmentstobaseweights(eitherbaseweightsequalto1forsimplerandomsamplesorequalto
HTsurveyweightsortheirgeneralizationsformorecomplexdesigns).Accordingly,itisquitenatural
to multiply the weights w i,ATT and w i,ATC by any survey weights that adjust for an underlying
surveydesign,aswewilldolaterinthischapterwhenanalyzingdatafromthe2002and2004waves
oftheEducationLongitudinalStudy.Forthegeneralreasoningbehindthemultiplicationofweights,
seeLevy,Lemeshow,Biemer,andChrist(2008)andValliant,Dever,andKreuter(2013,chapter13).

4Inotherwords,foracontrolcasewithalowpropensityscore,thenumeratorfurtherdecreasesthe
weightbecausethecaseisunlikelytoreflectthecharacteristicsofthetreatmentgroup.Forexample,
forpˆi=.2,w i,ATE= 1−1 = 1−1 .2=1.25whilew i,ATT= 1−pˆi = 1−.2 .2=.25.Foracontrolcasewitha
pˆi pˆi
highpropensityscore,thenumeratorstilldecreases theweight,butitdoes sorelativelylessbecause
the caseismorelikelytoreflect thecharacteristics ofthe treatment group. Forexample, forpˆi=.8,
w i,ATE= 1−1 = 1−1 .8=5whilew i,ATT= 1−pˆi = 1−.8 .8=4.

pˆi pˆi
Table 7.2 Weighted Regression Estimates of the ATT and
ATC, Using and Extending the Data Setup for Matching
Demonstration 3
ATT ATC
Variant I: Y1and Y0 linear in A and B
Truetreatment effects 4.89 4.40
OLSregression estimates:
Yregressed on D 5.39 5.39
Yregressed on D and linear A and B 4.75 4.75
Yregressed on D and quadraticA and B 4.74 4.74
ATTor ATC weighted regression of Yon D 4.89 4.40
Variant II: Y1and Y0 nonlinear in A and B
Truetreatment effects 5.77 4.79
OLSregression estimates:
Yregressed on D 5.88 5.88
Yregressed on D and linear A and B 5.47 5.47
Yregressed on D and quadratic A and B 5.44 5.44
ATTor ATC weighted regression of Yon D 5.77 4.79
and (7.6) ensure that those with high levels of A and B together have much larger
individual-level treatment effects than others. For Variant I, the differential sizes of
thetreatmenteffects areseparableinto simplelinearpiecesthatcanbe independently
attributed to A and B, as shown in Equations (7.3) and (7.4).

For each panel of Table 7.2, the same three unweighted OLS regression estimates
alreadyreportedforTable7.1arereportedagain.Now,theyareplacedinbothcolumns
because standard unweighted OLS regression estimators do not differentiate between
the ATE, ATT, or the ATC. The estimator is the same for each target parameter
becauseit is often regardedas anestimatorofanimplicit constantstructuraleffect of
D onY,whichwouldrendertheATE,ATT,andATCequaliftheconstant-coefficient
assumption were true.

Forthelastrowofeachpanel,wethenimplementedtheweightedregressionmodels
specified earlier inEquation ( 7.2). For these estimates, we again took the estimated
propensityscoresfromtherowlabeled“Perfectlyspecifiedpropensityscoreestimates”
in Table 5.5, but now we formed the weights wi,ATT or wi,ATC in Equations (7.7)
and (7.8). Unlike the unweighted regression estimates, the ATT-weighted and ATC-
weighted regression estimates land exactly on their respective target parameters for
eachvariant.Inaddition,theyeffectivelyundothecomplexpatternofnonlinearityfor
VariantII,wherethe propensityscoresandthe potentialoutcomesarebothnonlinear
in A and B.

As for the weighted regression estimates of the ATE, these results only hold over
repeatedsamplesfromthesamepopulationorintheprobabilitylimitasasinglesam-
ple approachesinfinity. And the same caveatsintroduced in Section 7.1 still obtain. If
the equation that estimates the propensity scores is misspecified, then the estimates
of the ATT and ATC will be inconsistent and biased because the weights will not
fully balance the underlying determinants of treatment assignment. In addition, dis-
proportionately small or large weights may still emerge even if the propensity scores
are estimated flawlessly, and in these cases the estimates may be imprecise (i.e., still
consistentbutnotnecessarilyclosetothetrueATTorATCinthesinglefinitesample
under analysis).

## 7.3 Doubly Robust Weighted Regression Estimators

Many perspectives existon how matching andregressioncanbe combined. In Section

6.5, we demonstrated how parametric regression can be used to provide supplemen-
tal adjustment for matching estimators, following several decades of practice in the
applied matching literature.The rationale for this type of adjustment is that the cho-
sen matching routine has almost certainly not eliminated all of the imbalance in the
observedtreatmentassignmentvariables,andapost-matchparametricregressionthat
adjustsforthesamevariableswhilealsoestimatingthetreatmenteffectmayeliminate
at least some of the lingering imbalance.

An alternative but related perspective has also been discussed at several points,
and it has more recent origins. Rather than consider regression as a supplement to
an imperfect matching routine, one can consider matching as a remedy to artifac-
tual regression results that have been produced by incautious data mining. Ho et al.

(2007) suggest that the general procedure one should carry out in any multivariate
analysis that aspires to generate causal inferences is to first balance one’s data as
much as possible with a matching routine and then estimate a regression model on
the matched data. From this perspective, matching is a preprocessor, which can be
used to prepare the data for subsequent analysis with something such as a regression
model.

Both of these perspectives are motivated by the goal of giving the analyst two
chances to “get it right,” first with a matching routine and second with a parametric
regressionmodel.Inthissection,wepresentthemostinfluentialversionofthisencom-
passing strategy. For the estimators presented in Sections 7.1 and 7.2, the observed
determinantsoftreatmentassignmentwereusedonlytoestimatethepropensityscores.

In this section, we present a related set of estimators that use these same variables a
secondtime, aspartofthe regressionmodelthatgeneratesthepointestimates.Recall
Equation (7.2),
δˆ OLS,weighted≡(Q(cid:2) PQ)−1Q(cid:2) Py,
wherewedefinedtheQmatrixascontainingacolumnof1sandacolumnofindividual-
level values di for the treatment variable, along with a diagonal matrix P that
represents a set of weights specific to the target parameter. For this estimator, as
used up until this section, treatment assignment variables are presumed to have been
used only in a first stage to estimate the values of pˆi, which then structure the appro-
priate weights in P. The estimators that we present and demonstrate in this section
usethesamevariablesasecondtimeassupplementaryadjustmentvariables.Theesti-
mator in Equation (7.2) is still used, but these variables are included in additional
columns in Q.

The idea is to offer what James Robins and his colleagues refer to as a “doubly
robust”or“doublyprotected”estimator(seeBangandRobins2005;RobinsandRot-
nitzky2001).RobinsandRotnitzkyreflectonthefallibilityofbothstandardregression
methods, as presented in Chapter 6, as well as propensity-score-basedweighting esti-
mators, as presented in Sections 7.1 and 7.2:
There has been considerable debate as to which approach to confounder
control is to be preferred, as the first is biased if the outcome regression
model is misspecified while the second approachis biased if the treatment
regression,i.e.,propensity,modelismisspecified.Thiscontroversycouldbe
resolved if an estimator were available that was guaranteed to be consis-
tent...whenever atleast one of the two models wascorrect....We refer to
such combined methods as doubly-robust or doubly-protected as they can
protectagainstmisspecificationofeither the outcome ortreatmentmodel,
although not against simultaneous misspecification of both. (Robins and
Rotnitzky 2001:922)
Thebasicmotivationistogivetheanalysttwochancesto“getitright,”inhopesthat
misspecifications of the propensity-score-estimating equation and the final regression
equation will neutralize each other. And, although Robins is credited with developing
the recentasymptotic justification for a variety ofspecific procedures(see Robins and
Hernn 2009; Robins and Ritov 1997; Robins, Rotnitzky, and Zhao 1994; Scharfstein,
Rotnitzky, and Robins 1999; and van der Laan and Robins 2003), the idea of using
matching and regression together is quite general and has a long legacy in applied
work, as we noted earlier in Section 6.5 (see Cochran and Rubin 1973; Gelman and
King 1990; Heckman, Ichimura, and Todd 1998; Hirano and Imbens 2001; and Rubin
and Thomas 1996,2000).

Because we used flawlessly estimated propensity scores for an infinite sample in
Weighted Regression Demonstration 1, there would be no value in demonstrating the
doublyrobustestimationstrategyforthesamesetup.Wedonotneedasecondchance
to“getitright.”Instead,wenextofferademonstrationwithdoublyrobustestimators,
where we use simulated data and vary our capacity to “get it right” when estimating
the propensity scores.

Weighted Regression Demonstration 2
Forthis demonstration,we revisitMatchingDemonstration4 andRegressionDemon-
stration 4 (see pages 171 and 216, respectively). We will use the same 10 simulated
datasets for the Catholic school effect on learning, modeled on the National Edu-
cation Longitudinal Study (NELS) data analyzed in Morgan (2001). Recall that for
this hypothetical substantive example, we have concluded that only the ATT can be
estimated with any degree of confidence because we have not observed variables that
wouldallowustodirectlymodelself-selectionontheindividual-leveleffectofCatholic
schooling.

We already showed in Regression Demonstration 4 that matching performs well
when the complete specification of treatment assignment is used, along with a sup-
plementary regression adjustment. The reason for this result is precisely the double
protection argument outlined above. The varying level of imbalance that remains for
eachmatching estimatorcanbe seenas slightmisspecificationofthe matchingmodel,
whichisproducedeitherbecausethepropensityscoremodelhasnotbeenrespecifiedto
removeasmuchimbalanceaspossibleorbecausethe matchingalgorithmhasfeatures
that render it suboptimal for the particular application. The supplemental regression
adjustments,asshowninTable6.8,reducethe averagebiasinthe matchingestimates
because they further adjust for remaining imbalance in the means of the matching
variables. As such, the matching and supplementary adjustment are workingtogether
to minimize bias in the estimates of the ATT, using the double protection reasoning
introduced above.

In the demonstration we offer here, we will present doubly robust estimates from
ATT-weighted regression models for the same 10 simulated datasets. As shown in
Table 7.3, we again use estimated propensity scores from two scenarios, where for
the incomplete specification we omit the crucial cognitive skills variable as well as
additionalhigher-orderandinteractionterms.We thenestimate theATT,usingthese
two sets of propensity scores in two ways, first as simple weighted ATT estimators as
for Weighted Regression Demonstration 1 but also now as doubly robust estimators
as defined in this section.

For the first row of Table 7.3, we report the minimum, maximum, and average
bias of ATT-weighted regression estimates under both specifications of the models
that generate the values of pˆi across all 10 simulated datasets. These bias values are
directlycomparabletothoseofthe19matchingestimatorsreportedearlierinTable5.7
forMatchingDemonstration4.Asshownhere,thebiasissubstantialfortheweighted
regression estimates that use the incomplete specification to estimate the propensity
scores. This result is the same as for the matching estimators reported in Table 5.7,
and the bias is produced mostly because of the exclusion of the variable for cognitive
skills. In contrast, the average bias for the weighted regressionestimates that use the
complete specification to estimate the propensity score is small. In fact, the average
biasoftheATT-weightedregressionisinthemiddleofthedistributionofaveragebias
of all 19 matching estimators reported in the final column of Table 5.7.

For the second row of Table 7.3, the equivalent bias values are reported for the
doublyrobustestimators,wheretheassumedtreatmentassignment/selectionvariables
are used a second time in the outcome regressionequations. Perhaps surprisingly, the
double protection of supplementary regression adjustment does not narrow the aver-
age bias further (and, in fact, may even increase it for these 10 samples). This result
Table 7.3 Bias for Weighted Regression Estimates of the ATT, Catholic
Schooling on Achievement Across 10 Simulated Datasets Utilized for Matching
Demonstration 4 and RegressionDemonstration 4
Specification of treatment assignment variables:
Incomplete specification Complete specification
Method Min, Max Average Min, Max Average
Weighted regression estimate of
theATT −0.08, 2.17 0.82 −0.87, 1.11 −0.09
Doubly robust weighted
regression estimate
of the ATT −0.05, 2.19 0.83 −0.87, 1.08 −0.10
departsfromwhatweshowedinTable6.8forthesame10datasetswhensupplemental
regressionwasusedtoeliminatesomeoftheremainingbias.There,asopposedtohere,
one can see clear evidence of double protection.

Thereasonthatthebiasisrelativelyunchanged,forthisdemonstration,andhence
littleevidenceofdoubleprotectionseemstoemerge,isthattheATTandATCweights
arealreadyverywellestimatedinthesensethattheyleaveverylittleimbalanceinthe
data on the observed values that generate them. In particular, the logit estimation of
the propensity scores matches the assumed logistic distribution for the true propen-
sity scores. As such, no unusual weights emerge because, on average, the parametric
structureoftheestimatedlogitmodeldoesnotforceanunwarranteddistributiononto
the values of pˆi.

Isthisresulttypicalforweightedregressionestimators?Iftheweightsareestimated
very well in the sense that they effectively represent all of the relevant information in
the determinants of treatment assignmenton which they are based(as can usually be
discernedbyanexaminationofbalance),thensupplementaryadjustmentbythetreat-
mentassignment/selectionvariableswillhavelittle ornoeffectontheestimates.None
ofthevirtuouseffectsofdoubleprotectionwouldbeevidentbecausethesupplemental
adjustment is redundant. In many cases, especially for small datasets, these condi-
tions will not be present, and the supplementary adjustment will offer clear double
protection.

As this demonstrationand the last show, propensity scores can be used effectively
withinaweightedregressionframeworktoestimateaveragecausaleffects.Thecaveats
noted in Section 7.1 continue to apply, and in the next section we will discuss these.

In the section that follows the next, we will offer an extended and realistic example
with genuine data, which demonstrates how effective weighted regressionestimates of
the ATT and ATC can be, but also how carefully they must be interpreted, just like
all other estimators considered in Chapters 5 through 7.

## 7.4 Remaining Practical Issues in Weighted Regression Analysis

Inthis section,we bridgethe simulatedresults forthis chapterwith a relatedbutreal

application.Wefirstdiscusstheneedtoconsidertheconsequencesofhavingestimated
weights that may appear to be unreasonably large. We then discuss how and why
weighted regression estimates have a distinct advantage over matching methods in
their ability to handle survey data, which is rarely generated by a simple random
sample. Finally, we consider alternatives for estimating standard errors.

We will not discuss here some issues that are common to both matching and
weighted regression estimators. Our prior discussions of estimation when treatment
assignment is nonignorable (Section 5.5.1), estimation on the region of common sup-
port (Section 5.5.2), and estimation for many-valued treatments (Section 5.5.4) apply
toweightedregressionestimatorsaswellinonlyslightlymodifiedwaysthatshouldbe
obvious.

7.4.1 The Concern Over Extreme Weights
As we noted when introducing weighted regression estimators of the ATE, it is pos-
sible to generate large weights if the estimated propensity score, pˆ, is close to 0 or 1.

Similarly,for the weightsusedto estimate the ATT andATC,valuesofpˆcloseto 0or
1 will generate either small or large weights. The literature on propensity-score-based
weighting includes a number of decidedly skeptical pieces (e.g., Freedman and Berk
2008), some of which focus on the consequences of such weights (e.g., Lee, Lessler,
and Stuart 2011). In some pieces, which we will not cite, manifestly poor weights
have been used to demonstrate the obvious point that estimated propensity scores
will not necessarily balance the data or warrant a causal inference. The more revela-
tory work demonstrates why one should proceed with caution when the estimation of
the propensityscoresgeneratesdisproportionatelylargeweights,whichmay thengive
undue influence to only a very few members of a givensample. Yet, the literature has
not determinedprecisely whensmall andlargeweightsshould be regardedas extreme
or, more deeply, when extreme weights should be regarded as problematic.

Toapproachthe keyissues,firstconsiderthree scenariosinwhichextremeweights
might emerge:
1. The weights are basedon an empirical model of treatment assignmentthat uses
observed variables as predictors that do not collectively sustain the relevant
ignorability assumption.

2. The weights are basedon an empirical model of treatment assignmentthat uses
observedvariablesaspredictorsthatsustaintherelevantignorabilityassumption,
but the model is nonetheless misspecified so that the estimated distribution of
the propensity score departs systematically from the distribution of the true
propensity score.

3. The weights are basedon an empirical model of treatment assignmentthat uses
observedvariablesaspredictorsthatsustaintherelevantignorabilityassumption,
and the model is thought to be well specified, after an inspection of covariate
overlapandindicesofbalance.Asaresult,extremeweightsmustreflecteither(a)
a strong treatment assignment/selection regime for which some true propensity
scores are very close to either 0 or 1 and/or (b) very unusual cases sampled at
random from the population.

Scenario1isaweakpositionfromwhichtoestimateacausaleffect,anditdoesnotrep-
resent a unique threat to weighted regression estimators. Analogous to the discussion
onmatchinginChapter5,forweightedregressionestimatorsinthissituationtheana-
lystwillnecessarilypassonto the regressionroutine some poorlyconstructedweights
andtherebygenerateestimatesthatareinconsistentandbiasedforthetruetreatment
effects of interest. Although scenario 1 might generate extreme weights (especially if
some of the misspecification issues we will discuss for the next scenario emerge), it
has comparatively low probability of doing so. If back-door paths remain unblocked,
it is more likely than not that the range of the estimated propensity score will be too
narrow.

Scenarios 2 and 3, however, raise particular issues for weighted regression estima-
tors.Forscenario2,themodelmay,forexample,“overfit”thedatainthespecificsense
that the model has been too heavily parameterized so that cases appear artificially
overdetermined. Imagine the extreme (but preposterous) scenario where a researcher
includesoneormoreindividual-identifyingindicatorvariables(e.g.,adummyvariable
for“individualnumber566inthedataset”basedonanassumptionthatthispersonis,
forreasonsdeeplyfeltbytheinvestigator,perfectlypredisposedtobeinthetreatment
group). Any such variable will lead to a perfect prediction for the relevant case, and
mostsoftwarepackageswill happily deliver (if the relevantswitch is turned on) a pre-
dictedprobabilityoftreatmentassignmentthatissetarbitrarilyclosetoeither0or1.

Milder forms of overfitting can also generate estimated propensity scores that are too
dispersed (see Hill et al. 2011).5 The solution here, however, is straightforward. One
should not overfit, and the protection against overfitting is to (1) grounda condition-
ing strategy in defendable assumptions about back-door paths and then (2) conduct
balance checking while specifying the equation for propensity-score estimation.6
Forscenario3,everythinghasbeendonecorrectly.Instead,itissimplyanempirical
fact, as best can be discerned, that the true propensity scores are either very large or
very small for some members of the population (even though they are not structural
5Matchingestimatorsof sometypes mayescape fromsomeoftheconsequences ofover-dispersed
estimatedpropensityscores.One-to-onenearest-neighbormatchingwithoutreplacement,forexample,
pairsup treatment and control respondents andthen calculates mean differences, ignoringthe scale
ofthepropensityscore.Allcasesarethengiventhesameweightintheanalysis.Ifcalipersareused,
however,thencaseswithpropensityscoresverynearto0or1maybecastasideasunmatchable.The
resulting matching estimator is then implicitly replacing unduly large weights with weights of zero,
which could be deemed worthwhile under an appropriate consideration of expected mean-squared
error.

6Another remedy, following the double protection strategy, would be to estimate weights based
on an incomplete propensity-score model, where the variable that generates the extreme weights
is removed from the propensity-score-estimating equation. This variable would then be used in the
weighted regressionmodel that estimates the effect. A downsideof this strategy isthat conditional-
variance-basedweighting withrespecttothis variablecouldthenpushthe estimated effect offofits
target parameter. Accordingly, this remedy should be avoided if one has reason to believe that the
individual-leveleffectofinterestvariesinthelevelsofthevariableinquestion.

constants equal to 0 or 1, as for Matching Demonstration 2; see page 148). What are
the consequences of such very large weights, and what can be done to mitigate any
negative consequences?
We noted above that the ATE, ATT, and ATC weights can be interpreted as
analogs to survey weights. In the survey methodology literature, it is commonplace
to evaluate the distribution of constructed survey weights and to consider procedures
that may mitigate the consequences of using large weights. There are two common
positions.

First,onecanregardtheweightsascorrect,eventhoughextreme,andsimplycarry
on (mindful that an appropriate variance estimator must, however, be utilized, as we
discuss below). Levy et al. (2008) describe the distribution of weights constructed for
the National Survey of Child and Adolescent Well-Being (NSCAW). These weights
were constructed to adjust for the stratified sampling design and also patterns of
nonresponse.TheyshowthattheconstructedweightsfortheNSCAWhadaminimum
of 2 and a maximum of 8,175 and write:
The distribution is highly skewed to the right, which is not atypical for
unequalprobability sample designs.This is because the units in the popu-
lationthathave higherprobabilities ofselection,andconsequently smaller
base weights, will dominate the sample. Some units with very small selec-
tion probabilities will still be selected in large samples...and the weights
for these units can be quite large. (Levy et al. 2008:511)
Inthissituation,analysiscanproceedeventhoughmostsamplemembershaveweights
less than 50, but a few have weights greater than 4,000,with one at 8,175.

Second, one can trim the weights back so that one does not have to assume that
the extreme weights are correct, as might be appropriate if one had a lack of confi-
dence in the model that generates them. Valliant et al. (2013) consider the procedure
that is used to trim the weights for the National Assessment of Educational Progress
(NAEP). Here, estimated weights that are greater than 3.5 times the median weight
are trimmed back to 3.5 times the median weight (and the aggregate trimmed-away
weight is then redistributed equally across cases beneath the upper bound for trim-
ming). This procedurewasadoptedby the data contractorswith the expectationthat
thetrimmedweightswouldlikelyimpartsomebiastoestimatedparametersofinterest
butwouldalsolowerthe expectedvarianceforeachofthem. Valliantetal.(2013:388)
note that “these methods are ad hoc and largely theoretical,” suggesting that in gen-
eral mean-squared-error calculations are less influential than “agency preference or
historical precedence.”7
The same two positions are applicable to weights used to estimate the ATE,ATT,
and ATC. First, an analyst who has confidence, perhaps after sufficient inspection of
overlap and a specification produced by careful balance checking (as in the extended
example we will offer below in Section 7.5), may choose to assertthat the weights are
7A third possibility would be to smooth the weights nonparametrically across strata defined by
theinitialsetofestimated propensity scores,pullingintheextreme values inthetails andreducing
thedependence ofallweightvaluesontheparticularspecificationofthepropensityscoreestimating
equation. See Hong (2010, 2012) for a marginal mean weighting estimator that is based on such
smoothedweights.

indeedcorrectandworthusing,regardlessoftheirdistribution.Or,second,ananalyst
can trim back the weights by truncating their distribution by progressively recoding
themtointeriorpercentilesoftheinitialestimateddistribution(i.e.,perhapsfirstback
to the 1st and 99th percentiles, then the 5th and 95th percentiles, and so on).

Finally, a third option is also available,which is to focus the parameter of interest
onasubsetofthepopulation.Oftenreferredtocolloquiallyas“movingthegoalposts,”
one changes the parameter of interest to something for which the seemingly extreme
weights are irrelevant. Rather than estimate the ATE, ATT, or ATC, one instead
estimates an average effect over a specific range of the estimated propensity score.

Although it would likely be hard to defend in a principled fashion, one could argue
that the average treatment effect for those whose propensity scores are ≥.1 and ≤.9
is a well-defined parameter of interest. A more common strategy would be to restrict
theanalysistothecommonsupportorregionofoverlapinthepropensityscoreacross
the treatment and control groups (see Section 5.5.2 for a description of this strategy
when offering matching estimates). In this case, one could, for example, still offer an
estimate of the ATT that may still apply to most members of the treatment group
and yet does not draw the cases with extreme weights into the analysis. The prudent
approachmay be to take all three of these strategies and develop conclusions that do
not depend on adopting only one or another.

7.4.2 Survey Data
Relatively few of the surveys that are routinely analyzed by social scientists have
simple sample designs. As explained in survey methodology texts such as Thompson
(2002), most survey samples have multistage, stratified designs that entail unequal
probabilities of inclusion across members of the population. Accordingly, most of the
datasetsfromthesesurveysthataredeliveredtothedesktopsofobservationalanalysts
come with survey weights that have been constructed to account for their design
features. Most also include weights that adjust for patterns of nonresponse, typically
constructed in a series of nested steps (see Valliant et al. 2013).

Weighted regressionestimators of the ATE, ATT, and ATC can incorporate these
weightswithoutdifficulty.Incontrast,thereisnoconsensuspositiononhowmatching
algorithmsshould be deployed for complex survey data. Most matching routines were
designedfor the analysisofsimple randomsamples ornonsampledcollections of units
that can be treated as equally representative pieces of information. For the weights
used for regression estimation of the ATE, ATT, and ATC, all one needs to do is
(1) weight the propensity-score-estimatingequation by the appropriate survey weight
suggested by the data distributor and then (2) multiply the constructed weights for
the ATE,ATT, and/orATC by the same surveyweight.Inso doing,the analystthen
passes to the regressionroutine a model-based weight for the relevant parameter that
ismodifiedbytheprobabilityofinclusionintheanalysissamplethatisbeingutilized.

For example, the ATE weights can be formed as
1
For di=1: wi,ATE,complex=surveyweight × ,
pˆi
(7.9)
1
For di=0: wi,ATE,complex=surveyweight × 1−pˆi.

The survey weights will alter the distribution of the weights that are passed to the
regression routine, but they will not necessarily inflate the variance of the weight.

Cases with relatively low or high estimated propensity scores may have probabilities
of inclusion that place them near the mean of the constructed survey weights.8
7.4.3 Expected Sampling Variance and Estimated
Standard Errors
Forallweightedregressionestimatorsofthetypeconsideredhere,noconvincingratio-
nale exists for assuming homoscedasticity when calculating standard errors. We rec-
ommendthatresearchersroutinelyreportheteroscedasticity-consistentstandarderrors
(e.g., the robust option in Stata, which will be called automatically if the weights are
specified as pweights).9 These estimated standard errors are more likely to reflect
the true expected sampling variability of weighted regression estimates, although the
degreetowhichrobustvarianceestimationisfullyeffectiveinfinitesamples(especially
small ones) has not been clearly established in the literature.

Inourownsimulationwork,wehavefoundthatheteroscedasticity-consistentstan-
darderrorshaveperformedquite well forlargersamplesandthe estimationofparam-
eters that are identified. Consider the following results. Following up on Weighted
Regression Demonstration 2 (see page 235), we performed the following Monte Carlo
simulation. Rather than analyze the 10 simulated datasets already produced for the
priorsimulations(seetheexplanationoftheirgenerationintheintroductiontoMatch-
ing Demonstration 4 on page 171), we generated 10,000 new datasets, each of which
included 10,000 simulated individuals. On average across all of these datasets, 1,049
caseswereassignedtothetreatment,andtheaveragevalueforthetrueATTwas6.93.

For each dataset, we then estimated the weighted regression and doubly robust
weighted regression estimates of the ATT, equivalent to those labeled as the “com-
plete specification” for Table 7.3. Across all10,000datasets, the averagebias for each
estimator was <.01 (and we assume that the average bias of each would approach
0 in the limit if the number of simulated datasets was increased from 10,000 to
infinity). The standard deviations of the distributions of these estimates were .47
and .46, respectively, across all 10,000 datasets. These two values of .47 and .46 are
Monte Carlo benchmarks for the true standard errors of the corresponding weighted
regressionestimates of the ATT.

To evaluate alternative methods for estimating standard errors for the point esti-
mates of the ATT, we also calculated two estimated standard errors, a classical stan-
darderrorthatassumeshomoscedasticityandaheteroscedasticity-consistentstandard
error (the latter using the “sandwich” package for R; see Lumley and Zeileis 2013).10
8The rationale for ratio multipliers to base survey weights is very general, and an analyst can
furthermultiplyATE,ATT,andATCweightsbymodel-basedweightsofanytype(suchasattrition-
adjustment weights in a longitudinal model, as for the demonstration in the next section based on
MorganandTodd2008).

9TheseestimatedstandarderrorsarealsosometimesreferredtoasHuber-Whitestandarderrors,
robuststandarderrors,sandwichstandarderrors,andothervariants;seeAngristandPischke(2009,
chapter 8)aswellasLongandErvin(2000).

10The sandwich routine for R calls a version of the estimator that is known as “HC3” and that
corrects for finite sample bias in the estimated variance of the residuals (see Angrist and Pischke
The classicalstandarderrorsweretoo small by a wide margin,at .26and.24 onaver-
age,respectively.However,theheteroscedasticity-consistentstandarderrorswereclose
to the simulated true standard errors, at .50 and .46 on average.

As with matching estimators, more work is needed to determine when
heteroscedasticity-consistentstandarderrorsarevalid. However,weareconfidentthat
they are more reasonable than the classical standard errors that are produced as
defaults by most software packages. For all types of regressionmodeling, Angrist and
Pischke (2009:307) recommend a conservative rule of thumb: For the parameter of
interest,calculateboth classicalandheteroscedasticity-consistentstandarderrorsand
then use whichever one is larger.

## 7.5 An Extended Example

Inthissection,weofferafullanalysisoftheestimationoftheATTandtheATCfrom

a weighted regression perspective, using real data where we do not know either the
true treatment effects or the form of whatever underlying equation generates the true
propensity scores. The substance of the demonstration is again the Catholic school
effect on learning in high school.

Weighted Regression Demonstration 3
Forthisdemonstration,wedrawonMorganandTodd(2008)andpresenttheanalysis
in the steps in which it was undertaken. In particular, we will first model the effect
of Catholic schooling on the math test scores of high school students in the tenth
and twelfth grade in 2002 and 2004 using standard OLS regression models typical of
the original researchon the Catholic school effect. We will then offer weighted regres-
sion estimates of the ATT and ATC, under provisional acceptance of the identifying
Assumptions 1-S and 2-S in Equations (5.1) and (5.2). However, we will conclude the
demonstration with an extended set of interpretations that critically reevaluate these
assumptions,whereinwewill arguethat, atbest, onlythe ATTisidentified. Nonethe-
less, we aim to convince the reader that provisional estimation of the ATC helps to
explain why neither the ATC nor the ATE is identified and promotes a substantive
consideration of how best to interpret the estimate of the ATT.

Data and Measures. The data for this demonstration were drawn from the 2002
base-year and 2004 follow-up waves of the Education Longitudinal Study (ELS), col-
lected by the National Center for Education Statistics (NCES) of the United States
Department of Education. The ELS is a nationally representative sample of students
in public and private high schools, based on a two-stage sampling design that first
2009,chapter8).AlthoughavailableinStataaswell,thedefaultthatStatacallswiththecommonly
usedvce(robust)option(orthedefaultthatisautomaticallycalledinthebackgroundwhenpweights
arespecified) is the original “HC0”that is biasedfor the variance of the residuals infinite samples.

Long and Ervin (2000) offer a Monte Carlo simulation that suggests that for linear regression and
samplesoflessthan500,theHC3formulaoutperformstheHC0formula.Fortheirlargesamplesize,
thedifferences weretrivialinthesimulation,asweexpecttheywouldbeforoursimulationtoo.

draws a random sample of public and private high schools and then draws random
within-school samples of tenth graders (typically aged 16). For the first follow-up in
2004,respondentsweretrackedtoalternativedestinations,andmostrespondentswere
twelfth graders (typically aged 18).

From among all base-year ELS participants, we restricted the analysis to respon-
dents who were enrolled in either a Catholic school or a public school during the
2001–2002 academic school year. Table 7.4 presents means and standard deviations
for the variables we will analyze on the 1,918 students who were enrolled in Catholic
schools and the 12,025 students who were enrolled in public schools (for a total of
13,943 students).

Several practical features of our subsequent analysis, which have their sources in
the complex nature of the ELS survey data, require detailed explanation. Because
these details are not essential for understanding the main contours of the demonstra-
tion, we will provide this supplementary information in footnotes (and they are more
completely specified in the appendix to Morgan and Todd 2008). Readers who are
contemplating using these estimators for a project with a similar data structure –
where a complex sampling design necessitates the use of a post-stratification weight
that corrects for unit-level nonresponse and where some models are estimated with
an adjustment for panel attrition – should consult this supplementary material for
specificpracticaladvice.Inshort,theweightsweutilizefortheATTandATCestima-
tors are multiplied by additional weights that account for design features of the data.

In addition, we use heteroscedasticity-consistent estimated standard errors, with an
adjustment for clustering in schools, for both the ATT and ATC estimates reported
below.

Step 1: Estimate a Bivariate Regression Model. To initiate the analysis with
naive estimators, we first estimate three bivariate regression equations with ordinary
least squares,
Y =αˆ+δˆ D+ε, (7.10)
OLS,bivariate
whereY isoneofthreeinterval-scaledoutcomevariablesandDisanindicatorvariable
equal to 1 for those who attend Catholic high schools (and equal to 0 for those who
attend public high schools). The estimated coefficient δˆ is the estimated
OLS,bivariate
effect of D on Y. If regardedas a structural constant, this coefficientis anestimate of
the ATE, ATT, and ATC.

ThebivariateregressionestimatesfortheCatholicschooleffectonachievementare
presented in the first row of each panel of Table 7.5. The three panels offer analogous
resultsforthreerelatedoutcomevariables:tenthgrademathtestscores,twelfthgrade
mathtestscores,andmathgainsbetweenthetenthandtwelfthgrades.Theestimates
of δˆ in Equation (7.10) are 7.31, 8.45, and 2.00 for these three different
OLS,bivariate
outcome variables. Each of these estimates suggests that Catholic school students
havehigher levelsofachievementonstandardizedtests andongrowthin achievement
between the tenth and twelfth grades, matching results from research since the 1980s
(see Section 1.3.2, page 22).

Table 7.4 Means and Standard Deviations of the Primary Variables Used in the
Demonstration
Public Catholic
Variable Mean SD Mean SD
Math Test Scores
IRTestimated numberright (10th grade) 41.68 13.97 48.99 12.02
IRTestimated numberright (12th grade) 47.64 15.05 56.08 12.80
Math gain (12th grade −10th grade) 4.66 6.49 6.66 6.06
Female .50 .48
Race(White is thereference category)
Black .15 .06
Hispanic .17 .11
Asian .04 .04
Native American .01 <.01
Multiracial .04 .04
Urbanicity (Suburbanis thereference category)
Urban .28 .58
Rural .21 .01
Region (Midwest is the reference category)
Northeast .18 .31
South .34 .23
West .23 .17
Family Background
Mother’s education (in years) 13.46 2.32 14.77 2.22
Father’s education (in years) 13.59 2.59 15.25 2.57
SEI score of mother’s occupation 44.98 12.87 50.55 12.85
SEI score of father’s occupation 44.15 11.70 49.81 11.71
Family income (naturallog) 10.60 1.09 11.23 .90
Family income (naturallog) squared 113.61 19.83 126.99 17.04
Family income (naturallog) cubed 1225.64 295.46 1441.33 267.98
Two-parent family .75 .84
Past History (as reported by parent)
Learning disability .13 .07
Ever held back .13 .05
Repeated 4th grade .01 <.01
Years parents lived in current neighborhood 10.56 8.00 12.90 8.21
Source:EducationLongitudinal Study,2002and2004.

Step 2: Estimate a Multiple Regression Model by Introducing Adjustment
Variables. Wenextestimatethreemultipleregressionequationswithordinaryleast
squares,
Y =αˆ+δˆ D+Xβˆ+ε, (7.11)
OLS,multiple
Table 7.5 Catholic School Coefficients from Baseline Regression
Models Predicting Tenth Grade Math Test Scores, Twelfth Grade Math
Test Scores, and Math Test Gains
Outcome Variable:
Predictor Variables 10th Grade Math Test Score
Model 1: Dummyfor Catholic school 7.31
(.66)
Model 2: Model 1 + family background, 1.48
demographics, and past history (.52)
Outcome Variable:
12th Grade Math Test Score
Model 1: Dummyfor Catholic school 8.45
(.74)
Model 2: Model 1 + family background, 2.13
demographics, and past history (.60)
Outcome Variable:
Math Gain (12th−10th)
Model 1: Dummyfor Catholic school 2.00
(.23)
Model 2: Model 1 + family background, 1.27
demographics, and past history (.26)
Note:Heteroscedasticity-consistent standarderrorsinparentheses.

where X represents observed variables thought to determine D and Y (because they
lie on back-door paths from D to Y, as in Figure 5.2), δˆ is the estimated
OLS,multiple
causal effect of D on Y adjusted for X, and βˆ is a conformable vector of estimated
coefficients that correspond to the variables in X.

Descriptive statistics for the 23 variables specified as X in Equation (7.11) are
presented above in Table 7.4. The variables in X represent the most common family
background, demographic, and educational history variables utilized in school effects
research. The multiple regression estimates for the Catholic school effect on achieve-
ment are presented in the second row of each panel of Table 7.5. The coefficients for
δˆ are 1.48,2.13,and1.27inthe three panels, eachof whichis considerably
OLS,multiple
smallerthanthecorrespondingvaluesofδˆ fromtheestimationofEquation
OLS,bivariate
(7.10). Nonetheless, the values of δˆ suggest that Catholic school students
OLS,multiple
outperformpublicschoolstudentsevenafteradjustmentsforthevariablesinX,again
matching results of past research since the 1980s.

Step 3: Estimate Propensity Scores and Form Weights to Estimate the
ATT and ATC. In this step we iteratively estimate propensity scoresin pursuit of
maximumachievablebalanceonthevariablesinX andthenformweightsbasedonthe
final set of estimates. We first estimated a model of treatment selection/assignment
using the variables in X as predictors, and using the same simple linear specification
as for the multiple regressionmodels estimated for Table 7.5.

In particular, we estimated a logit model where the variables specified as X are
thesame23variablesspecifiedasX forthemultipleregressionmodels.Theestimated
logit model fit the data reasonably well and delivered a chi-squared test statistic of
404 with 23 degrees of freedom. Predicted values for the estimated propensity scores,
pˆi, were then calculated. The estimated propensity scores had a mean of .0440 and a
standard deviation of .0688. The distribution was heavily skewed with a minimum of
.0000182but a maximum of .857.

We then took these estimated propensity scores and formed two sets of weights,
wi,ATT and wi,ATC, using the expressions in Equations (7.7) and (7.8). We next
checked how effective this first set of estimated weights was in balancing the data.

Again, perfect balance requires that all moments of the joint distributions of the vari-
ables in X be exactly the same in the treatment and control groups.

Inthis case,the rawdataaresubstantiallyimbalanced,aswasshowninthemeans
and standard deviations that were reported above in Table 7.4. In general, public
school students are less advantaged and are more heterogeneous with respect to the
characteristics measured as X. For example, the mean of mother’s education in years
is 13.46 for those in public schools but 14.77 for those in Catholic schools. The mean
of the log of family income is 10.60 for those in public schools but 11.23 for those in
Catholic schools. Moreover,the dispersion of the log of family income is substantially
different as well; its standard deviation is 1.09 for those in public schools but only .90
for those in Catholic schools.

To assess the degree of balance achievedby the weights formed in this first step, a
balancecriteriamustbe chosen.The firstmetric weuseis the averageofstandardized
mean differences across treatment and control groups (see Rubin 1973a, 1973b). The
standardized difference of the mean for each variable in X is calculated as
|EN[xi|di=1]−EN[xi|di=0]|
(cid:20) , (7.12)
1VarN[xi|di=1]+1VarN[xi|di=0]
2 2
which we introduced earlier as Equation (5.20). Equation (7.12) yields a scaled abso-
lutedifferenceinthe meanofavariableinX acrossthetreatmentandcontrolgroups.

ThesevaluescanbecombinedacrossallvariablesinX inordertoconstructanaverage
standardizeddifferenceofmeans.Theaveragestandardizeddifferenceofmeanscanbe
calculated under different weighting schemes in order to compare the relative perfor-
manceofalternativeweightsinachievingbalancewithrespecttothetargetparameter
(e.g., the balance of means on average for estimation of the ATT).

Because balance is not just a property of the means of variables but also of higher
moments of the distributions, we used a second metric of balance for variables that
are not two-valued indicator/dummy variables. For this metric, we change Equation
(7.12) slightly, substituting standard deviations in the treatment and control groups
for EN[xi|di =1] and EN[xi|di =0]. The modified version of Equation (7.12) then
yields a scaled absolute difference in the standard deviation of a variable in X across
thetreatmentandcontrolgroups.Becausethesevaluesarestandardized,theycanalso
be combinedacrossalternativevariablesin X in orderto constructanestimate ofthe
average standardized difference in standard deviations.11
To set a baseline against which to measure improvements in balance, we first cal-
culated a baseline level of imbalance for the raw data by estimating the averagestan-
dardized difference of means and standard deviations for the variables in X. The
means of the variables (as well as the corresponding standard deviations for variables
that take on more than two values) were already reported in Table 7.4, separately
for those in Catholic and public schools. To assess how much imbalance the weights
eliminate, wethen calculatedthe balanceafterusing the twoseparateweightswi,ATT
and wi,ATC. The results showed that the weights succeeded in producing substantial
balance, reducing the average standardized difference of means from .350 to .00634
when using wi,ATT and to .111 when using wi,ATC. The average standardized dif-
ference of standard deviations also fell substantially from .0715 to .0391 when using
wi,ATT and to .0287 when using wi,ATC. The increase in balance that results from
employing wi,ATT and wi,ATC is substantial, but some minor imbalance remains.

Theremainingimbalancesuggeststhatrespecifyingthemodeloftreatmentassign-
mentmaybeworthwhile.Theinitialspecificationofthemodeloftreatmentassignment
wasborrowedfromthesimpledefaultlinearspecificationoftheadjustmentvariablesin
X forthemultipleregressionmodelsreportedinTable7.5,whichisbasedonthetypical
specifications offered in the early literature. The goal is now to enrich the parameter-
ization of the treatment assignment model in order to construct weights that further
improve the balance on the variables in X when the weights are deployed. Accord-
ingly, interactions between the variables in X not already included in the regression
specification,aswellastransformationsoftheoriginalvariables,shouldbeconsidered.

Although various data mining procedures can be wedded to balancing metrics in
pursuitofabestpossiblemodel(seeSection5.4.2),wechosethetraditionalstrategyof
controlled trial-and-error respecification of the propensity-score-estimating equation.

We usedaforwardselectionprocedurewhere interactionsthathavesomejustification
in theory and past research were added progressively until improvements in balance
ceasedto arise.We ignoredthe size andstatistical significanceoflogitcoefficients and
only inspected improvements in balance using our chosen criteria.

As we explained just above, the original logit model fit the data reasonably well
andalsoprovidedgoodbalanceby the standardsofthe matching literature.However,
a better fit was available that also yielded weights that provided even better balance.

Weadded75interactiontermstotheinitiallogitmodelthatpredictedCatholicschool
attendance. The estimated propensity scores,pˆi, from this new model have a mean of
.0440, a standard deviation of .0756, a minimum of 0, and a maximum of .892.12
11Inprinciple,andasdiscussedindetailinSection5.4.2,onecouldmoveontohighermomentsof
thedistributions,assessingskewnessnextorbeginningtoconsiderinteractionsandother featuresof
thejointdistributionofX.WestopatthesecondmomentofeachvariableinX.Note,however,that
weconsiderthemeanandstandarddeviationoflogfamilyincome,itssquare,anditscube.Thus,for
thisvariable,weattempttomatchfarmorethanjustitsexpectation andvariance.

12The model was so predictive that a number of cases were completely determined. In particu-
lar, 2,406 public school students were given predictive values arbitrarily close to 0 by the software
(although no Catholic schools students were deemed completely determined and given values arbi-
trarilycloseto1).Thesepublicschoolstudents weremostlylow-SESruralstudents.

30
20
10
0
0 .2 .4 .6 .8 1
Figure7.1 Kernel density estimates of the estimated propensity score, calculated
separately for public school students (black solid line) and Catholic school students
(gray dashed line).

Figure 7.1 presents kernel density estimates of these estimated propensity scores,
separatelyforthoseinCatholicschoolsandpublicschools.Thereissubstantialoverlap
in the estimated propensity scores, but there are no public school students with pˆi
greater than .738 and no Catholic school students with pˆi less than .00115. If we
focused in very closely on the cases within the tails of these densities, we would be
able to see that there are 6 Catholic school students with .738<pˆi ≤ .892 who have
no counterparts among public school students as well as 2,739 public school students
with 0≤pˆi <.00115 who have no counterparts among Catholic school students.

By the common support standards that prevail in observational data analysis,
these data would be regarded as characterized by sufficient overlap for analysis to be
worthwhile,since 1,912ofthe 1,918treatmentcaseshavepˆi withinthe rangeofpˆi for
the control cases. However, there is enough of a lack of overlap that some caution is
in order, especially when making inferences about how public school students would
fareiftheywereinsteadenrolledinCatholicschools.We willdiscusstheseconcernsin
more detail later when offering estimates restricted to the region of overlap (i.e., the
common support) where .00115≤pˆi ≤ .738.

Asjustmentioned,therevisedweightsyieldedslightlybetterbalancewhenapplied
to the data. In particular, the average standardized difference of means fell further to
.00437 when using wi,ATT and to .0899 when using wi,ATC. Likewise, the average
standardized difference of standard deviations also fell to .0166 when using wi,ATT
and to .0229 when using wi,ATC.

To give a better sense of how well these weights have succeeded in producing bal-
ance on a variable-by-variable basis (and for two different weighting schemes), we
present the weighted means (and standard deviations where appropriate) of each of
the variables in X for Catholic and public school students in Tables 7.6 and 7.7.

Table 7.6 Means and Standard Deviations of Primary Variables, Weighted by the
ATT Weight from the Final Estimation of the Treatment Assignment Model
Public Catholic
Variable Mean SD Mean SD
Female .48 .48
Race (Whiteis thereference category)
Black .06 .06
Hispanic .11 .11
Asian .04 .04
NativeAmerican <.01 <.01
Multiracial .04 .04
Urbanicity (Suburbanis thereference category)
Urban .58 .58
Rural .01 .01
Region (Midwest is thereference category)
Northeast .31 .31
South .23 .23
West .16 .17
Family Background
Mother’s education (in years) 14.77 2.22 14.77 2.22
Father’s education (in years) 15.25 2.57 15.25 2.57
SEI score of mother’s occupation 50.56 12.77 50.55 12.85
SEI score of father’s occupation 49.67 11.68 49.81 11.71
Family income (natural log) 11.24 .84 11.23 .90
Family income (natural log) squared 127.07 16.50 126.99 17.04
Family income (natural log) cubed 1441.92 261.94 1441.33 267.98
Two-parent family .83 .84
Past History (as reported by parent)
Learning disability .07 .07
Everheld back .05 .05
Repeated 4th grade <.01 <.01
Years parentslived in current neighborhood 12.93 8.96 12.90 8.21
The differences between the columns in each of these two tables can be directly com-
paredtothe rawdifferencesreportedaboveinTable7.4.Forexample,the unbalanced
raw difference in mother’s education between Catholic and public school students is
1.31 years (i.e., |14.77−13.46| from Table 7.4), whereas the difference is reduced to
.00years(afterrounding)whenusingwi,ATT (i.e.,|14.77−14.77|fromTable7.6)and
to .12 years when using wi,ATC (i.e., |13.58−13.46|from Table 7.7).

By our readings of applications of these sorts of models, the balance achieved by
these weights is impressive. Some imbalance remains, and more so for the weights,
wi,ATC,thataredesignedto enableestimationofthe ATC. Thevariablesthatproved
Table 7.7 Means and Standard Deviations of Primary Variables, Weighted by the
ATC Weight from the Final Estimation of the Treatment Assignment Model
Public Catholic
Variable Mean SD Mean SD
Female .50 .53
Race(White is thereference category)
Black .15 .20
Hispanic .17 .13
Asian .04 .06
Native American .01 .01
Multiracial .04 .05
Urbanicity (Suburbanis thereference category)
Urban .28 .33
Rural .21 .05
Region (Midwest is the reference category)
Northeast .18 .28
South .34 .29
West .23 .16
Family Background
Mother’s education (in years) 13.46 2.32 13.58 2.35
Father’s education (in years) 13.59 2.59 13.80 2.68
SEI score of mother’s occupation 44.98 12.87 45.88 13.10
SEI score of father’s occupation 44.15 11.70 44.05 11.71
Family income (naturallog) 10.60 1.09 10.62 1.03
Family income (naturallog) squared 113.61 19.83 113.87 19.36
Family income (naturallog) cubed 1225.64 295.46 1228.94 292.93
Two-parent family .75 .71
Past History (as reported by parent)
Learning disability .13 .14
Ever held back .13 .12
Repeated 4th grade .01 <.01
Years parents lived in current neighborhood 10.56 8.00 10.72 6.89
most difficult to balance were some of the categorical variables, especially urbanicity
and region because of the more limited geographic distribution of Catholic schools.

Are there general standards for how good the balance must be for analysis to
proceed? Of course, perfect balance for the full distribution of X is the standard for
which an analyst should strive. Even with abundant data, as in this application, the
standardcannotbe met. Rubin(2006)discussesthe generalpredicamentanalystswill
encounter, and he concludes with this advice:
Of course, at some point, this sort of [perfect balance] assessment must
terminate, because no matter how large the samples, the investigator will
almost certainly not be able to achieve this balance for all covariates and
their interactions simultaneously,and higher order terms in prognostically
minor covariates are clearly less important than prognostically important
ones, and so scientific judgment must enter the process, just as it does
when designing a randomized experiment. (Rubin 2006:462)
As discussed already, remaining imbalance can be addressed by supplemental para-
metric adjustment within a weighted regression framework, and we will offer such
estimates later. And typically the weakness of an estimate arises not from lingering
imbalance on observed variables, but rather the imbalance on unobserved variables
thatmakesthemaintenanceofignorabilityassumptionsunreasonable.Wewilldiscuss
this issue in detail later in this demonstration, when we interpretour estimates of the
ATT and ATC.

Step 4: Estimate Weighted Bivariate Regression Models Using the Weights
fortheATTandATC. ATT-weightedandATC-weightedvariantsofδˆ
OLS,bivariate
are reported in the three panels of Table 7.8. Notice that for all three outcome vari-
ables,thepointestimateoftheATC isconsiderablylargerthanthe pointestimatefor
the ATT. Past research on the Catholic school effect has tended to show, by fitting
interactionterms, that the estimated Catholic school effect is largestfor low-SESand
non-white students (see Bryk, Lee, and Holland 1993; Hoffer, Greeley, and Coleman
1985; Neal 1997). The results presented in Table 7.8 are consistent with this pattern.

In particular, a comparisonof Tables 7.6 and 7.7 shows that Catholic school students
whohavethe profileofthetreatmentgrouphavehigherlevelsofsocioeconomicstatus
and are less likely to be black or Hispanic.

Having shown how to estimate the weights and produce point estimates for the
ATT and ATC with the ELS data, we will not yet give a full interpretation to these
estimates or to the common pattern of difference between the estimates of the ATT
and ATC for all three outcome measures. We will save that discussion until after we
havepresentedaseriesofmodelsthatassesswhetherthispatternofdifferenceisrobust
to alternative analysis decisions.

The first issue we consider is whether allowing the models to use data off the
common support of the treatment and control cases may have contributed to the
difference between the estimates of the ATT and the ATC. For the estimation of the
weighted regression models just reported, we used all sample members, recognizing,
however, that with respect to pˆi, there are 6 Catholic school students who have no
counterpartsamongpublicschoolstudentsand2,739publicschoolstudents whohave
no counterparts among Catholic school students.

Table7.9presentsallofthemodelsfromTable7.8again,butthistime theestima-
tion sample is restricted to the region of overlap on the estimated propensity scores,
.00115≤pˆi ≤ .738. For the tenth grade math test score models, the sample size is
reduced from 13,943to 11,198.For the twelfth grade math test score and math gains
models, the sample size is reduced from 10,502 to 8,469. A comparison of the results
in Table 7.9 to those reported earlier in Table 7.8 shows that the point estimates of
therespectiveaveragecausaleffectschangeslightly,withtheATCestimatescomingin
Table 7.8 Catholic School Coefficients from ATT-Weighted and
ATC-Weighted RegressionModels Predicting Tenth Grade Math
Test Scores, Twelfth Grade Math Test Scores, and Math Test Gains
Outcome Variable:
10th Grade Math Test Score
Predictor Variables ATT Weight ATCWeight
Model 1: Dummyfor Catholic school 1.08 2.44
(.77) (1.17)
Outcome Variable:
12th Grade Math Test Score
ATT Weight ATCWeight
Model 1: Dummyfor Catholic school 1.42 3.29
(.89) (1.36)
Outcome Variable:
Math Gain (12th−10th)
ATT Weight ATCWeight
Model 1: Dummyfor Catholic school 1.02 1.98
(.31) (.37)
a bit smaller. But, in general, the same pattern holds with ATT estimates remaining
about the same and considerably smaller than the ATC estimates.

Step5:EstimateDoublyRobustWeightedRegressionEstimates. Todemon-
strate doubly robust weighted regression estimators, Table 7.10 presents weighted
regression estimators analogous to those in Table 7.8 but with further regression
adjustment for the 23 covariates used in Model 2 for Table 7.5. Beyond the weighted
regressionmodels presented in Table 7.8, these models are designed to adjust for any
remaining imbalance in X due to misspecification of the model that was used to esti-
mate the weights. Again, acrossall three outcome variables,the point estimate of the
ATC is considerably larger than the point estimate for the ATT.

Giventheconsistencyofthepatternshownintheselastthreetables,the nextstep
is to ask the simple statisticalquestion:Are the point estimates of the ATT and ATC
sufficiently different that it makes sense to consider whether they support the claim
that students who have the typical profile of public school students are more likely to
benefit fromCatholic schooling thanstudents who have the typical profile of Catholic
school students?
To answer this question, we must consider some thorny issues in statistical infer-
ence. Consider first the weighted multiple regression model for the Catholic school
effect on the tenth grade math test. The estimated coefficient is 1.08 with a standard
error of .56 when the wi,ATT weight is utilized. In contrast, when the wi,ATC weight
Table 7.9 Catholic School Coefficients from Weighted Regression
Models Restricted to the Region of Overlap in the Estimated
Propensity Scores
OutcomeVariable:
10th Grade Math Test Score
Predictor Variables ATT Weight ATC Weight
Model 1: Dummy for Catholic school 1.02 2.18
(.77) (1.17)
OutcomeVariable:
12th Grade Math Test Score
ATT Weight ATC Weight
Model 1: Dummy for Catholic school 1.38 2.85
(.89) (1.36)
OutcomeVariable:
Math Gain (12th−10th)
ATT Weight ATC Weight
Model 1: Dummy for Catholic school 1.03 1.82
(.31) (.37)
isutilized,thecoefficientincreasesto2.42withastandarderrorof.59.Aredifferences
such as these large enough to be considered meaningful?
A comparisonofthe 95 percent confidence intervals for eachestimate may suggest
not. Consider the regression model for the Catholic school effect on the tenth grade
mathtest.Here,the95-percentconfidenceintervalis(−.01,2.17)fortheestimateusing
wi,ATT and(1.26,3.58)fortheestimateusingwi,ATC.Clearly,theseintervalsoverlap.

Scientific judgment, however,suggeststhat this overlapshouldnot leadresearchersto
conclude that there are no substantive differences of importance, as we now explain.

First, the difference betweenthe twopoint estimatesis substantivelylargeat1.34;
this difference suggeststhat the averageeffect ofCatholic schoolingis 124%largerfor
thosewhotypicallyattendpublicschoolsthanforthosewhotypicallyattendCatholic
2.42−1.08
schools (i.e., =1.24). The 95 percent confidence interval for the difference,
1.08
basedon a standarderrorof .81,is (−.26,2.92).This confidence interval is dominated
by positiveprobabilitymassandsuggeststhat valuesforthe difference≥2.66arejust
as likely as values ≤0.13
13Moreover, theestimated standard erroronwhichthis confidence interval isbased does not take
into account that the two estimates were generated from the same sample. The confidence interval
(−.26,2.92) is, in fact, a bit too wide (but not by much given the size of the available sample). In
otherapplications,asame-samplecorrectionmaybemoreconsequential.

Table 7.10 Catholic School Coefficients from Doubly Robust Weighted
Regression Models
OutcomeVariable:
10th Grade Math Test Score
Predictor Variables ATT Weight ATC Weight
Model 2: Model 1 + family background, 1.08 2.42
demographics, and past history (.56) (.59)
OutcomeVariable:
12th Grade Math Test Score
ATT Weight ATC Weight
Model 2: Model 1 + family background, 1.60 4.01
demographics, and past history (.66) (.71)
OutcomeVariable:
Math Gain (12th−10th)
ATT Weight ATC Weight
Model 2: Model 1 + family background, 1.05 2.06
demographics, and past history (.29) (.45)
Second,asnotedjustabove,thedifferenceof1.34isconsistentwithmuchpastwork
on this substantive question. Evolving interpretive standards in statistical inference
demand that such prior information be considered. If a full Bayesian posterior were
generated, the lower end of the frequentist confidence interval, −.26, would be judged
too negative as guidance for further research.

Forthese tworeasons,wejudge the differencebetweenthe doubly robustweighted
regression estimates of the ATT and the ATC to be large enough to be meaningful.

Before attaching meaning to this difference, we need to consider assumptions about
the extent to which the observed determinants of treatment assignment can sustain
alternativetypesofignorability.Beforeofferingsuchinterpretations,wehaveonefinal
type of analysis to perform, which will assess the extent to which the apparent differ-
encesbetweenthe pointestimatesofthe ATTandtheATC arerobusteventofurther
conditioning.

Step 6: Further Assess the Robustness of the Difference Between the Esti-
mates of the ATT and the ATC. In Step 4, we showed that the vast majority
of the difference between the ATT-weighted and ATC-weighted regression estimates
heldwhenthedatawererestrictedtotheregionofoverlapontheestimatedpropensity
score.Thesameresultcouldalsobeshownforthedoublyrobustestimatesofthesame
parameters.Fornow,weconsideradifferenttypeofrobustnesscheck:whetherthedif-
ference between the point estimates continues to hold after additional supplemental
parametric adjustment for variables that other researchers might instead regard as
essential determinants of treatment assignment/selection.

Some of the earliestliterature on the Catholic school effect consideredslightly dif-
ferentvariablesforregressionadjustmentthanthe variablesthatweincludedinX for
this demonstration. As we discussed in Section 6.6.2 (beginning on page 219), regres-
sion adjustments were often performed with variables such as students’ educational
expectations and parental involvement. The original researchers,James Coleman and
his colleagues, recognized that these variables were not clearly “prior to” Catholic
school attendance and thus were likely influenced by the posited causal effect itself.

Yet they wanted to show that, even adjusting for these variables, the apparenteffects
of Catholic schooling persisted in their models.

Inourcase,wearenotprimarilyinterestedindetermininghowmuchtheestimated
causal effects are reduced when additional adjustment variables are entered into the
various regression models (although were they to change in unexpected ways, such
as vanishing entirely, one of a number of reasonable interpretations would need to
be advanced). Rather, we are most interested in determining whether the inclusion
of additional adjustment variables in the doubly robust weighted regressions models
would cause us to revisit our preliminary decision that the difference between the
estimates of the ATT and ATC is robust and deserving of interpretation.

With this goal in mind, we consider additional variables for educational expec-
tations and parental involvement in school. As shown in Morgan and Todd (2008),
students attending Catholic schools are expected to obtain more years of postsec-
ondary schooling (nearly a year in students’ own expectations and almost as much in
parents’ expectations). In addition, more than half of all parents of Catholic school
students volunteer at their schools, which is twice as high as the rate for the parents
of public school students.

Table 7.11 presents weighted regression models that utilize variables for expecta-
tionsandparentalinvolvementassupplementaladjustmentvariables(i.e.,asvariables
only in the outcome regressionequations, not as variablesalso in the propensity score
estimating equation). The results in Table 7.11 show that these variables reduce the
estimates of the ATT and ATC by a substantial amount. However, the coefficients
remainpositiveandinthesamepattern.Moreover,therelativedifferencebetweenthe
estimates ofthe ATT andthe ATC is largerfor Model 3 in Table 7.11than for Model
2 in Table 7.8.

Insum,themainpatternofresultsissupportedbytheanalysesreportedinTables
7.9 through 7.11. Alternative decisions about overlap issues and supplemental regres-
sion adjustment did not alter the relative sizes of the weighted regression estimates
of the ATT and ATC. As a consequence, we conclude that there is compelling evi-
dence that these estimates differ. The deeper question is whether this pattern can be
interpreted as evidence that true ATT and ATC differ, which is the issue we consider
next.14
14Another strategy that could be adopted to extend the analysis we report here is to attempt to
modeltheunderlyingheterogeneityinamorefine-grainedway.Weseethecomparisonofestimatesof
theATTandATCasonlyafirststep,andothermethodsmaybeausefulnextstep.Ifonebelieved
Table 7.11 Catholic School Coefficients from Weighted
Regression Models, Including Additional Covariates
Outcome Variable:
10th Grade Math Test Score
Predictor Variables ATT Weight ATC Weight
Model 3: Model 2 + expectations .22 1.26
and parental involvement (.54) (.62)
Outcome Variable:
12th Grade Math Test Score
ATT Weight ATC Weight
Model 3: Model 2 + expectations .82 2.77
and parental involvement (.63) (.74)
Outcome Variable:
Math Gain (12th−10th)
ATT Weight ATC Weight
Model 3: Model 2 + expectations .98 1.94
and parental involvement (.29) (.44)
Interpretation of Results. We have generated estimates of the ATT and ATC
usingatreatmentassignmentmodelthatincludes variableswehavelabeledX.Recall
thatinthecounterfactualtradition,treatmentassignmentpatternsarerepresentedby
the propensity score, Pr[D=1|S], where S denotes all variables that systematically
determine treatment assignment. Complete observation of S allows a researcher to
assertthat treatmentassignmentis ignorableandthen consistentlyestimate the ATT
and ATC, and, as a result, the ATE or any other average treatment effect that can
be formed by weighting across the marginal distribution of the observed variables in
S (see Section 4.3).

Are the ATT and ATC both identified? Thecrucialquestionforidentification
iswhetherthevariableswehavedeclaredasX forourestimatorsinthisdemonstration
are sufficiently complete to be regarded as equivalent to S, which we have previously
labeled the perfect stratification set. To approach this question, it is useful to first
reconsiderthe same substantive example modeled for our simulated data in Matching
thattheestimatedpropensityscoreinaparticularapplicationhasaclearinterpretation(andhence
ismorethanatoolforbalancingthedeterminantsoftreatmentassignment),thenonecouldanalyze
directly the association between conditional average treatment effects and the estimated propensity
score. Xie, Brand, and Jann (2012) and Brand and Thomas (2013) offer guidance for this sort of
analysis,includingaStataadd-onprogram.Alternatively,onecouldmovetowarddirectexamination
oftheseparateresponsesurfacesofthetreatmentandcontrolgroups,usingageneralnonparametric
regression framework. Hill (2011) offers a compelling demonstration of the value of this alternative
approach. Finally,as wewillexplaininChapters 9and 12,one couldattempt tomodel someofthe
local average treatment effects and marginal treatment effects that constitute the ATT and ATC,
althoughonlyifappropriateinstrumentalvariablesareavailable.

Demonstration4,whereidentification ofthe ATT but notthe ATC is clearbecause it
was guaranteed by construction.

In the subsection on identification for that demonstration(beginning on page 173;
seeespeciallyFigure5.2),weexplainedwhyself-selectionontheindividual-levelcausal
effect renders the ATC and ATE unidentified. In particular, with reference to the
equations that defined the simulated data, we noted that we did not create observed
variablesthatweresufficienttosustainanassumptionoffullignorability,asdefinedby
Equation (4.4). However, we showed that we could nonetheless consistently estimate
the ATT because we created observed variables that allowed us to assert what is
labeled Assumption 2-S in Equation (5.2),
E[Y0|D=1,S]=E[Y0|D=0,S].

Assumption2-Sisimpliedbyastrongerassumptionofpartialignorabilitywithrespect
to S, such that
Y0⊥⊥D|S, (7.13)
which we introduced in Section 4.3. The basic idea is that, on average within strata
definedbyS,thevaluesofyiamongthoseinthecontrolgroupcanbeusedtoeffectively
estimatethe counterfactualvaluesofy0 forthoseinthe treatmentgroup.Weknowby
i
the setup of Matching Demonstration 4 that this assumption holds for the simulated
data,inparticularbecauseallofthevariablesontheright-handsideofEquation(5.21)
were declared observed variables. For the remainder of that demonstration, we then
explained why the ATC is not identified, which is the same explanation for why the
ATE is not identified.

Nowreturnto the currentdemonstration.Becausewedid notsimulatethese data,
we cannot assert that the ATT is identified with full confidence. We think it is rea-
sonable to assert that Assumption 2-S is valid, treating X as equivalent to S for this
assumption. However, it is possible that, for the cases observed in the ELS, those
students most likely to benefit from public schools are those students who are least
likely to attend Catholic schools, in which case Assumption 2-S does not obtain for
the conditioning set X because
E[Y0|D=1,X]<E[Y0|D=0,X]. (7.14)
ThiswouldhavebeenthecaseforMatchingDemonstration4ifwehadincludedaterm
such as −.5(δ(cid:2)(cid:2)) on the right-hand side of of Equation (5.21). We do not know of any
i
research that suggests that the inequality in Equation (7.14) is true for the Catholic
school effect, as would be the case if we had evidence that those who are most likely
to do well in public schools are those with an aversion to educational institutions
with religious foundations. On balance, it seems reasonable to assume that the ATT
is identified in this demonstration.

The ATC is another matter entirely. Based on past research that maintains that
self-selection is present, and the fact that we do not have any variables in the ELS
that could plausibly measure students’ (and their parents’) own expectations for the
benefits they might obtain from attending a Catholic school, we cannot accept what
is labeled Assumption 1-S in Equation (5.1),
E[Y1|D=1,S]=E[Y1|D=0,S],
or the stronger assumption of partial ignorability,
Y1⊥⊥D|S, (7.15)
thatimpliesit.Inotherwords,wedonotbelievethatfortheATCthevariablesinX are
equivalenttothemoreencompassingsetofvariablesinS thatdefinesthisassumption.

Operationally, we do not believe that for the ELS data we can use the values of yi
among those in the treatment group to effectively estimate the counterfactual values
of y1 for those in the control group, on average within strata defined by X. Sufficient
i
evidence exists to suggest that some Catholic school students attend Catholic schools
because they expect to gain from doing so. As such, we do not see any basis for
regarding the ATC estimates as consistent or unbiased for the true ATC. Instead,
these estimates are very likely too large because
E[Y1|D=1,X]>E[Y1|D=0,X]. (7.16)
Although this reasoning is sufficient to convince us that the ATC is not identified,
it also bears mentioning that the common support models show that 23 percent of
public school students (i.e., 2,739 out of 12,025) have estimated propensity scores
lower than the lowest estimated propensity score of any Catholic school student. Our
comparison of the results in Tables 7.8 and 7.9 suggested that this lack of overlap is
relatively inconsequential for the empirical results in this demonstration, and yet this
provides only modest reassurance that the data can inform us at all about the likely
benefit that students such as these 23 percent of public school students would obtain
from attending a Catholic school.

Basedonthisreasoning,theATCestimateislargerthantheATTestimatebecause
theformerisinconsistentandupwardlybiasedwhilethelatteriseitherconsistentand
unbiased, or still inconsistent but far less upwardly biased. Nonetheless, we cannot
know for sure that this reasoning is correct because it is contingent on the validity of
Equations (7.14) and (7.16), and these are assumptions that cannot be tested.

Why might the true ATC still be larger than the true ATT? Because the
reasoning just offered could be wrong, we will conclude this section by considering
alternative interpretations that would hold under the most plausible alternative pat-
terning of results where (1) the true ATC is larger than the true ATT and (2) the
estimates we have reported are sufficiently unbiased to convey this basic ordering of
the underlying effects.

Based on past research, there are two possible explanations for why one might
expectthatthetrueATCwouldbe largerthanthetrueATTfortheeffectofCatholic
schooling:
1. The common school explanation: Catholic schools distribute opportunities for
learning,suchasadvancedcourse-taking,moreequitablythandopublicschools.

This explanation was stressed by Coleman and his colleagues in their initial
research and was then more comprehensively developed by Bryk, Lee, and Hol-
land (1993). It suggests that variables such as parental education and non-
minority status have positive relationships with D but negative relationships
with the variation in δ among Catholic schools students. The explanation is
based on the implicit claim that
E[Y1−Y0|D=1,CSE=1]>E[Y1−Y0|D=1,CSE=0], (7.17)
where CSE is a “common school effect” dummy variable that indicates which
particular students receive a “boost” in their individual-level treatment effect
becauseofthe comparativelyegalitariannature ofCatholicschooling.Low-SES,
black, and Hispanic students are more likely to receive the CSE boost. Accord-
ingly, when the average of individual-level treatment effects is weighted to the
distributionofS thatcharacterizesthecontrolgroup,theresultingaveragetreat-
menteffectislargerbecausethissyntheticgroupofCatholicschoolstudentshas
moremembers with CSE=1. (The same is alsotrue whenthe weighting is per-
formedonlywithrespecttotheobservedvariablesinX becausetherelationship
betweenS andCSE isgeneratedbytherelationshipbetweenX andCSE,which
does not depend in any way on the determinants of self-selection in S that are
not among the observed variables in X.)
2. The better alternatives explanation: Catholic schooling is particularly beneficial
tothosestudentswhohavepoorpublicschoolingalternatives,inparticularthose
students from families who are not able to afford to live in school districts with
thebestpublicschools.ThisexplanationwasfirstfullydevelopedbyNeal(1997),
and it suggests that variables such as family income and wealth have positive
relationships with D but negative relationships with the variation in δ among
Catholic school students. The explanation is based on an implicit claim, of the
same basic structure as Equation (7.17), that
E[Y1−Y0|D=1,WAP =1]>E[Y1−Y0|D=1,WAP =0], (7.18)
where WAP is a “worse alternative public school” indicator variable equal to 1
for those Catholic school students who have particularly poor public schooling
alternatives, and which is assumed for this explanation to be a function in S.

However, here the claim is implicitly in two separable pieces, which makes it
qualitatively different than the common school explanation. This explanation is
composed of two assumptions,
E[Y1|D=1,WAP =1]=E[Y1|D=1,WAP =0]
and
E[Y0|D=1,WAP =1]<E[Y0|D=1,WAP =0],
which together imply Equation (7.18).15 In this case, when the average of
individual-leveltreatmenteffectsisweightedtothedistributionofS thatcharac-
terizesthe controlgroup,the resultingaveragetreatmenteffectislargerbecause
this synthetic group of Catholic school students has more members with
WAP=1.

Ifeitherthe commonschoolexplanationorthe better alternativesexplanationis true,
then the true ATC would be larger than the true ATT, and this might also be true
for the estimated ATC and ATT if the bias in the estimates is small enough not to
15Weassumeforsimplicityofnotationthatthelinearityoftheexpectationsatthepopulationlevel
applies also at the individual level. This assumption will hold for the third explanation introduced
belowaswell.

obscure the true difference between the target parameters (as usual, assuming that
sampling error is zero).

Wefavoranalternativethirdexplanation,whichwethink ismorecompatiblewith
theunderlyingclaimthattheestimatedATCislargerthantheestimatedATTinpart
because self-selectionis very likely presentand cannotbe adjusted awaybecause X is
only a subset of S:
3. Thebindingconstraint explanation:Differentialresponsivenessexiststoaccurate
perceptions of students’ likely benefits from Catholic schooling. For low-income
families for whom tuition at a Catholic school represents a genuine financial
sacrifice, the students who enroll in Catholic schools are much more likely to be
studentswhoarelikelytobenefitfromenrolling.Incontrast,amonghigh-income
families for whom tuition is not a substantial financial sacrifice, even students
who arenotlikely to benefitfromattending Catholic schoolinginsteadof public
schoolingmayenrollinCatholicschools.ThisexplanationisdiscussedinMorgan
(2001), and it is based on the assumption that it takes a larger individual-level
value of δ to induce low-income students to enroll in Catholic schooling. As
a result, variables that capture resource availability have positive relationships
withD butnegativerelationshipswiththevariationinδ amongthosewhoenter
Catholic schooling. The implicit claim here is that
E[Y1−Y0|D=1,BC=1]>E[Y1−Y0|D=1,BC=0], (7.19)
where BC is an indicator variable equal to 1 for those students from families
for whom Catholic school tuition is a genuine financial sacrifice, and which is
therefore a function in S. Here, as with the better alternatives explanation, the
claim is implicitly in two separable pieces,
E[Y1|D=1,BC=1]>E[Y1|D=1,BC=0]
and
E[Y0|D=1,BC=1]=E[Y0|D=1,BC=0],
whichtogetherimplyEquation(7.19).Inthiscase,whentheaverageofindividual-
leveltreatmenteffects is weightedto the distribution ofS that characterizesthe
control group, the resulting average treatment effect is larger because this syn-
thetic group of Catholic school students has more members with BC=1.

Having laidout these alternative explanations,there is no reasonto assume that only
one of them holds. One reasonable blended explanation would combine the better
alternatives and binding constraint explanations by asserting both
E[Y1|D=1,BC=1]>E[Y1|D=1,BC=0]
and
E[Y0|D=1,WAP =1]<E[Y0|D=1,WAP =0],
and then noting that there is likely to be a strong positive association between BC
and WAP in the population, conditional on S (and its typical observed subset X).

Theseassertionscouldthenbecombinedwiththeclaimthatthedifferencebetweenthe
estimated ATC and the estimated ATT is further increased because these assertions
also lend indirect support to the claim that the estimated ATC is inconsistent and
upwardly biased for the true ATC because
E[Y1|D=1,X]>E[Y1|D=0,X].

Other blended explanations are also possible, and we cannot rule out the possi-
bility that Coleman and his colleagues had it correct all along: Catholic schools and
public schools do have differences in their instructional practices, which at least for
Coleman had deeper sources in alternative ideological beliefs about the capacities of
children.Theseinstructionaldifferencesmaybeparticularlybeneficialtostudentswho
are systematically disadvantaged in public schools.

Overall,wasitworthofferingprovisionalestimatesoftheATC?Ofcourse,weknew
from the outset which assumptions likely held, and it would have been reasonable to
estimateandreportonlytheATT.Nonetheless,wethinkitisclearthatwhataremost
likelyinconsistentandbiasedestimates ofthe ATC still giveusa valuableperspective
on why the ATC is not identified, and hence enhance our explanationof why, at best,
only the ATT is identified by conditioning on the observed data. In addition, the
reasoning that was motivated by the need to interpret the estimated ATC may also
explain why the common school explanation of Coleman and his colleagues also may
reflect underlying heterogeneity that is produced by individual-level selection on the
treatment effect.

## 7.6 Conclusions

In this chapter, we have presented weighted regression estimators of the ATE, ATT,

and ATC, and we have argued that they have enough comparative advantages that
they arelikelyto continueto growinprominenceinthe comingyears.We haveshown
how weightedregressionestimators allow the analyst to adopta matching orientation
and thereby take advantage of the clarity that a matching perspective provides. We
have also shown that weighted regression estimators require no specialized software
and can be utilized when analyzing complex survey data of many types.

Theseadvantagesnotwithstanding,itshouldalsobe clearthatweightedregression
estimators are no panacea, especially if practitioners fall back too casually into stan-
dard regression thinking. Instead, analysts must carefully consider the estimation of
the propensityscoresthat generatethe weights,checkingbalance andthen examining
theconsequencesoflargeweights.Onlythereaftershouldonecalculatepointestimates
of the averagetreatment effects of interest.

The ultimate value of weighted regressionestimators in comparisonto other types
of conditioning estimators has not yet been fully determined. As with the matching
estimators presented Chapter 5, this is an area of active methodological scholarship,
and it is not easy to predict the developments of the coming years. Our current pre-
diction is that weightedregressionwill be at the center ofan emergentconsensus,but
our prediction is accompanied by substantial uncertainty.

With this chapter,wehaveconcludedourpresentationoftechniquesthatestimate
causal effects by conditioning on variables that block back-door paths. In the next
section of the book, we present techniques that can be used effectively when simple
conditioning will not identify causal effects because crucial variables that lie along
back-door paths have not been observed. We will consider general strategies first,
elaborating on the causal graphs we have used so far in this book. Thereafter, we will
presentinstrumentalvariableestimators,front-doorconditioningestimatorsgrounded
inassumptionsaboutcausalmechanisms,andapproachesthatutilizeover-timeobser-
vations of the outcome variable.

# Part IV: Estimating Causal Effects When Back-Door Conditioning Is Ineffective

# Chapter 8

# Self-Selection, Heterogeneity, and Causal Graphs

In this chapter, we will lay the groundwork for our presentation of three strategies

to estimate causal effects when simple conditioning on observed variables that lie
along back-door paths will not suffice. These strategies will be taken up in Chap-
ters 9, 10, and 11, where we will explain instrumental variable estimators, front-door
identification with causal mechanisms, and conditioning estimators that use data on
pretreatment values of the outcome variable. Under very specific assumptions, these
three strategies will identify averagecausaleffects ofinterest, eventhough selectionis
on the unobservables and treatment assignment is nonignorable.

In this chapter,we willfirstreview the relatedconceptsof nonignorabletreatment
assignmentandselectiononthe unobservables,using the directed graphspresentedin
prior chapters. To deepen the understanding of these concepts, we will then demon-
strate why the usage of additional posttreatment data on the outcome of interest is
unlikely to aid in the point identification of the treatment effects of most central con-
cern. One indirect goal of this demonstration is to convince the reader that oft-heard
claims such as “I would be able to establish that this association is causal if I had
longitudinal data” are nearly always untrue if the longed-for longitudinal data are
additional measurements taken only after treatment exposure. Instead, longitudinal
data are most useful, as we will later explain in detail in Chapter 11, when pretreat-
mentmeasuresareavailableforthosewhoaresubsequentlyexposedtothe treatment.

The extended example we will use to make this point involves simple confounding
(stable unobserved common causes of the treatment variable and the outcome vari-
able) and more subtle confounding (direct self-selection into the treatment based on
accurate perceptions of the individual-level treatment effect). Accordingly,this exam-
ple will serve as a bridge to the second half of this chapter, where we will expand
upon our introduction to causal graph methodology in order to explain how hetero-
geneity of effects can be accommodated. In Chapter 2, we introduced the potential
outcome model while taking the position that individual-level heterogeneity of treat-
menteffectsispervasive.Inparticular,wehaveimplicitlyassumed,andoftenexplicitly
267
stated, that, in general, individual-level treatment effects do not all equal the average
treatmenteffect(ATE)(i.e., δi(cid:6)=E[δ]foralli).We haveofferedmanyexampleswhere
individual-leveltreatmenteffectsarepatternedinconsequentialnonrandomways,and
we have explained the consequences of such heterogeneity for conditioning estimators
in Chapters 5, 6, and 7.

From this chapter onward, we will consider the interconnections between self-
selectionandindividual-levelheterogeneityoftreatmenteffectsmoredirectly,asthese
patterns combine to generate selection on the unobservables. We ended our presenta-
tion of conditioning by considering these complications, especially for the interpreta-
tion of the results for Weighted Regression Demonstration 3 (see pages 257–262). In
thischapter,weapproachthesecomplicationsmoredirectlybyfirstshowinghowtouse
causal graphs with latent class variables to jointly represent patterns of self-selection
and heterogeneity.

## 8.1 Nonignorability and Selection on the Unobservables Revisited

AsdemonstratedinSections4.3.1and4.3.2,theconceptofignorabletreatmentassign-

ment is closely related to the concept of selection on the observables. In many cases,
they can both be represented by the same directed graph. Recall Figure 4.8(a), in
which there are two types of paths between D and Y: the causal effect of D on Y
represented by D →Y and an unspecified set of back-door paths represented col-
lectively by the bidirected edge in D(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)Y. If this graph can be elaborated, as
in Figure 4.8(b), by replacing D (cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)Y with a fully articulated back-door path
D← S→Y, then the graph becomes a full causal model. Observation of S ensures
that the conditioning strategies of the prior three chapters can be used to generate
consistentestimates ofthe causaleffectofD onY. Inthis scenario,selectionis onthe
observables–thevariablesinS –andtheremainingtreatmentassignmentmechanism
is composed only of random variation that is ignorable.

If,incontrast,asshowninFigure4.9(b)ratherthanFigure4.8(b),onlyasubsetZ
of the variables in S is observed, then selection is on the unobservables because some
components of S are now embedded in U. Conditioning on Z in this graph leaves
unblocked back-door paths represented by D ←U (cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)Y untouched. And, as a
result, any observed association between D and Y within strata defined by Z cannot
be separated into the genuine causal effect of D on Y and the back-door noncausal
association between D and Y that is generated by the unobserved determinants of
selection, U.

As explained in Chapter 4, and then as shown in demonstrations in Chapters 5
through7,the concepts ofignorabilityandselectiononthe observablesarea bitmore
subtle when potential outcomes are introduced. Weaker forms of conditionalindepen-
dence can be asserted about the joint distribution of Y1, Y0, D, and S than can
be easily conveyed as in Figures 4.8 and 4.9, in which the observable variable Y is
depicted instead of the underlying potential outcome variables Y1 and Y0. For exam-
ple, the average treatment effect for the treated (ATT) can be estimated consistently
X X Y
10
O Y 10 O Y 12
U D U D
(a) The identification puzzle (b) Coleman’s approach
Figure8.1 Coleman’s strategy for the identification of the causal effect of Catholic
schooling on achievement.

byassertingonlythatY0 isindependentofD conditionalonS,eventhoughfullignor-
ability does not hold; see the discussion of Equation (4.4) and Section 4.3.3.1 These
possibilitiesarenotfullyrevealedbyconventionaldirectedgraphs,giventhatforthese
graphspotential outcome variablesaretypically notrepresented(seethe discussionof
Figure 3.9).

## 8.2 Selection on the Unobservables and the Utility of Additional Posttreatment Measures of the Outcome

In this section, we present the challenges of modeling causal effects when selection

is on unobservables, using as an example the regression equations offered by James
ColemanandhiscolleaguesfortheestimationofthecausaleffectofCatholicschooling
on high school achievement. The basic estimation challenge that Coleman and his
colleagues confronted is depicted in Figure 8.1(a). Although somewhat simplified, the
graph represents the basic types of causal variables that Coleman and his colleagues
contemplatedintheiroriginalanalysesand thenindebate withtheircritics(Coleman
et al. 1982; see also our prior discussion in Section 6.6.2). For Figure 8.1(a), Y is an
10
observedscoreona standardizedachievementtestgiveninthe tenth gradeto second-
year high school students. The variable D is again an observed dichotomous causal
variable equal to 1 for those who attend Catholic schools and 0 for those who attend
public schools. A primary goal of the original research was to estimate the causal
effectofD onY ,conceptualizedasthe averagecausaleffect ofCatholicschoolingon
10
achievement.

The remaining variables in the graph represent the basic types of variables that
Coleman and his colleagues decided should be specified as adjustment variables in
1Furthermore, as discussed inSection 5.2.1 inthe presentation of matching techniques, one need
not assume full conditional independence of Y0 in order to offer consistent and unbiased estimates
of the ATT. An equality of the two conditional expectations, E[Y0|D=1,S]=E[Y0|D=0,S], will
suffice;seediscussionofAssumption2-SinEquation(5.2).

their regression equations. The variables in X are determinants of achievement test
scores that have no direct causal effects on school sector selection. The variables in
O are ultimate background factors that determine all other variables in the graph
(i.e., X, U, D, and Y ). Coleman and his colleagues designated many variables that
10
they believed were contained in O and X, although they were unsure of whether
to consider them as members of O or X. Finally, the variables in U are the crucial
variablesthatColemanandhiscolleaguesrecognizedwereprobablyunobserved.These
variables–intrinsic motivationto learn,subtle featuresofthe homeenvironment,and
anticipation of the causal effect itself – were thought to determine both school sector
choiceandachievement.Becausethese variableswereassumedtobe unobserved,they
are represented collectively in Figure 8.1(a) by the variable U with a node that is a
hollow circle ◦.

In the initial research, the analysis strategy of Coleman and his colleagues was to
conditionon observedvariablesin O and X in orderto attempt to removeas much of
theconfoundingofD→Y aspossible.Reinterpretedwiththeaidofdirectedgraphs,
10
to identify the causal effect they needed to block five separate back-door paths from
D to Y :
10
1. D←U→Y ,
10
2. D←U←O→Y ,
10
3. D←U←O→X→Y ,
10
4. D←O→Y , and
10
5. D←O→X→Y .

10
Accordingto the back-doorcriterion,conditioning onthe variablesin O andX would
blockpaths2,3,4,and5butwouldleavepath1unblocked.Colemanandhiscolleagues
recognized that the variables in U rendered the causal effect of D on Y formally
unidentified,andtheycouldnotconvincetheircriticsthattheirestimatesfrommodels
that conditioned only on O and X were sufficiently close to the ATE (or the ATT) to
offer the conclusion that they did.

TheirsolutiontothispredicamentispresentedinFigure8.1(b),whichbecamepos-
sible when the secondroundof surveydata was releasedtwo yearslater (see Coleman
and Hoffer 1987; Hoffer et al. 1985). Rather than focus on explaining variation in the
tenth grade test score variable, Y , they reclassified it as a conditioning variable and
10
instead designated the new twelfth grade test score variable, Y , as the outcome of
12
interest.TheythenarguedthatY couldservetoscreenofftheeffectsofthevariables
10
inU onY . Inparticular,their strategywasequivalentto assertingthatconditioning
12
on O, X, and Y blocks all five of the back-door paths between D and Y in Figure
10 12
8.1(b):
1. D←U→Y →Y ,
10 12
2. D←U←O→Y →Y ,
10 12
3. D←U←O→X→Y →Y ,
10 12
4. D←O→Y →Y , and
10 12
5. D←O→X→Y →Y .

10 12
Indeed, all of these back-door paths are blocked by conditioning on Y , and four of
10
themareblockedbysupplemental butunnecessaryconditioningonO andX aswell.2
However, notice that Y does not satisfy Condition 2 of the back-door criterion.

10
It lies on a directed path that begins at the causal variable and reaches the outcome
variable, D→Y →Y . Conditioning on Y adjusts away some of the total causal
10 12 10
effectofCatholicschoolingonachievementmeasuredinthetwelfthgrade.Asaresult,
by adopting this analysis strategy, Coleman and his colleagues changed the average
causal effect of interest from the total effect of Catholic schooling on achievement
to a net direct effect, D→Y . This effect is best thought of as the average gain in
12
achievement between the tenth and twelfth grades attributable to Catholic schooling,
although the specific interpretation depends on the model that is estimated.

Holdingasidethefundamentalissueofwhethernarrowingthefocustothisparticu-
larnetdirecteffectishelpfulfortheresearchquestionsathand,considernowthegraph
presentedinFigure8.2,whichsuggeststwomorebasiccriticismsofthisapproach.The
first was seized on by their critics: the variables in U that confound the causal effect
of D on Y are not effectively screened off by Y . More generally, Figure 8.2 should
12 10
be seen as more plausible than Figure 8.1(b) because it is unreasonable to rule out
three direct effects: O→Y , X→Y , and U →Y (or, as Coleman and colleagues
12 12 12
asserted, that these effect are indirect and transmitted through Y →Y ). Because
10 12
O and X are observed, the claims that O→Y and X →Y should be included
12 12
in the graph can be accommodated in subsequent analysis. However, the inclusion of
U →Y renders back-door adjustment with the observed variables ineffective. The
12
rationale for the inclusion of U →Y in the graph is the following. If the parents
12
of highly motivated students were more likely to pay tuition to enroll in Catholic
schools, then enhanced motivation would contribute directly to learning in both the
tenth grade and the twelfth grade. Similarly, it is unreasonable to assume that the
motivation that is correlated with willingness to pay tuition would exert only a one-
timeboostearlyintheCatholicschoolcareersofstudents,whichwouldthenstructure
subsequentachievementonlybywayofatwelfthgradeknock-oneffectfromtheinitial
boost in achievement in the tenth grade. Taken together, the critics argued, in effect,
that Coleman and his colleagues mistakenly ignored a back-door path, D←U→Y ,
12
that remains unblocked after conditioning on O, X, and Y because they failed to
10
acknowledge that U causes Y directly.

12
The second criticism is more subtle. For Figure 8.2, we have omitted the effect
Y →Y that Coleman and his colleagues seem to have asserted for their models,
10 12
andwhich we depicted in Figure8.1(b). Whether this effect shouldbe included in the
graphdependsontherichnessofthevariablesinO,X,andU.Ifthesevariables,when
combinedwithD,constitutefullmodelsofachievementforpublicandCatholicschool
students, then no direct relationship between Y and Y needs to be represented in
10 12
2Coleman and his colleagues sometimes wrote as if they allowed for effects such as O→Y 12 and
X→Y 12. The back-door paths generated by these additional direct effects would all be blocked by
conditioningon O,X, andY 10.Thekey assumptionistheir implicitclaimthat U does not havean
effectonY 12,exceptthroughY 10.

X Y 10
E
O Y 12
U D
Figure8.2 Criticism of Coleman’s estimates of the effect of Catholic schooling on
learning.

the graph. The critics did not take a position on this issue, but we suspect that they
wouldnothavebeenwillingtomaintainthatthemeasuredvariablesinO andX were
richenoughtoeliminatetheneedforincludingY →Y insuchagraph.Instead,they
10 12
would have likely allowed for such an effect so that the causes embedded in eY10 are
allowedto contribute to Y via Y . The critics only emphasized the implausibility of
12 10
interpretingmodelsunderthefaultyassumptionthatD←U→Y doesnotexist,and
12
this point of criticism stands regardless of what position one takes on the plausibility
of Y →Y .

10 12
Yet, once one begins to think about the relationship between Y and Y , it may
10 12
seem implausible to assume that these variables are only associated because of their
commondependenceonO,X,U,andD.Isitreasonabletoassumethatthestructural
error terms eY10 and eY12, which are viewable only under magnification, are indepen-
dent of each other? For Figure 8.1(b), they were assumed to be so. For Figure 8.2,
instead it is assumed that they are only independent of each other after we allow for
unobservedcommondirect causes of both Y and Y , which are representedby E in
10 12
Figure 8.2. Although the common cause relationship Y ←E→Y is quite general,
10 12
for now consider E to be an unobservedand completely random characteristic of stu-
dents that measures their taste for tests. Independent of all else, some students enjoy
takingtestsandperformwellonthem.3 IfsuchacommoncauseofY andY exists,
10 12
it creates four new back-door paths from D to Y through E:
12
1. D←U→Y ←E→Y ,
10 12
2. D←O→Y ←E→Y ,
10 12
3. D←U←O→X→Y ←E→Y ,
10 12
4. D←O→X→Y ←E→Y .

10 12
For these back-door paths, Y is a collider. In the absence of conditioning, all four of
10
these paths are blocked and do not create additional noncausal associations between
D and Y . But, when O, X, and Y are used as adjustment variables, the first path
12 10
3Of course, if this particular variablein E exists, itis unlikelyto be independent of both O and
X.Were weto addedges toalsospecifyO→E orX→E as additional causal effects inFigure8.2,
all of what is written in the maintext would be the same. These additional back-door paths would
beblockedbyconditioningonOandX,butthesameback-doorpath,D←U→Y 10←E→Y 12,that
isunblockedafterconditioningonY 10 wouldremain.

becomesunblockedbecauseconditioningonY inducesanassociationbetweenU and
10
E (seeChapter4).Thesecondandthirdback-doorpathsremainblockedbythesimul-
taneousconditioningontheobservedvariablesO andX,eventhoughconditioningon
Y induces an association between O and E as well as between X and E. In short,
10
if Figure 8.2 is the appropriate representation of the causal system, Coleman and his
colleagues unblocked an already blocked back-door path, thereby creating a new net
association between D and Y . This induced noncausal association is then mixed in
12
with the noncausal association generated by D←U →Y , which critics argued had
12
been mistakenly assumed not to exist. The following demonstration, which considers
thesimplestpossiblecausalmodelconsistentwithFigure8.2,explainsthesecomplica-
tions together, while also leading into the explicit consideration of heterogeneity that
we will take up in the section that follows it.

Panel Data Demonstration 1
ForthissimulatedexampleoftheanalysisofCatholicschooleffectsbyColemanandhis
colleagues,we will use the panel datanotationintroducedinSection 2.8.Nonetheless,
because we will consider only posttreatment data on the outcome and because our
other variables are fixed in time, we can suppress some of the subscripting and other
fine distinctions introduced there.4 In order to focus on the essential identification
issues,weconsideronlylinearspecificationsand,exceptwhennotedotherwise,restrict
all causal effects to be constants or to vary across individuals in completely random
ways independent of all else in the models. These conditions are consistent with the
original research by Coleman and his colleagues, even though they are inconsistent
withourextensivetreatmentofthisresearchquestionusingthemorerecentliterature
(as shown in Chapters 5 through 7, where nonlinearities and heterogeneity of effects
were both shown to be vital considerations when modeling the Catholic school effect
on achievement).

For this demonstration, the potential outcome variables are Y1 and Y0, where
t t
t={10,11,12} for the three grades that occur during the observation window from
the tenth grade through the twelfth grade. Because treatment selection occurs before
t=10, we have observed data only for posttreatment time periods. The treatment
indicator variable, D, is equal to 1 if a student is enrolled in a Catholic school and 0
if enrolled in a public school. (We again ignore other types of private schools.) The
observed outcome variable, Yt, is defined as DY t1+(1−D)Y t0 for t={10,11,12}.

For simplicity, our other variables O, X, and U should be interpreted as indices
of many underlying variables, which we will scale as normally distributed composite
variables. Consistent with our discussion of Figures 8.1 and 8.2, X is a composite
determinant of achievement test scores, Yt, that has no direct effect on whether stu-
dents select Catholic schooling, D. U is a composite variable of unobserved factors
thatdeterminesbothD andYt.AndO isacompositevariableofultimatebackground
4Most importantly, for this demonstration we do not need to make a distinction between D it
(the treatment exposure indicator) and D∗ (the treatment group indicator). Because we have no
i
pretreatment observations and we ignore (as did Coleman and his colleagues) students who switch
between public and Catholic schools between the tenth and twelfth grade, D it=D i∗ for all t. We
thereforeuseourcustomaryD withoutsubscriptsforeitheriort.

factors that determines U, X, D, and Yt. To give these composite variables distribu-
tions that are familiar, O is a standard normal random variable with mean of 0 and
varianceof1.HavingdefinedO asanexogenousrootvariable,wethensetX=O+eX
andU=O+eU, where eX andeU areindependent standardnormalrandomvariables
with mean of 0 and variance of 1.

Weconsiderfourdatasetupscenarios,definedasacross-classificationoftwobinary
conditions:(1)thepresenceofself-selectiononaccurateexpectationsofindividual-level
effectsofCatholicschoolingand(2)thepresenceofsupplementaldependencebetween
the potential outcomes that is produced by an exogenous variable E (see Figure 8.2).

Forallscenarios,theprobabilityofCatholicschoolenrollmentis specifiedasalogistic
distribution
exp(−3.8+O+U)
Pr[D=1|O,U]= , (8.1)
1+exp(−3.8+O+U)
where O and U are as defined above. The probabilities defined by Equation (8.1)
are then specified as the parameters for draws from a binomial distribution, yielding
the indicator variable D for Catholic schooling defined above. As explained below,
we introduce self-selection into two of the four scenarios by allowing U to structure
the potential outcomes, such that those with higher values for U have higher average
individual-level treatment effects. Because of the presence of U in Equation (8.1),
students with highervalues forU arethen morelikely to enterCatholic schoolingand
more likely to benefit from doing so.

For the scenarios without supplemental dependence on E, Y0 is defined as
t
Y0 =100+O+U+X+υ0 ,
10 10
Y0 =101+O+U+X+υ0 , (8.2)
11 11
Y0 =102+O+U+X+υ0 ,
12 12
where the υ0 are independent normal random variables with mean of 0. For the sce-
t
narios with supplemental dependence, Y0 is instead defined as
t
Y0 =100+O+U+X+E+υ0 ,
10 10
Y0 =101+O+U+X+E+υ0 , (8.3)
11 11
Y0 =102+O+U+X+E+υ0 ,
12 12
where E is also a normal random variable with mean of 0.5 On average, Y0 follows a
t
linear time path as determined by the intercept values of 100,101,and 102.However,
the levels of these potential outcomes for individuals are set by the time-invariant
values of O, U, X, and E as well as by time-specific shocks to their outcomes, υ0.

t
5To yield a covariance structure similar to real test score data, for Equation (8.2) we specify
υ t0 as time-period-specific standard normal random variables multiplied by 10. For Equation (8.3),
we specify E as a standard normal random variable multiplied by 5 and υ t0 as time-period-specific
standardnormalrandomvariablesmultipliedby8.6.

To specify a treatment effect that increases linearly in time, Y1 is defined as
t
Y1 =Y0 +δ(cid:2) +δ(cid:2)(cid:2) ,
10 10
Y1 =Y0 +(1+δ(cid:2) )+δ(cid:2)(cid:2) , (8.4)
11 11
Y1 =Y0 +(2+δ(cid:2) )+δ(cid:2)(cid:2) ,
12 12
where δ(cid:2) is a baseline individual-level causal effect, specified as a normal random
variablewithmeanof10andvarianceof1.Theconstitutionofδ(cid:2)(cid:2) dependsonwhether
self-selection is present. In the no-self-selection scenarios, δ(cid:2)(cid:2) is additional random
individual-level variation, specified as a standard normal random variable with mean
of 0 and variance of 1. In the self-selection scenarios, δ(cid:2)(cid:2) varies systematically over
individuals. The values of δ(cid:2)(cid:2) are set as single draws from individual-specific standard
normalrandomvariables with expectation equal to eachindividual’s realizedvalue ui
of U.

The first panel of Table 8.1 presents the ATE, ATT, and ATC for the effect of
Catholic schooling on test scores in the tenth and twelfth grades, as implied by the
data setup just detailed. For the first two columns, students do not self-select into
Catholic schooling based on accurate expectations of the individual-level gains from
doingso.Accordingly,theATE,ATT,andATCareallthesame,andtheyallincrease
from10.00 to 12.00 between the tenth and twelfth grades, as determined by Equation
(8.4). For the last two columns, students self-select on the causal effect, as explained
above.The ATT is largerthan the ATE andthe ATC. But, again,the averagegainis
2.00 for the ATE, ATT, and ATC.

The second panel of Table 8.1 presents estimates for the coefficient on D from a
series of regression models, first for cross-sectional estimators that use outcome data
from only one point in time and then, as in the research of Coleman and colleagues,
for panel data models that use outcome data from two posttreatment points in time.

Theselatterregressionmodels,aswewillexplaininChapter11,arelabeledpaneldata
analysisof covariancemodels. We use generic ordinaryleast squares (OLS) regression
estimation, as in the original research of Coleman and his colleagues, but we have
givenOLSestimationabestcasedatasetupwherelinearspecificationsarereasonable
and the pattern of individual-level heterogeneity is simple.

Considerfirsttheresultsfortheregressionmodelsintheno-self-selectionscenarios.

For the first column, we also do not assume that E is a common cause of both Y
10
and Y , which does not render Y a collider on any back-door paths from D to Y .

12 10 12
For the second column, E is a common cause. This distinction for the data setup
producesnodifferencesforthecross-sectionalregressionestimatesofthecoefficienton
D because Y is not in the conditioning set for these models.

10
For both sets of cross-sectional estimators in the no-self-selection scenarios, the
same pattern of results is present for models that have Y as the outcome variable
10
and for models that have Y as the outcome variables. The naive estimator is too
12
large, and adjustment for O and X eliminates only some of the confounding.6
6Additional adjustment for U wouldyield estimates that areequal to the ATE, ATT,and ATC.

Thislastresultismerelyabenchmark, giventhat wehave assumedthat U isunobserved, asinthe
researchofColemanandhiscolleagues.

Table 8.1 Simulated Results for the Identification Approach Adopted by
Coleman and Colleagues
Setup conditions:
Self-selection on the causal effect No No Yes Yes
E is a common a cause of Y t0 No Yes No Yes
True average treatment effects:
ATE,tenth grade 10.00 10.00 10.00 10.00
ATT, tenthgrade 10.00 10.00 11.85 11.85
ATC, tenthgrade 10.00 10.00 9.81 9.81
ATE,twelfth grade 12.00 12.00 12.00 12.00
ATT, twelfth grade 12.00 12.00 13.85 13.85
ATC, twelfth grade 12.00 12.00 11.81 11.81
Estimated Coefficient on D
Cross-sectional estimators:
Regression of Y 10 on D 14.75 14.75 16.60 16.60
Regression of Y 10 on O, X, and D 10.80 10.80 12.58 12.58
Regression of Y 12 on D 16.75 16.75 18.60 18.60
Regression of Y 12 on O, X, and D 12.80 12.80 14.58 14.58
Panel data analysis of covariance estimators:
Regression of Y 12 on Y 10, O, X, and D 12.68 9.98 14.41 11.27
For the analysis of covariance models with Y as the outcome variable, the coeffi-
12
cientestimatesonD donotequaltheATE,ATT,orATCforthetwelfthgrade,which
are all 12.00. The coefficient estimate of 12.68 is too large when E is not a common
cause because the unblocked back-doorpath throughU biases the coefficient upward.

The estimate is then too small when E is a common cause because the upward bias
fromtheunblockedback-doorpaththroughU isthenjoinedbyalargerdownwardbias
produced by conditioning on Y , which is a collider along the new back-door paths
10
through E (see the discussion that precedes the demonstration for an accounting of
these back-door paths).

As shown in the third and fourth columns, the basic pattern for the estimated
models changes only modestly when self-selection is present. The last two columns
are analogous to the first two, after allowing the self-selection term, δ(cid:2)(cid:2), to vary with
U, as explained above for Equation (8.4). For these last two scenarios, none of the
cross-sectional estimators yield estimates equal to any of the average causal effects,
eitherinthetenthgradeorthetwelfthgrade.7 Theanalysisofcovariancemodelshave
7Evenmodels thatadjustforU wouldnot suffice.Fortheself-selectionscenarios,theindividual-
leveleffectofCatholicschoolingvarieswithU,suchthatthosewithhigheraveragevaluesofU have
the same pattern as in the no-self-selectionscenarios.When E is not a common cause
of Y and Y , the estimate is larger than the ATE, ATT, and ATC. When E is a
10 12
common cause, rendering Y a collider, the estimate is smaller than the ATE, ATT,
10
and ATC.

Finally,noticealsothattheanalysisofcovarianceestimatesarenowhereneartothe
average gain in achievement between the tenth and twelfth grades, which is equal to
2.00,and which by construction is equal for both Catholic and public school students
and does not depend on whether self-selection is present. As such, under this setup,
which is consistent with Figure 8.2, the analysis of covariancemodels do not estimate
a net direct effect of Catholic schooling on achievement in the twelfth grade that can
be given an interpretation as an estimate of an average gain in achievement.

Many analysis puzzles and ensuing causal controversies in the social science lit-
erature have the same basic features as this demonstration. The plausibility of the
criticism in Figure 8.2 should serve as a caution because it demonstrates how addi-
tional posttreatment observations of the outcome variable are unlikely to resolve the
fundamental identification challenge created by selection on unobservables and non-
ignorability of treatment assignment. We consider models of this type in detail in
Chapter 11, including a more complete discussion of the sorts of processes that gen-
erate over-time dependencies, such as the one produced by E in Figure 8.2. However,
we also have some more encouragingresults to offer in Chapter 11. If, as was the case
for this demonstration, the causal effect is evolving in time, such that the trajectory
for the outcome in the absence of treatment has the same time path before and after
treatment exposure, then it is possible to obtain consistent estimates of some average
treatment effects of interest.

Before offering a full explanation of analysis strategies when data are available
from pretreatment time periods, we will consider two other types of estimators –
instrumental variable estimators in Chapter 9 and mechanism-based estimators in
Chapter 10. To motivate our presentation of these methods in subsequent chapters,
we conclude this chapter in the next section by enriching our presentation of directed
graph methodology, explaining how graphs can be used to represent full patterns of
self-selection and heterogeneity using latent class variables.

larger treatment effects. As a by-product, the individual-level causal effect also varies with O and
X, given that these variables are positively associated with U because of the common-cause path
U←O→X. The conditional-variance weighting that is implicit in OLS regression averages these
heterogeneous individual-level effects, giving more weight to those whose implicit propensity scores
are near to .5. Given the data setup, where only 9 percent of students end up enrolled in Catholic
schools–becauseoftheinterceptof−3.8forthelogisticdistributioninEquation(8.1)–theimplicit
weighting would move the estimated average effects toward the ATT relative to the ATC. Yet, the
coefficientestimateswouldnotequaltheATT.AsexplainedinSection6.3,thesecoefficientsarebest
interpretedasestimates oftheATEwithsupplemental conditional-variance-based weighting, which,
for this demonstration, would push the estimates toward the ATT because of the distribution of D
and the positive association between U and D. In practice, of course, the variable U would not be
availableforanalysisinthefirstplace.

## 8.3 Causal Graphs for Complex Patterns of Self-Selection and Heterogeneity

Weconcludethischapterwithapresentationofhowpatternsofself-selectionandhet-

erogeneitycanberepresentedwithdirectedgraphs.8Wehavetwogoalsinthissection.

First, we want to demonstrate and explain the generality of the graphical approach
to the representationof causalrelationships,which we will utilize insubsequentchap-
ters. Second, we want to make the following obvious (but frequently forgotten) point:
The best solution to an unobserved variable problem is to develop and deploy addi-
tional new measures. Too often, the literature implies that self-selection patterns are
so complex that estimation in their presence will forever remain infeasible. We see
more promise in developing methods to directly confront the limitations of available
data thanthe literature often implies, andwe wantto make this caseexplicitly before
offering explanations in the next three chapters of estimation strategies that may be
feasible while the limitations of available data remain unaddressed.

In this section, we use the charter school effect on learning as the focal example,
which we introduced in Section 1.3.2 (see page 24). This example shares some of the
samecomplicationsastheexampleoftheCatholicschooleffectthatwehaveconsidered
extensively already, but it offers some new complications as well (and serves as a
bridge to the school voucher instrumental variable example that will be considered in
Chapter 9). In the material that follows, we start with a simple latent class model
of heterogeneity that allows families of different types to differ in their likelihood of
choosing charter schools. We then build toward a full directed graph that shows the
estimationchallengeclearly,atwhichpointwewillthenelaboratetheback-doorpaths
inordertodiscussfeasibleestimationstrategiesthatwouldbepossibleifnewmeasures
were constructed that would enable direct modeling of choice behavior. We conclude
withagraph-aidedinterpretationofextantempiricalresearchoncharterschooleffects.

8.3.1 A Starting Point: Separate Graphs for Separate
Latent Classes
Consider the two causal graphs in Figure 8.3, and suppose that the population is
partitioned into two latent classes, each of which has its own graph in panel (a) or
panel (b). Suppose that P is a family’s parental background, D is charter school
attendance, and Y is a score on a standardized test given to all fifth graders in a
large metropolitan school district. For these two graphs, the subscripts refer to latent
classes, which are also indicated by a latent class membership variable G that takes
on values of 1 and 2.9
Althoughsurelyagrossoversimplification,supposenonethelessthatthepopulation
is composed of fifth graders who have been raised in two types of families. Families
with G=1chooseschoolspredominantlyforlifestylereasons,suchasproximitytothe
home and tastes for particular school cultures, assuming that all schools are similar
8ThissectiondrawsonmaterialpreviouslypublishedinMorganandWinship(2012).

9Thelowercasevaluesx,d,andy forthetwocausalgraphs aremeanttoconnote that theseare
realizedvaluesofX,D,andY thatmaydifferintheirdistributionsacrossthetwolatentclasses.

d d
1 2
α δ α δ
1 1 2 2
p 1 β 1 y 1 p 2 β 2 y 2
(a) G = 1 (b) G = 2
Figure8.3 Separate causal graphs for two groups of individuals (G=1 and G=2)
where the effects of parental background (P) and charter schools (D) on test scores
(Y) may differ for the two groups.

in instructional impact because achievement is largely a function of individual effort.

FamilieswithG=2chooseelementaryschoolsfortheirchildrenbyselectingtheschool,
subject to constraints, that they feel will maximize the achievement of their children,
assumingthatschoolsdiffer inqualityandthattheir childrenmaylearnmoreinsome
schools than in others. Accordingly, these families are attentive to the national press
coverageofeducationalpolicy,inwhichmanypolicymakershavearguedforincreasing
the number of charter schools in the country because some research has claimed that
charter schools are more effective than traditional public schools. As a consequence,
the second group of families is more likely to send their children to charter schools,
such that the mean of D is higher for those families with G=2 than G=1.

Finally,supposethatparentswithhigherlevelsofeducationaremorelikelytovalue
distinctive forms of education, and as a result are more likely to send their children
to charter schools (independent of whether or not highly educated parents are more
likely to be found in the latent class for whom G=2, which we will discuss later).

They are also more likely to be able to support children in completing homework and
otherwise making the most of the educational opportunities that are offered to their
children. Accordingly, suppose that in both groups the causal effects P → D and
P → Y are positive and substantial (i.e., that α , β , α , and β in Figure 8.3 are
1 1 2 2
positive and substantial).

The question for investigation is whether the effect of D on Y is positive for both
groups and, if so, whether it is the same size for both groups. If one is willing to
assume, assome ofthe literature suggests,that the secondgroupoffamilies is correct
in the sense that school quality does matter for student learning, and further that
charter schools are higher quality, then we should expect that both δ and δ are
1 2
more likely positive than not. And, if one believes that parents with G=2 have some
sense that this is correct, then not only will more of them send their children to
charterschools,theywillalsosorttheirchildrenmoreeffectivelyintocharterandnon-
charterschools.Inotherwords,theywillalsobemorelikelytocontinuetoenrolltheir
childreninregularpublicschoolsiftheyfeelthattheirchildrenwillnotbenefitfromthe
distinctive characteristics of available charter schools (e.g., if the charter schools that
have openings have instructional themes that their children find distasteful). Because
both of these self-selection effects are reinforcing, is it likely that δ >δ .10
2 1
10Thesetargetparameters,δ 2andδ 1,aredefinedimplicitlyastheaverageeffectofcharterschooling
forallstudents fromfamilieswithG=2andG=1,respectively.

If this plausible scenario is true in reality, what would happen if a researcher
ignored the latent classes (either by mistake or, more realistically, because the mem-
bership variable G is unobserved) and simply assumed that a single graph prevailed?
In this case, a researcher might estimate the effect of D on Y for each value of P
and then average these effects over the distribution of P, yielding a population-level
estimate δ. At best, this estimate would be uninformative about the underlying pat-
tern of heterogeneity that suggests that δ >δ . At worst, this estimate would be
2 1
completely wrong as an estimate of the average causal effect of D on Y, which we
have referred to as the ATE in prior chapters. For example, if P predicts latent class
membershipG,andGpredictsthesizeoftheeffectofDonY,thenP-stratum-specific
effects mix together individual-level causal effects that vary with the conditional dis-
tribution of G within the strata of P. Combining P-stratum-specific effects by cal-
culating an average effect across only the distribution of P does not properly weight
the G-stratum-specific effects that are embedded in differential patterns within the
strata of P.

In order to consider these possibilities, we need to have a model of selection into
D that is informed by a model of the traits of families that would cause them to be
foundinunderlyinglatentclasses.Itismostnaturaltopursuesuchamodelinasingle
causal graph that explicitly represents the latent classes by including the variable G
as a node within it.

8.3.2 A Single Graph That Represents All Latent Classes
Consider Figure 8.4, which contains a standard causal triangle where D has an effect
on Y but where both D and Y share a common cause P. To this triangle, the latent
class membership variable G is introduced as an explicit cause of D. The variable G
is given a hollow node, ◦, to indicate that it is unobserved.11
The arrowfromG to D is presentbecause there are alternativegroups offamilies,
codedbythealternativevaluesoftheunobservedvariableG,thatapproachdifferently
thedecisionofwhethertosendtheirchildrentocharterschools.Asaresult,Gpredicts
charter school attendance, D. Although we will continue to write as if G only takes
on two values that identify two latent classes, this restriction is no longer necessary.

G may take on as many values as there are alternative groups of families who differ
systematically in how they approach and enact the decision of whether to send their
children to a charter school. (We considered only two values for G in Figure 8.3 to
limit the number of G-specific graphs that needed to be drawn.)
The corresponding structural equations for the graph in Figure 8.4 are then
P =fP(eP), (8.5)
G=fG(eG), (8.6)
D=fD(P,G,eD), (8.7)
Y =fY(P,D,eY). (8.8)
11Here, we followElwertand Winship (2010) and introduce alatent class variableG to represent
effectheterogeneity.

G
D
P Y
Figure8.4 A graphwheregroupsarerepresentedby anunobservedlatentclassvari-
able (G) in a single graph.

The latent class membership variable G only enters these structural equations in two
places, on its own in Equation (8.6) and then as an input to fD(.) in Equation (8.7).

Recall also that the unspecified structure of the functions such as fY(.) permits the
sort of interactions discussed in the last subsection, where, for example, the effect of
D depends on the level of P. (See Section 3.3.2 for a full discussion.)
To accept Figure 8.4 as a full representationof the causalrelationships between G
and the other variables P, D, and Y, we must be able to assume that G shares no
commoncauseswithP,D,orY thathavebeenmistakenlysuppressed.Thenecessary
assumptions are that students who have parents with higher levels of education are
no more likely to know of the educational policy dialogue that claims that charter
schools have advantages and also are no more likely to think that school quality has
anyeffectsonachievement.Wemustalsobewillingtoassumethat,withinvaluesofP
andD,GhasnocausaleffectonY,whichwithourexampleistantamounttoassuming
thatthosewhoattempttomaximizethelearningoftheirchildrenbyselectingoptimal
schools(1)donotmanagetodosowellenoughsothattheobtainedeffectisanylarger
on average,conditional on other factors, for their own children than for those who do
not attempt to select on the causaleffect of schooling and (2) do not do anything else
that helps their children to benefit from the learning opportunities provided to them
in schoolor in the home that is not alreadycapturedby the direct effect P →Y. This
wouldrequirethattheimpulsetoselectintocharterschoolsbasedonbeliefsaboutthe
size of the charter school effect for one’s own child is a completely ignorable process,
since it does notresult in any actualselectionon the variationin the causaleffect nor
generate any reinforcing behavior that might complement the charter school effect.

None of the literature on charterschooleffects supports such a dismissal of the power
of self-selection.

Accordingly, for Figures 8.5(a) and 8.5(b), we add an arrow from G to Y to the
graph presented earlier in Figure 8.4. For Figure 8.5(a), which includes only this one
additional arrow,the structural equations are
P =fP(eP), (8.9)
G=fG(eG), (8.10)
D=fD(P,G,eD), (8.11)
Y =fY(P,D,G,eY). (8.12)
G G
D D
P Y P Y
(a) (b)
Figure8.5 Two graphs where selection into charter schools (D) is determined by
group (G) and where selection renders the effect of D on Y unidentified as long as G
remains unobserved.

For Figure 8.5(b), we drop the assumption that G is independent of P. This elabo-
rated graph now includes an arrow from P to G. As a result, fG(eG) is no longer the
appropriate function for G.Equation ( 8.10) must be replaced by
G=fG(P,eG) (8.13)
so that family background is an explicit cause of latent class membership. It is likely
that parents with high socioeconomic status are more likely to select on the possible
causal effect of charter schooling, which is how the latent classes were discussed for
Figure 8.3. Still, how these latent classes emerge is not sufficiently transparent in
Figure 8.5. A more explicit causal model that gives structure to the causal pathway
from P to G may help to clarify the self-selection dynamic, as we show next.12
8.3.3 Self-Selection into the Latent Classes
Suppose that the latentclass membershipvariableG is determined atleastin partby
avariablethatmeasuresafamily’ssubjectiveexpectationoftheirchild’slikelybenefit
from attending a charter school instead of a regular public school.Although we could
enter this variable into a graph with a single letter, such as S or E, for Figure 8.6 we
useafullmnemonicrepresentationasavariablelabeledExp(D→Y),whichrepresents
“thefamily’ssubjectiveexpectationofthespecificeffectofD onY fortheirparticular
child.” For Figure 8.6(a), which is a direct analog to Figure 8.5(a), this subjective
12Insomework,latent classmembershipvariables suchasGarenotregardedas causal variables.

WeregardGasanominalcausalvariablebecausewecanconceiveofaninterventionthatcouldmove
a family from one value of G to another. The goal of introducing G into this graph is to provide
a representation of consequential individual-levelheterogeneity, and accordingly weallow G to have
nominal causal effects on the outcome of interest through G→Y. We will explain later why a fully
elaboratedgraphthatlocates thesourcesofallsuchheterogeneity instructural variablesthat lieon
directed paths that reach G would thereby render G as a redundant carrier of these fully specified
determinantsofheterogeneity. Inthiscase,Gcouldthenberemovedfromthegraph,astherewould
be no need for a nominal causal variable to transmit the heterogeneity produced by its genuine
determinants.

Exp(D Y) G Exp(D Y) G
I
D D
P Y P Y
(a) (b)
Figure8.6 Two graphswhere selectiononthe unobservablesis givenanexplicit rep-
resentationas self-selectionon subjective expectations ofvariationin the causal effect
of D on Y. For panel (b), these expectations are determined by information (I) that
is differentially available to families with particular parental backgrounds (P).

expectation is the sole determinant of G. The structural equations are then
P =fP(eP), (8.14)
Exp(D→Y)=f (e ), (8.15)
Exp Exp
G=fG[Exp(D→Y), eG], (8.16)
D=fD(P,G,eD), (8.17)
Y =fY(P,D,G,eY). (8.18)
Note that Exp(D→Y) is determined solely by e in Equation (8.15). Thus, the
Exp
graph in Figure 8.6(a) would be an accurate representation of the system of causal
relationshipsifsubjectiveexpectationswereeithercompletelyrandomorinsteadbased
solely on characteristics of families that are independent of the family background
variables in P.

Given what we have written about the likelihood that families with different pat-
terns of P will end up in different latent classes represented by G, it seems clear
that Figure 8.6(a) is not the proper representation for the research scenario we have
alreadyspecified. Accordingly,in Figure 8.6(b), e is joined by an unspecified addi-
Exp
tional input I into the subjective expectation of the child-specific causal effect of D
onY,whichisthenpresumedtobecaused,inpart,byfamilybackground.Asaresult,
thereisnowapathfromP toGthroughI andExp(D→Y).Thestructuralequations
are now augmented as
P =fP(eP), (8.19)
I=fI(P,eI), (8.20)
Exp(D→Y)=f (I,e ), (8.21)
Exp Exp
G=fG[Exp(D→Y), eG], (8.22)
D=fD(P,G,eD), (8.23)
Y =fY(P,D,G,eY). (8.24)
Insociology,thecausaleffectofP onExp(D→Y)viaI followsfromthepositionthat
privilegedpositionsinsocialstructureareoccupiedbyadvantagedfamilies.Fromthese
positions,individualsacquireinformationI thatallowsthemtorecognizebenefitsthat
are available to them.13
The directed path P →I →Exp(D→Y)→G carries one important systematic
source of self-selection through to the latent class variable G. However, this path is
not the only directed path that is present, as could be seen under magnification.

The differences in information about the charter school effect that are independent
of parental background have their effect on G through eI →I →Exp(D→Y)→G.

Likewise, differences in expectation formation processes that are not based on infor-
mation and are independent of parental background have their effects on G through
e →Exp(D→Y)→G.

Exp
By building the full graph progressively from Figures 8.4 through 8.6(b), we have
explicitly elaboratedwhat is often presumedin models that incorporateself-selection.

BackgroundvariablesinP arerelatedtothecauseDbywayofasetoflatentclassesin
Gthatencodesubjectiveevaluationsoftheindividual-specificcausaleffectofD onY.

These expectations are functions, in part, of characteristics in P by way of the infor-
mation I that is differentially available to families that differ on P. Yet, even though
we now have an elaborate representation of self-selection, we still have not brought
what some would label “contextual effects” into the model, such as neighborhood of
residence. We consider this complication next, which is clearly important to consider
when modeling the effects of charter schools on learning.

8.3.4 Self-Selection into the Treatment and a
Complementary Context
How hard is the task of allowing for contextual effects? Consider Figure 8.7, which
incorporates a contextual variable N into the causal graph in Figure 8.6(b). N repre-
sentsallcausesofstudentachievementthatcanbeconceptualizedaseitherfeaturesof
astudent’sresidentialneighborhoodorfeaturesofacharterschool’ssurroundingneigh-
borhood. The component variables in N might be access to resources not measured
by P or specific local cultures that may or may not promote student achievement.14
13In addition, it may be that there are also additional common causes of P and I, which could
be represented by a bidirected edge between P and I in the graph. This would be reasonable if
informational advantages that structure expectations for optimal school choices are determined by
deeper structural factors that alsoconfer socioeconomic advantages onparents beforethey arriveat
thedecisionpointofwhether ornottosendtheirchildrentocharter schools.Itisalsopossiblethat
parental background determines expectation formationprocessestosomedegree,suchthat different
familiesprocess informationdifferently, aswouldbecase ifthedirected pathP→Exp(D→Y)→G
were added to the graph. We do not include these additional causal pathways in the graph because
they would add additional back-door paths to the subsequent discussion without changing the core
identificationresults.

14If the latter are only diffuse cultural understandings that only weakly shape local norms about
theappropriatenessofenactingtheroleofachievement-orientedstudent,thensuchvariablesmaybe
difficulttoobserve.Inthiscase,N mightthenbecodedasaseriesofneighborhooddummyidentifier
variables. Analysis of these effects would then only be possible if there were sufficient numbers of
students to analyze from within each neighborhood studied. Without such variation, the potential
effectsofN couldnotbeseparatedfromindividualcharacteristicsofstudentsandtheirfamilies.And,
if modeled in this way, only the total effects of N would be identified, since the dummy variables
for N would not contain any information on the underlying explanatory factors that structure the
neighborhoodeffects thattheyidentify.

Exp(D Y) G
N
I
D
Y
P
Figure8.7 A graph where self-selection on the causal effect of charter schooling also
triggers self-selection into consequential and interactive neighborhood contexts (N).

With the addition of N, the function for Y is now fY(P,D,G,N,eY). Recall, again,
that N is not restricted by any functional form assumption for fY(.). As a result, the
causal effect of N can modify or interact with the effects of G, D, and P on Y.15
Figure 8.7also allowsforevenmore powerfuleffects of self-selection.Suppose that
self-selectionintothelatentclassesinGisassociatedwithself-selectionintoN aswell.

We see two separate and countervailing tendencies. Parents attuned to the potential
benefitsofcharterschoolingarealsomorelikelytochooseneighborhoodcontextsthat
bestallowthemtoencouragetheirchildrentostudyhardinschool.Atthesametime,
after obtaining an attendance offer from a charter school, a family may also decide to
move to an alternative neighborhood in the catchment area of a suboptimal regular
public school, since attendance at such a school may no longer be a consideration in
the family’s residential decision. If either effect is present, then the function for N is
equal to fN(G,eN), and we then have seven structural equations as
P =fP(eP), (8.25)
I=fI(P,eI), (8.26)
Exp(D→Y)=f (I,e ), (8.27)
Exp Exp
G=fG[Exp(D→Y), eG], (8.28)
D=fD(P,G,eD), (8.29)
N=fN(G,eN), (8.30)
Y =fY(P,D,G,N,eY). (8.31)
The nonparametric nature of these structural equations allows for fully interactive
effects. Most importantly,the function for Y, fY(P,D,G,N,eY), allows for the effects
of D and N to vary within each distinct combination of values between them, as
wouldbe the caseif the charterschooleffectvariedbasedonthe neighborhoodwithin
which students lived. We should also note that we could enrich the causal model
further by drawing from the literature that posits deeper causal narratives for the
joint determination of P and N, as well as other causal pathways that link P to N.

We see the graph in Figure 8.7 as sufficiently rich to motivate the discussion we have
offered so far as well as for the analysis of the extant empirical research to which we
turn next.

15SeeVanderWeele(2009b)foranincisiveanalysisofthedifferencebetweenaninteractionandan
effect modification. Our interest, conceptually at least, is in instances of genuine causal interaction,
althoughmuchofwhatwewritewouldholdundersimplerstructuresofonlyeffect modification.

8.3.5 A Graph-Aided Interpretation of Extant Empirical
Models of Charter School Effects
There are two basic goals of writing down a causal graph: (1) to represent the set
of causal relationships implied by the available state of knowledge and (2) to assess
thefeasibilityofalternativeestimationstrategies.Figure8.7representsacausalgraph
that is a reasonable representation of the causal structure that generates the charter
school effect. This is a matter of judgment, and one might contend, for example, that
the claim that self-selection on the charter school effect generates movement between
neighborhoods is overly complex.

Supposethatonehasaccesstoobservationaldata,suchastheNationalAssessment
ofEducationProgress(NAEP)dataanalyzedbyLubienskiandLubienski(2003),that
provide information on standardized test scores, school type, and some family back-
groundcharacteristics.Forthesakeofourexposition,supposefurtherthattheseNAEP
datahadevenbettermeasuresoffamilybackgroundandneighborhoodcharacteristics,
so that we could conclude that high-quality data are available for all of the variables
in Figure 8.7 with solid nodes: Y, D, N, and P. Yet, no data are available for the
variables with hollow nodes: I, Exp(D→Y), and G. The primary goal of analysis
is to estimate the average causal effect of D on Y, as this effect interacts with the
complementary causal effect of N on Y. Can one adjust for confounding in order to
estimate these effects?
The first question to consider is the following: Is there a set of observed variables
inFigure 8.7thatsatisfies the back-doorcriterionwiththe respectthe causaleffect of
D on Y and the causal effect of N on Y? The relevant back-door paths are,
for D,
1. D←P →Y,
2. D←P →I→Exp(D→Y)→G→Y,
3. D←P →I→Exp(D→Y)→G→N→Y,
4. D←G→N→Y,
5. D←G→Y;
and
for N,
6. N←G→Y,
7. N←G→D→Y,
8. N←G←Exp(D→Y)←I←P →Y,
9. N←G←Exp(D→Y)←I←P →D→Y,
10. N←G←Exp(D→Y)←I←P →D←G→Y.

How many of these paths can be blocked by conditioning on the observed data?
For models that estimate the effect of D on Y, paths 1 through 4 can be blocked
by conditioning on P and N. However, path 5 remains unblocked. Likewise, paths
7 through 10 can be blocked by conditioning on P and D, but path 6 remains
unblocked.Forthetwounblockedpaths,thesameproblematiceffectispresent:G→Y.

This effect transmits the effects of exogenous causal determinants of I and
Exp(D→Y), which are eI and e Exp, through the directed path I →Exp(D→Y)
→G→Y.Thus,ifthereisselectiononthecausaleffectitself,independentofparental
background, then it enters the model through G and confounds the conditional asso-
ciations between D and Y and between N and Y. This confounding cannot be elimi-
nated by conditioning on the observeddata, and therefore back-door conditioning for
the effects of D and N on Y is infeasible.

Thisconclusionishardlyrevelatoryforreaderswhoalreadyknowtheliteratureon
self-selectionbiasand/ortheempiricalliteratureoncharterschooleffects.Nonetheless,
we would argue that there is substantial didactic and communicative value in seeing
this result expressed with a causal graph to which the back-door criterion is then
applied.To effectively use back-doorconditioning to identify all averagecausal effects
of primary interest – the ATC, ATT, and ATE – we would need to specify a more
elaborate set of causes of G, which would generate G through and/or alongside the
structuralequations that determine I andExp(D→Y). Itwouldbe sufficient to have
a model for G, fG(.), where all inputs other than eG are observed and where these
inputs are sufficiently rich such that eG can be regarded as a constant that applies
to everyone.Equivalently, we would need a set of observedmeasures as variables that
point to G in the graph that would allow us to declare that there are no more latent
classesprecisely because G is a deterministic function of the observedvariables in the
graph. In this case, all sources of the noncausal association between D and Y and
between N and Y would be indexed by the observed variables that determine G, and
we could safely remove G from the graph and allow those variables to point directly
to D, N, and Y.

Without accessto suchobservedvariables,whichpreventus fromexplaining away
the existence of the latent classes indexed by G, how can analysis proceed? There are
twomainchoices.First,theanalystcanconcedethatself-selectiononthecausaleffect
ispresent(because Gcannotbe eliminatedfromthe graph),whichmayevengenerate
neighborhood-basedselectionasa by-product.Inthese circumstances,the presenceof
the causal relationship G→Y rendersestimates of D andN on Y unidentified, either
in interactive fashion or when averaging one over the other. In this case, analysis
must then be scaled back, and we would recommend that set identification results be
pursued, as we will explain later in Chapter 12. The new goal would be to estimate
an interval within which the averagecausal effect of interest must fall.

In the actual empirical literature on the charter school effect, this humble option
has not been pursued by any of the main combatants in the debates. Instead, this
research is a good example of what Manski (2013b) has labeled “policy analysis with
incredible certitude.” The desire to provide point estimates of causal effects has been
too strong, even though it would seem clear to many outside readers that the debate
over charter school effects persists simply because the point estimate of the ATE is
unidentified. Consider the two dominant positions in the extant literature.

One group of researchers has used the lottery-induced structure of charter school
enrollmentsinordertoestimateeffects.Incitieswherethenumberofcharterschoolsis
insufficienttomeetdemand,mostschoolsarerequiredbytheircharteringauthoritiesto
performrandomlotteriesandofferadmissionfirsttothosewhowintheirlotteries.This
admissions mechanism delivers two comparable groups: lottery winners and lottery
losers. If the lottery winners attend charter schools and the lottery losers do not,
then observation of achievement trajectories following the lottery enables estimation
of averagetreatment effects for those who participate in the lottery.16
The researchers who use this research design typically define the charter school
effect of interest as solely the ATT: the effect of charter schooling among those who
would self-select into charter schooling by applying for the lottery. This is entirely
appropriate for the interpretation of lottery-based results. The problem is that these
samescholarstoofrequentlyforgettheboundednatureoftheirconclusions.Forexam-
ple, in their study of charter schools in New York City, Hoxby, Murarka, and Kang
(2009:vii) introduce their results in their “Executive Summary” with three bullet
points:
• “Lottery-basedanalysis of charter schools’ effects on achievement is, by far, the
mostreliablemethodofevaluation.Itistheonlymethodthatreliablyeliminates
‘selection biases’ which occur if students who apply to charter schools are more
disadvantaged,moremotivated,ordifferentinanyotherwaythanstudents who
do not apply.”
• “On average, a student who attended a charter school for all of grades kinder-
garten through eight would close about 86 percent of the ‘Scarsdale-Harlem
achievement gap’ in math and 66 percent of the achievement gap in English. A
studentwho attended fewer gradeswouldimproveby a commensuratelysmaller
amount.”
• “Onaverage,alotteried-outstudentwhostayedinthetraditionalpublicschools
for allofgradeskindergartenthrougheightwould stayon gradelevelbut would
notclosethe‘Scarsdale-Harlemachievementgap’bymuch.However,thelotteried-
outstudents’ performance does improveandis better thanthe norminthe U.S.

where, as a rule, disadvantaged students fall further behind as they age.”
Nowhere in their “Executive Summary” is it stated that these comparisons across
lotteried-inandlotteried-outstudentsareonlyinformativeaboutthosewhoself-select
into the relevant charter school lottery. Selection bias is not eliminated, as claimed in
the first bullet point; the lottery-generateddata simply provide a reasonable compar-
ison among those who self-select into the charter school lottery.

More generally, it is not conceded that the results are uninformative about two
first-order policy questions:
1. What is the expected charter school effect for a randomly chosen student from
New York City, assuming the supply of charter schools is held constant?
2. What is the expected charter school effect for the subset of students in public
schoolswhowouldbeinducedtoapplytocharterschoolsifapolicyintervention
were implemented to expand the supply of charter schools?
16For simplicity, in this discussion we ignore non-comparability generated by random variation,
initialcompliancewiththelottery,andselectiveattritionovertheobservation windowfollowingthe
lottery. In most cases, the researchers who have modeled these effects have carefully adjusted their
datatoneutralizethesethreats toinference.

To answer these questions, the authors would need a full model of the charter school
effect for students who never applied to charter schools, and lottery-basedstudies use
no data on these students. The ATT is the appropriate parameter to estimate only
when addressing a second-order policy question that is not the focus of the debate:
“Should charter schools in New York City continue to receive support because those
students who have chosen to attend them have learned more than they would have
if they had attended regular public schools?” The answer to this question appears to
be yes, and yet Hoxby et al. (2009) chose not to limit their conclusions only to this
supportable position, at least when putting forward their primary conclusions.

If this were nottroubling enough,the alternative is worse.One cansimply assume
away the unblocked paths that include G→Y, which is tantamount to assuming
that self-selection does not exist. The study of the Center for Research on Education
Outcomes(2009)isclosertothisposition.Itsauthorsofferacomplexsetofconclusions
based on national results where charter school students are matched to students from
traditional public schools based on observed characteristics. Their overall conclusion
isthatcharterschoolsaregenerallyineffective foramajorityofstudents,eventhough
charter schools may be effective for a minority of students who are not well servedby
regular public schools:
In our nationally pooled sample, two subgroups fare better in charters
than inthe traditional system: students inpovertyand ELL[EnglishLan-
guage Learner] students....These findings are particularly heartening for
the charter advocates who target the most challenging educational popu-
lationsorstrivetoimproveeducationoptionsinthe mostdifficultcommu-
nities. Charter schools that are organized around a mission to teach the
mosteconomicallydisadvantagedstudentsinparticularseemtohavedevel-
opedexpertiseinservingthesecommunities....Theflip-sideofthisinsight
shouldnotbeignoredeither.Studentsnotinpovertyandstudentswhoare
not English language learners on average do notably worse than the same
students who remain in the traditional public school system. Additional
workisneededtodeterminethereasonsunderlyingthisphenomenon.Per-
haps these students are “off-mission” in the schools they attend. (Center
for Research on Education Outcomes 2009:7)
These conclusions are offered based on models that match students on observable
characteristics, leaving unobserved selection on the causal effect unaccounted for and
almost entirely ignored in the write-up of the results. The report is written as if
variation in the average treatment effect for different types of students is the central
interest, and that matching justifies estimation of all such conditional averageeffects.

It bears noting that the pattern presented in this study by CREO is consistent
with the one that we favored for the extended example that concluded Chapter 7,
whichweseemoregenerallyasthesignatureofanunderlyingpatternofself-selection.

In this case, students from families who are living in poverty but who make their way
into charter schools are fleeing poor alternatives in their own neighborhood schools
and,furthermore,haveextraamountsof motivationto succeedinschool.Atthe same
time, it is likely that students from more advantaged families are more likely to be
attending charter schools solely for lifestyle reasons. In fact, they may be trading off
academic opportunities in high-quality schools that they have found distasteful for
medium-quality charter schools with peer cultures or instructional programs that are
more appealing.

## 8.4 Conclusions

Inthischapter,wehavemadethetransitionfrom“easy”to“hard”instancesofcausal

effect estimation. No longer does simple conditioning onthe observeddeterminants of
the cause or all other direct causes of the outcome allow for identification and consis-
tent estimation of the causal effect of interest. Instead, we have considered examples
in which important variables that might have been used to mount an effective con-
ditioning strategy are unobserved. Thus, selection of the treatment of interest is on
unobserved characteristics of individuals that have unknown but suspected relation-
ships to the outcome. We have also expanded our usage of directed graphs to show
how patterns of self-selection and heterogeneity can be given explicit representations,
andwehavemadetheimplicitcasethatomittedvariableproblemsarebestaddressed,
in the long run, by developing and deploying new measures.

Weturninthenextthreechapterstoapresentationofadditionalmethodstoiden-
tify causaleffects withobservedvariableswhenonecannotmovebeyondthe available
data: instrumental variable estimators in Chapter 9, causal mechanisms in Chapter
10, andpaneldata models that utilize pretreatmentmeasures ofthe outcome variable
inChapter11.Wewillexplainthesestrategiesindetail,discussingtheirstrengthsand
weaknesses along the way.

# Chapter 9

# Instrumental Variable Estimators of Causal Effects

If a perfect stratification cannot be enacted with the available data, and thus neither

matching nor regression nor any other type of basic conditioning technique can be
used to effectively estimate a causal effect of D on Y, one possible solution is to find
anexogenoussourceofvariationthatdeterminesY onlybywayofthe causalvariable
D. The causal effect is then estimated by measuring how Y varies with the portion of
the total variation in D that is attributable to the exogenous variation. The variable
that indexes this variation in D is an instrumental variable (IV).

Inthischapter,weorientthereaderbyfirstpresentingIVestimationwithabinary
instrumentandasimpledemonstration.WethenreturntotheoriginsofIVtechniques,
and we contrast this estimation strategy with the perspective on regression that was
presented in Chapter 6. We then develop the same ideas using the potential outcome
model, showinghow the counterfactualperspective has ledto a new literature onhow
to interpret IV estimates. This new literature suggests that IV techniques are more
effectiveforestimatingnarrowlydefinedlocalaveragecausaleffectsthanforestimating
more general average causal effects, such as the average treatment effect (ATE) and
the average treatment effect for the treated (ATT). We also consider causal graphs
that can represent this recent literature and conclude with a discussion of marginal
treatment effects identified by local IVs.

## 9.1 Causal Effect Estimation with a Binary IV

Webeginourpresentationwiththesimplestscenarioinwhichaninstrumentalvariable

can be used to effectively estimate a causal effect. Recall the causal regression setup
in Equation (6.3):
Y =α+δD+ε, (9.1)
where Y is the outcome variable, D is a binary causal exposure variable, α is an
intercept, δ is the causal effect of D on Y, and ε is a summary random variable
291
Z ε Z ε
D Y D Y
(a) Z is a valid instrumental (b) Z is not a valid instrumental
variable for D variable for D
Figure 9.1 Two graphs in which Z is a potential instrumental variable.

that represents all other causes of Y. As noted above, when Equation (9.1) is used
to represent the causal effect of D on Y, the parameter δ is usually considered an
invariant, structural causal effect that applies to all members of the population of
interest. We will maintain this traditional assumption in this section.1
Suppose that the probability that D is equal to 1 rather than 0 is a function of a
binaryvariableZ thattakesonvaluesof0and1.Figure9.1presentstwopossibleways
in which the variable Z could be related to both D and Y. Note first that, for both
graphs, the back-door paths represented by D(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)ε→Y prevent a least squares
regression of Y on D from generating a consistent or unbiased estimate of the effect
of D on Y. More generally, no conditioning estimator would effectively estimate the
causal effect of D on Y for these graphs because no observed variables satisfy the
back-door criterion.

Now consider how Z, which we have labeled a “potential instrumental variable,”
is related to the outcome variable Y according to the alternative structures of these
two graphs. For both Figures 9.1(a) and 9.1(b), Z has an association with Y because
of the directed path Z →D→Y. In addition, the paths collectively represented by
Z→D(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)ε→Y do not contribute to the association between Z and Y because
D is a collider variable along all of them. However, for Figure 9.1(b), the additional
paths represented by Z(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)ε→Y contribute to the association between Z and Y
because of the common causes that determine both Z and ε.2 This last difference is
thereasonthatZ canbeusedtoestimatethecausaleffectofD onY forFigure9.1(a)
but not for Figure 9.1(b), as we will now explain.

If we continue to maintain the assumption that the effect of D on Y is a constant
structural effect δ, then it is not necessary to relate all of the variation in D to all of
the variation in Y in order to obtain a consistent estimate of the causal effect. Under
this assumption, if we can find a way of isolating the covariation in D and Y that is
causal,thenwecanignorethe othercovariationinD andY thatisnoncausalbecause
it is generated by the common causes of D and ε. For Figure 9.1(a), the variable
Z represents an isolated source of variation across which the analyst can examine
the covariation in D and Y that is causal. In this sense, Z is an “instrument” for
1InPearl’sframework,weareassumingthatf Y(D,e Y)isdefinedasthelinearfunctionα+δD+ε
andwhereαandβ arescalarconstants.

2We have drawn the two bidirected edges separately for Figure 9.1(b) for simplicity. The same
reasoningholdswhensomeofthecommoncauses ofZ andεarealsocauses ofD (andsoon).

examining an isolated slice of the covariation in D and Y. For Figure 9.1(b), Z does
notprovideanisolatedsourceofvariation.Theanalystcanstillexaminetheportionof
the covariationin D and Y that can be calculated across levels of Z, but some of this
covariation must be noncausal because D and Y are dependent on common causes
embedded in the bidirected edge in the back-door paths collectively represented by
D←Z(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)ε→Y.

Toseethisresultwithoutreferencetographs,takethepopulation-levelexpectation
ofEquation(9.1),E[Y]=E[α+δD+ε]=α+δE[D]+E[ε],andrewriteitasadifference
equation in Z:
E[Y|Z=1]−E[Y|Z=0] (9.2)
=δ(E[D|Z=1]−E[D|Z=0])+(E[ε|Z=1]−E[ε|Z=0]).

Equation (9.2) is now focused narrowly on the variation in Y, D, and ε that exists
across levels of Z.3 Now, take Equation (9.2) and divide both sides by E[D|Z =1]
−E[D|Z=0], yielding
E[Y|Z=1]−E[Y|Z=0]
(9.3)
E[D|Z=1]−E[D|Z=0]
δ(E[D|Z=1]−E[D|Z=0])+(E[ε|Z=1]−E[ε|Z=0])
= .

E[D|Z=1]−E[D|Z=0]
If the data are generated by the set of causal relationships depicted in Figure 9.1(a),
then Z has no linear associationwith ε, and E[ε|Z=1]−E[ε|Z=0] in Equation(9.3)
is equal to 0. Consequently, the right-hand side of Equation (9.3) simplifies to δ:
E[Y|Z=1]−E[Y|Z=0]
=δ. (9.4)
E[D|Z=1]−E[D|Z=0]
Under these conditions, the ratio of the population-level linear association between
Y and Z and between D and Z is equal to the causal effect of D on Y. This result
suggests that, if Z is in fact associated with D but not associated with ε (or with
Y, except through D), then the following sample-based estimator will equal δ in an
infinite sample:
δˆ IV,WALD≡ EE NN [[ dyi i| |z zi i= =1 1] ]− −E EN N[ [y di i| |z zi i= =0 0] ]. (9.5)
As suggested by its subscript, this is the IV estimator, which is known as the Wald
estimatorwhentheinstrumentisbinary.AlthoughtheWaldestimatorisconsistentfor
δ in this scenario, the assumption that δ is an invariant structural effect is crucial for
thisresult.4 Fromapotentialoutcomesperspective,inwhichwegenerallyassumethat
3Equation (9.2) is generated in the following way. First, write E[Y]=α+δE[D]+E[ε] con-
ditional on the two values of Z, yielding E[Y|Z =1]=α+δE[D|Z=1]+E[ε|Z=1] and E[Y|
Z=0]=α+δE[D|Z=0]+E[ε|Z=0]. Note that, because α and δ are considered constant struc-
turaleffectsforthistraditionalmotivationofIVestimation,theydonotvarywithZ.Now,subtract
E[Y|Z=0]=α+δE[D|Z=0]+E[ε|Z=0] from E[Y|Z=1]=α+δE[D|Z=1]+E[ε|Z=1]. The
parameterαiseliminatedbythesubtraction,andδcanbefactoredoutofitstwoterms,resultingin
Equation(9.2).

4AsfortheoriginoftheWaldestimator,itiscustomarilytracedtoWald(1940)byauthorssuch
asAngristand Krueger(1999). Aswediscuss later,theWaldestimator isnot generallyunbiasedin
afinitesampleandinsteadisonlyconsistent.

causaleffectsvarymeaningfullyacrossindividuals,thisassumptionisverylimitingand
quite likely unreasonable.Explainingwhenandhow this assumptioncanbe relaxedis
one of the main goals of this chapter.

Forcompleteness,returntoconsiderationofFigure9.1(b),inwhichZ hasanonzero
association with ε. In this case, E[ε|Z=1]−E[ε|Z=0] in Equations (9.2) and (9.3)
cannot be equal to 0, and thus Equation (9.3) does not reduce further to Equation
(9.4). Rather, it reduces only to
E[Y|Z=1]−E[Y|Z=0] E[ε|Z=1]−E[ε|Z=0]
=δ+ . (9.6)
E[D|Z=1]−E[D|Z=0] E[D|Z=1]−E[D|Z=0]
In this case, the ratio of the population-level linear association between Y and Z and
between D and Z does not equal the causal effect of D on Y but rather the causal
effectofD onY plusthelasttermontheright-handsideofEquation(9.6). TheWald
estimator in Equation (9.5) is not consistent for δ in this case. Instead, it converges
to the right-handside of Equation (9.6), which is equal to δ plus a bias term that is a
function of the net association between Z and ε.

More generally, an IV estimator is a ratio that is a joint projection of Y and D
onto a third dimension Z. In this sense, an IV estimator isolates a specific portion of
the covariation in D and Y. For that selected covariation to be the basis of a valid
causal inference for the effect of D on Y, it cannot be attributable to any extraneous
commoncausesthatdeterminebothZ andY.And,tojustifythecausaleffectestimate
generated by a subset of the covariation in D and Y as a consistent estimate of the
population-level causal effect of D on Y, it is typically assumed in this tradition that
δ isaconstantforallmembersofthepopulation.5 Considerthefollowinghypothetical
demonstration, which is based on the school voucher example introduced in Section
1.3.2 (see page 23).

IV Demonstration 1
Suppose that a state education department wishes to determine whether private high
schools outperform public high schools in a given metropolitan area, as measured by
the achievement of ninth graders on a standardized test. For context, suppose that
a school voucher program is operating in the city and that the state is considering
whether to introduce the program in other areas in order to shift students out of
public schools and into private schools.

To answer this policy question, the state department of education uses a census
of the population in the metropolitan area to select a random sample of 10,000 ninth
graders.Theythengiveastandardizedtesttoeachsampledninthgraderattheendof
theyear,andtheycollectdataas{yi,di}1 i=0, 1000,whereY isthescoreonthestandardized
5Thereisonetrivialwayaroundthisassumption.IfthenaiveestimatorofDonY isconsistentfor
theaveragecausaleffect ofD onY,thenD isitsownIV.ThesubsetofthecovariationinD andY
thatisprojectedontoZ isthenthefullsetofcovariationinDandY becauseZ isequaltoD.Inthis
case,noextrapolationisneededandtheconstanttreatmenteffectassumptioncanbeavoided.Aswe
willdiscusslater,thereareslightlylesstrivialwaystoavoidtheassumptionaswell.Onealternative
is to assert that δ is a constant among the treated and then stipulate instead that the IV identifies
only the ATT. Although plausible, there arebetter ways to handle heterogeneity, as we willdiscuss
asthischapter unfolds.

Table 9.1 The Distribution of Voucher Winners by
School Sector for IV Demonstration 1
Public school Private school
d i=0 d i=1
Voucherloser z i=0 8000 1000
Voucherwinner z i=1 800 200
test and D is equal to 1 for students who attend private high schools and equal to 0
for students who attend public high schools.

After the data are collected, suppose that the values of yi are regressed on the
values of di and that a predicted regressionsurface is obtained:
Yˆ =50.0+9.67(D). (9.7)
The state officials recognize that private school students typically have more highly
educated parents and therefore are more likely to have higher test scores no matter
what curriculum and school culture they have been exposed to. Accordingly, they
surmise that 9.67 is likely a poor causal effect estimate, or at least not one that they
would want to defend in public as equal to the ATE.

The state officials therefore decide to merge the data with administrative records
onthe school voucherprogramin the area. For this program,all eighthgradersin the
city (both in public and private schools) are entered into a random lottery for $3,000
schoolvouchersthat are redeemable at a private highschool. By mandate, 10 percent
of all eligible students win the voucher lottery.

After merging the data, the state officials cross-tabulate eighth grade lottery win-
ners (where zi=1 for those who won the lottery and zi=0 for those who did not)
by school sector attendance in the ninth grade, di. As shown in Table 9.1, 1,000 of
the 10,000 sampled students were voucher lottery winners.6 Of these 1,000 students,
200 were observed in private schools in the ninth grade. In comparison, of the 9,000
sampled students who were not voucher lottery winners, only 1,000 were observed in
private schools.

TheresearchersassumethatthedummyvariableZ forwinningthevoucherlottery
isavalidIVforDbecausetheybelievethat(1)therandomizationofthelotteryrenders
Z independent of ε in the population-level causal regression equation Y =α+δD+ε
and that (2) Z has a causal effect on Y only through Z.. They therefore estimate
δˆ IV,WALD in Equation (9.5) as
EN[yi|zi=1]−EN[yi|zi=0] 51.600−51.111
= =5.5, (9.8)
EN[di|zi=1]−EN[di|zi=0] .200−.111
and conclude that the true causal effect of private schooling on ninth grade achieve-
ment is 5.5 rather than 9.67. Operationally, the Wald estimator takes the average
6Forsimplicity,wehaveassumedthatthesamplepercentageoflotterywinnersisthesameasthe
populationpercentage. Ofcourse,somerandomvariationwouldbeexpected inanysample.

difference in test scoresamongthose students who havewona voucherandthose who
have not won a voucher and divides that difference by a corresponding difference in
the proportion of high school students who attend private schools among those who
have won a voucher and the proportion of high school students who attend private
schools among those who have not won a voucher. The numerator of Equation (9.8)
is equal to 51.600−51.111 by an assumed construction of the outcome Y, which we
will present later when we repeat this demonstration in more detail in Section 9.3.1
(as IV Demonstration 2, beginning on page 309). The denominator, however, can be
calculated directly from Table 9.1. In particular, EN[di=1|zi=1]=200/1000=.200,
whereas EN[di=1|zi=0]=1000/9000=.111.

For this demonstration, Z is a valid instrument by the traditional assumptions
maintained in this section of the chapter; it is randomly assigned to students and has
no association with Y except for the one produced by the directed path Z→D→Y.

The resulting estimator yields a point estimate that can be given a traditional causal
interpretation based on the position that the casual effect of interest is a constant
structural effect. However, as we will show later in this chapter when we reintroduce
this demonstration as IV Demonstration 2, the particular causal effect that this IV
identifiesisquiteabitdifferentwhenindividual-levelcausaleffectheterogeneityisnot
assumed away. The IV does not identify the ATE or the ATT. Instead, it identifies
onlytheaveragecausaleffectforthesubsetofallstudentswhowouldattendaprivate
school if given a voucher but who would not attend a private school in the absence
of a voucher. This means, for example, that the IV estimate is uninformative about
the average causal effect among those who would enroll in private high schools in the
absence of a voucher. This group of students represents the vast majority of private
school students (in this example 1,000/1,200 or 83 percent). The potential outcome
literature has provided the insight that allows such a precise causal interpretation
and clarifies what a valid IV estimate does not inform. Before presenting that newer
material, we return to a more complete accounting of the traditional IV literature.

## 9.2 Traditional IV Estimators

As detailed by Goldberger (1972), Bowden and Turkington (1984), Heckman (2000),

and Bollen (2012), IV estimators were developed first in the 1920s by biologists and
economists analyzing equilibrium price determination in market exchange (see E.

Working 1927; H. Working 1925; and Wright 1921, 1925). After subsequent devel-
opment in the 1930s and 1940s (e.g., Wright 1934; Schultz 1938; Reiersl 1941; and
Haavelmo 1943), IV estimators were brought into widespread use in economics by
researchers associated with the Cowles commission (see Hood and Koopmans 1953;
Koopmans and Reiersl 1950).7 The structural equation tradition in sociology shares
7The canonical example for this early development was the estimation of price determination in
markets.Foramarketinequilibrium,onlyonepriceandonequantity ofgoodssoldisobservableat
any point intime. To makeprospective predictions about the potential effects of exogenous supply-
and-demandshocksonpricesandquantitiesforanewmarketequilibrium,theshapeoflatentsupply-
and-demand curves must be determined. To estimate points on such curves, separate variables are
similaroriginstothatoftheIVliterature(seeDuncan1975).Themostfamiliardeploy-
ment of IV estimation in the extant sociologicalresearch is as the order condition for
identificationofasystemofstructuralequations(seeBollen1989,1995,1996a,1996b,
2001,2012; Fox 1984).

9.2.1 The Linear Structural Equation IV Estimator
Consider the same basic ideas presented earlier for the Wald estimator in Equation
(9.5). Again, recall the causal regressionsetup in Equation (9.1):
Y =α+δD+ε, (9.9)
andagainassumethatweareinthetraditionalsetupwhereδisaninvariant,structural
causal effect that applies to all members of the population of interest. The ordinary
least squares (OLS) estimator of the regressioncoefficient on D is
OLS,bivariate≡CovN(yi,di)
δˆ , (9.10)
VarN(di)
where CovN(.) and VarN(.) denote unbiased, sample-based estimates from a sample
of size N of the population-level covariance and variance.

Now, again suppose that the back-door association between D and ε renders the
leastsquaresestimatorbiasedandinconsistentfor δ inEquation(9.9).Ifleastsquares
cannotbeusedtoeffectivelyestimateδ,analternativeIVestimatorcanbeattempted,
with an IV Z, as in
CovN(yi,zi)
δˆ ≡ , (9.11)
IV
CovN(di,zi)
where Z can now take on more than two values. If the instrument Z is linearly asso-
ciated with D but unassociated with ε, then the IV estimator in Equation (9.11) is
consistent for δ in Equation (9.9).8
One way to see why IV estimators yield consistent estimates is to again consider
the population-level relationships between Y, D, and Z, as in Equations (9.1)–(9.4).

ManipulatingEquation(9.1)asbefore,thecovariancebetweentheoutcomeY andthe
instrument Z can be written as
Cov(Y,Z)=δCov(D,Z)+Cov(ε,Z), (9.12)
againassumingthatδisaconstantstructuraleffect.DividingbyCov(D,Z)thenyields
Cov(Y,Z) δCov(D,Z)+Cov(ε,Z)
= , (9.13)
Cov(D,Z) Cov(D,Z)
needed that uniquely index separate supply-and-demand shocks. Usually based on data from a set
of exchangeable markets or alternative well-chosen equilibria for the same market from past time
periods, these IVs are then used to identify different points of intersection between a shifted linear
supply/demandcurveandafixedlineardemand/supplycurve.

8Notice that substituting d i for z i in Equation (9.11) results in the least squares regression esti-
mator in Equation (9.10). Thus, the least squares regression estimator implicitly treats D as an
instrumentforitself.

W
Z V ε Z
ε∗
D Y D Y
(a) Z is a valid surrogate (b) Z is a valid conditional
instrumental variable instrumental variable
Figure9.2 Two graphs in which Z is a valid IV.

which is directly analogous to Equation (9.3). When Cov(ε,Z) is equal to 0 in the
population, then the right-hand side of Equation (9.13) simplifies to δ. This suggests
that
CovN(yi,zi) −p
→δ (9.14)
CovN(di,zi)
if Cov(ε,Z)=0 in the population and if Cov(D,Z)(cid:6)=0. This would be the case for
the causal diagram in Figure 9.1(a). But here the claim is more general and holds for
cases in which Z is many-valued (and, in fact, for cases in which D is many-valued
as well, assuming that the linear, constant-coefficient specification in Equation (9.9)
is appropriate).

Our priorgraphicalpresentationwas alsomore restricted thanit needed to be. As
we discussedabove,if Z is relatedto D andY as in Figure9.1(a),then IV estimation
with Z is feasible.9 Figure 9.2(a) presents another graph in which Z can be used as
a valid instrumental variable for the effect of D on Y. In this case, the instrument V
is unobserved. What we have instead is a surrogate instrumental variable, Z, which
is not a direct cause of D but which has an association with D because both Z and
D mutually depend on the unobserved instrument V. A complication, which we will
discussbelow,isthatthe associationbetweenZ andD maybeveryweakinthiscase,
creating a particular set of statistical problems.10
Figure9.2(b)representsperhapsthemostcommonsetupinthetraditionalapplied
literature. In this case, Z is not a “clean” instrument that has no association with
Y other than the association that is generated by a directed path that begins at the
instrument and ends at the outcome. Nonetheless, all of the additional associations
between Z and Y are generated by back-door paths from the instrument Z to the
outcome Y that can be blocked by simultaneous conditioning on observed variables,
such as W in Figure 9.2(b). In this case, Z is sometimes referred to as a conditional
9TheonlydifferenceinthissectionisthatwearenowallowingZtotakeonmorethantwovalues.

Because of this relaxation, in order for the graph to be compatible with the traditional setup, we
needtomakethefurtherassumptionthatZ hasalinearcausaleffectonD,whichneithervariesover
individualsnorinanypiecewisefashionacrossthelevelsofZ.

10As elsewhereup until this point inthe chapter, inorder to stay withinthe traditional setup we
must now assume that linearity holds throughout, so that the effect of V on Z generates a linear
relationshipbetweenZ andD.

instrumentalvariable,andestimationmustproceedwithaconditionalversionofEqua-
tion (9.11), usually the two-stage least squares estimator that we will discuss below.

Consider the following examples of IV estimation from the applied literature.

9.2.2 Examples of IV Estimation
Amongsocialscientists,demographic,andhealthresearchers,economistsarethemost
prone to the adoption of IV estimation.11 Consider the causal effect of education on
labor market earnings, as introduced earlier in Section 1.3.1 and as used as a focal
example inpriorchapters.As reviewedinpieces suchas Card(1999)andAngristand
Krueger(2001),thecausaleffectofyearsofschoolingonsubsequentearningshasbeen
estimated with a variety of IVs, including proximity to college, regionaland temporal
variation in school construction, tuition at local colleges, temporal variation in the
minimumschool-leavingage,andquarterofbirth.Theargumentintheseapplications
is that the IVs predict educational attainment but have no direct effects on earnings.

For the quarter-of-birth instrument, which is one of the most widely discussed IVs in
the literature, Angrist and Krueger (1991:981–82)reason:
If the fraction of students who desire to leave school before they reachthe
legaldropoutageisconstantacrossbirthdays,astudent’s birthday should
be expected to influence his or her ultimate educational attainment. This
relationship would be expected because, in the absence of rolling admis-
sions to school, students born in different months of the year start school
atdifferentages.Thisfact,inconjunctionwithcompulsoryschoolinglaws,
which require students to attend school until they reach a specified birth-
day,producesacorrelationbetweendateofbirthandyearsofschooling....

Students who are born early in the calendar year are typically older when
they enter school than children born late in the year.... Hence, if a fixed
fractionofstudentsisconstrainedbythecompulsoryattendancelaw,those
borninthe beginning ofthe yearwill haveless schooling,onaverage,than
those born near the end of the year.

The results of Angrist and Krueger (1991) were sufficiently persuasive that many
additionalresearchershavesincebeenconvincedtouserelatedIVs.Braakmann(2011),
for example, uses an IV based on month of birth to estimate the effect of education
on health-related behaviors. Other researchers have used IVs that index over-time
variation in compulsory schooling laws, such as Oreopoulos (2006) for the effect of
education on earnings, Machin, Marie, and Vuji (2011) for the effect of education
on crime, and Kemptner, Ju¨rges, and Reinhold (2011) for the effect of education on
health.12
11Some of the examples we introduce inthis section adopt the traditional setup presented above,
wherein the causal effect of interest is a structural constant. Many of the more recent examples
adoptthealternativesetupthatwewillintroducelaterinthechapter,whereitisassumedasafirst
principlethattreatmenteffectsvaryattheindividuallevel.Fornow,weoffertheseexamplesonlyto
demonstratethetypical identifyingassumptionspresentedinFigures9.1(a)and9.2.

12And,inturn,eachoftheseeffectshasbeenmodeledwithalternativeIVs.Forexample,inthecase
ofhealthandhealthbehaviors,Lindahl(2005)usedlotterywinningsasanIVfortheeffectofincome
For another example, consider the literature on the effects of military service on
subsequentlabormarketoutcomes,atopicthatbotheconomistsandsociologistshave
studied for several decades. Some have argued that military service can serve as an
effective quasi-job-training program for young men likely to otherwise experience low
earnings because of weak attachment to more traditional forms of education (Brown-
ing,Lopreato,andPoston1973)orasamoregeneralproductivitysignalthatgenerates
a veteran premium (De Tray 1982). In one of the earliest studies, which focused pri-
marily on veterans who served around the time of the Korean War, Cutright (1974)
concluded that
two yearsin the military environment,coupledwith the extensive benefits
awardedtoveterans,donot resultinaclearcut,largenetpositiveeffectof
service....Therefore,onemayquestionthelikelyutilityofsocialprograms
that offer minority men and whites likely to have low earnings a career
contingencyinabridgingenvironmentsimilartothatprovidedbymilitary
service. (Cutright 1974:326)
Followingthe warin Vietnam,attention thenfocused onwhether any military service
premium had declined (see Rosen and Taubman 1982; Schwartz 1986; see also Berger
and Hirsch 1983).Angrist (1990)used the randomization created by the Vietnam-era
draft lottery to estimate the veteran effect. Here, the draft lottery turns date of birth
into an IV, in much the same way that compulsory school entry and school-leaving
laws turn date of birth into an IV for years of education. Angrist determined that
veteranstatushadanegativeeffect onearnings,whichhe attributedto a lossoflabor
market experience.13
The quarter-of-birth and draft-lottery IVs are widely discussed because they are
determined by processes that are very unlikely to be structured by any of the unob-
served determinants of the outcome of interest. Many IVs in the economics literature
do not have this feature. As discussed in Section 1.3.2, much of the early debate on
the effectiveness of private schooling relative to its alternatives was carried out with
observational survey data on high school students from national samples of public
and Catholic high schools. In attempts to resolve the concerns over selection bias,
EvansandSchwab(1995),Hoxby(1996),andNeal(1997)introducedplausibleIVsfor
onhealthand mortality,whileCawley, Moran,and Simon(2010) usedanover-timediscontinuity in
SocialSecuritybenefits asanIVfortheeffect ofincomeontheobesityoftheelderly.

13We do not mean to imply that Angrist’s work on this issue ended in 1990. Not only was his
work very important for understanding what IV estimators accomplish in the presence of causal
effect heterogeneity (see next section), but he also continued with subsequent substantive work on
the military service effect. Angrist and Krueger (1994) estimated the World War II veteran effect,
and, in an attempt to reconcile past estimates, concluded: “Empirical results using the 1960, 1970,
and 1980 censuses support a conclusion that World War II veterans earn no more than comparable
nonveterans, and may well earn less. These findings suggest that the answer to the question ‘Why
do World War II veterans earn more than nonveterans?’ appears to be that World War II veterans
wouldhaveearnedmorethannonveteransevenhadtheynotservedinthemilitary.Militaryservice,
in fact, may have reduced World War II veterans’ earnings from what they otherwise would have
been” (Angristand Krueger 1994:92). Then, Angrist(1998) assessedthe effects of voluntary service
inthemilitaryinthe1980s, andhefoundmixedevidence. InAngristandChen(2011), herevisited
the Vietnam-era veteran effect, analyzing 2000 census data, arguing that the effect on education is
positivebecauseoftheGIbillbutisnonetheless closetozeroforearnings.

Catholic school attendance. Hoxby and Neal argued that the share of the local popu-
lation that is Catholic is a valid IV for Catholic school attendance, maintaining that
exogenous differences in population composition influence the likelihood of attending
aCatholicschool(byloweringthecostsofopeningsuchschools,whichthenlowersthe
tuitionthat schoolsneedto chargeandto whichparentsrespondwhenmaking school
sector selection decisions). Variation in the number of Catholics in each county was
attributedtolaggedeffectsfrompastimmigrationpatternsandwasthereforeassumed
to have no direct effect on learning.14
These examples of IV estimation in economics are but the tip of an iceberg of
applications.SomeeconomistshavearguedthattheattentiongiventoIVestimationin
theappliedliteratureinthepasttwodecadeshasbeenexcessive,andathrivingdebate
is now under way on the future direction of observational research in economics, as
revealedby a comparisonof AngristandPischke(2010)andImbens (2010)to Deaton
(2010), Heckman and Urzua (2010), and Leamer (2010). We will discuss this debate
at several points in this chapter and the next.

Moving beyond researchin economics, examples of IV estimation follow more var-
ied patterns. For political science, Dunning (2012), Sekhon and Titiunik (2012), and
Soveyand Green(2011)review the growing list of applications that draw on “natural
experiments,” some of which are instrumental variable designs. In sociology, Bollen
(2012) shows that IV estimation is uncommon but still utilized in models with a
structuralequationsfoundation.15 Finally,epidemiologistsandhealthresearchershave
notutilized instrumental variableswith substantial frequency, to some extentheeding
the warning of Hern´an and Robins (2006b:364) about the “risk [of] transforming the
methodologicdreamofavoidingunmeasuredconfoundingintoanightmareofconflict-
ing biased estimates.”
9.2.3 The IV Identifying Assumption Cannot Be Tested
The basic identification assumption underlying all of the studies just summarized –
that Z has no net association with Y except for the one generated by the directed
path Z→D→Y – is a strong and untestable assumption. Some researchers believe
mistakenlythatthisassumptionisempiricallytestable.Inparticular,theybelievethat
the assumption that Z has no direct effect on Y implies that there is no association
14Evans and Schwab (1995) used a student’s religiousidentification as an IV. This IV has proven
toberatherunconvincingtomanyscholars(seeAltonji,Elder,andTaber2005a,2005b)becausethe
assumedexclusionrestrictionappearsunreasonable.Neal(1997)alsousedthisIVbutonlyselectively
inhisanalysis.

15As noted, IV estimation is an inherent part of structural equation modeling because point esti-
matesofcoefficients arenotinfrequentlygenerated byIV-basedorderidentification inthistradition
of analysis. For example, Messner, Baumer, and Rosenfeld (2004) estimate a two-equation model,
with communities as the unit of analysis, where (1) the effect of community-level social trust on
the homicide rate is identified by an instrument for community-level subjective alienation and (2)
the effect of community-level social activism on the homicide rate is identified by instruments for
thecommunity-levelaverageamountoftelevisionwatchedandextremepoliticalattitudes.Thistype
ofapplicationreliesquiteheavilyonthe theoretical rationaleforinstrumentselection, moresothan
for the “natural experiment” instruments prized in economics where the prima facie case for the
independence oftheinstrumentZ fromcauses ofY other thanD isstronger.

Z
U
D Y
Figure 9.3 A graph with an unblocked back-door path and a valid IV.

betweenZ andY conditionalonD.Thus,ifanassociationbetweenZandY isdetected
after conditioning on D, then the assumption must be incorrect.

Causal graphs show clearly why individuals might believe that the identifying
assumption can be tested in this way and also why it cannot. Consider the sim-
plest possible causal graph, presented in Figure 9.3, in which (1) an unblocked back-
door path between D and Y exists because of the unobserved common cause U, but
(2) Z is a valid IV that identifies the causal effect of D on Y.16 Here, the instrument
Z is valid because it causes D, has no causaleffect on Yother than through D, and is
unconditionally unassociated with U.

Whyisthesuggestedtestfaulty?Again,therationaleforthetestisthatcondition-
ingonDwillblocktheindirectrelationshipbetweenZ andY throughD.Accordingly,
if the only associationbetween Z andY is indirect throughD, then it is thoughtthat
thereshouldbenoassociationbetweenZ andY afterconditioningonD.Ifsuchanet
associationisdetected,thenitmayseemreasonabletoconcludethattheIVidentifying
assumption must be false.

Although this rationale feels convincing, it is incorrect. It is certainly true that
if the IV assumption is invalid, then Z and Y will be associated after conditioning
on D. But the converse is not true. In fact, Z and Y will always be associated after
conditioning on D when the IV assumption is valid. The explanation follows from
the fact that D in Figure 9.3 is a collider that is mutually caused by both Z and
U. As discussed extensively in this book, conditioning on a collider variable creates
dependencebetweenthevariablesthatcauseit.Accordingly,conditioningonDinthis
graphcreatesdependencebetweenZ andU,eventhoughtheIVidentifyingassumption
isvalid.And,asaresult,Z andY willalwaysbeassociatedwithinatleastonestratum
of D even if the IV is valid. The faulty test yields an association between Z and Y
whenconditioningonDregardlessofwhethertheIVidentifyingassumptionisvalid.17
16Forourpurposeshere,thisgraphisisomorphicwithFigure9.1(a).Wehavereplacedthebidirected
edgefromDtoεbyrepresentingtheassociationbetweenDandεasasingleback-doorpathbetween
D and Y generated by an unobserved common cause U. We have then eliminated the remainder of
thedistributionofεfromthegraphbecauseitisunconditionallyunassociatedwithZ andD(andis,
inPearl’sframework,nowtheusualerrorterme Y thatcomesintoviewonlyundermagnification).

17Forcompleteness,considerwhatthefaultytestrevealswhentheIVassumptionisinvalid.Suppose
that Figure 9.3 is augmented by an unobserved cause E and then two edges E→Z and E→U. In
this case, Z and Y would be associated within levels of D for two reasons: (1) conditioning on the
collider D generates a net association between Z and U (and hence Z and Y) and (2) the common
causeE ofZ andU generates anunconditional associationbetween Z andY.

9.2.4 Recognized Pitfalls of Traditional IV Estimation
The traditionalIVliteraturesuggeststhat, aslongas there isaninstrumentthat pre-
dicts the causal variable of interest but is linearly unrelated to the outcome variable
except by way of the causal variable, then an IV estimator will effectively estimate
the causal effect. Even within this traditional setup, however, there are some recog-
nized pitfalls of an IV estimation strategy. First, the assumption that an IV does not
have a net direct effect on the outcome variable is often hard to defend. Second, even
when an IV does not have a net direct effect on the outcome variable, IV estimators
are biased in finite samples. Moreover, this bias can be substantial when an instru-
ment only weakly predicts the causal variable. We discuss each of these weaknesses
here.

Even “natural experiments” that generate compelling IVs are not immune from
criticism.Consider date of birth as an instrument for veteranstatus in estimating the
effect of military service in Vietnam on subsequent earnings (Angrist 1990). The case
forexcludingdateofbirthfromtheearningsequationthatistheprimaryinterestofthe
study is the randomization of the draft lottery, in which draft numbers were assigned
at random to different dates of birth. Even though a type of randomization generates
the IV, this does not necessarily imply that date of birth has no net direct effect on
earnings.Aftertherandomizationoccursandthelotteryoutcomesareknown,employ-
ers may behave differently with respect to individuals with different lottery numbers,
investing more heavily in individuals who are less likely to be drafted. As a result,
lottery number may be a direct, though probably weak, determinant of future earn-
ings (see Heckman 1997; Moffitt 1996). IVs that are not generated by randomization
are even more susceptible to causal narrativesthat challenge the assumption that the
purported IV does not have a net direct effect on the outcome of interest.

Even in the absence of this complication, there are well-recognized statistical pit-
falls.Byusingonlyaportionofthecovariationinthecausalvariableandtheoutcome
variable, IV estimators use only a portion of the information in the data. This repre-
sents a direct loss in statistical power, and as a result IV estimators tend to exhibit
substantiallymoreexpectedsamplingvariancethanotherestimators.Bythecriterion
of mean-squared error, a consistent and asymptotically unbiased IV estimator can be
outperformed by a biased and inconsistent regressionestimator.

The problem canbe especially acute in some cases. It has been shownthat instru-
ments that only weakly predict the causal variable of interest should be avoided
entirely, even if they generate point estimates with acceptably small estimated stan-
dard errors (see Bound, Jaeger, and Baker 1995). In brief, the argument here is four-
fold: (1)in finite samples,IVpointestimates canalwaysbe computedbecausesample
covariances are never exactly equal to zero; (2) as a result, an IV point estimate can
be computed even for an instrument that is invalid because it does not predict the
endogenous variable in the population (i.e., even if Cov(D,Z)=0 in the population,
renderingEquation(9.13) undefinedbecause its denominatoris equalto 0); (3)atthe
sametime,the formulasforcalculatingthestandarderrorsofIVestimatesfailinsuch
situations, giving artificially small standard errors (when in fact the true standard
error for the undefined parameter is infinity); and (4) the bias imparted by a small
violation of the assumption that the IV affects the outcome variable only by way of
the causal variable can explode if the instrument is weak.18 To see this last result,
consider Equation (9.6), which depicts the expected bias in the Wald estimator for a
binary IV as the term
E[ε|Z=1]−E[ε|Z=0]
. (9.15)
E[D|Z=1]−E[D|Z=0]
When the identifying assumption is violated, the numerator of Equation (9.15) is
nonzero because Z is associated with Y through ε. The bias is then an inverse func-
tion of the strength of the instrument; the weaker the instrument, the smaller the
denominator and the larger the bias. If the denominator is close to zero, even a tiny
violationoftheidentifyingassumptioncangeneratealargeamountofbias.And,unfor-
tunately,thisrelationshipisindependentofthesamplesize.Thus,eventhoughaweak
instrumentmay suggesta reasonable(or perhaps evenintriguing)pointestimate, and
one with an acceptably small estimated standard error, the IV estimate may contain
no genuine information whatsoever about the true causal effect of interest (see Hahn
and Hausman 2003; Small and Rosenbaum 2008; Staiger and Stock 1997; Wooldridge
2010).19
Beyond these widely recognized pitfalls of standard IV estimation in economics, a
third criticism is emerging of current practice, especially in economics. As explained
by Angrist and Krueger (2001) and Angrist and Pischke (2009, 2010), the ways in
which IVs are used has changed in the past 40 years. Because it has been hard to
achieve consensus that particular no-net-direct-effect assumptions are credible, IVs
thatarisefromnaturallyoccurringvariationhavebecomemorepopular.Genuine“gifts
of nature,” such as variationin the weather and natural boundaries, have become the
most prized sources of IVs (see Dunning 2012 and Rosenzweig and Wolpin 2000 for
lists of such instruments).

NotalleconomistsseethisshiftinIVestimationtechniquestowardnaturallyoccur-
ring IVs as necessarily a step in the right direction. Rosenzweig and Wolpin (2000)
offerone ofthe mostcogentcritiques (butsee alsoDeaton2010;Heckman2000,2005;
Heckman and Urzua 2010). Rosenzweig and Wolpin make three main points. First,
the variation on which naturally occurring IVs capitalize is often poorly explained
and/or does not reflect the variation that maintained theories posit should be impor-
tant. As a result, IV estimates from natural experiments have a black-box character
that lessens their appeal as informative estimates for the development of theory or
policyguidance.Second,the randomvariationcreatedbyanaturallyoccurringexper-
iment does not necessarily ensure that an IV has no net direct effect on the outcome.

OthercausesoftheoutcomecanrespondtothenaturaleventthatgeneratestheIVas
well. Third, naturally occurring IVs typically do not estimate structural parameters
18Complications(1), (2), (3),and(4)areallcloselyrelated. Situation(4)canbeconsideredaless
extremeversionofthethree-partpredicamentdepicted in(1)–(3).

19TherearenoclearguidelinesonhowlargeanassociationbetweenanIVandatreatmentvariable
must be before analysis can proceed safely. Most everyone agrees that an IV is too weak if it does
notyieldateststatisticthatrejectsanullhypotheses ofnoassociationbetween Z andD.However,
amainpointofthisliteratureisthattheconverseisnottrue.Ifadatasetislargeenough,thesmall
associationbetweenZ andDgeneratedbyaweakIVcanstillyieldateststatisticthatrejectsanull
hypotheses ofnoassociation. Evenso,theproblemsinthemaintextarenotvitiated, especiallythe
explosionofthebiasgeneratedbyasmallviolationoftheidentifyingassumption.

of fundamental interest, which can and should be defined in advance of estimation
basedoncriteriaotherthanwhether anaturallyoccurringIVisavailable.Rosenzweig
and Wolpin contend that natural experiments tend to lead analysts to ignore these
issues because natural experiments appear falsely infallible. Reflecting on the same
setof issues, Deaton (2010:432)writes, “The generallessonis once againthe ultimate
futility of trying to avoid thinking about how and why things work.”
Wewillexplainthesepointsfurtherinthischapter,afterintroducingIVestimation
in the presence of causal effect heterogeneity. (We will also then revisit this critique
in the next chapter on mechanisms.) The new IV literature, to be discussed next,
addresses complications of the constant coefficient assumption implied by the stipu-
lated constant value of δ in Equations (9.1) and (9.9). The issues are similar to those
presentedfor regressionestimatorsinChapter6,inthatheterogeneityinvalidatestra-
ditional causal inference from IV estimates. But IV estimators do identify specific
narrowslices of averagecausal effects that may be of distinct interest, and as a result
they represent a narrowly targeted estimation strategy with considerable appeal.

## 9.3 Instrumental Variable Estimators in the Presence of Individual-Level Heterogeneity

Following the adoption of a counterfactual perspective, a group of econometricians

and statisticians has clarified what IVs identify when individual-level causal effects
are heterogeneous. In this section, we will emphasize the work that has developed the
connections between traditional IV estimators and potential-outcome-defined treat-
ment effects (Angrist and Imbens 1995; Angrist, Imbens, and Rubin 1996; Imbens
and Angrist 1994; Imbens and Rubin 1997). The key innovation here is the defini-
tion of a new treatment effect parameter: the local average treatment effect (LATE).

We will also discuss other important work that has further clarified these issues, and
some of this literature is more general than the LATE literature that we introduce
first(seeHeckman1996,1997,2000,2010;Heckman,Tobias,andVytlacil2003;Heck-
man,Urzua,andVytlacil2006;HeckmanandVytlacil1999,2000,2005;Manski2003;
Vytlacil 2002).20
9.3.1 IV Estimation as LATE Estimation
Consider the following motivation of the Wald estimator in Equation (9.5), and recall
the definition of Y presented in Equation (4.5):
Y =Y0+(Y1−Y0)D (9.16)
=Y0+δD
=μ0+δD+υ0,
20Giventhe rapidityof these developments inthe IV literature, somedisagreement on the origins
oftheseideaspervadestheliterature.HeckmanandRobb(1985,1986)didprovideextensiveanalysis
of what IV estimators identify in the presence of heterogeneity. Subsequent work by others, as we
discussinthissection,hasclarifiedandextendedtheseideas,evenwhileHeckmanandhiscolleagues
continuedtorefinetheirideas.

whereμ0≡E[Y0]andυ0≡Y0−E[Y0].NotethatδisnowdefinedasY1−Y0,unlikeits
structural representationin Equations (9.1) and (9.9) where δ was implicitly assumed
to be constant across all individuals.

TounderstandwhenanIVestimatorcanbeinterpretedasanaveragecausaleffect
estimator, Imbens and Angrist (1994) developed a framework to classify individuals
intothosewhorespondpositivelytoaninstrument,thosewhoremainunaffectedbyan
instrument,andthosewhorebelagainstaninstrument.Theirinnovationwastodefine
potentialtreatment assignmentvariables,DZ=z,for eachstate z ofthe instrument Z.

When D and Z are binary variables, there are four possible groups of individuals in
the population.21 These can be summarized by a four-category latent variable C for
compliance status:
DZ=0=0 DZ=1=1,
Compliers (C=c): and
DZ=0=1 DZ=1=0,
Defiers (C=d): and
DZ=0=1 DZ=1=1,
Always takers (C=a): and
DZ=0=0 DZ=1=0.

Never takers (C=n): and
Consider the private schooling example presented earlier in IV Demonstration 1 (see
page 294). Students who would enroll in private schools only if offered the voucher
are compliers (C=c). Students who would enroll in private schools only if not offered
the voucher are defiers (C=d). Students who would always enroll in private schools,
regardless of whether they are offered the voucher, are always takers (C=a). And,
finally, students who would never enroll in private schools are never takers (C=n).

Analogous to the definition of the observed outcome, Y, the observed treatment
indicator variable D can then be defined as
D=DZ=0+(DZ=1−DZ=0)Z
(9.17)
=DZ=0+κZ,
where κ≡DZ=1−DZ=0.22 The parameterκ in Equation(9.17) is the individual-level
causal effect of the instrument on D, and it varies across individuals if DZ=1−DZ=0
varies across individuals (i.e., if observed treatment status varies as the instrument is
switched from “off” to “on” for each individual). If the instrument represents encour-
agement to take the treatment, such as the randomly assigned school voucher in IV
Demonstration1,then κ canbe interpretedasthe individual-levelcomplianceinduce-
ment effect of the instrument. Accordingly,κ=1 for compliers and κ=−1 for defiers.

For always takers and never takers, κ=0 because none of these individuals respond
to the instrument.

21ThesefourgroupsareconsideredprincipalstrataintheframeworkofFrangakisandRubin(2002).

22Note alsothat D has now been counterfactually defined with referenceto DZ. Accordingly, the
definitionofY inEquation(9.16)isconditionalonthedefinitionofDinEquation(9.17).Furthermore,
althoughthereislittlebenefitindoingso,itbearsnotingthatthisdefinitionofDcouldbestructured
analogouslytothedefinitionofY inEquation(9.16)sothatthelastlinewouldbecomeD=ζ+κZ+ι,
whereζ≡E[DZ=0]andι≡DZ=0−E[DZ=0].Theparameterζwouldthenbetheexpectedprobability
ofbeinginthetreatmentifallindividualswereassignedtothestate“instrumentswitchedoff,”and
ιwouldbetheindividual-leveldeparturefromthisexpectedvalue,takingonvalues1−E[DZ=0]and
−E[DZ=0]tobalancetheright-handsideofEquation(9.17)sothatD isequal toeither1or0.

Giventhesedefinitionsofpotentialoutcomevariablesandpotentialtreatmentvari-
ables,a valid instrument Z for the causaleffect of D on Y must satisfy three assump-
tions in order to identify a LATE:
Independence assumption: (Y1,Y0,DZ=1,DZ=0) ⊥⊥ Z, (9.18)
Nonzero effect of instrument assumption: κ(cid:6)=0 for all i, (9.19)
Monotonicity assumption: either κ≥0 for all i or κ≤0 for all i. (9.20)
The independence assumptionin Equation(9.18) is analogousto the assumptionthat
Cov(Z,ε)=0 in the traditional IV literature; see the earlier discussion of Equation
(9.13).23 It stipulates that the instrument must be independent of the potential out-
comes and potential treatments. Knowing the value of the instrument for individual i
mustnotyieldanyinformationaboutthepotentialoutcomeofindividualiundereither
treatmentstate.Moreover,knowingtherealizedvalueoftheinstrumentforindividual
imustnotyieldanyinformationabouttheprobabilityofbeinginthetreatmentunder
alternative hypothetical values of the instrument. This latter point may well appear
confusing, but it is exactly analogous to the independence assumption of potential
outcomesfromobservedtreatmentstatus,discussedearlierforEquation(2.6).Avalid
instrument predicts observed treatment status (D), but it does not predict potential
treatment status (DZ=z).

The assumptions in Equations (9.19) and (9.20) are assumptions about individual
responsesto shifts in the instrument. The assumptionofa nonzero effect ofZ on D is
astipulationthatthe instrumentmustpredicttreatmentassignmentforatleastsome
individuals. There must be at least some compliers or some defiers in the population
ofinterest.The monotonicityassumptionthenfurther specifies thatthe effect of Z on
D must be either weakly positive or weakly negative for all individuals i. Thus, there
may be either defiers or compliers in the population but not both.24
If these three assumptions obtain, then an instrument Z identifies the LATE: the
averagetreatment effect for the subset of the population whose treatment selection is
inducedby the instrument.25 Ifκ≥0forall i,thenthe WaldestimatorfromEquation
23The stable unit treatment value assumption (SUTVA) must continue to hold, and now it must
applytopotential treatments as well.Inaddition, as wenoted earlier,our presentation herefollows
ImbensandAngrist(1994),AngristandImbens(1995),andAngristetal.(1996).Aswenotelater,IVs
canbedefinedinslightlydifferent(insomecasesmoregeneral)ways.Butfornow,werestrictattention
to the LATE literature, inwhich assumptions such as complete independence of the instrument are
utilized.

24Manskidefinesthisassumptionasamonotonetreatmentselection(MTS)assumptioninorderto
distinguish it from his monotone treatment response (MTR) assumption (see Manski 1997; Manski
and Pepper 2000). Vytlacil (2002) establishes its connections to the index structure model laid out
in Heckman and Vytlacil (1999), as we discuss in Section 9.3.4. Heckman (2000, 2010), Heckman
and Vytlacil (2005, 2007), Heckman et al. (2006), and Heckman and Urzua (2010) provide a broad
accountingoftherelationshipsbetweenalternativeIVestimators.

25TheLATEisoftenreferredtoasthe“complieraveragecausaleffect”tosignifythatthedescriptor
localisreallydefinedbytherestrictedapplicabilityoftheLATEestimatetotheaveragecausaleffect
of compliers. The followingexample does not use the compliance language explicitly, except insofar
asthosewhorespondtothevoucherarelabeledcompliers.TheLATEliteraturethatweciteprovides
the explicit connections between LATE and the large literature on noncompliance in randomized
experiments(seeinparticularImbens andRubin1997andcitationstherein).

(9.5) converges to a particular LATE:
δˆ IV,WALD−p →E[δ|C=c], (9.21)
whichisequaltoE[Y1−Y0|DZ=1=1,DZ=0=0]andisthereforetheaveragetreatment
effect among compliers. In contrast, if κ≤0 for all i, then the Wald estimator from
Equation (9.5) converges to the opposite LATE:
δˆ IV,WALD−p →E[δ|C=d], (9.22)
whichisequaltoE[Y1−Y0|DZ=1=0,DZ=0=1]andisthereforetheaveragetreatment
effect among defiers. In either case, the treatment effects of always takers and never
takers are not informed in any way by the IV estimate.

In the next section, we will explain the claims in Equations (9.21) and (9.22)
in considerable detail through a more elaborate version of IV Demonstration 1. But
the basic intuition is straightforward. A valid IV is nothing more than an exogenous
dimensionacrosswhichthe treatmentand outcomevariables areanalyzedjointly.For
a binary instrument, this dimension is a simple contrast, which is the ratio presented
earlier; see Equations (9.5) and (9.8):
EN[yi|zi=1]−EN[yi|zi=0]
.

EN[di|zi=1]−EN[di|zi=0]
The numerator is the naive estimate of the effect of Z on Y, and the denominator is
the naive estimate of the effect of Z on D.

Togiveacausalinterpretationtothisratioofdifferencesacrossthethirddimension
indexed by Z, a model of individual treatment response must be specified and then
usedto interpretthe causaleffect estimate.The modelofindividualresponseadopted
foraLATE analysiswithabinaryIVisthe fourfoldtypologyofcompliance,captured
by the latent variable C defined earlier for alwaystakers, never takers,compliers, and
defiers. Within this model, the always takers and never takers do not respond to the
instrument (i.e., they did not choose to take part in the “experiment” created by the
IV, and thus their treatment assignment is not determined by Z). This means that
theyaredistributedinthesameproportionwithinalternativevaluesoftheinstrument
Z. And, as a result, differences in the average value of Y, when examined across Z,
are not a function of the outcomes of always takers and never takers.26
Incontrast,defiersand complierscontribute all ofthe variationthat generatesthe
IV estimate because only their behavior is responsive to the instrument. For this rea-
son, any differences in the average value of Y, when examined across Z, must result
from treatment effects for those who move into and out of the causal states repre-
sented by D. If compliers are presentbut defiers are not, then the estimate offered by
the ratio is interpretable as the average treatment effect for compliers. If defiers are
present but compliers are not, then the estimate offered by the ratio is interpretable
as the average treatment effect for defiers. If both compliers and defiers are present,
then the estimate generatedby the ratio does not have a well-defined causal interpre-
tation. In the following demonstration, we will consider the most common case in the
26Inasense,theoutcomes ofalwaystakers andnevertakers representatypeofbackground noise
thatisignoredbytheIVestimator.Moreprecisely,alwaystakersandnevertakershaveadistribution
ofoutcomes, butthedistributionoftheseoutcomes isbalancedacrossthevaluesoftheinstrument.

LATEliteratureforwhichthe monotonicityconditionholdsinthe directionsuchthat
compliers exist in the population but defiers do not.

IV Demonstration 2
Recall the setup for IV Demonstration 1 (see page 294). In an attempt to determine
whetherprivatehighschoolsoutperformpublichighschools,astateeducationdepart-
mentassemblesadatasetonarandomsampleof10,000ninthgraders,{yi,di,zi}1 i=0, 1000,
where Y is a standardized test, and D is equal to 1 for students who attend private
high schools and 0 for students who attend public high schools. Likewise, Z is equal
to 1 for those who win a lottery for a $3,000 school voucher and 0 for those who do
not.

As noted for IV Demonstration 1, a bivariate regression of the values of yi on
di yielded a treatment effect estimate of 9.67; see discussion of Equation (9.7). An
alternative IV estimate with Z as an instrument for D yielded an estimate of 5.5; see
Equation (9.8). The hypothetical state officials relied on the IV estimate rather than
on the regression estimate because they recognized that private school students have
more advantaged social backgrounds. And they assumed that the randomization of
the voucher lottery, in combination with the relationship between D and Z shown in
Table 9.1, established the voucher lottery outcome as a valid IV.

We stated just after our discussionof IV Demonstration 1 that the estimate of 5.5
is properly interpreted as a particular LATE: the average causal effect for the subset
of all students who would attend a private school if given a voucher but would not
attend a private school in the absence of a voucher. To explain the reasoning behind
thisconclusion,wewillfirstexplainhowtheobservedvaluesforDandY aregenerated
asaconsequenceofvariationinZ.Thenwewillintroducepotentialoutcomesanduse
the treatmentresponsemodel inorderto explainwhy the IVestimate is interpretable
as the average treatment effect for compliers.

We reported the frequency distribution of D and Z in Table 9.1. The same infor-
mation is presented again in Table 9.2, but now also as probability values (where,
for example, the term PrN[.,.] in the upper left cell is equal to PrN[di=0,zi=0] by
plugging the row and column headings into the joint probability statement). We also
now report the expectations of the outcome variable Y, conditional on D and Z.

First,considerhowtheleastsquaresandIVestimatesarecalculated.Thecoefficient
of9.67onDinEquation(9.7)isequaltothenaiveestimator,EN[yi|di=1]−EN[yi|di=
0]. One can calculate these two conditional expectations from the elements of Table
9.2 by forming weighted averages within columns:
.1 .02
EN[yi|di=1]= 60+ 58=59.667,
.1+.02 .1+.02
.8 .08
EN[yi|di=0]= 50+ 50=50.0.

.8+.08 .8+.08
As shown earlier in Equation (9.8), the IV estimate of 5.5 is the ratio of two specific
contrasts:
EN[yi|zi=1]−EN[yi|zi=0] 51.6−51.111
= =5.5. (9.23)
EN[di|zi=1]−EN[di|zi=0] .2−.111
Table 9.2 The Joint Probability Distribution and
Conditional Expectations of the Test Score for Voucher
Winner by School Sector for IV Demonstrations 1 and 2
Public school Private school
d i=0 d i=1
Voucherloser z i=0 N=8000 N=1000
PrN[.,.]=.8 PrN[.,.]=.1
E N[y i|.,.]=50 E N[y i|.,.]=60
Voucherwinner z i=1 N=800 N=200
PrN[.,.]=.08 PrN[.,.]=.02
E N[y i|.,.]=50 E N[y i|.,.]=58
Both of these contrasts are calculated within the rows of Table 9.2 rather than the
columns. The contrast in the numerator is the naive estimate of the effect of Z on Y.

It is calculated as the difference between
.08 .02
EN[yi|zi=1]= 50+ 58=51.6 and
.08+.02 .08+.02
.8 .1
EN[yi|zi=0]= 50+ 60=51.111.

.8+.1 .8+.1
The contrast in the denominator is the naive estimate of the effect of Z on D. It is
calculated as the difference between
.02
EN[di=1|zi=1]= =.2 and
.08+.02
.1
EN[di=1|zi=0]= =.111.

.8+.1
Thus, calculatingthe IVestimate inthis caseis quite simple anddoes notrequireany
consideration of the underlying potential outcomes or potential treatments.

But, to interpret the IV estimate when causal effect heterogeneity is present, the
potential outcome and potential treatment framework are needed. Consider the three
identifying assumptions in Equations (9.18) through (9.20). Because the voucher lot-
tery is completely random, the voucher instrument Z is independent of the potential
outcomeandpotentialtreatmentvariables.Also,asjustshown,Z predictsD,thereby
sustainingthe nonzeroeffectassumption.Thus,the firsttwoassumptionsaresatisfied
as explained for IV Demonstration 1.

Only the monotonicity assumption in Equation(9.20) requires a new justification.

Fortunately,thereisnoevidenceintheschoolchoiceliteraturethatstudentsandtheir
parentsrebelagainstvouchers,changingtheirbehaviortoavoidprivateschoolingonly
Table 9.3 The Distribution of Never Takers, Compliers, and
Always Takers for IV Demonstration 2
Public school Private school
d i=0 d i=1
Voucherloser z i=0 7200 Nevertakers 1000 Always takers
800 Compliers
Voucherwinner z i=1 800 Nevertakers 111 Alwaystakers
89 Compliers
when offered a voucher.27 Accordingly, it seems reasonable to assume that there are
nodefiersinthishypotheticalpopulationandhencethatthemonotonicityassumption
obtains.

The joint implications of independence and monotonicity for the four groups of
individualsinthecellsofTable9.2shouldbeclear.Monotonicityallowsustostipulate
thatdefiersdonotexist,whileindependenceensuresthatthesamedistributionofnever
takers,alwaystakers,andcompliersispresentamongthosewhowinthevoucherlottery
and those who do not. As a result, the proportion of always takers can be estimated
consistently from the first row of Table 9.2 and the proportion of never takers can be
estimated consistently from the second row of Table 9.2 as
PrN[di=1,zi=0] −p
→Pr[C=a], (9.24)
PrN[zi=0]
PrN[di=0,zi=1] −p
→Pr[C=n]. (9.25)
PrN[zi=1]
For this example, the proportion of always takers is 1,000/9,000=.111, and the pro-
portion of never takers is 800/1,000=.8. Because no defiers exist in the population
with regard to this instrument, these two estimated proportions can be subtracted
from 1 in order to obtain the proportion of compliers:
1−PrN[di=1,zi=0] −PrN[di=0,zi=1] −p
→Pr[C=c]. (9.26)
PrN[zi=0] PrN[zi=1]
For this example, the proportionof compliers in the population is 1−.111−.8=.089.

Applying this distribution of always takers, never takers, and compliers (and a bit
of rounding) to the frequencies from Table 9.2 yields the joint frequency distribution
presented in Table 9.3.

For Table 9.3, notice the symmetry across rows that is generated by the indepen-
denceoftheinstrument:1,000/7,200≈111/800(subjecttorounding)and800/9,000≈
89/1,000(again,subjecttorounding).Ofcourse,thereisonemajordifferencebetween
27Someparents mightreasonthatprivateschoolingisnolonger asattractive ifitisto beflooded
with an army of voucher-funded children. Thus, defiers might emerge if the vouchers were widely
distributed, and the monotonicity condition would then fail. In this case, however, SUTVA would
alsofail,necessitating deeperanalysisinanycase.

thetworows:Thecompliersareinprivateschoolsamongvoucherwinnersbutinpublic
schools among voucher losers.

Before continuing, two important points should be noted. First, it is important
to recognize that the calculations that give rise to the distribution of never takers,
always takers, and compliers in Table 9.3 are not determined solely by the data. In
a deeper sense, they are entailed by maintenance of the monotonicity assumption. In
theabsenceofthatassumption,anunspecifiednumberofdefierswouldbeinthetable
as well, making the calculation of these proportions impossible.

Second,notallstudentsinthedatasetcanbeindividuallyidentifiedasalwaystak-
ers, never takers, or compliers. Consider the private school students for this example.

Of these 1,200 students, 1,000 students are known to be always takers, as they have
observed values of di=1 and zi=0. The remaining 200 private school students are
observationally equivalent, with observed values of di=1 and zi=1. We know, based
onthemaintenanceofthemonotonicityandindependenceassumptions,thatthese200
studentsinclude 111alwaystakersand89compliers.Butitisimpossibletodetermine
which of these 200 students are among the 111 always takers and which are among
the 89 compliers. The same pattern prevails for public school students. Here, we can
definitively identify 800students as nevertakers,but the 8,000public schoolstudents
who are voucher losers cannot be definitively partitioned into the specific 7,200 never
takers and the 800 compliers.

Now, consider why the IV estimator yields 5.5 for this example, and then why 5.5
is interpretable as the averageeffect of private schooling for those who are induced to
enroll in private schools because they have won vouchers. As noted already, because
Z is independent of Y1 and Y0, the same proportion of always takers and never
takers is present among both voucher winners and voucher losers. The difference in
theexpectationofY acrossthetworowsofTable9.2mustarisefrom(1)theexistence
of compliers only in public schools in the first row and only in private schools in the
second row and (2) the existence of a nonzero average treatment effect for compliers.

To see this claim more formally, recall Equation (9.21), in which this particular
LATE is defined. By the linearity of expectations and the definition of an individual-
level causal effect as a linear difference between y1 and y0, the average causal effect
i i
amongcompliers,E[δ|C=c],isequaltotheexpectationE[Y1|C=c]minustheexpec-
tation E[Y0|C =c]. To obtain a consistent estimate of the average causal effect for
compliers,itissufficienttoobtainconsistentestimatesofE[Y1|C=c]andE[Y0|C=c]
separately and then to subtract the latter from the former.

Fortunately, this strategy is feasible because the contribution of these two condi-
tionalexpectationstothe observeddatacanbe writtenoutintwoequationsandthen
solved. In particular, E[Y1|C=c] and E[Y0|C=c] contribute to the expectations of
the observed outcome Y, conditional on D and Z, in the following two equations:
Pr[C=c]
E[Y|D=1,Z=1]= E[Y1|C=c]
Pr[C=c]+Pr[C=a]
(9.27)
Pr[C=a]
+ E[Y1|C=a],
Pr[C=c]+Pr[C=a]
Pr[C=c]
E[Y|D=0,Z=0]= E[Y0|C=c]
Pr[C=c]+Pr[C=n]
(9.28)
Pr[C=n]
+ E[Y0|C=n].

Pr[C=c]+Pr[C=n]
These two equations are population-level decompositions of the conditional expecta-
tions for the observed data that correspond to the two cells of the diagonal of Table
9.2.Thesearethe onlytwocells inwhichcompliersarepresent,andthusthe onlytwo
cells in which the observed data are affected by the outcomes of compliers.

How can we plug values into Equations (9.27) and (9.28) in order to solve for
E[Y1|C=c] and E[Y0|C=c] and thereby obtain all of the ingredients of a consistent
estimate of E[δ|C=c]? We have already shown from applying the convergence asser-
tionsinEquations(9.24)–(9.26)thatthetermsPr[C=c],Pr[C=a],andPr[C=n]can
be consistentlyestimated.And,infact,these aregivenearlierfor the exampledata as
.089,.8,and.111.Thus,tosolvethese equationsforE[Y1|C=c]andE[Y0|C=c],the
only remaining pieces that need to be estimated are E[Y1|C=a] and E[Y0|C=n],
which are the average outcome under the treatment for the always takers and the
averageoutcomeunderthecontrolforthenevertakers.Fortunately,theindependence
and monotonicity assumptions guarantee that voucher losers in private schools repre-
sentarandomsampleofalwaystakers.Thus,E[Y1|C=a]isestimatedconsistentlyby
EN[yi|di=1,zi=0],whichis60forthisexample(seetheupperright-handcellinTable
9.2). Similarly, because voucher winners in public schools represent a random sample
of never takers, E[Y0|C=n] is estimated consistently by EN[yi|di=0,zi=1], which
is equal to 50 for this example (see the lower left-hand cell in Table 9.2). Plugging all
of these values into Equations (9.27) and (9.28) then yields
.089 .111
58= E[Y1|C=c]+ 60, (9.29)
.089+.111 .089+.111
.089 .8
50= E[Y0|C=c]+ 50. (9.30)
.089+.8 .089+.8
Solving Equation (9.29) for E[Y1|C =c] results in 55.5, whereas solving Equation
(9.30) for E[Y0|C=c] results in 50. The difference between these values is 5.5, which
is the average causal effect for the subset of all students who would attend a private
school if given a voucher but would not attend a private school in the absence of a
voucher.28Thevalueof5.5yieldsnoinformationwhatsoeverabouttheeffectofprivate
schooling for the always takers and the never takers.29
28For completeness, consider how the naive estimate and the LATE would differ if all remained
the same except the stipulated value of 50 for E N[d i=0,z i=0] in Table 9.2. If E N[d i=0,z i=0]
were instead 50.25, then the naive estimate would be 9.44 and the LATE estimate would be 3.00.

And, if E N[d i=0,z i=0] were instead 50.5, then the naive estimate would be 9.21 and the LATE
estimate would be .5. Thus, for the example in the main text, compliers on average do no worse in
publicschoolsthannevertakers.But,forthesetwovariantsoftheexample,compliersonaveragedo
slightly better in public schools than never takers. As a result, the calculations in Equation (9.29)
remainthesame,butthevaluesofEquation(9.30)changesuchthatE[Y0|C=c]isequalto52.5and
55.0,respectively. TheLATEestimateisthereforesmallerinbothcases because theperformanceof
compliersinpublicschoolsishigher(whereastheperformanceofcompliersinprivateschoolsremains
thesame).

29We can estimate E[Y1|C =a] and E[Y0|C =n] consistently with E N[y i|d i =1,z i =0] and
E N[y i|d i=0,z i=1]. But we have no way to effectively estimate their counterfactual analogs: the
Of course, the Wald estimate is also 5.5, as shown in Equations (9.8) and (9.23).

And thus, in one sense, the Wald estimator can be thought of as a quick alternative
method for calculating all of the steps just presented to solve exactly for E[δ|C=c].

Even so, this correspondence does not explain when and how the Wald estimator can
be interpreted as the average causal effect for compliers. For this example, the cor-
respondence arises precisely because we have assumed that there are no defiers in
the population, basedon the substance of the applicationand the treatment response
model thatwe adopted.As a result,the Wald estimate canbe interpretedas a consis-
tent estimate of the averageeffect of private schooling for those who comply with the
instrument because it is equal to that value under the assumed model of treatment
response we are willing to adopt.30
LATE estimators have been criticized because the identified effect is defined by
the instrument under consideration. As a result, different instruments define different
averagetreatment effects for the same groupof treated individuals. And, when this is
possible, the meanings of the labels for the latent compliance variable C depend on
theinstrument,suchthatsomeindividualscanbenevertakersforoneinstrumentand
compliers for another. Deaton writes:
Without explicit prior consideration of the effect of the instrument choice
ontheparameterbeingestimated,suchaprocedureiseffectivelytheoppo-
site of standard statistical practice in which a parameter of interest is
definedfirst,followedbyanestimatorthatdeliversthatparameter.Instead,
we have a procedure in which the choice of the instrument ... is implic-
itly allowed to determine the parameter of interest. This goes beyond the
old story of looking for an object where the light is strong enough to see;
rather, we have at leastsome control overthe light but choose to let if fall
where it may and then proclaim that whatever it illuminates is what we
were looking for all along. (Deaton 2010:429)
Although from one perspective the instrument-dependent nature of the LATE is a
weakness, from another perspective it is the most attractive feature of the LATE.

For IV Demonstration2, the IV estimate does not provide any information about the
average effect for individuals who would attend private schooling anyway (i.e., the
always takers) or for those who would still not attend the private schools if given a
voucher (i.e., the never takers). Instead, the IV estimate is an estimate of a narrowly
defined averageeffectonly amongthose induced to take the treatmentby the voucher
policy intervention. But, for IV Demonstration 2, this is precisely what should be of
interest to the state officials. If the policy question is “What is the effect of vouchers
meanoutcomeinpublicschoolsforalwaystakersandthemeanoutcomeinprivatesschoolsfornever
takers.

30In other words, the Wald estimate of 5.5 is also a quick method for calculating an entirely
differentcausaleffectunderadifferentsetofassumptions.Ifmonotonicitycannotbedefended,then
the IV estimate can be given a traditional structural interpretation, under the assumption that the
causal effect is constant for all individuals. In this sense, because the Wald estimate has more than
one possible causal interpretation, merely understanding how it is calculated does not furnish an
explanationforhowitcanbeinterpreted.

onschool performance?” then they presumably care most about the averageeffect for
compliers.

The limited power of the LATE interpretation of an IV estimate is thus, in some
contexts,beneficial because ofits targetedclarity.Moreover,when supplementedby a
range of additional IV estimates (i.e., different voucher sizes and so on), complemen-
taryLATE estimates maycollectively representanextremely useful setof parameters
that describe variation in the causal effect of interest for different groups of individ-
uals exposed to the cause for alternative (but related) reasons. Before summarizing
the marginal treatment effect literature that more completely specifies the interre-
lationships among all types of average causal effect estimators, we first lay out the
implications of the LATE perspective for traditional IV estimation and consider the
relevant graphs for representing IVs that identify LATEs.

9.3.2 Implications of the LATE Perspective for
Traditional IV Estimation
TheLATEliteraturespecifiesasetofassumptionsunderwhichitispermissibletogive
IVestimatesanaveragecausaleffectinterpretationusingthepotentialoutcomemodel.

In this sense, the new framework is mostly a set of guidelines for how to interpret IV
estimates. As such, the LATE perspective has direct implications for traditional IV
estimation, as introduced earlier in this chapter.

Monotonicity and Assumptions of Homogeneous Response
An important implication of the LATE framework is that many conventional IV esti-
mates lack a justifiable average causal effect interpretation if the IV does not satisfy
a monotonicity condition. In the presence of causal effect heterogeneity and in the
absence of monotonicity of response to the instrument, a conventional IV estimator
yields a parameter estimate that has no clear interpretation, as it is likely an uniden-
tifiable mixture of the treatment effects of compliers and defiers.

ForIVDemonstration2,weshowedthattheestimateof5.5isapplicabletostudents
whose families would change their child’s enrollment choice from a public school to a
private schoolfor a $3,000voucher.Canan assumptionbe introducedthat allows the
estimate of 5.5 to be be interpreted as informative about other students who do (or
who would) attend private schools?
Two variants of the same homogeneity assumption allow for such extrapolated
inference: the assumption that the causal effect is a structural effect that is (1) con-
stant across all members of the population or (2) constant across all members of the
populationwhotypicallytakethetreatment.31Initsstrongerform(1),theassumption
simply asserts that the causal effect estimate is equally valid for all members of the
population,regardlessofwhetherornotthegroupofstudentswhoseenrollmentstatus
wouldchangeinresponsetothevoucherisrepresentativeofthepopulationofstudents
as a whole. In its weaker form (2), the assumption pushes the assumed constancy of
the effect only half as far, stipulating that the IV estimate is valid as an estimate
31 These assumptions are known as constant-coefficient assumptions, homogeneous response
assumptions,orshiftedoutcome assumptions(seeAngristandPischke2009;Manski1995, 2003).

of the ATT only. For IV Demonstration 2, the weaker variant of the homogeneity
assumption is equivalent to asserting that the IV estimate provides information only
about the achievement gains obtained by private school students. Although weaker,
the homogeneity assumption (2) is still quite strong, in that all individuals in private
schools are considered homogeneous with respect to the size of the treatment effect.

In examples such as IV Demonstration2,it is clear that there are two distinct groups
within the treated: always takers and compliers. And there is little reason to expect
that both groups respond in exactly the same way to private schooling. Thus, for
examplessuchasthisone,Manski(1995:44)arguesthatthishomogeneityassumption
“strains credibility” because there is almost certainly patterned heterogeneity in the
effect among treated individuals.

One traditional way to bolster a homogeneity assumption is to condition on vari-
ables in a vector X that can account for all such heterogeneity and then assert a
conditional homogeneity of response assumption. To do so, the Wald estimator must
be abandonedin favorof a two-stageleastsquares(2SLS)estimator.As showninany
econometrics textbook (e.g., Greene 2000; Wooldridge 2010), the endogenous regres-
sorsD andX areembeddedinanencompassingXmatrix,whichis n× k, wheren is
the number of respondents and k is the number of variables in X plus 2 (one for the
constantand one for the treatment variable D). Then, a matrix Z is constructedthat
is equivalent to X, except that the column in X that includes the treatment variable
D is replaced with its instrument Z. The 2SLS estimator is then
δˆ IV,2SLS≡(Z(cid:2) X)−1Z(cid:2) y, (9.31)
where y is an n × 1 vector containing the outcomes yi. The strategy is to attempt
to condition out all of the systematic variability in the observedresponse and then to
simultaneously use the instrument Z to identify a pure net structural effect that can
be regarded as an invariant constant.

Is this strategy a feasible solution? Probably not. If good measures of all of the
necessary variables in X are available, a simple OLS estimator probably would have
been feasible in the first place. Rarely would all possible necessary variables be avail-
able,exceptforasinglevariablethathasanetadditiveconstanteffectontheoutcome
that can then be estimated consistently by an available IV.

Other Challenges for Interpretation
IVestimatesarehard,andsometimesimpossible,tointerpretasLATEestimateswhen
the instrument measures something other than an incentive to which individuals can
consciously respond by complying or defying. Instruments based on exogenous field
variation (as championed in Angrist and Krueger 2001 but criticized in Rosenzweig
and Wolpin 2000 andDeaton 2010)canbe particularly hardto interpret, because the
shifts in costs and benefits that the natural variation is supposed to induce generally
remain unspecified, thereby weakening a main link in the narrative that explains why
some individuals take the treatment in response to the instrument.

Moreover,if two or more IVs are available, then the traditional econometric liter-
ature suggests that they should both be used to “overidentify” the model and obtain
a more precise treatment effect estimate by the 2SLS estimator in Equation (9.31).

Overidentifiedmodels,inwhichmorethanoneinstrumentisusedtoidentifythesame
treatment effect, generate a mixture-of-LATEs challenge.

Consider the Catholic school example discussed earlier. Suppose that two IVs are
used: the share of the county that identifies as Catholic and a student’s religious
identification (as in Neal 1997). Even if these potential IVs have no net direct effects
on test scores (and, further, that the weak instrument problem discussed earlier is
not applicable), can a theoretically meaningful LATE interpretation be given to the
effect that the two instruments in this example jointly identify? For the religious
identificationinstrument,theimpliedLATEistheaverageeffectofCatholicschooling
amongthosewhoarelikelytoattendCatholicschoolsonlybecausethey areCatholic.

When overidentified with the IV represented by the share of the local population
that is Catholic, this first LATE is mixed in with a second LATE: the average effect
of Catholic schooling among those who attend Catholic schools only because of the
small difference in tuition that a high proportion of Catholics in the local population
tends to generate.As a result, the overidentifiedcausaleffect that is estimated by the
2SLS estimator would be an average across two very different groups of hypothetical
individuals, both of which likely deserve separate attention.32
It is sometimes possible to deconstruct 2SLS estimates into component LATEs
when multiple IVs are used, but explaining how to do so is beyond the scope of
this book. We advise readers who are in this situation to first consult Angrist and
Pischke (2009, section 4.5) and the work cited therein. Our position is that there is
comparatively little value in estimating a single treatment effect parameter using a
2SLS model in these cases. Usually, if more than one LATE is identified, then these
can and should be estimated separately.

In sum, if causal effect heterogeneity is present, then a constant-coefficient inter-
pretationofanIVestimateisimplausible.However,iftheinstrumentsatisfiesamono-
tonicity condition and can be conceptualized as a proximate inducement to take the
treatment, then IV estimates can be given LATE interpretations. These fine-grained
interpretations can be very illuminating about particular groups of individuals, even
thoughtheymayprovidenoinformationwhatsoeveraboutothergroupsofindividuals
in the population (including other individuals who typically choose to take the treat-
ment).Thus,thelimitednatureofIVestimatorswheninterpretedasLATEestimators
shows both the potential strengths and weaknesses of IV estimation in general.

9.3.3 Graphs for IVs That Identify LATEs
In this section, we will explain how to represent instrumental variables that identify
LATEs as observed variables in directed graphs. The primary complication is that
compliance with the instrumental variable is a latent class variable, across which it
32There is also the possibility that, contra the justification of Hoxby (1996), the individuals who
are induced to attend Catholic schooling because a greater share of the population is Catholic are
not at all the same as those who are supposedly at the margin of a tuition-based cost calculation.

TheremaybeanothermechanismthatgeneratesanyobservedassociationbetweenZ andD,suchas
thepossibilitythat theCatholicschools aresimplybetter inthesecommunities andhence aremore
attractiveingeneral.ThisisonebasiccriticismthatRosenzweigandWolpin(2000)levelagainstall
suchnaturallyoccurringIVs:ThereisoftennoevidencethattheIVisinducingagroupofindividuals
totakethetreatment accordingtoanassumedcost-benefitsetofchoices.

Z
D Y
Figure9.4 Instrumental variable identification of the causal effect of charter schools
(D) on test scores (Y), where Z is the instrument.

must be assumed that heterogeneity of effects is present. Recall the charter schools
example, as introduced in Section 1.3.2and then as analyzed at length in Section 8.3.

Inthatpriordiscussion,weshowedhowcausalgraphscanbeusedtorepresentcomplex
patterns of self-selectionand heterogeneity using a latent class variable. In particular,
reconsiderFigure8.6(b),whichweusedtoexplainwhyback-doorconditioningforthe
effect of charter schooling D on educational achievement Y was infeasible because of
back-door paths through G.33
For simplicity, suppose now that the parental background confounder P is also
unobserved.As aresult, the analystis left with no wayto evenbeginto enacta back-
door conditioning strategy for the effect of charter schools. Suppose, instead, that an
instrumental variable Z is observed, as in Figure 9.4.

Are there any plausible instrumental variables for charter school attendance? The
geographic distance between the student’s residence and the charter school site is
similar to the sorts of potential IVs used in the traditional economics literature. The
rationale would be that the location of the treatment site is arbitrary but has an
effect on enrollment propensity because of the implicit costs of traveling to the site,
which are typically borne by the parents, not by the school district. For the charter
school example, it is unclear whether such an instrument would have any chance of
satisfying the relevant assumptions, and it would depend crucially on the extent to
which charter schools are located in arbitrary places. Our reading of the literature is
that charter schools tend to be located nearer to students most likely to benefit from
charter schooling, both because many have missions to serve disadvantaged students
who are thought to benefit most from having a charter school opportunity and also
becauseparentsmaythenmovetoneighborhoodsthatareclosertothecharterschools
that they select for their children. It is possible that these threats to the identifying
assumption could be mitigated by conditioning on other determinants of the location
of charter schools within the district and also obtaining family residence data before
students entered charter schools.

Forthesakeofmethodologicalclarityinourpresentation,wewilluseasourexam-
pleamoreconvincingbutunlikelyinstrumentalvariable,inthesensethatithasnever
33For a real example with a structure that is not too dissimilar from ours, Jin and Rubin (2009)
eschew graphs and adopt an alternative principal stratification approach to represent latent classes
fortypesofcomplianceaswellasaverageeffectswithintheseclasses.Byomission,theydemonstrate
thatgraphsarenotneededinordertoofferasensiblerepresentationofunderlyingheterogeneityand
tofocusoncompliancetypesofparticularinterest.Theutilityoftheprincipalstratificationapproach
for compliance latent classes, first laid out in Frangakis and Rubin (2002), is unrelated to a more
recent debate on its utility for interpreting direct and indirect causal effects (see Joffe 2011; Pearl
2011;VanderWeele 2008,2011a).

yet become available and is unlikely to become available in the future. Suppose that
in New York City conditional cash transfers are offered to families that send their
childrentocharterschools.Suppose thatthis programismodeledonNew YorkCity’s
recent Opportunity NYC program, which was justified by the position that families
should be given incentives to make decisions that promote their children’s futures.

Suppose that for the new hypothetical program$3,000in cash is offered eachyear
to families for each child that they enroll in a charter school. Since charter schools
do not charge tuition, families can spend the $3,000 per child however they see fit.

Supposefurtherthat,becauseofabudgetconstraint,cashtransferscannotbeextended
to all eligible families. For fairness, it is decided that families should be drawn at
random from among all families resident in New York City with school-age children.

Accordingly, a fixed number of letters is sent out notifying a set of winning families.

It is later determined that 10 percent of students in charter schools received cash
transfers. A dataset is then compiled with performance data on all students in the
schooldistrict,andthe cashtransferofferis codedasa variableZ,whichis equal to1
forthosewhowereofferedacashtransferand0forthosewhowerenot.Aquickanalysis
ofthe datashowsthatsomefamilies whoreceivedoffersofcashtransfersturnedthem
down and chose to send their children to regular public schools. Moreover, it is then
assumed that at least some of the charter school students who receivedcash transfers
wouldhave attended charter schools anyway,and they were simply lucky to have also
received a cash transfer.

By the standards typical of IV applications, Z would be considered a valid instru-
ment. It is randomly assigned in the population, and it is reasonable to assume that
it has a direct causal effect on D because it is an effective incentive for charter school
attendance.(WehavealsoassumedinthesetupthatthedatashowthatZ predictsD.)
Again, the crucial assumption is that the entire association between Z and Y is
attributable solely to the directed path, Z →D→Y. As we will discuss below in
this section,this assumptionis debatablein this case becausethe subsidy is cashand,
withoutfurtherrestrictions,couldbeusedbyfamiliesofcharterschoolstudentstopur-
chaseothergoodsthathaveeffectsonY.Anysuchalternativeusesofthecashtransfer
would open up additional causal pathways from Z to Y that are not intercepted by
D. For now, however, we will provisionally accept this identification assumption.

WhatparameterdoesZ identify?Supposethatamonotonicityassumptionisvalid
whereby the cash transfers do not create a disincentive for anyone to enter charter
schools(i.e.,defierswithrespecttoZ donotexistinthepopulation).Thisassumption
allows us to abandon the constant coefficient assumption and instead assert that Z
identifiesthefollowingLATE:theaverageeffectofcharterschoolingamongthosewho
enter charter schools in response to the offer of a conditional cash transfer.

Figure9.5showsonewaytorepresentestimatorsofthistype.Forthesetwographs,
the population can be partitioned into two mutually exclusive groups, compliers and
noncompliers (as explained in Section 9.3, and assuming defiers do not exist). Fig-
ure 9.5(a) is the graph for compliers. No back-door paths connect D to Y in this
graphbecause compliers,by definition, decide to enter charterschoolssolely basedon
Z Z
D Y D Y
(a) Compliers (b) Always takers
and never takers
Figure9.5 Instrumental variable identification of the causal effect of charter
schools (D) on test scores (Y), where separate graphs are drawn for compliers and
noncompliers.

whether they are offered the conditional cash transfer.34 Analogous to the distribu-
tion calculated for Table 9.3, compliers are present in both regularpublic schools and
charter schools.

Figure 9.5(b) is the graph for noncompliers. Always takers enter charter schools
regardlessof whether they receivethe offer of a cashtransfer,and nevertakersdo not
enter charter schools regardless of whether they receive the offer of a cash transfer.

As a result, Z does not cause D for either always takers or never takers. The analyst
can therefore place Z within the graph, but the causal effect Z→D must be omitted.

Instead, the analyst includes D(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)Y to represent the unobserved joint causes of
D and Y, as it is these factors that suggest why identification via an instrumental
variable is needed.

Given that a central theme of this book is the power of graphs to represent causal
relationships,wewillconcludebyaddressingafinalquestion:CantheclarityofFigure
9.5berepresentedinasinglecausalgraph,akintothemovefromFigure8.3toFigure
8.4 in Section 8.3? Yes, but readers may not agree that the clarity is preserved.

Figure9.6isacombinedrepresentationofFigure9.5,whichnowappliestothefull
population. The representation of compliance-based heterogeneity is accomplished by
augmenting the graphwith a latent class variable, C, which signifies whether an indi-
vidualisacomplierornot.35 Inparticular,C takesonthreevalues, oneforcompliers,
one for always takers, and one for never takers (and we assume that defiers do not
exist in the population). Most importantly, C interacts with Z in determining D, and
then C interacts with D in determining Y.36
Now, to make the connection to the fully elaborated Figure 8.7 (see page 285),
consider Figure 9.7, which includes all of the relevant back-door paths between D
34WethankPeterSteinerforpointingouttousthat,contrarytofigureA2inMorganandWinship
(2012), Figure9.5(a)shouldnotincludeD(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)Y.NoneofthecommoncausesofD andY among
noncompliershaveanalogouseffectsforcompliersbecauseDisdeterminedsolelybyZ forcompliers.

35Analternativeandmorecompact graphcouldbeusedforFigure9.6.Because C isunobserved,
onecouldsimplydeclarethatitisamemberofthesetofvariablesthatgeneratethebidirectededge
in Figure 9.6 (or as a member of the set of variables in V that will be introduced below for Figure
9.7). We give C its own pair of explicit causal effects on D and Y for clarity, even though it makes
thegraphmorecomplexthanitneedstobe.

36It is possible that one could assume that C does not determine Y. This would be the case, for
example, if one had reason to believe that the LATE is equal to the ATE, which would seem to be
veryunlikelyinsocialscienceapplications.

Z
D Y
C
Figure9.6 A combined graph for Figures 9.5(a)–(b), where Z is the instrument and
compliance is represented as an unobserved latent class variable (C).

and Y represented as D(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)Y for Figure 9.6. Still, for simplicity we have replaced
the path I →Exp(D→Y)→G from Figure 8.7 with the single variable V.37 The
conditionalcashtransfer is then representedas aninstrumental variable Z, which has
a sole causaleffect in the graphon D because we haveassumedthat the cashtransfer
offer does not have other effects on Y. Finally, we then add the additional back-door
path from D to Y through their new common cause C.

With the addition of D←C→Y to the graph,two sources of confusion may arise
for some readers. First, it remains true that we cannot use back-door conditioning
to estimate the effect of D on Y because of the unblockable back-door path through
D←V →Y.However,itisimportanttorememberthatthesimilarlystructuredback-
doorpathD←C→Y doesnotpresentanyproblemsforanIVestimatorbecauseitis
not a back-door path from Z to Y, nor part of a directed path that carries the effect
of Z to Y. It only represents an additional unblocked back-door path from D to Y.

Second,nothinginthecausalgraphitselfexplainswhyaresultingIVestimatordelivers
an average causal effect that applies only to compliers. To understand this point, it
may be more helpful to draw two separate causal graphs, as in Figure 9.5. The single
causal graph does not reveal that there is an implicit interactionbetween Z and C as
causes of D. In particular, the instrument Z does not cause D for noncompliers, and
C does not cause D for those who do not receive the offer of a cash transfer. Only
the co-occurrence of Z and C switches some members of the population from D=0
to D=1.

Now, to conclude the discussion of the estimation of the charter school effect,
considertwofinalpoints. ItislikelythatFigure9.7improperlyomitsthe likelycausal
effect P →C. The parental background variable P implicitly includes within it a
variable for family income. Students from families with high incomes should be less
likely to switch from regular public schools to charter schools because of an offer of a
modestconditionalcashtransfertotheirparents.Addingsuchapath,however,would
notharmthe feasibility of the IVestimator, since it does notgeneratean unblockable
path from Z to Y. In fact, the effect P →C helps to explain who compliers likely
are, because it suggests that they are more likely to be lower income families. In this
sense, recognizing the likely presence of this effect helps to interpret the LATE that
the IV identifies.38 In addition, this type of effect reveals a distinct advantage of a
37This simplification is permissibleunder the assumption that an impliciterror term e V contains
alloftheinformationintheerrortermse I,e Exp,ande G inthecausal graphinFigure8.7.

38For situations suchas these, Angristand Fernandez-Val (2013) propose alternative methods for
usingmultiple IVs and covariate information to put forwardestimates of broader parameters based
onidentifiedLATEs(seealsoAronowandCarnegie2013).

Z V
N
D
P Y
C
Figure9.7 Identificationofthe LATEusinganinstrument(Z)forthe charterschool
graph presented earlier in Figure 8.7. The unobserved variable V is a composite for
the causalchain that generates self-selectionin Figure 8.7 throughinformation access
and selection on the subjective evaluation of the individual-level causal effect.

single population-levelgraphthat representscompliance asa node within it. Separate
graphs for compliance classes do not permit a representation of the effect of P on
compliance.

But,ofcourse,notalladditionalcausaleffectswillhelptoclarifytheIVestimator.

Suppose,forexample,thatZ generatesaneffectonN becausethecashtransferisused
topayhigherrentinanotherneighborhoodforsomefamilies.Asaresult,adirecteffect
fromZ toN isopenedup.ConditioningontheobservedvariableN willblockthenew
directed path Z → N → Y. But, because N is a collider on another path, Z → N←
V →Y, conditioning on N opens up this pathway by inducing a relationship between
Z and V. Thus, conditioning away self-selection into neighborhoods then allows self-
selection on the causal effect of charter schooling to confound the IV estimate of the
LATE.

9.3.4 Local IVs and Marginal Treatment Effects
In this final section, we discuss one additional perspective on the identifying power
of IVs in the presence of individual-level heterogeneity, which shows how a perfect
instrument can help to identify a full pattern of causal effect heterogeneity. Heckman
andVytlacil(1999,2000,2005,2007),buildinguponHeckman(1997),haveshownthat
LATEs and many other average treatment effects can be seen as weighted averages
of more fundamental marginal treatment effects.39 Although the generality of their
perspective is captivating, and the methodological content of the perspective unifies
manystrandsoftheliteratureincausaleffectestimation,wesummarizeitonlybriefly
here because the demands on data are quite substantial. The all-powerful IV that is
neededtoestimateafullscheduleofmarginaltreatmenteffectswillrarelybeavailable
to researchers.

The marginal treatment effect (MTE) perspective can be easily graspedwith only
a slight modification to the setup of IV Demonstration 2. Instead of 10 percent of
students receiving a voucher that is exactly equal to $3,000, suppose instead that
39SeealsoHeckmanetal.(2006) andHeckmanandUrzua(2010).

these 10 percent receive a voucher that is a randomdraw from a uniform distribution
with a minimum of $1 and a maximum equal to the tuition charged by the most
expensive private school in the area.

For Heckman and his coauthors, the size of each student’s voucher is a valid
instrument Z, maintaining the same assumptions as we did for IV Demonstration
2 (i.e., Z is randomly assigned, Z has a nonzero effect on D, and the effect of Z
on D is monotonic). The monotonicity assumption is a little more complex than
before, but it stipulates that the true probability of taking the treatment is higher
for all individuals with values of Z equal to z(cid:2)(cid:2) rather than z(cid:2) if z(cid:2)(cid:2)> z(cid:2). This fits
cleanlyinto the notationintroducedearlierin this chapter by simply allowingZ to be
many-valued.

Heckman and his coauthors then define two related concepts: a local instrumental
variable (LIV) and an MTE. An LIV is the limiting case of a component binary IV
drawn from Z in which z(cid:2)(cid:2) approaches z(cid:2) for any two values of Z such that z(cid:2)(cid:2)> z(cid:2).

Each LIV then defines a marginal treatment effect, which is the limiting form of a
LATE, in which the IV is an LIV.

Consider the more elaborate version of IV Demonstration 2 just introduced here.

One could form LIVs from Z by stratifying the data by the values of Z and then
considering adjacent strata. Given a large enough sample for a large enough voucher
program,LIVs could be constructedfor eachdollarincreasein the voucher.EachLIV
could then be used to estimate a LATE, and these LIV-identified LATEs could then
be considered MTEs.

Heckman and Vytlacil (2005) show that most average causal effect estimates can
be represented as weighted averages of MTEs, identified by LIVs. But the weight-
ing schemes differ based on the parameter of interest, some of which, as was the
case in our regression chapter, may have no inherent interest. Heckman and Vyt-
lacil therefore propose a more general strategy. They argue that researchers should
define the policy-relevant treatment effect (PRTE) based on an assessment of how
a contemplated policy would affect treatment selection. Then, MTEs should be esti-
mated with LIVs and weighted appropriately to obtain the PRTE that is of primary
interest.

There is much to recommend in this approach, and in fact it should not be con-
sidered an approach relevant only to policy research. The approach is quite easily
extended to targeted theory-relevant causal effects, for which one wishes to weight
marginal causal effects according to a foundational theoretical model. But, in spite
of this appeal, the entire approach may well come to represent a gold standard for
what ought to be done rather than what actually can be done in practice. If it is
generally recognized that IVs satisfying the LATE assumptions are hard to find,
then those that satisfy LIV assumptions for all MTEs of interest must be harder
still.40
40Partlyforthis reason, Carneiro, Heckman, and Vytlacil (2010) elaborate the PRTE perspective
andfocusattentiononalimitingformofthePRTEthattheylabelmarginalpolicy-relevanttreatment
effects (MPRTEs).TheyarguethatitiseasiertoestimateMPRTEsandthatthese maybeallthat
areneededtoevaluateproposedpolicychanges.

## 9.4 Conclusions

The impressive development of the IV literature in econometrics and statistics in the

past two decades suggests a variety of recommendations for practice that differ from
those found in the older IV literature:
1. Weakinstrumentsyieldestimatesthatareespeciallysusceptibletofinite sample
bias.Consequently,naturalexperimentsshouldbeavoidediftheimpliedIVsonly
veryweaklypredictthecausalvariableofinterest.Nomatterhowseductivetheir
claimstosatisfyidentificationassumptionsmaybe,resultingpointestimatesand
standard errors may be very misleading.

2. Ifindividual-levelcausaleffectheterogeneityispresent,apotentialIVshouldbe
used only if it satisfies a monotonicity condition. IV estimates should then be
interpreted as LATE estimates defined by the instrument.

3. Ifindividual-levelcausaleffectheterogeneityis present,IVsshouldprobablynot
be combined in a 2SLS model (except in the rare cases in which measures of all
of the variables that account for the causal effect heterogeneity are available).

Instead, IV estimates should be offered for those IVs that satisfy monotonic-
ity conditions. These alternative estimates should then be interpreted as LATE
estimates and reconciled with each other based on a narrative about why the
causal effect varies for different types of individuals who are exposed to the
cause (and/or different levels of the cause) for different reasons.

4. When possible, IVs should be used to examine general patterns of causal effect
heterogeneity. Using IVs to estimate only the ATE or ATT is too narrow of a
purpose because there is likely a good deal of variation in the treatment effect
that is amenable to analysis with complementary IVs. The possibilities for this
type ofanalysisaremostclearlydevelopedinthe literature onthe identification
of MTEs using LIVs.

Properlyhandled,thereismuchtorecommendintheIVestimationstrategyforcausal
analysis.But,ofcourse,IVsmaynotbeavailable.Wenowturntoothertechniquesthat
mayallowforthepointidentificationandestimationofacausaleffectwhenacomplete
model of causal exposure cannot be formulated because selection is determined by
relevant unobserved variables.

# Chapter 10

# Mechanisms and Causal Explanation

Socialscientistshaverecognizedfordecadesthatthe bestexplanationsforhowcauses

bringabouttheireffectsmustspecifyinempiricallyverifiablewaysthecausalpathways
between causes and their outcomes. This valuation of depth of causal explanation
applies to the counterfactual tradition as well. Accordingly, it is widely recognized
that a consistent estimate of a counterfactually defined causal effect of D on Y may
not qualify as a sufficiently deep causal account of how D effects Y, based on the
standards that prevail in a particular field of study.

In this chapter, we first discuss the dangers of insufficiently deep explanations
of causal effects, reconsidering the weak explanatory power of some of the natural
experiments discussed already in Chapter 9. We then consider the older literature
on intervening variables in the social sciences as a way to introduce the mechanism-
basedestimationstrategyproposedbyPearl(2009).Insomerespects,Pearl’sapproach
is completely new, and it shows in a novel and sophisticated way how intervening
variables can be used to identify causal effects, even when unblocked back-door paths
between a causal variable and an outcome variable are present. In other respects,
however,Pearl’sapproachisrefreshinglyfamiliar,asithelpstoclarifytheappropriate
usage of intervening variables when attempting to deepen the explanation of a causal
claim.

Independent of Pearl’s important work, a diverse group of social scientists has
appealed recently for the importance of mechanisms to all explanation in social sci-
ence research. Although some of these appeals are not inconsistent with the basic
counterfactual approach to observational data analysis, some of the more extended
appeals argue against the utility of the counterfactual model. After presenting these
positions,weargueinsteadthatthereisnoincompatibilitybetweenthe elaborationof
generative causal mechanisms and the counterfactual approach to observational data
analysis. Finally, we draw on Machamer, Darden, and Craver (2000) and introduce
their concepts of mechanism sketch, mechanism schema, and the process of bottoming
out inmechanisticexplanation.Thisterminologyhelpstoframeourfinaldiscussionof
325
how mechanisms can be used to sustain and deepen causal explanation, which draws
together Pearl’s front-door identification strategy with standards for sufficient causal
depth.

## 10.1 The Dangers of Insufficiently Deep Explanations

Before considering how mechanisms can be used to identify causal effects, we first

discuss the importance of explanatory depth in causal analysis. To do so, we return
to the critical work of Rosenzweig and Wolpin (2000) on the limited appeal of many
natural experiments. As discussed inChapter 9, the natural experiment literature
in economics uses naturally occurring forms of randomness as instrumental variables
(IVs) in order to identify and then estimate causal effects of long-standing interest.

Initially,thisliteraturewasheraldedasthearrivalofanewageofeconometricanalysis,
in which it appeared possible to consistently estimate some of the causal effects of
greatest interest to economists, such as the effect of human capital investments in
education on earnings. Looking back on these bold claims, Rosenzweig and Wolpin
(2000:829–30) conclude, “The impression left by this literature is that if one accepts
that the instruments are perfectly random and plausibly affect the variable whose
effect is of interest, then the instrumental-variables estimates are conclusive.” They
then argue that these estimates are far from conclusive and, in fact, are far more
shallow than typically recognized.

To somewhat overstate the case, the initial overconfidence of the natural experi-
ment movement was based on the mistaken belief that the randomness of a natural
experimentallowsonetooffervalidcausalinferenceintheabsenceofanyexplicitthe-
ory.Onemightsaythatsomeeconometricianshadbeenseducedbyapositionimplicit
in some writing in statistics: We do not need explicit theories in order to perform
data analysis. Rosenzweig and Wolpin (2000) counter this position by arguing that
the theorythat underlies any modelspecificationis criticalto the interpretationof an
estimate of a causal effect, and almost all examples of estimation by natural experi-
mentshavemodelspecificationsthatmakeimplicittheoreticalclaims(seealsoDeaton
2010 and our prior discussion in Section 9.3).

Here, we provide an informal presentation of two of the examples analyzed by
RosenzweigandWolpin–the effectofeducationonearningsandthe effectofmilitary
service on earnings – each of which was already introduced and discussed briefly in
Chapter9.Wewillusedirectedgraphshereinordertodemonstratetheissuesinvolved.

Angrist and Krueger (1991, 1992) address the ability-bias concern for the estima-
tionofthe causaleffectofschoolingonsubsequentlabormarketearnings.Theyassert
thatthe quarterinwhichoneis bornis randombutnonetheless predictsone’slevelof
education because of compulsory school entry and dropout laws (see the quotation in
Section 9.2 that gives the rationale). Angrist and Krueger’s estimates of the increase
in log earnings for each year of education fall between .072 and .102, values that are
consistent with those found by others using different methods (see Card 1999).

As discussed already in Chapter 9, the first limitation of their results is that their
IVestimatesapplytoonlyanarrowsegmentofthepopulation:thoseindividualswhose
School
Wages
Quarter of Birth
Experience
Figure10.1 A directed graph for compliers with quarter of birth as an IV for
years of schooling.

schoolingwouldhave changedif their birthdate was in a different quarter.Again, this
is a local average treatment effect (LATE) estimate that applies to those individuals
whose years of schooling are responsive to school entry and dropout laws. No one
maintainsthatthisnarrowsubpopulationissimplyarandomsampleofallindividuals
inthepopulationofinterest,andmostwouldarguethatAngristandKruegerestimated
the returns to schooling only for disadvantaged youth prone to dropping out of high
school for other reasons. There are, however, complications of how to interpret their
estimates even for this subpopulation.

Consider the directed graph in Figure 10.1, which is based loosely on the critique
offeredbyRosenzweigandWolpin(2000)andisasummaryofthedebatethatunfolded
inthe yearsfollowingthe publicationofAngristandKrueger(1991).The graphisnot
meant to represent a full causal account of how education determines wages, and it
is restricted only to the causal effect among compliers. As discussed in Chapter 9, for
this example, compliers are those members of the population whose education is (or
would be) responsive to a switch in their quarter of birth. Thus, this graph takes it
for granted that this particular LATE is the only parameter that is informed by this
analysis.1
For Figure 10.1, schooling has both direct and indirect effects on wages. Most
important, as is maintained in the human capital literature, schooling is thought to
haveanegativeindirecteffectonwagesthroughworkexperience;goingtoschoollonger
reducestheamountofworkexperienceoneacquiresbyanyparticularage.Accordingly,
there is a causal pathway from schooling to wages via work experience. The quarter-
of-birth IV does not provide a separate estimate of this distinct pathway because
a change in schooling in response to one’s birthdate also changes work experience.

Instead, the quarter-of-birth IV estimates only the total effect of schooling on wages,
not its direct effect.2 The IV yields a LATE estimate that likely mixes together two
1Thispositionisequivalenttoassumingthatamoreencompassinggraphexiststhatisapplicable
to the entire population and that Figure 10.1 applies only to compliers. See our prior discussion of
Figure9.5(a).

2Angrist and Krueger could deal with this problem by conditioning on a measure of work expe-
rience, but in their data no such variable is available. The only alternative with their data, which
School
Wages
Military Service
Draft Lottery
Civilian Experience/Training
Figure10.2 A directed graph for compliers with the Vietnam draft lottery as
an IV for military service.

distinct and countervailing causal pathways: a positive direct effect of schooling on
wages and a negative indirect effect via work experience. Given the long-standing
interest of economists in the interaction between investments in formal schooling and
the provision of on-the-job training, this total effect estimate can be regarded as an
insufficiently deep causal account of the effect of education on earnings (even if one is
convinced, as we are, that learning about compliers in this case is still illuminating).

Forasecondexample,considertheeffectofmilitaryserviceonlifetimeearnings,as
analyzedbyAngrist(1990)andintroducedinSection9.2.Thequestionofinteresthere
iswhethermilitaryserviceprovidesimportanttrainingthatincreaseslaterearningsin
civilian life or rather whether military service is simply a period of lost civilian work
experience. Military service, however, is not random. On the one hand, individuals
mustpassamentalabilitytestandahealthexaminationinordertoenlist.Ontheother
hand, individuals with attractive schooling opportunities and civilian labor market
opportunitiesarelesslikelytoenlist.Todealwiththeproblemofnonrandomselection
into the military, Angrist (1990)considers individuals who were potentially eligible to
be drafted into the military by a lottery during the later stages of the Vietnam War.

To ensure that the draft was fair, the government decided to draft individuals based
on a lottery that selected birthdates (see our earlier discussion in Section 9.2).

Consider now the directed graph in Figure 10.2, again based on the summary of
critiquesofthestudycompiledbyRosenzweigandWolpin(2000).Here,therearethree
issues to consider. First, as we noted for the last example, the draft lottery identifies
a LATE,andthus itis notapplicableto the causaleffectfor alwaystakers(those who
voluntarilyenlisted) andnevertakers(those who weredraftdodgers,thosewho failed
the mental ability test, and those who failed the physical examination). Accordingly,
as for Figure 10.1, the graph in Figure 10.2 also applies to compliers only.

Second, note that there is a potential path from the draft lottery to civilian expe-
rience/training.If this path exists, then the draft lottery is nota valid IV for military
is common in the literature, is to attempt to untangle the effects by conditioning on the number of
yearssincetherespondentcompletedhisorherhighestlevelofeducation.However,thisformofcon-
ditioning does not completely explain away the association between schooling and work experience,
asiswidelyrecognized(seeCard1999).

service. As we noted in Chapter 9, Heckman (1997) argued that employers would be
likelyto investless inindividuals with unfavorablelotterynumbers. Forexample, itis
plausible that employers may have given less on-the-job training to those most likely
to be drafted and/or may have assigned such individuals to short-run tasks that did
not require the accumulation of skill to master. If this effect exists, then the draft
lottery would be an invalid instrument for military service.

Third,andmostimportantforourconsiderationhere,therearefourseparatecausal
pathways between military service and wages. In addition to the direct causal effect
of military service on wages, there are two directed paths solely mediated by civilian
experience and schooling, respectively. Here, it is generally thought that military ser-
vice reduces civilian labor force experience and schooling, both of which then reduce
wages.Butthereisthenacountervailingeffectofmilitaryservicethatsnakesthrough
the graph via a fourth directed path: Military service reduces schooling, which then
increases work experience, and which then increases wages. Because all four of these
pathwaysareactivatedbytheshockinducedbythedraftlottery,Angrist’sonlyresort
isto assertthathis estimates areforthe total effectofmilitary serviceonwages.But,
giventhe inherent interest in untangling how the military service effect interacts with
bothschoolingandtheaccumulationofcivilianworkexperience,atotaleffectestimate
is insufficiently deep to end all future research, even though this natural experiment
was informative and a very important contribution to the literature.

RosenzweigandWolpin(2000)considermanyotherexamples,allofwhichempha-
size the same basic points as these two examples. IV analyses typically provide total
causal effect estimates, often in substantive areas in which scholars have an inherent
interestintheseparablecausalpathwaysthatgeneratetheoutcomeinresponsetothe
cause. Understanding the separable causal pathways that make up these total effects
requires an explicit specification of additional intervening and mediating variables,
which together compose the full causal mechanism of interest.

Now consider these two issues more generally, moving away from IV estimates
towardmoregeneralestimatesofaveragecausaleffects.Consideranoptimisticscenario
for which one obtains what all agree is a consistent estimate of the averagetreatment
effect (ATE) for the effect of D on Y (as warranted, for example, by a consensus
that one has conditioned on all variables that block all back-door paths from D to
Y). Even in this scenario, in which the causal claim is valid by the standards of the
counterfactual model, there are two related ways in which such an estimate can be
regardedas insufficiently deep.

First, the ATE may not be a parameter of any fundamental interest. This point
has been made most forcefully by Heckman (2000, 2005, 2010). If treatment effects
are heterogeneous, which often is the case, as we have noted in prior chapters, then
whatisoffundamentalinterestareconditionalaveragetreatmenteffectsofsomeform
(perhapsevenjustthe averagetreatmenteffectforthe treated(ATT)andthe average
treatmenteffectforthecontrols(ATC)).TheoverallATEissimplyaweightedaverage
of any such underlying effects. Heckman and many others have noted that the ATE
may be of limited use for predicting the outcomes of policy interventions, either for
new populations or in different contexts, because the ATE is tied to the current con-
figuration of the population and prevailing pattern of causal exposure. Often, social
scientists desire explanations for outcomes that can be modified in straightforward
wayswhenpopulationsshiftorcontextschangeinwaysthatareseparablefromcondi-
tionalaveragecausaleffects(especiallyifthereisreasontobelievethattheconditional
averagecasualeffects are morefundamental inthe sense that they canbe expected to
remain invariant under any such shifts and changes).

The second issue, which is our primary focus in the remainder of this chapter, is
that a consistent estimate of the ATE, or any other average causal effect, does not
necessarily entail any particular mechanism that explains how D brings about Y. If a
theorysuggestswhyandhowD bringsaboutY,thenmerelyprovidingevidenceofthe
amountthatY canbeexpectedtochangeinresponsetoaninterventiononDdoesnot
then provide any support for the underlying theory. If an assessment of the support
for the underlying theory is desired, which is often a primary goal of social science
research, then a more narrowly focused analysis of the putative causal pathways that
relate D to Y must be undertaken.

In the next section, we present Pearl’s approach to this type of analysis. We will
make the case that his approach is consistent with decades of prior research in the
social sciences and, furthermore, that it provides a particularly clear guide for future
researchinthe samemodeofanalysis.Tosetthe stageforPearl’sperspective,wefirst
bring this long history of practice to the foreground, presenting the classic literature
on the importance of intervening variables in causal explanation.

## 10.2 The Front-Door Criterion and Identification of Causal Effects by Mechanisms

For decades, social scientists have considered the explication of mechanisms through

theintroductionofinterveningandmediatingvariablestobeessentialtosoundexplana-
tory practice in causal analysis. Duncan and his colleagues wrote in their 1972 book,
Socioeconomic Background and Achievement:
much of the scientific quest is concerned with the search for intervening
variablesthatwillservetointerpretorexplaingrossassociationspresumed
toreflectacausalrelationship.(Duncan,Featherman,andDuncan1972:12)
The words “interpret” and “explain” are implicit references to the language of social
researchthatisusuallyassociatedwithPaulLazarsfeld.Morethantwodecadesearlier,
Kendall and Lazarsfeld (1950) distinguished between alternative types of elaboration
thatcanbe carriedoutwheninvestigatinganassociationbetweenacausalvariableX
and an outcome variable Y.3 Each type of elaboration involves the introduction of a
3The citations in the text are for a retrospective discussion of Samuel Stouffer’s research in The
AmericanSoldier (whichwealsodiscussedinChapter1).PatriciaKendallwastheleadauthorforthe
1950piecewecite,andyetsheisalmostnevercreditedinthederivativeliteratureasacontributorto
thislanguage.BecauseitisoftenwrittenthatLazarsfeldpresentedanddiscussedthisbasictypology
inmanyplaces,itispossiblethatitisfairtocredithimdisproportionatelyfortheseideas.Ourreading
of the literature, however, does not yield a clear interpretation. It does suggest to us that Kendall
hasreceivedlesscreditthanshedeserved.Indeed,intheversionoftheseideaspublishedinHyman’s
widelyreadtextSurveyDesignandAnalysis,Hyman(1955:275)notesonlyinafootnote,“Themajor
testfactor(ortestvariable)T,afterwhichtheassociationbetweenthecausalvariable
X and the outcome variable Y is calculated for each value of T.

Kendall and Lazarsfeld considered two types of M-elaboration, which arise when
the partial association between X and Y within strata defined by T is smaller than
theoriginaltotalassociationbetweenX andY.4 AssumingthatbothXandT precede
Y in time, the twotypes ofM-elaborationaredeterminedby whether T alsoprecedes
X in time:
1. If T follows X in time, then an M-type elaboration can be represented by a
chain of mediation, X→T →Y (Kendall and Lazarsfeld 1950:157). They refer
tothistypeofelaborationasaninterpretation oftheassociationbetweenX and
Y, using a test factor that is an “intervening” variable.

2. IfT precedesX intime,thenanM-typeelaborationcanberepresentedbyafork
of mutual dependence, X ←T →Y (Kendall and Lazarsfeld 1950:157). They
refer to this type of elaborationas an explanation of the association between X
and Y, using a test factor that is an “antecedent” variable.

Although Kendall and Lazarsfeld did not argue that causality can be established by
what they call “interpretation,” and although they use the word “explanation” in a
rather limited sense (and with a different usage than Duncan and colleagues, as just
quoted), Kendall and Lazarsfeld were clearly interested in mechanistic accounts that
reveal how causes bring about their effects. For example, they wrote:
When we interpreta resultwe tryto determine the processthroughwhich
the assumed cause is related to what we take to be its effect. How did
the result come about? What are the “links” between the two variables?
Answerstothesequestionsareprovidedinthe interpretationofthe result.

(Kendall and Lazarsfeld 1950:148)
Alongtraditionofempiricalsocialscienceexiststhatfollowsthesebasicideas,inwhich
a central goal of investigation is the search for variables – intervening, mediating, or
processualvariables – thatcanaccountfor anassociationthatis thoughtto be causal
(see MacKinnon 2008; Winship and Harding 2008). Even so, as we noted in Chapter
6, applications of the all-cause regression specification approach gradually obscured
this goal, leading from the 1970s through the 1990s to more frequent attempts to
offer single-equation models in which all effects of all observed putative causes of an
outcome are estimated simultaneously.

Fortunately, Pearl (2009)has developed an “inside-out” perspective on the identi-
fyingpowerofmechanismsthatcanhelpthesocialsciencesrecapturetheinclinationto
pursuemechanisticexplanationofcausaleffectsinempiricalresearch.Pearl’sapproach
sections of this chapter have been written by Patricia Kendall and represent an enlargement of an
earlieranalyticschema.”
4Theyalsolayoutathirdformofelaboration,referredtoasP-typeelaboration(orspecification).

Here, the goal is to focus “on the relative size of the partial relationship [between X and Y within
strataofthetest factor T]inordertospecifythe circumstances under whichtheoriginalrelationis
moreorlesspronounced”(KendallandLazarsfeld1950:157).Thistypeofelaborationisappropriate
whenthetestfactorisrelatedtoeitherX orY butnotboth.Weignorethisformofelaborationhere,
aswefocusonvariablesthatarerelatedtoboththecausalandoutcomevariables.

U
M
D Y
N
Figure10.3 AdirectedgraphinwhichM andN representanexhaustiveandisolated
identifying mechanism for the causal effect of D on Y.

goeswellbeyondLazarsfeldianelaboration.Instead,heshowshowonecanconsistently
estimatetheeffectofacausalvariableonanoutcomevariablebyestimatingtheeffect
asitpropagatesthroughanexhaustiveandisolatedmechanism.Helabelsthisstrategy
the “front-door” identification of a causal effect (see Pearl 2009:81–85).

ConsiderFigure10.3,whereanunblockableback-doorpathD←U→Y existsfrom
D andY becausethevariableU isunobserved.Asaresult,identificationusingPearl’s
back-doorcriterion,aspresentedinChapter4,is infeasible.Nonetheless,the variables
M and N intercept the full causal effect of D on Y, and for Pearl these two variables
representan identifying mechanism for the effect of D on Y. (Again, recall that there
is no assumption of linearity in a directed graph of this type, and thus this model is
consistentwithanynonlinearstructuralequationsforthegenerationofD,M,N,and
Y.)
For this graph, observation of M and N identifies the causal effect of D on Y by
a two-part consideration of the back-door criterion:
1. For D→M and D→ N, two back-doorpaths exist: D←U→Y ←M and D←
U →Y ←N, respectively.5 Because Y is a collider variable along both of these
back-door paths, each path is blocked by Y in the absence of any conditioning.

Accordingly,theseback-doorpathsdonotcontributetotheobservedassociations
between D and either M or N. And, as a result, the causal effects D →M and
D→N canbeestimatedconsistentlybytheirsimpleunconditionalassociations.

2. For M →Y and N → Y, two back-door paths exist for each causal effect. For
M →Y, they are M ←D←U →Y and M ←D→N →Y. For N →Y, they
are N ←D←U →Y and N ←D→M →Y. All four of these back-door paths
generate noncausal associations between M and Y and also between N and Y
5Both D←U→Y ←M and D←U→Y ←N satisfy the definition of a back-door path, even
though they do not end with →M and →N, respectively. They are both paths between pairs of
causallyorderedvariables(D andM,ontheonehand, andD andN,ontheother), andtheyboth
beginwithanarrowpointingtothe firstvariable(i.e.,D←).Assuch, they areback-door paths for
D→M and D→N, respectively, even though they do not resemble most of the other examples of
back-door paths presented in this book. We have focused our earlier examples on back-door paths
thatmustbeblockedbyconditioning.However,seeourdiscussionofFigure4.12intheappendixto
Chapter 4,wherewediscussasimilarback-doorpath.

because none of these paths includes collider variables that block them in the
absence of any conditioning. Fortunately, all four of these back-door paths can
be blocked by conditioning on D. And, as a result, the casual effects M →Y
and N → Y can be estimated consistently after conditioning on the observed
variable D.

In short, for this graph the unblocked back-door path D←U →Y does not prevent
consistent estimation of the effect of D on Y as long as both M and N are observed.

Becauseone canobtainconsistent estimates of the casualeffects ofD on both M and
N and, in turn, of both M and N on Y, one can calculate the full causal effect of
D on Y by combining these causal effect estimates. Pearl (2009:83) gives the general
estimation formula in the underlying probability distributions. For the ATE, the sim-
plest case that is also consistent with the structure of Figure 10.3 is one where (1) D
is a binary variable, (2) M, N, and Y are interval-scaled variables, (3) all structural
equationsarelinearandadditive,e.g.,Y =fY(M,N,eY)=aY +bMM+bNN+eY,and
(4) all individual-level causal effects do not vary in the levels of the variables in the
mechanism.Inthis case,theATEcanbeestimatedconsistentlybyasumofproducts,
(cid:16) (cid:17) (cid:16) (cid:17)
ˆbD→M×ˆbM→Y + ˆbD→N×ˆbN→Y ,
where ˆbD→M is the estimated coefficient for M in a bivariate regression of Y on M,
ˆbD→N istheestimatedcoefficientforN inabivariateregressionofY onN,andˆbM→Y
and ˆbN→Y are the estimated coefficients for M and N for a multiple regression of Y
on M, N, and D.6
Asshownbythisexample,thefront-dooridentificationstrategycanbeverysimple,
asit involvesnothing morethana straightforwardtwo-stepconsiderationofthe back-
door criterion introduced in Chapter 4 (see our presentation beginning on page 109).

Pearlformalizesthis identificationstrategyby offeringa complementto his back-door
criterion, which he labels the front-door criterion (Pearl 2009:82):
Front-Door Criterion
If one or more unblocked back-door paths connect a causal variable to an
outcome variable, the causal effect is identified by conditioning on a set of
observed variables, {M}, that make up an identifying mechanism if
Condition1(exhaustiveness).Thevariablesintheset{M}inter-
cept all directed paths from the causal variable to the outcome
variable;
and
6Inthiscase,Pearl’sfront-dooradjustmentformulareducestothissumofproductsforthecausal
contrast he would label E(Y|do(D=1)−E(Y|do(D=0). When conditions (1) through (3) do not
obtain, the computation is more complex because one needs to propagate the effects through the
probability distributions of the mechanistic variables, conditional on the causal variable, and then
calculate average effects for the chosen contrast (see Pearl 2009). We omit these details because we
arefocusinginthischapter ontheessential identificationissues.

Condition 2 (isolation). No unblocked back-door paths connect
the causalvariabletothe variablesinthe set{M},andallback-
door paths from the variables in the set {M} to the outcome
variable can be blocked by conditioning on the causal variable.7
Noticethatthefront-doorcriteriondoesnotgivedirectguidanceonhowdeepaniden-
tifyingmechanismmustbeinordertoqualifyasasufficientlydeepcausalexplanation.

It only specifies the features that a mechanismmust have in order to be used to iden-
tifyanaverageeffectofacausalvariableonanoutcomevariable.Anysuchidentifying
mechanism can be considered shallow by the standards of a particular researchgroup
or field of interest. Before addressing this issue, we clarify in the remainder of this
section what the requirements of exhaustiveness and isolation entail.

The Assumptions That the Mechanism Is Exhaustive and Isolated
Thecrucialassumptionsofthisapproach,aswehavenotedalready,arethatthe iden-
tifying mechanism is exhaustive and isolated. To see the importance of isolation first,
consider the alternative graph presented in Figure 10.4. Here, the variable U is again
unobserved,andthustheback-doorpathD←U→Y cannotbeblockedbycondition-
ing on any observedvariablesin the graph.In this case,the variableM intercepts the
full causal effect of D on Y, and therefore the identifying mechanism is exhaustive,
satisfying Condition 1 of Pearl’s front-door criterion. However, the identifying mech-
anism M is not isolated because U has a direct causal effect on M. Corresponding
to both components of Condition 2 of the front-door criterion, two problems arise.

The causal effect U →M generates a new back-door path from M to Y, which is
M←U→Y, as well as a new back-door path from D and M, which is D←U→M.

Neither of the effects that compose the casual pathwayD→M→Y canbe estimated
consistently because no observed variables are available to block these new back-door
paths by conditioning. With reference to the structure of Pearl’s front-door criterion,
the problems are that (1) an unblocked back-door path connects the causal variable
to M (D←U →M) and (2) a back-door path from M to Y cannot be blocked by
conditioning on D (M←U→Y).

This example also shows what is crucial in the criterion of isolation. The mech-
anistic variables must be isolated from otherwise unblocked back-door paths so that
the back-door criterion can be applied in order to recover the full causal effect from
the data. For Figure 10.4, if U were an observed variable, then the back-door paths
D←U→M and M←U→Y could be blockedby conditioning on U. In this case, we
could then use the front-door criterion in a conditional variant, estimating the effect
of D on Y by estimating the effects D→M and then M →Y while conditioning
on U.

More generally, isolation comes in strong and weak forms, both of which are suffi-
cient. For the strong form, none of the variables that lie on back-door paths from D
7In our accounting of Pearl’s front-door criterion, we label his (i) as our Condition 1, which we
thencharacterizeasanexhaustivenesscondition.Wealsocombinehis(ii)and(iii)intoourCondition
2,whichwecharacterizeasisolation.

U
M Y
D
Figure10.4 AdirectedgraphinwhichM isnotanisolatedmechanismforthecausal
effect of D on Y.

to Y can have causal effects on the mechanistic variables, except indirectly through
directed paths that pass through D. For Figure 10.3, the only directed paths from U
that terminate at M and N pass through D. In this case, conditioning on D alone is
sufficient.Fortheweakform,someofthevariablesthatliealongback-doorpathsfrom
D to Y can have causal effects on the mechanistic variables through directed paths
that do not pass through D, but it must still be possible to block any relevant back-
doorpathsby conditioningonD and otherobservedvariablesinthe graph.Theweak
formofisolationmakesitclearthatonemustbeconcernedonlyaboutthedependence
of the variables in the mechanism on components of back-door paths between D and
Y that cannot be blocked by conditioning on observed variables.

An implication of the necessity of assuming isolation is that a very good under-
standingofthe back-doorpathsbetweenthe causalvariableandthe outcomevariable
is needed. If the isolation assumption cannot be maintained, then the mechanistic
variables are similarly affected by the same set of dependencies that invalidate basic
back-door conditioning as a strategy to identify the causal effect.

Now return to Condition 1 of the front-door criterion, which requires that the
identifying mechanism is exhaustive. For Figure 10.5(a), suppose, again, that there
is an unblocked back-door path and also two distinct causal pathways from D to Y,
which are represented by the two variables M and N. Finally, unlike for Figure 10.3,
suppose that N is unobserved.

In this case, the causal effects D→N and N→Y cannot be estimated, and thus
the full causaleffectofD onY cannotbe estimatedby front-doorconditioning.Ifone
were to asserta mistaken assumption that M is an identifying causal mechanism (for
example,bysubstitutingaback-doorpathD←N→Y forthegenuinecausalpathway
D→N →Y), then one can obtain a causal effect estimate. But the causal effect of
D on Y will then be underestimated (assuming all causal effects are linear, positive,
etc.) because the part of the causal effect generated by the pathway D→N →Y is
attributed to a mistakenly asserted back-door path D←N→Y.

Relaxing the Assumption That the Mechanism Is Exhaustive
FortheexampledepictedinFigure10.5(a),amechanism-basedempiricalanalysismay
stillbeusefulbecauseanisolatedpieceofthecausaleffectcanstillbeestimated.Even
though N is unobserved, the causal effect of D on M is identified by their observed
U U
M M
D Y D Y
N N
(a) The causal pathway via M is (b) The causal pathway via M is
identified even though N is not identified
unobserved
Figure10.5 Directed graphs in which one pathway in an exhaustive and isolated
mechanism is unobserved.

association because the back-door path from D to M, which is D←U →Y ←M, is
blockedbythecolliderY intheabsenceofanyconditioning.And,asbefore,thecausal
effect of M on Y is identified because both back-door paths from M to Y, which are
M←D←U→Y andM←D→N→Y,canbeblockedbyconditioningonD.Onecan
therebyobtainaconsistentestimateofthe causaleffectofM onY byconditioningon
D,whichguaranteesthatthepartofthecausaleffectthattravelsthroughthepathway
D→M→Y can be estimated consistently. This is an important result, especially for
practice,becauseidentifyingandconsistentlyestimatingadistinctcausalpathwaycan
be very useful, even if one cannot in the end offer a causal effect estimate of the full
effect of the causal variable on the outcome variable.8
KnightandWinship (2013:290–91)consider anexample with the structure of Fig-
ure 10.5(a) and where the populationof interest is womenin the paidlabor force. For
their example, D is whether or not women have children, M is the number of hours
per week worked in a paid job, N is the amount of bias in compensation practices
againstwomen with children, and Y is wagespaid to women. Evenif one cannot esti-
mate the effect of bias against women with children on wages received, being able to
estimatethewagedifferencesthatareattributabletothereductionofworkhoursthat
oftenresultsfromhavingchildrenmaybeimportanttoestablishthecaseforproviding
better childcare to support working women.

8Note, further, that one can then assess the portion of the total variation in D and Y that can
beattributedtothepathwaythroughM.Thiscalculationcanbeuseful,butitdoesnotidentifythe
amountofthecausaleffectthatisexplainedbyM.TheproblemisthattheassociationbetweenDand
Y that is notattributable toM cannot beapportioned acrossthe two unblocked paths D←U→Y
and D→N→Y. In addition, if the underlying structural equations are nonlinear, then additional
complicationsarisebecauseofthepossibilityofinherentinteractionsbetweenthecausalvariableand
mechanisticidentifyingvariablesintheproductionoftheoutcomevariables.Forfullexplanations of
these complications, see Pearl (2012a, 2012b), VanderWeele (2009b, 2012, in press), and Wang and
Sobel(2013).Wealsodiscussthesecomplicationsintheappendixtochapter11,whereweintroduce
aframeworkfordefiningandestimatingnetdirecteffects.

But,eventhoughthispartialestimationresultisveryuseful,thereisanimportant
implicitassumptionthatishiddenbythisexample:Variablesontheunobservedcausal
pathways cannot have direct or indirect causal effects on any of the variables that lie
along the observed causal pathways. To see the complications that such dependence
could produce, consider the graph in Figure 10.5(b). For this graph, the mechanism
is isolated, but the unobserved variable N has a causal effect on M. In this situation,
the effect of M on Y is not identified. Three back-door paths between M and Y are
still blocked by D: M←D←U→Y, M←D→N→Y, and M←N ←D←U →Y.

However, a fourth back-door path, M ←N →Y, cannot be blocked by conditioning
on D or any other observed variable. This path remains unblocked because its only
intermediatevariableN isunobservedandisnotacollider.Notonlyisitimpossibleto
estimatetheeffectofDontheunobservedvariableN,butthevariableN maytransmit
tobothM andY itsownexogenousvariationthatiscompletelyunrelatedtoDandU.

Without recognition of this outside source of dependence, one could mistakenly infer
that the causal pathway D→M→Y is much more powerful than it is (assuming all
causaleffectsarelinear,positive,etc.).KnightandWinship(2013:293)elaboratetheir
example,summarizedabove,toshowthisresultaswell.TheyallowunobservedbiasN
to affect work hours M. In this case, the analystcan no longer advocate for increased
childcare support by building support for the causal pathway D→M →Y because
the reductions in wages may all result from the direct effect of bias on wages and the
indirect effect of bias on wages through work hours (which could result either from
differential work assignments from biased supervisors or the protective withdrawalon
the part of working women who confront a hostile workplace).

As these simple graphs show, if one wants to use a mechanism-based strategy
to identify the full effect of a causal variable on an outcome variable, one must put
forwardanidentifying mechanismthat is exhaustiveandisolated.The exhaustiveness
requirement can be relaxed if one is satisfied with identifying only part of the causal
effect of interest. But, to secure partial estimation of this form, one must be willing
to assume that the observed portion of the mechanism is not affected by any of the
variablesinthe unobservedportionofthe mechanism.And,toassertthisassumption,
onetypicallyneedstohaveaveryspecifictheoreticalmodelofthecompleteidentifying
mechanism, even though parts of it remain unobserved.

In sum, Pearl’s front-door criterion represents a powerful and original set of ideas
that clarifies the extent to which a mechanism, composed of one or more intervening
variables, can be used to identify and estimate a causal effect. And, by approaching
the causalinference predicamentfromthe inside out, the approachhelps to shape the
question of whether a causal claim qualifies as a sufficiently deep explanation. Rather
thanestimatingacausaleffectbyback-doorconditioningorwithanaturallyoccurring
experimentand then wonderingwhether a mechanismcanbe elaboratedto show how
the effect comesabout, Pearlinsteadshowsthat, if we canagreeonthe variablesthat
constitute an exhaustive and isolated mechanism, then we can estimate the causal
effect from its component causal pathways.

The approach cannot be taken out of context, though, lest one claim too much
explanatory power for a nonexhaustive and/or nonisolated mechanism. And, at the
same time, it must be acknowledged that even a front-door-identified causal effect
may not be explained deeply enough by the exhaustive and isolated mechanism that
identifies it, for any such mechanism may still be too shallow for a particular sub-
stantive area. To consider these issues further, we now turn to recent social scientific
writing on mechanisms, wherein the connections among theory construction, genera-
tive mechanisms, and modes of explanation have been carefully examined.

## 10.3 The Appeal for Generative Mechanisms

To some extentinspiredby the workofJonElster(e.g., Elster1989),butmore gener-

ally by their readingof pastsuccessesand failures in explanatoryinquiry inthe social
sciences since the 1940s, Peter Hedstr¨om and Richard Swedberg convened a group of
leading scholars to discuss a reorientation of explanatory practices in the social sci-
ences. A collection of papers was then published in 1998 as Social Mechanisms: An
Analytical Approach to Social Theory. At the same time, John Goldthorpe developed
his case for grounding all causal modeling in the social sciences on the elaboration of
generative mechanisms. His proposal was published in 2001 as “Causation, Statistics,
andSociology,”whichthenreceivedcommentsfromavarietyofscholars,includingthe
statisticiansDavidCoxandNannyWermuth(whoseresponsewewilldiscussbelow).9
Subsequently, Peter Hedstr¨om laid out in considerable detail his full program for a
mechanism-basedsocialscienceinhis2005book,Dissectingthe Social: On the Princi-
ples of Analytical Sociology. Along withPeterBearman,Hedstr¨omthen compiledThe
Oxford Handbook on Analytical Sociology, which is a collective effort to demonstrate
the power of this approach (Hedstr¨om and Bearman 2009). To orient the reader to
thispushformechanism-basedsocialscience,wewillfirstpresenttheslightlydifferent
proposals of Goldthorpe (2001) and then Hedstr¨om (2005).10
9Goldthorpe’s argument wasrepublishedasachapter inboth thefirstandsecond editions ofhis
programmaticcollection,OnSociology (e.g.,Goldthorpe2007,vol1.,ch.9).Ourcitationsaretothe
original2001journalarticle.

10Wewillnottracethefullhistoryofmechanistictheorizinginthesocialsciences,asthepiecesjust
cited cover much of the same territory (see also Hedstro¨m and Ylikoski 2010; Knight and Winship
2013). However, it does seem to us that the novelty of recent mechanism-based theorizing has been
oversold at least a bit. At the same time that Kendall and Lazarsfeld were directing researchers to
buildmechanisticinterpretations ofcausal effects inempiricalresearch,whileholdingupStouffer as
a successful practitioner, mechanism-based modes of conjecturing were widespreadamong theorists.

Hedstro¨mandUdehn(2009)lionizeRobertMerton’sproposalforthepursuitofmiddle-rangetheory,
whichtheyargueisimplicitlymechanism-based.Likemanyothers,theycontrastMerton’sworkwith
the“grand”system-leveltheoreticalprogramofTalcottParsons.ButevenParsonswrotefrequentlyof
mechanisms,includingthoseforsocialization,socialcontrol,andtheequilibrationofthesocialsystem
(see Parsons 1951, chapters 6 and 7). As an example, Parsons (1951:206) wrote, “A mechanism
of social control, then, is a motivational process in one or more individual actors which tends to
counteractatendencytodeviancefromthefulfillmentofrole-expectations,inhimselforinoneormore
alters. It is a re-equilibrating mechanism.” Explaining his usage of the term “mechanism,” Parsons
(1951:22) wrote,“Motivational dynamicsinsociologicaltheory, then,musttaketheforminthefirst
instance of the formulationof mechanisms which ‘account for’ the functioning of social systems, for
the maintenance or breakdown of given structural patterns, for a typical process of transition from
one structural pattern to another. Such a mechanism is always an empirical generalization about
the operation of motivational ‘forces’ under the conditions stated.” It is clear from this work that
Parsons saw mechanistic theorizing as a way to develop the sort of conjectures that Craver (2007)
wouldregardas“how-possible”or“how-plausible”modelsandthatHedstro¨mandBearman(2009:7)
label “semigeneral mechanisms.” It is also clear that Parsons’ mechanisms came to be regarded as
insufficientlydeepbysubsequentsociologists.Indeed,agreatdealoftheempiricalworkthathasbeen
Goldthorpedevelopshisproposalbyfirstattemptingtodriveawedgebetweenthe
counterfactualmodel,whichhelabels “causationasconsequentialmanipulation,”and
his alternative mechanistic model of causality. To develop his argument, he advances
the claim that the counterfactual model is irretrievably tied to actual experimental
manipulationsofcausalvariables.Goldthorpe(2001:6)writes,“thecruxofthematter
is of course the insistence of Rubin, Holland, and others that causes must be manipu-
lable, and their unwillingness to allow causal significance to be accorded to variables
that are not manipulable, at least in principle.”11 (See our discussion of this issue in
Chapter 13, in which we present the positions of Woodward (2003) and others that
this argument is incorrect.) Goldthorpe also argues, citing the work of statisticians
Cox and Wermuth (1996; also Cox 1992), that the counterfactual model too easily
settles for causalclaims ofinsufficient depth thatdo notaccountfor how causes bring
abouttheireffects(apointthatisclearlysupportedbyourpresentationofthenatural
experiment literature discussed earlier in this chapter).

With this criticism of the counterfactual model in mind, Goldthorpe writes:
The approach to causal analysis that is here proposed ... is presented in
the form of a three phase sequence: (i) establishing the phenomena that
formtheexplananda; (ii)hypothesizinggenerativeprocessesatthe levelof
social action; and (iii) testing the hypotheses. (Goldthorpe 2001:10)
Goldthorpe then proceeds to lay out the basic contours of the first two steps, arguing
thatthemostusefulmechanismsinthesocialsciencesarethosethatarebasedonratio-
nal choice theory (because these are sufficiently microscopic and focus on the actions
and beliefs of individuals). He then explicates the third step of his approach,which is
hisrequirementthatonemusttesthypothesessuggestedbythegenerativemechanism
that one has proposed.12 And here, he takes the position that generative processes
of the sort that he prefers, which are “specified at a ‘deeper,’ or ‘more microscopic’
level, thanthat of the data that constitute the explananda” (15), canalmostnever be
directly evaluated. Instead, Goldthorpe advises that analysts spend their effort deter-
mining whether the hypothesized generative mechanisms can be indirectly supported
throughrepeatedvalidationofentailedhypotheses.Theseentailedhypothesesmaybe
atthe levelofthe “microscopic”mechanism,aswouldbethe caseforconjecturedpat-
ternsamongcorrelatesoftheunobservedtruepreferencesandmicro-interactionsthat,
publishedsincethe1950scanbeinterpretedasattemptstodeepenthemechanisticclaimsthatwere
overlyabundant intheworkofParsons,Merton,andotherscholarsoftheirera.

11It is unclear from this passage what Goldthorpe means by “inprinciple.”However, on the next
page of the article, he offers an example that reveals that his conception of a manipulation can
be very narrow. Following an example of Holland (1986), he introduces mechanistic variables and
arguesthatinsodoinghehasproducedacausalnarrativethathasnothingtodowithhypothetical
manipulations/interventions and hence cannot be represented in a counterfactual framework. The
argumentseems to bethat themechanistic variables arenonmanipulable because they aretypically
voluntarydecisionsofanindividual.

12Byourreading,Goldthorpe endsupbackatthecounterfactual modelatthispoint. Hisdefense
againstsuchareadingisthis:“whileitmightseemthat,atthisstage,attentiondoesafterallcometo
focusontheeffectsof–given–causesratherthanonthecausesofeffects,thisiswithinthecontext
notofrandomizedexperimentaldesignbutof(whatshouldbe)atheoreticallyinformedaccountofa
generativeprocessthatissubjecttoongoingevaluation.”(Goldthorpe2001:13)
accordingtothehypothesizedgenerativemechanism,determinetheactionthatgener-
ates the outcome. More realistically, these entailed hypotheses would be at the higher
level where data are available on the outcome of interest, as would be the case when
analyzing conjectured patterns of the outcome itself at the population level(based on
further assumptions about how the generative mechanism produces a distribution of
outcomesacrosssubgroupsthatcanbeidentifiedbytheirmeasuredcharacteristics).13
Considernowthemoreextendedappealformechanism-basedsocialscienceoffered
by Peter Hedstr¨om (2005). Unlike Goldthorpe, Hedstr¨om does not confront the coun-
terfactual causalityliterature directly. He instead develops an argumentthat suggests
the following orienting principle: “The core idea behind the mechanism approach is
that we explain not by evoking universal laws, or by identifying statistically relevant
factors, but by specifying mechanisms that show how phenomena are brought about”
(Hedstro¨m 2005:24). Hedstr¨om arrives at this position from two different directions.

First, he signs on to the dominant position in the philosophy of science that the
best explanation of how a phenomenon is brought about must necessarily be a causal
accountofsomeformthatdoesnotrelyonunrealisticpresuppositionsoftheexistence
of invariant general (or covering) laws (see Hedstr¨om 2005:15–20). But he also jus-
tifies the principle by criticizing regression-based causal models in social science (see
Hedstr¨om 2005:20–23):
Suchstatisticalanalysisisoftendescribedasaformof“causalanalysis.”If
a factor appears to be systematically related to the expected value or the
conditional probability of the outcome, then the factor is often referred to
as a (probabilistic) “cause” of the outcome. Although it makes little sense
to quibble over words, I would like to reserve the word cause for a less
casual notion of causality. (Hedstr¨om 2005:23)
Like Goldthorpe, Hedstro¨m also lays out a script for the construction of mecha-
nisms, which is similar in its appeal to the principles of methodological individualism
(although he steps back from Goldthorpe’s stronger preference for forms of rational
choice theory). Most importantly, Hedstro¨m does not advocate the testing of mecha-
nisms in the way that Goldthorpe does. Instead, he defends the explanatory utility of
mechanisms in a much more general way:
Mechanismsshouldbeseenastheoreticalpropositionsaboutcausaltenden-
cies,not as statements about actualities. An explanationmay be perfectly
13Blossfeld (2009) aims to build on Goldthorpe’s orienting program and argues for the centrality
of event history processes in generating relationships that can be interpreted as causal. Blossfeld
(2009:101) writes, “We can only hope to make sensible causal statements about how a given or
(hypothesized) change in variable Y tA (e.g., pregnancy/birth) in the past affects the probability of
a change in variable Y tB (cid:2) (e.g., marriage) in the future. Correspondingly, the basic causal relation
becomes:ΔY tA→ΔPr(Y tB (cid:2)),(t<t(cid:3)).Inotherwords,achangeinthetime-dependentcovariateY tAwill
changetheprobabilitythatthedependentvariableY tB willchangeinthefuture(t<t(cid:3)).”IfBlossfeld’s
(cid:2)
“given or (hypothesized)” distinction can be interpreted as consistent with potential outcomes tied
to the states A and not-A, then this is simply a restatement of the potential outcome definition of
acausal effect. Ifnot, andthisdefinition ismeanttodispensewithcounterfactual dependence, then
the only “causal relations” that are well defined for Blossfeld are those between values of observed
variablesthatchangeintimeduringtheobservationwindow.Ifitisthelatter,thenthisisjustthesort
ofrobustdependencerelationshiprejectedbyGoldthorpe(andBlossfeld),althoughnowexpressedas
arobust-dependence-in-timeperspective.

correct if understood as a proposition about a causal tendency, and yet
it may be inadequate for predicting actual outcomes if other processes are
alsoatwork....Sinceitistheruleratherthantheexceptionthatconcretely
observed phenomena are influenced by several different processes, testing
a theory by examining the accuracy of its predictions is likely to conflate
thetruthorrelevanceofthepostulatedmechanismwiththeimportanceof
other processes,andthis may leadus to mistakenly rejectperfectly appro-
priate causal accounts. (Hedstr¨om 2005:108)
What,then,istheexplanatorystatusofmechanismsthatare“theoreticalpropositions
about causal tendencies”? Here, Hedstro¨m seems to argue three basic points: (1) The
best explanations are causal accounts; (2) causal accounts must include mechanisms;
(3) mechanisms may or may not explain actualities. The direct implication of this
position is that the best explanations in social science do not necessarily have to
explain actualities, but they must explain causal tendencies.14
In our view, Goldthorpe and Hedstr¨om have developed a wonderful appeal for the
need to construct sufficiently deep theories of social processes. Their work is filled
with much insight on a variety of promising ways to formulate plausible theoretical
mechanisms. And they have helped to further convince many social scientists that
specifying the socialprocesses that accountfor how causes bring about their effects is
acentralgoalofanalysis.Itisthereforeunsurprisingthatthisnewwaveofscholarship
has inspired a scholarlymovementof sorts, which we and many others regardas both
promising and very healthy for theory construction in the social sciences.15
But, to be seen as blueprints for explanatory causal analysis, both of these par-
ticular perspectives need to be augmented. And we would argue that they can be
usefully extended by embracing the counterfactualmodel of causality more directly.16
We explain this position in the remainder of this section, first by offering a slightly
14Itisunclearfromtheforegoingpassagewhattheproblematic“otherprocesses”aremeanttobe.

Clearly,theymustcomeintwodifferentforms:(1)othermechanismsthatarecompletelyindependent
of the postulated mechanism of primary interest and (2) other mechanisms that interact with the
postulated mechanism of primary interest. If one is estimating the effects of a cause, it is only the
latter that areproblematicforthe evaluation of mechanisms,and hence forthe evaluation ofcausal
accounts based on mechanisms. See our earlier discussion of partial identification by the front-door
criterion.

15Butwearesomewhatmoretraditionalinfavoringmechanismsthatareformalmodels,asweare
lessconvincedoftheutilityofmanysimulation-basedmethodsoftheoryconstruction;seeHedstr¨om
(2005:76–87, 131–36, 149) on the appeal of such techniques. We agree with Humphreys’ (2004:132)
caution: “Agent-based modelsareapowerfuladditiontothearmoryofsocialscientists, butaswith
any black-box computational procedures, the illusion of understanding is all too easy to generate.”
Scholars suchas Manzo (2011) disagree sharplywith this position, andwe welcomeefforts that will
convinceustochangeourposition.

16Inmorerecentwork, Hedstro¨m andUdehn (2009:42) writethat the mechanism-based approach
to social science “should not necessarily be seen as an alternative to the counterfactual approach,
but rather as adding further requirements. As emphasized by Woodward (2002) and Morgan and
Winship (2007) there is nothing in the counterfactual approach as such which guarantees sufficient
causal depth, because perceptions of sufficient depth are discipline-specific while the counterfactual
approachisnot.”Weassumethatthereferencehereistotheargumentthatweofferedinthischapter
inthefirsteditionofthisbook.

differentreadingofrecentdevelopmentsin the philosophyof scienceandthen by rais-
ing the issue of how social scientists can retain the capacity to adjudicate between
competing mechanistic accounts of causal effects.

Philosophy of Science and Explanation by Mechanisms
Aswenotedatthebeginningofthischapter,theappealtomechanismsaselaborations
of causal claims has been entrenched in the sociological literature for many decades,
and we suspect that this emphasis is true of all of the social sciences. Where perhaps
thefocusongenerativemechanismsisnewisintheproposedelevationoftheirstatusto
theobjectofprimaryinvestigation.Thiselevationisnotunrelatedtoshiftingcurrents
in the philosophy of science.

Someproponentsofamechanism-basedsocialsciencehavedrawninspirationfrom
the demise of covering law models of explanation in the philosophy of science (e.g.,
Gorski 2004; Hedstr¨om 2005). The covering law model, as most famously explicated
by Carl Hempel, maintains that all valid explanations can be formulated as logico-
deductive entailment from invariant general laws.17 Since 1970 at least, the covering
law model has received near-continuous challenges to its basic premises (see Godfrey-
Smith 2003; Salmon 1989; and Woodward 2003). The presupposition that general
and exceptionless laws exist and that they can be used to warrant all valid causal
claimscannotbesustainedinmostscientificdisciplines,andcertainlynotinthesocial
sciences.

In response, a variety of alternative models of scientific explanation have arisen,
with realist models attracting the largest number of adherents (see Psillos 1999). In
general, realist models grant ontological status to unobserved quantities (sometimes
conferringprovisionaltruthstatusonthem).Mostrealistmodelsrejectcausalnihilism
and affirm that valid scientific explanation must necessarily be grounded in causal
accounts of some form. Especially when invoked for the social sciences, realist models
admitthe possibilityofinherentheterogeneityofcausalrelationships–intime, space,
and within populations. But the depth of the appeal to unobservables varies across
types of realist models, as does the level of provisional truth status conferred upon
unobservables.

What we wish to emphasize in this section is how uneasily the focus ongenerative
mechanisms sits within this new terrain, especially when seen as a call for the con-
struction of mechanisms that explain only causal tendencies rather than observable
actualities.Aswehavejustnoted,theappealformechanisticexplanationinthesocial
sciences is attractive partly because it is claimed that it does not rest on the exis-
tence of general laws. But some philosophers who endorse the mechanisms position
disagree with this claim, arguing that laws are still essential, perhaps even consti-
tuting the defining characteristic of what a mechanism is. For example, after having
written on the role of mechanisms in scientific explanation for several decades, Mario
17Wedonotattempttogiveafullsummaryofthefallofcoveringlawmodels,asmanyaccessible
textsexistinphilosophy(seecitationsinthemaintext)andothersthatarewrittenforsocialscientists
alone(e.g.,Gorski2004;Hedstro¨m2005).Nordowegiveafullexplicationofthevarietyofpositions
thathavereplacedthecoveringlawmodel,asthesetooarewellsummarizedelsewhere(seecitations
in the main text for realist models in particular, as well as the variety of naturalist positions that
contend withthem).

Bunge (2004:207)concluded, “No law, no possible mechanism; and no mechanism, no
explanation.”18
Hedstr¨om (2005) considers this complication carefully, and he emphasizes that his
mechanism-based approach to explanation is less reliant on invariant laws than the
covering law models that he rejects. This position is certainly correct, but one must
still consider how to grapple with what seem to be three fairly common declarative
statements on the relationships between laws and mechanisms: (1) invariant covering
laws do not exist, (2) mechanisms depend to some degree on the existence of laws
that are weaker than general, invariant laws, (3) mechanisms are nested within each
other. Accepting all three statements seems to delimit laws to the smallest possible
configuration within each level of a set of nested mechanisms.

Ifamechanismisdesignedtoexplainhowanactualitycomesabout,thenallseems
to be fine with this perspective.19 But if one instead maintains, as does Hedstro¨m
(2005), that mechanisms are the key to the explanation of causal tendencies only –
suchthatthevalidityofamechanismcannotbeunderminedbyitsinabilitytoexplain
anything in particular – then this line of thought leads all too easily to the critical
realist perspective on mechanisms. We suspect that most empirical social scientists
wouldfind critical realismuninspiring. Critical realism’spioneer, Roy Bhaskar,writes
with regardto mechanisms:
Theworldconsistsofmechanismsnotevents.Suchmechanismscombineto
generate the flux of phenomena that constitute the actual states and hap-
penings of the world. They may be saidto be real, though it is rarelythat
they are actually manifest and rarer still that they are empirically identi-
fied by men. They are the intransitive objects of scientific theory. They
are quite independent of men – as thinkers, causal agents and perceivers.

They are not unknowable though knowledge of them depends upon a rare
blending of intellectual, practico-technical and perceptual skills. They are
notartificialconstructs.But neither arethey Platonicforms.Forthey can
become manifest to men in experience. Thus we are not imprisoned in
caves,eitherofourownorofnature’smaking.Wearenotdoomedtoigno-
rance. But neither are we spontaneously free. This is the arduous task of
science:theproductionoftheknowledgeofthoseenduringandcontinually
active mechanisms of nature that produce the phenomena of the world.

(Bhaskar 1998[1997]:34–35)
If the social sciences sign on to the idea that mechanisms are general and transcen-
dentally valid explanations that may not explain any actualities or particularities, we
will be led inevitably to a fundamental premise of critical realism: The mechanisms
that constitute causal explanations are irreducible, even if they are nested in each
18Given Bunge’s position, one then necessarily wonders, How does one discover these crucial
explanatory mechanisms? Bunge’s (2004:200) guidance is this: “Thereis no method, letalone logic,
for conjecturing mechanisms. True, Peirce wrote about the ‘method of abduction,’ but ‘abduction’
issynonymous with‘conjecturing,’ and this – as Peirce himselfwarned – isan art, not atechnique.

Onereasonisthat, typically,mechanismsareunobservable, andthereforetheirdescriptionisbound
tocontainconcepts thatdonotoccurinempiricaldata.”
19Asbestwecantell,Woodward(2003,section4.6)takesthisposition,notingtheneedforonlya
ratherlimited“backing”relationshipbetweencausalclaimsandlaws.

other. This position is summarized by Andrew Collier (2005:335): “Critical realism
defends the idea that reality is many-layered,and each level has its own kind of laws,
irreducible to those of any other layer.”
For the social sciences, one might argue that such an irreducibility presumption
couldbe unifying inoffering protectionagainstincursionsfrombiology andphysics.20
But, if accepted, it would undermine the work of social scientists who have at least
some interest in developing causal claims that unite levels of analysis. If irreducibility
wereaccepted,howthencouldmethodologicalindividualistssuchasGoldthorpecriti-
cize those whoseek todevelopmacrolevelcausalclaimswith onlyminimally sufficient
reliance onproximateactors andinstitutions (e.g., Alexander 2003)?21 Gorski(2004),
for example, lays out a constructive realist model of explanation, built up from the
causal process perspective of Wesley Salmon’s early work, that is completely at odds
with the perspective of Goldthorpe (2007).22 But Goldthorpe (2007, chapter 2) ques-
tions the explanatory utility of all secondhand historical analysis, in essence rejecting
the capacity of historical analysis, as practiced in sociology, to sustain causal claims
ofany form. IfGoldthorpe wereto signonto irreducibility, whichwe doubt he would,
he could not thereby criticize macrosocial claims of causal relationships.

Giventhattheseextremepositionsonmechanismsinthe philosophyofscience are
likelytobeunhelpfultopracticingsocialscientists,andgiventhatHedstro¨mandothers
in the generative mechanisms movement seem to agree (see Hedstr¨om 2005:70–74),
which type of philosophy of science gives the appropriate backing for causal analysis?
Ifanything,itisthephilosophicalwritingonthecounterfactualmodelthatprovidesa
solid and pragmatic foundation, as best representedfor the causal modeling tradition
by Woodward (2003). The key to understanding why this is the case is to consider
alternative ways to adjudicate between the rival mechanisms proposed by alternative
investigators, which we turn to next.

Adjudication Between Rival Mechanisms
Imagine that social scientist A and social scientist B have proposed distinct mecha-
nisms for how X brings about Y. How do they determine whose mechanism is sup-
ported? According to Goldthorpe (2001, 2007), each scholar is expected to derive
entailedhypotheses,typicallyindirect, andtestthem with data.One mighthope that
scholars A and B will be able to agree on a clear critical test that could tip the scales
in favor of one mechanism or the other. Unfortunately, the mechanisms of the two
20Ofcourse,nontranscendental protectionisavailableaswell,asweexplainbelowwhendiscussing
thenotionof“bottomingout”inmechanisticexplanation.EvenStrevens(2008:472),whiledefending
reducibility to fundamental physics, can concede that many lower-level details may be suppressed
whentheyplaynoroleinproducingtheoutcomeofinterest.

21Methodological individualism is the basic position of Goldthorpe (2001, 2007) and Hedstro¨m
(2005),asinfluencedheavilybythescholarshipofRaymondBoudon(seeBoudon1998andcitations
therein).

22Gorski (2004) endorses the causal process model of Wesley Salmon, as developed in Salmon’s
work from the 1970s and early 1980s (see Salmon 1984). Given the ways in which Salmon’s work
developedlaterinhiscareer,turningcompletelytowardcausalmechanicalideasbasedonthenotion
ofconservedquantities,hisupdatedideasseemcompletelyirrelevanttowhatwetaketobeGorski’s
main position: “Social science is ‘nothing but history.’ The real error was ever to think it could be
anythingmore”(Gorski2004:30;emphasisinoriginal).

scholarsmaybe sodifferentthatnosuchcriticaltestcanbederivedandagreedon(as
wouldoften be the case if scholar A is a sociologistand scholarB is an economist, for
example).If no suchagreementcanbe found, the two scholarsmay end up expending
effort seeking to affirm their own entailed indirect hypotheses, producing results that
are then regarded as irrelevant by each other.

Consider the reaction that Goldthorpe’s proposal elicited from the statisticians
David Cox and Nanny Wermuth, whose prior work Goldthorpe had used to develop
his proposal:
Goldthorpe (2001) has argued for this ... view of causality as the appro-
priate one for sociology with explanation via rational choice theory as an
importantrouteforinterpretation.Tobesatisfactorythereneedstobeevi-
dence,typicallyarisingfromstudiesofdifferentkinds,thatsuchgenerating
processes are not merely hypothesized. Causality is not to be established
by merely calling a statistical model causal. (Cox and Wermuth 2001:69)
By our interpretation, Cox and Wermuth take the position that generative mecha-
nisms must be directly evaluated, not evaluated only by indirect entailed hypotheses.

Anything shortof this analysis strategy could resultin a flourishing of mechanisms in
the social sciences, without an attendant sense of which ones have sufficient empirical
support to command attention.

The alternative to any such mechanism anarchy could be even worse: mechanism
warlordism.The mechanisms of the most industrious scholars – those who can dream
up the largest number of hypotheses to affirm, who can recruit the largest number
of students to do the same, and who can attract the largest amount of funding to
collect the data on their hypotheses – could receive the most affirmation. The only
defense for out-of-favormechanisms might then be to appeal to the hidden structures
of alternativemechanisms, which one would be tempted to claim cannot be evaluated
because of a lack of data.

Insum,thegenerativemechanismsmovementinthesocialsciencesisanadmirable
call for theory construction.23 The appeal for finely articulated “semigeneral” mech-
anisms to fill the toolkit of social theory (see Hedstr¨om and Bearman 2009:6–7) is
consistent with the appeal to forms of abduction that generate what Craver (2007)
has labeled “how-possibly” and “how-plausibly” models:
How-possiblymodels areoftenheuristicallyusefulinconstructingandexplor-
ing the space of possible mechanisms, but they are not adequate explana-
tions. How-actually models, in contrast, describe real components, activi-
ties, and organizational features of the mechanism that in fact produces
the phenomenon.Betweenthese extremes is a rangeof how-plausibly mod-
els that are more or less consistent with the known constraints on the
components,theiractivities,andtheirorganization.(Craver2007:111–12).

We see the generative mechanisms movement as a call for the construction of how-
possibleandhow-plausiblemodels.Suchactivityis worthwhileinits ownright,andit
23Infact,thefirstauthorfounditconvincingandinspiringwhenwritingMorgan(2005).

mayhelptoinformempiricalresearch.Weseecausalanalysis,incontrast,asadirected
effort to evaluate the support for specific claims implied by how-actually models.

Finally,aslongasthegenerativemechanismsmovementdoesnotvergeintocritical-
realisttranscendentalismin the future, it will remaina veryuseful callfor the pursuit
of sufficiently deep causal accounts. An elegant mechanism, if how-plausible, may be
a crucial stepforwardin convincinga fieldthat anaccepted causalclaimis supported
by an underlying mechanistic account that should be seen as too shallow. Thus, even
though theory construction is not causal analysis, theory construction may help to
establish our goals for explanatory depth. We take the position that genuine causal
depth must be secured by empirical analysis, and that such analysis is often best
grounded on the counterfactual model. In the next section, we work our way back
to Pearl’s front-door criterion, after introducing a language of mechanism sketches
and mechanism schemas that is helpful for classifying alternative representations of
mechanisms.

## 10.4 The Pursuit of Explanation with Mechanisms That Bottom Out

Amid the resurgence of writing on mechanisms, we find one statement more help-

ful than many others, the 2000 article “Thinking About Mechanisms” written by
Machamer, Darden, and Craver and published in Philosophy of Science. In their arti-
cle, Machamer, Darden, and Craver develop two particularly helpful lines of thought:
(1) the distinctions between a fully articulated mechanism, a mechanism sketch, and
a mechanism schema, and (2) the process of “bottoming out” in mechanistic model
building and subsequent explanation. To develop these concepts, Machamer et al.

(2000:12) first note that “in a complete description of [a] mechanism, there are no
gapsthatleavespecificstepsunintelligible;theprocessasawholeisrenderedintelligi-
bleintermsofentitiesandactivitiesthatareacceptabletoafieldatatime.”Butthey
thenexplainthatexplanatoryinquiryusingmechanismsisnotanall-or-nothingaffair,
inwhicheverystepisalwaysspecified.Variabilityintherepresentationofmechanisms
is possible because
mechanisms occur in nested hierarchies. ... The levels in these hierarchies
should be thought of as part-whole hierarchies with the additional restric-
tion that lower level entities, properties, and activities are components in
mechanisms that produce higher level phenomena....” (Machamer et al.

2000:13)
In spite of such nesting, there is a natural bottoming out of mechanism-based expla-
nations:
Nestedhierarchicaldescriptionsofmechanismstypicallybottomout inlow-
estlevel mechanisms.These are the components that are acceptedas rela-
tivelyfundamentalortakentobeunproblematicforthepurposesofagiven
scientist,researchgroup,orfield.Bottomingoutisrelative:Differenttypes
of entities and activities are where a given field stops when constructing
mechanisms. The explanation comes to an end, and description of lower-
level mechanisms would be irrelevant to their interests. (Machamer et al.

2000:13)
Then, by thinking through the complexity of the nesting of mechanisms, and how
scholars represent mechanisms to each other, they develop two related concepts. A
mechanism schema is a representation of a mechanism in which some known details
(or known nested levels) are suppressed for the sake of simplicity. Or, as Machamer
et al. (2000:15) state, “a mechanism schema is a truncated abstract description of a
mechanism that can be filled with descriptions of known component parts and activi-
ties.” In contrast, a mechanism sketch is quite different:
A sketch is an abstraction for which bottom out entities and activities
cannot (yet) be supplied or which contains gaps in its stages.The produc-
tive continuity from one stage to the next has missing pieces, black boxes,
which we do not yet know how to fill in. A sketch thus serves to indicate
whatfurther workneedsto be done inorderto havea mechanismschema.

Sometimes a sketch has to be abandoned in the light of new findings. In
othercasesitmaybecome aschema,servingasanabstractionthatcanbe
instantiated as needed. (Machamer et al. 2000:18)
Within this framework, one can conceive of causal analysis in the social sciences as
the pursuit of explanations that bottom out.24 Although there will inevitably be dif-
ferences of opinion on how deep an explanation must be to bottom out, it would
seemuncontroversialto state that a validexplanationthatinvokesamechanismmust
bottom out at least as far as the observables in the data at hand.25
This position, although we think it uncontroversial, is still not specific enough
for our tastes. In the remainder of this section, we discuss two entangled issues:
(1) when deep accounts cannot be provided because nominal causal states are too
coarselydefinedand(2)howthe pursuitofdeepcausalaccountsshouldproceedwhen
the specification of causal states will allow it.

Coarse Causal States Impede the Pursuit of Causal Depth. When we
introduced in Section 2.1 the causal states that define potential outcomes, we took
the position that causal states should be finely articulated and motivate comparisons
that are local and reasonable. We also noted, in the subsection beginning on page 39,
24See alsothe discussions of modularityinWoodward (2003, chapter 7) and Knight and Winship
(2013).

25Acriticalrealistcouldescapefromthispositioninavarietyofways:assertingirreducibilityand
transcendentalismandthen,morespecifically,byarguingintheendthatthedatathatoneisforced
to consider are but a poor reflection of the phenomena that the mechanism truly does explain. For
allofthesereasons,thelackofobservedexplanatorypowerforobservedeventswouldthenbeargued
tobeuntroubling.Thisposition,however,thenbecomes avariantofanappeal toahiddenbutpre-
supposed valid underlyingstructure, which Woodward convincingly argues cannot be anacceptable
explanatory strategy for any field that hopes to resolve its explanatory controversies because “the
appealtohiddenstructuremakesittooeasytoprotectone’sfavoredtheoryofexplanationfromgen-
uinecounterexamples” (Woodward2003:175). Moreover,iftheparticularitiesinthedataaremerely
a poor reflection of the phenomenon that the mechanism is supposed to explain, then presumably
whatever generates the mismatch can be encoded in the mechanism that explains both the genuine
phenomenonofinterestandtheprocessthatgenerates themisleadingdata.

that we see value in regarding each state of each treatment as a nominal state with
constitutivefeatures(e.g.,entities,activities,andrelations)thatarejointlycapableof
producingtheoutcomeofinterest.Wethenprovidedexampleswherethecausalstates
are composed of constitutive features. For example, the types of schools that define
the causal states for many of the examples in this book are composed of teachers,
classrooms, curricula, administrators, normative environments, affiliated institutions,
and networks of peers and parents. We maintained that causal effects can still be
defined with reference to these nominal states because we can conceive of differences
in outcomes that would result from alternative exposure in toto to the constitutive
features of each nominal state.

We will not repeat the pragmatism-based argument of Section 2.1 here, but the
discussionthereendsonacrucialquestionrelevanthere.Afterpresenting,asanexam-
ple, the literature that has focused on the particular features that may give Catholic
schools an advantage in the production of learning, we asked what should be made
of any such lower-level causal claims. More generally, we asked: When should nom-
inal causal states be decomposed into component causal states in pursuit of more
finely articulatedcausalexplanations?If Catholicschoolsandpublic schoolsareto be
regarded as alternative nominal causal states relative to each other, and yet one has
somebasisforclaimingthatCatholicschoolsproducealearningadvantagebecause of
a greaterendowmentof one particularconstitutive feature – dense parental networks,
forexample–thenshouldwedispensewiththe nominalcausalstatesandredefinethe
research question solely to enable an examination of this particular feature?
Ifinterestexistsinunderstandingwhatreallywouldhappenifweexposedindividu-
alstoalternativenominalcausalstates,thenthisinterestaloneissufficientjustification
for not doing so. Many policy evaluation studies take this position. Investigatorsmay
not be able to discern which particular features of an intervention program are effec-
tive, but they still want to know whether the program, altogether, has an effect on
average, and, furthermore, whether that effect varies across types of individuals who
could be exposed to it. More generally, when nominal causal states are composed of
many constitutive features, only some of which contribute to the production of the
outcome,therelevantscholarlycommunitymayrecognizethatonlyshalloweffectsare
feasible toestimate. Ifdataarenotavailableto analyzeall ofthe constitutivefeatures
–eithertoassesstheirautonomouscausalcapacitiesortheprocessesthatimbuethem
withjointandinteractivecausalcapacities–thenthecausalclaimsbasedonthenom-
inal states alone may be regardedas insufficiently deep and yetstill be as deep as can
be sustained by an empirical analysis.

Overall,whenthesechallengesariseinpractice,weseeinherenttensions,andhence
can offer no general guidance, on whether one should (1) preserve the nominal causal
states as originally defined andsettle for a shallowaccountof how the cause produces
its effect, (2) preserve the nominal causal states as originally defined but then also
attempt to deepen the shallow account by specifying a full mechanism for how the
cause produces its effect, or (3) decompose the original nominal causal states into
component causal states and then specify separable mechanisms that can account for
the partial effects attributable to particular constitutive features, now redefined as
lower-level nominal states. Making this choice surely depends on the state of relevant
theory about the process under analysis, whether the constitutive features can be
meaningfully separated and then measured, whether data with such measures are
available, and what standards prevail in the field for which the study is intended.

The PursuitofCausal Depth byInvestigation ofNested Mechanisms.As
we noted at the beginning of this chapter with illustrative quotations fromDuncan et
al. (1972) and Kendall and Lazarsfeld (1950), for many decades social scientists have
usedinterveningvariablesinempiricalanalysisinattemptstoexplainhowcausesbring
abouttheireffects.Inthissection,wewillapplythelanguageofMachameretal.(2000)
to this tradition of analysis, using causal graphs and making explicit connections to
our presentation of Pearl’s front-door criterion.

Recall that for Machamer et al. (2000)the difference between a mechanism sketch
and a mechanism schema is the source of the abstraction in each. For a schema, all
of the parts of the mechanism are known, and the abstraction from them is enacted
for presentation purposes. For a sketch, some of the parts are unknown, and thus the
abstraction is a representation of the analyst’s epistemic limitations.

Beforeconsideringdirectedgraphsofthe sortutilizedinthis book,weshouldnote
howeasyitistofindarrow-basedfigurativerepresentationsthatcanbeinterpretedas
mechanismabstractions.Herearefiveexamplesfromwidelyregardedworkinsociology
where →’s are utilized liberally:
1. In Foundations of Social Theory, Coleman (1990:637, see figure 23.4) offers a
representation of a feedback process for social policy research where five actors
and activities – “Government,”“Intermediaries,”“Policyrecipients,” “Research
on social policy,” and “Political representation” – are connected by eight →’s
and five (cid:3)(cid:3)(cid:4)’s.

2. InClassCounts,Wright(1997:262,seefigure10.1)offersamodelfortheeffectsof
classlocationonclassidentitywhere“Directclasslocation”and“Mediatedclass
location”areconnectedto“Classidentity”throughseven→’sthatareconnected
to “Patternsof daily work interaction,”“Materialclass interests,” “Production-
centered class experiences,” and “Consumption-centered class experiences.”
3. In “A Plea for Mechanisms,” Elster (1998:63, see figure 3.1) offers mechanisms
for the interaction of democracy and religion where “Democracy,” “Religion,”
“Irreligion,”“Desires,”“Opportunities,”and“Action”areconnectedbysix→’s.

4. InInteraction Ritual Chains,Collins(2004:48,seefigure2.1)offersarepresenta-
tion where Durkheimian “Collective effervescence” converts four “Ritual ingre-
dients” (group assembly, barrier to outsiders, mutual focus of attention, and
shared mood) into four “Ritual outcomes” (group solidarity, emotional energy
in the individual, symbols of social relationship, and standards of morality), via
a relation ]→[.

5. In A Theory of Fields, Fligstein and McAdam (2012:20, see figure 1.1) offer a
representation of “three linked mechanisms” for episodes of contention where
two types of actors “Incumbent” and “Challenger” respond to “Destabilizing
changes” and “Escalationof perceived uncertainty” by enacting “Attribution of
threat/opportunity,” which leads to “Social appropriation,” and then to “Inno-
vative collective action.” These mechanisms of action are connected by 12 →’s,
Many more examples exist.26 Our point in offering these five examples is to highlight
the revealed presentation value of mechanism abstractions that use arrows.

Now,considerthesortoffinelystructuredcausalgraphswehaveconsideredexten-
sively in this book. Suppose that one uses some form of back-door conditioning to
identify a causal effect of D on Y. Suppose, furthermore, that one has done so from
within the counterfactual framework, settling on the ATE as the parameter of first-
order interest. One then necessarily confronts the question that we raised in the
beginning of this chapter: Does a counterfactually defined and consistent estimate
of the causal effect of D on Y by itself meet the standard of an explanation that
bottoms out?
The answer to this question is clear: It depends on what D and Y are, who is
conducting the study, and for what purposes. If one wishes to know only how a hypo-
thetical intervention on D would shift Y, and hence has no interest in anything else
whatsoever, then bottoming out has been achieved in some minimalist way, as we
noted above. The analysis yields up a consistent estimate of the average causal effect
of D on Y that holds for the population within which both are observed.In this case,
the modelD→Y is then regardedas merely a mechanismsketch,whichsuffices to be
treated as a sufficiently deep explanation for the purposes at hand.

However,itwilloftenbethecasethatanestimateofawarrantedcausaleffectofD
on Y, grounded in the potential outcomes framework,is properly considered to be an
insufficiently deep explanation of how D brings about Y. Such a judgment would be
appropriate when the interest of the field is in understanding both how interventions
on D and interventions on the mechanistic intervening variables that link D to Y
would shift Y. In this case, the model D→Y is a mechanism sketch that, for the
purposesathand, cannotbe regardedas asufficiently deepexplanation.The arrowin
the sketch D→Y is a black box that must be filled in through further analysis.

Ifawarrantedclaimofacounterfactuallydefinedcausaleffectisproperlyregarded
as insufficiently deep, the recourse is not to abandon the counterfactual model but
rather to investigate the nested mechanism that intercepts the effect of D on Y. Such
analysis may initially take the form of a set of alternative conjectured mechanisms.

But, ultimately, any such analysismust returnto the particular observedrelationship
betweenDandY inthepopulationofinterest(ormorebroadlyinmultiplewell-defined
populations for which the question of interest is relevant). Thus, although theoretical
creativity and new measurement techniques may be required, opening up black boxes
is, at least in part, an empirical pursuit. At some point, one must specify the causal
statesforthevariablesthatconstitutethemechanisms,andeachlinktherebyspecified
to give rise to an effect must be submitted to its own causal analysis.

Consider this process abstractly with reference to a causal graph, after which we
willintroduceexamplesfromthepublishedliterature.Supposethatonepursuesfurther
theoretical conjecturing and subsequent empirical analysis, and one then determines
that the variables A, B, and C constitute an exhaustive and isolated mechanism that
identifies thecausaleffectofD onY by Pearl’sfront-doorcriterion.Atthispoint, one
may be tempted to declare that a sufficiently deep causal explanation of the effect of
26Anearly(andparticularlyobtuse) oneisParsons(1937:741, footnote 1),wherea“webofinter-
wovenstrands”isusedtoexplainhowmeans-endchainsevolveintimeandstructureunitacts.

D on Y has been secured. Such a claim may well be true, but it is not guaranteed. It
couldbe that further nested mechanistic variables exist, such that, for example, three
additional variables M, N, and O (each of which is a concept of considerable interest
to one’s peers) are then found to elaborate the casual pathway D→ A →Y. In this
case,thecausalpathwayD→A→Y isthenitselfbestregardedinhindsightasmerely
a component of a mechanism sketch. When M, N, and O are then observed, D→ A
→Y isreplacedinthemechanismsketchwith,forexample,oneormorerelatedcausal
pathways, such as D→M →A →N→Y and D→A →O→Y. In this example, A,
B, and C may well identify the causal effect by the front-door criterion, but they do
not qualify as a sufficiently deep causal account of how D brings about Y.

As we noted in the first part of this chapter, the progressive deepening of causal
explanation through the modeling of intervening processes is entirely consistent with
social science tradition. And yet we also claimed that Pearl’s front-door criterion can
help guide sharpenedanalysis practices in this regard.To see what we mean, consider
the example of Duncan’s research on status attainment processes again. As we noted
in Chapter 1, Blau and Duncan (1967) deepened the causal account of how parental
socialstatusdeterminesoffsprings’socialstatusby specifyingwhatmostscholarsnow
regardas the most important link: levels of educational attainment.

Thereafter,Duncanandhiscolleaguesthensupportedandencouragedfurtherwork
on the process of educational attainment, most importantly the Wisconsin model of
status attainment that we introduced in Section 1.3.1. This model is a direct exten-
sion of Blau and Duncan’s research, in which the causal pathways between parental
status and offspring’s attainment were elaborated by the introduction of intervening
variables for significant others’ influence and educational aspirations. In fact, in the
mostimportantarticleinthistradition,Sewelletal.(1969)usedmechanisticlanguage
to introduce the contribution of their study:
wepresenttheoryanddataregardingwhatwebelievetobealogicallycon-
sistent social psychological model. This provides a plausible causal argu-
menttolink stratificationandmentalabilityinputs throughasetofsocial
psychologicaland behavioralmechanisms to educationaland occupational
attainments.Onecompellingfeatureofthemodelisthatsomeoftheinputs
may be manipulated through experimental or other purposive interven-
tions. This means that parts of it can be experimentally tested in future
research and that practical policy agents can reasonably hope to use it in
order to change educational and occupational attainments. (Sewell et al.

1969:84)
The Wisconsinmodelwasveryfavorablyreceivedinsociology,as it wasconsideredto
be consistentwith the basic features of the model of BlauandDuncan (1967)andyet
had a claim to greater causal depth.27
Even so, as we also noted in Section 1.3.1, critics emerged immediately (see also
Morgan2005,chapter2,foramoreextendedsummary).Thebasicargumentwasthat,
even if significant others’ influence and educational aspirations have causal effects on
27Anotherwidelyreadexampleofthetimeistheearliermechanisticelaborationintheresearchof
KendallandWolf,contributedbyKendalltoHyman(1955:324–27).

educationalattainment, they are both groundedin partin sourcesoutside of parental
status and mental ability (a point the authors of the Wisconsin model recognized).

Thus,althoughsignificantothers’influenceandeducationalaspirationsmaybehelpful
tosomeextentinofferinganinterpretationofsomeofthecausalprocessthatgenerates
intergenerationalcorrelationsofeducationalattainment,theseinterveningvariablesdo
notqualifyasanexhaustiveandisolatedmechanismthatfullyaccountsfortheeffects
of parental status on offsprings’ status.

Inthisregard,theBlauandDuncanmodelcanberegardedasamechanismsketch
for the status attainment process, and the Wisconsin model can then be regarded as
a mechanism-based attempt to deepen its implied explanation. The Wisconsin model
was therefore an important step forward, but it was not conclusive and did not settle
all further research.

More than four decades later, it is now clear that the Wisconsin model itself is a
mechanism sketch. The research community of inequality scholars in sociology seems
to have concluded that its pathways have not bottomed out, and much research con-
tinuesontheprocessesthatgenerateeducationalaspirations(aswellaswhetherornot
the relationship between aspirations and attainment is sufficiently explanatory to be
useful).Moreover,somescholars(e.g.,Goldthorpe2007)haveproducedentirelydiffer-
ent mechanism sketches for the relationship between parental status and educational
attainment. The future of this research tradition is clearly careful empirical analysis
that can adjudicate between these rival mechanism sketches, which will be decisive
only when alternative mechanism sketches are pushed down to lower-level entities on
which critical tests can then be performed.

## 10.5 Conclusions

Pearl’s front-door strategy for the identification of a causal effect is a powerful and

illuminating perspective on the explanatory power of mechanisms. It clearly shows
that the identification of a causal effect by a mechanism requires that the mechanism
be exhaustive and isolated and that its variables be observed. For such a mechanism
to count as a sufficiently deep explanation, its causal pathwaysmust be finely enough
articulated that it meets whatever standard of bottoming out is maintained in the
relevant field of study. If such a standard is not reached, then the causal effect is
identifiedeventhoughitisnotaccompaniedbyasufficientlydeepexplanation.Instead,
the identifying causal pathways represent a mechanism sketch that demands further
analysis.

Considering this chapter and the strategies for causal effect estimation from prior
chapters, we have come back full circle to our initial presentation of causal modeling
optionsinChapter1.Wenotedthere,withreferencetoFigure1.3,thatacausaleffect
thatisidentifiedbyboththeback-doorcriterionandanIVisbestexplainedwhenitis
also identified by an exhaustive and isolated mechanism. This is the highest standard
for an explanatory causal analysis, at least until a field decides that a crucial linkage
within a mechanism must then be opened up and subjected to its own analysis.

Inthenextchapter,weturninadifferentdirectiontoconsidertheextenttowhich
over-time data on an outcome variable can be used to identify and estimate a causal
effect.Oneoftenhearspresentationsinwhichscholarsremark,“Icannotgetatcausal-
ity because I do not have longitudinal data.” We will argue in the next chapter that
longitudinal data, althoughvery helpful in many cases, are not the panacea that such
statementsseemto imply. Moreover,wewill showthatsomelong-standingtechniques
that are thought to reveal causal effects are strongly dependent on assumptions that
are often entirely inappropriate and sometimes completely unrecognized.

# Chapter 11

# Repeated Observations and the Estimation of Causal Effects

Asdiscussedinpreviouschapters,thefundamentalchallengeofcausalinferenceisthat

an individual cannot be simultaneously observed in both the treatment and control
states.Insomesituations,however,itispossibletoobservethesameindividualorunit
of observation in the treatment and control states at different points in time. If the
potentialoutcomesdonotevolveintimeforreasonsotherthanthetreatment,thenthe
causaleffect ofatreatmentcanbe estimatedasthe difference betweenanindividual’s
observed outcome in the control state at time 1 and the same individual’s observed
outcome in the treatment state at time 2. The assumption that potential outcomes
are stable in time (and thus age for individuals) is often heroic. If, however, potential
outcomes evolve in a predictable way, then it may be possible to use the longitudinal
structure of the data to predict the counterfactual outcomes of each individual.

We begin our discussion with the interrupted time series (ITS) design, which we
introducedalreadywith the example ofthe yearofthe fire horseinSection2.8.1. The
ITS design is the simplest case where the goal is to determine the degree to which
a treatment shifts the underlying trajectory of an outcome. It is simple because the
analysis is based only on data for a single individual or unit of analysis observed at
multiple time points. We also consider the regression discontinuity design. Although
not a case in which we have repeated observations on a single individual or unit, the
structure of the regression discontinuity (RD) design is sufficiently similar to that of
the ITSthatit is useful to presentit hereas well. Forthe RDdesign, we alsoconsider
thecaseoffuzzyassignment,whichamountstousinginstrumentalvariable(IV)meth-
ods to correct for possible imprecision in the treatment assignment criterion.

Wethentransitiontoafullconsiderationofpaneldata:multiple observationsover
time on multiple individuals or units. We first examine the adequacy of traditional
two-period adjustment strategies, building on our brief introduction to these models
inSection8.2,wherewedemonstratedhowlittleinsightcanbegainedfromadditional
354
posttreatmentdata.We showinthischapterthatsuchmethods,evenwhenusedwith
pretreatmentdata,areinadequateformakingcausalinferencesunlessoneiswillingto
make strong and usually untestable assumptions about how the outcome evolves over
time across individuals.

We then consider a more comprehensive model-based approach. The key require-
ments of this approach are assumptions about the evolutionary dynamics of the out-
come and how selection into the treatment depends on these dynamics. This type of
strategy typically requires data from multiple pretreatment time periods. With data
over a sufficient number of time periods, it is possible to test the appropriateness of
different models.

Although for the main body of this chapter we will assume that the time period
at which the treatment occurs is fixed and has no dynamic structure, in an appendix
to this chapter we will consider scenariosin which the treatment canbe repeated and
the specific timing of each treatment instantiation is endogenous. These scenarios are
considerably more complex because a treatment indicator must be modeled for every
time period, recognizing that selection of the treatment in any single time period is
not only a function of individual characteristics but also of previous decisions and
expectations of future decisions.

## 11.1 Interrupted Time Series Models

To estimate the treatment effect for a study with an ITS design, a time series model

is typically offered:
Yt=f(t)+Dtb+et, (11.1)
where Yt is some function in time (which is represented by f(t) on the right-hand
side), Dt is a dummy variable indicating whether the treatment is in effect in time
period t, and et is time-varying noise. The basic strategy of an ITS analysis is to use
the observed trajectory of Yt prior to the treatment to forecast the future trajectory
of Yt in the absence of the treatment (see the introductions in Marcantonio and Cook
1994,McDowall, McCleary, Meidinger, and Hay 1980, and Shadish et al. 2001).

Consider, as in our prior example in Section 2.8.1 on the year of the fire horse,
howpotentialoutcome notationcanbe usedto understandthe ITSdesign.For setup,
supposethatwehavediscreteintervalsoftimetthatincreasefrom1toT.Theoutcome
variable Yt in Equation (11.1) then has observed values {y 1,y 2,y 3,...,yT}. The two-
statecausalvariable,Dt,isequalto1ifthe treatmentisinplaceduringatimeperiod
tandis equalto 0 otherwise.For the ITSdesign, it is typicallyassumedthatonce the
treatment is introduced in time period t∗, its effect persists through the end of the
observation window, T.

Analogous to (but a bit simpler than) our general setup in Section 2.8.1, the ITS
observed data are defined in terms of potential outcome variables as
1. Before the treatment is introduced (for t<t∗):1
Dt=0
Yt=Y t0
2. After the treatment is in place (from t∗ through T):
Dt=1
Yt=Y t1
Y0existsbutiscounterfactual.

t
The causal effect of the treatment is then
δt=Y t1−Y t0 (11.2)
for time periods t∗ through T. By the definition of the potential outcomes, Equation
(11.2) is equal to
δt=Yt−Y t0, (11.3)
again for time periods t∗ through T.

ThecrucialidentifyingassumptionfortheITSdesignisthattheobservedvaluesof
ytbeforet∗ canbeusedtospecifyf(t)foralltimeperiods,includingtimeperiodsfrom
t∗ toT.2 Equivalently,theprimaryweaknessofthe ITSdesignis thatthe evolutionof
Yt prior to the introduction of the treatment may not be a sufficiently good predictor
of how Yt would evolve in the absence of the treatment. In other words, even though
the pretreatment evolution of Yt is by definition a perfect reflection of the evolution
of Y0 before t∗, it may be unreasonable to extrapolate to posttreatment time periods
t
in order to estimate treatment effects defined by Equation (11.3).

Consider the trajectory of Yt in the hypothetical example depicted in Figure 11.1.

The solid line represents the observed data on Yt, and the time of the introduction
of the treatment is indicated on the horizontal axis, which we defined above as t∗.

The true counterfactualevolution of Y0 in the absence of treatment is representedby
t
the dashedline. Clearly,this counterfactualtrajectorywouldbe poorlypredictedbya
straightforward linear extrapolation from the observed data before the treatment. In
fact, in this case, assuming that the counterfactual trajectory followed such a linear
trajectory would result in substantial overestimation of the treatment effect in all
posttreatment time periods.

For estimation, no issues beyond those relevant to a standard time series analysis
ariseforanITSmodel.Thekeystatisticalconcernisthattheerrorset arelikelytobe
correlated over time. If we use least squares regression, the parameter estimates will
be consistent, but the standarderrorsandany hypothesis tests basedon them will be
incorrect. This problem can be especially acute when the number of data points in a
1Again, as in Section 2.8.1, counterfactual values for Y t1 exist in pretreatment time periods, but
thesevaluesarenottypicallyconsideredinanITSanalysis.

2Asecondaryassumption,whichwedonotemphasize,isthecommonpositionthattheparameter
b in Equation (11.1) is a structural constant that does not vary with t. This assumption can be
relaxed,allowingbtovaryfromt∗ throughT assomefunctionint.

Y
t Observed
True counterfactual
Assumed counterfactual
t* Time
Figure11.1 Trajectories of the observed outcome as well as the true and assumed
counterfactual outcomes for a faulty ITS model.

time series is small. We will not address any of the issues involved in estimating time
series models, as there are many books that cover the topic in depth (e.g., Hamilton
1994;Hendry 1995).

Instead,wewillillustratethebasicthinkingbehind anITSanalysiswithanexam-
plefromBraga,Kennedy,Waring,andPiehl(2001),whichispresentedinFigure11.2.

Bragaandhiscolleagueswereinterestedinevaluatingwhetheraninnovativeprogram,
“Operation Ceasefire,” initiated by the Boston Police Department in June 1996, pre-
ventedyouthhomicides.Figure11.2presentsthetrendinthemonthlyyouthhomicide
rate in Boston between June 1991 and May 1998.

OperationCeasefireinvolvedmeetingswithgang-involvedyouthwhowereengaged
ingangconflict.Gangmemberswereofferededucational,employment,andothersocial
servicesiftheycommittedtorefrainingfromgang-relateddeviance.Atthesametime,
the police made it clear that they would use every legal means available to see that
thosewhocontinuedtobeinvolvedinviolentbehaviorweresenttoprison(seeKennedy
1997 for a more detailed description).

The vertical line in Figure 11.2 marks the date at which Operation Ceasefire was
initiated.Thetwohorizontallinesindicate,respectively,themeanlevelofyouthhomi-
cides before and after June 1996. As can be seen in Figure 11.2, there appears to be
an abrupt and large drop in the level of youth homicide in Boston immediately after
the implementation of Operation Ceasefire.

Braga and his colleagues carried out a more formal analysis using standard time
series techniques (but because their dependent variable is a count variable – number
of youth homicides in a month – they used a Poisson regression model). In their first
model,theyadjustedonlyforseasonaleffectsbyusingdummyvariablesformonthand
a lineartermfor time. Inclusionof the time trend is particularlyimportant. Although
it is not clear in Figure 11.2, there is a slight downward time trend in the homicide
rateinthe pretreatmenttime period, whichitseemsreasonableto assumewouldhave
continued even if Operation Ceasefire had not been implemented. For this model,
Ceasefire intervention
May 15, 1996
12
smitciv 8
fo
rebmuN19-naJ
4
0
19-raM 19-yaM 19-luJ 19-peS 19-voN 29-naJ 29-raM 29-yaM 29-luJ 29-peS 29-voN 39-naJ 39-raM 39-yaM 39-luJ 39-peS 39-voN 49-naJ 49-raM 49-yaM 49-luJ 49-peS 49-voN 59-naJ 59-raM 59-yaM 59-luJ 59-peS 59-voN 69-naJ 69-raM 69-yaM 69-luJ 69-peS 69-voN 79-naJ 79-raM 79-yaM 79-luJ 79-peS 79-voN 89-naJ 89-raM 89-yaM
Date
Youth Homicides Pre-Test Mean Post-Test Mean
Figure11.2 Monthly youth homicide rates in Boston, 1991–1999.

Source: Braga et al. (2001), figure2.

Braga and his colleagues reported a large negative and statistically significant effect
of Operation Ceasefire on youth homicides.

In general, a researcher would usually prefer a situation in which the underlying
time trend and the treatment effect are in the opposite directions. In such a case,
disentangling the treatment effect and the time trend is far easier, strengthening any
warrant for a causal inference. However, for this example, the underlying time trend
and the expected program impact move in the same direction. Thus, a researcher
should be concerned about the ability to accurately estimate the size of the program
effect in the presence of the underlying trend. Recall that Figure 11.1 illustrated a
similar but more problematic situation. Not only does the time trend move in the
same direction as the effect in that hypothetical example, but there is a change in the
time trend in the same direction as the treatment effect, making accurate estimation
of the effect impossible with an ITS model.

The research of Braga et al. (2001) represents a very high-quality example of how
to use an ITS design to investigate a treatment effect. They offered four types of sup-
plemental analysis, eachof which is broadly applicable to all ITS designs, and each of
whichcanbe usedtostrengthenthe warrantfor acausalclaim. First, they considered
additional dependent variables that Operation Ceasefire should have affected. Specif-
ically, they analyzed whether the program affected the number of gun assaults and
reports of gun shots fired. For these dependent variables, they found an even larger
programimpact.Theiranalysiswouldhavebeenstrengthenedfurtheriftheyalsohad
considered dependent variables that Operation Ceasefire should not have affected as
much(e.g., number ofrobberiesandincidents ofdomestic violence). Here, evidence of
an impact would suggest that factors other than the program itself at least partially
accounted for the observed drop in youth homicides.

Second, they focused their hypothesis and considered it within meaningful sub-
groups.Inparticular,theyanalyzedthelevelofgunassaultsinpolicedistrictB-2,the
districtwheregangviolencewasthehighestintheearly1990sandOperationCeasefire
was most active. As they predicted, the programeffect was largerin district B-2 than
in the city as a whole. If there had been districts with high levels of youth violence
whereOperationCeasefirewasinactive,it wouldhavebeenuseful to havetestedfora
programimpact. If evidence were found that the programhad animpact in these dis-
tricts,itwouldsuggestthatsomethingotherthantheprogramwasresponsibleforthe
observeddecline inyouthhomicides, gunassaults,andgunshotsfired. Unfortunately,
atleastforthe analyst,almostallyouthviolenceinBostonoccurredinthree adjacent
police districts, all districts in whichOperationCeasefirewas active. As a result, such
an analysis was not possible.

Third, they includedadditional adjustmentvariablesintheir time seriesmodels in
ordertocapturetheunderlyingtimetrendaswellastheyear-by-yearvariabilitybefore
and after the introduction of the treatment. These time-varying covariates included
unemployment rates, the size of the youth population, the robbery rate, the homicide
rate for older victims, and the drug-related arrest rate. The advisability of adjusting
for the latter three variables is questionable, given that these variables are also likely
to have been affected by Operation Ceasefire to at least some degree. Nonetheless,
conditioning on these additional variables produced little change in their estimate of
the programimpact on any of their dependent variables.

Finally,theycomparedthetimetrendinhomicidesinBostonwiththetimetrendin
41 other cities where no targeted interventions for homicide rates were implemented.

Their goal was to determine whether other cities experienced declines in rates as
abrupt as the one observed in Boston. The explanation of Braga and his colleagues
for the abruptness of the decline in Boston – in fact, a decline that emerged in only
two months – was that word got out on the street quickly that the police meant
business. For many of the other cities considered, homicide rates fell throughout the
1990s. With the exception of New York City, the declines were substantially smaller
than in Boston. Braga and his colleagues then showed that abrupt declines did occur
in five other cities, but the exact timing of these abrupt declines was different than
in Boston. This evidence raises perhaps the greatest doubt about the assertion that
OperationCeasefire reduced youth homicide rates in Boston because there is no clear
explanation for why these abrupt declines occurred elsewhere either. And, because it
may be implausible that OperationCeasefire’s effect could have fully taken hold in as
short as two months, the possibility exists that the decline in homicide rates and the
introduction of Operation Ceasefire were coincidental.

IfBragaandhiscolleagueshadcarriedouttheirevaluationanumberofyearslater,
theycouldhaveimplementedoneadditionalstrategy.In1999,OperationCeasefirewas
cut back and then terminated. If they had performed their analysis for at least a few
yearsbeyond1999,theycouldhaveexaminedwhethertheterminationoftheprogram
resulted in an increase in homicide rates. In fact, after 1999, the youth homicide rate
didincreasesuchthat,bythesummerof2006,itwasatnearlythesamelevelasinthe
early1990s(seeBraga,Hureau,andWinship2008).The subsequentincreaseprovides
additional evidence for the impact of Operation Ceasefire while it was in place.

Thisexamplenicelyillustratesthevarietyofgeneralstrategiesthatareoftenavail-
able to strengthen an ITS analysis:
1. Assess the effect of the cause on multiple outcomes that should be affected by
the cause.

2. Assess the effect of the cause on outcomes that should not be affected by the
cause.

3. Assess the effect of the cause within subgroups across which the causal effect
should vary in predictable ways.

4. Adjustfortrendsinothervariablesthatmayaffectorberelatedtotheunderlying
time series of interest.

5. Comparethe focaltime trendwith the time trendforother units orpopulations
to determine whether breaksin the time seriesare likelyto occur inthe absence
of the cause.

6. Assess the impact of the termination of the cause in addition to its initiation.

Thesestrategiesareoftenavailableforothertypesofanalysis,andtheyarealsowidely
applicable to all formsofdata analysisthatattempt to infer causationfromover-time
relationships. Unless one has a case as dramatic as the year of the fire horse, these
strategies are essential for building support for a causal inference.

## 11.2 Regression Discontinuity Designs

A regression discontinuity (RD) design is very similar to an ITS design, except that

the treatment assignment pattern is a function of the values of a variable rather than
the passageof time. An RD design is especially appropriate in situations where treat-
ment assignment is sharply discontinuous in the values of a variable, and it has been
appliedtoavarietyofproblems:theeffectofstudentscholarshipsoncareeraspirations
(ThistlewaiteandCampbell1960),theeffectofunemploymentbenefitsforformerpris-
oners on recidivism (Berk and Rauma 1983), the effect of financial aid on attendance
at a particular college (Van der Klaauw 2002), the effect of class size on student test
scores(AngristandLavy1999),andthewillingnessofparentstopayforbetterschools
(Black 1999).

Campbell wasthe firsttoproposethe RDdesign(see Shadishetal.2001;Trochim
1984), but it has evolved considerably since then (see Bloom 2012; Hahn, Todd, and
VanderKlaauw2001;ImbensandLemieux2008).Itismosteasilyunderstoodwithan
example. Herewe considerthe example ofMarkandMellor (1991),whichis discussed
alsoby Shadishet al. (2001).MarkandMellorwere interestedin examiningthe effect
thataneventofhighpersonalrelevancemayhaveonhindsightbias–theclaimthatan
eventwasforeseeableafteritoccurred.Selectingallmembersofalargemanufacturing
union, they examined the specific effect of being laid off from work on retrospective
High 3.00
2.75
2.50
snaeM
2.25
thgiseroF 2.00
1.75
1.50
1.25
Low 1.00
5 8 11 14 17 20 23 28 29 32 35 38
Laid-off Survivors
Years of Job Seniority
Figure11.3 Foreseeability of a layoff as an example of an RD design.

Source: Mark and Mellor (1991), figure 1.

foresight claims (measured as agreement with statements such as “I saw it coming
all the way”). The study took place just after workers with fewer than 20 years of
senioritywerelaidoff.Figure11.3showstherelationshipsbetweenretrospectiveclaims
of foresight and both layoff status and seniority.

As shown inFigure 11.3, there is an abrupt discontinuity in the relationship
between retrospective foresight claims and seniority at the point in seniority where
individuals were laid off. All workers, regardless of whether they were laid off, were
asked whether they had expected the layoffs that occurred among union members.

Those who were not laid off (i.e., individuals with 20 or more years of seniority) were
on average more likely to claim that the layoffs in the union were expected, even
though they were not themselves laid off. At the same time, those who were laid off
were less likely to claim that the layoffs were expected. Notice also that the associa-
tionbetweenseniorityandretrospectiveclaimsofforesightisinthe oppositedirection
of the estimated treatment effect: Individuals with more seniority were less likely to
claimthatthelayoffswereexpected,evenamongthosewhoweresubsequentlylaidoff.

Because the layoff effect and the underlying seniority association are in the opposite
directions,MarkandMellorhadstrongevidencethatbeinglaidoffdecreasedthelike-
lihoodthat anindividual who waslaid offwouldclaim that the layoffswere expected.

This finding strengthened their overallinterpretation that the personal relevance of a
negativeeventdecreasesthelikelihoodthatanindividualwillclaimthattheeventwas
expected.Theyconcludedthatthispatternreflectsatypeofself-protection,according
to which individuals seek to avoidblaming themselves for not having been sufficiently
prepared to mitigate the negative consequences of an event.

U U
D Y
f(Z) Y
D
Z
Figure 11.4 An example of a fuzzy RD design.

Ingeneral,anRDmodelcanbeestimatedinthesamewayasanITSmodelbecause
mostofthesameissuesapply.OnekeyandhelpfuldifferenceisthatinmostRDdesigns
individualsaresampledindependently.Asaresult,the problemofcorrelatederrorsin
an ITS design is absent in an RD design.

A generalization of the RD design, known as the fuzzy RD design, has received
recentattention.3Here,thetreatmentvariableisafunctionofanassignmentprocessin
whichthereiserrorthatisassociatedwithY.ConsiderthegraphinFigure11.4,where
f(Z)representstheintendedassignmentruletoD asafunctioninZ.However,inthis
case the assignment is imperfect in the specific sense that the other determinants of
assignment,UD,cannotbeassumedtobeindependentoftheunobserveddeterminants
of Y, UY. Instead, UD and UY are assumed to be determined by common causes
represented by the dashed, bidirected edge in UD(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)UY.

For fuzzy RD design, the assignmentrule is notdeterministic because D is a func-
tion of both f(Z) and UD, and, furthermore, because UD and UY are determined by
commoncauses.ForafuzzyRDanalysis,theinvestigatorconditionsonZ sothatf(Z)
can then be used as an instrument for D (because it is mean-independent of both UD
and UY and affects Y only through D).4 Conditioning on Z is necessary to eliminate
the back-door path f(Z)←Z→Y in order to establish f(Z) as a valid IV; see our
prior discussion of conditional IVs in relation to Figure 9.2(b). A fuzzy RD analysis
is possible only if f(Z) is some nonlinear function of Z, so that f(Z) and Z are not
linearly dependent.

Angrist and Lavy (1999) use the fuzzy RD design to study the effects of class size
on student test performance in Israel. In the Israeli public school system during the
period of their study, an additional class was added to a grade within a school when
theexistingclassescrossedathresholdsizeof40studentsinresponsetoanincreasein
theoverallschoolenrollment.Thispolicycreatedadiscontinuityinthedistributionof
classsizes,whichallowedAngristandLavytocreateanonlinearfunctionofenrollment
that couldthen be used asaninstrument for classsize.They found that classsize has
3Another type ofgeneralization is towardthe consideration ofmultipleassignment variables(see
Wong, Steiner,andCook2013).

4Thesituationisdirectlyanalogoustoanexperimentwithnoncomplianceinwhichnoncompliance
is thought to be nonrandom. As Imbens and Rubin (1997) show, one can deal with noncompliance
bytreatingtheintention-to-treat indicatorasaninstrument,Z,fortheactualtreatment, D.

a substantial effect on test performance for fourth and fifth graders, but not for third
graders.

As shown by these examples, RD designs are simple and can be convincing. But
thesameweaknessesofITSdesignsarepresent.Counterfactualvaluesmustbeextrap-
olated from observed data below and above the value that triggers the introduction
of the treatment. If the assumptions built into the chosen method of extrapolation
are unreasonable, then causal effect estimates will be incorrect. Caughey and Sekhon
(2011) present a critique of RD analyses where adoption of the assumptions requires
substantialadditionalconditioning,preciselyofthesortthatRDdesignsaremeantto
avoid. In other cases, where the assumptions are reasonable, RD designs can be very
powerful (see Berk, Barnes, Ahlman, and Kurtz 2010; Shadish, Galindo, Wong et al.

2011).

## 11.3 Panel Data

A severe limitation of time series data is that we have data on only a single unit over

time. Because we do not observethe treated unit of analysis in the control state after
the treatment is introduced, the only way to estimate the counterfactual outcome is
to assumethatthe future canbe predicted accuratelyfromthe past.This assumption
is generally untestable.

Panel data, where multiple individuals or units are observed over time, may solve
this problem. Assuming that each individual’s time series is relatively long, separate
ITSanalysescouldbeconductedforeachindividualandthenpooledtoformanaverage
causaleffectestimate.Moreover,becauseindividualsreceivethetreatmentatdifferent
times or do not receive the treatment at all, it is possible to observe how Y0 changes
t
overtime for someindividuals after othershavereceivedthe treatment.To the degree
thatY0 evolvessimilarlyovertimeforindividualsinthetreatmentandcontrolgroups,
t
it may be possible to make reasonable predictions about the counterfactual values of
Y0 for individuals in the treatment group after they are exposed to the treatment.

t
Fortheremainderofthischapter,wewilladoptthepaneldatanotationintroduced
in Section 2.8.2 to differentiate between quantities that vary only over individuals
(subscriptedbyi),quantitiesthatvaryonlyovertime(subscriptedbyt),andquantities
thatvaryoverindividualsandtime(subscriptedbyit).Inmostcases,thesubscripting
for i is redundant and is utilized only for additional clarity. For example, in prior
chapters,we haverepresentedthe averagetreatmenteffect(ATE)as E[δ], recognizing
that the argument of the expectation, δ, can be regarded as a random variable that
takes on values that vary across individuals, which we specified was possible when
definingtheindividual-levelcausaleffectasδi=y i1−y i0.Ournotationintheremainder
of this chapter requires that we write the same time-constant ATE as E[δi], because
foratime-varyingATE,wewouldinsteadneedtosubscriptfortaswell,writingE[δit].

As explained in Section 2.8.2, we will distinguish between two different treatment
indicatorvariables:Dit is a time-varyingdummy variablethatindicates whether indi-
vidual i receives the treatment in time period t, and D∗ is a time-constant dummy
i
variable that indicates whether individual i ever receives the treatment at any point
in the time span under study. Dit is best thought of as a treatment exposure indi-
cator variable, and D∗ is best thought of as a treatment group indicator variable.

i
Observed and potential outcomes are related to each other by time-specific relations,
Yit =DitY i1 +(1−Dit)Y i0 t, where Y i1 t, Y i0 t, and Dit all vary over i and t. Finally,
t
individual-leveltreatmenteffectsvaryintime,suchthatδit=y i1 t−y i0 tforallt.Asnoted
above,theATEisnowlikewisetime-specificandcanbewrittenasE[δit]=E[Y i1 t−Y i0 t].

The average treatment effect for the treated (ATT) and the average treatment effect
for the controls (ATC), and any other conditional average treatment effect one might
be interested in estimating, are defined analogously.

11.3.1 Traditional Adjustment Strategies
Themostcommonsituationinpaneldataanalysisconsistsofnonequivalenttreatment
and control groups and two periods of data, where the first wave of data is from
pretreatment time period t−1 and the second wave of data is from posttreatment
timeperiodt.Suchtwo-period,pretreatment-posttreatmentpaneldataaresometimes
thought to be a panacea for not having a randomized experiment. Typically, it is
assumedthatchangesovertimeinthecontrolgroupcanbeusedtoadjustthechanges
observed for the treatment group, with the net change then representing a consistent
and unbiased estimate of the causal effect of the treatment.

Unfortunately, the situation is far more complicated. There are aninfinite number
of ways to adjust for differences in gains between the treatment and control groups,
and alternative methods of adjustment give estimates that sometimes differ dramati-
cally. Specifically, as we will show in this section,by choosing a particular adjustment
technique when analyzingtwo-period,pretreatment-posttreatmentdata, any estimate
that a researcher may want can be obtained.

Consider the two most common methods, usually referred to as change score and
analysis of covariance models. The change score model is often referred to as a panel
data variantof a difference-in-difference model, especially in the economics literature;
seeImbensandWooldridge(2009).Thesetwomodelsareequivalenttoestimatingthe
following two equations with least squares regression:
Change score: Yit−Yit−1=a+D i∗ c+ei, (11.4)
∗
Analysis of covariance: Yit=a+Yit−1b+D ic+ei. (11.5)
These two equations provide different means of adjustment for Yit−1. In the change
score model, one adjusts Yit by subtracting out Yit−1. For the analysis of covariance
model,oneadjustsYit byregressingitonYit−1.5Recallthatweintroducedtheanalysis
of covariance model already in Panel Data Demonstration 1 (see page 273), where we
considered its utility when analyzing posttreatment-only data.

5Also,itbearsmentioningthatwhenwepresentalternativeequations,suchasEquations(11.4)and
(11.5)inthischapter,wegivegenericnotation–suchasa,b,andc–toregressionparameters,such
asinterceptsandtreatmenteffectestimates.Wedothesame,ingeneral,forregressionresiduals,and
soon.Wedonotmeantoimplythatsuchquantitiesareequalacrossequations,butitiscumbersome
tointroducedistinctnotation foreachcoefficientacrossequations tomakesurethatweneverimply
equalitybyreusinggenericcharacters suchasa,b,c,ande.

Consider now an example that shows how these two models can yield different
results with pretreatment-posttreatment data. After decades of studying the environ-
mentalandgeneticdeterminantsofintelligence,considerablecontroversyremainsover
theirrelativeeffectsonlifecourseoutcomes.AsdiscussedinDevlin,Fienberg,Resnick,
and Roeder (1997) and other similar collections, these debates resurfaced after the
publication of The Bell Curve: Intelligence and Class Structure in American Life by
HerrnsteinandMurrayin1994.Eventhoughexistingreviewsoftheliteratureempha-
sizedthe malleabilityofIQ(see Ceci1991),HerrnsteinandMurrayconcludedintheir
widely read book:
Taken together, the story of attempts to raise intelligence is one of high
hopes, flamboyant claims, and disappointing results. For the foreseeable
future, the problems of low cognitive ability are not going to be solved by
outside interventions to make children smarter. (Herrnstein and Murray
1994:389)
As discussed in Winship and Korenman (1997), the weight of evidence supports the
claim that education determines measured intelligence to some degree, even though
debate remains on how best to measure intelligence.

Considernowaveryspecificquestionassociatedwiththiscontroversy:Whatisthe
causaleffectofatwelfthyearofeducationonmeasuredIQ?Thefollowingresults,based
ondatafromtheNationalLongitudinalSurveyofYouth,showhowdifferenttheresults
fromchangescoreandanalysisofcovariancemodelscanbe(seeWinshipandWinship
2013for additionaldetails). For both models, IQ is measuredbefore the twelfth grade
for all individuals who meet various analysis-sample criteria (N =1,354). IQ is then
measured after high school completion, and high school completion is designated the
treatment variable. A change score model yields a treatment effect estimate of 1.318
(witha standarderrorof.241)andananalysisofcovariancemodel yields atreatment
effect estimate of 2.323 (with a standard error of .217).6 These estimates are quite
different: The analysis of covariance model suggests that the effect of a twelfth year
of schooling on IQ is 76 percent larger than that of the change score model (i.e.,
[2.323−1.318]/1.318). Which estimate should one use? Before we discuss how (and
if) one canchoosebetween these two types oftraditional adjustment, considera more
general, but still simple, hypothetical example.

Panel Data Demonstration 2
For this demonstration, we will again consider the Catholic school effect analyzed by
Coleman and his colleagues. Departing from the setup of Panel Data Demonstration
1 (see page 273), in this demonstration we will consider how alternative estimators
perform assuming a world in which (1) no Catholic elementary schools or middle
6For completeness, we report additional features of these models here. Each was estimated with
three other covariates: age, year of the test, and a standardized measure of socioeconomic status.

The coefficients on these three variables were −.18, −.76, and −.43 for the change score model and
−.97,−.50,and2.05fortheanalysisofcovariancemodel.TheR2 was.06forthechangescoremodel
and .68 for the analysis of covariance model, inwhich the lag coefficient on IQ in the twelfth grade
was.62.

schools exist, (2) all students consider entering either public or Catholic high schools
after the end of the eighth grade, and (3) a pretreatment achievement test score is
availablefortheeighthgrade.Suchaworlddoesnotexist,because(1)and(2)arenot
true (and, furthermore, Coleman and colleagues were not fortunate enough to have
(3) either). We offer a demonstration assuming such a world for didactic purposes.

Basic Setup. AsforPanelDataDemonstration1,wewillconsideronlylinearspeci-
ficationsand,exceptwhenotherwisedetailed,restrictallcausaleffectstobeconstants
or to vary acrossindividuals in completely randomwaysindependent of allelse in the
models. This setup gives traditional panel data regression estimators the best chance
of succeeding. Even so, recall that we showed through demonstrations in Chapters
5, 6, and 7 that least squares regression estimators invoke implicit weighting that is
unlikely to effectively deal with the nonrandom individual-level heterogeneity of the
Catholic school effect on achievement. We hold these additional complications aside
in this demonstration in order to focus narrowly on the potential value of traditional
panel data estimators of causal effects.

The potential outcome variables are Y1 and Y0, where now t={8,9,10} for the
it it
threegradesthatoccurduringtheassumedobservationwindowfromtheeighthgrade
through the tenth grade. Because treatment selection occurs before t=9, we have
observeddataonlyforonepretreatmenttimeperiod,andwewillassumethatColeman
and his colleagues had the tenth grade data as well (and that no data were collected
in the ninth grade). The treatment group indicator variable, D∗, is equal to 1 if the
i
student enrolls in a Catholic high school and 0 if the student enrolls in a public high
school.

The observed outcome variable, Yit, is defined with reference to the time-specific
treatmentexposureindicatorvariable,Dit.BecausenoonecanbeexposedtoCatholic
schoolsinthe eighthgrade(i.e.,we haveassumedthatCatholicmiddle schoolsdo not
exist for this demonstration), Di8=0 for all students. As a result, Yi8=Y i0 for all
8
students, and the eighth grade test score is therefore a pretreatmentoutcome that we
observe for all students. However, for t={9,10} the observable outcome is equal to
the relevant potential outcome defined by our usual definition: DitY i1 t+(1−Dit)Y i0 t.

We will assume that those observed to be in Catholic or public schools in the tenth
grade were in the same type of school in the ninth grade as well. Accordingly, for
this demonstration, D i∗ =Di10, and the definition of the observed outcome in the
tenth grade can be written either as Yi10 =Di10Y i1 10+(1−Di10)Y i0 or as Yi10 =
10
D∗Y1 +(1−D∗)Y0 .7
i i10 i i10
Figure 11.5 presents a directed graph for the core features of this demonstration,
which we will elaborate below when introducing alternative patterns of treatment
selection. The graph has the same basic structure as Figure 8.2, but the first achieve-
menttest(nowY )isapretreatmentoutcome,whilethesecondachievementtest(now
8
Y ) is a posttreatment outcome. We are interested in estimating the effect of D on
10
Y , as in the research of Coleman and his colleagues. In comparison to Panel Data
10
7Asistypicalinthistypeofanalysis,studentswhoswitchtreatmentsbetweentheninthandtenth
grades receive no special consideration because we do not observe their type of school enrollment
in the ninth grade. See the appendix to this chapter, where we introduce the literature on dynamic
treatmentregimesthatattemptstomodelallcombinationsoftheeffectsoftime-varyingtreatments.

X Y 8 E
Y
O 10
U D
Figure11.5 A directed graph for the effect of Catholic schooling on tenth grade
achievement when a measure of eighth grade achievement is also available.

Demonstration 1, we have more reason to be optimistic. We can compare posttreat-
ment outcomes for the Catholic school students to their pretreatmentoutcomes when
inpublic schoolsandalsoto theoutcomesofstudentsenrolledinpublic schoolsinthe
posttreatment time period.

For simplicity, our other variables O, X, and U are specified as indices of many
underlyingvariables,whichweagainscaleasnormallydistributedcompositevariables.

X isacompositedeterminantofachievementtestscoresinallyearsthathasnodirect
effect on whether students select Catholic schooling. U is a composite variable of
unobserved factors that determine both Catholic school attendance and achievement
tests in all years. O is a composite variable of ultimate background factors that has
effects on U and X, as well as direct effects on Catholic school attendance and test
scoresinallyears.Togivethesecompositevariablesdistributionsthatarefamiliarand
that align with their counterparts for Panel Data Demonstration 1, O is a standard
normal random variable with mean of 0 and variance of 1. Having defined O as an
exogenous root variable, we then set X=O+eX and U =O+eU, where eX and eU
are independent standard normal random variables with mean of 0 and variance of
1. Finally, E is a normal random variable with mean of 0 and variance of 1 that is a
common cause of test scores in all years and is independent of all else in the graph.

Scenarios for Analysis. We will consider eight separate scenarios, defined as a
cross-classification of two patterns of between-group differences in the trajectories of
outcomes (parallel or divergent trajectories) and four treatment selection patterns
(no-self-selection, self-selection on the individual-specific treatment effect, positive
selection on the pretreatment outcome, and negative selection on the pretreatment
outcome). For the four parallel-trajectoryscenarios, Y0 is defined as
it
Y i0 8=98+Oi+Ui+Xi+Ei+υ i0 8, (11.6)
Y i0 9=99+Oi+Ui+Xi+Ei+υ i0 9,
Y i0 10=100+Oi+Ui+Xi+Ei+υ i0 10,
where the υ0 terms are values from independent normal random variables with mean
it
of0andvarianceof10.Onaverage,Y0 followsalineartimepathasdeterminedbythe
it
intercept values of 98, 99, and 100.8 However, the levels of these potential outcomes
for individuals aresetby the time-invariantvalues ofOi, Ui,Xi, andEi, aswell as by
time-specific shocks to their outcomes, υ0.

it
To specify a treatment effect that increases in time, Y1 is defined as
it
Y1=Y0+δ(cid:2) +δ(cid:2)(cid:2)
, (11.7)
i9 i9 i i
Y1 =Y0 +(1+δ(cid:2) )+δ(cid:2)(cid:2) ,
i10 i10 i i
where δ(cid:2) is a baseline individual-level treatment effect, specified as values for each
i
individual from a normal random variable with mean of 9 and variance of 1. The
values of δ(cid:2)(cid:2) are a separate source of individual-level variation in the treatment effect,
i
specified as values for each individual from a normal random variable with mean of 0
andvarianceof1.Intheno-self-selectionscenarios,δ(cid:2)(cid:2) isadditionalrandomindividual-
i
level variation. In the scenarios that specify self-selection on the treatment effect, δ(cid:2)(cid:2)
i
will be an input into treatment selection decisions, as explained below.9
For the four divergent-trajectoryscenarios,we specify group-specificintercepts for
Equation(11.6)sothatthetrajectoryofE[Y0]differsacrossthetreatmentandcontrol
it
groups after the onset of treatment. For the treatment group (D∗=1), the intercepts
i
are specified as 98 for t=8 and 99 for t=9, but then 100.5 for t=10. For the control
group (D∗=0), the intercepts are specified also as 98 for t=8 and 99 for t=9, but
i
then only 99.5 for t=10. Taken together, by the end of the observation window in
the tenth grade, the treatment group’s value for E[Y0 ] is higher by 1 than for the
i10
control group (i.e., 100.5−99.5=1). For this “fan spread” pattern, in the absence of
treatmentthetestscoresofthoseinthetreatmentgroupincreasefasteraftertheonset
oftreatmentthan the test scoresof thosein the control.Inother words,students who
select into Catholic schools would have had a boost in achievement even if they had
remained in public schools, net of all other determinants of Y0 in Equation (11.6).10
it
We consider four types of treatment selection. For the first, treatment selection is
on fixed characteristics of individuals unrelated in any way to the outcomes before
or after the treatment. Accordingly, the probability of Catholic school enrollment is
specified as a logistic distribution
1+ex ep x( p− (−3. 38 .+ 8+Oi O+ i+Ui U)
Pr[D i∗ =1|Oi,Ui]= i), (11.8)
8To mimic real data, the intercept values such as 98, 99, and 100 in this demonstration will
always be expected values of individual-specific intercepts, where the variation in the intercepts is
independentofallelseontheright-handsidesoftherelevantequations.Wesuppressthisfactinthe
maintextforsimplicityofexposition.Tobeprecise,wesetupindividual-specifictimetrendsiny i0 tby
specifyingindividual-specificmultipliers(fromuniformdistributionswithstrictlypositiveprobability
andmeanof1),whichwethenapplytothecommontimetrendsthatdefinetheexpectationsE[Y i0 t],
sometimesdifferentiallywithrespecttoD∗.

i
9Y i1 8 iscounterfactual forallindividuals,andweexcludeitfromEquation(11.7)becausewehave
assumed for this demonstration that Catholic middleschools do not exist. Explicitlyallowing for it
wouldsuggestotherwise.

10Wetakenopositiononwhyfanspreadoccurs,althoughinthisdemonstrationitisequivalentto
assumingthatanothervariable,Q,existsthatgeneratesthispatternbystructuringY0 ininteraction
it
with D∗ after the onset of treatment. In many situations in education research, it is assumed that
i
fanspreadexistsbecauselearningisacumulativeprocess.Weconsiderthistypeofthinkinglaterin
thischapter,whenconsideringdynamicscenarioswhereY it isstructureddirectlybyitspriorvalues.

where Oi and Ui are as defined above. As in prior demonstrations, the probabilities
defined by Equation (11.8) are then set as the parameters for draws from a binomial
distribution, yielding the indicator variable D∗ for Catholic schooling defined above.

i
For the second type of treatment selection, we introduce self-selection on the
individual-specific treatment effect, assuming that students and their parents are
able to forecast and then choose based on accurate beliefs about how much they
wouldbenefit fromattendingaCatholicschool.The treatmentselectionprobabilityis
specified as
1+ex ep x( p− (−7. 73 .+ 3+Oi O+ i+Ui U+ i+5δ 5i(cid:2)(cid:2) δ)
Pr[D i∗ =1|Oi,Ui]= i(cid:2)(cid:2)), (11.9)
where δ(cid:2)(cid:2) is as defined above. For the directed graph in Figure 11.5, this type of self-
i
selection is equivalent to adding an additional bidirected edge, D(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)Y .11
10
For the final two types of treatment selection, we specify the treatment selection
probability as
Pr[D i∗ =1|Oi,Ui]= 1+ex ep x( p− (−3. 38 .+ 8+Oi O+ i+Ui U+ i+k( kY (i Y8 i− 8−E E[Y [i Y8] i) 8) ])), (11.10)
where (Yi8−E[Yi8]) is the individual deviation from the expectation of the pretreat-
ment test. These individual-level values are scaled by k, which is set to either .05 or
−.05.Forthepositivevalueofk,studentsandtheirparentsareselectingthetreatment
assuming that those with higher pretreatment test scores will be the most likely to
benefit from Catholic schooling, perhaps because they believe that Catholic schools
haveamorechallengingcurriculumfromwhichonlyhighachieverswillbenefit.Forthe
negativevalueofk,theyareassumingtheopposite,perhapsbecausetheybelievethat
Catholic schools can compensate for lower achievement in the past. For the directed
graphinFigure11.5,this type ofselectionis equivalenttoadding anadditionaldirect
causal effect, Y →D.

8
ResultsfromTraditionalPanelDataEstimators. Considerfirstthefourparallel-
trajectoryscenariosinthefirstpanelofTable11.1.Forthefirstcolumn,selectionpat-
ternsaresimple andbasedonlyonthe fixedcharacteristicsofindividuals, as specified
aboveinEquation(11.8). The trueATE is10.00,whichis equaltothe ATT andATC
by construction.

For this scenario, the naive estimator yields 14.75 (on average across repeated
samples),andthis valueis upwardlybiasedbecauseO andU arepositivelyassociated
with both D and Y . We could use a cross-sectional estimator to block the back-
10
door paths through the observed characteristics of individuals, O, which are shown
in Figure 11.5. Unfortunately, the unobserved variable U generates a back-door path
D←U→Y that remains unblocked after conditioning on O.

10
Can traditional panel data estimators solve this problem? The change score esti-
mator yields a value of 10.00, which is equal to the true ATE, ATT, and ATC. In
11Or,aswiththecharterschoolexampleinSection8.3,wecouldaddafullyelaboratedback-door
path using latent classes and attempting to capture the inputs into the self-selection decision itself
(seeFigures8.5through8.7).

Table 11.1 Change Score and Analysis of Covariance Estimates of the
Catholic School Effect in the Tenth Grade
Setupconditions:
Self-selection on thecausal effect No Yes No No
Positive self-selection on thepretest No No Yes No
Negative self-selection on the pretest No No No Yes
Parallel Trajectories
Trueaverage treatment effects:
ATE 10.00 10.00 10.00 10.00
ATT 10.00 11.51 10.00 10.00
ATC 10.00 9.83 10.00 10.00
Estimated coefficients for D∗:
Naiveestimator:
Regression of Y 10 on D∗ 14.75 13.86 15.92 13.25
Change score estimator:
Regression of (Y 10−Y 8) on D∗ 10.00 11.51 7.96 12.26
Analysis of covariance estimator:
Regression of Y 10 on D∗, Y 8, O, and X 10.51 11.75 10.49 10.52
Divergent Trajectories
Trueaverage treatment effects:
ATE 10.00 10.00 10.00 10.00
ATT 10.00 11.51 10.00 10.00
ATC 10.00 9.83 10.00 10.00
Estimated coefficients for D∗:
Naiveestimator:
Regression of Y 10 on D∗ 15.75 14.86 16.88 14.30
Change score estimator:
Regression of (Y 10−Y 8) on D∗ 11.00 12.51 8.92 13.31
Analysis of covariance estimator:
Regression of Y 10 on D∗, Y 8, O, and X 11.52 12.75 11.50 11.53
contrast, the analysis of covariance estimator instead yields a value of 10.51, which is
upwardly biased for the ATE, ATT, and ATC. The bias is smaller than for the naive
estimator because conditioning on O has removed some of the back-door confound-
ing.12 We know that 10.00 is the correct answer and therefore can favor the estimate
from the change score model. If we did not know the correct answer ahead of time
and/orwereuncertainaboutthecorrectdirectedgraphforthe generationofthedata,
12Atthesametime,itisunclearfromtheseresultswhatthetotalconsequencesareofconditioning
furtheronXandY 8.Thelatterisacolliderthat,whenconditionedon,inducesaback-doorassociation
between D andY 10 byunblockingthepathD←U→Y 8←E→Y 10.Noticethatconditioning onY 8
wouldalsounblockotherback-doorpathsinthegraph,butalloftheseremainblockedbysimultaneous
conditioningonO andX.

we would have a hard time picking between these two estimates. Before offering an
explanation for this result, it is helpful to consider the next scenario for comparison.

The second column of the first panel presents the same results for the scenario
where treatment selection is on fixed characteristics as well as on the causal effect
itself, as specified above in Equation (11.9). As with past demonstrations, the true
ATT is now greater than both the ATE and the ATC. The naive estimator is again
upwardly biased for the ATE, ATT, and ATC. The analysis of covariance estimator
is also upwardly biased for all three. In contrast, the change score model yields an
estimate of 11.51, which is equal to the ATT, but not to the ATE or to the ATC.

Takentogether,thefirsttwocolumnssuggestthatthechangescoreestimatoryields
valuesthatwillonaverageequaltheATT. Whenself-selectionisabsent,theATTwill
equal the ATE and the ATC, and as a result a consistent and unbiased estimate of
the ATT will also be a consistent and unbiased estimate of the ATE and the ATC.

We will explain this result more formally following this demonstration. The core
of the explanation is that the change score model subtracts out the effects of all fixed
characteristics – observed and unobserved – and can then generate a consistent and
unbiasedestimateoftheATTinscenariossuchasthesetwo.Ifoneiswillingtoassume
that no self-selection on the causal effect is present, as is the case for the scenario in
the firstcolumn, then this estimate ofthe ATT is alsoconsistentandunbiasedfor the
ATE and ATC.

These resultsmay suggestthatthe changescoremodelis mostcommonlythe best
choiceforthesesituations,andonemightalsobeencouragedthateveninthepresence
of self-selection it can be used to effectively estimate the ATT. The third and fourth
columns were constructed to temper any such enthusiasm. For these two columns,
individuals do not self-select on the treatment effect itself, and thus the ATE, ATT,
and ATC are all equal. However,treatment selection is on the pretreatmentoutcome,
as specified by Equation (11.10), where individuals choose Catholic schooling either
as a positive or negative function of the eighth grade test score.

For the third and fourth columns of the first panel, the naive estimator is again
upwardly biased for the ATE, ATT, and ATC. More important for our considera-
tion, the change score model now yields values that are either too small or too large,
depending on whether selection is a positive or negative function in the eighth grade
test score. In fact, the estimates yielded by the analysis of covariance model are on
averagemuch closerto the ATE, ATT, and ATC. In these scenarios,the change score
modelcontinuestogenerateestimatesbasedonaveragedifferencesbetweeneighthand
tenth grade tests scores within the treatment group, but the average of these differ-
ences is no longer a consistent or unbiased estimate of the ATT. If the distribution of
the individual-level treatment effects does not vary across the treatment and control
groups,the averagedifference,Yi10−Yi8, withinthetreatmentgroupwill betoosmall
if those with high values for Yi8 select into Catholic schooling and will be too large if
those with low values of Yi8 select into Catholic schooling. The analysis of covariance
estimator offers a less extreme adjustment for the eighth grade test score and is thus
closer to the true ATE, ATT, and ATC. Nonetheless, the analysis of covariance esti-
matorgeneratesvaluesthatdonotequalthetargetparameters,andthissuggeststhat
theadjustmentmaynotbecorrect,whichwewillexplainbelowisusuallythecase(i.e.,
except in the very rare case that the estimated regression coefficient exactly adjusts
for a regression to the mean effect that is generated by the behavior of individuals).

The second panel of Table 11.1 presents four scenarios for diverging trajectories
of Y0, using the same four patterns of treatment selection. The true ATE, ATT, and
it
ATC are all the same as for the first panel because the underlying fan spread in the
potential outcomes only applies to the potential outcome in the control state in the
tenth grade, Y0 . The treatment effect continues to be defined by Equation (11.7),
i10
which does not vary across the scenarios for parallel and divergent trajectories. To
focus on this key point, recall from our discussion above that even for this set of
scenariosthe trajectoriesofthe potential outcomeare the same forthe treatmentand
control groups from t=8 to t=9 because
E[Y0|D∗ =1]−E[Y0|D∗ =0]=98−98=0
i8 i i8 i
and
E[Y0|D∗ =1]−E[Y0|D∗ =0]=99−99=0.

i9 i i9 i
The difference of 1 emerges between t=9 and t=10 because we specified that
E[Y0 |D∗ =1]−E[Y0 |D∗ =0]=100.5−99.5=1.

i10 i i10 i
These divergent trajectories are inconsequential for the true ATE, ATT, and ATC
because these target parameters continue to be structured in the same way for both
groups. More specifically, the term (1+δ(cid:2))+δ(cid:2)(cid:2) in Equation (11.7) does not vary by
i i
group.

Consider the first column in the second panel, which is for the treatment selec-
tion pattern where selection is on the fixed characteristics of individuals, Oi and Ui.

As was the case for the parallel-trajectory scenarios, the naive estimator and analy-
sis of covariance estimator yield values that are too large. Now, however, the change
scoreestimatorfailsaswell.ThechangescoreestimatoryieldsacoefficientonD∗ that
is equal to 11, assuming an infinite sample (or averaged over repeated samples). In
particular, with reference to Equation (11.4), it yields
Yi10−Yi8=aˆ+D i∗ cˆ
∗
=1.5+D 11.

i
As we explain in the next section, the intercept is equal to
aˆ=E[Y0 |D∗ =0]−E[Y0|D∗ =0]
i10 i i8 i
=E[Yi10|D i∗ =0]−E[Yi8|D i∗ =0]
=99.5−98,
whichis the difference in the observedoutcome in the absence of treatmentfor public
school students. In addition, the treatment effect estimate is equal to
(cid:27) (cid:28) (cid:27) (cid:28)
cˆ= E[Y1 |D∗ =1]−E[Y0|D∗ =1] − E[Y0 |D∗ =0]−E[Y0|D∗ =0]
i10 i i8 i i10 i i8 i
={E[Yi10|D i∗ =1]−E[Yi8|D i∗ =1]}−{E[Yi10|D i∗ =0]−E[Yi8|D i∗ =0]}
={110.5−98}−{99.5−98},
which is the expected gain in the observed outcome for the students who enrolled in
Catholicschoolsminustheexpectedgainintheobservedoutcomeforthestudentswho
remained in public schools. The change score estimator delivers an upwardly biased
estimate because it assumes implicitly (but incorrectly) that the observed average
gain among public school students in test scores between the eighth and tenth grades
is the same gainthat those whoenter Catholic schoolswouldhaveexperiencedif they
had instead remained in public schools. This assumption was correct for the parallel-
trajectory scenario presented in the first panel of Table 11.1, but it is incorrect, by
construction, for the scenarios we are considering now. For our divergent-trajectory
scenarios, we have set the (counterfactual) gain to be equal to 2.5 for the treatment
group and the factual and observed gain to be 1.5 for the control group (i.e., 100.5−
98=2.5 in contrast to 99.5−98=1.5).

For completeness, consider the final three columns in the second panel briefly. As
shown in the second column, the change score estimator remains upwardly biased for
the ATT when self-selection is present, and the magnitude of the bias is exactly the
same because the trajectory-induced bias is unrelated to selection on the treatment
effect.Asshowninthethirdandfourthcolumns,whenselectionisonthepretreatment
outcome, the change score estimator will yield values that are either too small or too
largefortheATT,ATE,andATCforthesamereasonsasinthefirstpanelforparallel
trajectories.Theanalysisofcovariancemodelsshowthesamebasicpatternsasforthe
parallel-trajectoryscenarios.

Altogether, this demonstration suggests that the change score estimator will offer
consistent and unbiased estimates of the ATT when selection is not a function of the
pretreatment outcome and when the unobserved average trajectory for the potential
outcome in the absence of treatment for the treatment group is equal to the observed
trajectory for the control group.13 If individuals do not self-select on the treatment
effect, then the ATT will be equal to the ATE and ATC by definition; the change
scoreestimatoristhereforeconsistentandunbiasedforallthree.If, however,selection
is on the pretreatment outcome or the trajectories are not parallel, then the change
score estimator is no longer consistent and unbiased for the ATT (or the ATC or
ATE). Finally, althoughwe haveyetto fully explainedwhy, in this demonstrationthe
analysis of covariance model never appears to be consistent or unbiased for any of
the target parameters, even though it appears to be less sensitive to departures from
13Inthisdemonstration,theparalleltrajectoriesarealsolinear.Linearityisnotrequired.Parallelism
existsifE[Y0|D∗=1]−E[Y0|D∗=0]=kforallt,wherekisanyconstantthatdoesnotvaryint.For
it i it i
thedemonstration, wesetk=0.Parallelisminallvaluesoftissufficient,butitisnotnecessary.As
weexplainbelow,weonlyneedktobethesameforthetwotimeperiodsinwhichthepretreatment
andposttreatment outcomes areobserved.

the parallelismofthe firstfour scenarios.The explanationfor this outcome willfollow
the demonstration.

In conclusion, we should note four additional points. First, only because we con-
structed the data for this demonstration is it clear when the change score estimator
outperforms the analysis of covariance estimator. In observational research, the true
values for the ATE, ATT, and ATC are unknown and thus no benchmark for com-
parisonis available. Second, it is ofcoursepossible to havea situationwhere selection
is a function of both the pretreatment outcome and also accurate expectations of the
individual-level treatment effect. In this case, the results of the demonstration are as
implied: Neither the change score estimator nor the analysis of covariance estimator
would deliver estimates that are consistent or unbiased for any of the average treat-
menteffects.Third,withdatafromonlytwopointsintime,thereisnowaytoevaluate
whether selection is onthe pretreatmentoutcome using the observeddata.This point
should be obvious from a consideration of Figure 11.5. If we add the effect Y →D
8
to the graph, we have no way to analyze the data to separate this casual effect from
the associationgeneratedby the unobservedvariablein Y ←U→D. Thus, any argu-
8
ment in favor of the change score model would have to rest entirely on an argument
grounded in theory or past research. Finally, if the fan spread pattern emerges in the
same basic pattern considered here, where it only emerges at the same time as the
treatment, analysis will be extremely difficult. However, if the trajectories differ but
canbe effectively modeled as a function ofthe pretreatmentdata frommorethan one
time period, then the model-based strategy we introduce in the final section of this
chapter may be effective.

Return to the question that motivated this demonstration, where we are not in
the fortunate situation of knowing the true values for the ATE, ATT, or ATC. All we
havearealternativetreatmenteffectestimatessuggestedbyachangescoremodel and
an analysis of covariance model. How should one choose between them? There are at
least three possible ways to decide:
1. Choose the method that gives us the results we want.

2. Choose basedon the nature of the problem. As Allison (1990)suggests:If selec-
tion is based on fixed characteristics, use change score analysis. If selection is
based on the dependent variable, use an analysis of covariance.

3. Use the data to determine which model, if either, is appropriate(as in Heckman
and Hotz 1989).

We hope that the first approach to the decision is not a serious consideration. The
second is a better option, in that it at least suggests that one should begin to think
throughthespecificnatureoftheproblemofinterest.Thethirdappearsmostpromis-
ing, at least at face value. However, in some cases (perhaps most where these two
estimators are utilized), we have data from only two points in time. This is the sit-
uation for the estimate of the causal effect of a twelfth year of schooling on IQ. It
is also the case for the demonstration that we have just offered. Unfortunately, with
only two time periods, the data cannot be used to test whether one of the two mod-
els is more appropriate. As we will explain when we discuss model-based approaches
in the next section, we need at least two periods of pretreatment data in order to
carryoutaninformativetest. For example,wewouldbe able toperformatestfor the
demonstration above only if we also had test score data from the seventh grade.

For now, consider the case in which we continue to have data from only one pre-
treatment time point, t−1, and one posttreatment time point, t. Suppose also that
no self-selection on the individual-level treatment effect is present so that the ATT is
equal to the ATE. Consider the implicit assumptions that are made if it is asserted
thateitherachangescoremodelorananalysisofcovariancemodelisaconsistentand
unbiased estimator of the ATT or the ATE:
• Thechangescoremodelassumesthat,intheabsenceof treatment,anydifference
between the expectations of the outcome for those in the treatment group and
those in the control group remains constant over time. With potential outcome
notation, the required assumption for two-period, pretreatment-posttreatment
dataisthatE[Y0 |D∗=1]−E[Y0 |D∗=0]=kandE[Y0|D∗=1]−E[Y0|D∗=
it−1 i it−1 i it i it i
0]=k, where k is the same constant in both time periods t−1 and t. The
constant k can be equal to 0, as in the parallel-trajectories scenarios for Panel
Data Demonstration 2. In this case, there are no differences in E[Y0] between
it
the treatment and control groups in time periods t−1 and t.

• The analysis of covariance model assumes that, in the absence of treatment,
any difference between the expectations of the outcome for those in the treat-
ment group and those in the control group shrinks by a multiplicative factor
r in each subsequent time period. An implication of this assumption is that,
afterenoughtime, the analysisofcovariancemodelassumesthattherewouldbe
no difference in the expected outcomes for the treatment and control groups if
the treatment is not introduced. With potential outcome notation, the required
assumption for two-period, pretreatment-posttreatment data is that any differ-
ence E[Y0 |D∗=1]−E[Y0 |D∗=0]=k inthe pretreatmenttime periodt−1
it−1 i it−1 i
isequaltoE[Y0|D∗=1]−E[Y0|D∗=0]=k×r intheposttreatmenttimeperiod
it i it i
t, where k is the same constant in both time periods and where r is the amount
of between-group shrinkage that is assumed to occur in each and every time
period. Any remaining difference between the two groups approaches 0 in the
limit so that by time period t=∞, E[Y0 |D∗ =1]=E[Y0 |D∗ =0]. In
it=∞ i it=∞ i
addition, the analysis of covariance model assumes that r is equal, in an infi-
nite sample, to the least squares coefficient on Yit−1 in a regression equation
Yit =a+Yit−1b+D i∗c+ei (or Yit =a+Yit−1b+D i∗c+Xiq+ei if additional
adjustment variables in Xi are also specified).

The key difference between these two models is therefore their implicit assumptions
about the evolution of the difference between E[Y0] for the treatment group and for
it
the control group.

Considerageneralequationthatcanbeusedtorepresentthevalueofthe ATEfor
the posttreatment time period t (again assuming that the ATE is equal to the ATT
because no self-selection is present):
(cid:29) (cid:30)
E[δit]= E[Y i1 t|D i∗ =1]−E[Y i0 t−1|D i∗ =1]
(cid:29) (cid:30) (11.11)
−α E[Y0|D∗ =0]−E[Y0 |D∗ =0]
it i it−1 i
for some unknown value α.14 The term in the first set of parentheses is equal to the
average difference in the observed outcome between time periods t−1 and t for the
treatmentgroup.Giventhe definitionofthe observedoutcome,this differenceisequal
to E[Yit|D i∗=1]−E[Yit−1|D i∗=1],whichis the observedgainin the treatmentgroup.

The second term is an adjustment factor. It has two pieces: an unspecified value, α,
andaterminparenthesesthatisthedifferencebetweentimeperiodst−1andtinthe
potential outcome in the absence of the treatment for the control group. The latter
is equal to E[Yit|D i∗=0]−E[Yit−1|D i∗=0], which is the observed gain in the control
group. Equation (11.11) can therefore be rewritten as
E[δit]=(E[Yit|D i∗ =1]−E[Yit−1|D i∗ =1]) (11.12)
−α(E[Yit|D i∗ =0]−E[Yit−1|D i∗ =0]),
and its right-hand side can then be written even more simply with words as
(treatment group gain in Y) − α (control group gain in Y) (11.13)
Thechangescoremodelandtheanalysisofcovariancemodelcanbeseenasalternative
methods that make very different and very rigid assumptions about the value of α in
Equations (11.11)–(11.13). The change score model implicitly assumes that α=1. In
contrast,theanalysisofcovariancemodelimplicitlyassumesthatα=r,wherer isthe
intraclasscorrelationbetween Yit and Yit−1 (i.e., r is the correlationcoefficientfor Yit
and Yit−1). In other contexts, this correlation coefficient r is known as the reliability
of Y. If other covariates are included in the model, then the analysis of covariance
model assumes that the coefficient on Yit−1 is a conditional variant of the intraclass
correlation (i.e., the intraclass correlation of residualized variants of Yit and Yit−1,
from which their common linear dependence on the covariates has been purged).

Researchersoftenbelievethat,becausethecoefficientonYit−1isestimatedfromthe
data,ananalysisofcovariancemodelissuperiortoachangescoremodel.Thisposition
is incorrect. To be sure, an analysisof covariancemodel does estimate a coefficient on
Yit−1, and this coefficient can be interpreted as an intraclass correlation coefficient.

This fact is irrelevant to the more fundamental issue of whether r, or a conditional
variant of it, is the correct adjustment factor for generating consistent estimates of
average treatment effects. In other words, if the goal is to estimate the ATE or ATT,
researchers who favor the analysis of covariance model because it allows the data to
14In this section, we willconsider values for α that would be appropriate for estimating the ATE
because this is the typical scenario in which researchers use change score models and analysis of
covariance models. We could offer an analogous explanation for the ATT in the presence of self-
selection, and here the values for α would be different if self-selection were present. The overall
argumentwouldhavethesamestructurebutwouldbeginwithananalogousexpressionforE[δ it|D i∗=
1] instead of Equation (11.11). We avoid having to do this by stating above that no self-selectionis
presentforthisexplanation, sothattheATEisequal totheATT.

E[Y0]
t α = 1
α < 1
α > 1
t
Figure11.6 ExamplesofpossibletrajectoriesforE[Y0] forthe treatmentgroup(the
it
upper line of each pair) and the control group (the lower line of each pair) where the
correct adjustment favor, α, varies.

determinethecoefficientonYit−1 areassumingimplicitlythatαinEquations(11.11)–
(11.13) should be equal to r, or a conditional variant of it that is determined by the
relationship between Yit−1 and any covariates that are specified.

Consider the graph presented in Figure 11.6, which presents three scenarios for
changes over time in the expected value of the outcome in the absence of the treat-
ment.15 For each pair of lines, the upper line is E[Y0] for the treatment group, and
it
the lower line is E[Y0] for the control group. For the first pair of lines, the correct
it
adjustment factor, α, is equal to 1. In this situation, a change score model is appro-
priate. For the second pair of lines, the correct adjustment factor is less than 1. In
this situation, the change score model is inappropriate, but it is conceivable that the
analysisofcovariancemodel candeliveranestimatedcoefficientonYit−1 thatis equal
to the correct adjustment factor. It is not guaranteed to do so because, even in an
infinite sample, the coefficient on Yit−1 is simply the partial slope for the best linear
predictorof Yit. Finally, this graphshows a third possibility where the correctadjust-
ment factor is greater than 1. In this case, neither the change score model nor the
analysis of covariance model is appropriate. Here, in the absence of treatment, E[Y0]
it
for the treatment group and for the control group diverge over time. There are many
possible examples of this situation, but the most famous is represented by situations
described in the Gospel of Matthew, where it is written, “Unto every one that hath
shall be given, and he shall have abundance: but from him that hath not shall be
taken away even that which he hath” (quoted in Merton 1968, who is credited with
introducing this version of the idea into the social sciences).

The key point is that different methods of estimation make different implicit
assumptions about how the difference in the expectations between the treatment and
controlgroups would change with time in the absence of the treatment (which, in the
15See Judd and Kenny (1981, figure 6.4) for a similar figure and explanation that does not use
potential outcomes.

counterfactualtradition,aredifferentassumptionsabouttreatmentandcontrolgroup
differences in the evolution of E[Y0]). Researchers typically use either change score
it
models or analysis of covariance models without taking note of these assumptions.

Nevertheless, these assumptions canbe very consequential, as we now show in a more
general way than for Panel Data Demonstration 2.

Our claim that any assumption about α is potentially reasonable can be justified
by consideration of the following model for the generation of the potential outcome
variables:
Y i0 t=λi+Tτi, (11.14)
Y i1 t=Y i0 t+δi, (11.15)
where λi is an individual-varying intercept, the variable T identifies the time period,
and τi is an individual-varying coefficient on time T. For this model, the following
equality holds:
E[Y i0 t|D i∗ =1]−E[Y i0 t|D i∗ =0]=(E[λi|D i∗ =1]−E[λi|D i∗ =0]) (11.16)
+T(E[τi|D i∗ =1]−E[τi|D i∗ =0]),
wheretheT ontheright-handsideissetequaltothevalueoftinthesubscriptonthe
left-hand side. Without loss of generality, assume for the moment that (E[λi|D i∗=1]
−E[λi|D i∗=0])>0. In this case, note that whether the initial difference in E[Y i0 t−1]
betweenthoseinthetreatmentgroupandthoseinthecontrolgroupremainsthesame,
grows, or shrinks, respectively, is a function of whether (E[τi|D i∗=1]−E[τi|D i∗=0])
is equal to 0, is greater than 0, or is less than 0.

If we assume that (E[λi|D i∗=1]−E[λi|D i∗=0])=0, then the appropriate adjust-
ment factor, α, equals
α=1+(E[τi|D i∗ =1]−E[τi|D i∗ =0]). (11.17)
If (E[τi|D i∗=1]−E[τi|D i∗=0])=0 (i.e., E[Y i0 t] changes on average over time at the
same rate for individuals in the treatment and controlgroup), then α=1 in Equation
(11.17),andtheassumptionsofthechangescoremodelareappropriate.If(E[τi|D i∗=1]
−E[τi|D i∗=0])=(r−1), which is necessarily nonpositive (because 0<r<1), then
α=r inEquation(11.17),andtheassumptionsoftheanalysisofcovariancemodelare
appropriate instead.

Of course, there is no reason that (E[τi|D i∗=1]−E[τi|D i∗=0]) should necessar-
ily be equal to either 0 or r−1. Thus, it is possible that neither the change score
model nor the analysis of covariancemodel provides the correct adjustment. To bring
this point home, consider Table 11.2, in which the stipulated true causal effect is
1. The table reports different estimates of the average treatment effect for differ-
ent combinations of correct and assumed adjustment factors. Equivalently, because
α=1+(E[τi|D i∗=1]−E[τi|D i∗=0]), the table reports estimates for different actual
and assumed values of the difference in slopes for the treatment and control groups.

Note first that all of the diagonal elements of Table 11.2 are equal to 1. If the
assumed adjustment factor equals the correct adjustment factor, we get the correct
estimate of the causal effect, 1. Below the diagonal are cases where we have overad-
justed (that is, in which the assumed adjustment factor is greater than the correct
Table 11.2 Estimated Average Treatment
Effects for Different Combinations of Correct
and Assumed Adjustment Factors, Where the
True Effect Is Equal to 1
Assumed α
2 1.5 1 .5 0
2 1 1.5 2 2.5 3
1.5 .5 1 1.5 2 2.5
Correct α 1 0 .5 1 1.5 2
.5 −.5 0 .5 1 1.5
0 −1 −.5 0 .5 1
one). As a result, we get estimates of the causal effect that are too low, ranging from
.5 to −1, including an estimate of no effect at all. Above the diagonal, we have cases
where we have underadjusted (that is, the assumed adjustment factor is smaller than
the correct one). As a result, our estimates of the causal effect are too high, ranging
from 1.5 to 3.

For this example, the true average treatment effect is 1 by construction. Across
Table11.2,wehaveestimatesrangingfrom−1to3.Wecouldeasilyexpandtherange
of these estimates by considering a broader range of correct and assumed adjustment
factors.And alternative examples couldbe developedin which the true averagetreat-
menteffectequalsalternativevalues,andinwhichtherangeofestimatesvariesjustas
widely. Although the calculations behind Table 11.2 are simple, the point of the table
is to show that one can obtain any estimate of an averagetreatment effect by making
different assumptions about the appropriate adjustment factor.16
Inviewofthisproblem,whatshouldaresearcherdo?Iftherearestrongtheoretical
reasons for arguing that a particular adjustment factor is correct, and others agree,
then analysisis straightforward.If not, which we suspect is generallythe case,then it
may be possible to argue for a range of adjustment factors. In this case, a researcher
may be able to bound the causal effect to a regionon which all researcherscan agree.

In general, the assumption that a particular adjustment factor is correct must
be based on a set of assumptions about how E[Y0] for those in the treatment and
it
control groups evolves over time. This leads naturally to a more explicit model-based
approach, which we present in the next section. As we will also see, with data from
more than one pretreatment time period, it may be possible to test the adequacy of
the assumptions and thus the appropriateness of a particular adjustment factor.

16RecallPanelDataDemonstration2.There,thedivergent-trajectoryscenariowithnoself-selection
yieldedachangescoreestimatethatwasbiasedupwardby1.Adoptingthelogicofthisexplanation,
the correct adjustment factor was 5/3, so that (110.5−98)−(5/3)(99.5−98)=10. However, the
changescoreestimatorassumedthatthecorrectadjustmentfactorwas1,resultingin(110.5−98)−
(1)(99.5−98)=11.

11.3.2 Model-Based Approaches
Indiscussingpaneldatamodelswehaveuntilnowconsideredonlytraditionalmethods
of estimating a causal effect. There is, however, much merit to considering explicit
models of the evolution of Y1 and Y0 and asking, “Under what model assumptions
it it
dodifferentmethodsgiveconsistentestimates?”Inthissection,wetakethisapproach
and address four questions:
1. What is the dynamic structure of the outcome? In particular, how are future
valuesofthe outcome relatedto previousvaluesofthe outcome?Answeringthis
questioniscriticalifourgoalistoestimatecounterfactualvalues.Inthepotential
outcome framework for the sort of examples we will consider, we are interested
primarilyinthedynamicstructureofY0,whichisthepotentialoutcomevariable
it
under the control state.

2. How is assignment to the treatment determined? As in cross-sectional attempts
to estimate causal effects, modeling treatment assignment/selection is crucial if
a researcher hopes to generate consistent estimates of a particular causal effect.

3. Whatarethe alternativemethods ofestimationthatcanbe usedtoconsistently
estimate average effects, given a valid set of assumptions?
4. How can the estimated model be tested against the data?
We will consider these four questions in this order.

Dynamic Structure
As shown in any advanced time series textbook, the dynamic structure of the out-
come can be infinitely complex. In the context of panel data models, researchershave
typically considered fairly simple structures, often because of the limited number of
wavesof data that are available. Rather than trying to provide anexhaustive account
– which would take a book in and of itself – we primarily focus on conceptual issues.

The broad statistics and econometric literature on panel data models is quite
distinct from the estimation of treatment effects from a counterfactual perspective.

Implicit in much of this literature is the assumption that causal effects are constant
across individuals, such that causes/treatments simply shift the outcome by fixed
amounts.Fromacounterfactualperspective,suchassumptionsareoverlyrigid.Anec-
essarycomponentofestimatingatreatmenteffectistheconsiderationofthehypothet-
ical evolution of Y0 for the treatment group after the treatment occurs. If treatment
it
effects are heterogeneous and selection is on the treatment effect itself, then the ATT
is usually the parameter of interest, as it is often the only one that can be identified
by any model (and, fortunately, it is also often of inherent substantive interest).

Consider the following possible two equations for the generation of Y0:
it
Y i0 t=λi+eit, (11.18)
eit=ρeit−1+vit−1, (11.19)
Table 11.3 Alternative Trajectories of the Outcome Under the Control
State for Different Assumptions About Its Dynamic Structure
Model Assumed Constraints Evolution of Y i0 t
A ρ=0 Var(λi)(cid:6)=0 Immediate regression of individualvalues
to separate group expectations
B ρ(cid:6)=0 Var(λi)=0 Regression overtime of individualvalues
to a common expectation
C ρ(cid:6)=0 Var(λi)(cid:6)=0 Regression overtime of individualvalues
to separate group expectations
whereλi is atime-constant,individual-varyingfixedeffect,vit−1 is purerandomnoise
(that is, uncorrelated with everything), and ρ is the correlation between eit over time
(not the correlation between Y0 over time, which we labeled as r earlier). Equation
it
(11.19) specifies an autoregressive process of order (1). It is order (1) because the
current eit is dependent on only the last eit−1, not eit−2 or any errorsfrom priortime
periods. There are many possible ways that the current error could be dependent on
pasterrors.Thesedefinewhatareknownastheclassofautoregressivemovingaverage
(ARMA) models.

Withinthecurrentcontext(i.e.,assumingthatweknowthatEquations(11.18)and
(11.19) are capable of representingthe full dynamic structure of Y0), determining the
it
dynamicportionofthe modelforY i0 amountsto askingwhether Var(λi)=0, ρ=0, or
t
both. Multiple tests are available to evaluate these restrictions (see, again, texts such
as Hamilton 1994 and Hendry 1995 for comprehensive details). Most standard data
analysis programs allow a researcher to estimate a full model on the pretreatment
values of Yit, assuming that neither Var(λi)=0 nor ρ=0, and then to reestimate
variousconstrainedversions.Thereafter,aresearchercanthenusestandardlikelihood
ratio tests of these model constraints. Such tests on the pretreatment data are not
full tests of how Y0 evolvesfor the treatment groupin the absence of treatment (here
it
again, we are back to the issue for the ITS model in Figure 11.1). Thus, a researcher
most likely will need to make some untestable assumptions.

Consider the following scenarios. If both Var(λi) and ρ are nonzero (and, further-
more, selection into the treatment is on λi only), how then do the values of Y i0 in
t
the treatment and control group evolve? When asking this question, we are implic-
itly considering how E[Y0|D∗=1] and E[Y0|D∗=0] evolve over time toward one or
it i it i
morevalues,eventhoughtheevolutionofthesetwoconditionalexpectationsrepresent
average trajectories of individual-specific patterns of evolution in trajectories of Y0.

it
ConsiderasummaryofthesedifferentsituationsinTable11.3,whicharethendepicted
as pairs of lines in Figure 11.7.

Note that Model A is consistent with the assumptions of the change score model.

ModelBisconsistentwiththeassumptionsoftheanalysisofcovariancemodel.Model
C is consistent with neither, but we suspect that it is the most common scenario in
empirical research.

E[Y0]
t Model A
Model B
Model C
t–2 t–1 t
Figure11.7 Depictions of possible trajectories, as specified by the models in Table
11.3, for E[Y0|D∗=1] (the upper line of each pair, corresponding to the treatment
it i
group) and E[Y0|D∗=0] (the lower line of each pair, corresponding to the control
it i
group).

Many of the most common models in panel data analysis assume that there is
virtually no dynamic structure to the process that generates the outcome. In fact,
most versions of the model that generally goes by the name of a “fixed effects” model
are based on the following implicit model for the generation of Y0 and Y1:
Y i0 t=λi+Tτ+vit, (11.20)
Y i1 t=Y i0 t+δi, (11.21)
where λi is a fixed time constant, individual-level determinant of the outcome in the
absence of treatment, Tτ is a time trend common to all (because T is a variable
measuring time, τ is a constant coefficient that does not vary over individuals or
time), vit is random noise, and δi is an individual-specific additive causal effect that
is assumed to be independent of λi and vit. The assumed data generation process
that motivates the most standard form of a fixed effect model is equivalent to the
assumption that each individual has his or her own intercept, but there is neither
serial correlationin vit nor individual-specific trajectories in time.

Themotivationforthe standardfixedeffects model canbe generalizedbyallowing
each individual to have his or her own slope with respect to time, which is indicated
bysubscriptingτ byiinthe assumeddatagenerationmodelinEquations(11.20)and
(11.21). This more general model is then
Y i0 t=λi+Tτi+vit, (11.22)
Y i1 t=Y i0 t+δi, (11.23)
which, apartfrom the stochastic term vit, was considered already in the previous sec-
tion;seeEquations(11.14)and(11.15).There,weshowedthatallowingfordifferences
between E[τi|D i∗=1] and E[τi|D i∗=0] could lead to the necessity of adjustment fac-
tors ranging from negative to positive infinity. The attractiveness of this model, of
course, is that it allows E[Y0] for the treatment and control groups to evolve in par-
it
allel, diverge, or converge.This will depend, respectively, on whether the difference in
e e e
t–2 t–1 t
Y t–2 Y t
Y
t–1
D
Figure11.8 A model of endogenous treatment assignment in which selection is on
the pretreatment outcome, Yt−1.

the expectedslopes forthe treatmentandcontrolgroupsis zero,positive, ornegative.

But substantial amounts of data are needed to estimate it, and certainly from more
than just one pretreatment time period and one posttreatment time period.

Determining the Assignment Process
As we have argued throughout this book, the key to estimating a treatment effect is
understanding the process of treatment assignment/selection. One of the advantages
of conceptualizing and then analyzing the dynamic process of the outcome is that it
may provide evidence about the factors that structure the assignment process. Two
generalcasesareofparticularinterestandleadtoquitedifferentestimationstrategies.

The issue, however, is potentially tricky in that we may want to condition on one or
moreendogenousvariables.Aswehavediscussedatmanypointsthroughoutthisbook,
conditioning on an endogenous variable that is a collider along a back-door path will
unblockanalreadyblockedback-doorpath,thuscreatinganewsourceofconfounding.

Considerfirstthe caseinwhichassignmentisdirectlyafunctionofpreviousvalues
ofY asinFigure11.8.Inthisgraph,theassociationbetweenYtandDdoesnotidentify
the causal effect of D on Yt because they are connected by a back-door path through
Yt−1:D←Yt−1→Yt.However,this back-doorpathcanbe blockedbyconditioningon
Yt−1.

Note that Yt−1 is a collider on the path et−2→Yt−2→Yt−1←et−1. Thus, condi-
tioningonYt−1 willinduceassociationsbetweenYt−2 andet−1 aswellasbetweenet−2
and et−1. These new associations are unproblematic, however, because they do not
create any new as-if back-door paths between D and Yt. Note also that if we thought
that treatment assignment D was determined by earlier values of Y, we could condi-
tion on these Y’s without creating as-if back-door paths that confound the effect of
interest.

Consider an alternative and much more complex model, presented in Figure 11.9,
where treatment assignment D is determined by λ instead of Yt−1. For this model,
there is an unblockedback-doorpathconnecting D to Yt: D←λ→Yt. What happens
ifweconditiononYt−1?Obviously,theunblockedback-doorpathD←λ→Yt remains
unblockedbecauseYt−1doesnotliealongit.Inaddition,conditioningonYt−1unblocks
a set of already blocked back-door paths because Yt−1 is a collider on the previously
e e e
t–2 t–1 t
Y Y Y
t–2 t–1 t
D
λ
Figure11.9 A model of endogenous treatment assignment in which selection is on a
fixed effect that also determines the outcome.

blockedback-doorpaths representedcollectivelybyD←λ→Yt−1←et−1 (cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)et→
Yt. In combination, conditioning on Yt−1 has only made things worse. We failed to
block the original back-door path that was of concern, and we unblocked already
blocked back-door paths.

Consider this problem from another perspective. Suppose that the standard moti-
vation of a fixed effect model is in place, such that one has reason to believe that Y0
it
and Y1 are generated in the simple way specified for Equations (11.20) and (11.21).

it
Suppose, therefore, that we wish to estimate the following regressionequation:
Yit=li+Ditc+eit, (11.24)
where the li are individual-specific intercepts, and where we then hope that the esti-
mated coefficient c on the treatment exposure variable in time period t will then be
equal to the ATE (or the ATT if self-selection is present).

Ifwehadameasureofλi,thenestimatingthemodelinEquation(11.24)wouldbe
straightforward. We could put in a dummy variable specification to parameterize the
li intercepts. For the graph in Figure 11.9, and from a standard structural equation
perspective, Yit−1 can be thought of as a measure of λi. This then suggests that the
following regressionequation can be estimated instead of Equation (11.24):
Yit=a+Yit−1b+Ditc+eit. (11.25)
IfwethinkofYit−1 asameasureofλi,thenitcontainsmeasurementerrorbecauseitis
alsoafunctionofeit−1.Asaresult,thecoefficientonYit−1 willbedownwardlybiased.

In fact, the estimate of b will be a consistent estimate of r, which is the reliability of
Y.ThisisnotsurprisingbecauseEquation(11.25)istheanalysisofcovariancemodel.

Thus, the analysis of covariance model can be interpreted as a fixed effect model in
which we have used a noisy measure of λi as an adjustment variable.

In the last section, we saw that the choice of either the analysis of covariance
model or the change score model can be consequential. Accordingly, it is critical to
determine whether assignment to D is function of Yit−1 or λi. If we have two or more
pretreatment observations, this is easy to do. The first step is to determine whether
b=c or c=0 in the following model:
Logit(Di)=a+Yit−1b+Yit−2c. (11.26)
InFigure11.8,D isdependentonlyonYt−1.Thus,cshouldequal0.InFigure11.9,D
isassociatedwithonlyYt−1 andYt−2 throughtheirjointdependenceonλ.Asaresult,
b=c.17 Obviously, with this test, we may also include additional observed variables
that we believe also determine D. And the test generalizes in the obvious way when
we observe Y at more than two pretreatment time periods.

Effect Estimation
Extensive discussions exist in the econometrics literature on the estimation of the
fixedeffectsmodelanditsgeneralizations.Basically,therearetwodifferentestimation
strategies. For the differencing approach, the specification is
differencing: Yit−Yit−1=(λi−λi)+(Dit−Dit−1)d (11.27)
+(Xit−Xit−1)b+(eit−eit−1)
=(Dit−Dit−1)d+(Xit−Xit−1)b+(eit−eit−1),
where treatment exposure occurs between time period t−1 and t. In contrast, the
dummy variable approach is
individual dummies: Yit=Pili+Ditd+Xitb+eit, (11.28)
where Pi is a dummy variable for person i and li is its associated coefficient. This
second method amounts to estimating a separate intercept for each individual. It is
alsoequivalenttodifferencingY andX fromtheirrespectiveindividual-levelmeans.If
onewantstoestimatethegeneralizedfixedeffectmodelinwhichthereisaninteraction
betweenanindividualeffectandtime,onecandothisbyeitherdifferencingadditional
timesorbyinteractingtheindividualdummies,Pi,withtimeandestimatingaseparate
interaction term for each dummy.

To understandthe differences between these two approaches,evolving conventions
in data analysis must be noted. For the representationof the change score model and
the analysis of covariance model in Equations (11.4) and (11.5), we conformed to the
17Theseassumptionscanmoreeasilybetestedbyestimatingthemodel
Logit(D i)=a+Y it−1b+(Y it−1+Y it−2)c
and testing whether b=0 or c=0. Here, (Y it−1+Y it−2) is essentially acting as a measure of λ i.

Thisstrategyisbasedonthefollowingtrickoftenusedtotestfortheequalityofcoefficients fortwo
variables X and Z. Let the coefficient on X bem and on Z bem+n. Runthe followingregression
equation:
Y =Xm+Z(m+p)+u
=(X+Z)m+Zp+u
anduseastandardstatisticaltesttoevaluate thenullhypothesis thatp=0.

convention in the literature wherein the models are written out so that they can be
estimated easily with a cross-sectionaldataset. In other words,time is encoded in the
variables, so that time-varying outcome variables, Yit and Yit−1, are regressed on a
cross-sectional treatment group dummy variable D∗ in an implicit dataset with one
i
record for each of N individuals. This data setup is also the implicit background for
the differencing specification of the fixed effect estimator in Equation (11.27).

As can be seen in virtually any panel data textbook (e.g., Baltagi 2005), the con-
ventionistonowstructureone’sdatasetinperson–timerecords,whichresultsinN×T
records rather than N records. Forcing time to be constant within each data record
allows for variables such as Dit and D i∗ to be cleanly parameterized in subsequent
analysis. This data setup is the implicit background for the individual dummy speci-
fication of the fixed effect estimator in Equation (11.28), and that is why there is no
referencetotime t−1versustimetinEquation(11.28).Throughouttheremainderof
this section,wewillwrite withsuchanN×T datasetinmind. The ideas,however,do
not depend onsuchanimplicit structuring, as one canswitchback andforth between
both setups based on analogs to Equations (11.27) and (11.28).

As for the alternative fixed effect specifications in Equations (11.27) and (11.28),
the two methods giveidenticalanswerswhen there are only two points in time. When
the errors are correlated across time and there are more than two time periods, the
two methods will give somewhat different estimates, although both estimators are
consistent. Which estimator is preferable depends on the nature of the correlation
structure. We need not be concerned about this issue here; see Baltagi (2005), Hsiao
(2003), and Wooldridge (2010) for discussion.

Traditional fixed effect and differencing methods are generally inefficient, how-
ever, if the goal is only to estimate the effect of a treatment. These methods simply
eliminate unobserved individual effects from the data. Doing so powerfully eliminates
all associations between the treatment variable Dit and unobserved time-constant,
individual-level variables. If the coefficients of all observed variables are of interest,
then this is appropriate.

In the present case, however, our focus is simply on estimating the effect of treat-
ment exposure, Dit. As pointed out repeatedly in previous chapters, one approach
to consistently estimate the effect of Dit is to balance the data with respect to all
systematic determinants of Dit. As discussed in the last section, our interest in the
case of linear models (the situation with nonlinear models being more complicated)
is in differences in the expected trajectories of Y0 for those in the treatment group
it
and those in the control group. If we want to use the average observed values of Yit
in the controlgroupin the posttreatmenttime periods in orderto predictthe average
counterfactualvaluesofY0 inthe treatmentgroupinthe posttreatmenttime periods,
it
then it is essential that differences in the average trajectories of these two groups be
modeled effectively.

Tobemoreconcrete,supposethatwehavethreetime points.Iftheonlydifference
inthe expected trajectoriesofY0 for the twogroupsisintheir averagelevels,then all
it
we need to do is allow for differences in group-level intercepts by estimating
∗
Yit=a+D ib+Ditd+eit. (11.29)
Here,thecoefficientbcapturesdifferencesintheexpectedtrajectoriesforthetreatment
andcontrolgroups,suchthattheinterceptforthecontrolgroupisaandtheintercept
for the treatment group is a+b.18
If the expected trajectories also differ in their slopes, then we need to include a
term for time and an interaction term between group membership and time, as in
i∗ i∗×T)c(cid:2)
Yit=a+D b+Tc+(D +Ditd+eit. (11.30)
The coefficient b again captures differences in the expected trajectories, and c(cid:2) now
captures differences in the slopes of the expected trajectories. Interactions between
D∗ and higher-order polynomials of T (or any other function of time) can also be
introduced, assuming sufficient pretreatment data are available.

Estimating the model in Equation (11.30) is equivalent to differencing out the
treatment/controlgroup expectations of λi and τi in the following assumed data gen-
eration model for Y0 and Y1, based on an augmentation of Equations (11.22) and
(11.23). Expanding a standard fixed effect model separately for the treatment and
control groups using the time-constant indicator of the treatment group D∗ yields
∗
forD =0: (11.31)
i
Y i0 t,D∗=0=(μλ,D∗=0+vi,D∗=0)+T(μτ,D∗=0+τ i(cid:2) ,D∗=0),
Y i1 t=Y i0 t+δi,
and
∗
forD =1: (11.32)
i
Y i0 t,D∗=1=(μλ,D∗=1+vi,D∗=1)+T(μτ,D∗=1+τ i(cid:2) ,D∗=1),
Y i1 t=Y i0 t+δi.

Here,μλ,D∗=0 istheexpectationofλi inthecontrolgroup,andλi=μλ,D∗=0+vi,D∗=0
forthoseinthe controlgroup.Likewise,μτ,D∗=0 is the expectationofτi inthe control
group, and τi=μτ,D∗=0+τ i(cid:2) for those in the control group. The terms for the
λ,D∗=0
treatment group are defined analogously.

In this setup, the terms vi,D∗=0, vi,D∗=1, Tτ i(cid:2) ,D∗=0, and Tτ i(cid:2) become compo-
,D∗=1
nents of the error term eit of Equation (11.30) as constant individual-level differences
vi andtime-varyingindividualdifferencesTτ i(cid:2).Becausevi,D∗=0,vi,D∗=1,Tτ i(cid:2) ,D∗=0,and
Tτ i(cid:2) are all by construction uncorrelated with D i∗, eit is uncorrelated with D i∗,
,D∗=1
assuminganyextraindividualortime-varyingnoiseembeddedwithineit iscompletely
random. Furthermore, the coefficient a in Equation (11.30) is equal to μλ,D∗=0, and
the coefficient b is equal to μλ,D∗=1− μλ,D∗=0. Thus, b captures the difference in the
expected intercept for individuals in the treatment and control groups. Likewise, the
coefficientcinEquation(11.30)isequaltoμτ,D∗=0,andthecoefficientc(cid:2) isthenequal
toμτ,D∗=1−μτ,D∗=0.Andthusc(cid:2) capturesthedifferenceinexpectedslopeofthetime
trends for individuals in the treatment and control groups.

18Notice that we can include both D it and D i∗ in the same regression equation because we have
multiplerecordsforeachindividualovertimeinourdataset.Inposttreatmenttimeperiods,D i∗=D
it
forallindividuals(assumingthatnooneleavesthetreatmentstatebeforetheendofthestudy),but
inpretreatmenttimeperiods,D i∗=D it onlyforindividualsinthecontrolgroup.

The coefficient d on Dit is a consistent estimate of the ATE because the expec-
tations of λi and τi are balanced across the treatment and control groups. All of
their systematic components related to treatment group membership are parameter-
ized completely by a, b, c, and c(cid:2). This leaves all remaining components of the distri-
butions of λi and τi safely relegated to the error term.19
There are two advantages of estimating Equation (11.30), as opposed to using
traditionalmethods forestimating fixed effectmodels andtheir generalizations.First,
conceptually, the model makes clear that if the goalis consistent estimation, then the
expected trajectories of Y0 for the treatment and control groups must be correctly
it
modeled, not necessarily all individual-specific trajectories. Later, we show how this
principle leads to a general specification test. Second, there are potential efficiency
gains. For example, in a standard fixed effect model, half of the overall degrees of
freedom are lost by specifying individual-specific fixed effects (when there are only
two time periods of data). In estimating Equation(11.30), only one degreeof freedom
is lost to an estimate of the difference in the intercept for the mean of Y0. We should
it
note, however, that this minimization in the loss of degrees of freedom is moderated
bythefactthattheerrorsinEquation(11.30)arelikelytobehighlycorrelatedwithin
individuals (because the errors within individuals include a common fixed effect). An
estimation procedure should be used for the standard errors that accounts for this
correlation.

In the situation in which Yit is determined only by Yit−1 and Dit, estimation is
simpler. As already discussed with reference to Figure 11.8, conditioning on Yit−1 is
sufficient to block all back-door paths connecting D to Yit. How the necessary condi-
tioningshouldbeperformedwilldependonthedetailsoftheapplication.Conditioning
could be done by matching, as in the analysis of Dehejia and Wahba (1999) for the
National Supported Work data (although there is no evidence that they attempt to
test the suitability of this specification as opposed to a fixed effect specification).20
Alternatively,Yit−1 couldbeconditionedonbyaregressionmodel,asinananalysisof
covariancemodel.Thesemodelswillnotyieldthe sameresults,anditmaybe difficult
to choose between them. More complicated specifications in which Yit is a function of
both Yit−1 and individual-level variables are also possible. Halaby (2004) provides a
clear introduction to these methods.

Model Testing
Bynow,we hopeto haveconvincedthe readerthatmaintainedmodelingassumptions
can have large consequences. Given this dependence, it is critical that researchers
be explicit about the assumptions that they have made and be able to defend those
assumptions.Assumptionscanbedefendedeithertheoreticallyoronempiricalgrounds.

Often neither is done. In fact, they are made often without any explicit recognition.

Fortunately, if pretreatment observations are available for multiple time periods, it is
19Moreover,because thismodelissetupas alinearspecification ofthetreatment effect, alackof
balanceinhigher-order(centered) momentsofλ i andτ i doesnotaffecttheestimationofd.

20Fordetaileddiscussionsoftheappropriatemodelspecificationforthesedata,seeSmithandTodd
(2005) andassociatedcommentandreply.

possible in many circumstances to test the assumptions against the data. Here, we
describe two conceptually different, but mathematically closely related, approaches.

In discussing strategies to increase confidence in a causal effect estimate from an
ITS model, we suggested that a researcher could either use a dependent variable for
whichno effect should occur or estimate the effect for a groupfor which no treatment
effect should occur. Evidence of a treatment effect in either case is evidence that the
model is misspecified.

HeckmanandHotz(1989)suggestapplyingthissameprincipletopaneldatawhen
twoormorepretreatmentwavesofdataareavailable.Specifically,theysuggesttaking
one of the pretreatment outcomes and analyzing it as if it occurred posttreatment. A
researcherthensimplyappliestheestimationmethodtothenewpseudo-posttreatment
data and tests for whether there is evidence of a “treatment effect.” Because neither
the treatment nor the control group has experienced a treatment in the data under
consideration,evidence ofatreatmenteffectisevidencethatthe modelis misspecified
(i.e., that the model has failed to fully adjust for differences between the treatment
and control groups).

In the analysis of covariance model, care must be taken. Here, it is implicitly
assumedthat selection is on Yit−1. For example, for a logit specification of the proba-
bility of treatment selection, it is implicitly assumed that
∗
Logit(D i)=a+Yit−1b. (11.33)
Inthismodel,D i∗ isafunctionofYit−1.Thisismathematicallyequivalenttomaintain-
ing that D i∗ is a function of Yit−2+(Yit−1−Yit−2). Generally, Yit−1 will be correlated
with (Yit−1−Yit−2). Consider the following model:
∗
Yit−1=a+Yit−2r+D ic+ui. (11.34)
BecauseD i∗ isafunctionofbothYit−1 and(Yit−1−Yit−2),andYit−1 iscorrelatedwith
the latter term, in general c will not equal 0. The basic point is that D∗ is partially
i
a function of a component of Yit−1 that is not contained in Yit−2. In general, the
coefficient c on D∗ is a function of this dependence.

i
We can, however, run time backwards. Accordingly, we can estimate
Yit−2=a+Yit−1r+vi. (11.35)
If we are going to use the testing strategy of Heckman and Hotz (1989) to evaluate
an analysis of covariance model, we should then test whether c=0 in the following
related model:
∗
Yit−2=a+Yit−1r+D ic+ei. (11.36)
Because there is no component of D i∗ that depends on Yit−2 conditional on Yit−1, c
shouldequal0 in this model if the analysisof covariancemodel has correctlyadjusted
for treatment group differences in Yit−2.

HeckmanandHotz’stestalsoindicateshowtwo-period,pretreatment-posttreatment
data can be used. What we should do is fit a cross-sectional model. We should then
treatthepretreatmentoutcomeasifitwereaposttreatmentoutcomeandthentestfor
a treatment effect. Evidence of a treatment effect is evidence that our cross-sectional
model has failed to fully adjust for pretreatment differences between the treatment
and control groups.

To better understand these procedures, consider a more general specification of
this type of test. Recall that, net of our adjustments for variousfunctions of time and
other variables, we seek to evaluate for these tests whether the trajectories of Y0 are
it
equivalent in the pretreatment data for the treatment and control groups. A variety
of different models can be assessed. A fixed effect model allows for differences in the
intercepts for two groups.A model with individual- or group-specific time coefficients
allows for differences in slopes. If we have enough pretreatment data, we can add
additionalfunctionsoftimetoourmodelandtherebyallowforevenmoreheterogeneity
for the trajectories of Y0.

it
The most general specification would be to choose one time period as the base,
create a dummy variable for all other time periods, and allow these dummy variables
to fully interact with our treatment group indicator D∗. This is what is known as the
saturatedmodelinthistradition.Itisacompletelyflexiblefunctionalformandallows
for completely separate time trajectoriesfor Y0 for the treatment and control groups.

it
It is of little use in estimating the true causal effect.

Using just the pretreatment data, we can, however, compare the saturated model
with any more restrictive model – such as a fixed effects model – using an F-test
or likelihood ratio test. Evidence that the more restrictive model does not fit is evi-
dence that the more restrictive model fails to fully model the differences between the
treatment and control groups in the trajectories of Y0.

it
ConsidertheresultsofHeckmanandHotz(1989),aportionofwhichispresentedin
Table11.4.21 Fortheiranalysis,HeckmanandHotzestimatedawiderangeofalterna-
tivemodelsoftheeffectoftheNationalSupportedWorkprogramonthe1978earnings
of participants who were high school dropouts. The first column reports selected esti-
mated effects from their study. The experimental estimate suggests that there is no
evidence that the program has an effect (given a point estimate of −$48 with a stan-
darderrorof$144).The regressionandfixedeffectmodels showlargenegativeeffects,
whicharestatisticallysignificantbyconventionalstandards.Therandom-growthmod-
els,whichallowforindividualslopecoefficientsforthetrajectoriesofearnings,suggest
a modest but still nonsignificant negative effect.

ThesecondcolumnofTable11.4reportsthepvaluesfortestsofnotreatmenteffect,
in which the preprogram1975 earnings are used as if they were in fact posttreatment
earnings. If the models that are tested adequately adjust for underlying differences
between the treatment and control groups in the trajectories of earnings, one would
expectthe treatmenteffect estimate to be nonsignificant(i.e.,havea highp value). In
the case of the regression and fixed effects models, the faux-treatment-effect estimate
is highly significant, indicating a lack of model fit. In the case of the random-growth
model, however,it appears to fit the data.

21Although Heckman and Hotz (1989) is an exemplary early example of this sort of analysis, the
basicspecificationtestapproachisusedinoneformoranotherinotherworkaswell(e.g.,Petersen,
Penner,andHøgsnes2011).

Table 11.4 Specification Tests from the Analysis of Heckman and Hotz (1989) of
the Effect of the National Supported Work Programon the Earnings of High School
Dropouts
p valuesfor specification tests
Preprogram Postprogram
Estimated effect, in dollers 1975 earnings 1978 earnings
Experiment −48
(144)
Regression −1884 .000 .000
(247)
Fixed effect model −1886 .000 .000
(pre-1972) (242)
Random-growth model −231 .375 .329
(pre-1972 and 1973) (414)
Note:Resultsarefromtables3and5ofHeckmanandHotz(1989).

The third column reports results from a similar test, where Heckman and Hotz
analyze the valid 1978 posttreatment data as if one time period was in fact pretreat-
mentdata.Again,theytestforwhetherthereisevidenceofatreatmenteffect.Aswith
the tests reported in the second column, if the model is properly specified, then there
shouldbenoevidenceofatreatmenteffect.Butherealsothepvaluesfortheregression
and fixed effects models suggest a significant treatment effect, indicating that these
models do not fit the data. And, as before, the p value for the random-growth model
indicates that it fits the data.22
TheNationalSupportedWorkdatahavebeenanalyzedbymanydifferentsocialsci-
entists,andtheyareperhapsthemostwidelyuseddatatoassesstherelativeexplana-
tory power of alternative types of panel data estimators. There has been considerable
debateaboutwhetherornotresearchersneedmethodsthattakeaccountofunobserv-
ables or whether adjusting only for observables is sufficient. Smith and Todd (2005;
see also the associated comment and reply) show clearly how sensitive estimates can
be to the sample that is chosen. Their results support Heckman’s position that there
are important situations for which treatment selection is likely to be a function of
unobserved variables.

22A note of caution is warranted here. As in all situations, the power of these tests is a function
of sample size. In this case, there are only 566 treatment cases. From the data, it is impossible to
tell whether the random-growth model fits the data because it is a sufficiently correct model of the
underlyingindividual-specifictrajectoriesorratherbecausethesampleissmall.

## 11.4 Conclusions

Longitudinaldatamaybehelpfulforestimatingcausaleffects,butlongitudinaldatado

notconstituteamagicbullet.Defendableassumptionsaboutthetreatmentassignment
process must be specified. And, to use longitudinal data to its maximum potential,
researchers must carefully consider the dynamic process that generates the outcome,
clearly define the causaleffect of interest, andthen use constrainedmodels only when
there is reason to believe that they fit the underlying data.

With this chapter,we havecompletedourconsiderationofidentificationand anal-
ysisstrategiesthatcanbereliedupontoestimatetheATE,ATT, andATC.Wemake
no claim to have considered anything but a subset of all strategies that are available,
butwehaveattemptedtocoverthematerialthatreceivesthemostattentioninthelit-
erature.Inthenextchapter,weconsiderhowanalysiscanproceedwhentheprospects
are low for point identification of a causal effect of interest. Informative empirical
analysis is still possible, even though strong causal conclusions cannot be developed.

## 11.5 Appendix to Chapter 11: Time-Varying Treatment Regimes

The longitudinaldatamodels andanalysisstrategiesthatwe haveconsideredupuntil

this point make the strong assumptions that the treatment is administered only once
and that the timing of the treatment is fixed. Models that relax these assumptions
are needed in order to consider research questions where they cannot be sustained,
or where maintaining them alters the structure of the questions that are of genuine
interest.Socialscientistsregularlyencountersystemsofcausaleffectswherethetiming
of the treatment varies across individuals and where the treatment is repeated across
multiple time periods in dynamic fashion.

Dealing with data where the timing of the treatment varies and where there are
multiple treatments at different times complicates analysis considerably. First, indi-
vidualsmaydiffernotonlyinwhethertheyreceivethetreatmentornot,buttheyalso
may differ on when the treatment is received. These additional sources of differences
betweenindividualsleadtonewidentificationchallenges.Second,newquestionsabout
treatmenteffectsmaybeofinterest:Doesitmatterwhenthetreatmentoccurs?Ifthere
are repeated treatments, what are the effects of different combinations of treatments?
Third, new estimation requirements arise. Even in the seemingly ideal case where
ignorabilityholds(i.e., therearenounobservedconfoundersofthetreatmentsandthe
outcomes,sothatallcausaleffectsareidentified),standardconditioningmethodssuch
as matching and regression do not always provide consistent estimates. As a result,
new specialized methods must be utilized.

Robins and his collaborators have developed several different approaches to mod-
eling data where treatments vary in these ways (see Robins 1997, 1998, 1999, 2000;
Robins and Hern´an 2009). Unfortunately, these methods do not solve the problem of
selectionontheunobservablesthatthemainbodyofthischapteraddresses.Infact,as
we will discuss below, serious estimation challenges exist even in the absence of selec-
tion on the unobservables, with the main challenge being the dependency between
treatmentstatesandintermediateoutcomesevenwhenunconfoundednessholds.Even
so, the methods we present in this appendix are an exciting frontier of methodologi-
cal scholarship that social scientists need to learn. And directed graphs elucidate the
crucial issues.

In this appendix, we will follow the presentation of Robins and Hern´an (2009).

We will examine methods that areappropriatewhen the datahavebeen generatedby
what is known as a “dynamic treatment regime” – a treatment exposure at one point
in time is potentially a function of pasttreatment history and/orcurrent and/orpast
time-varying covariates. However, we will only discuss the estimation of the effects
of what are called “static regimes”: the difference in an outcome between individuals
when all individuals follow one regime versus another regime. Thus, although we will
assume that the data have been generated by a dynamic regime, we will focus on the
effects of static regimes.

Types of Regimes
Fixed Treatment Regimes. Situations where the timing of a single treatment
or multiple treatments is determined at the beginning of the study are considered to
have fixed treatment times. The case where treatment occurs at the same time for
all individuals provides the simplest case. The Operation Ceasefire study discussed
in Section 11.1 is an example. A college or university where promotion to associate
professor always occurs in the sixth year after initial appointment is another. More
complicatedexamplesarealsopossible.Arandomizedexperimentfortheevaluationof
aworkertrainingprogram(LaLonde1986)wouldbeconsideredtohavefixedtreatment
times, even though participants in the experiment have work histories of different
lengths, because for each individual the timing of treatment assignment is known at
baseline and thus fixed. A medical treatment regime where different doses or types of
drugs are taken for fixed periods of time would be considered to have fixed treatment
times as long as which drugs are taken and how long they are taken are determined
at baseline.

Nondynamic Regimes. When treatment assignment is endogenous in the
restricted sense that treatment status at one point in time is a (nondeterministic)
function of treatment status at prior points in time, the treatment regime is labeled
“nondynamic” by Robins and Herna´n (2009). We do not find this label particularly
helpful. The classic example is a sequentially randomized experiment where individ-
uals are randomized at different stages to different treatment possibilities, such that
the probability of receiving a treatment at a later stage is solely a function of the
outcome of a previous randomization. A simple example would be a worker training
experimentwhere(1)individualsarefirstrandomizedtoeithertrainingornotraining
andthen(2)individualswhoareassignedtotrainingarethenrandomizedintospecific
trainingprogramsforeithercomputerskillsorconstructionskills.Thekeyfeatureofa
nondynamic regime is that all randomizationprobabilities are fixed at baseline before
randomizationis enacted, sothat the randomizationprobabilities are notfunctions of
eithertime-varyingcovariatesoractualpriortreatmentstatuses.Whensuchadditional
dependence does exist, the regime is considered to be dynamic.

Dynamic Regimes. Fixed and nondynamic treatment regimes represent con-
strainedformsoftime-varyingtreatmentstructures,andtheyaretheonesthatpresent
no new analysis challenges beyond those explained in prior chapters of this book.

Dynamictreatmentregimesareamoregeneralclassofmodelswheretreatmentstatus
at time t, Dt, is determined by a covariate or set of time-varying covariates that may
be functions of earlier treatments. The classic example comes from medicine, where
treatmentattime t is determinedasa function ofthe patient’s observedsymptoms at
timet,whichare,inturn,afunctionofwhetherornotthepatientreceivedatreatment
in a prior time period. There are many social science examples as well, and we next
consider an example that follows from others we have considered in this book.

The Catholic School Example as a Dynamic Treatment Regime
Consider the effect of Catholic schooling on twelfth grade test scores. For a dynamic
treatment regime version of this effect, we allow students to do what some of them
areactuallyobservedtodo:changethe typeofschool–Catholicorpublic –thatthey
are enrolled in between the tenth and twelfth grades.23 In order to keep the example
from becoming too complex, we assume that students can only change type of school
at the end of tenth grade (i.e., students are assumed to be in the same type of school
in both the eleventh and the twelfth grades).

The indicator variables for enrollment type in the tenth grade and in the eleventh
and twelfth grades are D and D , respectively. Students may follow any of the
10 12
following four regimes:
1. D =D =0 (public school throughout),
10 12
2. D =D =1 (Catholic school throughout),
10 12
3. D =1, D =0 (Catholic school, then public school),
10 12
4. D =0, D =1 (public school, then Catholic school).

10 12
The questions for analysis are how twelfth grade tests scores are affected by these
alternative treatment regimes, not simply what the effect of twelfth grade enrollment
status is on test scores in the twelfth grade. The effect of Catholic schooling is likely
to differ acrossstudents whohavebeenenrolledinCatholic schoolscontinuouslyfrom
the tenth grade throughthe twelfth grade in comparisonto students who switch from
public schools after the tenth grade and are then enrolled in Catholic schools in the
eleventh and twelfth grades.

Becauseofthecomplexityoftreatmentregimepatterns,wethereforeneedtounder-
stand the effects that generate tenth grade test scores, even if our primary goal is to
estimate effects that can be measured at the end of high school in the twelfth grade.

Accordingly, we must model test scores in both the tenth and twelfth grades, Y and
10
Y , respectively. For this appendix, we will reduce the complexity of our discussion
12
and the worked example we offer below by analyzing Y and Y as two dummy
10 12
variables that indicate whether students receive high rather than low test scores.

23For Panel Data Demonstration 1 (see page 273), we considered the effect of Catholic schooling
on tenth and twelfth grade test scores, but we restricted attention, as in the existing literature, to
studentswhoremainedinthesametypesofschoolsinbothgrades.ForPanelDataDemonstration2
(seepage365),weconsideredonlytheeffects ofCatholicschoolingontenthgradetestscores,which
wemodeledusingpretreatmentoutcome measuresfromtheeighthgrade.

D
10
Y Y
10 D 12
12
U
Figure11.10 TheCatholicschooleffectinthetenthandtwelfthgradesasadynamic
treatment regime.

Consider the directed graph in Figure 11.10. In order to keep the discussion as
simple as possible, Figure 11.10 does not include any observed variables other than
the two treatment indicator variables, D and D , and the two outcome indicator
10 12
variables, Y and Y . Additional observed variables would affect any or all of these
10 12
four variables, as in the other demonstrations in this book that analyze the Catholic
schooleffect.ItisappropriatetothinkofFigure11.10asthegraphthatapplieswithin
onestratumdefinedbysomecombinationofothervariables.Thissimplificationimplies
that, unlike in the other demonstrations, we ignore the determinants of D (see, for
10
example,Equations(5.24)and(5.25)inMatchingDemonstration4).This meansthat
we are holding aside all of the other complications shown in prior demonstrations
and now considering an additional set of complications that would still remain if we
could solve all of the other complications explained in prior demonstrations. A more
realistic model would include variables that would allow us to demonstrate all of the
complications at once, but our presentation would then lose focus on the issues we
wish to explain in this appendix.

For Figure 11.10, we also assume that whether a student is enrolled in a Catholic
school by the twelfth grade, D , is solely determined by whether the student was
12
enrolled in a Catholic school in tenth grade, D , and by how successful the student
10
was on the test at the end of tenth grade, Y . Thus, the directed graph allows for
10
persistenceeffects(i.e.,studentsmaybemorelikelytobeinthesametypeofschoolin
twelfthgradeasinthetenthgrade)andalsothepossibilitythatsomestudentschange
school type based on test performance at the end of the tenth grade. For example,
the directed graph is consistent with scenarios where students in public schools who
perform poorly at the end tenth grade switch to Catholic schools thereafter.

Finally, note the restrictedway in which the unobservedvariable U structures Y
10
andY andnothingelseinthegraph.Becausewehaveassumedthatweareanalyzing
12
Figure11.10withinastratumdefinedbyvariablesthatmayalsodeterminetreatment
assignment,the unobservedvariableU inFigure 11.10is not one ofthe variables that
define these strata. U might reflect the portions of innate intelligence, motivation,
or other variables that determine the test score outcomes but that have no role in
structuringtreatmentselectiondecisions.The criticalassumptioninthe modelis that
selection into D is solely a function of observed variables, in this case D and Y .

12 10 10
Unobserved variables that determine D and either Y or Y are assumed not to
12 10 12
exist. As we discuss below, this assumption is the key to identification.

To clarify the language of treatment regimes, note that Figure 11.10 represents a
dynamic treatment regime because the second treatment, D , is determined by an
12
intermediate outcome, Y , that is itself determined by the initial treatment, D . If
10 10
Y were omitted from Figure 11.10, we would then have a nondynamic treatment
10
regime because the second treatment, D , would be determined only by the first
12
treatment,D ,inadditionto idiosyncraticdeterminants unrelatedto allelse.And,if
10
the dependence of D on D did not exist, we would have a fixed treatment regime
12 10
consisting of the two treatments, D and D , that could be analyzed separately
10 12
without concern for the implications of one analysis on the other.

Independent of whether Figure 11.10 contains Y or not, or whether D is a
10 10
cause of D or not, the directed graph represents a structure of effects that is equiv-
12
alent to a sequentially randomized experiment. Because D is a function of no other
10
variables, it is akin to a randomized treatment (again, within strata of observed and
unobservedvariablesthatstructuretreatmentassignmentintheworldsconsideredfor
priordemonstrations).Analogously,D canbe thoughtofashavingbeendetermined
12
by a randomization scheme where the probability of receiving the treatment in the
twelfth grade is determined by two specific observed variables, D and Y . Since
10 10
the directed graph in Figure 11.10 represents a sequentially randomized experiment,
ignorability holds with the result that the total causal effects of D on Y , D on
10 10 10
Y , and D on Y are all identified. We explain this result, and related results for
12 12 12
direct causal effects, in considerable detail below.

General Identification Conditions
As noted in the introduction to this appendix, our concern now is whether it is pos-
sible to identify the causal effects of a fixed regime (i.e., the effects of combinations
across time of Catholic and public school enrollment) from data generated as part
of a dynamic treatment regime. Identification of the causal effect of a fixed regime
of treatments holds under three conditions, two of which are demanding and worth
explaining.24 The most important condition is that sequential ignorability holds (i.e.,
conditionalonobservables,treatmentassignmentineachtimeperiodisindependentof
the potential outcomes). This assumption is equivalent to maintaining that no unob-
servedconfoundersexistthatdetermineboththetreatmentsandoutcomes.Ingeneral,
thisconditionisuntestableandmustbedefendedbyappealstosubstantiveknowledge.

We have discussed this issue extensively in previous chapters.

For this appendix, we are assuming away this problem by focusing on an analysis
within a stratum where we can assume that sequential ignorability holds. Return to
the directed graph in Figure 11.10. The fact that it has the same structure as the
directed graphthat would be an appropriaterepresentationofa sequentially random-
ized experiment means that ignorability holds for both D and D separately and
10 12
together. This result can be confirmed by noting that neither D nor D is affected
10 12
by any unobserved confounders that also affect either Y or Y .

10 12
The second condition is known as positivity. For this condition, it must be the
case that at least some individuals have followed each logically possible treatment
24Thethirdconditioniswhatisknownasconsistency,whichstatesthatthevalueoftherealizedY
underaspecifictreatmentconditionisequaltothepotentialoutcomeunderthattreatment.Hernan
(2005) discussessituationswhereconsistency maynothold.

regime within each stratum. When there are a large number of possible treatment
combinations and/or strata, nonpositivity can be a serious problem because there
may well be too few individuals (indeed, perhaps none) in particular combinations of
treatments andthe strata defined by observedconfounders. As with any stratification
procedure,onemayfacethe“curseofdimensionality.”Aswediscussbelow,themethod
ofG-computation,whichisastratification-typeprocedure,isoftenimpracticalbecause
ofthecurseofdimensionality(eventhoughG-computationisaveryusefulwaytothink
through identification results).

A Specific Setup of the Dynamic Treatment Regime Variant
of the Catholic School Example
In order to demonstrate how various methods do or do not work, we now introduce
a hypothetical empirical dataset that is consistent with the directed graph in Figure
11.10. We do so in two steps. First, we posit a set of equations consistent with Figure
11.10. To keep matters simple, we use linear equations, although we will allow for
interactions. Second, we generate a table of the expected values for the endogenous
variables in the directed graph in Figure 11.10. We use expected values as opposed
to a fully simulated dataset because this setup makes it easier to demonstrate that a
particular estimation strategy will generate consistent estimates of effects of interest.

First, we assume that E[D ]=.20because 20 percentofthe students are enrolled
10
inCatholicschoolsinthe tenth grade.U is adummy indicatorvariablethatmeasures
whether a student is high, as opposed to low, on unobserved characteristics, such as
motivation, effort, and mental ability. We assume that E[U]=.60 because 60 percent
ofstudents areinthe highcategoryforU. Withthese distributionsfor D andU,we
10
set the expected value of test scores at the end of tenth grade as
E[Y |D ,U]=.1+.2D +.4U. (11.37)
10 10 10
Enrolling in a Catholic school increases the probability that a student will be in the
high-test-score group by .2. In addition, being in the high category of the unobserved
variable (U =1) increases the probability of being in the high-test-score category
by .4.25
25NotethatwehavenotdefinedE[Y 10|D 10,U]directlyinvaluesofunderlyingpotentialoutcomes.

WecoulddosobyworkingtowardaconditionalexpectationfunctionanalogoustoEquation(11.37)
bystartingwiththreeequations:
Y 10 2=.1+.4U+υ0,
Y 11 0=Y 10 0+.2+υ1,
Y 10=D 10Y 11 0+(1−D 10)Y 10 0.

We will not use this type of setup for this example because we will not focus on individual-level
variability of causal effects and because the Markov structure of Figure 11.10, along with binary
variables, allows us to fit saturated models to recover all conditional expectations that match those
we could define explicitly with potential outcomes. This is consistent with the dynamic treatment
regime literature, where Markov assumptions for (sometimes implicit) causal graphs are often used
toallowforaconsiderationofcausaleffectsthatarestructuredbyhowobservedtreatmentvariables
have effects on observed outcome variables. These observed outcome variables could be defined in
termsofunderlyingpotential outcomes.

Having set the distributions for D and Y , we then set enrollment in Catholic
10 10
schools in the twelfth grade as
E[D |D ,Y ]=.5+.4D −.4Y +.4(D ×Y ), (11.38)
12 10 10 10 10 10 10
whichspecifiesacross-productinteractionbetweenD andY .Accordingly,Equation
10 10
(11.38)indicatesthat,forstudentsenrolledinpublicschoolsinthetenthgrade(D =
10
0) and in the low-test-score group (Y =0), their probability of being in a Catholic
10
school in the twelfth grade is .5. However, for students enrolled in a public school in
tenth grade (D = 0) and in the high-test-score group (Y =1), their probability of
10 10
being inCatholicschoolinthe twelfthgradeisonly.1.We specify this patterntogive
the treatment regimea dynamic structure where students doing well in public schools
attheendofthe tenthgradearemuchlesslikelytodecidetoswitchenrollmentstatus
to enter into a Catholic school in the twelfth grade. Finally, for students enrolled in
Catholic schools in the tenth grade (D =1), the probability of being in a Catholic
10
schoolin the twelfth gradeis .9, regardlessofwhether or notthese students are inthe
high-test-score or the low-test-score groups at the end of the tenth grade.

To complete the specification ofthe example,we setthe expected value ofthe test
scores at the end of the twelfth grade as
E[Y |D ,D ,U]=.2+.2D +.1(D ×D )+.4U. (11.39)
12 10 12 12 10 12
TheunobservedvariableU hasthelargesteffectontheexpectedvalueofY (but,at.4,
12
hasthe sameeffectontheexpectedvalueofY asforY ).BeinginaCatholicschool
12 10
in the twelfth grade increases the probability of being in the high-test-score group by
.2. However, being in a Catholic school in the tenth grade only increases the chances
of being in the high-test-score group in the twelfth grade if one was also enrolled in a
Catholic schoolin the twelfth grade.This repeated treatment effect generates a boost
of .1 for students enrolled in Catholic schools in both the tenth and twelfth grades.26
Table11.5presentsexpectedvaluesfortheendogenousvariables,Y ,D ,andY
10 12 12
based on this setup. Note that there are four variables, D , Y , D , Y , and that
10 10 10 12
eachtakes on the value 0 and 1. The table reports the conditional expected values for
thethreeendogenousvariables:E[Y |D ],E[D |D ,Y ],andE[Y |D ,Y ,D ].

10 10 12 10 10 12 10 10 12
The final column of Table 11.5 presents the proportion of the sample in the 16 strata
defined across the 4 dichotomous variables. These values can be used to calculate
additionalconditionalexpectationsdefinedbycombinationsofvaluesforthevariables
in the first four columns.

Identification of Total and Direct Effects for the Example For total causal
effects, which have been the focus of this book, the key identification results in the
dynamic treatment regime literature are given by the back-door criterion. In cases
wherethetotalcausaleffectisnotequivalenttothedirectcausaleffect(e.g.,theeffect
of D on Y in Figure 11.10, which has both a direct effect, D →Y , and two
10 12 10 12
26In other words, there is an implicit term in Equation (11.39) of 0×D 10 because enrollment in
a Catholic school in the tenth grade has no effects on twelfth grade test scores, which implies that
students do not carrywiththem alagged effect oftenth gradeCatholic schoolingwhen they switch
fromCatholicschoolstopublicschoolsfortheeleventh andtwelfthgrades.

Table 11.5 Expected Values for the Endogenous Variables in the Directed Graph in
Figure 11.10
D 10 Y 10 D 12 Y 12 E[Y 10|D 10] E[D 12|D 10,Y 10] E[Y 12|D 10,D 12,Y 10] Proportion
1 1 1 1 .460 .900 .811 .079
1 1 1 0 .460 .900 .811 .018
1 1 0 1 .460 .900 .511 .006
1 1 0 0 .460 .900 .511 .005
1 0 1 1 .460 .900 .657 .054
1 0 1 0 .460 .900 .657 .028
1 0 0 1 .460 .900 .357 .003
1 0 0 0 .460 .900 .357 .006
0 1 1 1 .260 .100 .753 .020
0 1 1 0 .260 .100 .753 .007
0 1 0 1 .260 .100 .553 .135
0 1 0 0 .260 .100 .553 .109
0 0 1 1 .260 .500 .582 .154
0 0 1 0 .260 .500 .582 .110
0 0 0 1 .260 .500 .382 .101
0 0 0 0 .260 .500 .382 .163
indirect effects, D →Y →D →Y and D →D →Y ), the key identification
10 10 12 12 10 12 12
results are given by a related literature on causal mediation; see Pearl (2009), Wang
andSobel (2013),andVanderWeele (inpress). Accordingly,the firststepinanidenti-
fication analysis, which we offer below for the Catholic school example, is to consider
the total causal effects in Figure 11.10 by consulting the back-door criterion. The
results that we offer below will be consistent with many others offered in Chapters 4
through7.We thengivesustainedattentionto the identificationofdirecteffects, con-
centrating on what have been labeled the “controlled direct effects” in the literature
oncausalmediation. These effects havenotbeen consideredinthis book upuntil now
in any explicit way, although the careful reader will have seen references to them in
the details of Chapter 10. Our identification analysis will make use of the conditional
expectations reported in Table 11.5, with reference to Equations (11.37)–(11.39) that
generate them. In the section that follows, we will then discuss how to estimate these
identified effects from a single sample of data.

Total Effects. Table 11.6 indicates which of the eightpossible total causal effects
in Figure 11.10 are identified, as well as the method that would need to be used in
order to consistently estimate those that are identified.27 Most of the identification
resultsin Table 11.6are notsurprising,althoughthe lastthree differ fromothers that
27ThefactthatallofthetotaleffectsofobservedvariablesinFigure11.10areidentifiedmeansthat
wecantestwhethertheyareequalto0ornotandthusatleastpartiallyconsidertheappropriateness
ofthedirectedgraphasawhole.Elwert(2013,table13.1)givesanexampleofhowsuchtestingcan
beorganized.

Table 11.6 IdentificationStatus of the Total Causal Effects in Figure 11.10
Total Effect Identified? Method for Estimation
1. U→Y 10 No
2. U→Y 12 No
3. D 10→Y 10 Yes Unconditional association
4. Y 10→D 12 Yes Condition on D 10
5. D 12→Y 12 Yes Condition on D 10 and Y 10
6. (Y 10→D 12→Y 12) Yes Front-doorcombination of
already identified effects
Y 10→D 12 and D 12→Y 12
7. (D 10→D 12)+(D 10→Y 10→D 12) Yes Unconditional association
8. (D 10→Y 12)+(D 10→D 12→Y 12) Yes Unconditional association
+(D 10→Y 10→D 12→Y 12)
we have considered explicitly in this book. We will examine these eight effects in the
order in which they are listed Table 11.6, and they fall into five distinct identification
patterns according to the order in which they are listed.

First, because is U is unobserved, the total effects of U on both Y and Y are
10 12
not identified by the observed data. Second, because D and Y are not connected
10 10
byanyconfoundersthatgenerateaback-doorpath,itfollowsthattheirunconditional
association identifies D →Y . For our hypothetical data, the effect is equal to the
10 10
difference in the expected values of Y for the two values of D ,
10 10
E[Y |D =1]−E[Y |D =0]=.460−.260
10 10 10 10
=.200,
giveninTable 11.5.Nonetheless,recallthatthisresultfollowsfromtheconstructionof
the example, where we have assumed that we are analyzing the Catholic school effect
within a stratum where Figure 11.10 can be accepted as reasonable.

Third,thenexttwototaleffectsareidentifiedbyconditioningthatiswarrantedby
the back-door criterion. For the effect Y →D , three back-door paths are present:
10 12
1. Y ←D →D ,
10 10 12
2. Y ←D →Y ←D ,
10 10 12 12
3. Y ←U→Y ←D .

10 12 12
Without any conditioning, paths 2 and 3 are blocked by the collider Y . However,
12
path1remainsunblockedandgeneratesanoncausalassociationbetweenY andD .

10 12
When D is conditioned on, all three back-door paths are blocked and a consistent
10
estimate of the effect Y →D can be obtained. Similarly, for the effect D →Y ,
10 12 12 12
four back-door paths are present:
1. D ←D →Y ,
12 10 12
2. D ←Y ←D →Y ,
12 10 10 12
3. D ←Y ←U→Y ,
12 10 12
4. D ←D →Y ←U→Y .

12 10 10 12
In the absence of conditioning, path 4 is blocked by the collider Y , while paths
10
1, 2, and 3 remain unblocked. If only D is conditioned on, paths 1, 2, and 4 are
10
blocked, but path 3 remains unblocked. If only Y is conditioned on, paths 2, 3, and
10
4 are blocked, but path 1 remains unblocked. If both D and Y are conditioned
10 10
on, then all four back-door paths are blocked and a consistent estimate of the effect
D 12→Y 12 can be obtained.

Fourth, the total causal effect of Y on Y , which is a two-edge directed path
10 12
Y →D →Y , is also identified. This result follows from a double consideration
10 12 12
of the back-door criterion, which is the front-door identification strategy presented
in Chapter 10. The edge-by-edge identification results that constitute the front-door
identification strategy are given in the corresponding rows of the table immediately
above the row for the total effect of Y on Y , and as discussed already.

10 12
Fifth, the final two total effects are identified but are different because they are
composed of both a direct effect and one or more indirect effects through chains of
mediation.ThetotalcausaleffectofD onD (whichiscomposedofthetwodirected
10 12
paths D →Y →D and D →D ) is identified by the unconditional association
10 10 12 10 12
between D and D because no back-door paths between D and Y are present
10 12 10 12
that generate confounding. Likewise, the total causal effect of D on Y , which is
10 12
composedof the three directed paths (D →Y →D →Y , D →D →Y , and
10 10 12 12 10 12 12
D →Y ) is identified by the unconditional association between D and Y , again
10 12 10 12
because no back-door paths are present that generate confounding. Note, however,
that we have established these last two identification results by construction of the
example, just as for our prior consideration of the total effect of D on Y .

10 10
Overall, the directed graph in Figure 11.10 has a simple structure, allowing for
the estimation of all total causal effects of the observed variables, including the total
effects ofD onboth Y andY as wellas the total causaleffect ofD onY . The
10 10 12 12 12
simple structure yields straightforward identification results because Figure 11.10 is
equivalent to a sequential randomized experiment.

Direct Effects. Consider now the identification of direct effects, ignoring those
thatareequaltotheirtotaleffects(i.e.,D →Y ).Twosuchdirecteffectsarepresent
10 10
in Figure 11.10, one of which is straightforward and of secondary interest (D →
10
D ) and one of which is not straightforward but of primary interest (D →Y ).

12 10 12
Theseeffectsareidentified,buttheyarenotidentifiedusingtheback-doorcriterionto
warrantconditioningvariables(becausenoback-doorpaths confoundthese twodirect
effects).

Tobegintoappreciatethecomplications,itisusefultoconsiderhowtheconditional
expectations in Equations (11.38) and (11.39) structure these direct effects. Consider
first the direct effect D 10→D 12. Here, the direct effect varies with the two values of
Y because of the nature of the dynamic treatment regime. We can use Equation
10
(11.38) to see how these effects were set by construction. The first step is to generate
the conditional expectations that will define the direct effects:
E[D |D =1,Y =1]=.5+.4(1)−.4(1)+.4(1×1)
12 10 10 (11.40)
=.9,
E[D |D =0,Y =1]=.5+.4(0)−.4(1)+.4(0×1)
12 10 10 (11.41)
=.1,
E[D |D =1,Y =0]=.5+.4(1)−.4(0)+.4(1×0)
12 10 10 (11.42)
=.9,
E[D |D =0,Y =0]=.5+.4(0)−.4(0)+.4(0×0)
12 10 10 (11.43)
=.5.

These values are also given in the sixth column of Table 11.5.

The second step is take the values yielded by Equations (11.40)–(11.43) and then
calculate what have become known as “controlled direct effects” in the literature on
mediation,direct,andindirecteffects(seePearl2001,2009,2012a,2012b;VanderWeele
2009a, 2010; Wang and Sobel 2013):
CDED10→D12(Y 10=1)
=E[D |D =1,Y =1]−E[D |D =0,Y =1] (11.44)
12 10 10 12 10 10
=.9−.1
=.8,
CDED10→D12(Y 10=0)
=E[D |D =1,Y =0]−E[D |D =0,Y =0]
12 10 10 12 10 10 (11.45)
=.9−.5
=.4.

These two controlled direct effects for D →D are two distinct components of the
10 12
directeffect,eachofwhichcanbecalculatedwhenY issettooneofitstwovaluesof
10
0 or 1. The label “controlled” refers to the action of setting the value for the variable
Y beforecalculatingtheeffectoftheprimarycausalvariableontheoutcomevariable
10
of interest.

Whencontrolleddirecteffectsareidentified,thenthedirecteffectcanbeconsidered
identified. In other words, the direct effect is identified because all of its component
effectsareidentified.28Tounderstandthisresult,noticefirstthatallofthecalculations
28Nonetheless,onemayprefertohaveasinglevalueforadirecteffect,ratherthanmultiplevaluesfor
eachcontrolleddirecteffect.Themostcommonsingle-valuedirecteffectiswhathasbeenlabeledboth
carried out for Equations (11.40)–(11.46) use values for conditional expectations and
probabilities that are functions in observed variables only. As such, if a sample of
infinite size were available, we could exactly calculate these effects for such a sample
because the sample values would be exactly equal to these population values. This
explanation, however, is too shallow. The deepest explanation can be found in the
primaryliteratureonresultsthathavebeenestablishedforgraphsthathaveaMarkov
structure; see Pearl (2009), after reading our appendix to Chapter 3. The core idea is
that the simple structure of the graph in Figure 11.10, where no unblockedback-door
paths are present between the two treatment variables, ensures that we can define
the conditional expectations using Equations (11.37)–(11.39) and then assert that
differences in the estimated values of the conditional expectations on the left-hand
sides of Equations (11.40)–(11.43) are causal contrasts that identify controlled direct
effects. Consider a counterexample for insight. If the graph in Figure 11.10 cannot be
defended for the substantive example because an unobserved confounder of D and
10
D exists, such that a back-door path D ←C→D exists where C is unobserved,
12 10 12
thenthe conditionalexpectationsthatdefinethe controlleddirecteffectsinEquations
(11.44)and(11.45)wouldnotidentifycausaleffects.Thedifferencebetweenthesample
analogs to these conditional expectations, such as
EN[di12=1|di10=1,yi10=1]−E[di12=1|di10=0,yi10=1],
would not converge to the relevant controlled direct effect, CDED10→D12(Y =1)
10
because the confounder C generates additional noncausal dependence between D
10
and D within strata defined by Y .29
12 10
We find another explanation of this identification result helpful as well because
of the way it connects to the sort of thinking that we have used extensively when
the “puredirect effect” and the “natural directeffect” inthe causal mediation literature. Whatever
labelchosen,itisaweightedaverageofthecontrolleddirecteffectsthatcorrespondtothedistribution
ofthemediatorthatexistsinthecontrolgroup.Inthiscase,thenaturaldirecteffect is
NDED10→D12=CDED10→D12(Y 10=1)×Pr[Y 10=1|D 10=0]
+CDED10→D12(Y 10=0)×Pr[Y 10=0|D 10=0]
(11.46)
=(.8×.34)+(.8×.66)
=.536,
where the values of .34 and .66 for Pr[Y 10=1|D 10=0] and Pr[Y 10=0|D 10=0] are calculated from
thefinalcolumnofTable11.5.Inthiscase,thenaturaldirecteffectisacounterfactual quantity:the
Catholic school persistence effect, net of the dynamic nature of the treatment regime that we have
assumed by construction exists. Thus, apart from how test score performance is determined in the
tenth grade, the estimate suggests that the probability of entering a Catholic school in the twelfth
gradeis higher by.536 ifa student was enrolled inaCatholic school inthe tenth grade. We do not
find this counterfactual single-value direct effect to provide any additional information beyond the
controlled direct effects. In the broader literature on causal mediation, natural direct effects yield
effects that are more informative, typically when the mediator represents the primary substantive
mechanismthatgenerates thetotal effect.

29In the causal graph literature, this identification result follows from the Markov structure of
the graph, which allows all differences in the conditional expectations of observed variables in the
pre-intervention graph to be equal to their under-intervention differences. These equalities could be
made more explicit by using either potential outcome notation or Pearl’s do(.) operator. When the
graphhas aMarkovstructure, such representations areredundant, as weexplained inthe appendix
toChapter3.

invoking the back-door criterion in this book. Consider the following graphical expla-
nation for the role of conditioning in calculating controlled direct effects. In order to
estimate the controlled direct effects, we need to condition on Y . The basic idea
10
here is that we need to set the indirect effect of D on Y to 0 by blocking the
10 12
directed path D →Y →D in order to then calculate the separable controlled
10 10 12
direct effects. As a result, conditioning is essential to the calculation of these effects.

Yet,notealsothatY isacollideronapaththatbeginsatD andendsatD ,which
10 10 12
is D →Y ←U →Y ←D . Although this path is not a back-door path between
10 10 12 12
these two variables (because it does not begin with D ←), conditioning on Y does
10 10
nonetheless induce an associationbetweenD andU. Fortunately, this induced asso-
10
ciation is blocked by a second collider on the same path, Y . Accordingly, we can
12
see that conditioning on Y effectively sets the indirect path to 0 without inducing
10
any unwanted noncausal associationsbetween D and D . This result suggests that
10 12
a straightforward approach for the estimation of the direct effect D →D is to
10 12
calculate the conditional associations between D and D for each value of Y .

10 12 10
Tofullyappreciatethedepthoftheissuesinvolvedinthedynamictreatmentregime
literature, we need to consider the direct effect of D on Y , which is D →Y in
10 12 10 12
Figure 11.10. This direct effect is identified according to some of the same reasoning
just laid out for the direct effect of D on D , with some very important differences
10 12
we will fully explainbelow. Firstnote that the direct effect D →Y is a muchmore
10 12
importantsubstantiveeffecttoestimatebecauseitisanetaveragetreatmenteffectfor
the treatment introduced in the first time period on the final outcome observed. It is
also a more complicated direct effect to consider because the indirect effect of D on
10
Y traverses two separate directed paths, D →D →Y and D →Y →D →
12 10 12 12 10 10 12
Y .Fortunately,becausethedirectedpaththroughY liesontopofthedirectedpath
12 10
through D , the indirect effect through Y is fully absorbed into the distribution of
12 10
D . Accordingly, and following the reasoning above, we can set both indirect effects
12
to 0 by conditioning in D .

12
As was the case for the direct effect D →D , the first step to developing an
10 12
explanation for the identification results is to generate the conditional expectations
that define the controlled direct effects, plugging all combinations of values for D
10
and D into Equation (11.39) while allowing U to vary:
12
E[Y |D =1,D =1,U]=.2+.2(1)+.1(1×1)+.4U
12 10 12 (11.47)
=.5+.4U,
E[Y |D =0,D =1,U]=.2+.2(1)+.1(0×1)+.4U
12 10 12 (11.48)
=.4+.4U,
E[Y |D =1,D =0,U]=.2+.2(0)+.1(1×0)+.4U
12 10 12 (11.49)
=.2+.4U,
E[Y |D =0,D =0,U]=.2+.2(0)+.1(0×0)+.4U
12 10 12 (11.50)
=.2+.4U.

Note that, even though Y lies on a path that is part of the indirect effect of D on
10 10
Y , Y is absent from Equation (11.39). According to the graph, this effect is fully
12 10
absorbed into the effect of D on Y . The controlled direct effects are then
12 12
CDED10→Y12(D 12=1)
=E[Y |D =1,D =1,U]−E[Y |D =0,D =1,U]
12 10 12 12 10 12 (11.51)
=(.5+.4U)−(.4+.4U)
=.1,
CDED10→Y12(D 12=0)
=E[Y |D =1,D =0,U]−E[Y |D =0,D =0,U]
12 10 12 12 10 12 (11.52)
=(.2+.4U)−(.2+.4U)
=0,
where the effects of U cancel.30 These controlled direct effects match the values of
Equation(11.39)byconstruction,andthey indicate thatbeing inaCatholicschoolin
the tenth grade has no direct effect on test scoresin the twelfth grade unless one is in
a Catholic school in the twelfth grade.31
We again must ask: How do we know that the controlled direct effects are all
identified?As forthe directeffectD →D ,the coreoftheansweristhesameasfor
10 12
the direct effect D →Y . It is still the case that the controlled directed effects are
10 12
identified by the observed data based of the results established for graphs that have
a Markov structure (again, see Pearl 2009 after reading our appendix to Chapter 3).

30Although we did not specify a value for U in Equations (11.47)–(11.50), and simply allowed U
to cancel in the calculation of the controlled direct effects, we could have developed eight separate
conditional expectations because weknowthevalues ofU andtheprobabilitydistributionofU.We
donotdosobecausethisinformationisnottypicallyavailabletotheanalyst.Itwouldalsorequireus
tothenaverageovertheseeightconditionalexpectationstogettothefourvaluesfortheconditional
expectationsthatcanbeusedtodirectlycalculatethetruecontrolleddirecteffects.Instead,weshow
howtosolveforthesevaluesusingothermethods inthenextsection.

31Forcompleteness, thenaturaldirecteffect isthen
NDED10→Y12=CDED10→Y12(D 12=1)×Pr[D 12=1|D 10=0] (11.53)
+CDED10→Y12(D 12=0)×Pr[D 12=0|D 10=0]
=(.1×.36)+(0×.64)
=.036,
wherethevaluesof.36and.64forPr[D 12=1|D 10=0]andPr[D 12=0|D 10=0]arecalculatedfromthe
final columnof Table11.5.Thenatural directeffect issmalland isagaina counterfactual quantity:
the effect of Catholic schooling in the tenth grade on test scores in the twelfth grade, net of the
dynamic nature of the treatment regime that we have assumed by construction exists. Thus, apart
fromhow Catholic school attendance is determined inthe twelfth grade, the estimate suggests that
the probability of being inthe high-test-score group increases by .036 if astudent was enrolledin a
Catholicschoolinthetenthgrade.Thiscounterfactual effect isanexampleofanaturaldirecteffect
that probably does not deserve attention. The weighting in Equation (11.53) is a direct function of
thenumberofstudentswhoenterCatholicschoolsinthetwelfthgrade,havingbeeninpublicschools
inthetenthgrade,andthisispreciselythegroupforwhomthecontrolleddirecteffectisequalto0.

Inthiscase,thecontrolleddirecteffects aresensibleandhaveclearinterpretations.

Thekeyfeaturethatestablishesidentificationisagaintheabsenceofconfoundersthat
would generate noncausal associations through unblocked back-door paths between
the treatment and outcome variables (in this case between D and Y and between
10 12
D and Y ).

12 12
Althoughidentificationisagainpositive,alloftheshallowerexplanationsweoffered
for the direct effect D →D no longer easily apply. Instead, the same explanatory
10 12
strategies reveal complexities that suggest why a clever set of techniques has been
developed to estimate direct effects of these types. When we discussed the identifica-
tion of the direct effect D →D , we were able to point out that sample analogs
10 12
to the conditional expectations on the left-hand sides of Equations (11.40)–(11.43)
wouldconvergetothetruevaluesforthoseconditionalexpectationsasthesamplesize
approachesinfinity.When consideringthe directeffect D →Y , anequivalentclaim
10 12
is true for the conditional expectations on the left-hand sides of Equations (11.47)–
(11.50), but with one debilitating caveat: We cannot form the sample analogs to the
true conditional expectations because U is an unobserved variable. And, if we try
to estimate controlled direct effects by recklessly substituting in sample analogs to
E[Y |D ,D ] for what would be the proper sample analogs to E[Y |D ,D ,U]
12 12 10 12 12 10
that are impossible to generate from the observed data, we will obtain inconsistent
and biased estimates of the controlled direct effects. The usual culprit produces this
bias: a collider. This complication can be seen in the graph, as we now explain.

Recallour priorgraphicalexplanationfor the crucialrolethat conditioning onthe
mediatorplayedinthe identificationofthe controlleddirecteffects forD →D .We
10 12
explainedthatconditioningonY effectivelysetstheindirecteffectpathD →Y →
10 10 10
D to0,enablingidentificationofthecontrolleddirecteffectswithinstratadefinedby
12
themediator,Y .ForthedirecteffectD →Y ,thesituationismorecomplicated.In
10 10 12
order to estimate the controlled direct effects in this case, we again need to condition
inawaythatsetstheindirecteffectto0.But, nowweneedtoconditioninawaythat
blockstwopaths,D →D →Y andD →Y →D →Y .Theobviouscandidate
10 12 12 10 10 12 12
conditioning variable is D because it lies on both of these paths. At the same time,
12
it should also be obvious that Y is not a good candidate for conditioning. Not only
10
would conditioning on Y fail to block the path D →D →Y , Y is a collider
10 10 12 12 10
on the path D →Y ←U →Y that begins at D and ends at Y . Conditioning
10 10 12 10 12
on Y would induce an associationbetween D and U, which would then generate a
10 10
noncausal association between D and Y because U is a direct cause of Y .

10 12 12
Upon closer inspection, however,we can see that D is a descendant of Y . As a
12 10
result, conditioning on D will also induce an associationbetween D and U, which
12 10
then generates a noncausal association between D and Y within strata defined by
10 12
the mediator D . Given this predicament, it is not obvious how we can condition on
12
the D to set the indirect effect to 0 without triggeringa new source of confounding.

12
Yet, without conditioning in a way that will set the indirect effect to 0, we cannot
estimate the controlleddirecteffects thataccordingto the causalgraphliteratureare,
infact,identifiedbecauseoftheabsenceofunobservedconfounders.Thispredicament
is often referred to colloquially in this literature as “damned if you do and damned if
you don’t.”
Beforetoomuchdespairaccumulates,notethatifwecouldfindawaytocondition
on D in order to set the indirect effects to 0 and then also adjust away the induced
12
biasthattravelsbywayofU,wewouldbeabletoestimatethecontrolleddirecteffects.

The signal contribution of the literature on dynamic treatment regimes is a solution
tothis predicament,whichwe willexplainbelowwhenpresentingestimationmethods
in the next section. The key innovation is to use the relationships that constitute the
indirect effects (i.e., the joint probability distribution of D , Y , and D ) to adjust
10 10 12
awaythe induced confounding that travelsby way ofthe unobservedvariableU when
we condition on D , Y , or both.

12 10
Estimation Strategies
Wewillnotdiscusshowtoestimatetotaleffectsindetailbecausethestrategiesshould
be obvious. As shown in Table 11.6, many of these effects can be estimated using the
naiveestimatorbecauseunconditionalassociationsidentifytheeffects.Evenwhenthis
is not the case, standard back-door conditioning estimators can be used to estimate
the others. Instead, we will focus in this section on the two direct effects, D →
10
D and D →Y . Estimation of the first of these effects is straightforward, once
12 10 12
the identification result is known. Estimation of the second of these effects is not
straightforwardand is the focus of the dynamic treatment regime literature.

Estimating the Direct Effect of D10 on D12. How would one estimate the
controlled direct effects of D on D in a finite sample? Assuming that conditions
10 12
such as positivity are met for the available data, our identification explanation in the
section above suggests one straightforward method. The researcher estimates sample
analogs to the conditional expectations on the left-hand sides of Equations (11.40)–
(11.43), which would be
EN[di12=1|di10=1,yi10=1] for E[D 12|D 10=1,Y 10=1],
EN[di12=1|di10=0,yi10=1] for E[D 12|D 10=0,Y 10=1],
EN[di12=1|di10=1,yi10=0] for E[D 12|D 10=1,Y 10=0],
EN[di12=1|di10=0,yi10=0] for E[D 12|D 10=0,Y 10=0].

Differences between these four estimated conditional expectations can then be taken
to estimate the controlled direct effects in Equations (11.44) and (11.45).32
In the literature on dynamic treatment regimes, this straightforward estimation
strategyislabeledG-computation(Robins 1986;Robins andHern´an2009),where the
“G”isanabbreviationof“General.”G-computationisoneofthreerelatedapproaches
to the estimation of treatment effects for dynamic treatment regimes. For examples
such as this one, where we have three binary variables, positivity, and no emergent
conditioning bias from colliders, G-computation takes a particularly simple form and
is nearly certain to be feasible. As such, the other two estimation methods, which we
detail in the next section, would not need to be used.

Estimating the Direct Effect of D10 on Y12. To estimate the direct effect of
D onY ,thedynamictreatmenteffectliteratureoffersthreemethods.Thefirst,G-
10 12
Computation(Robins 1986),wasjust presented,anditconveysthe coreidentification
32Inaddition,theseestimatedcontrolleddirecteffectscanthenbecombinedintoaweightedaverage,
usingthe sampleanalogto Pr[Y 10=1|D 10=0], whichwouldthen yielda consistent estimate of the
naturaldirecteffect.

O
D Y
Figure11.11 An illustrative directed graph for G-computation.

challenge and how it is resolved. As we will show in this section, it is more compli-
cated for the direct effect of D on Y . The second approach, known as the estima-
10 12
tion of marginal structural models (MSMs), is feasible for researchscenarios in which
G-Computationisinfeasiblebecauseofthecurseofdimensionality(Robins1998,1999,
2000). We will also briefly discuss a third approach, G-Estimation, and the intuition
behind it.

G-Computation.ConsiderthesimpleexampleinFigure11.11ofadirectedgraph
whereD is asingle fixedtreatmentandY is anoutcome ofinterest.As inmanyother
examples in this book, the association between D and Y does not identify the causal
effect of D on Y because of the back-door path D←O→Y. However, because O is
observed, we can condition on it and generate a consistent estimate of D→Y for the
reasons discussed extensively in Chapters 4 through 7.

IfD andO arediscrete,thentheoverallcausaleffectofD onY iseasilyestimated
viastratification(seeMatchingDemonstration1onpage145).Twodifferentstrategies,
however, are possible. The standard approach would be to first estimate the causal
effect of Y within strata of O and then calculate the overall causal effect of D on
Y as the weighted average of the causal effects across strata where the weights are
proportional to stratum size; see Equations (5.5) and (5.6). A second approachwould
be to estimate the expectation of each of the potential outcomes, Y1 and Y0, within
each stratum of O as
p
EN[yi|di=1,oi=o]−→E[Y1|O=o], (11.54)
p
EN[yi|di=0,oi=o]−→E[Y0|O=o].

Weightedsumsofthesestratifiedestimatescanthenbetaken,whichwillbeconsistent
estimates of E[Y1] and E[Y0] because
(cid:6)
E[Y1]= E[Y1|O=o]Pr(O=o), (11.55)
O
(cid:6)
E[Y0]= E[Y0|O=o]Pr(O=o). (11.56)
O
To then estimate the ATE, the researcher takes the difference between the sample
analogs to the expectations in Equations (11.55) and (11.56).

This generalapproachto estimationis G-computation,and Equations(11.55) and
(11.56) are an example of what are labeled G-formulas. The “G” for “General” is
meant to indicate that this procedure representsa generalapproachto the estimation
ofacausaleffect.Ifacausaleffectisidentified,andignorabilityholds,theninprinciple
acausaleffectcanbeestimatedusingG-computation.Asimplebutkeyrequirementis
that we are consideringaveragecausal effects defined using expectations.In this case,
causal effects calculated as weighted averagesof differences within strata are equal to
causal effects calculated as differences between weighted outcomes across strata.

Consider what G-computation does. G-computation stratifies the sample in order
to estimate the expected potential outcome for each possible treatment regime under
the assumption that all individuals have the same treatment status. With consistent
estimatesoftheseexpectedpotentialoutcomes,estimatingthe effectofanytreatment
regimerelativetoanyothertreatmentregimethenonlyrequiresthatonecalculatethe
differences between these expectations. An important point in this literature is that
controlleddirecteffects canbe thoughtof asdifferences between compoundeffects for
different combinations of treatments, as we will demonstrate below.

Now consider again the directed graph in Figure 11.10. From a G-computation
perspective, what we want to estimate are the outcomes of Y for the four different
12
regimes (i.e., the four possible combinations of values of D and D ). Because sus-
10 12
pense offers no explanatory value for this appendix, we will revealthese values before
we show how to estimate them:
E[Y |D =1,D =1]=.74, (11.57)
12 10 12
E[Y |D =0,D =1]=.64, (11.58)
12 10 12
E[Y |D =1,D =0]=.44, (11.59)
12 10 12
E[Y |D =0,D =0]=.44. (11.60)
12 10 12
Fromthe valuesinEquations(11.57)–(11.60),itistrivialtocalculatethecausaleffect
ofoneregimerelativetoanother.33 Noticethis shiftinlanguage:fromtotalanddirect
effects to alternative treatment regimes. In particular, we can calculate the expected
effect of enrollment in Catholic school in the tenth grade as
E[Y |D =1,D =1]−E[Y |D =0,D =0]=.74−.44=.3.

12 10 12 12 10 12
Mostimportantforourconsiderationofdirecteffects,thevaluesinEquations(11.57)–
(11.60) can be used to calculate the difference in Y produced by D , separately by
12 10
thevalueofD .Theseare,infact,whatwelabeledthecontrolleddirecteffectsabove:
12
CDED10→Y12(D 12=1)
=E[Y |D =1,D =1]−E[Y |D =0,D =1]
12 10 12 12 10 12 (11.61)
=.74−.64
=.1,
33Inaddition, twoequivalences areworthnoting at this point. Given the Markovstructure of the
graph, the values in Equations (11.57)–(11.60) are equivalent to expected potential outcomes. They
are also equivalent to the conditional expectations in Equations (11.47)–(11.50), averaged over the
distributionofU.

CDED10→Y12(D 12=0)
=E[Y |D =1,D =0]−E[Y |D =0,D =0]
12 10 12 12 10 12 (11.62)
=.44−.44
=0,
butnowU isnolongerpresentforreasonswewillexplainbelow;seeEquations(11.51)
and (11.52) for comparison. In the literature on dynamic treatment regimes, these
differencesaresimplytheeffectofCatholicschoolinginthetenthgradeontestscoresin
thetwelfthgradecalculatedfirstfortheregimeinwhichstudentsalsoattendCatholic
schools in the twelfth grade and then second for the regime in which students do not
attend Catholic schools in the twelfth grade.34 In short, with the values in Equations
(11.57)–(11.60), we can calculate all of the treatment effects we want for all contrasts
across the permissible treatment regimes.

How do we estimate these values with G-computation? We use the appropriate
G-formula:
E[Y |D ,D ]=E[Y |D ,D ,Y =1]×Pr[Y =1|D ]
12 10 12 12 10 12 10 10 10 (11.63)
+E[Y |D ,D ,Y =0]×Pr[Y =0|D ].

12 10 12 10 10 10
Although the structure of this G-formula is given by the graph and the identifying
assumptions that it represents, the computed expectation can be interpreted as the
expectedoutcome forY forthe particularcombinationofvaluessetby interventions
12
on D and D . The right-hand side is a sum of two products, where each product
10 12
includes the appropriate conditional expectation weighted by whether Y equals 1 or
10
0. This weight is conditional on D , but not D (because Y is determined by D
10 12 10 10
but not by D ).35
12
Operationally,wetakeeightstratadefinedacrossalltwo-waycombinationsofD ,
10
D , and Y and then calculate the mean values for Y . We then averageover strata
12 10 12
defined by Y , conditionalon patterns of D and D , to generate the four values in
10 12 10
Equations (11.57)–(11.60).

For this example, the expectations for the relevant eight strata are presented in
the seventhcolumn ofTable 11.5. Sample analogsto the conditionalexpectations will
converge to the true values for these conditional expectations:
p
EN[y 12|d 10=1,d 12=1,y 10=1]−→.811,
p
EN[y 12|d 10=1,d 12=1,y 10=0]−→.657,
p
EN[y 12|d 10=0,d 12=1,y 10=1]−→.753,
p
EN[y 12|d 10=0,d 12=1,y 10=0]−→.582, (11.64)
34Inthisliterature,controlleddirecteffectsareconsidereddifferencesincompoundeffectsforalter-
nativecombinationsoftreatments.

35For completeness, we should note that the G-formula for the direct effect D 10→D 12 is much
simpler.ItisE[D 12|D 10,Y 10]anddoesnotrequireaveragingoveranyunderlyingstrata.

p
EN[y 12|d 10=1,d 12=0,y 10=1]−→.511,
p
EN[y 12|d 10=1,d 12=0,y 10=0]−→.357,
p
EN[y 12|d 10=0,d 12=0,y 10=1]−→.553,
p
EN[y 12|d 10=0,d 12=0,y 10=0]−→.382.

Inserting these conditional expectations into the G-formula in Equation (11.63), and
whileassuminganinfinitesample,wecancalculatethedesiredfourvaluesinEquations
(11.57)–(11.60) as
EN[y 12|d 10=1,d 12=1]
=.811×PrN[y 10=1|d 10=1]+.657×PrN[y 10=0|d 10=1]
(11.65)
=(.811×.55)+(.657×.45)
=.74,
EN[y 12|d 10=0,d 12=1]
=.753×PrN[y 10=1|d 10=0]+.582×PrN[y 10=0|d 10=0]
(11.66)
=(.753×.34)+(.582×.66)
=.64,
EN[y 12|d 10=1,d 12=0]
=.511×PrN[y 10=1|d 10=1]+.357×PrN[y 10=0|d 10=1]
(11.67)
=(.511×.55)+(.357×.45)
=.44,
EN[y 12|d 10=0,d 12=0]
=.553×Pr[y 10=1|d 10=0]+.382×PrN[y 10=0|d 10=0]
(11.68)
=(.553×.34)+(.382×.66)
=.44,
wheretheconditionalprobabilitiesPrN[y 10=1|d 10=1],PrN[y 10=0|d 10=1],PrN[y 10=
1|d 10=0],andPrN[y 10=0|d 10=0]arecalculatedfromthe finalcolumnofTable11.5.

With the four values produced by Equations (11.65)–(11.68), we can estimate the
causaleffectforanytwocontrastingtreatmentregimes,asshownabovewithreference
to the values in Equations (11.57)–(11.60). In effect, the structure of the graphallows
ustocollapsethestratadefinedbyY aslongasthestrataareweightedinaccordance
10
withtheconditionalprobabilitydistributionsencodedbythegraph.Aswewillexplain
in the next section, there are alternative methods available to achieve this type of
weighted collapsing.

D
10
Y 10 D Y 12
12
U
Figure11.12 Adirectedgraphforapseudo-populationproducedusinginverseprob-
ability of treatment weighting.

Alternatives to G-Computation.If thereis sufficientdataandthe appropriate
ignorability assumptions hold, estimating a saturated model via G-computation will
always provide consistent estimates of the causal effect of any one regime relative to
another. From these treatment regime differences, one can then calculate the relevant
controlled direct effects.

However, because of the curse of dimensionality, G-computation-based estimates
can be very imprecise because some conditional expectations will be estimated for
strata with very small samples. In this final section, we consider two alternative
approaches to G-computation that are meant to deal with the curse of dimension-
ality: marginal structural models (MSMs) estimated via inverse probability of treat-
mentweighting(IPTW),andstructuralnestedmeanmodels(SNMMs)estimatedviaa
G-estimation. Our discussion of the later approach will be brief.

Marginal Structural Models (MSMs). These models are attracting interest in soci-
ology and have been used in several published papers (Wimer, Sampson, and Laub
2008;SharkeyandElwert2011;Wodtke,Harding,andElwert2011).Theyarelabeled
structural because they estimate a causal effect and marginal because the effect that
is estimated is the marginal effect over a set of collapsed strata. MSMs are attracting
interest because they are feasible when G-computation is not, because they are com-
paratively easy to understand relative to G-estimation (see below), and because they
can be estimated using available software.

Considerthe directedgraphin Figure 11.12. Notice that D is notdetermined by
12
either D or Y . As a result, D no longer has an indirect effect on Y through
10 10 10 12
Y and D . As a result, there is no reason to condition on either Y or D when
10 12 10 12
estimating the causal effect of D on Y for this graph. Notice also that the path
10 12
D →Y ←U→Y that connects D to Y is blockedby the collider Y . As long
10 10 12 10 12 10
as we do not condition on Y , this path will remain blocked. If the directed graph
10
in Figure 11.12 described our data, the unconditional association between D and
10
Y wouldidentify the (direct) effect of D on Y . It would also be the case that the
12 10 12
unconditionalassociationbetweenD andY wouldidentifytheeffectofD onY .

12 12 12 12
Of course, the causal dependence of D on D and Y cannot just be assumed
12 10 10
away. Nonetheless, Robins (1999) showed how one can create a pseudo-population in
which the directed graph in Figure 11.12 can be substituted for the directed graph in
Figure 11.10. The pseudo-population construction is achieved using the inverse prob-
ability weighting methods we presented in Chapter 7. In particular, after examining
the directed graphin Figure 11.10, one estimates a propensity score model predicting
assignment to D as a function of D and Y :
12 10 10
Pr(D =1|D ,Y )=F(D ,Y ). (11.69)
12 10 10 10 10
For each individual, the probability of enrolling in a Catholic school in the twelfth
gradecaneither be estimatednonparametricallyfromthe dataif thereareasufficient
numberofcasesorusingagenerallinearmodel,suchasalogitorprobit.We canthen
define the weights in two different ways:
1
For d 12i=1: wi,MSM= ,
pˆi
1
For d 12i=0: wi,MSM= 1−pˆi,
or
swi,MSM=EN[d 12=1]
For d 12i=1: ,
pˆi
For d 12i=0: swi,MSM=1−E 1N −[d pˆ1 i2=1] ,
where pˆis the estimated probability for eachindividual of enteringCatholic schooling
in the twelfth grade based on Equation (11.69). Robins and Hern´an (2009) refer to
the wi weights as “unstabilized weights” and the swi weights as “stabilized weights.”
Unstabilizedweightsgenerallyhavegreatervarianceandtypicallyleadto wider confi-
dence intervals. As such, stabilized weights are usually recommended, although there
are special circumstances where stabilized weights will produce inconsistentestimates
of causal effects (Robins and Herna´n 2009:576).

Table11.7presentsthepseudo-populationproportionsthatwouldresultfromnon-
parametric estimation of the weights for the dynamic treatment regime versionof the
Catholic school effect we have been analyzing in this appendix. The final column of
this table can be directly compared to the observed population proportions in Table
11.5 that we set by construction for the hypothetical example. If we use these esti-
matedproportionstocalculateweightedmeansofY conditionalonvaluesforallfour
12
combinations of D and D , we can then calculate differences to recover the total
10 12
effect of D on Y as well as the two controlled direct effects.

10 12
The advantage of MSMs, relative to G-computation, is that we do not have to
calculate the means of Y within each stratum (i.e., across Y as in our example).

12 10
Instead, we estimate weights and then calculate contrasts for Y with the weighted
12
data.Thisisthesameadvantagethatthepropensity-score-basedweightingestimators
presented in Chapter 7 have relative to the full stratification estimators presented in
Chapter5.MSMsstillrequirepositivitywithrespecttoallpossibletreatmentregimes,
buttheypermitsparsenessinobservedvariablesthatdeterminetreatmentassignment,
just as for propensity-score estimators for a fixed-time treatment regime.

Table 11.7 Pseudo-PopulationProportions for
the Directed Graph in Figure 11.12
Pseudo-Population
D 10 Y 10 D 12 Y 12 Proportion
1 1 1 1 .041
1 1 1 0 .010
1 1 0 1 .093
1 1 0 0 .037
1 0 1 1 .031
1 0 1 0 .036
1 0 0 1 .021
1 0 0 0 .025
0 1 1 1 .082
0 1 1 0 .020
0 1 0 1 .011
0 1 0 0 .064
0 0 1 1 .145
0 0 1 0 .104
0 0 0 1 .107
0 0 0 0 .173
Accordingly, MSMs can be a very useful approachto dealing with “damned if you
do, damned if you don’t” situations. MSMs, however, are not a panacea and have
several weaknesses. First, and most importantly, even stabilized weights can produce
unusually large weights resulting in imprecise estimates. In Chapter 7, we have dis-
cussedvarious methods, suchas trimming,for dealingwith this situation, noting that
these methods will lead to biased estimates. Second, MSMs cannot be used when an
instrumentalvariableisavailable.Third,the types ofsensitivityanalysis(seeChapter
12) that can be done with MSMs are limited (Robins and Herna´n 2009:592–93). We
next consider a method, G-estimation (not to be confused with G-computation) that
does not share these problems. Unfortunately, G-estimation is both more difficult to
understand and more difficult to implement.

G-estimation. Our discussion of G-estimation will be brief because our goal is to
give the reader an intuitive understanding of how G-estimation works, with the hope
that when readers encounter these methods, they will have a basic understanding of
the procedure.G-estimationis closely relatedto the method ofgeneralizedestimating
equations (GEE) and other methods-of-moments estimators. G-estimation seeks a set
of estimates that satisfies an orthogonality condition. As we have discussed above,
identification occurs when ignorability holds. Ignorability holds if the potential out-
comes are independent of an individual’s past treatment, conditional on their past
and present covariate history. The intuition behind G-estimation is that one wants to
create a set of predicted counterfactual potential outcomes by modeling the observed
outcomes. This goal is pursued by searching for a set of parameters that results in
orthogonality of both observed and the predicted potential outcomes with respect to
treatmentassignment,conditionalontreatmenthistoryandcurrentandpastcovariate
values. Unfortunately, in most cases it is necessary to use a grid search procedure to
findthedesiredsetofparameters,whichcanrequiresubstantialcomputingpowerand
time to generate results. Also, as far as we are aware, no software routines have been
shared for use with either commercial or freely available data analysis programs. For
more details on G-estimation, consult (Robins and Herna´n 2009:577–92).

Conclusions
We have chosen a simple example where the data are generated from a hypothetical
dynamic treatment regime, and we have then shown how it is possible to identify
static treatment effects from such data. This example is rich enough to convey both
the basic identification results and the clever ways in which estimation is rendered
feasible with the methods developed by Robins and his colleagues. If one’s interest is
in identifying dynamic treatment effects, then identification and estimation are con-
siderably more challenging (see Robins and Hern´an 2009). If sequential ignorability
doesnot holdbecause confounderssuchasU in ourexample determine either or both
of the treatment exposure variables, then the models developed in this literature are
not identified, just as in the case for fixed treatment regimes. In addition, not all esti-
mation issues have been resolved. G-computation is beyond reproach, but it is often
infeasible because of insufficient data. Marginal structural models can be fragile for
the same reasons as the weighted regression estimators discussed in Chapter 7. The
specificationofthemodelthatgeneratesthe weightsmustbecorrect,andthe concern
withextremeweightswillbepresentformanyapplications,especiallyifsomepatterns
oftreatmentexposurearecomparativelyrare.Finally,G-estimationalsorequiresthat
the model predicting potential outcomes be correct,something which may be difficult
to test. In addition to Robins and Hern´an (2009), we recommend that readers seek
additional guidance in Chakraborty and Moodie (2013).

# Part V: Estimation When Causal Effects Are Not Point-Identified by Observables

# Chapter 12

# Distributional Assumptions, Set Identification, and Sensitivity Analysis

In this chapter, we consider how analysts can proceed when no observed variables

are available to point-identify and then estimate causal effects using the procedures
explained in prior chapters. We discuss three complementary approaches. First, we
will review the early literature on selection-bias adjustment, which shows clearly how
distributional assumptions about unobservables, when harnessed from within a struc-
tural model, can identify causal parameters of interest. Point identification and esti-
mation utilizing this strategy was frequent before it became clear to researchers in
the 1990show rarelythe requireddistributional assumptions werewarrantedfor their
applications.Themorerecentselection-biasadjustmentliteratureofferslessrestrictive
semiparametric methods, but it also reemphasizes the relative value of instrumental
variables in contrast to distributional assumptions for unobservables.

We will then consider the exact opposite strategy. Rather than place strong and
usually untestable assumptions on the distributional characteristics of unobservables,
theset-identificationapproachaskswhatcanbelearnedaboutparticularcausalparam-
eters by asserting only weak but defendable assumptions about unobserved variables.

Instead of attempting to point-identify average causal effects, the set-identification
approachsuggests that it is more credible to try to limit the interval within which an
averagetreatment effect must fall.

Finally, we will consider the related approach known as sensitivity analysis. Here,
the analyst offers an estimate based on the provisional maintenance of an identify-
ing assumption – most often, ignorability or selection on the observables – and then
assesses the extent to which the estimate would vary as violations of the identifying
assumption increase in severity. These final two modeling strategies are complemen-
tary, and each of them may be an effective path forward when an analyst has low
confidence that any of the methods presented in prior chapters will suffice.

419
## 12.1 Distributional Assumptions and Latent Variable Selection-Bias Models

Heckman’s early work in the 1970son selection bias, particularly his lambda method,

hasreceivedagreatdealofattentioninthe socialsciences.Hiscloselyrelatedworkon
dummyendogenousvariables,pursuedatthesametime,hasreceivedfarlessattention
(seeHeckman1978,1979).AlthoughcompletedbeforemostofRubinandRosenbaum’s
work on propensity scores, Heckman’s work on dummy endogenous variables can be
understood in relation to the propensity score approach.

Suppose that we are again interested in estimating the average treatment effect
(ATE) for the effect of a binary cause D on an interval-scaled outcome Y. Recall
the treatment selection model from the econometric tradition and Equation (4.7) in
particular:
D˜=Zφ+U. (12.1)
For this equation, D˜ is a latent continuous variable, Z represents observed variables
thatdeterminetreatmentselection(eitherinstrumentsforD ordeterminantsoftreat-
ment selection that are also determinants of Y), and φ is a coefficient (or a vector of
coefficients if Z represents more than one variable). Most importantly for these meth-
ods, U represents both systematic unobserved determinants of treatment selection as
well as completely randomidiosyncratic determinants of treatment selection. It is the
unobserved systematic determinants in U that generate confounding that cannot be
removedby conditioning on Z, and therefore this model is used to represent selection
on the unobservables. Finally, as in Section 4.3.2, the latent continuous variable D˜ in
Equation (4.7) is related to the treatment selection dummy variable, D, by
D=1 if D˜ ≥0,
D=0 if D˜ <0,
where the threshold 0 is arbitrary because U has no inherent metric.

Ratherthanfocusontheconditionalprobabilityoftreatmentselection(i.e.,directly
on the propensity score Pr[D=1|Z]), Heckman instead focused on the conditional
expectation function of the latent variable D˜. Using the linearity of Equation (12.1),
he wrote the conditional expectation function as
E[D˜|Zφ,D]=Zφ+E[U|Zφ,D]. (12.2)
Accordingly, the expectation of D˜ is a function in Zφ and D, which therefore varies
across individuals according to characteristics measured by zi, and whether or not
individuals select into the treatment, di. Heckman’s insight was the recognition that,
althoughone cannotobserveui directly foreachindividual (unlike zi anddi), onecan
formulate anexpressionfor a conditional expectationfunction of U if one is willing to
assertdistributionalassumptionsthatimplyvaluesfortheexpectationofU conditional
on Zφ and D. The standard assumption for selection-bias adjustment is that U is
normallydistributedwithmean0andvariance1.1Iff(.)isthenormaldensityfunction
1In the treatment effects context, it is also common to assert trivariate normality for the distri-
butions of u i, υ i0, and υ i1, where the latter two are the individual-level variation in the potential
and F(.) is the corresponding cumulative distribution function, then standard results
for truncated normal distributions yield the following expressions for the conditional
expectation functions for U:
f(Zφ)
E[U|Zφ,D=1]= , (12.3)
F(Zφ)
−f(Zφ)
E[U|Zφ,D=0]= . (12.4)
[1−F(Zφ)]
Equation(12.3) simply givesthe formula for Heckman’s λ in a standardsample selec-
tion problem. In the treatment effects context, this expression is the λ for the treat-
ment group (D=1). The full dummy endogenous variable model requires a second λ
forthoseinthecontrolgroup(D=0),whichiscalculatedfromEquation(12.4).These
two λ’s are then used to form two new regressors,
(cid:7) (cid:8) (cid:7) (cid:8)
f(ziφˆ) −f(ziφˆ)
di× and (1−di)× , (12.5)
F(ziφˆ) [1−F(ziφˆ)]
that are specified as adjustment variables alongside other conditioning variables in
the regression model that estimates the effect of D on Y. Thus, the procedure here is
identicaltoHeckman’sgenerallambdamethodforcorrectingforselectionbias,except
that two distinct λ’s are utilized, each of which applies either to the treatment group
or to the control group. Because these supplementary adjustment terms are functions
in ziφˆand di, the model is often referred to as a control function estimator.

As many researchershavecome to appreciate, estimates from these models can be
very sensitive to assumptions about the distribution of U. This recognition prompted
the development of a second generation of selection-bias estimators that introduced
semiparametric estimation of the treatment selection equation (see Honor and Powell
1994; Pagan and Ullah 1999). And it led to a greater appreciation of a point that
Heckman made clearly in the original development of the approach: sample selection-
biasmodelsaremosteffectivelyestimatedwhenthevariablesinZ includeinstrumental
variables,sothatthe addedregressorsinEquation(12.5)haveanexogenoussourceof
variation unrelated to the distributional assumption placed on U.

Morerecently,HeckmanandVytlacil(2005,2007)haveofferedalatentindexmodel
for heterogeneous treatment effects that can represent latent variable selection-bias
estimators, their semiparametric extensions, and instrumental variable (IV) estima-
tors that satisfy monotonicity assumptions. Although the latent index model accom-
modates the original control function strategy and is consistent with the basic struc-
ture of the potential outcome model, it emphasizes the core identifying power of local
instrumentalvariables(LIVs) ratherthanthe distributionalassumptionsaboutunob-
servables that were heavily relied upon in the applied literature; see our discussion of
local IVs and MTEs in Section 9.3.4. As such, one can read the latent index model
as an appeal for piecewise IV identification of heterogeneous treatment effects, not
for structural identification of average treatment effects by assumptions about the
outcomes;seeSection4.3.2.Inadditiontothetwo-stagemodelsexplainedinthissection,thesemod-
elscanalsobeestimatedbymaximumlikelihoodandnonlinearleastsquares.SeeWinshipandMare
(1984,1992)andFu,Winship,andMare(2004)forfurtherdiscussion.

distributions of unobservables. In response to this most recent literature, the control
function approach to selection-bias adjustment appears likely to continue to decline
in usage in the applied literature, except in cases where instrumental variables for
treatment selection equations are available.

## 12.2 Set Identification with Minimal Assumptions

Ifonecannot(ordoesnot)imposeastrongassumptiontopoint-identifyandthenesti-

mate an average treatment effect, it is natural to wonder about an opposing strategy
for analysis:What can be learned about averagecausal effects while imposing weaker
but defendable assumptions? In a series of articles and books that have built on less
formalized work of the past, Manski (1994, 1995, 1997, 2003, 2013b) has investigated
plausible values for treatment effect parameters, such as the ATE, that are consis-
tent with the data when weak assumptions alone are maintained. In this section, we
introduce Manski’s work to show that, in most researchsituations, the observed data
themselves provide some information on the size of average treatment effects without
any assumptions. We then introduce some of the additional assumptions considered
by Manskito showhowthey boundaveragecausaleffects topermissible intervals.We
use the label of “set identification” in contrast to point identification of single values.

Manski often uses the alternative phrase “partial identification,” and many writers
refer to this strategy as an “analysis of bounds.”
12.2.1 No-Assumptions Bounds
To see why the collection of data can bound the range of permissible values for the
ATE, consider a hypothetical example in which we know that both Y1 and Y0 are
bounded by 0 and 1, and thus that Y is also bounded by 0 and 1. Examples could
be dichotomous potential outcomes for graduating high school or not in response to
twocausalstates,suchasCatholicschoolingorpublicschooling,discussedextensively
already.OrthepotentialoutcomescouldbewhetheronevotedforAlGore,depending
on whether or not one received a butterfly ballot. This latter example (see Section
1.3.2)wouldbe especiallyappropriateto analyzefroma bounds andset-identification
perspective because the goal of such a causal analysis would be to determine whether
thecausaleffectisplausiblylargeenoughtohaveflippedtheelectionresults.Withthat
goal clearly in focus, concerns over putative statistical significance are of secondary
concern.

In this case, we know from the definitions of Y1 and Y0, even without collect-
ing data, that the ATE, E[δ], cannot be greater than 1 or less than −1. This is a
straightforward implication of the obvious point that no individual treatment effect
can be greater than 1 or less than −1. Accordingly, the maximum ATE of 1 would
occur if E[Y1|D=1]=E[Y1|D=0]=1 and E[Y0|D=1]=E[Y0|D=0]=0, whereas
the minimum ATE of −1 would occur instead if E[Y1|D=1]=E[Y1|D=0]=0 and
E[Y0|D=1]=E[Y0|D=0]=1. Thus, we know that E[δ] must be contained in an
intervaloflength2,whichcanbestatedasaknownboundonE[δ],usingthenotation
−1≤E[δ]≤1 (12.6)
Table 12.1 A Hypothetical Example of the Calculation of Bounds
for the ATE
E[Y1| .] E[Y0| .]
Naive estimator suggests E[δ]=.4
Treatment group E[Y1|D=1]=.7 E[Y0|D=1]= ?
Control group E[Y1|D=0]= ? E[Y0|D=0]=.3
Largest possible E[δ]=.7
Treatment group E[Y1|D=1]=.7 E[Y0|D=1]=0
Control group E[Y1|D=0]=1 E[Y0|D=0]=.3
Smallest possible E[δ]=−.3
Treatment group E[Y1|D=1]=.7 E[Y0|D=1]=1
Control group E[Y1|D=0]=0 E[Y0|D=0]=.3
or that E[δ] lies in an interval with closed bounds, as in
E[δ]∈[−1,1]. (12.7)
Manski has shown that we can improve on these bounded intervals considerably
without making additional assumptions but by collecting data on Y and D. By fol-
lowing a systematic sampling strategy from a well-defined population, we can assert
the specific convergence results stated earlier in Equations (2.9)–(2.11). These would
ensure that, for an infinite sample, EN[di]=E[D], EN[yi|di=1]=E[Y1|D=1], and
EN[yi|di=0]=E[Y0|D=0].Knowledgeofthesethree quantitiesallowsonetonarrow
the bound of width 2 in Equations (12.6) and (12.7) to one with a width of only 1.

Consider the hypothetical example depicted in Table 12.1, where, as shown in
the first panel, we stipulate that E[Y1|D=1]=.7 and E[Y0|D=0]=.3. The naive
estimator, EN[yi|di=1]−EN[yi|di=0], would yield values that converge to .4 as the
sample size increases. Note that the naive estimator does not use the information
about the distribution of the sample across the observed values of D. And, we leave
question marks to stand in for the unknown values of the counterfactual conditional
expectations E[Y1|D=0] and E[Y0|D=1].

Suppose that E[D]=.5 and that our sample is infinite such that sampling error
is 0. And, for simplicity of notation and consistency with the decomposition in Chap-
ter 2, allow π to again stand in for E[D]. For the second and third panels of Table
12.1, the minimum and maximum values of 0 and 1 for the counterfactual conditional
expectations E[Y1|D=0] are E[Y0|D=1] and substituted for the question marks in
the first panel.

If half of the sample is in the treatment group, and if E[Y1|D =1]=.7 and
E[Y0|D=0]=.3, then the largest possible treatment effect is .7, whereas the small-
est possible treatment effect is −.3. This result is a straightforward calculation using
what-if values for the decomposition of the ATE presented in Equation (2.10), which
wasusedearlierinChapter 2andelsewhereto discuss the bias ofthe naiveestimator:
E[δ]={πE[Y1|D=1]+(1−π)E[Y1|D=0]} (12.8)
− {πE[Y0|D=1]+(1−π)E[Y0|D=0]}.

Plugging in the values from the second panel of Table 12.1 into the decomposition in
Equation (12.8) yields the largest possible treatment effect as
E[δ]={(.5)(.7)+(1−.5)(1)} −{(.5)(0)+(1−.5)(.3)}
=.85−.15
=.7,
whereas plugging in the values from the third panel yields the smallestpossible treat-
ment effect as
E[δ]={(.5)(.7)+(1−.5)(0)} −{(.5)(1)+(1−.5)(.3)}
=.35−.65
=−.3.

Thus, the constraints implied by the observeddata alone guarantee,for this example,
that E[δ]∈[−.3,.7], which is an interval of length 1 and is half the length of the
maximum interval calculated before estimates of π, E[Y1|D=1], and E[Y0|D=0]
were obtained from the data.

Manskilabels this intervalthe “no-assumptionsbound” because it requiresknowl-
edgeonlyoftheboundsonY1 andY0,aswellascollectionofdataonY andD froma
systematic random sample of a well-defined population. Consider now a more general
development of these same ideas.

The treatment effect can be bounded by finite values only when the potential
outcomesY1andY0areboundedbyfinitevalues.Inotherwords,becauseE[Y1|D=0]
and E[Y0|D=1] are both unobserved, they can take on any values from −∞ to ∞ in
the absence of known restrictions on the ranges of Y1 and Y0. Thus, in the absence
of any known restrictions on E[Y1|D=0] and E[Y0|D=1], E[δ] is contained in the
completely uninformative interval between −∞ and ∞.

Manski(1994,1995,2003)showsthatwithpotentialoutcomevariablesboundedby
1and0,theno-assumptionsboundwillalwaysbeoflength1.Thisresultisobtainedby
a more generalmanipulation of Equation (12.8), for which the lower bound is derived
as
{πE[Y1|D=1]+(1−π)(0)} −{π(1)+(1−π)E[Y0|D=0]}, (12.9)
and the upper bound is derived as
{πE[Y1|D=1]+(1−π)(1)} −{π(0)+(1−π)E[Y0|D=0]}. (12.10)
SimplifyingandthencombiningEquations(12.9)and(12.10)yieldstheno-assumptions
bound for potential outcomes bounded by 1 and 0:
πE[Y1|D=1]−(1−π)E[Y0|D=0]−π (12.11)
≤E[δ]
≤πE[Y1|D=1] −(1−π)E[Y0|D=0]+(1−π).

The length of the bound is 1 because the upper and lower bounds differ only by two
complementaryprobabilities π and1−π that sum to 1. The locationof the bound in
the [−1,1] interval is set by the common term πE[Y1|D=1] −(1−π)E[Y0|D=0], to
which −π and 1−π are then added to form the bound.

More generally, if Y1 and Y0 are bounded by any finite values a and b, where
b>a, such as theoretical minimum and maximum scores on a standardized test, then
Equation (12.6) can be written more generally as
−b+a≤E[δ]≤b−a, (12.12)
which then generates the more general no-assumptions bound for the observed data:
πE[Y1|D=1]−(1−π)E[Y0|D=0]+a(1−π) −bπ (12.13)
≤E[δ]
≤πE[Y1|D=1]−(1−π)E[Y0|D=0]+b(1−π)−aπ.

The same basic results hold as before. The no-assumptions bound always includes 0,
anditisonlyhalfaswideastheboundinEquation(12.12)impliedonlybythebounds
on the potential outcomes. In this case, the no-assumptions bound is of length b−a
rather than of length 2(b−a).2 As with the case for potential outcomes bounded by
1 and 0, the particular location of the interval of length b−a in [−b+a,b−a]is again
determined by the same term, πE[Y1|D=1]−(1−π)E[Y0|D=0].

12.2.2 Bounds Under Additional Weak Assumptions
ForManski,calculationoftheno-assumptionsboundisonlythestartingpointofaset-
identificationanalysis.Theprimarygoalistoanalyzehowadditionalassumptionscan
narrowthe no-assumptionsbound. Manski’sbasicperspectiveis summarizednicely in
the following passage:
Empirical researchers should be concerned with both the logic and the
credibility of their inferences. Credibility is a subjective matter, yet I take
there to be wide agreement on a principle I shall call:
TheLawofDecreasingCredibility:Thecredibilityofinferencedecreases
with the strength of the assumptions maintained.

Thisprincipleimpliesthatempiricalresearchersfaceadilemmaasthey
decide what assumptions to maintain: Stronger assumptions yield infer-
ences that may be more powerful but less credible. (Manski 2003:1)
Manski has shown that weak and often plausible assumptions can substantially nar-
row the no-assumptions bound. Consider the following simple assumptions about the
direction of individual-level treatment effects and the direction of self selection.3
2To see this result, note that [b−a]+[−1(−b+a)] simplifies to 2(b−a), and [b(1−π)−aπ]
+[−1(a(1−π) −bπ)]simplifiestob−a.

3Forempiricalexampleswiththesamestructure,seefirsttheapplicationsofferedatthetimeMan-
skiwasdevelopingtheset-identificationperspective(e.g.,ManskiandNagin1998;Manski,Sandefur,
McLanahan, andPowers1992). Morerecently, Manskihasusedthesamebasicapproach tocritique
the“duelingcertitudes”andother noncredibleclaimsthatpervadepublicpolicypronouncements in
academicresearchandbeyond(Manski2013b). SeealsoReinandWinship(1999).

Monotone Treatment Response
Inmanysituations,itmaybereasonabletoassumethattheindividual-leveltreatment
effect cannot be negative, such that δ≥0 for every individual i. Manski labels this
assumption the monotone treatment response (MTR) assumption.

Under MTR (in the direction where δ≥0), the lower bound for the ATE must
be0.MTRimpliesthatmembersofthecontrolgrouphavecounterfactualvaluesofy1
i
thatareatleastashighastheir observedvalues ofyi.The reasoninghereis simple:If
yi=y i0 for members of the control group, then the MTR assumption that y i1 ≥y i0 for
all individuals i implies that y i1 ≥yi for members of the control group. The opposite
is likewise true for members of the treatment group; their counterfactual values for
y i0 are no higher than their observed values of yi. Under MTR for the hypothetical
examplepresentedinTable12.1,onecanthereforereplacetheextremevaluesof1and
0 in the no-assumptions lower bound:
{(.5)(.7)+(1−.5)(0)} −{(.5)1+(1−.5)(.3)}=−.3
with less extreme values of .7 and .3. As a result, one obtains a new lower bound:
{(.5)(.7)+(1−.5)(.3)} −{(.5)(.7)+(1−.5)(.3)}=0,
implyingthattheboundfortheATE,assumingMTRinthis direction,is[0,.7]rather
than [−.3,.7].

Monotone Treatment Selection
Itmay alsobe reasonableto assumethatthose who receivethe treatmenthavehigher
average outcomes under potential exposure to both the treatment and control, which
Manski labels the monotone treatment selection (MTS) assumption. In most cases,
one would assume jointly that E[Y1|D=1]≥E[Y1|D=0] and E[Y0|D=1]≥E[Y0|
D=0], which is traditionally thought of as positive self-selection. (But one could flip
the direction of the assumption, just as we also noted for MTR.) Manski and Pepper
(2000)presentthis type ofMTSassumptionforthe example ofthe effectofeducation
on earnings, for which it is equivalent to assuming that individuals with higher edu-
cation would on average receive higher wages than individuals with lower education,
under counterfactual conditions in which they had the same levels of education.

For the hypothetical example presentedin Table 12.1, MTS implies that the naive
estimator would be an upper bound for the ATE. In short, MTS in this direction
stipulates that members of the treatment groupcould not have done any worse in the
control state than those observedin the control group(and, vice versa,that members
of the controlgroupcouldnot have done any better in the treatment state than those
observedinthetreatmentgroup).MaintainingMTSallowsonetoreplacetheextreme
values of 1 and 0 in the no-assumptions upper bound,
{(.5)(.7)+(1−.5)(1)} −{(.5)0+(1−.5)(.3)}=.7,
with the less extreme values of .7 and .3, yielding for this example,
{(.5)(.7)+(1−.5)(.7)} −{(.5)(.3)+(1−.5)(.3)}=.4.

MTS thereby implies that the bound for the ATE is [−.3,.4] rather than [−.3,.7].

Monotone Treatment Response and Treatment Selection Together
ThepowerofManski’sapproachcomesfromtheabilitytoapplymultipleassumptions
at the same time in order to narrow the no-assumptions bound to a bound that is
considerablymore informative. For the hypothetical example presented in Table 12.1,
one can narrow the no-assumptions bound from [−.3,.7] to [0,.4] by invoking the
MTR and MTS assumptions together. The resulting bound still includes 0, but in
someapplicationssuchnarrowingmaywellbehelpfulinrulingoutsomeunreasonable
and extreme causal claims.

Monotone Instrumental Variables
WhereastherecentworkofHeckmanandhiscolleagueshasdemonstratedhowpower-
ful the conclusions of a study can be if a perfect and finely articulated IV is available
(see Section 9.3.4), Manski’s work on IVs probes the opposite territory, following on
the consideration in his early work of the capacity of traditional IVs to narrow the
no-assumptionsbound(seeManski1994,1995).ManskiandPepper(2000)investigate
what can be learned about the ATE when both standard and weaker IV assumptions
are maintained. Their results are then presented as a component of the general set-
identification methodology laid out in Manski (2003; see especially chapter 9).

Manski and Pepper (2000) first define the traditional IV assumption in terms of
meanindependence,afterconditioningonacovariateX forgenerality.Inournotation,
thestandardIVassumptionofnodirecteffectofZ onY (byeitherY1orY0)iswritten
out as
E[Y1|X,Z=z(cid:2) ]=E[Y1|X,Z=z(cid:2)(cid:2)
], (12.14)
E[Y0|X,Z=z(cid:2) ]=E[Y0|X,Z=z(cid:2)(cid:2)
], (12.15)
for any two values z(cid:2) and z(cid:2)(cid:2) of Z (and separately for strata defined by X). In other
words, Equations (12.14) and (12.15) require that the expectations of the potential
outcomes be equal within strata defined by Z (conditional on X). Accordingly, the
boundsanalysispresentedabovethenapplieswithineachstratumofZ,andthebound
on the ATE can then be defined as the intersection of the bounds across the strata
definedbyZ.Thisresultimpliesthattheno-assumptionsboundcanonlybenarrowed
by an IV if the no-assumptions bounds that could be calculated within each stratum
z of Z also vary across the strata defined by Z.

Manski and Pepper (2000) then consider a weaker assumption for an IV analy-
sis, known as a monotone IV (MIV) assumption. It states that for all values of the
instrument Z, in which z(cid:2)(cid:2)≥z(cid:2), the variable Z is an MIV if
E[Y1|X,Z=z(cid:2)(cid:2) ]≥E[Y1|X,Z=z(cid:2)
], (12.16)
E[Y0|X,Z=z(cid:2)(cid:2) ]≥E[Y0|X,Z=z(cid:2)
]. (12.17)
In Equations (12.16) and (12.17), the expected values of both potential outcomes are
weakly increasing in Z. Note that this usage of the concept of monotonicity is quite
different than for a local averagetreatment effect (LATE) analysis or an LIV analysis
(see Section 9.3, beginning on page 305). For an MIV, monotonicity refers to the
relationship between the instrument and the potential outcomes, not the relationship
between the treatment and the instrument. The latter type of assumption is referred
to as monotone treatment selection (MTS) by Manski and his colleagues (see our
discussion above).

To what extent does an MIV narrow the bound for the ATE (or, in the words
of Manski 2003, shrink the identification region for it)? The short answer: No more
than a traditional IV (and usually considerable less), but still enough to have some
identifying power.

ItiseasiertoexplainhowanMIVboundstheexpectationofeachpotentialoutcome
than it is to demonstrate directly how an MIV bounds the ATE that is a function of
these expectations. Consider just the determination of the upper bound for E[Y1].

Under the standard IV assumption of mean independence, the upper bound for
E[Y1]isequaltothesmallestupperboundacrossthedifferentsubpopulationsdefined
by the instrument Z. More precisely, the upper bound is the smallest value that
E[Y1|Z=z] takes on across all values z of Z.

In contrast, under the weaker MIV assumption, the upper bound for E[Y1] is a
weightedaverageofsubpopulationupper bounds,forwhicheachsubpopulationupper
bound is defined across the values of Z. The implicit calculation of this upper bound
on E[Y1] can be described in a series of as-if algorithmic steps. First, a value of Z is
selected as z(cid:2). The upper bound for E[Y1], with respect to z(cid:2), is set as the smallest
value that E[Y1|Z=z] takes on across all values z(cid:2)(cid:2) of Z where z(cid:2)(cid:2) ≥z(cid:2).4 After this
smallest upper bound is found with z(cid:2) fixed, the next value of z(cid:2) is selected, and a
smallest upper bound is found with respect to this next z(cid:2). After all values of Z have
been selected as z(cid:2), the upper bound for E[Y1] is set as the weighted average of the
subpopulation upper bounds with respect to each value of Z, where the weights are
the marginal distribution of Z attached pointwise to the smallest upper bounds set
withrespecttoallz(cid:2) ofZ.ThedeterminationofthelowerboundonE[Y1]underMIV
is the opposite of this procedure, in the sense that the greatest lower bound is first
sought across subpopulations of Z, restricting the range of Z over which one searches
in each step to be larger than the selected anchoring point z(cid:2) of Z.

Tofind the bounds implied byanMIVfor the ATE,the bounds onE[Y0]mustbe
calculated with the same basic procedure.These bounds can then be substituted into
thesamebasicframeworkintroducedinthelastsection,withthemarginaldistribution
of D used to characterize the known distribution across treatment states.

Of course, as we noted above, the goal of a set-identification analysis is to invoke
combinations of weak assumptions.5 As with the more general set-identification
4Becausethissmallestupperboundrelativetoz(cid:3)isselectedfromasmallersubsetofpossibleupper
bounds (onlythosegreater than z(cid:3) ratherthan allvalues ofZ),theresultingweighted upperbound
acrossz(cid:3)isbydefinitionnosmaller(andusuallylarger)thanwouldbetheupperboundsuggestedby
amorestringentmean-independenceIVassumption.Asaresult,MIVsnevershrinktheidentification
regionmorethantraditionalIVs(andusuallyconsiderableless).

5Inapriorversionoftheirmanuscript,ManskiandPepperusedtheMTR,MTS,andMIVassump-
tionstogethertodeterminetheboundsontheeffectofeducationontheloggedwagesofrespondents
fortheNationalLongitudinalSurveyofYouth.WhentheyinvokedMTRandMTSassumptions,they
foundthattheboundfortheeffectofatwelfthyearofschoolingwas[0,.199],thattheboundforthe
effectofafifteenthyearofschoolingwas[0,.255],andthattheboundfortheeffectofasixteenthyear
ofschoolingwas[0,.256].WhentheythenusedtheArmedForcesQualificationTestasanMIVwhile
still maintaining the MTR and MTS assumptions, they obtained narrower bounds, respectively, of
[0,.126],[0,.162],and[0,.167].

approach,it is generally difficult to eliminate values of 0 for averagetreatment effects
in this tradition, but the methodology can be used, as Manski shows, to convincingly
reject extreme causal effect assertions and build regions of credible inference to move
the literature forward in any given area. Moreover, it is presumably much easier to
find MIVs in any substantiveareathan IVs thatallow for the identificationofLATEs
or full schedules of MTEs.

In sum, the set-identification approach is a principled and strict framework for
developing warranted causal claims. In part because it is so strict, but more funda-
mentallybecausescholarsandreviewersvaluepointestimatessohighly,theusagerate
of set-identificationstrategies in empirical researchremains quite low. For exceptions,
it is well worth consulting the applications offered at the time Manski was developing
his set-identification perspective (e.g., Manski and Nagin 1998; Manski et al. 1992).

Morerecently,Blundell,Gosling,Ichimura,andMeghir(2007)use abounds approach
to analyze wage trajectories for men and women. Gunderson, Kreider, and Pepper
(2012) offer an MIV application to generate support for the claim that reduced-price
lunches in public schools have positive effects on health outcomes of children. Manski
and Pepper (2013) offer a full analysis of the deterrence effect of the death penalty.

And, following on the general orientation reflected in this last piece, Manski (2013b)
offers an extended critique of the “dueling certitudes” and other noncredible claims
that pervade public policy pronouncements in academic research and beyond.

## 12.3 Sensitivity Analysis for Provisional Causal Effect Estimates

Considerasituationwherearesearchersuspects,basedonsubstantiveknowledgefrom

other studies or a particular theoretical perspective, that treatment selection is non-
ignorable because selection is, in part, on unobserved variables. Yet, the researcher is
unwilling to adopt the set-identification perspective because she feels that the viola-
tionsofthepoint-identifyingassumptionsareverysmall.Inthiscase,shemaywantto
offer a causal effect estimate under the assumption that treatment selection is ignor-
able,butsheshouldthenjudgehowwrongtheresultsmaybeandofferinterpretations
that are appropriately cautious.

Although Blalock is often accused of inspiring naive causal analysis (and we have
engaged, as well, in our own share of Blalock criticism in Chapter 1), he did warn
against overconfident causal claims based on conditioning with regression methods
long before most of the methods we have presented in this book were developed. At
the end of his influential 1961 book Causal Inferences in Nonexperimental Research,
he wrote:
It seems safe to conclude that the problem of making causal inferences
on the basis of nonexperimental data is by no stretch of the imagination
a simple one. A number of simplifying assumptions must be made, per-
haps so many that the goal would seem almost impossible to achieve. The
temptationmayverywellbetogiveuptheentireventure.But,aswehave
suggestedatanumberofpoints,theremaynotbeanysatisfactoryalterna-
tives. Most likely, social scientists will continue to make causal inferences,
either with or without an explicit awareness of these problems. (Blalock
1964[1961]:184)
His recommendation was to report a range of plausible results, and he lamented the
pressures to settle in on only one favored set of results:
itwouldbe extremelyhelpful ifsocialscientistswoulddevelopthe habitof
contrasting the results of several different procedures. ... If conclusions
or results differed, one might gain valuable insights as to why specific
differences have occurred. ... Present practices and publication policies
are undoubtedly unfavorable to such a strategy. ... there are undoubtedly
pressures on the individual investigator to report only his “best” results
in instances where different techniques have not given the same results.

(Blalock 1964[1961]:184–85)
In the decades since scholars such as Blalock appealed for the multimodel reporting
of results, a number of scholars have attempted to systematize this approach.

Inthecounterfactualtradition,theapproachknownassensitivityanalysishasbeen
the most influential.6 Based largely on the work of Rosenbaum and his colleagues
(see Rosenbaum 1991, 1992, 2002, 2010), the guiding principle of the approach is
simple: When reporting and interpreting an estimate of a causal effect, researchers
should analyze and report how sensitive the estimates and interpretations are to the
maintained assumptions of the analysis.

For Rosenbaum, sensitivity analysis of this form is quite distinct from other types
of robustness checks on one’s results because of its concern with estimates of causal
effects. Rosenbaum (1999:275) writes, “Assumptions are of three kinds: (i) the sci-
entific model or hypothesis, which is the focus of scientific interest, (ii) incidental
assumptions, needed for statistical inference but of little or no scientific interest and
(iii) pivotal assumptions which rival the scientific hypothesis and are the focus of sci-
entific controversy.” Sensitivity analysis is usually focused narrowly on the specific
and pivotal assumption of ignorability of treatment assignment. Here, the question
of interest is usually, How sensitive are estimates of an average causal effect to the
potential effects of unobservable treatment selection patterns?
Rosenbaum(2002;seealsoRosenbaum2010)devotesalargeportionofhisexcellent
book on observational data analysis to strategies for performing sensitivity analysis,
especially for matching designs.7 Consider for reference the simple directed graph in
6Thereisarelatedliteratureonsensitivityanalysisthatistiedtosimulationmethodsanddeter-
ministic modeling more generally. In this tradition, for example, the parameters of a deterministic
simulationofanoutcomearevariedsystematically.Ifvariationinnuisanceparametersofnoinherent
interest does not change the basicresults ofthe model, then themodel isrobust. And, as described
inSaltelli,Tarantola,Campolongo,andRatto(2004),suchmethodscanbeusedtoassesstheuncer-
tainty ofmodel predictions basedonthe uncertainty of modelinputs. Such resultscandirectfuture
effort optimally, so as to reduce the uncertainty of those inputs that generate the most uncertainty
ofprediction.

7Forexpositionsofthebasicperspectivewrittenforsocialscientists,seeDiPreteandGangl(2004),
Frank(2000), andGangl (2013).

C U
D Y
Figure12.1 A graph in which the causal effect of D on Y is confounded by an
observed variable C and an unobserved variable U.

Figure 12.1, where an analyst seeks to estimate the effect of D on Y. In this case, the
researcherobservesonlyoneoftwoknownconfounders,C butnotU.ForRosenbaum,
adjustingforC wouldremove“overtbias”butwouldleavethe“hiddenbias”produced
by D←U→Y untouched. For a sensitivity analysis, the typical steps would be
1. Offer a provisionalpoint estimate of the ATE for the effect of D on Y by condi-
tioning on C and assuming that ignorability holds.

2. Choose multiple pairs of values for the effects of U on D and of U on Y.

3. Using either analytic methods or simulation methods, present results that show
howmuchtheprovisionalpointestimateoftheATEwouldbeexpectedtochange
assuming each pair of values.

4. Identify and report the pairs of values that would push the provisional point
estimateoftheATEbelowthecriticallevelthatwouldpreventonefromrejecting
the null hypothesis of no effect.

5. Use external information on what is known about U and its relationships to D
and Y to assess whether or not the pairs of values that would prevent one from
rejecting the null hypothesis of no effect are reasonably likely.8
If, after after executing these steps, the researchercanarguethat all plausible vio-
lations of ignorability (i.e., the pairs of values for the effects of U on D and of U on
Y)wouldnotchangethequalitativeconclusions,thenonecanreportthelevelsofsen-
sitivity from step 3 and confidently stick to the main substantive conclusion that the
ATE is sufficiently unlikely to be equal to 0. If, however,plausible violations of ignor-
ability would change the main substantive conclusion, because 0 cannot be regarded
as implausible, then one should step back from strong conclusions and consider other
methods of analysis.

Examplesintheliteraturedemonstratetheutilityofthesensitivityanalysisapproach,
althoughfor obvious reasonsit is hardto find published examples where causal asser-
tionshavebeenabandonedinresponsetosensitivityanalyses.Instead,sensitivityanal-
ysis is usually used to defend conclusions against the reasonable objections of either
8Note how this strategy differs from the set-identification approach presented above. From this
alternativeorientation,theresearcherwouldfirstcalculateno-assumptionsboundsfortheconditional
averageeffectofDonY withinstrataofC.Then,theresearcherwouldintroduceadditionalcredible
assumptions about theindividual-leveland/or average effects ofU onD and U onY inanattempt
tonarrowtheno-assumptionsboundstointervalsthatallresearcherscanaccept.

fictitious fair critics or the specific assertions of real critics. Consider an example of
each type.

In response to fictitious critics, Harding (2003) assesses the strength of the rela-
tionshipthatacompositeofunobservedvariableswouldhavetohavewithatreatment
variableandanoutcomevariableinordertochallengethecausalinterpretationsofhis
estimatesofthe effectofneighborhoodcontextonthe odds ofcompletinghighschool.

He uses Rosenbaum’s specific pair-matching thresholds for violations of ignorability
to demonstrate that convincing support for his conclusions is available. He is able
to conclude, “Thus, to drive the [estimated] neighborhood effect to nonsignificance,
parental involvement would have to be more powerful than family income or having
poorly educated parents, net of these variables” (Harding 2003:712).

Foraresponsetorealcritics,VanderWeele(2011b)defendsthe claimofChristakis
and Fowler (2007) that obesity is contagious and spreads through social networks.

The critics claimed that the results of Christakis and Fowler did not provide sup-
port for the causal effects of interest and instead reflected both homophily bias and
unmeasured effects of shared environments (see, e.g., Cohen-Cole and Fletcher 2008;
ShaliziandThomas2011).VanderWeele(2011b)performedasensitivityanalysis,also
based on Rosenbaum’s general procedures, and concluded that his sensitivity analy-
sis suggested that the contagion effects on obesity “were reasonably robust to latent
homophily” (VanderWeele 2011b:252).The results, however,were not definitive, even
iftheywereencouragingtotheoriginalauthors(seeChristakisandFowler2013).Shal-
izi(2012)raisedobjectionstotherealismofthesensitivityanalysis,whilealsomaking
the more fundamental point that the original models were themselves less suited to
the estimation task than Christakis and Fowler recognized when first offering them.

Given the close connections between set identification and sensitivity analysis, are
there reasons to favor one or the other approach when both are equally feasible? To
considerthisquestion,itisusefultofirstreviewthewritingofManskiandRosenbaum.

Manski’s identification focus is clear, as explained in the quotations that we used in
Section3.1(seepage78).Incontrast,Rosenbaumseesatargetedfocusonidentification
to be considerably less helpful:
The idea of identification draws a bright red line between two types of
problems. Is this red line useful? ... In principle, in a problem that is
formally not identified, there may be quite a bit of information about β
[acausalparameterofinterest],perhapsenoughforsomeparticularpracti-
caldecision....Arguably,abrightredlinerelatingassumptionstoasymp-
totics is less interesting than an exact confidence interval describing what
has been learned from the evidence actually at hand. (Rosenbaum 2002:
185–86)
Rosenbaum’s objection to the bright red line of identification is issued in a discussion
ofanIVestimator,whichweexplainedinChapter9canofferanestimateofaformally
identified parameter that may be so noisy in a dataset of finite size that one cannot
possibly learn anything from the estimate. However, an alternative estimator in the
same context – usually a least squares regression estimator – that does not formally
identify aparameterbecause itremainsasymptoticallybiasedeveninaninfinite sam-
plemaynonethelessprovidesufficientlysystematicinformationsoastoremainuseful,
especially if one has a sense from other aspects of the analysis of the likely direction
and size of any remaining bias.

WeacceptRosenbaum’sperspectivetosomeextent.Itisundeniablethatanempir-
ical researcher who forsakes all concern with statistical inference could be led astray
by consideringonly estimates thatare formallyidentified. But, for this book,ourper-
spective has been much closer to that of Manski. We have focused on identification
problems almost exclusively because our primary goalhas been to help researchersto
determine what assumptions must be maintained in order to identify causal effects
andthenestimate them.Accordingly,wedo nottakea particularpositiononwhether
set identification or sensitivity analysis is a better strategy when point estimation of
a causal effect of interest is infeasible. We give more space with a workedexample for
an analysis of bounds only because it fits with the identification focus of this book.

Ourpositionnotwithstanding,Manskidoeshaveaprincipledreasonforfavoringset
identification,eventhoughheseesitas“mathematicallycomplementary”tosensitivity
analysis(Manski2003:5).HeregardsRosenbaum’ssensitivityanalysisapproachastoo
narrow,writing:
Where Rosenbaum and I differ is that I do not view the assumption of
ignorabletreatmentselectiontohaveaspecialstatusinobservationalstud-
ies of treatment effects. As an economist, I usually am inclined to think
thattreatmentsarepurposefullyselectedandthatcomparisonofoutcomes
plays an important role in the selection process. Perhaps the departures
from ignorable treatment selection that Rosenbaum entertains in his sen-
sitivity analysis can be interpreted behaviorally in terms of some model
of purposeful treatment selection, but for now I do not see how. (Manski
1999:281)
Other social scientists may agree with this position, based on whether they also feel
that it is too difficult to discuss departures from ignorability of treatment assignment
inacoherentwaywithoutreferencetothebehaviorofindividuals.Tosomedegree,we
found ourselves in the same situation when discussing the charter school example in
Section 8.3, where we found it necessary to elaborate the back-door path that Rosen-
baum would regard as a source of hidden bias. This orientation likely also underlies
the critique that Shalizi (2012) offers of VanderWeele’s sensitivity analysis in defense
of Christakis and Fowler:
[VanderWeele2011b]isatrulyingeniouspaper,whichadvancedthefield...

However, it did so under very strong parametric and substantive assump-
tions, such as, e.g., all latent homophily being due to a single binary vari-
able, which interacts with observables in very specific and limiting ways.

Provingresultsunderthese restrictionsis morethananyoneelse hasdone,
but before one appeals to the results in empirical problems, one needs to
eitherhavesomescientificreasontothink the restrictionshold,oramath-
ematical reason to think that the conclusions are robust to substantial
departuresfromthose assumptions. Since those mathematical reasonsare,
at least for now,unavailable,we are forcedto rely on scientific knowledge.

Is anyone prepared to argue that we ought, on biological or sociological
grounds, to think that everything relevant to friendship formation and
obesity (in suburban Massachusetts) boils down to one binary variable?
(Shalizi 2012:2)
It remains to be determined, therefore, whether sensitivity analysis can serve as an
effective defense against real critics.

Nonetheless, sensitivity analysis can be and is being generalized, to the extent
that the boundary between sensitivity analysis and set identification seems likely to
gradually disappear. Consider, for example, savvy applied work such as Berk and de
Leeuw (1999), where simulation is used to insert uncertainty into conclusions that
may result from violations of assumptions. The prospects for such work are bright,
especially when used to extend interpretations of findings by exploring alternative
structures for outcomes, rather than simply trying to defend against the claims of
critics who challenge identifying assumptions.

## 12.4 Conclusions

Inthis chapter,wehaveconsideredthreeseparatestrategiesforhowanalystscanpro-

ceedwhentheyareunabletouseobserveddatatopoint-identifyaveragecausaleffects
ofinterest.Afterusingtheclassicselection-biasliteratureasanexampleofhowdistri-
butionalassumptionsforunobservablescanidentifysomeestimatesofinterest,wethen
tookthepositionofthe morerecentliteraturethatdistributionalassumptionsmaybe
particularlyhardto justify. We thenconsideredthe set-identificationliterature,which
is motivated by a similar type of skepticism. Rather than issue daring assumptions
thatmay be hardto justify, the goalis to offer easilydefendable assumptionsthat are
not open to doubt. This literature has shown that through combinations of assump-
tions, some causalclaims canbe eliminated. Yet, these methods have notbeen widely
used because they typically cannot eliminate 0 as a permissible value for estimated
causaleffectsand,evenmoreso,becausesocialscientistscontinuetoverymuchprefer
single-value estimates. Finally, we considered an approach that is complementary to
setidentification,whereanalystsofferprovisionalpointestimatesofaveragetreatment
effects,withfullrecognitionthattheyarelikelyinconsistentandbiased.Analyststhen
examine how wrongthese estimates may be byassessingtheir sensitivity to violations
of the maintained assumptions.

# Part VI: Conclusions

# Chapter 13

# Counterfactuals and the Future of Empirical Research in Observational Social Science

What role should the counterfactual approach to observational data analysis play in

causal analysis in the social sciences? Some scholars see its elaboration as a justifi-
cation for experimental methodology as an alternative to observational data analysis.

We agree that by laying bare the challenges that confront causal analysis with obser-
vationaldata,thecounterfactualapproachdoesindirectlysupportexperimentationas
an alternative to observation. But, because experiments are often (perhaps usually)
infeasible for most of the causal questions that practicing social scientists appear to
wanttoanswer,thisimplication,whenconsideredapartfromothers,isunderstandably
distressing.

We see the observationaldata analysis methods associatedwith the potential out-
comemodel, motivatedusingdirectedgraphs,asuseful toolsthatcanhelptoimprove
the investigation of causal relationships within the social sciences, especially when
experiments are infeasible. Accordingly, we believe that the methods associated with
the counterfactual approachcomplement and extend older approaches to causal anal-
ysis with observational data by shaping the goals of an analysis, requiring explicit
consideration of individual-level heterogeneity of causal effects, encouraging a wider
considerationofavailableidentificationstrategies,andclarifyingstandardsforcredible
interpretations.

Inthischapter,wefirstshoreupourpresentationofthecounterfactualapproachby
consideringseveralcriticalperspectivesonits utility. We weighinwith the arguments
that we find most compelling, and it will not be surprising to the reader that we find
theseobjectionslessseriousthandothosewhohaveformulatedthem.However,weuse
quotations from the published literature in order to demonstrate the richness of these
437
debates andto encouragea full readingof the materialthat we areable to summarize
only briefly here.

We conclude the chapter with a discussion of causal modeling practices where we
delineatethemultiplemodesofcausalinquirythatexistinobservationalsocialscience.

We argue that the counterfactual approach is useful because it facilitates movement
betweenmodesofcausalinquiry, guidinganalysisto the deepestlevelthattheoryand
data can enable at any given point in time.

## 13.1 Objections to Adoption of the Counterfactual Approach

The counterfactual approach is not without serious objections from thoughtful crit-

ics. In this section, we will present three objections from the published literature. If
theseobjectionsareaccepted,thenajustificationforeschewingmuchofwhatwehave
presented in prior chapters is available. Such a decision, however, would presumably
require the adoption of the counterposition(s) of those who raise the following objec-
tions. We will not lay out these alternative approaches to causal analysis here, but
their main features are implicit in the objections.

Wewillnotfurtherdiscusstwoobjectionsthatwehavealreadyaddressedindetail
inpriorchapters.First,foraresponsetothe supposedlimitationsforpracticeimplied
by the typical adoption of stable unit treatment value assumption (SUTVA), see Sec-
tion 2.5. As argued there, the potential outcome model cannot be considered prob-
lematic or inappropriate for the social sciences because it more clearly demonstrates
a challenge to the definition and estimation of causal effects than other less complete
frameworksforcausalinference.Inaddition,counterfactualanalysiscanproceedwhen
SUTVAdoesnothold,althoughthepotentialoutcomemodelthenshowshowdifficult
it can be to identify average causal effects of various forms.

Second, fora responseto the claimthatthe counterfactualapproachdoes notgive
sufficientattentiontogenerativemechanisms,seeChapter10.Whilethecounterfactual
approachtakesnogeneralpositiononthenecessarydepthofacausalclaim,weargued
there that (1) the counterfactual approach is suitable for use when evaluating levels
of support for conjectured alternative mechanisms that generate observed outcomes
and(2)thecounterfactualapproachisentirelyconsistentwiththetheoryconstruction
agenda of the generative mechanisms movement, as long as such theory construction
is not itself passed off as causal explanation.1
1Wewillalsonotdiscusstheclaimthat,byadoptinganotionofcausalitythatgrantscurrencyto
counterfactuals, theanalystisforcedtoincludeinanyexplanation anabundance ofancillarycausal
claims, typically those grounded in causality by omission (“because the moon did not crash into
the earth”) and those grounded in causality by prehistory (“because of the birth of the universe”).

Proponents of this red-herring objection then argue that, because such ancillary claims have little
or no explanatory value, but the counterfactual approach requires that they be admitted into the
explanation,itmustbethecasethatthecounterfactualapproachtocausationisindefensiblebecause
it is incomplete. See Martin (2011) for the style of argument, where he writes, for example, “[W]e
cannotaskthequestion,WhatcausesB’sdeath?andbringinanythinglessthananinfinitenumber
ofcauses,withlittlewayoftellingthemapart.Almosteverythingthatledourworldtobeourworld
(and not some other) was acause of B’s death.... Committed counterfacualists have learned to live
Objection 1: Nonmanipulable Causes Cannot Be Analyzed When
Using the Potential Outcome Model
The counterfactual approachis most natural when one can conceive of a specific pro-
cedure for manipulating the cause of interest, or in the words of Berk (2004:91), “in
the sense that conscious human action can change things.” If the effects of a cause
thatcannotbemanipulatedby“humanaction”areofinterest,thenthepotentialout-
comemodel losessomeofits transparencybecausethe counterfactualsbecomeharder
to conceptualize. The statistician Paul Holland is usually cited as offering the most
eloquentstatement ofthis position, using the motto “no causationwithout manipula-
tion”thathe developedinapriordiscussionwithRubin(seeHolland1986:959).2 The
objectionwe consider in this section maintains that, because one must agree with the
1986 Holland-Rubin position in order to utilize the potential outcome model, schol-
ars who are interested in the effects of (typically) immutable characteristics– such as
gender and race – must instead find some other approach to causal analysis to use in
theirresearch.And,giventhatsomanysocialscientistsareinterestedinthesesortsof
effects, the potential outcome model must therefore be regardedas one that has quite
limited utility for observational social science (see, e.g., Goldthorpe 2001).

We find this objection unpersuasive for the following reasons. Even if one adopts
the counterfactual approach while also accepting the rigid position of “no causation
without manipulation,” the entailed restrictions on permissible analysis are not as
limitingasisoftenclaimed.Woodward(2003)hasarguedthispositionmorecompletely
thananyoneelse(see,inparticular,hissection3.4,“InWhatSenseMustInterventions
Be Possible?”).In developinghis conceptionof anintervention,Woodwardconcludes:
The sorts of counterfactuals that cannot be legitimately used to elucidate
the meaning of causal claims will be those for which we cannot coherently
describe what it would be like for the relevant intervention to occur at
all or for which there is no conceivable basis for assessing claims about
what would happen under such interventions because we have no basis for
disentangling, even conceptually, the effect of changing the cause variable
alone fromthe effects of other sorts of changesthat accompanychangesin
the cause variable. (Woodward 2003:132)
In this regard, what matters is not the ability for humans to manipulate the cause
throughsomeformofactualphysicalinterventionbutratherthatwebeable,asobser-
vational analysts, to conceive of the conditions that would follow from a hypothetical
(but perhaps physically impossible) intervention.3
with this strange conclusion” (38). The position that we have maintained in this book is that the
simpleanddirectexplanatorygoalsathandarevalidguidesforthedelineationofcausalstates and,
furthermore,thatclaimsaboutthesizesofestimatedcausaleffectswillbesufficientlyinformativefor
thepurposesathandifthecausalstatesthatdefinethemarelocalandreasonable.Simplyput,claims
fortherelevanceofcausalitybyomission,andespeciallycausalitybyprehistory,canbeheldasideby
scientificjudgmentalonebecausetheyaresufficientlyremoterelativetothegoalsoftheanalysis.

2Even so, Holland’s position is frequently misinterpreted. He didnot argue that nonmanipulable
causes cannot beanalyzed usingthe potential outcome model but rather that the effects of nonma-
nipulablecauses areill-definedand thereforecannot be estimated effectively withany methods. For
anupdatetohisargument,seeHolland(2008).

3Woodward(2003:122)alsodiscusseshowthefocusonconceivableinterventionsallowsonetoavoid
havingtocontemplatepreposterouslyunreasonablecounterfactuals.Holland(2008)stillsupportsthe
Inaddition,themanipulabilitycriterionisnotasrelevantasissometimessupposed.

For example, if discrimination is the topic of study, the attributes of individuals do
not need to be manipulated, only the perception of them by potential discriminators.

Deceptionthencanbe usedto gainleverageonthe causaleffects ofinterest,while the
attributes of the subjects of potential discriminationremainfixed. Greiner and Rubin
(2011)offer a discussionof appropriateresearchdesigns, consistentwith the potential
outcome model, where the causal effects of immutable characteristics can be studied
by manipulations of perceptions.

Even if Woodward’s position is rejected, and thus if a researcher does not feel
comfortable using counterfactuals to define the causal effects for hard-to-conceive-
of-actually-manipulating attributes, the counterfactual approach can still be used in
an as-if mode in order to sharpen the goals and contribution of an analysis. This is
the position of Glymour (1986), who responds to the original Holland-Rubin position
by arguing that counterfactuals can be used to elucidate effects that are presumed to
havebeencausedbyasetofpotentiallymanipulablefactorsbutaremerelyreferredto
collectivelybynominallabels.Thegoalofresearchistopushtheanalysisfurtherdown
from the nominal labels to the separable manipulable factors. In pursuit of this goal,
it can be efficient to first define the counterfactuals associated with nonmanipulable
attributes as if they could be easily and naturally manipulated by human action.4
Consider studying the effect of race on socioeconomic outcomes, one of the most
commontopicsofstudyintheliteratureonsocialinequality.Althoughracecannotbe
manipulatedeasily,theframeworkcanstillbeusedtomotivateanattempttoestimate
average gains that employed black adults working full-time, full-year would expect to
capture if all prospective employers believed them to be white. This effect would dif-
fer from an attempt to estimate what the black–white gap in earnings would be if
blackadultshadgrownupinfamilieswiththesameaveragelevelofincomeaswhites,
and hence would have had the available resources with which to purchase higher-
qualitysecondaryandpostsecondaryeducation.Byhelpingtoframesuchfinedistinc-
tions betweenalternative causalstates, the potential outcome model helps to sharpen
research questions and then shape reasonable interpretations of whatever results can
be distilled from the data that are at hand. Such a basic framing of differentials is
a necessary first step, and only thereafter can one begin to systematically investigate
the particularmechanismsthatgeneratethe causalrelationshipsandthatcanexplain
the sources of the differences that motivate the inquiry in the first place.

In this regard, stating merely that an attribute D causes an outcome Y is simply
the crudest form of a mechanism sketch (as we discussed in Chapter 10). To further
investigate this mechanism sketch, counterfactuals must then be defined for what-
ever conjectured process is thought to generate the causal effect of D on Y. Reskin
(2003),forexample,providesaclearexpositionofhowtheinvestigationofsucheffects
original1986motto, buthispositionismorenuanced thanmuchofthesecondary literatureimplies
andappearstohavesoftenedtosomesmalldegree.

4Weshouldalsonote,consistent withourpriordiscussioninSection 2.1,thatsomeofthecauses
that wecaneasilyconceive ofmanipulatingarealsonominal,inthesensethatthecausal capacities
inherentinthemmaybeattributabletoonlysomeoftheirconstituentfeatures.Fromthisperspective,
perhapsmostofthecausesthatwecanconceiveofmanipulating–obtaininganotheryearofschooling,
enrollinginaworkertrainingprogram,movingtoanalternativeneighborhood–arenominalstarting
pointsaswell.

of attributes should proceed. She argues that researchers should lay out alternative
mechanismsthatgenerateascriptiveinequality–primarilythosebasedonthediscrim-
inatory motives of gatekeepers versus those based on unequal access in structures of
opportunity – and then evaluate the relative of importance of each set of mechanisms
in targeted empirical analysis.

Objection 2: The Counterfactual Approach Is Appropriate Only for
Modeling the Effects of Causes, Not the Causes of Effects
If an investigator is interested in estimating the effect of a particular cause, D, on an
outcome of interest, Y, then the potential outcome model offers a strong foundation
for empirical inquiry. Causal analysis of this type is often labeled an effects-of-causes
analysis, and we have explained the counterfactual approachto such analysis at great
length in this book.

If,instead,aninvestigatorisinterestedinansweringtheall-encompassingquestion
“What causes Y?” then the investigator is interested in conducting what is often
labeled a causes-of-effects analysis. No progress in such an investigation is possible
without consulting extant theory or abducting relevant hypotheses that suggest that
theeffectsofoneormorecandidatecauses–A,B,C,D,andsoon–needtobemodeled
to determine whether evidence exists that one or more of these causes contributes
to the full account that explains the pattern of all observations of Y. For this type
of investigation, the potential outcome model is less natural. In fact, when potential
outcomesaredefinedforeachdistinctcombinationofstatesacrossallcandidatecauses,
theresultingnotationquicklybecomesanimpedimenttopracticewhenmorethantwo
orthreecandidatecausalvariablesmustbeconsidered.Fortunately,thecausalgraphs
thatwehavealsoutilizedinthis bookoffercorrespondingdefinitionsforcausaleffects
and, asa result, permit efficientrepresentationsof full causalsystems.These systems,
when fully written out, can effectively guide model specifications that can, in theory,
estimate the effects of an unlimited number of causes of an outcome of interest. For
this reason, it is false to claim that the counterfactual approach can only be used to
motivatestudies thatestimatethe effects ofcauses.Thisclaimcanonlybe considered
reasonableifonerestrictsthecounterfactualapproachtothepotentialoutcomemodel
and if one is concerned unduly with the practicality of using potential outcomes to
define effects for complex patterns of causal configurations.

The issues worth debating, as we see them, are whether social scientists pose too
many causes-of-effects questions relative to effects-of-causes questions and whether
thecounterfactualapproachdiffersfromotherapproachesinitscapacitytoenablethe
analysis of causes-of-effects questions. Michael Sobel has provided perhaps the most
vigorousindictment ofthe commonpracticeofattempting to estimate simultaneously
large numbers of causes of an effect of interest with observational data. To cite one
example of his perspective, he writes in the overview essay “Causal Inference in the
Social Sciences” for a millennium issue of the Journal of the American Statistical
Association:
much of quantitative political science and sociology may be characterized
as a highly stylized search for new causes of effects. Researchers typically
beginwithoneormoreoutcomesandalistofcausesidentifiedbyprevious
workers.Potentiallynewcausesarethenlisted;iftheseaccount(“explain”)
for additional variability of the response, then the new causes are held to
affect the outcome, and the significant coefficients in the new model are
endowed with a causal interpretation. The process is repeated by subse-
quent workers, resulting in further “progress.” When researchers realize
that they are merely adding more and more variables to a predictive con-
ditioning set, one wonders what will take the place of the thousands of
purported(causal) effects that currently fill the journals. (Sobel 2000:650)
If Sobel is correct (and we are inclined to agree with him), then the social sciences in
the pastfew decades have given too much attention to the estimation of the causes of
effectsandtoolittleattentiontothesimplerandmoretractablegoalofestimatingthe
effects of particular causes. But even if one disagrees with this position, maintaining
instead that causes-of-effects questions should always be in the foreground, it is hard
to deny that the quest for a full account of the causes of any outcome is aided (and
perhaps, at times, best advanced) by the pursuit of well-defined questions that focus
narrowlyontheeffectsofparticularcauses.Asknowledgeoftheseeffectsaccumulates,
we can then attempt to build full causal accounts of all of the effects on the outcome
of interest. If the counterfactual approach is then justified only as an instrumental
path toward the ultimate goal of sustaining full causal accounts, little of its appeal is
diminished in our view.5
ThephilosopherPaulHumphreysoffersanelegantappealtothispragmaticrealist–
empiricist position in the concluding paragraph of his 1989 book, The Chances of
Explanation: Causal Explanation in the Social, Medical, and Physical Sciences. After
reflectingonthedemiseofthecoveringlawmodelofexplanationandsomeofitsfailed
alternatives, Humphreys writes:
What, then, do we have to replace the traditional account of explana-
tory knowledge? It is not propositional knowledge.... Nor is it de dicto
knowledge.... It is de re knowledge of the causes that contributed to the
effect, gainedinacumulativemanner,coupledwiththe discoveryofprevi-
ouslyunknownstructuresthatpushes the movingboundaryofthe observ-
ableevenfurtherfromordinaryexperienceandallowsustobecomeacquainted
withfinerandfinerdetailsofhowtheworldworks.Whenweknowofallof
the causes, then we shall know all there is to know of the kind with which
we are concerned,for all that we will be left is pure chance,and chance is,
as I have said, literally nothing. (Humphreys 1989:140–41)
5Onefrontierofcurrentmethodological scholarship,consistentwiththecounterfactual approach,
istheelaborationofsufficientcomponentcausemodelsthatbridgeclassicepidemiologicalmodelswith
causal graph methodology (see VanderWeele and Robins 2007b, 2008, 2009; VanderWeele, Vanstee-
landt,andRobins2010;Vansteelandt,VanderWeele,andRobins2012).Thesecauses-of-effectsmodels
adoptathreshold-crossingframeworkwherecombinationsofriskfactorsaremodeledasjointlysuffi-
cienttogenerate theoutcome ofinterest(typically, onset ofahealth conditionof someform).Pearl
(2009, chapters 9 and 10) has long recognized the value in using his structural equation approach
to develop “actual cause” models. We expect that in the coming years recognition that these sorts
of models exist will decrease the frequency with which others raise the causes-of-effects objection
discussedinthissection.

The idea here is that we should strive to explain phenomena by estimating the effects
of putative causes on particular outcomes. And, in practice for observational data
analysis, most such attempts require a consideration of at least two types of other
causesof the outcome: (1) those that may lie along back-doorpaths in a causalgraph
and (2) those that constitute the mechanisms that link the putative cause to the
outcome. Over time, we collect more data and estimate the effects of the same causes
on the same outcomes in a variety of conditions, which deepens our understanding of
the additional causes that were considered unobservables initially.

The counterfactual approach we have presented in this book is well suited to
this pragmatic account of social science research, where progress results from cred-
ible advances rather than grand claims. Even so, the counterfactual approach is not
inconsistent with the development and analysis of full causal systems that deliver
answersforcauses-of-effectsquestions,eventhoughitencouragesskepticismofresults
that are warranted only by assumptions of dubious validity.

Objection 3: Causal Inference Should Not Depend on Metaphysical
Quantities Such as Potential Outcomes
Inawide-rangingarticletitled“CausalInferenceWithoutCounterfactuals,”thestatis-
tician A. Philip Dawid argues that potential outcomes are inherently metaphysical,
andthus the counterfactualmodel forcausalinference is“generallyunhelpful andfre-
quently misleading” (Dawid 2000:409). He argues that causal claims must rest only
oninherently testable ideas,andhe presents analternativethat he arguessucceeds in
realizing the goal of estimating the effects of causes.6
Although some aspects of Dawid’s critique are rather involved, some of its central
features are quite simple. He first argues that the potential outcome model embraces
“fatalism” because it implicitly assumes that the potential outcomes of individuals
(i.e., y1 and y0 for a binary cause) are fixed values that are regarded as “predeter-
i i
mined attributes” of individuals “waiting only to be uncovered by suitable experi-
mentation” (Dawid 2000:412). For his alternative, Dawid considers a basic Bayesian
decision model that, without reference to potential outcomes, allows a statistician
to (1) design a randomized experiment to compare the effects of a treatment on an
outcome (in comparison with a base state of either no treatment or an alternative
treatment) and (2) convey the results of this experiment to inform a relevant decision
makeroftheexpectedeffectofapplyingthetreatmenttoanadditionalsubjectsimilar
to those on whom the experiment was conducted.7 After contrasting his model with
the counterfactual model, he concludes:
Ihavearguedthatthecounterfactualapproachtocausalinferenceisessen-
tially metaphysical, and full of temptation to make “inferences” that can-
not be justified on the basis of empirical data and are thus unscientific.

6For brevity, we do not cover Dawid’s position on modeling the causes of effects here. We just
addressedthecauses-of-effects versuseffects-of-causes positioninthelastsection.

7Following in the Bayesian tradition, the decision maker (who could also be the statistician)
can then assess the consequences of applying the treatment to the subject, with reference to cost
considerations and other determinants of her loss function. These additional points are not stressed
byDawid,inpartbecausetheyarenotincompatiblewiththecounterfactual model.

An alternative approach based on decision analysis, naturally appealing
and fully scientific, has been presented. This approachis completely satis-
factory for addressingthe problemof inference about the effects of causes,
andthefamiliar“blackbox”approachofexperimentalstatisticsisperfectly
adequate for this purpose. (Dawid 2000:423)
The response to Dawid’s critique of the potential outcome model has been largely
negative,asrevealedinthe commentspublishedalongsideit.The cruxofthe counter-
argument is the following. If perfect experiments for every causal question of interest
could be designed and then implemented, then potential outcomes are unnecessary
(even though they might still be useful for some purposes, such as to think through
theresultsthatmighthaveemergedfromalternativeexperimentalprotocols).Further-
more, no one seems to disagree with the claim that we should use study designs that
can rescue us from having to apply assumptions to what-if quantities. In this regard,
it would of course be preferable to be able to use a crossover design in all situations,
which Rothman et al. (2008) describe as follows:
Theclassiccrossover studyisatypeofexperimentinwhichtwo(ormore)
treatments are compared, as in any experimental study. In a crossover
study, however, each subject receives both treatments, with one following
the other. Preferably, the order in which the two treatments are applied
is randomly chosen for each subject. Enough time should be allocated
betweenthetwoadministrationssothattheeffectofeachtreatmentcanbe
measuredandcansubsidebeforetheothertreatmentisgiven.Apersistent
effectofthefirstinterventioniscalledacarryover effect.Acrossoverstudy
is only valid to study treatments for which effects occur within a short
induction period and do not persist, i.e., carryovereffects must be absent,
so that the effect of the second intervention is not intermingled with the
effect of the first. (Rothman et al. 2008:125)
The appeal of this sort of a study design, in view of Dawid’s critique, is that each
ostensiblymetaphysicalpotentialoutcomewouldbecomeanobservedoutcome.Unfor-
tunately, asRothmanetal.(2008)note,the crossoverdesignisonlyfeasiblewhenone
has control over the allocation of the treatment(s), is only effective when the treat-
ment effects of interest do not leave carryover effects behind, and is only possible if
the effectshaveashortenoughdurationthatonecanallocateandassesseachofthem
during the available observation window. These conditions exist very rarely for the
causal questions that concern social scientists, and as a result crossover studies are
most common in clinical settings where the goal is to examine “the efficacy of thera-
pies intended to reduce the frequency or severity of chronic, recurrent problems, such
as seizures” (Rothman et al. 2008:649).

Forobservationaldataanalysis,whichDawidbarelymentionsinhisarticle,wesee
no way to escape having to assert what-if assumptions about potential outcomes in
ordertomoveforward.RobinsandGreenland(2000),whencommentingontheDawid
critique, consider many of the applied examples for which counterfactual models have
been used. They conclude:
Bynarrowlyconcentratingonrandomizedexperimentswithcompletecom-
pliance, Dawid, in our opinion, incorrectly concludes that an approach to
causal inference based on“decisionanalysis”andfree ofcounterfactuals is
completely satisfactory for addressing the problem of inference about the
effects ofcauses.We arguethat whenattempting to estimate the effects of
causesinobservationalstudiesorinrandomizedexperimentswithnoncom-
pliance ... [a]relianceoncounterfactualsor their logicalequivalentcannot
be avoided. (Robins and Greenland 2000:431)
This basic point is echoed by most of the other commentators on the article. Cox
(2000:424) asks this question: “And yet: has the philosophical coherence [of Dawid’s
position],ifnotthrownthebabyoutwiththebathwater,atleastleftthebabyseriously
bruised in some vital organs?” Casella and Schwartz (2000:425–26)conclude, “Dawid
insists that such choices [about how to conduct a causal analysis] ... must be based
onstrictprinciples that canbe verifiedempirically. We believe thatsuch a programis
so overly rigid that, in the end, science is not served.”
Even so,Dawid’s objectionto the metaphysicalnature of potential outcomes does
bring up a deeper question: What is the epistemological status of the potential out-
come model?8 It is certainly not positivist, as it breaks radically from the positivist–
empiricist prescription that analysis must be based only on observed quantities. The
relianceonwhat-ifpotentialoutcomesandthe considerationofunobservables–inthe
treatment assignment process and for the presumed generative mechanism – consigns
the counterfactual approach to the postpositivist model of science generally labeled
realism(seePsillos1999;Putnam1975;seealsoGodfrey-Smith2003foranoverview).

But, because eachunobservedpotential outcome could have become an observedout-
come if the unobservables in the treatment assignment process had been configured
in an alternative way, and the variables that constitute the generative mechanism
could be observed as well, the entire framework aspires to help us become reductive
empiricists.

In this regard,we suspect thatmost socialscientists who adoptthe counterfactual
approach would find the enigmatic but enabling position of Donald Campbell similar
to their own, as he laid it out in 1977:
I am a fallibilist and antifoundationalist. No part of our system of knowl-
edge is immune to correction. There are no firm building blocks, either
as indubitable and therefore valid axioms, or in any set of posits that are
unequivocaloncemade.Norarethereevenanyunequivocalexperiencesor
explicit operations on which to found certainty of communication in lieu
of a certainty of knowledge.

8Whenwadingintothephilosophyliterature,onepointleapsoutinregardtoDawid’scharge.The
literature on causality is considered by most philosophers to be properly situated in the subfield of
metaphysics.Thus,Dawid’schargethatthepotentialoutcomeframeworkismetaphysicalis,fromthe
perspectiveofphilosophers,bothaccurateanduntroubling.SeealsothepositionofPearl(2009:33–34),
whoargues that, even ifcounterfactuals aremetaphysical insomesensebecause theyarestructures
in the mind, individuals are all too happy to use them in their daily lives. For this reason alone, it
seemsnaturaltobuildnotionsofcausalityaroundthem.

I am some kind of a realist,some kind of a critical,hypothetical, corri-
gible, scientific realist. But I am against direct realism, naive realism, and
epistemological complacency. (Campbell 1988[1977]:444–45)
We read this passage as indicating that Campbell recognized, grudgingly to be sure,
that the pursuit of valid knowledge necessitates the invocation of unobservable quan-
tities, such as potential outcomes. This necessity tips one into the realm of realism,
whereinsuchunobservablesaregivenprovisionaltruthstatus for pragmaticpurposes.

But,foranycorrigiblerealistlikeCampbell,theultimateaspirationistobringconjec-
tured unobservables out in the open, drawing analysis down to its most generic form
as an as-if positivist endeavor.

For scholars who find the counterfactual approach to observational data analysis
unappealing,perhapsbecauseofthepersuasivenessofsomeoftheobjectionspresented
inthissection,avarietyofresponsesexists.Somescholarsargue,simply,thatweshould
devotemuchmoreattentionto descriptivemodelingbecause causalanalysiscanbe so
intractable. We begin the next section with this position, after which we then move
on to consider alternative modes of causal inquiry within which the counterfactual
approach can be utilized.

## 13.2 Modes of Causal Inquiry in the Social Sciences

Some scholars argue that many long-standing questions in the social sciences can and

should be pursued without any reference to causality. When the sole interest is a par-
simonious account of “what the data show” or “what the historical record reveals,”
then all strategies for causal analysis are largely irrelevant, including the counterfac-
tual approach. But, there are also good reasons to consider descriptive analysis more
generally. Berk (2004:218) notes that “good description is the bread and butter of
good science and good policy research.” Sobel (1996:376) declares that many ques-
tions “neither require nor benefit from the introduction of causal considerations, and
the tendency to treat such questions as if they are causal only leads to confusion.”
Weagreewiththispositiontoagreatextent.Buttheappealfordescriptiveresearch
cannotbetakentoofar.Epistemologicalquestionsstillariseindescriptiveresearch,as
notalldescriptiveaccountscanbeconsideredequallyworthyofourattention.Perhaps
moreimportantly,socialscientistsmaynotwanttobackpedalfromcausalinquiry,lest
journalists,partisanthink-tankscholars,andpoliticianstakeitoverentirely.Wewould
mostprefertoseebothjudiciousdescriptiveanalysisandcarefulcausalanalysisjointly
crowd out poor causal analysis in the social sciences and beyond.

As we have noted at several points, when considering the causal controversies
that pervade the literature, many social scientists have echoed the point summarized
most clearly for sociology by John Goldthorpe, who writes, “sociologists have to find
their own ways of thinking about causation, proper to the kinds of research that
they can realistically carry out and the problems that they can realistically address”
(Goldthorpe 2001:8). With this appeal in mind, we conclude this book with a discus-
sion of the primary modes of causal inquiry that exist in observational social science.

We have two goals for this concluding presentation of complementary modes of
causal inquiry: (1) to affirm that all of these modes of inquiry are valuable and (2)
to argue that adopting a counterfactual approach can help us to move productively
betweenthem.Evenso,wewouldnotwanttoargueforthehegemonyofcounterfactual
thinking. The specter of widespread mechanical adoption of the potential outcome
model is truly frightening to us: No one wishes to have to review journal submissions
in which scholars define the average treatment effect for the treated (ATT), offer
up a fairly arbitrary set of matching estimates, and then a disingenuous sensitivity
analysis that purportedly bolsters the results. This prospect alone is sufficient for us
torecommendconsiderablecaution.But,perhapsmoreimportant,wecannotenvision
thepursuitofempiricalanalysisinourownresearchareaswithoutengaginginanalysis
thatincludesallofthemodesbelow.Inotherwords,wecanseemanyfutureprofitable
lines ofinquiry inour ownresearchin whichcounterfactualthinking will be usedonly
as a backgroundtool to encourage clear thinking.

Withthatbacking,weofferthefollowing(necessarilyoversimplified)representation
of complementary modes of causal inquiry in observational social science:
Mode 1: Associational Analysis. In practice, most causal inquiry begins with an
assessment,sometimesunreported,ofwhetherputativeobservedcausesareassociated
withanoutcomeofinterestinsomeway.Itisoftenstatedthatestablishingsuchasso-
ciationsareapreconditionforsubsequentcausalanalysis,asreflectedinthe aphorism
“no causation without association.”9
Mode 2: Conditional Associational Analysis. After associations have been estab-
lished, it is customaryto thenreestimate the associationsafter conditioningonvalues
of other observed variables. Although quite general, the typical approach usually fol-
lowsone of two implementations:(1) conditioning onother variables that arethought
to determine the outcome and that may also be related to the cause(s) and(2) condi-
tioning on variables that determine the cause(s) and that may also be related to the
outcome. Although conceptually quite different (as we noted in our discussion in Sec-
tion 4.4), the goal of such conditioning is to eliminate obvious sources of confounding
in order to build basic support for causal relevance.

Mode 3a: Targeted Analysis of the Effects of One or More Focal Causes. After an
assessment of basic causal relevance for a set of putative causes, the effects of one or
more particular causes are then estimated in targeted analysis. This mode of causal
inquiry can be (or, we would argue, should be) undertaken after first elaborating a
directedgraphentailedbyextanttheory.Inanycase,carefulattentiontomodelspeci-
ficationisneeded,adoptingassumptions,forexample,ofignorabilityifidentificationis
byback-doorconditioningorexclusionsrestrictionsifidentificationisbyinstrumental
variables.

9Formally,ofcourse,therearecasesforwhichthismaynotbetrue,suchaswhenindividual-varying
causaleffects perfectlycancel outeachotherorwhensuppressioneffects exist.Weignoreexceptions
such as these here, as they are rare. The sorts of physical equilibriathat rigidlygenerate balancing
ofresponsestocausalshockshavenoclearanalogsinthesocialsciencesthatwouldgeneratesimilar
perfectcancellationofunit-specificcausaleffects.And,althoughsuppressioneffectsexistinthesocial
sciences,wecannot thinkofexamples forwhichthey havebeenshowntocompletely erasebivariate
associationsthatareatleastpartlycausal.

Mode 3b: Mechanism-Based Analysis. After (or while) targeted estimation of the
effects of one or more causes is undertaken, a common practice in causal inquiry is
to then introduce intervening variables between the focal causal variable(s) subjected
to targeted analysis and the outcome variable in an effort to develop a mechanistic
explanation of the process that generates the causal effect. Such a form of causal
inquiry can proceed, as is often the case, even though it may be unclear whether or
not all forms of confounding have been eliminated.

Mode 4: All-Cause Structural Analysis. At its most ambitious level, causal inquiry
is pursued as an attempt to identify all causes in chains of causality from the causal
variables to the outcome variable,eliminating or neutralizing allconfounding in order
to identify all parameters of full causal systems. This approach is best represented in
the formsofstructuralequationmodelingthatprevailineconomics,whereinallspeci-
ficationsarejustifiedwithappealstomicroeconomictheoryandpurporttoexplainthe
entire “who, when, where, and how” of all of the causes of the outcome of interest.10
Consider now how the counterfactual approach can be related to these comple-
mentary but increasingly ambitious modes of causal inquiry and how adoption of the
approach facilitates movement between them as advances in theory construction and
data collection are achieved. For Mode 1 (associational analysis), the counterfactual
approach encourages the consideration of causes for which one can conceive of the
reasonable and theoretically possible conditions that would result from an interven-
tion that changes the causal variable from one value to another. When causal inquiry
is stuck by convention on the consideration of the effects of attributes for which the
conditions ofas-ifinterventionsareunclear, the approachencouragesadditional effort
to break the associational analysis into pieces that are more amenable to analysis by
consideration of specific counterfactual dependencies. The hope of such a refined and
expansive strategy is that the analysis can be brought down to a level where manip-
ulations are more easily conceivable, which may then allow for a redirection of the
extant associational inquiry. Such redirection may be necessary in order to open up
the possibility of advancement beyond Modes 1 and 2.

For the transition from Mode 1 to Mode 2 (that is, from associational to condi-
tional associational analysis), the counterfactual model encourages separate but com-
parative consideration of the determinants of the causes and the determinants of the
outcome. Determinants of causal variables lost some deserved attention as regression
methods became dominant in observational social science in the 1980s and 1990s,but
the matching literature associated with the counterfactual model has restored some
of this attention by focusing analysis on the goal of balancing the data with respect
to the determinants of the cause. For the subsequent transition to Mode 3a (targeted
analysis of one or more focal causes), the joint consideration of both types of vari-
ables then allows for a determination, by carefully defined assumptions grounded in
theory, of which sufficient subset of such determinants may be used in a conditioning
10In addition, all-cause structural analysis may drill down to model directly the separable causal
effectsoftheconstituentfeaturesthatcomposethecausalstates.Inotherwords,thecausalvariables
analyzed for Modes 1, 2, and 3a may come to be regarded as too broad to motivate sensible struc-
tural models. This decision may emerge following analysis within Mode 3b when the analyst comes
to recognize that the relevant generative mechanisms apply to only a subset of the causal state’s
constitutive features.

strategy to achieve identification of the causal effect by eliminating all confounding.

If the assumptions cannot be sustained for any set of observed variables, then point
identification of the focal causal effects by back-door conditioning is impossible.

If no other researchdesign is possible, such as those that exemplify Modes 3b and
4, then the counterfactual model suggests clearly why analysis should then expand
beyond efforts to point-identify causal effects to alternative forms of set identifica-
tionandsensitivity analysis.In addition,the counterfactualapproachalsoencourages
especially careful examination of all back-door paths from the causal variable to the
outcome variable (rather than simply a one-by-one consideration of all variables that
lie alonganyback-doorpaths). This formofsystematic considerationofmodel identi-
ficationcanpreventresearchersfrommistakenly generatingnew confounding between
the causal variables and the outcome variable, as occurs when the analyst conditions
on a collider variable that lies along an already blocked back-door path.

For the transition to Mode 3b (mechanism-based analysis), the counterfactual
approach shows that such a transition is substantive, not methodological. No new
estimation techniques beyond those used for Modes 2 and 3a are required. All that is
required to pursue Mode 3b is a theory that suggests which variables (and in which
configuration) represent the causal mechanism that brings about the causal effect.

Moreover,the counterfactual approach suggests that typical mechanism-based analy-
sesmust be clearlyseparatedinto two verydifferentvarieties: those thatmerely point
to possible causal pathways and those that fully identify the causal effects of interest.

For analysis of the former type, some explanationcan be achieved.But, to realize the
moreambitiousgoalsofthelatter,themechanisticvariablesthatarespecifiedmustbe
exhaustive and isolated (or made so by suitable conditioning). Mechanistic variables
thatarenotindependentofunblockedback-doorpaths afterconditioningonobserved
variables cannot be used to identify a causal effect.

For the transition to Mode 4 (all-cause structural analysis), the counterfactual
approach sensitizes researchers to the stringency of the required assumptions. Pearl
(2009)issurelycorrectthatourambitionshouldalwaysbetogetascloseaspossibleto
all-causestructuralmodelswhereaccountscanbeofferedforallofthecausesofanout-
come.Adoptingthe counterfactualapproachhelpstoclarifythedubiousnatureofthe
maintained assumptions that pervade the published literature where all-cause models
are offered. For example, most such models are based on combinations of two identi-
fication strategies – basic conditioning and instrumental variable techniques – under
maintainedassumptionsthatcausaleffects arehomogeneous(oratleastconditionally
random). As the matching literature associated with the counterfactual approach has
shown, such homogeneity is rarely justified empirically even for singular causes, and
most parametric forms of conditioning average systematic causal effect heterogeneity
in arcane ways. Moreover, the instrumented variable (IV) literature associated with
the counterfactual approach has shown that, in the presence of such heterogeneity,
IVs estimate marginal causal effects that cannot then be extrapolated to other seg-
mentsofthe populationofinterestwithoutintroducingunsupportableassumptionsof
homogeneity of effects.

By making these issues clear, the counterfactual approach shows how high the
demandsontheoryandondatamustbeinordertosustaintheall-causemodeofcausal
inquiry: Answers to all of the “who, when, where, and how” questions for the causal
relationships of interest must be provided. Dodging these questions by introducing
homogeneity assumptions that have only a dubious grounding in theory (or a solid
grounding in dubious theory) can undermine causal claims, at least in the eyes of a
fair critic. In this sense, the counterfactual approach encourages modesty of causal
inquiry.

Finally, such modesty can be pursued outside of these modes of inquiry, after
which analysis can then shift into whichever of these modes seems most appropriate.

As shown perhaps most clearly when adopting Manski’s set-identification perspective
(see Chapter 12), the range that a causal effect may take on can be defined and
then examined with the potential outcome model before any data are considered.

Thereafter,anassessmentcanbeundertakenofthedatathatareavailabletoestimate
averagecausaleffectsofvariousforms.Forthesesteps,assumptionsaboutwhyacausal
relationship may exist need not be introduced, nor in fact assumptions that there is
anysystematicrelationshipbetweentheprocessesthatgeneratecausalrelationshipsat
the individual level. Such flexibility leaves analysis wide open at the outset, focusing
attention on clear definitions of effects of interest, independent of data availability
issues.

But, once an analysis has begun, a theoretical position must be adopted in order
to provide answers to at least some of the “who, when, where, and how” questions
for the causal relationship of interest. Given provisional answers to these questions,
the counterfactual approach helps one to consider which modes of causal inquiry are
feasible. Analysis may have to stop at the associational level, yielding nothing other
than analogs to the naive estimator. If some of the determinants of the cause and/or
outcome are systematic and observed, then analysis can move down to conditional
variants of associational analysis, followed by an analysis of bounds (and perhaps a
sensitivity analysis). If a directed graph can be drawn that suggests that ignorability
assumptions or exclusionrestrictions are available for focal causaleffects, then it may
be feasible to generate consistent estimates of the effects of these specific causes. If
theoryanddataareavailabletoexaminewhatbringsabouttheeffectofthecause,then
analysis can move down toward a mechanism-based mode of causal inquiry. Finally,
if theory is finely articulated and supported by past substantive scholarship, and if
all data requirements are met, then full structural modeling can be attempted. Such
all-cause models represent a standard that is rarely achieved but properly valued, for
they provide complete explanations not only of the causes of an outcome but of every
linkageinthe causalchainsbetweenthem. Counterfactualmodeling guidesusasclose
to this standard as is appropriate, given the constraints of theory and of data that
prevail at any given time.

# References

Abadie, Alberto and Guido W. Imbens. 2006. “Large Sample Properties of Matching

Estimators for Average Treatment Effects.” Econometrica 74:235–67.

—. 2008. “On the Failure of the Bootstrap for Matching Estimators.” Econometrica
76:1537–57.

—.2009.“MatchingontheEstimatedPropensityScore.”NationalBureauofEconomic
Research, Cambridge, Massachusetts.

—.2011.“Bias-CorrectedMatchingEstimatorsforAverageTreatmentEffects.”Jour-
nal of Business and Economic Statistics 29:1–11.

—. 2012. “A Martingale Representation for Matching Estimators.” Journal of the
American Statistical Association 107:833–43.

Abbott, Andrew D. 1988.“TranscendingGeneral LinearReality.” Sociological Theory
6:169–86.

—.2001[1998].Time Matters: On Theory and Method. Chicago:UniversityofChicago
Press.

Abdulkadiroglu, Atila, Joshua D. Angrist, Susan M. Dynarski, Thomas J. Kane, and
Parag Pathak. 2011. “Accountability and Flexibility in Public Schools: Evidence
from Boston’s Charters and Pilots.” Quarterly Journal of Economics 126:699–748.

Adler, Nancy E. andKatherineNewman. 2002.“SocioeconomicDisparities in Health:
Pathwaysand Policies.” Health Affairs 21:60–76.

Agresti, Alan. 2002. Categorical Data Analysis. New York: Wiley.

Alexander,JeffreyC.2003.TheMeaningsofSocialLife:ACulturalSociology.NewYork:
Oxford University Press.

Alexander, Karl L. and Aaron M. Pallas. 1983. “Private Schools and Public Policy:
New Evidence on Cognitive Achievement in Public and Private Schools.” Sociology
of Education 56:170–82.

—. 1985.“SchoolSectorandCognitivePerformance:When Is aLittle aLittle?” Soci-
ology of Education 58:115–28.

451
Allison,PaulD.1990.“ChangeScoresasDependentVariablesinRegressionAnalysis.”
Sociological Methodology 20:93–114.

—. 2009. Fixed Effects Regression Models. Los Angeles: Sage.

Althauser, Robert P. and Donald B. Rubin. 1970. “The Computerized Construction
of a Matched Sample.” American Journal of Sociology 76:325–46.

—. 1971. “Measurement Error and Regression to the Mean in Matched Samples.”
Social Forces 50:206–14.

Altonji, Joseph G., Todd E. Elder, and Christopher Taber. 2005a. “An Evaluation of
Instrumental Variable Strategies for Estimating the Effects of Catholic Schooling.”
Journal of Human Resources 40:791–821.

—. 2005b.“Selectionon Observedand UnobservedVariables:Assessing the Effective-
ness of Catholic Schools.” Journal of Political Economy 113:151–83.

Alwin, Duane F. andRobertM. Hauser.1975.“TheDecompositionofEffects inPath
Analysis.” American Sociological Review 40:37–47.

An, Weihua. 2010. “Bayesian Propensity Score Estimators: Incorporating Uncertain-
ties in Propensity Scores into Causal Inference.” Sociological Methodology 40:
151–89.

—. 2013. “Models and Methods to Identify Peer Effects.” Pp. 514–32 in The Sage
HandbookofSocialNetworkAnalysis,editedbyJ.ScottandP.J.Carrington.Thou-
sand Oaks: Sage.

Angrist, Joshua D. 1990. “Lifetime Earnings and the Vietnam Era Draft Lottery:
EvidencefromSocialSecurityAdministrativeRecords.”AmericanEconomicReview
80:313–36.

—. 1998. “Estimating the Labor Market Impact of Voluntary Military Service Using
Social Security Data on Military Applicants.” Econometrica 66:249–88.

Angrist,JoshuaD.andStaceyH.Chen.2011.“SchoolingandtheVietnam-EraGIBill:
EvidencefromtheDraftLottery.”American Economic Journal: Applied Economics
3:96–119.

Angrist, Joshua D., Susan M. Dynarski, Thomas J. Kane, Parag A. Pathak, and
ChristopherR.Walters.2010.“InputsandImpactsinCharterSchools:KIPPLynn.”
American Economic Review: Papers & Proceedings 100:1–5.

Angrist,JoshuaD.andIvanFernandez-Val.2013.“ExtrapoLATE-ing:ExternalValid-
ity and Overidentification in the LATE Framework.” Pp. 401–36 in Advances in
Economics and Econometrics, vol. 3, edited by D. Acemoglu, M. Arellano, and D.

Eddie. Cambridge: Cambridge University Press.

Angrist,JoshuaD.andGuidoW.Imbens.1995.“Two-StageLeastSquaresEstimation
ofAverageCausalEffects inModels with VariableTreatmentIntensity.” Journal of
the American Statistical Association 90:431–42.

Angrist, Joshua D., Guido W. Imbens, and Donald B. Rubin. 1996. “Identification of
Causal Effects Using Instrumental Variables.” Journal of the American Statistical
Association 87:328–36.

Angrist,JoshuaD. andAlanB.Krueger.1991.“DoesCompulsorySchoolAttendance
Affect Schooling and Earnings?” Quarterly Journal of Economics 106:979–1014.

—. 1992. “The Effect of Age at School Entry on Educational Attainment: An Appli-
cationof Instrumental Variables with Moments from Two Samples.” Journal of the
American Statistical Association 87:328–36.

—. 1994. “Why Do World War II Veterans Earn More Than Nonveterans?” Journal
of Labor Economics 12:74–97.

—. 1999. “Empirical Strategies in Labor Economics.” Pp. 1277–366 in Handbook of
Labor Economics, vol. 3, edited by O. C. Ashenfelter and D. Card. Amsterdam:
Elsevier.

—. 2001. “Instrumental Variables and the Search for Identification: From Supply and
Demand to Natural Experiments.” Journal of Economic Perspectives 15:65–83.

Angrist, Joshua D. and Victor Lavy. 1999. “Using Maimonides’ Rule to Estimate the
Effect of Class Size on Scholastic Achievement.” Quarterly Journal of Economics
114:533–75.

Angrist, Joshua D. and J¨orn-Steffen Pischke. 2009. Mostly Harmless Econometrics:
An Empiricist’s Companion. Princeton: Princeton University Press.

—. 2010. “The Credibility Revolution in Empirical Economics: How Better
ResearchDesignIsTakingtheConOutofEconometrics.”The Journalof Economic
Perspectives 24:3–30.

Arminger, Gerhard, Clifford C. Clogg, and Michael E. Sobel, Eds. 1995. Handbook of
Statistical Modeling for the Social and Behavioral Sciences. New York: Plenum.

Armor, David J. 1995. Forced Justice: School Desegregation and the Law. New York:
Oxford University Press.

Aronow, Peter M. and Allison Carnegie. 2013. “Beyond LATE: Estimation of the
AverageTreatmentEffectwithanInstrumentalVariable.”PoliticalAnalysis21:492–
506.

Ashenfelter,OrleyC.1978.“EstimatingtheEffectofTrainingProgramsonEarnings.”
Review of Economics and Statistics 60:47–57.

Ashenfelter, Orley C. and David Card. 1985. “Using the Longitudinal Structure of
Earnings to Estimate the Effect of Training Programs.” Review of Economics and
Statistics 67:648–60.

Austin, PeterC.2009a.“BalanceDiagnosticsforComparingtheDistributionofBase-
line Covariates between Treatment Groups in Propensity-Score Matched Samples.”
Statistics in Medicine 28:3083–107.

—. 2009b. “Some Methods of Propensity-Score Matching Had Superior Performance
to Others: Results of an Empirical Investigation and Monte Carlo Simulations.”
Biometrical Journal 51:171–84.

Baltagi, Badi H. 2005. Econometric Analysis of Panel Data. Chichester: J. Wiley &
Sons.

Bang, Heejung and James M. Robins. 2005. “Doubly Robust Estimation in Missing
Data and Causal Inference Models.” Biometrics 61:962–72.

Barnow,BurtS.,GlenG.Cain,andArthurS.Goldberger.1980.“IssuesintheAnalysis
of Selectivity Bias.” Evaluation Studies Review Annual 5:43–59.

Barringer, Sondra N., Erin Leahey, and Scott R. Eliason. 2013. “A History of Causal
AnalysisintheSocialSciences.”Pp.9–26inHandbook of Causal Analysis for Social
Research, edited by S. L. Morgan. Dordrecht: Springer.

Becker, Gary S. 1993[1964]. Human Capital: A Theoretical and Empirical Analysis
with Special Reference to Education. Chicago: University of Chicago Press.

Becker,SaschaO.andAndreaIchino.2005.“Pscore:StataProgramsforATTEstima-
tionBasedonPropensityScoreMatching.”SoftwareRoutineforStata,Department
of Economics, University of Warwick, Coventry, United Kingdom.

Behrens,Angela,ChristopherUggen,andJeffManza.2003.“BallotManipulationand
the ‘Menace of Negro Domination’: Racial Threat and Felon Disenfranchisement in
the United States, 1850–2002.”American Journal of Sociology 109:559–605.

Berger, Mark C. and Barry T. Hirsch. 1983. “The Civilian Earnings Experience of
Vietnam-Era Veterans.” Journal of Human Resources 18:455–79.

Berinsky, Adam J. and Gabriel S. Lenz. 2011.“Educationand PoliticalParticipation:
Exploring the Causal Link.” Political Behavior 33:357–73.

Berk, Richard, Geoffrey Barnes, Lindsay Ahlman, and Ellen Kurtz. 2010. “When
Second Best Is Good Enough: A Comparison between a True Experiment and a
RegressionDiscontinuity Quasi-Experiment.”Journal of Experimental Criminology
6:191–208.

Berk,RichardA. 1988.“CausalInference forSociologicalData.”Pp. 155–72inHand-
book of Sociology, edited by N. J. Smelser. Newbury Park: Sage.

—. 2004. Regression Analysis: A Constructive Critique. Thousand Oaks: Sage.

—. 2006. “An Introduction to Ensemble Methods for Data Analysis.” Sociological
Methods and Research 34:263–95.

—. 2008. Statistical Learning from a Regression Perspective. New York:
Springer.

Berk, Richard A. and Jan de Leeuw. 1999. “An Evaluation of California’s Inmate
Classification System Using a Generalized Discontinuity Design.” Journal of the
American Statistical Association 94:1045–52.

Berk, Richard A. and Phyllis J. Newton. 1985. “Does Arrest Really Deter Wife Bat-
tery? An Effort to Replicate the Findings of the Minneapolis Spouse Abuse Exper-
iment.” American Sociological Review 50:253–62.

Berk,RichardA.,PhyllisJ.Newton,andSarahFenstermakerBerk.1986.“WhataDif-
ference a Day Makes: An Empirical Study of the Impact of Shelters
for Battered Women.” Journal of Marriage and the Family 48:
481–90.

Berk,RichardA.andDavidRauma.1983.“CapitalizingonNonrandomAssignmentto
Treatments: A Regression-Discontinuity Evaluation of a Crime-Control Program.”
Journal of the American Statistical Association 78:21–27.

Berzuini,Carlo,PhilipDawid,andLuisaBernardinelli,Eds.2012.Causality:Statistical
Perspectives and Applications. Hoboken: Wiley.

Bhaskar, Roy. 1998[1997]. “Philosophy and Scientific Realism.” Pp. 16–47 in Critical
Realism: Essential Readings, edited by M. S. Archer, R. Bhaskar, A. Collier, T.

Lawson, and A. Norrie. London: Routledge.

Black,SandraE.1999.“Do Better SchoolsMatter?ParentalValuationofElementary
Education.” Quarterly Journal of Economics 114:577–99.

Blalock,HubertM.1964[1961].CausalInferencesinNonexperimentalResearch.Chapel
Hill: University of North Carolina Press.

Blau,PeterM.andOtisDudleyDuncan.1967.The American Occupational Structure.

New York: Wiley.

Bloom, Howard S. 2012. “Modern Regression Discontinuity Analysis.” Journal of
Research on Educational Effectiveness 5:43–82.

Blossfeld,Hans-Peter.2009.“CausationasaGenerativeProcess:TheElaborationofan
Ideaforthe SocialSciences andanApplicationtoanAnalysisofanInterdependent
Social System.” Pp. 83–109 in Causal Analysis in Population Studies: Concepts,
Methods, Applications, edited by H. Engelhardt, H.-P. Kohler, and A. Prskawetz.

Dordrecht: Springer.

Blundell, Richard, Amanda Gosling, Hidehiko Ichimura, and Costas Meghir. 2007.

“ChangesintheDistributionofMaleandFemaleWagesAccountingforEmployment
Composition Using Bounds.” Econometrica 75:323–63.

Bollen,KennethA.1989.StructuralEquationswithLatentVariables.NewYork:Wiley.

—. 1995. “Structural Equation Models That Are Nonlinear in Latent Variables: A
Least-Squares Estimator.” Sociological Methodology 25:223–51.

—. 1996a. “An Alternative Two-Stage Least Squares (2SLS) Estimator for Latent
Variable Equations.” Psychometrika 61:109–21.

—. 1996b. “A Limited-Information Estimator for LISREL Models with or Without
Heteroscedastic Errors.” Pp. 227–41 in Advanced Structural Equation Modeling:
IssuesandTechniques,editedbyG.A.MarcoulidesandR.E.Schumacker.Mahwah:
Lawrence Erlbaum.

—. 2001. “Two-Stage Least Squares and Latent Variable Models: Simultaneous Esti-
mation and Robustness to Misspecifications.” Pp. 119–38 in Structural Equation
Modeling: PresentandFuture–aFestschriftinHonorofKarlJo¨reskog,editedbyR.

Cudeck, S. du Toit, and D. So¨rbom. Lincolnwood: Scientific Software
International.

—.2012.“InstrumentalVariablesinSociologyandtheSocialSciences.”AnnualReview
of Sociology 38:37–72.

Bollen, Kenneth A. and Judea Pearl. 2013. “Eight Myths About Structural Equation
Models.” Pp. 301–28in Handbook of Causal Analysis for Social Research, edited by
S. L. Morgan. Dordrecht: Springer.

Boudon, Raymond. 1998. “Social Mechanisms Without Black Boxes.” Pp. 172–203in
SocialMechanisms:AnAnalyticalApproachtoSocialTheory,editedbyP.Hedstro¨m
and R. Swedberg. Cambridge: Cambridge University Press.

Bound, John, David A. Jaeger, and Regina M. Baker. 1995. “Problems with Instru-
mental Variables Estimation When the Correlation between the Instruments and
the Endogenous Explanatory Variable Is Weak.” Journal of the American Statisti-
cal Association 90:443–50.

Bourdieu,Pierre.1973.“CulturalReproductionandSocialReproduction.”Pp.71–112
in Knowledge, Education, and Cultural Change: Papers in the Sociology of Educa-
tion, edited by R. K. Brown. London: Tavistock.

Bowden, Roger J. and Darrell A. Turkington. 1984. Instrumental Variables. Cam-
bridge: Cambridge University Press.

Braakmann, Nils. 2011. “The Causal Relationship between Education, Health and
HealthRelatedBehaviour:EvidencefromaNaturalExperimentinEngland.”Jour-
nal of Health Economics 30:753–63.

Brady, Henry E. and David Collier, Eds. 2010. Rethinking Social Inquiry: Diverse
Tools, Shared Standards. Lanham: Rowman and Littlefield.

Braga, Anthony A., David Hureau, and Christopher Winship. 2008. “Losing Faith?
Police, Black Churches, and the Resurgence of Youth Violence in Boston.” Ohio
State Journal of Criminal Law 6:141–72.

Braga, Anthony A., David M. Kennedy, Elin J. Waring, and Anne Morrison Piehl.

2001. “Problem-OrientedPolicing, Deterrence, and Youth Violence: An Evaluation
of Boston’s Operation Ceasefire.” Journal of Research in Crime and Delinquency
38:195–225.

Brand, Jennie E. and Dwight Davis. 2011. “The Impact of College Education on
Fertility: Evidence for Heterogeneous Effects.” Demography 48:863–87.

Brand, Jennie E. and Juli Simon Thomas. 2013. “Causal Effect Heterogeneity.” Pp.

189–213inHandbookofCausalAnalysisforSocialResearch,editedbyS.L.Morgan.

Dordrecht: Springer.

Brand, Jennie E. and Yu Xie. 2010. “Who Benefits Most from College? Evidence
for Negative Selection in Heterogeneous Economic Returns to Higher Education.”
American Sociological Review 75:273–302.

Breen, Richard and Jan O. Jonsson. 2005. “Inequality of Opportunity in Compara-
tivePerspective:RecentResearchonEducationalAttainment andSocial Mobility.”
Annual Review of Sociology 31:223–43.

Brewster,KarinL.andRonaldR.Rindfuss.2000.“FertilityandWomen’sEmployment
in Industrialized Nations.” Annual Review of Sociology 26:271–96.

Browning, Harley L., Sally C. Lopreato, and Dudley L. Poston Jr. 1973. “Income
and Veteran Status: Variations among Mexican Americans, Blacks and Anglos.”
American Sociological Review 38:74–85.

Bryk, Anthony S., Valerie E. Lee, and Peter B. Holland. 1993. Catholic Schools and
the Common Good. Cambridge: Harvard University Press.

Bumpass, Larry L., Ronald R. Rindfuss, and Richard B. Janosik. 1978. “Age and
Marital Status at First Birth and the Pace of Subsequent Fertility.” Demography
15:75–86.

Bunge, Mario. 2004. “How Does It Work? The Search for Explanatory Mechanisms.”
Philosophy of Social Science 34:182–210.

Bush, Robert R. and Frederick Mosteller. 1955. Stochastic Models for Learning. New
York: Wiley.

—. 1959. “A Comparison of Eight Models.” Pp. 335–49 in Studies in Mathematical
Learning Theory, edited by R. R. Bush and W. K. Estes. Stanford: Stanford Uni-
versity Press.

Campbell, DonaldT.1957.“FactorsRelevanttothe ValidityofExperimentsinSocial
Settings.” Psychological Bulletin 54:297–312.

—. 1988[1977]. Methodology and Epistemology for Social Science: Selected Papers.

Chicago: University of Chicago Press.

Campbell, Donald T. and Julian C. Stanley. 1966[1963]. Experimental and Quasi-
Experimental Designs for Research. Chicago: Rand McNally.

Carbonaro,William and Elizabeth Covay. 2010. “School Sector and Student Achieve-
ment in the Era of Standards Based Reforms.” Sociology of Education 83:
160–82.

Card, David. 1999. “The Causal Effect of Education on Earnings.” Pp. 1801–63 in
Handbook of Labor Economics, vol. 3A, edited by O. C. Ashenfelter and D. Card.

Amsterdam: Elsevier.

Card,DavidandEnricoMoretti. 2007.“DoesVotingTechnologyAffect ElectionOut-
comes? Touch-Screen Voting and the 2004 Presidential Election.” Review of Eco-
nomics and Statistics 89:660–73.

Carneiro, Pedro, James J. Heckman, and Edward J. Vytlacil. 2010. “Evaluating
Marginal Policy Changes and the Average Effect of Treatment for Individuals at
the Margin.” Econometrica 78:377–94.

—. 2011. “Estimating Marginal Returns to Education.” American Economic
Review 101:2754–81.

—. 2007a. “Counterfactuals in Economics: A Commentary.” Pp. 191–216 in Causa-
tion and Explanation, edited by J. K. Campbell, M. O’Rourke, and H. Silverstein.

Cambridge: MIT Press.

—.2007b.HuntingCausesandUsingThem:ApproachesinPhilosophyandEconomics.

Cambridge: Cambridge University Press.

Casella,GeorgeandStephenP.Schwartz.2000.“Commenton‘CausalInferencewith-
out Counterfactuals’ by A. P. Dawid.” Journal of the American Statistical Associa-
tion 95:425–27.

Caughey, Devin and Jasjeet S. Sekhon. 2011. “Elections and the RegressionDisconti-
nuity Design: Lessons from Close U.S. House Races, 1942–2008.”Political Analysis
19:385–408.

Cawley,JohnandChristopherJ.Ruhm.2012.“TheEconomicsofRiskyHealthBehav-
iors.” Pp. 95–199 in Handbook of Health Economics, vol. 2, edited by M. V. Pauly,
T. G. Mcguire, and P. P. Barros. Amsterdam: Elsevier.

Cawley, John H., Ed. 2011. The Oxford Handbook of the Social Science of Obesity.

New York: Oxford University Press.

Cawley, John, John Moran, and Kosali Simon. 2010. “The Impact of Income on the
Weight of Elderly Americans.” Health Economics 19:979–93.

Ceci, Stephen J. 1991.“How Much Does Schooling Influence General Intelligence and
Its Cognitive Components? A Reassessment of the Evidence.” Developmental Psy-
chology 27:703–22.

Center for Researchon Education Outcomes. 2009. “Multiple Choice: Charter School
Performance in 16 States.” Stanford University, Stanford, California.

Chakraborty, Bibhas and Erica E. M. Moodie. 2013. Statistical Methods for Dynamic
Treatment Regimes: Reinforcement Learning, Causal Inference, and Personalized
Medicine. New York: Springer.

Chapin, F. Stuart. 1932. “The Advantages of Experimental Sociology in the Study of
Family Group Patterns.” Social Forces 11:200–207.

—. 1947. Experimental Designs in Sociological Research. New York: Harper.

Christakis,NicholasA.andJamesH.Fowler.2007.“TheSpreadofObesityinaLarge
Social Network over 32 Years.” New England Journal of Medicine 357:370–79.

—.2013.“SocialContagionTheory:ExaminingDynamicSocialNetworksandHuman
Behavior.” Statistics in Medicine 32:556–77.

Chubb, John E. and Terry M. Moe. 1990. Politics, Markets, and America’s Schools.

Washington, DC: Brookings Institution.

Clotfelter, Charles T. 2004. After Brown: The Rise and Retreat of School Desegrega-
tion. Princeton: Princeton University Press.

Cochran, William G. 1968. “The Effectiveness of Adjustment by Subclassification in
Removing Bias in Observational Studies.” Biometrics 24:295–313.

Cochran, William G. and Gertrude M. Cox. 1950. Experimental Designs. New York:
Wiley.

Cochran, William G. and Donald B. Rubin. 1973. “Controlling Bias in Observational
Studies: A Review.” Sankhya 35:417–46.

Cohen-Cole, Ethan and Jason M. Fletcher. 2008. “Detecting Implausible Social Net-
workEffects in Acne, Height, and Headaches: Longitudinal Analysis.” British Med-
ical Journal 337:a2533.

Cohen-Zada, Danny and Todd Elder. 2009. “Historical Religious Concentrations and
the Effects of Catholic Schooling.” Journal of Urban Economics 66: 65–74.

Coleman,JamesS. 1961.The Adolescent Society: The Social Life of the Teenager and
Its Impact on Education. New York: Free Press.

—. 1964. Introduction to Mathematical Sociology. New York: Free Press.

—. 1981. Longitudinal Data Analysis. New York: Basic Books.

—. 1990. Foundations of Social Theory. Cambridge: Harvard University Press.

Coleman, JamesS. andThomasHoffer. 1987.Public and Private Schools: The Impact
of Communities. New York: Basic Books.

Coleman,JamesS.,ThomasHoffer,andSallyKilgore.1982.HighSchoolAchievement:
Public, Catholic, and Private Schools Compared. New York: Basic Books.

Collier, Andrew. 2005.“Philosophyand Critical Realism.” Pp. 327–45in The Politics
of Method in theHuman Sciences:Positivism andIts Epistemological Others,edited
by G. Steinmetz. Durham: Duke University Press.

Collins, John, Ned Hall, and L. A. Paul, Eds. 2004. Causation and Counterfactuals.

Cambridge: MIT Press.

Collins, Randall. 2004. Interaction Ritual Chains. Princeton: Princeton University
Press.

Cook, Michael D. and William N. Evans. 2000. “Families or Schools? Explaining the
Convergence in White and Black Academic Performance.” Journal of Labor Eco-
nomics 18:729–54.

Cook, Thomas D. and Donald T. Campbell. 1979. Quasi-Experimentation: Design &
Analysis Issues for Field Settings. Chicago: Rand McNally.

Cook, Thomas D., Peter M. Steiner, and Steffi Pohl. 2009. “How Bias Reduction Is
Affected by Covariate Choice, Unreliability, and Mode of Data Analysis: Results
from Two Types of Within-Study Comparisons.” Multivariate Behavioral Research
44:828–47.

Cox, David R. 1958. Planning of Experiments. New York: Wiley.

—. 1992. Planning of Experiments. New York: Wiley.

Cox, D. R. 2000. “Comment on ‘Causal Inference Without Counterfactuals’ by A. P.

Dawid.” Journal of the American Statistical Association 95:424–25.

Cox,DavidR.andNancy Reid.2000.The Theory of the Design of Experiments.Boca
Raton: Chapman & Hall/CRC.

Cox, David R. and Nanny Wermuth. 1996. Multivariate Dependencies: Models, Anal-
ysis and Interpretation. New York: Chapman Hall.

—. 2001. “Some Statistical Aspects of Causality.” European Sociological Review 17:
65–74.

Crain, RobertL. andRita E. Mahard. 1983.“The Effectof ResearchMethodologyon
Desegregation-Achievement Studies: A Meta-Analysis.” American Journal of Soci-
ology 88:839–54.

Craver, Carl F. 2007. Explaining the Brain: Mechanisms and the Mosaic Unity of
Neuroscience. Oxford: Oxford University Press.

Crump, Richard K., V. Joseph Hotz, Guido W. Imbens, and Oscar A. Mitnik. 2009.

“Dealing with Limited Overlap in Estimation of Average Treatment Effects.”
Biometrika 96:187–99.

Cunha, Flavio and James J. Heckman. 2007. “Identifying and Estimating the Dis-
tributions of Ex Post and Ex Ante Returns to Schooling.” Labour Economics 14:
870–93.

Cutright, Phillips. 1974. “The Civilian Earnings of White and Black Draftees and
Nonveterans.” American Sociological Review 39:317–27.

Davenport, Tiffany C., Alan S. Gerber, Donald P. Green, Christopher W. Larimer,
Christopher B. Mann, and Costas Panagopoulos. 2010. “The Enduring Effects of
Social Pressure:Tracking Campaign Experiments overa Series of Elections.” Polit-
ical Behavior 32:423–30.

Davis,Kingsley.1945.“TheWorldDemographicTransition.”Annals of the American
Academy of Political and Social Science 237:1–11.

Dawid, A. Philip. 2000. “Causal Inference Without Counterfactuals.” Journal of the
American Statistical Association 95:407–24.

—.2002.“InfluenceDiagramsforCausalModellingandInference.”International Sta-
tistical Review 70:161–89.

—. 2010. “Beware of the DAG!” Journal of Machine Learning Research 6:59–86.

—.2012.“TheDecision-TheoreticApproachtoCausalInference.”Pp.25–42inCausal-
ity: Statistical Perspectives and Applications, edited by C. Berzuini, P. Dawid, and
L. Bernardinelli. Hoboken: Wiley.

de Luna, Xavier, Ingeborg Waernbaum, and Thomas S. Richardson. 2011. “Covari-
ate Selection for the Nonparametric Estimation of an Average Treatment Effect.”
Biometrika 98:861–75.

De Tray, Dennis. 1982. “Veteran Status as a Screening Device.” American Economic
Review 72:133–42.

Deaton, Angus. 2010. “Instruments, Randomization, and Learning about Develop-
ment.” Journal of Economic Literature 48:424–55.

Dechter, Rina, Hector Geffner, and Joseph Y. Halpern, Eds. 2010. Heuristics, Proba-
bility, and Causality: A Tribute to Judea Pearl. London: College Publications.

Dehejia,RajeevH.andSadekWahba.1999.“CausalEffectsinNonexperimentalStud-
ies: Reevaluating the Evaluation of Training Programs.” Journal of the American
Statistical Association 94:1053–62.

Devlin, Bernie, Stephen E. Fienberg, Daniel P. Resnick, and Kathryn Roeder, Eds.

1997. Intelligence, Genes, and Success: Scientists Respond to the Bell Curve. New
York: Springer.

Diamond, Alexis and Jasjeet S. Sekhon. 2013. “Genetic Matching for Estimating
Causal Effects: A General Multivariate Matching Method for Achieving Balance
in Observational Studies.” Review of Economics and Statistics 95:932–45.

Dinkel, Robert M. 1952. “Occupation and Fertility in the United States.” American
Sociological Review 17:178–83.

DiPrete, Thomas A. and Markus Gangl. 2004. “Assessing Bias in the Estimation of
CausalEffects:RosenbaumBoundsonMatchingEstimatorsandInstrumentalVari-
ablesEstimationwithImperfectInstruments.”Sociological Methodology34:271–310.

Draper, Norman R. and Harry Smith. 1998. Applied Regression Analysis. New York:
Wiley.

Druckman, James N., James H. Kuklinski, and Arthur Lupia, Eds. 2011. Cambridge
Handbook of Experimental Political Science. Cambridge: Cambridge University
Press.

DuMouchel, William H. and Greg J. Duncan. 1983. “Using Sample Survey Weights
in Multiple Regression Analyses of Stratified Samples.” Journal of the American
Statistical Association 78:535–43.

Duncan,GregJ.2008.“WhentoPromote,andWhentoAvoid,aPopulationPerspec-
tive.” Demography 45:763–84.

Duncan,OtisDudley.1966.“PathAnalysis:SociologicalExamples.”AmericanJournal
of Sociology 72:1–16.

—. 1975. Introduction to Structural Equation Models. New York: Academic Press.

—. 1984. Notes on Social Measurement: Historical and Critical. New York: Russell
Sage Foundation.

Duncan,OtisDudley,DavidL.Featherman,andBeverlyDuncan.1972.Socioeconomic
Background and Achievement. New York: Seminar Press.

Duncan,OtisDudley,ArchibaldO.Haller,andAlejandroPortes.1968.“PeerInfluences
onAspirations:AReinterpretation.”AmericanJournalofSociology74:119–37.

Dunning, Thad. 2012. Natural Experiments in the Social Sciences: A Design-Based
Approach. Cambridge: Cambridge University Press.

Ehrenberg, Ronald G. 2004. “Econometric Studies of Higher Education.” Journal of
Econometrics 121:19–37
Elster,Jon. 1989.Nuts and Bolts for the Social Sciences. Cambridge:CambridgeUni-
versity Press.

—. 1998. “A Plea for Mechanisms.” Pp. 45–73 in Social Mechanisms: An Analytical
Approach to Social Theory, edited by P. Hedstro¨m and R. Swedberg. Cambridge:
Cambridge University Press.

Elwert, Felix. 2013. “Graphical Causal Models.” Pp. 245–73 in Handbook of Causal
Analysis for Social Research, edited by S. L. Morgan. Dordrecht: Springer.

Elwert,FelixandChristopherWinship.2010.“EffectHeterogeneityandBiasinMain-
Effects-OnlyRegressionModels.” Pp. 327–36inHeuristics, Probability and Causal-
ity: A Tribute to Judea Pearl, edited by R. Dechter, H. Geffner, and J. Y. Halpern.

London: College Publications.

—. 2014. “Endogenous Selection Bias: The Problem of Conditioning on a Collider
Variable.” Annual Review of Sociology 40:31–53.

Engelhardt, Henriette, Hans-Peter Kohler, and Alexia Prskawetz, Eds. 2009. Causal
AnalysisinPopulationStudies:Concepts,Methods,Applications.Dordrecht:Springer.

Evans, William and Robert M. Schwab. 1995. “Finishing High School and Starting
College: Do Catholic Schools Make a Difference?” Quarterly Journal of Economics
110:41–74.

Firebaugh, Glenn. 2008. Seven Rules for Social Research. Princeton: Princeton Uni-
versity Press.

Fiscella,Kevin,PeterFranks,MartheR.Gold,andCarolynM.Clancy.2000.“Inequal-
ity in Quality: Addressing Socioeconomic, Racial, and Ethnic Disparities in Health
Care.” Journal of the American Medical Association 283:2579–84.

Fisher, Ronald A. 1935. The Design of Experiments. Edinburgh: Oliver and Boyde.

Fligstein, Neil and Doug McAdam. 2012. A Theory of Fields. New York: Oxford Uni-
versity Press.

Fox, John. 1984. Linear Statistical Models and Related Methods: With Applications to
Social Research. New York: Wiley.

—. 2008. Applied Regression Analysis and Generalized Linear Models. Los Angeles:
Sage.

Frangakis, Constantine E. and Donald B. Rubin. 2002. “Principal Stratification in
Causal Inference.” Biometrics 58:21–29.

Frank, Kenneth A. 2000. “Impact of a Confounding Variable on the Inference of a
RegressionCoefficient.” Sociological Methods and Research 29:147–94.

Freedman, David A. 1983. “A Note on Screening Regression Equations.” American
Statistician 37:152–55.

—. 2005. Statistical Models: Theory and Practice. Cambridge: Cambridge University
Press.

—.2010.StatisticalModels and Causal Inference: A Dialogue with theSocial Sciences.

New York: Cambridge University Press.

Freedman,DavidA.andRichardA.Berk.2008.“WeightingRegressionsbyPropensity
Scores.” Evaluation Review 32:392–409.

Freedman, Ronald and Amos H. Hawley. 1949. “Unemployment and Migration in the
Depression.” Journal of the American Statistical Association 44:260–72.

Freese, Jeremy and J. Alex Kevern. 2013. “Types of Causes.” Pp. 27–41 in Hand-
book of Causal Analysis for Social Research, edited by S. L. Morgan. Dordrecht:
Springer.

Frumento,Paolo,FabriziaMealli,BarbaraPacini,andDonaldB.Rubin.2012.“Evalu-
atingtheEffectofTrainingonWagesinthePresenceofNoncompliance,Nonemploy-
ment, andMissingOutcomeData.”Journal of the American Statistical Association
107:450–66.

Fu,VincentKang,ChristopherWinship,andRobertD.Mare.2004.“SampleSelection
BiasModels.”Pp.409–30inHandbook of DataAnalysis,editedbyM.A.Hardyand
A. Bryman. Thousand Oaks: Sage.

Fuller,BruceandRichardF.Elmore.1996.Who Chooses? Who Loses? Culture, Insti-
tutions, and the Unequal Effects of School Choice. New York: Teachers College
Press.

Gangl, Markus. 2010. “Causal Inference in Sociological Research.” Annual Review of
Sociology 36:21–47.

—. 2013. “Partial Identification and Sensitivity Analysis.” Pp. 377–402 in Hand-
book of Causal Analysis for Social Research, edited by S. L. Morgan. Dordrecht:
Springer.

Garen, John. 1984. “The Returns to Schooling: A Selectivity Bias Approach with a
Continuous Choice Variable.” Econometrica 52:1199–218.

Garfinkel,Irwin,CharlesF.Manski,andC.Michalopoulos.1992.“MicroExperiments
andMacroEffects.”Pp.253–73inEvaluatingWelfareandTrainingPrograms,edited
by C. F. Manski and I. Garfinkel. Cambridge: Harvard University Press.

Gelman, Andrew and Jennifer Hill. 2007. Applied Regression and Multilevel/
Hierarchical Models. Cambridge: Cambridge University Press.

Gelman, Andrew and Gary King. 1990.“Estimating Incumbency Advantage Without
Bias.” American Journal of Political Science 34:1142–64.

Gelman,AndrewandXiao-LiMeng,Eds.2004.AppliedBayesian ModelingandCausal
Inference from Incomplete-Data Perspectives: An Essential Journey with Donald
Rubin’s Statistical Family. New York: Wiley.

Gennetian, Lisa A., Lisa Sanbonmatsu, Lawrence F. Katz, Jeffrey R. Kling, Matthew
Sciandra, Jens Ludwig et al. 2012. “The Long-TermEffects of Moving to Opportu-
nity on Youth Outcomes.” Cityscape 14:137–67.

Gerber,AlanS. andDonaldP.Green.2012.Field Experiments: Design, Analysis, and
Interpretation. New York: W. W. Norton.

Gerber, Alan S., Donald P. Green, and Christopher W. Larimer. 2008. “Social Pres-
sureandVoterTurnout:EvidencefromaLarge-ScaleFieldExperiment.”American
Political Science Review 102:33–48.

Gerring,John. 2007.Case Study Research: Principles and Practices. New York: Cam-
bridge University Press.

Glymour,Clark.1986.“Statistics andMetaphysics:CommentonHolland’s ‘Statistics
and Causal Inference.”’ Journal of the American Statistical Association 81:964–66.

Glymour,Clark,RichardScheines,andPeterSpirtes.2001.Causation,Prediction,and
Search, 2nd ed. Cambridge: MIT Press.

Godfrey-Smith,Peter.2003.Theory and Reality: An Introduction to the Philosophy of
Science. Chicago: University of Chicago Press.

Goertz, Gary. 2006. Social Science Concepts: A User’s Guide. Princeton: Princeton
University Press.

Goertz, Gary and James Mahoney. 2012. A Tale of Two Cultures: Qualitative and
QuantitativeResearchin the Social Sciences.Princeton:PrincetonUniversityPress.

Goldberger, Arthur S. 1972. “Structural Equation Methods in the Social Sciences.”
Econometrica 40:979–1001.

—. 1991. A Course in Econometrics. Cambridge: Harvard University Press.

Goldberger, Arthur S. and Glen G. Cain. 1982. “The Causal Analysis of Cognitive
Outcomes in the Coleman, Hoffer, and Kilgore Report.” Sociology of Education
55:103–22.

Goldin,ClaudiaandLawrenceF.Katz.2002.“ThePowerofthePill:OralContracep-
tives and Women’s Career and Marriage Decisions.” Journal of Political Economy
110:730–70.

Goldthorpe, JohnH. 2001.“Causation, Statistics, and Sociology.”European Sociolog-
ical Review 17:1–20.

—. 2007. On Sociology. 2 vols. Stanford: Stanford University Press.

Gorski, Philip S. 2004. “The Poverty of Deductivism: A Constructive Realist Model
of Sociological Explanation.” Sociological Methodology 34:1–33.

Greene, William H. 2000.Econometric Analysis. Upper Saddle River: Prentice-Hall.

Greenwood, Ernest. 1945. Experimental Sociology: A Study in Method. New York:
King’s Crown Press.

Greiner,D.JamesandDonaldB.Rubin.2011.“CausalEffectsofPerceivedImmutable
Characteristics.” Review of Economics and Statistics 93:775–85.

Gundersen,Craig,BrentKreider,andJohnPepper.2012.“TheImpactoftheNational
SchoolLunchProgramonChildHealth: ANonparametricBounds Analysis.”Jour-
nal of Econometrics 166:79–91.

Guo,ShenyangandMarkW.Fraser.2010.PropensityScoreAnalysis:StatisticalMeth-
ods and Applications. Thousand Oaks: Sage.

Haavelmo, Trygve. 1943. “The Statistical Implications of a System of Simultaneous
Equations.” Econometrica 11:1–12.

Hahn,Jinyong.1998.“OntheRoleofthePropensityScoreinEfficientSemiparametric
Estimation of Average Treatment Effects.” Econometrica 66:315–31.

Hahn, JinyongandJerryHausman.2003.“WeakInstruments:DiagnosisandCuresin
Empirical Economics.” American Economic Review 93:118–25.

Hahn, Jinyong, Petra Todd, and Wilbert Van der Klaauw. 2001. “Identification and
Estimation of Treatment Effects with a Regression-Discontinuity Design.” Econo-
metrica 69:201–9.

Hainmueller, Jens. 2012. “Entropy Balancing for Causal Effects: A Multivariate
ReweightingMethodtoProduceBalancedSamplesinObservationalStudies.”Polit-
ical Analysis 20:25–46.

Halaby, Charles N. 2004. “Panel Models in Sociological Research: Theory into Prac-
tice.” Annual Review of Sociology 30:507–44.

Hallinan, Maureen T. and Warren N. Kubitschek. 2012. “A Comparison of Academic
Achievement and Adherence to the Common School Ideal in Public and Catholic
Schools.” Sociology of Education 85:1–22.

Halloran, M. Elizabeth, Ira M. Longini, and Claudio J. Struchiner. 2010. Design and
Analysis of Vaccine Studies. New York: Springer.

Ham, John C., Xianghong Li, and Patricia B. Reagan. 2011. “Matching and Semi-
Parametric IV Estimation, a Distance-Based Measure of Migration, and the Wages
of Young Men.” Journal of Econometrics 161:208–27.

Hamilton, James D. 1994. Time Series Analysis. Princeton: Princeton University
Press.

Hanmer, Michael J., Won-Ho Park, Michael W. Traugott, Richard G. Niemi, Paul S.

Herrnson, Benjamin B. Bederson et al. 2010. “Losing Fewer Votes: The Impact of
Changing Voting Systems on Residual Votes.” Political Research Quarterly 63:129–
42.

Hansen, Ben B. 2004. “Full Matching in an Observational Study of Coaching for the
SAT.” Journal of the American Statistical Association 99:609–18.

—. 2008. “The Prognostic Analogue of the Propensity Score.” Biometrika 95:481–88.

Hansen, Ben B. and Jake Bowers. 2008. “Covariate Balance in Simple, Stratified and
Clustered Comparative Studies.” Statistical Science 23:219–36.

Hansen,BenB.,MarkFredrickson,andJoshBuckner.2013.“Optmatch:Functionsfor
Optimal Matching.” Software Routine for R, Department of Statistics, University
of Michigan, Ann Arbor, Michigan.

Harder, Valerie S., Elizabeth A. Stuart, and James C. Anthony. 2010. “Propensity
ScoreTechniquesandtheAssessmentofMeasuredCovariateBalancetoTestCausal
Associations in PsychologicalResearch.” Psychological Methods 15:234–49.

Harding,DavidJ.2003.“CounterfactualModelsofNeighborhoodEffects:TheEffectof
Neighborhood Povertyon Dropping Out and Teenage Pregnancy.”American Jour-
nal of Sociology 109:676–719.

Harding, David J., Lisa Gennetian, Christopher Winship, Lisa Sanbonmatsu, and
Jeffrey Kling. 2011. “Unpacking Neighborhood Influences on Education Outcomes:
Setting the Stage for Future Research.” Pp. 277–96 in Social Inequality and Edu-
cational Disadvantage, edited by G. Duncan and R. Murnane. New York: Russell
Sage.

Harding, David J. and Kristin Seefeldt. 2013. “Mixed Methods and Causal Analy-
sis.” Pp. 91–110 in Handbook of Causal Analysis for Social Research, edited by
S. L. Morgan. Dordrecht: Springer.

Hastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2001.The Elements of Sta-
tistical Learning: Data Mining, Inference, and Prediction. New York: Springer.

Hauser,PhilipM.1962.“OnStouffer’sSocialResearchtoTestIdeas.”Public Opinion
Quarterly 26:329–34.

Hauser, Robert M. and Arthur S. Goldberger. 1971.“The Treatment of Unobservable
Variables in Path Analysis.” Sociological Methodology 3:81–117.

Hauser, Robert M., John Robert Warren, Min-Hsiung Huang, and Wendy Y. Carter.

2000. “Occupational Status, Education, and Social Mobility in the Meritocracy.”
Pp. 179–229 in Meritocracy and Economic Inequality, edited by K. J. Arrow, S.

Bowles, and S. N. Durlauf. Princeton: Princeton University Press.

Hayashi, Fumio. 2000. Econometrics. Princeton: Princeton University Press.

Hayford,SarahR.andS.PhilipMorgan.2008.“ReligiosityandFertilityintheUnited
States: The Role of Fertility Intentions.” Social Forces 86:1163–88.

Heckman, JamesJ.1974.“ShadowPrices,MarketWages,andLaborSupply.” Econo-
metrica 42:679–94.

—.1978.“DummyEndogenousVariablesinaSimultaneousEquationSystem.”Econo-
metrica 46:931–59.

—. 1979. “Selection Bias as a Specification Error.” Econometrica 47:153–61.

—. 1989.“CausalInference and NonrandomSamples.” Journal of Educational Statis-
tics 14:159–68.

—. 1992. “Randomization and Social Policy Evaluation.” Pp. 201–30 in Evaluating
WelfareandTrainingPrograms,editedbyC.F.ManskiandI.Garfinkel.Cambridge:
Harvard University Press.

—. 1996. “Randomization as an Instrumental Variable.” Review of Economics and
Statistics 77:336–41.

—. 1997. “Instrumental Variables: A Study of Implicit Behavioral Assumptions Used
in Making ProgramEvaluations.” Journal of Human Resources 32:441–62.

—.2000.“CausalParametersandPolicyAnalysisinEconomics:ATwentiethCentury
Retrospective.” Quarterly Journal of Economics 115:45–97.

—. 2005. “The Scientific Model of Causality.” Sociological Methodology 35:1–97.

—. 2008a. “Econometric Causality.” International Statistical Review 76:1–27.

—. 2008b. “Schools, Skills, and Synapses.” Economic Inquiry 46:289–324.

—. 2011. “Building Bridges Between Structural and Program Evaluation
Approaches to Evaluating Policy.” Journal of Economic Literature 48:356–98.

Heckman, James J. and V. Joseph Hotz. 1989. “Choosing among Alternative Non-
experimental Methods for Estimating the Impact of Social Programs: The Case of
Manpower Training.” Journal of the American Statistical Association 84:862–74.

Heckman, James J., Hidehiko Ichimura, Jeffrey A. Smith, and Petra Todd. 1998.

“Characterizing Selection Bias Using Experimental Data.” Econometrica 66:
1017–98.

Heckman, James J., Hidehiko Ichimura, and Petra Todd. 1997. “Matching as an
Econometric Evaluation Estimator: Evidence from Evaluating a Job Training Pro-
gramme.” Review of Economic Studies 64:605–54.

—. 1998. “Matching as an Econometric Evaluation Estimator.” Review of Economic
Studies 65:261–94.

Heckman, James J., Robert J. LaLonde, and Jeffrey A. Smith. 1999.“The Economics
and Econometrics of Active Labor Market Programs.” Pp. 1865–2097 in Handbook
of Labor Economics, vol. 3, edited by O. C. Ashenfelter and D. Card. Amsterdam:
Elsevier.

Heckman, James J. and Richard Robb. 1985. “Alternative Methods for Evaluating
theImpactofInterventions.”Pp.156–245inLongitudinal Analysis of Labor Market
Data, edited by J. J. Heckman and B. Singer. Cambridge: Cambridge University
Press.

—.1986.“AlternativeMethodsforSolvingtheProblemofSelectionBiasinEvaluating
the Impact of Treatments on Outcomes.” Pp. 63–113 in Drawing Inferences from
Self-Selected Samples, edited by H. Wainer. New York: Springer.

—. 1989. “The Value of Longitudinal Data for Solving the Problem of Selection Bias
inEvaluatingtheImpactofTreatmentonOutcomes.”Pp.512–38inPanel Surveys,
edited by D. Kasprzyk, G. Duncan, G. Kalton, and M. P. Singh. New York: Wiley.

Heckman,James J., Jeffrey Smith, andNancy Clements. 1997.“Makingthe Mostout
of Programme Evaluations and Social Experiments: Accounting for Heterogeneity
in Programme Impacts.” Review of Economic Studies 64:487–535.

Heckman, James J., Justin L. Tobias, and EdwardJ. Vytlacil. 2003. “Simple Estima-
tors for Treatment Parameters in a Latent-Variable Framework.” Review of Eco-
nomics and Statistics 85:748–55.

Heckman, James J. and Sergio Urzua. 2010. “Comparing IV with Structural Models:
What Simple IV Can and Cannot Identify.” Journal of Econometrics 156:27–37.

Heckman, James J., Sergio Urzua, and Edward J. Vytlacil. 2006. “Understanding
Instrumental Variables in Models with Essential Heterogeneity.” Review of Eco-
nomics and Statistics 88:389–432.

Heckman, James J. and Edward J. Vytlacil. 1999. “Local Instrumental Variables and
LatentVariableModelsforIdentifyingandBoundingTreatmentEffects.”Proceedings
oftheNationalAcademyofSciencesoftheUnitedStatesofAmerica96:4730–34.

—. 2000. “The Relationship between Treatment Parameterswithin a Latent Variable
Framework.” Economics Letters 66:33–39.

—. 2005. “Structural Equations, Treatment Effects, and Econometric Policy Evalua-
tion.” Econometrica 73:669–738.

—. 2007. “Econometric Evaluation of Social Programs, Part I: Causal Models, Struc-
tural Models and Econometric Policy Evaluation.” Pp. 4779–874 in Handbook of
Econometrics, vol. 6, part b, edited by J. J. Heckman and E. E. Leamer. Amster-
dam: Elsevier.

Hedstr¨om,Peter.2005.DissectingtheSocial:OnthePrinciples ofAnalyticalSociology.

Cambridge: Cambridge University Press.

Hedstr¨om, Peter and Peter Bearman, Eds. 2009. The Oxford Handbook of Analytical
Sociology. Oxford: Oxford University Press.

Hedstr¨om,PeterandRichardSwedberg,Eds.1998.Social Mechanisms: An Analytical
Approach to Social Theory. Cambridge: Cambridge University Press.

Hedstr¨om, Peter and Lars Udehn. 2009. “Analytical Sociology and Theories of the
Middle Range.” Pp. 25–47 in The Oxford Handbook of Analytical Sociology, edited
by P. Hedstro¨m and P. Bearman. Oxford: Oxford University Press.

Hedstr¨om,PeterandPetriYlikoski.2010.“CausalMechanismsintheSocialSciences.”
Annual Review of Sociology 36:49–67.

Heller, Ruth, Paul R. Rosenbaum, and Dylan S. Small. 2010. “Using the Cross-
MatchTesttoAppraiseCovariateBalanceinMatchedPairs.”AmericanStatistician
64:299–309.

Henderson,JohnandSaraChatfield.2011.“WhoMatches?PropensityScoresandBias
in the CausalEffects ofEducationonParticipation.”Journal of Politics 73:646–58.

Hendry, David F. 1995. Dynamic Econometrics. Oxford: Oxford University Press.

Henig,JeffreyR.2008.Spin Cycle: HowResearch Is Usedin Policy Debates:The Case
of Charter Schools. New York: Russell Sage.

Hern´an, Miguel A. 2005. “Invited Commentary: Hypothetical Interventions to Define
Causal Effects – Afterthought or Prerequisite?” American Journal of Epidemiology
162:618–20.

Hern´an,MiguelA., SoniaHernandez-Diaz,andJamesM. Robins.2004.“AStructural
Approach to Selection Bias.” Epidemiology 15:615–25.

Hern´an, Miguel A. and James M. Robins. 2006a. “Estimating Causal Effects from
EpidemiologicalData.” Journal of Epidemiology and Community Health 60:578–86.

—. 2006b.“Instruments for Causal Inference: An Epidemiologist’sDream?” Epidemi-
ology 17:360–72.

Herrnstein, RichardJ. andCharlesA. Murray.1994.The Bell Curve: Intelligence and
Class Structure in American Life. New York: Free Press.

Herron, Michael C. and Jasjeet S. Sekhon. 2003. “Overvoting and Representation:
An Examination of Overvoted Presidential Ballots in Broward and Miami-Dade
Counties.” Electoral Studies 22:21–47.

Highton, Benjamin. 2009. “Revisiting the Relationship between Educational Attain-
ment and Political Sophistication.” Journal of Politics 71:1564–76.

Hill, Jennifer and Jerome P. Reiter. 2006. “Interval Estimation for Treatment Effects
Using Propensity Score Matching.” Statistics in Medicine 25:2230–56.

Hill, Jennifer, Christopher Weiss, and Fuhua Zhai. 2011. “Challenges with Propen-
sity Score Strategies in a High-Dimensional Setting and a Potential Alternative.”
Multivariate Behavioral Research 46:477–513.

Hill,JenniferL.2011.“BayesianNonparametricModelingforCausalInference.”Jour-
nal of Computational and Graphical Statistics 20:217–40.

Hirano, Keisuke and Guido W. Imbens. 2001. “Estimation of Causal Effects Using
Propensity Score Weighting: An Application to Data on Right Heart Catheteriza-
tion.” Health Services & Outcomes Research Methodology 2:259–78.

—. 2004. “The Propensity Score with Continuous Treatments.” Pp. 73–84 in Applied
Bayesian Modeling and Causal Inference from Incomplete-Data Perspectives: An
Essential Journey with Donald Rubin’s Statistical Family, edited by A. Gelmanand
X.-L. Meng. New York: Wiley.

Hirano, Keisuke, Guido W. Imbens, and Geert Ridder. 2003. “Efficient Estimation of
Average Treatment Effects Using the Estimated Propensity Score.” Econometrica
71:1161–89.

Hitchcock, Christopher. 2007. “What’s Wrong with Neuron Diagrams?” Pp. 69–92
in Causation and Explanation, edited by J. K. Campbell, M. O’Rourke, and H.

Silverstein. Cambridge: MIT Press.

Ho, Daniel, Kosuke Imai, Gary King, and Elizabeth Stuart. 2011. “MatchIt: Non-
parametric Preprocessing for Parametric Causal Inference.” Software Routine for
R, Department of Government, Harvard University, Cambridge, Massachusetts.

Ho, Daniel E., Kosuke Imai, Gary King, and Elizabeth A. Stuart. 2007.“Matching as
NonparametricPreprocessingforReducingModelDependenceinParametricCausal
Inference.” Political Analysis 15:199–236.

Hodge,RobertW.andNaohiroOgawa.1991.FertilityChangeinContemporaryJapan.

Chicago: University of Chicago Press.

Hoffer, Thomas, Andrew M. Greeley, and James S. Coleman. 1985. “Achievement
Growth in Public and Catholic Schools.” Sociology of Education 58:74–97.

Holland, Paul W. 1986. “Statistics and Causal Inference.” Journal of the American
Statistical Association 81:945–70.

—. 2008. “Causation and Race.” Pp. 93–109 in White Logic, White Methods: Racism
and Methodology, edited by T. Zuberi and E. Bonilla-Silva. Lanham: Rowman and
Littlefield.

Holmlund,Helena,MikaelLindahl,andErikPlug.2011.“TheCausalEffectofParents’
SchoolingonChildren’sSchooling: AComparisonofEstimationMethods.” Journal
of Economic Literature 49:615–51.

Hong,Guanglei.2010.“MarginalMeanWeightingThroughStratification:Adjustment
forSelectionBiasinMultilevelData.”JournalofEducationalandBehavioral Statis-
tics 35:499–531.

—. 2012. “Marginal Mean Weighting Through Stratification: A Generalized
MethodforEvaluatingMultivaluedandMultipleTreatmentswithNonexperimental
Data.” Psychological Methods 17:44–60.

Hong,GuangleiandStephenW.Raudenbush.2006.“EvaluatingKindergartenReten-
tion Policy: A Case Study of Causal Inference for Multilevel Observational Data.”
Journal of the American Statistical Association 101:901–10.

—.2013.“HeterogeneousAgents,SocialInteractions,andCausalInference.”Pp.331–
52 in Handbook of Causal Analysis for Social Research, edited by S. L. Morgan.

Dordrecht: Springer.

Honor´e,BoE.andJamesL.Powell.1994.“PairwiseDifferenceEstimatorsofCensored
and Truncated Regression Models.” Journal of Econometrics 64:241–78.

Hood, William C. and Tjalling C. Koopmans, Eds. 1953. Studies in Econometric
Method. New York: Wiley.

Hout,Michael.2012.“SocialandEconomicReturnstoCollegeEducationintheUnited
States.” Annual Review of Sociology 38:379–400.

Howell, William G. and Paul E. Peterson. 2002. The Education Gap: Vouchers and
Urban Schools. Washington, DC: Brookings Institution.

Hoxby, Caroline M. 1996. “The Effects of Private School Vouchers on Schools and
Students.”Pp.177–208inHoldingSchools Accountable:Performance-Based Reform
in Education, edited by H. F. Ladd. Washington, DC: Brookings Institution.

Hoxby, Caroline M, Ed. 2003. The Economics of School Choice. Chicago: University
of Chicago Press.

—,Ed.2004.College Choices: The Economics of Where to Go, When to Go, and How
to Pay for It. Chicago: University of Chicago Press.

Hoxby, Caroline M., Sonali Murarka, and Jenny Kang. 2009. “How New York City’s
CharterSchoolsAffectAchievement.”NationalBureauofEconomicResearch,Cam-
bridge, Massachusetts.

Hsiao,Cheng. 2003.Analysis of Panel Data. Cambridge:CambridgeUniversityPress.

Hudgens,MichaelG.andM.ElizabethHalloran.2008.“TowardCausalInferencewith
Interference.” Journal of the American Statistical Association 103:832–42.

Hume, David.1977[1772].An Enquiry Concerning Human Understanding. Indianapo-
lis: Hackett.

Humphreys,Paul.1989.TheChancesofExplanation:CausalExplanationintheSocial,
Medical, and Physical Sciences. Princeton: Princeton University Press.

—. 2004. Extending Ourselves: Computational Science, Empiricism, and Scientific
Method. New York: Oxford University Press.

Hyman,Herbert.1955.SurveyDesign andAnalysis:Principles, Cases andProcedures.

Glencoe: Free Press.

Hyman, Herbert H. 1962. “Samuel A. Stouffer and Social Research.” Public Opinion
Quarterly 26:323–28.

Iacus, Stefano M. and Gary King. 2012. “How Coarsening Simplifies Matching-Based
Causal Inference Theory.” Department of Economics, Business and Statistics, Uni-
versity of Milan, Milan, Italy.

Iacus, Stefano M., Gary King, and Giuseppe Porro. 2011. “Multivariate Matching
Methods That Are Monotonic Imbalance Bounding.” Journal of the American Sta-
tistical Association 106:345–61.

—.2012a.“CausalInferenceWithoutBalanceChecking:CoarsenedExactMatching.”
Political Analysis 20:1–24.

—. 2012b. “CEM: Coarsened Exact Matching Software.” Software Routine for Stata,
Department of Government, Harvard University, Cambridge, Massachusetts.

Imai,Kosuke,GaryKing,andElizabethA.Stuart.2008.“Misunderstandingsbetween
Experimentalists and Observationalists about Causal Inference.” Journal of the
Royal Statistical Society 171:481–502.

Imai,KosukeandMarcRatkovic.2014.“CovariateBalancingPropensityScore.”Jour-
nal of the Royal Statistical Society, Series B 76:243–63.

Imai,KosukeandDavidA.vanDyk.2004.“CausalInferencewithGeneralTreatment
Regimes: Generalizing the Propensity Score.” Journal of the American Statistical
Association 99:854–66.

Imbens, Guido W. 2000. “The Role of the Propensity Score in Estimating Dose-
Response Functions.” Biometrika 87:706–10.

—.2004.“NonparametricEstimationofAverageTreatmentEffectsunderExogeneity:
A Review.” Review of Economics and Statistics 86:4–29.

—. 2010.“BetterLATE ThanNothing: Some Comments onDeaton(2009)andHeck-
man and Urzua (2009).” Journal of Economic Literature 48:399–423.

Imbens, Guido W. and Joshua D. Angrist. 1994. “Identification and Estimation of
Local Average Treatment Effects.” Econometrica 62:467–75.

Imbens, Guido W. and Thomas Lemieux. 2008. “RegressionDiscontinuity Designs: A
Guide to Practice.” Journal of Econometrics 142:1–21.

Imbens, Guido W. and Donald B. Rubin. 1997. “Estimating Outcome Distributions
for Compliers in Instrumental Variables Models.” Review of Economic Studies 64:
555–74.

Imbens, Guido W. and Jeffrey M. Wooldridge. 2009. “Recent Developments in the
Econometrics of ProgramEvaluation.” Journal of Economic Literature 47:5–86.

Jackson, Michelle V. 2013. Determined to Succeed? Performance versus Choice in
Educational Attainment. Stanford: Stanford University Press.

Jencks,ChristopherS.andSusanE.Mayer.1990.“TheSocialConsequencesofGrow-
ing Up in a Poor Neighborhood.” Pp. 111–86 in Inner-City Poverty in the United
States, edited by L. E. Lynn and M. G. H. McGeary. Washington, D.C.: National
Academy Press.

Jepsen,Christopher.2003.“TheEffectivenessofCatholicPrimarySchooling.”Journal
of Human Resources 38:928–41.

Jin, Hui, John Barnard, and Donald B. Rubin. 2010. “A Modified General Location
Model for Noncompliance with Missing Data: Revisiting the New York City School
ChoiceScholarshipProgramUsingPrincipalStratification.”Journal of Educational
and Behavioral Statistics 35:154–73.

Jin, Hui and Donald B. Rubin. 2009. “Public Schools versus Private Schools: Causal
Inference with Partial Compliance.” Journal of Educational and Behavioral Statis-
tics 34:24–45.

Joffe, Marshall M. 2011. “Principal Stratification and Attribution Prohibition: Good
Ideas Taken Too Far.” International Journal of Biostatistics 7:1–22.

Joffe, Marshall M. and Paul R. Rosenbaum. 1999. “Propensity Scores.” American
Journal of Epidemiology 150:327–31.

Judd, Charles M. and David A. Kenny. 1981. Estimating the Effects of Social Inter-
ventions. New York: Cambridge University Press.

Kam, Cindy D. andCarlL. Palmer.2008.“Reconsideringthe Effects ofEducationon
Political Participation.” Journal of Politics 70:612–31.

—. 2011.“Rejoinder:Reinvestigatingthe CausalRelationshipbetweenHigher Educa-
tion and Political Participation.” Journal of Politics 73:659–63.

Karpinos, Bernard D. 1938. “The Differential True Rates of Growth of the White
Populationin the United States andTheir ProbableEffects onthe GeneralGrowth
of the Population.” American Journal of Sociology 44:251–73.

Keane, Michael P. 2010. “A Structural Perspective on the Experimentalist School.”
Journal of Economic Perspectives 24:47–58.

Kempthorne, Oscar. 1948. “Review of Experimental Designs in Sociological Research
by F. Stuart Chapin.” Journal of the American Statistical Association 43:489–92.

—. 1952. The Design and Analysis of Experiments. New York: Wiley.

Kemptner, Daniel, Hendrik Ju¨rges, and Steffen Reinhold. 2011. “Changes in Com-
pulsory Schooling and the Causal Effect of Education on Health: Evidence from
Germany.” Journal of Health Economics 30:340–54.

Kendall, Patricia L. and Paul F. Lazarsfeld. 1950. “Problems of Survey Analysis.”
Pp. 133–96 in Continuities in Social Research: Studies in the Scope and Method of
“The American Soldier,” edited by R. K. Merton and P. F. Lazarsfeld. Glencoe:
Free Press.

Kennedy, David M. 1997. “Pulling Levers: Chronic Offenders, High-Crime Settings,
and a Theory of Prevention.” Valparaiso University Law Review 31:449–84.

Keyfitz, Nathan. 1948. “Review of Experimental Designs in Sociological Research by
F. Stuart Chapin.” American Journal of Sociology 54:259–60.

King, Gary, Robert O. Keohane, and Sidney Verba. 1994. Designing Social Inquiry:
Scientific Inference in Qualitative Research. Princeton: Princeton University Press.

Kish, Leslie. 1965. Survey Sampling. New York: Wiley.

—. 1987. Statistical Design for Research. New York: Wiley.

Kling, Jeffrey R., Jeffrey B. Liebman, and Lawrence F. Katz. 2007. “Experimental
Analysis of Neighborhood Effects.” Econometrica 75:83–119.

Kling,JeffreyR.,JensLudwig,andLawrenceF.Katz.2005.“NeighborhoodEffectson
Crime for Female and Male Youth: Evidence from a Randomized Housing Voucher
Experiment.” Quarterly Journal of Economics 120:87–130.

Knight,CarlyR.andChristopherWinship.2013.“TheCausalImplicationsofMecha-
nistic Thinking: IdentificationUsing DirectedAcyclic Graphs(DAGs).” Pp. 275–99
in Handbook of Causal Analysis for Social Research, edited by S. L. Morgan. Dor-
drecht: Springer.

Koller, Daphne and Nir Friedman. 2009. Probabilistic Graphical Models: Principles
and Techniques. Cambridge: MIT Press.

Koopmans,TjallingC.andOlavReiersøl.1950.“TheIdentificationofStructuralChar-
acteristics.” Annals of Mathematical Statistics 21:165–81.

Krasno, Jonathan S. and Donald P. Green. 2008. “Do Televised Presidential Ads
Increase Voter Turnout? Evidence from a Natural Experiment.” Journal of Poli-
tics 70:245–61.

Krueger, Alan B. and Pei Zhu. 2004. “Another Look at the New York City School
Voucher Experiment.” American Behavioral Scientist 47:658–98.

Krueger, Thomas M. and William F. Kennedy. 1990. “An Examination of the Super
Bowl Stock Market Predictor.” Journal of Finance 45:691–97.

Ladd, Helen F. 2002. “School Vouchers: A Critical View.” Journal of Economic Per-
spectives 16:3–24.

LaLonde, Robert J. 1986. “Evaluating the Econometric Evaluations of Training Pro-
grams with Experimental Data.” American Economic Review 76:604–20.

—. 1995. “The Promise of Public Sector-Sponsored Training Programs.” Journal of
Economic Perspectives 9:149–68.

Lauritzen, Steffen L. 1996. Graphical Models. Oxford: Clarendon.

Lazarsfeld,PaulF.,BernardBerelson,andHazelGaudet. 1955[1948].“PoliticalInter-
estandVoting Behavior.”Pp. 155–8in The Language of Social Research: A Reader
in the Methodology of Social Research,editedbyP.F.LazarsfeldandM.Rosenberg.

Glencoe: Free Press.

Leamer, Edward E. 1978. Specification Searches: Ad Hoc Inference with Nonexperi-
mental Data. New York: Wiley.

—. 1983. “Let’s Take the Con Out of Econometrics.” American Economic Review
73:31–43.

—. 2010. “Tantalus on the Road to Asymptopia.” Journal of Economic Perspectives
24:31–46.

Lechner, Michael. 2002a. “Program Heterogeneity and Propensity Score Matching:
An Application to the Evaluationof Active LaborMarketPolicies.”Review of Eco-
nomics and Statistics 84:205–20.

—. 2002b. “Some Practical Issues in the Evaluation of Heterogeneous Labour Market
ProgrammesbyMatchingMethods.”Journal of Royal Statistical Society165:59–82.

Lee, Brian K., Justin Lessler, and Elizabeth A. Stuart. 2009. “Improving Propensity
Score Weighting Using Machine Learning.” Statistics in Medicine 29:337–46.

—. 2011. “Weight Trimming and Propensity Score Weighting.” PLoS ONE
6:e18174.

Lee,Myoung-jae.2005.Micro-EconometricsforPolicy,Program,andTreatmentEffects.

Oxford: Oxford University Press.

Lee, Ronald. 2003. “The Demographic Transition: Three Centuries of Fundamental
Change.” Journal of Economic Perspectives 17:167–90.

Leuven, Edwin and Barbara Sianesi. 2012. “PSMATCH2: Stata Module to Perform
Full Mahalanobis and Propensity Score Matching, Common Support Graphing,
and CovariateImbalance Testing.” SoftwareRoutine for Stata, Departmentof Eco-
nomics, Boston College, Boston, Massachusetts.

Levy, Paul S., Stanley Lemeshow, Paul P. Biemer, and SharonL. Christ. 2008. “Con-
structing Survey Weights.” Pp. 489–516 in Sampling of Populations: Methods and
Applications. Hoboken: Wiley.

Lewis, David. 1973. “Causation.” Journal of Philosophy 70:556–67.

Lieberson, Stanley. 1985. Making It Count: The Improvement of Social Research and
Theory. Berkeley: University of California Press.

Lieberson, Stanley and Freda B. Lynn. 2002. “Barking Up the Wrong Branch: Scien-
tific Alternatives to the Current Model of Sociological Science.” Annual Review of
Sociology 28:1–19.

Lindahl,Mikael.2005.“EstimatingtheEffectofIncomeonHealthandMortalityUsing
Lottery Prizes as an Exogenous Source of Variation in Income.” Journal of Human
Resources 40:144–68.

Link, Bruce G. and JoC. Phelan. 1995.“Social Conditions as Fundamental Causes of
Disease.” Journal of Health and Social Behavior 35:80–94.

Little, Roderick J. A. 1982. “Models for Nonresponse in Sample Surveys.” Journal of
the American Statistical Association 77:237–50.

Little, Roderick J. A. and Donald B. Rubin. 2002. Statistical Analysis with Missing
Data. Hoboken: Wiley.

Long, J. Scott. 1997. Regression Models for Categorical and Limited Dependent Vari-
ables. Thousand Oaks: Sage Publications.

Long, J. Scott and Laurie H. Ervin. 2000. “Using Heteroscedasticity Consistent Stan-
dard Errors in the Linear Regression Model.” American Statistician 54:217–24.

Lu, Bo, Elaine Zanutto, Robert Hornik, and Paul R. Rosenbaum. 2001. “Matching
with Doses in an Observational Study of a Media Campaign Against Drug Abuse.”
Journal of the American Statistical Association 96:1245–53.

Lubienski, Sarah T. and Christopher Lubienski. 2003. “School Sector and Academic
Achievement: A Multilevel Analysis of NAEP Mathematics Data.” American Edu-
cational Research Journal 43:651–98.

Lumley,ThomasandAchimZeileis.2013.“Sandwich:RobustCovarianceMatrixEsti-
mators.” Software Routine for R, Department of Statistics, University of Washing-
ton, Seattle, Washington.

Lutfey,KarenandJeremyFreese.2005.“TowardSomeFundamentalsofFundamental
Causality: Socioeconomic Status and Health in the Routine Clinic Visit for Dia-
betes.” American Journal of Sociology 110:1326–72.

Machamer,Peter,Lindley Darden,andCarlF. Craver.2000.“ThinkingAbout Mech-
anisms.” Philosophy of Science 67:1–25.

Machin,Stephen,OlivierMarie,andSunˇcicaVuji´c.2011.“TheCrimeReducingEffect
of Education.” Economic Journal 121:463–84.

MacKinnon, DavidP. 2008.Introduction to Statistical Mediation Analysis. New York:
Lawrence Erlbaum.

Manski,CharlesF.1994.“TheSelectionProblem.”Pp.143–70in Advances in Econo-
metrics: Sixth World Congress, vol.1,editedbyC.A.Sims.Cambridge:Cambridge
University Press.

—. 1995. Identification Problems in the Social Sciences. Cambridge: Harvard Univer-
sity Press.

—. 1997. “Monotone Treatment Response.” Econometrica 65:1311–34.

—.1999.“Commenton‘ChoiceasanAlternativetoControlinObservationalStudies’
by Rosenbaum.” Statistical Science 14:279–81.

—. 2003. Partial Identification of Probability Distributions. New York: Springer.

—.2013a.“IdentificationofTreatmentResponsewithSocialInteractions.”Economet-
rics Journal 16:S1–S23.

—. 2013b. Public Policy in an Uncertain World: Analysis and Decisions. Cambridge:
Harvard University Press.

Manski, Charles F. and Irwin Garfinkel, Eds. 1992. Evaluating Welfare and Training
Programs. Cambridge: Harvard University Press.

Manski,CharlesF.andDanielS.Nagin.1998.“BoundingDisagreementsaboutTreat-
mentEffects:ACaseStudyofSentencingandRecidivism.”Sociological Methodology
28:99–137.

Manski, Charles F. and John V. Pepper. 2000. “Monotone Instrumental Variables:
With an Application to the Returns to Schooling.” Econometrica 68:997–1010.

—. 2013. “Deterrence and the Death Penalty: Partial Identification Analysis Using
Repeated Cross Sections.” Journal of Quantitative Criminology 29:123–41.

Manski, Charles F., Gary D. Sandefur, Sara McLanahan, and Daniel Powers. 1992.

“AlternativeEstimatesoftheEffectofFamilyStructureDuringAdolescenceonHigh
School Graduation.” Journal of the American Statistical Association 87:25–37.

Manza, Jeff and Christopher Uggen. 2004. “Punishment and Democracy: Disenfran-
chisementofNonincarceratedFelons inthe United States.” Perspectives on Politics
2:491–505.

Manzo, Gianluca. 2011. “Relative Deprivation in Silico: Agent-Based Models and
Causality in Analytical Sociology.” Pp. 266–308 in Analytical Sociology and Social
Mechanisms, edited by P. Demeulenaere. Cambridge: Cambridge University Press.

Marcantonio,RichardJ.andThomasD.Cook.1994.“ConvincingQuasi-Experiments:
The Interrupted Time Series and Regression-DiscontinuityDesigns.” Pp. 133–54in
Handbook of Practical Program Evaluation,editedbyJ.S.Wholey,H.P.Hatry,and
K. E. Newcomer. San Francisco: Jossey-Bass.

Marini, Margaret M. and Burton Singer. 1988. “Causality in the Social Sciences.”
Sociological Methodology 18:347–409.

Mark, Melvin M. and Steven Mellor. 1991. “Effect of Self-Relevance of an Event
on Hindsight Bias: The Foreseeability of a Layoff.” Journal of Applied Psychology
76:569–77.

Martin, John Levi. 2011. The Explanation of Social Action. New York: Oxford Uni-
versity Press.

Mayer, Albert J. and Sue Marx. 1957. “Social Change, Religion, and Birth Rates.”
American Journal of Sociology 62:383–90.

Mayer,AlexanderK.2011.“DoesEducationIncreasePoliticalParticipation?”Journal
of Politics 73:633–45.

McCaffrey,DanielF.,GregRidgeway,andAndrewR.Morral.2004.“PropensityScore
Estimationwith BoostedRegressionfor Evaluating CausalEffects in Observational
Studies.” Psychological Methods 9:403–25.

McDowall,David,RichardMcCleary,ErrolE.Meidinger,andRichardAHayJr.1980.

Interrupted Time Series Analysis. Beverly Hills: Sage.

McLanahan, Sara. 2004. “Diverging Destinies: How Children Are Faring under the
Second Demographic Transition.” Demography 41:607–27.

—.2009.“FragileFamiliesandthe ReproductionofPoverty.”Annals of the American
Academy of Political and Social Science 621:111–31.

McLanahan, Sara and Christine Percheski. 2008. “Family Structure and the Repro-
duction of Inequalities.” Annual Review of Sociology 34:257–76.

McLanahan, Sara and Gary D. Sandefur. 1994. Growing Up with a Single Parent:
What Hurts, What Helps. Cambridge: Harvard University Press.

McLanahan, Sara, Laura Tach, and Daniel Schneider. 2013. “The Causal Effects of
Father Absence.” Annual Review of Sociology 39:399–427.

Mebane, Walter R. 2004. “The Wrong Man Is President! Overvotes in the 2000 Pres-
idential Election in Florida.” Perspectives on Politics 2:525–35.

Merton, Robert K. 1968. “The Matthew Effect in Science.” Science 159:56–63.

Messner, Steven F., Eric P. Baumer, and Richard Rosenfeld. 2004. “Dimensions of
Social Capital and Rates of Criminal Homicide.” American Sociological Review
69:882–903.

Moffitt,Robert.2005.“RemarksontheAnalysisofCausalRelationshipsinPopulation
Research.” Demography 42:91–108.

Moffitt, Robert A. 1996. “Comment on ‘Identification of Causal Effects Using Instru-
mental Variables’by Angrist, Imbens, andRubin.” Journal of the American Statis-
tical Association 91:462–65.

—.2003.“CausalAnalysisinPopulationResearch:AnEconomist’sPerspective.”Pop-
ulation and Development Review 29:448–58.

Morgan, Stephen L. 2001. “Counterfactuals, Causal Effect Heterogeneity, and the
Catholic School Effect on Learning.” Sociology of Education 74:341–74.

—.2005.OntheEdgeofCommitment:EducationalAttainmentandRaceintheUnited
States. Stanford: Stanford University Press.

—, Ed. 2013. Handbook of Causal Analysis for Social Research. Dordrecht:
Springer.

Morgan, Stephen L. and David J. Harding. 2006. “Matching Estimators of Causal
Effects: Prospects and Pitfalls in Theory and Practice.” Sociological Methods and
Research 35:3–60.

Morgan, Stephen L., Theodore S. Leenman, Jennifer J. Todd, and Kim A. Weeden.

2013. “Occupational Plans, Beliefs about Educational Requirements, and Patterns
of College Entry.” Sociology of Education 86:197–217.

Morgan,StephenL.andJenniferJ.Todd. 2008.“ADiagnosticRoutine fortheDetec-
tion of Consequential Heterogeneity of Causal Effects.” Sociological Methodology
38:231–81.

Morgan,Stephen L. and ChristopherWinship. 2012.“BringingContext and Variabil-
ityBackintoCausalAnalysis.”Pp.319–54inTheOxfordHandbookofPhilosophy of
Social Science, edited by H. Kincaid. Oxford: Oxford University
Press.

Morgan, S. Philip and Ronald R. Rindfuss. 1999. “Reexamining the Link of Early
Childbearing to Marriage and to Subsequent Fertility.” Demography 36:59–75.

Morton, Rebecca B. and Kenneth C. Williams. 2010. Experimental Political Science
and the Study of Causality: From Nature to the Lab. Cambridge: Cambridge Uni-
versity Press.

Mumford, Stephen and Rani L. Anjum. 2011. Getting Causes from Powers. Oxford:
Oxford University Press.

Murnane, Richard J., Stephen E. Newstead, and Randall J. Olsen. 1985. “Compar-
ing Public and Private Schools: The Puzzling Role of Selectivity Bias.” Journal of
Business and Economic Statistics 3:23–35.

Murnane, Richard J. and John B. Willett. 2011. Methods Matter: Improving Causal
Inference in Educational and Social Science Research. Oxford: Oxford University
Press.

Musick,Kelly.2002.“PlannedandUnplannedChildbearingamongUnmarriedWomen.”
Journal of Marriage and Family 64:915–29.

Musick,Kelly,PaulaEngland,SarahEdgington,andNicoleKangas.2009.“Education
Differences in Intended and Unintended Fertility.” Social Forces 88:543–72.

Neal, Derek. 1997. “The Effects of Catholic Secondary Schooling on Educational
Achievement.” Journal of Labor Economics 14:98–123.

—. 2002. “How Vouchers Could Change the Market for Education.” Journal of Eco-
nomic Perspectives 16:25–44.

Neyman, Jerzy Splawa. 1935. “Statistical Problems in Agricultural Experimentation
(with Discussion).” Journal of the Royal Statistical Society, Series B 2:107–80.

—. 1990[1923]. “On the Application of Probability Theory to Agricultural Experi-
ments. Essay on Principles. Section 9.” Statistical Science 5:465–80.

N´ı Bhrolch´ain, M´aire and Tim Dyson. 2007. “On Causation in Demography: Issues
and Illustrations.” Population and Development Review 33:1–36.

Nie, Norman H., Jane Junn, and Kenneth Stehlik-Barry. 1996. Education and Demo-
cratic Citizenship in America. Chicago: University of Chicago Press.

Noell, Jay. 1982. “Public and Catholic Schools: A Reanalysis of ‘Public and Private
Schools.”’ Sociology of Education 55:123–32.

Notestein,FrankW.1933.“TheDifferentialRateofIncreaseamongtheSocialClasses
of the American Population.” Social Forces 12:17–33.

—. 1950. “The Population of the World in the Year 2000.” Journal of the American
Statistical Association 45:335–45.

Oreopoulos,Philip.2006.“EstimatingAverageandLocalAverageTreatmentEffectsof
EducationWhen Compulsory Schooling Laws Really Matter.” American Economic
Review 96:152–75.

Pagan,AdrianandAmanUllah.1999.Nonparametric Econometrics.NewYork:Cam-
bridge University Press.

Pampel, Fred C., Patrick M. Krueger, and Justin T. Denney. 2010. “Socioeconomic
Disparities in Health Behaviors.” Annual Review of Sociology 36:349–70.

Parsons, Talcott. 1937. The Structure of Social Action. New York: McGraw-Hill.

—. 1951. The Social System. Glencoe: Free Press.

Paul,L.A.andNedHall.2013.Causation: AUser’sGuide.Oxford:OxfordUniversity
Press.

Pearl, Judea. 2000. Causality: Models, Reasoning, and Inference. Cambridge: Cam-
bridge University Press.

—. 2001. “Direct and Indirect Effects.” Pp. 411–20 in Proceedings of the Seventeenth
Conference on Uncertainty in Artificial Intelligence. San Francisco: Morgan Kauf-
mann.

—.2009.Causality: Models, Reasoning, and Inference,2nded.Cambridge:Cambridge
University Press.

—. 2011. “Principal Stratification – a Goal or a Tool?” International Journal of Bio-
statistics 7:1–13.

—.2012a.“TheCausalMediationFormula:AGuidetotheAssessmentPathwaysand
Mechanisms.” Prevention Science 13:426–36.

—. 2012b. “The Mediation Formula: A Guide to the Assessment of Causal Pathways
in Nonlinear Models.” Pp. 151–79 in Causality: Statistical Perspectives and Appli-
cations, edited by C. Berzuini, P. Dawid, and L. Bernardinelli. Hoboken: Wiley.

Petersen, Trond, Andrew M. Penner, and Geir Høgsnes. 2011. “The Male Marital
WagePremium:Sortingvs.DifferentialPay.”IndustrialandLaborRelations Review
64:283–304.

Peterson, Paul E. and William G. Howell. 2004. “Efficiency, Bias, and Classification
Schemes: A Response to Alan B. Krueger and Pei Zhu.” American Behavioral Sci-
entist 47:699–717.

Phelan,JoC.,BruceG.Link,AnaDiez-Roux,IchiroKawachi,andBruceLevin.2004.

“‘Fundamental Causes’ of Social Inequalities in Mortality: A Test of the Theory.”
Journal of Health and Social Behavior 45:265–85.

Phelan,JoC.,BruceG.Link,andParisaTehranifar.2010.“SocialConditionsasFun-
damentalCausesofHealthInequalities:Theory,Evidence,andPolicyImplications.”
Journal of Health and Social Behavior 51:S28–S40.

Powers,DanielA.andYuXie.2000.StatisticalMethods for Categorical DataAnalysis.

San Diego: Academic Press.

Pratt, John W. and Robert Schlaifer. 1984. “On the Nature and Discovery of Struc-
ture.” Journal of the American Statistical Association 79:9–33.

—. 1988. “On the Interpretation and Observation of Laws.” Journal of Econometrics
39:23–52.

Psillos, Stathis. 1999. Scientific Realism: How Science Tracks Truth. London: Rout-
ledge.

Putnam,Hilary.1975.Mind, Language, and Reality. New York:CambridgeUniversity
Press.

Quandt, Richard E. 1972. “A New Approach to Estimating Switching Regression.”
Journal of the American Statistical Association 67:306–10.

Raftery, Adrian E. 1995. “Bayesian Model Selection in Social Research.” Sociological
Methodology 25:111–63.

Ragin, Charles C. 1987. The Comparative Method: Moving Beyond Qualitative and
Quantitative Strategies. Berkeley: University of California Press.

—. 2008. Redesigning Social Inquiry: Fuzzy Sets and Beyond. Chicago: University of
Chicago Press.

Raudenbush, Stephen W. and Anthony S. Bryk. 2002. Hierarchical Linear Models:
Applications and Data Analysis Methods. Thousand Oaks: Sage.

Reardon, Sean F., Jacob E. Cheadle, and Joseph P. Robinson. 2009. “The Effect of
Catholic Schooling on Math and Reading Development in Kindergarten Through
Fifth Grade.” Journal of Research on Educational Effectiveness 2:45–87.

Reed, Isaac. 2011. Interpretation and Social Knowledge: On the Use of Theory in the
Human Sciences. Chicago: University of Chicago Press.

Reiersøl,Olav.1941.“ConfluenceAnalysisbyMeansofLagMomentsandOtherMeth-
ods of Confluence Analysis.” Econometrica 9:1–24.

Rein, Martin and Christopher Winship. 1999. “The Dangers of ‘Strong’ Causal Rea-
soning in Social Policy.” Society 36:38–46.

Reskin,BarbaraF.2003.“IncludingMechanismsinOurModelsofAscriptiveInequal-
ity.” American Sociological Review 68:1–21.

Retherford,RobertD. andNaohiroOgawa.2006.“Japan’sBabyBust: Causes,Impli-
cations,andPolicyResponses.”Pp.5–47inTheBabyBust:WhoWillDotheWork?
Who Will Pay the Taxes?,editedbyF.R.Harris.Lanham:RowmanandLittlefield.

Robins, James M. 1986. “A New Approach to Causal Inference in Mortality Studies
with a Sustained Exposure Period: Application to Control of the Healthy Worker
Survivor Effect.” Mathematical Modelling 7:1393–512.

—. 1997. “Causal Inference from Complex Longitudinal Data.” Pp. 69–117 in Latent
Variable Modeling and Applications to Causality: Lecture Notes in Statistics, edited
by M. Berkane. New York: Springer.

—. 1998. “Marginal Structural Models.” Pp. 1–10 in 1997 Proceedings of the Amer-
ican Statistical Association, Section on Bayesian Statistical Science. Alexandria,
Virginia.

—. 1999. “Association, Causation, and Marginal Structural Models.” Synthese 121:
151–79.

—. 2000. “Marginal Structural Models versus Structural Nested Modes as Tools for
Causal Inference.” Pp. 95–134 in Statistical Models in Epidemiology: The Environ-
ment and Clinical Trials, edited by M. E. Halloran and D. A. Berry. New York:
Springer.

Robins,JamesM.andSanderGreenland.2000.“Commenton‘CausalInferenceWith-
out Counterfactuals’ by A. P. Dawid.” Journal of the American Statistical Associa-
tion 95:431–35.

Robins, James M. and Miguel A. Hern´an. 2009. “Estimation of the Causal Effects of
Time-Varying Exposures.” Pp. 553–99 in Longitudinal Data Analysis, edited by G.

Fitzmaurice,M.Davidian,G.Verbeke,andG.Molenberghs.BocaRaton:Chapman
& Hall/CRC.

Robins,JamesM.andThomasRichardson.2010.“AlternativeGraphicalCausalMod-
els and the Identification of Direct Effects.” Center for Statistics and the Social
Sciences, Working Paper 100, University of Washington, Seattle, Washington.

Robins,JamesM.andYa’acovRitov.1997.“TowardaCurseofDimensionalityAppro-
priate (CODA) Asymptotic Theory for Semi-Parametric Models.” Statistics in
Medicine 16:285–319.

Robins,JamesM.andAndreaRotnitzky.2001.“Commenton‘InferenceforSemipara-
metric Models: Some Questions and an Answer’ by Bickel and Kwon.” Statistica
Sinica 11:920–36.

Robins,JamesM.,AndreaRotnitzky,andLuePingZhao.1994.“EstimationofRegres-
sionCoefficients When Some RegressorsAre Not AlwaysObserved.”Journal of the
American Statistical Association 89:846–66.

Rohwer, Go¨tz. 2010. Models in Statistical Social Research. London: Routledge.

Rose, Arnold. 1962. “Review of Social Research to Test Ideas: Selected Writings by
Samuel A. Stouffer.” American Sociological Review 27:720–21.

Rose,ArnoldM.1942.“AResearchNoteontheInfluenceofImmigrationontheBirth
Rate.” American Journal of Sociology 47:614–21.

Rosen, SherwinandPaulTaubman. 1982.“ChangesinLife-Cycle Earnings:What Do
Social Security Data Show?” Journal of Human Resources 17:321–38.

Rosenbaum, Paul R. 1987. “Model-Based Direct Adjustment.” Journal of the Ameri-
can Statistical Association 82:387–94.

—. 1989. “Optimal Matching for Observational Studies.” Journal of the American
Statistical Association 84:1024–32.

—. 1991. “Sensitivity Analysis for Matched Case Control Studies.” Biometrics 47:
87–100.

—. 1992. “Detecting Bias with Confidence in Observational Studies.” Biometrika
79:367–74.

—. 1999. “Choice as an Alternative to Control in Observational Studies.” Statistical
Science 14:259–304.

—. 2002. Observational Studies. New York: Springer.

—. 2010. Design of Observational Studies. New York: Springer.

—. 2012. “Optimal Matching of an Optimally Chosen Subset in Observational Stud-
ies.” Journal of Computational and Graphical Statistics 21:57–71.

Rosenbaum,PaulR. andDonaldB. Rubin. 1983a.“AssessingSensitivity to anUnob-
served Covariate in an Observational Study with Binary Outcome.” Journal of the
Royal Statistical Society 45:212–18.

—. 1983b. “The Central Role of the Propensity Score in Observational Studies for
Causal Effects.” Biometrika 70:41–55.

—. 1984. “Reducing Bias in Observational Studies Using Subclassification on the
Propensity Score.” Journal of the American Statistical Association 79:516–24.

—. 1985a. “The Bias Due to Incomplete Matching.” Biometrics 41:103–16.

—. 1985b. “Constructing a Control Group Using Multivariate Matched Sampling
Methods.” American Statistician 39:33–38.

Rosenzweig, Mark R. and Kenneth I. Wolpin. 2000. “Natural ‘Natural Experiments’
in Economics.” Journal of Economic Literature 38:827–74.

Rossell, Christine H., David J. Armor, and Herbert J. Walberg, Eds. 2002. School
Desegregation in the 21st Century. Westport: Praeger.

Rothman, Kenneth J., Sander Greenland, and Timothy L. Lash. 2008. Modern Epi-
demiology. Philadelphia: Wolters Kluwer Health/Lippincott Williams & Wilkins.

Roy,A. D. 1951.“Some Thoughtsonthe Distribution ofEarnings.”Oxford Economic
Papers 3:135–46.

Rubin, Donald B. 1973a. “Matching to Remove Bias in Observational Studies.” Bio-
metrics 29:159–83.

—.1973b.“TheUseofMatchedSamplingandRegressionAdjustmenttoRemoveBias
in Observational Studies.” Biometrics 29:185–203.

—. 1974. “Estimating Causal Effects of Treatments in Randomized and Nonrandom-
ized Studies.” Journal of Educational Psychology 66: 688–701.

—. 1976. “Multivariate Matching Methods That Are Equal PercentBias Reducing, I:
Some Examples.” Biometrics 32:109–20.

—. 1977. “Assignment to Treatment Group on the Basis of a Covariate.” Journal of
Educational Statistics 2:1–26.

—.1978.“BayesianInferenceforCausalEffects:TheRoleofRandomization.”Annals
of Statistics 6:34–58.

—. 1979. “Using Multivariate Matched Sampling and RegressionAdjustment to Con-
trolBiasinObservationalStudies.” Journal of the American Statistical Association
74:318–28.

—. 1980a. “Bias Reduction Using Mahalanobis-Metric Matching.” Biometrics 36:
293–98.

—.1980b.“Commenton‘RandomizationAnalysisofExperimentalDataintheFisher
Randomization Test’ by Basu.” Journal of the American Statistical Association
75:591–93.

—. 1981. “Estimation in Parallel Randomized Experiments.” Journal of Educational
Statistics 6:377–400.

—. 1986.“Which Ifs Have CausalAnswers (Commenton ‘Statistics andCausal Infer-
ence’ by Paul W. Holland).” Journal of the American Statistical Association 81:
961–62.

—. 1990. “Formal Modes of Statistical Inference for Causal Effects.” Journal of Sta-
tistical Planning and Inference 25:279–92.

—. 1991. “Practical Implications of Modes of Statistical Inference for Causal Effects
and the Critical Role of the Assignment Mechanism.” Biometrics 47:1213–34.

—. 2005. “Causal Inference Using Potential Outcomes: Design, Modeling, Decisions.”
Journal of the American Statistical Association 100:322–31.

—.2006.MatchedSamplingforCausalEffects.NewYork:CambridgeUniversityPress.

Rubin, Donald B. and Neal Thomas. 1992. “Characterizing the Effect of Matching
Using Linear Propensity Score Methods with Normal Distributions.” Biometrika
79:787–809.

—.1996.“MatchingUsingEstimatedPropensityScores:RelatingTheorytoPractice.”
Biometrics 52:249–64.

—. 2000. “Combining Propensity Score Matching with Additional Adjustments for
Prognostic Covariates.” Journal of the American Statistical Association 95:573–85.

Ruppert, David, M. P. Wand, and RaymondJ. Carroll.2003.Semiparametric Regres-
sion. Cambridge: Cambridge University Press.

Ruud, Paul A. 2000. An Introduction to Classical Econometric Theory. New York:
Oxford University Press.

Salmon,WesleyC.1984.ScientificExplanation andtheCausalStructureoftheWorld.

Princeton: Princeton University Press.

—.1989.FourDecadesofScientificExplanation.Minneapolis:UniversityofMinnesota
Press.

Saltelli, Andrea, Stefano Tarantola, Francesca Campolongo, and Marco Ratto. 2004.

Sensitivity Analysis in Practice: A Guide to Assessing Scientific Models. Hoboken:
Wiley.

Sampson, Robert J. 2008. “Moving to Inequality: Neighborhood Effects and Experi-
ments Meet Social Structure.” American Journal of Sociology 114:189–231.

—.2012.GreatAmericanCity:ChicagoandtheEnduringNeighborhoodEffect.Chicago:
University of Chicago Press.

Sampson, Robert J., Patrick Sharkey, and Stephen W. Raudenbush. 2008. “Durable
Effects of Concentrated Disadvantage on Verbal Ability among African-American
Children.” Proceedings of the National Academy of Sciences 105:
845–52.

Scharfstein,Daniel O., AndreaRotnitzky, andJamesM. Robins. 1999.“Adjusting for
NonignorableDrop-outUsingSemiparametricNonresponseModels.”Journal of the
American Statistical Association 94:1096–120.

Schofield,JanetWard.1995.“ReviewofResearchonSchoolDesegregation’sImpacton
ElementaryandSecondary School Students.” Pp. 597–617in Handbook of Research
on Multicultural Education, edited by J. A. Banks and C. A. M. Banks. New York:
Macmillan.

Schultz, Henry. 1938. The Theory and Measurement of Demand. Chicago: University
of Chicago Press.

Schwartz, Saul. 1986. “The Relative Earnings of Vietnam and Korean-EraVeterans.”
Industrial and Labor Relations Review 39:564–72.

Sekhon, Jasjeet S. 2004. “The 2004 Florida Optical Voting Machine Controversy: A
CausalAnalysisUsingMatching.”WorkingPaper,DepartmentofGovernment,Har-
vard University, Cambridge, Massachusetts.

—. 2007. “Alternative Balance Metrics for Bias Reduction in Matching Methods for
CausalInference.”WorkingPaper,SurveyResearchCenter,UniversityofCalifornia,
Berkeley, California.

—. 2009. “Opiates for the Matches: Matching Methods for Causal Inference.” Annual
Review of Political Science 12:487–508.

—.2013.“Matching.”SoftwareRoutineforR,TraversDepartmentofPoliticalScience,
University of California, Berkeley, California.

Sekhon,JasjeetS.andRocioTitiunik.2012.“WhenNaturalExperimentsAreNeither
Natural Nor Experiments.” American Political Science Review 106:35–57.

Seltzer, Judith A., Christine A. Bachrach, Suzanne M. Bianchi, Caroline H. Bled-
soe, Lynne M. Casper, P. Lindsay Chase-Lansdale et al. 2005. “Explaining Family
Change and Variation: Challenges for Family Demographers.” Journal of Marriage
and Family 67:908–25.

Sewell, William H. 1964. “Community of Residence and College Plans.” American
Sociological Review 29:24–38.

Sewell, William H., Archibald O. Haller, and George W. Ohlendorf. 1970. “The Edu-
cational and Early Occupational Status Attainment Process: Replication and Revi-
sion.” American Sociological Review 35:1014–24.

Sewell,WilliamH.,ArchibaldO.Haller,andAlejandroPortes.1969.“TheEducational
and Early Occupational Attainment Process.” American Sociological Review 34:
82–92.

Sewell, William H., Robert M. Hauser, Kristen W. Springer, and Taissa S. Hauser.

2004. “As We Age: A Review of the Wisconsin Longitudinal Study, 1957–2001.”
Research in Social Stratification and Mobility 20:3–111.

Shadish, William R., Thomas D. Cook, and Donald Thomas Campbell. 2001.Experi-
mental and Quasi-Experimental Designs for Generalized Causal Inference. Boston:
Houghton Mifflin.

Shadish,WilliamR.,RodolfoGalindo,VivianC.Wong,PeterM.Steiner,andThomas
D. Cook. 2011.“A Randomized Experiment Comparing Random and Cutoff-Based
Assignment.” Psychological Methods 16:179–91.

Shalizi,CosmaRohilla.2012.“Commenton‘WhyandWhen“Flawed”SocialNetwork
Analyses Still Yield Valid Tests of No Contagion.”’ Statistics, Politics, and Policy
3:1–3.

Shalizi, Cosma Rohilla and Andrew C. Thomas. 2011. “Homophily and Contagion
Are Generically Confounded in ObservationalSocial Network Studies.” Sociological
Methods and Research 40:211–39.

Sharkey, Patrick and Felix Elwert. 2011. “The Legacy of Disadvantage: Multigenera-
tional Neighborhood Effects on Cognitive Ability.” American Journal of Sociology
116:1934–81.

Shpitser, Ilya. 2012a. “Graph-Based Criteria of Identifiability of Causal Questions.”
Pp. 59–70 in Causality: Statistical Perspectives and Applications, edited by
C. Berzuini, P. Dawid, and L. Bernardinelli. Hoboken: Wiley.

—. 2012b.“Structural Equations,Graphs and Interventions.”Pp. 15–24in Causality:
Statistical Perspectives and Applications, edited by C. Berzuini, P. Dawid, and L.

Bernardinelli. Hoboken: Wiley.

Shpitser, Ilya and Judea Pearl. 2007. “What Counterfactuals Can Be Tested.” Pp.

352–59 in Proceedings of the Twenty-Third Conference on Uncertainty in Artifi-
cial Intelligence, edited by R. Parr and L. van der Gaag. Corvallis: Association for
Uncertainty in Artificial Intelligence Press.

Shpitser, Ilya,TylerJ. VanderWeele, andJamesM. Robins. 2010.“Onthe Validity of
CovariateAdjustment for Estimating Causal Effects.” Pp. 527–36in Proceedings of
the Twenty-Sixth Conference on Uncertainty in Artificial Intelligence, edited by P.

Gru¨nwald and P. Spirtes. Catalina Island: Association for Uncertainty in Artificial
Intelligence Press.

Singer,BurtonandMargaretM.Marini. 1987.“AdvancingSocial Research:AnEssay
Based on Stanley Lieberson’s Making It Count.” Sociological Methodology 17:
373–91.

Small, Dylan S. and Paul R. Rosenbaum. 2008. “War and Wages: The Strength of
Instrumental Variables and Their Sensitivity to UnobservedBiases.” Journal of the
American Statistical Association 103:924–33.

Smith, HerbertL. 1989.“IntegratingTheoryandResearchonthe InstitutionalDeter-
minants of Fertility.” Demography 26:171–84.

—.1990.“SpecificationProblemsinExperimentalandNonexperimentalSocialResearch.”
Sociological Methodology 20:59–91.

—. 1997. “Matching with Multiple Controls to Estimate Treatment Effects in Obser-
vational Studies.” Sociological Methodology 27:325–53.

—. 2003.“Some Thoughtson Causationas It Relates to DemographyandPopulation
Studies.” Population and Development Review 29:459–69.

—. 2009. “Causation and Its Discontents.” Pp. 233–42 in Causal Analysis in Pop-
ulation Studies: Concepts, Methods, Applications, edited by H. Engelhardt, H.-P.

Kohler, and A. Prskawetz. Dordrecht: Springer.

—. 2013. “Research Design: Toward a Realistic Role for Causal Analysis.” Pp. 45–
73 in Handbook of Causal Analysis for Social Research, edited by S. L. Morgan.

Dordrecht: Springer.

Smith,JefferyA.andPetraTodd.2005.“DoesMatchingOvercomeLalonde’sCritique
of Nonexperimental Estimators?” Journal of Econometrics 125:305–53.

Sobel, Michael E. 1995. “Causal Inference in the Social and Behavioral Sciences.”
Pp.1–38inHandbook of Statistical Modeling for the Social and Behavioral Sciences,
edited by G. Arminger, C. C. Clogg, and M. E. Sobel. New York:
Plenum.

—. 1996. “An Introduction to Causal Inference.” Sociological Methods and Research
24:353–79.

—.2000.“CausalInferenceintheSocialSciences.”Journalof theAmerican Statistical
Association 95:647–51.

—. 2006. “What Do Randomized Studies of Housing Mobility Demonstrate? Causal
Inference in the Face of Interference.” Journal of the American Statistical Associa-
tion 101:1398–407.

Sondheimer, Rachel M. and Donald P. Green. 2010. “Using Experiments to Estimate
the Effects of Education on Voter Turnout.” American Journal of Political Science
54:174–89.

Sørensen, Aage B. 1998. “Theoretical Mechanisms and the Empirical Study of Social
Processes.”Pp.238–66inSocialMechanisms:AnAnalyticalApproachtoSocialThe-
ory, Studies in Rationality and Social Change, edited by P. Hedstr¨omandR. Swed-
berg. Cambridge: Cambridge University Press.

Sørensen, Aage B. and Stephen L. Morgan. 2000. “School Effects: Theoretical and
MethodologicalIssues.”Pp.137–60inHandbookoftheSociologyofEducation,edited
by M. T. Hallinan. New York: Kluwer/Plenum.

Sovey, Allison J. and Donald P. Green. 2011. “Instrumental Variables Estimation in
Political Science: A Readers’ Guide.” American Journal of Political Science 55:
188–200.

Staiger, Douglas and James H. Stock. 1997. “IV Regressionwith Weak Instruments.”
Econometrica 65:557–86.

Steiner,PeterM.,ThomasD.Cook,WilliamR.Shadish,andM.H.Clark.2010.“The
ImportanceofCovariateSelectioninControllingforSelectionBiasinObservational
Studies.” Psychological Methods 15:250–67.

Stevens, Mitchell L., Elizabeth A. Armstrong, and Richard Arum. 2008.“Sieve, Incu-
bator,Temple,Hub:EmpiricalandTheoreticalAdvancesintheSociologyofHigher
Education.” Annual Review of Sociology 34:127–51.

Stewart, Susan T., David M. Cutler, and Allison B. Rosen. 2009. “Forecasting the
Effects of Obesity and Smoking on U.S. Life Expectancy.” New England Journal of
Medicine 361:2252–60.

Stock, James H. and Mark W. Watson. 2007. Introduction to Econometrics. Boston:
Pearson/AddisonWesley.

Stolzenberg, Ross M. 2004.“Multiple RegressionAnalysis.” Pp. 165–207in Handbook
of Data Analysis, edited by M. A. Hardy and A. Bryman. Thousand Oaks: Sage.

Stouffer, Samuel A. 1949. The American Soldier. Princeton: Princeton University
Press.

—.1950.“SomeObservationsonStudyDesign.”AmericanJournalofSociology55:355–
61.

—.1955.Communism, Conformity, and Civil Liberties: A Cross-Section of the Nation
Speaks Its Mind. Garden City: Doubleday.

—. 1962[1948].Social Research to Test Ideas. Glencoe: Free Press.

Strevens, Michael. 2008. Depth: An Account of Scientific Explanation. Cambridge:
Harvard University Press.

Stuart, Elizabeth A. 2010. “Matching Methods for Causal Inference: A Review and a
Look Forward.” Statistical Science 25:1–21.

Stuart, Elizabeth A. and Nicholas S. Ialongo. 2010. “Matching Methods for Selection
of Participants for Follow-Up.” Multivariate Behavioral Research 45:746–65.

Swinburn,BoydA., GarySacks,KevinD. Hall,KlimMcPherson,Diane T.Finegood,
Marjory L. Moodie et al. 2011. “The Global Obesity Pandemic: Shaped by Global
Drivers and Local Environments.” Lancet 378:804–14.

Tchetgen Tchetgen, Eric J. and Tyler J. VanderWeele. 2010. “On Causal Inference in
the Presence of Interference.” Statistical Methods in Medical Research 21:55–75.

Tenn, Steven. 2005. “An Alternative Measure of Relative Education to Explain Voter
Turnout.” Journal of Politics 67:271–82.

Thistlewaite, D. L. and Donald T. Campbell. 1960. “Regression-Discontinuity Anal-
ysis: An Alternative to the Ex Post Facto Experiment.” Journal of Educational
Psychology 51:309–17.

Thompson, Steven K. 2002. Sampling. New York: Wiley.

Thompson,WarrenS.1948.“DifferentialsinFertilityandLevelsofLivingintheRural
Population of the United States.” American Sociological Review 13:516–34.

—.1949.“TheDemographicRevolutionintheUnitedStates.”AnnalsoftheAmerican
Academy of Political and Social Science 262:62–69.

Thornton, Arland, Georgina Binstock, Kathryn M. Yount, Mohammad Jalal Abbasi-
Shavazi, Ghimire Dirgha, and Yu Xie. 2012. “International Fertility Change: New
Data and Insights from the Developmental Idealism Framework.” Demography
49:677–98.

Treiman, Donald J. 2009. Quantitative Data Analysis: Doing Social Research to Test
Ideas. San Francisco: Jossey-Bass.

Trochim, William M. K. 1984. Research Design for Program Evaluation: The
Regression-Discontinuity Approach. Beverly Hills: Sage Publications.

Tu, Wanzhu and Xiao-Hua Zhou. 2002. “A Bootstrap Confidence Interval Procedure
for the TreatmentEffect Using PropensityScore Subclassification.” Health Services
& Outcomes Research Methodology 3:135–47.

Tuttle,ChristinaC.,BrianGill,PhilipGleason,VirginiaKnechtel,IraNichols-Barrer,
and Alexandra Resch. 2013. “KIPP Middle Schools: Impacts on Achievement and
Other Outcomes.” Mathematica Policy Research, Washington, DC.

Tyack,DavidB.1974.TheOneBestSystem:AHistoryofAmericanUrbanEducation.

Cambridge: Harvard University Press.

Uggen,Christopher,AngelaBehrens,andJeffManza.2005.“CriminalDisenfranchise-
ment.” Annual Review of Law and Social Science 1:307–22.

Uggen, ChristopherandJeff Manza.2002.“DemocraticContraction?Political Conse-
quences of Felon Disenfranchisement in the United States.” American Sociological
Review 67:777–803.

Valliant,Richard,JillA. Dever,andFraukeKreuter.2013.Practical Tools for Design-
ing and Weighting Survey Samples. New York: Springer.

Van der Klaauw, Wilbert. 2002. “Estimating the Effect of Financial Aid Offers on
CollegeEnrollment:ARegression-DiscontinuityApproach.”InternationalEconomic
Review 43:1249–87.

van der Laan, M. J. and James M. Robins. 2003. Unified Methods for Censored Lon-
gitudinal Data and Causality. New York: Springer.

VanderWeele, Tyler J. 2008. “Simple Relations Between Principal Stratification and
Direct and Indirect Effects.” Statistics and Probability Letters 78:2957–62.

—. 2009a. “Marginal Structural Models for the Estimation of Direct and Indirect
Effects.” Epidemiology 20:18–26.

—. 2009b. “On the Distinction Between Interaction and Effect Modification.” Epi-
demiology 20:863–71.

—. 2010. “Bias Formulas for Sensitivity Analysis for Direct and Indirect Effects.”
Epidemiology 21:540–51.

—. 2011a. “Principal Stratification – Uses and Limitations.” International Journal of
Biostatistics 7:1–14.

—.2011b.“SensitivityAnalysisforContagionEffectsinSocialNetworks.”Sociological
Methods and Research 40:240–55.

—. 2012.“Mediation Analysis with Multiple Versions of the Mediator.” Epidemiology
23:454–63.

—. In press.Explanation in Causal Inference: Methods for Mediation and Interaction.

Oxford: Oxford University Press.

VanderWeele, TylerJ. andWeihua An. 2013.“SocialNetworksandCausal Analysis.”
Pp. 353–74 in Handbook of Causal Analysis for Social Research, edited by S. L.

Morgan. Dordrecht: Springer.

VanderWeele, Tyler J. and James M. Robins. 2007a. “Four Types of Effect Modifica-
tion: A Classification Based on Directed Acyclic Graphs.” Epidemiology 18:561–68.

—.2007b.“TheIdentificationofSynergismintheSufficient-Component-CauseFrame-
work.” Epidemiology 18:329–39.

—.2008.“EmpiricalandCounterfactualConditionsforSufficientCauseInteractions.”
Biometrika 95:49–61.

—. 2009. “Minimal Sufficient Causation and Directed Acyclic Graphs.” Annals of
Statistics 37:1437–65.

VanderWeele, Tyler J. and Ilya Shpitser. 2011. “A New Criterion for Confounder
Selection.” Biometrics 67:1406–13.

VanderWeele, Tyler J., Stijn Vansteelandt, and James M. Robins. 2010. “Marginal
StructuralModelsforSufficientCauseInteractions.”American Journal of Epidemi-
ology 171:506–14.

Vansteelandt,Stijn,TylerJ.VanderWeele,andJamesM.Robins.2012.“Semiparamet-
ric Tests for Sufficient Cause Interaction.” Journal of the Royal Statistical Society
74:223–44.

Verba, Sidney and Norman H. Nie. 1972. Participation in America: Political Democ-
racy and Social Equality. New York: Harper.

Verba,Sidney,KayLehmanSchlozman,andHenryE.Brady.1995.VoiceandEquality:
Civic Voluntarism in American Politics. Cambridge: Harvard University Press.

Vytlacil,EdwardJ.2002.“Independence,Monotonicity,andLatentIndexModels:An
Equivalence Result.” Econometrica 70:331–41.

Wald, Abraham. 1940. “The Fitting of Straight Lines If Both Variables Are Subject
to Error.” Annals of Mathematical Statistics 11:284–300.

Wand, Jonathan, Kenneth W. Shotts, Jasjeet S. Sekhon, Walter R. Mebane Jr.,
Michael C. Herron, and Henry E. Brady. 2001. “The Butterfly Did It: The Aber-
rantVoteforBuchananinPalmBeachCounty,Florida.”AmericanPolitical Science
Review 95:793–810.

Wang, Xiaolu and Michael E. Sobel. 2013. “New Perspectives on Causal Mediation
Analysis.” Pp. 215–42 in Handbook of Causal Analysis for Social Research, edited
by S. L. Morgan. Dordrecht: Springer.

Wells, Amy Stuart and Robert L. Crain. 1994. “Perpetuation Theory and the Long-
Term Effects of School Desegregation.”Review of Educational Research 64:531–55.

West, Martin R. and Ludger Woessmann. 2010. “‘Every Catholic Child in a Catholic
School’: Historical Resistance to State Schooling, Contemporary Private Competi-
tion and Student Achievement across Countries.” Economic Journal 120:F229–55.

Westoff, Charles F. and Larry Bumpass. 1973. “The Revolution in Birth Control of
U.S. Roman Catholics.” Science 179:41–44.

Westoff,CharlesF.andEliseF.Jones.1979.“TheEndof‘Catholic’Fertility.”Demog-
raphy 16:209–17.

Westoff,CharlesF.andNormanB.Ryder.1977.TheContraceptiveRevolution.Prince-
ton: Princeton University Press.

Whelpton, Pascal K. 1932. “Trends in Age Composition and in Specific Birth-Rates,
1920–30.”American Journal of Sociology 37:855–61.

White, Halbert and Karim Chalak. 2009. “Settable Systems: An Extension of Pearl’s
Causal Model with Optimization, Equilibrium, and Learning.” Journal of Machine
Learning Research 10:1759–99.

Willis, Robert and Sherwin Rosen. 1979. “Education and Self-Selection.” Journal of
Political Economy 87:S7–S35.

Willms, J. Douglas. 1985. “Catholic-School Effects on Academic Achievement: New
Evidence from the High School and Beyond Follow-up Study.” Sociology of Educa-
tion 58:98–114.

Wilson, William Julius. 2011. “Reflections on a Sociological Career That Integrates
Social Science with Social Policy.” Annual Review of Sociology 37:1–18.

Wimer, Christopher, Robert J. Sampson, and John Laub. 2008. “Estimating Time-
Varying Causes and Outcomes, with Application to Incarceration and Crime.” Pp.

37–59 in Applied Data Analytic Techniques for Turning Points Research, edited by
P. Cohen. New York: Routledge.

Winship,ChristopherandDavidJ.Harding.2008.“AGeneralStrategyfortheIdenti-
ficationofAge,Period,CohortModels:AMechanism-BasedApproach.”Sociological
Methods and Research 36:362–401.

Winship, Christopher and Sanders Korenman. 1997. “Does Staying in School Make
You Smarter? The Effect of Education on IQ in the Bell Curve.” Pp. 215–34 in
Intelligence, Genes, and Success: Scientists Respond to the Bell Curve, edited by B.

Devlin, S. E. Fienberg, D. P. Resnick, and K. Roeder. New York:
Springer.

Winship, Christopher and Robert D. Mare. 1984. “Regression Models with Ordinal
Variables.” American Sociological Review 49:512–25.

—. 1992. “Models for Sample Selection Bias.” Annual Review of Sociology 18:
327–50.

Winship,ChristopherandStephenL.Morgan.1999.“TheEstimationofCausalEffects
from Observational Data.” Annual Review of Sociology 25:659–706.

Winship, Christopher and Michael E. Sobel. 2004. “Causal Analysis in Sociological
Studies.”Pp.481–503inHandbook of Data Analysis,editedbyM.A.HardyandA.

Bryman. Thousand Oaks: Sage.

Winship,ScottandChristopherWinship.2013.“ThePermanentandTransitoryEffect
ofSchoolingonMental Ability.” WorkingPaper,DepartmentofSociology,Harvard
University, Cambridge, Massachusetts.

Wodtke,GeoffreyT.,DavidJ.Harding,andFelixElwert.2011.“NeighborhoodEffects
inTemporalPerspective:The Impactof Long-TermExposureto ConcentratedDis-
advantage on High School Graduation.” American Sociological Review 76:713–36.

Wong,VivianC.,PeterM.Steiner,andThomasD.Cook.2013.“AnalyzingRegression-
DiscontinuityDesignswithMultipleAssignmentVariables:AComparativeStudyof
FourEstimationMethods.”JournalofEducationalandBehavioralStatistics38:107–
41.

Woodward, James. 2003. Making Things Happen: A Theory of Causal Explanation.

New York: Oxford University Press.

Wooldridge, Jeffrey M. 2010.Econometric Analysis of Cross Section and Panel Data.

Cambridge: MIT Press.

Working,E.J.1927.“WhatDoStatistical‘DemandCurves’Show?”QuarterlyJournal
of Economics 41:212–35.

Working, Holbrook. 1925. “The Statistical Determination of Demand Curves.” Quar-
terly Journal of Economics 39:503–45.

Wright, Erik Olin. 1997. Class Counts: Comparative Studies in Class Analysis. Cam-
bridge: Cambridge University Press.

Wright, Sewall. 1921. “Correlation and Causation.” Journal of Agricultural Research
20:557–85.

—. 1925.“CornandHogCorrelations.”U.S. DepartmentofAgriculture,Washington,
DC.

—.1934.“TheMethodofPathCoefficients.”AnnalsofMathematical Statistics5:161–
215.

Wu, Lawrence and Barbara L. Wolfe, Eds. 2001. Out of Wedlock: Causes and Conse-
quences of Nonmarital Fertility. New York: Russell Sage Foundation.

Wu, Lawrence L. 1996. “Effects of Family Instability, Income, and Income Instability
on the Risk of a Premarital Birth.” American Sociological Review 61:386–406.

—. 2008. “Cohort Estimates of Nonmarital Fertility for U.S. Women.” Demography
45:193–207.

Xie, Yu. 2007. “Otis Dudley Duncan’s Legacy: The Demographic Approach to Quan-
titative Reasoning in Social Science.” Research in Social Stratification and Mobility
25:141–56.

—.2011.“PopulationHeterogeneityandCausalInference.”PopulationStudiesCenter,
Institute for Social Research, University of Michigan, Ann Arbor, Michigan.

Xie,Yu, JennieE.Brand,andBenJann.2012.“EstimatingHeterogeneousTreatment
Effects with Observational Data.” Sociological Methodology 42:314–47.

Yamamoto, Teppei. 2012. “Understanding the Past: Statistical Analysis of Causal
Attribution.” American Journal of Political Science 56:237–56.

Yang,Dan,DylanS.Small,JeffreyH.Silber,andPaulR.Rosenbaum.2012.“Optimal
Matching with Minimal Deviation from Fine Balance in a Study of Obesity and
Surgical Outcomes.” Biometrics 68:628–36.

Yinger, Milton J., Kiyoshi Ikeda, and Frank Laycock. 1967. “Treating Matching as a
Variable in a Sociological Experiment.” American Sociological Review 32:801–12.

Zhang, Junni L., Donald B. Rubin, andFabriziaMealli. 2008.“Evaluatingthe Effects
ofJobTraining ProgramsonWages ThroughPrincipalStratification.”Advances in
Econometrics 21:117–45.

—.2009.“Likelihood-BasedAnalysisofCausalEffectsofJob-TrainingProgramsUsing
Principal Stratification.” Journal of the American Statistical Association 104:166–
76.

Zhao, Shandong, David A. van Dyk, and Kosuke Imai. 2012. “Causal Inference in
ObservationalStudieswithNon-BinaryTreatments.”DepartmentofStatistics,Uni-
versity of California, Irvine, California.

Zubizarreta, Jos´e R. 2012. “Using Mixed Integer Programming for Matching in an
Observational Study of Kidney Failure After Surgery.” Journal of the American
Statistical Association 107:1360–71.

# Index

adjustment criterion, 136–39 complier, 306–14, 320–21

always taker, 306–14, 320–21 conditioning, 82-84
analysis of covariance model, 275–77, control group, 44–45
364–88 control state, 37, 43–44
averagecausal effect, see counterfactual, 37–46
averagetreatment effect conditional expectation, 58
averagetreatment effect, 46–48 covering law, 11, 340–43, 442
conditional, 55–56
for the controls, 55 data-driven specification search, 130,
for the treated, 55 222–23
deffer, 306–14, 320–21
back-door criterion, 109–10 descendant, 80
back-door path, 106 directed acyclic graph (DAG), 80, 96
blocking, 110–14 directed path, 80
balancing
definition of balance, 128 error term, 88–89, 122–24, 131–36,
versus adjustment, 128–30 196–200
determinants of treatment, 162–66 examples
bias, 58–60 Catholic schools, 22–23, 39–41, 47, 50,
baseline, 59 55–58, 61, 120–21, 171–80, 215,
differential treatment effect, 59 220–24, 234–37, 243–62, 269–77,
omitted-variable, 110, 194–206 300–301, 317, 348, 365–374, 394–413
self-selection, 122, 197, 287 charter schools, 3, 24–25, 38, 50,
bound, 422 85–90, 278–90, 318–22
analysis of, 422–29 class size, 362
combinations of, 429–29 educational attainment, 14–15, 327–28
no-assumptions, 422–25 education on earnings, 15–16, 59–60,
72–73, 83–84, 98–101, 195–96, 219,
causal effect, see averagetreatment effect 299
and treatment effect father absence, 21–22, 38–39
causal graph, 79–81, 97–99 fertility, 17–19, 67
causal state, 37–43 felons and election outcomes, 42
chain of mediation, 81, 331 health and mortality, 19–20, 41–42,
change score model, 364–88 299–300
collider, 81 military service, 300, 328–29
497
examples (cont.) marginal treatment effect (MTE), 322–23
neighborhoods, 21, 85–90, 284–89, 318, matching
322, 432 as data analysis algorithm, 158–81
obesity, 26, 52, 432–34 as stratification, 143–50
Operation Ceasefire, 357–360 as weighting, 150–58
political participation, 16–17 caliper, 160–61
voting, 26–27 coarsened exact, 169–70, 181
school vouchers, 23–24 exact, 159–160
worker training, 25–26, 390–91 genetic, 167–68
Year of the Fire Horse, 64–68, 355, 360 interval, 161
experiment kernel, 162
definition of, 6 many-valued causes, 185–86
experimental design, 6-7, 118–19 Matching Demonstration 1, 145–47
Matching Demonstration 2, 148–50
front-door criterion, 330-38 Matching Demonstration 3, 153–56
Matching Demonstration 4, 171–80
generative mechanism, 338–42
nearest-neighbor, 160–61
on the region of common support,
how-actually model, 345–46
182–83
how-plausibly model, 345
optimal, 168–69
how-possibly model, 345
mechanism, 330–53
ignorability, 119–22, 127, 205, 268–69, exhaustive, 332–38
430–32 isolated, 332–38
sequential, 396–97 mechanism schema, 347, 349
independence mechanism sketch, 347, 349–52,
of potential outcomes from treatment, 440–41
119 monotone instrumental variable (MIV),
of instrument, 307, 311–13 427–28
instrumental variable(IV) monotone treatment response (MTR),
binary, 291–94 426–27
IV Demonstration 1, 294–96 monotone treatment selection (MTS),
IV Demonstration 2, 309–314 426–27
LATE assumptions,k 305–309 monotonicity
Traditional assumptions, 297–99 of response to instrument, 307–309
interrupted time series (ITS) design, 67,
na¨ıve estimator, 57–60
355–60
natural experiment, 303–305, 326–30
local average treatment effect (LATE), never taker, 306–14, 320–21
305, 327 nonignorable, see ignorability
local instrumental variable (LIV), 323, nonmanipulability, 339, 439–41
421
observational study, 7, 54
Mahalanobis metric, 158 omitted variable bias, see bias, omitted
manipulability, 339, 439–41 variable
many-valued treatments, 70–73, 185–86, ordinary least squares (OLS), see
218–19 regression,ordinary least squares
panel data, 68–70, 363–92 Weighted Regression Demonstration 1,
Panel Data Demonstration 1, 273–77 229–30, 232–33
Panel Data Demonstration 2, 365–74 Weighted Regression Demonstration 2,
partial identification, see bound, 235–37
analysis of Weighted Regression Demonstration 3,
path, 80 243–62
path model, 10, 85–87 regressiondiscontinuity (RD) design,
point identification, 78–79, 422 360–63
policy-relevant treatment effect (PRTE),
323 selection
population, 27–28, 37, 74–76 on the observables, 124–26,
potential outcome, 43–46 268
over-time, 62–70 on the unobservables, 124–26,
propensity score, 118–22, 151 268
estimated, 152, 157–58, 166–68 sensitivity analysis, 429–34
true, 118–22, 151 set identification, 422
stable unit treatment value assumption
quasi-experiment, 9 (SUTVA), 48–52, 307, 438
stratification, see conditioning and
realism, 445–46 matching, as stratification
critical, 343–44 superpopulation, 28, 74–76
regression,9–13, 188–225
as conditional-variance-weighted treatment assignment, 53–54
matching, 206–14 treatment effect, 43–44
ordinary least squares (OLS), 201–202 treatment group, 44–45
RegressionDemonstration 1, 189–92 treatment selection, see selection and
RegressionDemonstration 2, 207–11 treatment assignment, 37, 43–44
RegressionDemonstration 3, 213–14 two-stage lease squares (2SLS),
RegressionDemonstration 4, 216–17 316–17
as supplemental adjustment when
matching, 215–217 unconditional association, 81–82
weighted, 226–63 weighted regression, see regression
